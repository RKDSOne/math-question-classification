"<p>Suppose that $f(x) \leq g(x) \text{ for all }x$. Prove that $\lim_{x\to a} f(x) \leq \lim_{x \to a} g(x)$ provided these limits exist.</p>

<p>Attempt: I am not even sure how to start this question.  I had made an attempt but it was getting nowhere when I did it. I found a solution to the question, but I still do not understand what is going on:</p>

<p>Suppose $$ l = \lim_{x\to a}f(x) \geq \lim_{x\to a}g(x) = m$$. Let $$\epsilon = l - m &gt; 0$$ </p>

<p>Then  there is $$\delta &gt; 0 \text{ such that if } 0 &lt;|x-a|&lt;\delta \Rightarrow |l-f(x)|&lt; \frac{\epsilon}{2} \text{ and } |m-g(x)| &lt; \frac{\epsilon}{2}$$ </p>

<p>Thus for $$0 &lt;|x-a|&lt;\delta \text{ we have } g(x) &lt; m + \frac{\epsilon}{2} = l - \frac{\epsilon}{2} &lt; f(x)$$ </p>

<p>Contradicting the hypothesis.</p>

<p>My problem is I do not see clearly what the hypothesis is and of equal importance I don't see how this proof accomplishes the objectives of the question.</p>
",calculus
"<p>My attempt: I wrote the equation of a circle for x belongs to [0,xo]. But I had no clue about what should I do for x belongs to (xo,infinity).</p>

<p><a href=""http://i.stack.imgur.com/IMabt.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/IMabt.jpg"" alt=""""></a></p>
",calculus
"<p>The question is:
Show that $y = 11x + 5$ is a tangent to curve $y = 3x^2 + 5x + 8$.</p>

<p>I have no clue about how to go about figuring this out. 
Should I graph both curves? Or should I use a certain formula?</p>
",calculus
"<p><a href=""http://i.stack.imgur.com/RSKkW.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/RSKkW.png"" alt=""enter image description here""></a></p>

<p>I'm a little confused on how to go about approximating the function (Or part 2 of the 3 part question as shown in the image). Would I use the polynomial I got from part a but substitution a for x? Or would I use the formula $cos(0) - sin(0)(x-0) - \frac{cos(0)}{2!}(x-0)^2 + \frac{sin(0)}{3!}(x-0)^3 + \frac{cos(0)}{4!}(x-0)^4$? If I were to use the second formula, how would I go about simplifying the ratio using the formula? Any kind of guidance on this would be greatly appreciated.</p>
",calculus
"<p>This is the integral
$$\int\frac{dx}{(x+1)(n-x)}=\int kdt$$
I just need some assistance on how to begin the left side integral and I will most likely be able to continue it from there thank you.</p>
",calculus
"<p>I have a function of $3$ variables which are all functions of $t$.</p>

<p>$$x = \frac{v_1t-y}{\sqrt{(v_2/\dot{x})^2 -1}} \tag 1 $$ </p>

<p>In the equation $v_1,v_2$ are constant and $x$ and $y$ are both function of $t$ (also $\dot{x}$ is $\frac{dx}{dt}$). I am trying to differentiate $(1)$ with respect to $t$, but I am not sure how to do this as there are three variables and an $\dot{x}$ already. I tried holding $x,y$ constant but that instinctively does not make sense as these change with respect to $t$.</p>
",calculus
"<p>Consider the sequence $a_{n+2}=f(a_1,a_2)$ where $f(x,y)$ is the mean of $x, y$ (geometric/arithmetic/harmonic) and $a_1,a_2$ are positive real numbers.</p>

<p>In detail: </p>

<p>Geometric - $a_{n+2}=\sqrt{a_{n+1}a_n}$</p>

<p>Arithmetic - $a_{n+2}={1 \over 2}(a_{n+1}+a_n)$</p>

<p>Harmonic - $a_{n+2}={2 \over {a_{n+1}^{-1}+a_n}^{-1}}$</p>

<p>Now, it's easy to show that each sequence converges (though if you have an interesting method to show that, share it with us!), but the trick is to calculate the limit. Here I give my way to compute these limits and challenge you to do so for a recursive sequence that each step takes the mean of its three or more previous element, namely $a_{n+N}=f(a_{n+N-1},a_{n+N-2},...,a_{n})$.</p>
",calculus
"<p>I just finished reading the Wikipedia article on the <a href=""http://en.wikipedia.org/wiki/Cauchy%27s_condensation_test"" rel=""nofollow"">Cauchy condensation test</a>. I understand the trapezoidal view, but apparently ""the 'condensation' of terms is analogous to a substitution of an exponential function"". Can anyone explain what is meant by this?</p>
",calculus
"<p>For a given $k>0$ constant, assuming that $x,y>0$. Also this equation has a particular name, or some mathematician associated with it?</p>
",calculus
"<p>What is an upper bound on $e^{-W_{-1}(c_1)}$ and $e^{-W(c_1)}$, where $W$ is the Lambert W function?</p>
",calculus
"<p>Let $h : \mathbb{R}^2 \rightarrow \mathbb{R}$ be a function defined by $$h(x,y) =\begin{cases} x^2 + y^2 &amp; : (x,y) \in \mathbb{Q} \times \mathbb{Q} \\[1ex] 0 &amp; :  \mbox{otherwise}\end{cases}$$</p>

<p>Show that $h$ is continuous only at $(0,0)$, and differentiable there. </p>

<p>I can show the continuity of $h$ at $(0,0)$. Also, I can show the discontinuity of $h$ at rational pair which is not $(0,0)$. However, I cannot show the discontinuity of other points. Also, the differentiation. Could anyone give a hint ?</p>
",calculus
"<p>Suppose you have two infinite sequences $\{a_n\}, \{b_n\}$, with $0 &lt; a_n &lt; b_n$ for each $n$, such that $b_n \to 0$ as $n \to \infty$. Does there exist a sequence $\{s_n\}$ with $s_n \to 1$ as $n \to \infty$ such that $a_n s_n \geq b_n$ for $n$ large enough? Thank you. </p>
",calculus
"<p>I am asked to prove this statement $^{*}$. I am trying now, but it is getting to small and tiny steps that I even loose my way. my steps are as follows: 
$$\lim_{n\rightarrow \infty}(\sqrt[3]{n+\sqrt{n}}-\sqrt[3]{n})=0^{*}$$ </p>

<p>$\lim_{n\rightarrow \infty}(\sqrt[3]{n+\sqrt{n}}-\sqrt[3]{n})=\dfrac{(\sqrt[3]{n+\sqrt{n}}-\sqrt[3]{n}) \cdot (\sqrt[3]{n+\sqrt{n}}+\sqrt[3]{n})}{(\sqrt[3]{n+\sqrt{n}}+\sqrt[3]{n})}=\dfrac{(\sqrt[3]{n+\sqrt{n}})^2-(\sqrt[3]{n})^2}{(\sqrt[3]{n+\sqrt{n}}+\sqrt[3]{n})}=\dfrac{\sqrt[3]{n^2+2n\sqrt{n}+n}}{\sqrt[3]{n+\sqrt{n}}+\sqrt[3]{n}}=\dfrac{(n+\sqrt{n})^{\frac{2}{3}}-n^{\frac{2}{3}}}{(n+\sqrt{n})^{\frac{1}{3}}+n^{\frac{1}{3}}}= .. help = 0$ $$if \quad n\rightarrow \infty$$</p>
",calculus
"<p>I am given this statement and I need to prove it. the statement is for all $n\ge 1$: $$\sqrt[n]{n}\leq 1+\frac{2}{\sqrt{n}}$$</p>

<p>I am trying to prove with induction. But I am stuck for step n=k+1, how can I then decompose the step:  $\sqrt[n+1]{n+1}$? </p>

<p>Thanks for help in advance</p>
",calculus
"<p>In Thomas's calculus $10^{th}$ edition, chapter $5$, exercises $5.3$, problem $9$, I am asked to find the length of an arc with the equation:</p>

<p>$$x=\int^y_0\sqrt{\sec^4(t)-1} dt$$</p>

<p>and $\displaystyle {\frac{-\pi}{4}} \leq y \leq {\frac{\pi}{4}}$.</p>

<p>The problem is, I'm not entirely sure what the equation is supposed to be... The previous problems were relatively straight forward, with simple $x=f(y)$ equations. The second part, the parameters of $y$, is confusing me-- is this a parametric of some sort (considering the ""$t$"")? I've looked around the chapter and can't seem to find another example like it...</p>

<p>If someone could point me in the right direction, that'd be really helpful.</p>
",calculus
"<p>For the integral: $$\int_{-1}^{5} \left( x^{2} -4 \right) dx$$</p>

<p>My calculations:</p>

<p>$$\begin{align*}\Delta x &amp;= \frac6n\\\\
x_i &amp;= -1 + \frac{6i}n\\\\
f(x_i) &amp;= 1 + \frac{36i^2}{n^2} -4\\\\
A&amp;=72
\end{align*}$$</p>

<p>I'm unsure if this is correct as it is my first attempt at doing this type of problem.</p>
",calculus
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://math.stackexchange.com/questions/141987/is-my-riemann-sum-correct"">Is my Riemann Sum correct?</a>  </p>
</blockquote>



<p>This is my second attempt, the answer seems rather odd so I thought I would have it checked as well.
For the integral: $$\int_{-5}^{2} \left( x^{2} -4 \right) dx$$</p>

<p>My calculations:</p>

<p>$$\begin{align*}\Delta x &amp;= \frac7n\\\\
x_i &amp;= -5 + \frac{7i}n\\\\
f(x_i) &amp;= 21 - \frac{70i}{n} + \frac{49i^2}{n^2} \\\\
A&amp;=-738
\end{align*}$$</p>
",calculus
"<blockquote>
  <p>A viscous liquid is poured on to a flat surface. It forms a circular patch whose area grows at a steady rate of $5 \text{ cm}^2/s$. Find in terms of $π$,</p>
  
  <p>(a) the radius of the patch 20 seconds after pouring has commenced</p>
  
  <p>(b) the rate of increase of the radius at this instant.</p>
</blockquote>

<p><img src=""http://i.stack.imgur.com/F37Oz.jpg"" alt=""enter image description here""></p>
",calculus
"<p>Can someone walk me through how to do the following problem so I can attempt a few more practice problems?</p>

<p>If:
$$\int_{1}^{5} f(x) dx = 12  $$
and
$$\int_{4}^{5} f( x) dx = 3.6$$
find:
$$\int_{1}^{4} f( x) dx$$</p>

<p>Would it simply be $12 - 3.6$ ?</p>

<hr>

<p><strong>EDIT</strong></p>

<p>If:
$$\int_{0}^{9} f(x) dx = 37  $$
and
$$\int_{0}^{9} g( x) dx = 16$$
find:
$$\int_{0}^{9} 2f(x)+3g(x) dx$$</p>

<p>Would this simply be: $2 \times 37 + 3 \times 16$?</p>
",calculus
"<p>Let $$f(x) = x\cos\frac{1}{x}$$ for x in $[1,\infty)$</p>

<p>Now I need to prove or disprove the difference $$f(x+2) - f(x) &gt; 2$$ for all $x$ in the domain.</p>

<p>I tried a lot but I don't seem to be getting anywhere. My approach was to try and use graphs, but somehow that doesn't seem to work out that well.</p>

<p>Any ideas or suggestions please?</p>
",calculus
"<p>I've try solve this question, but I haven't sucess...</p>

<p>The problem is the following:</p>

<p>A continuous functions $f:[a,b]\rightarrow \mathbb{R}$ assume positive and negative values in its domain, show that there exists $a_1,a_2,\ldots,a_k$, k numbers that are arithmetic progression and it is in the domain such that
$$f(a_1)+f(a_2)+\cdots+f(a_k)=0$$</p>

<p>Someone can help me with this question?</p>
",calculus
"<p>Can you help me prove this identity: $\tan x\sin x = \sec x-\csc x$?
I began working on the left side, by first changing $\tan x$ to $\sin x/\cos x$ and then multiplying by $\sin x$, I can get it down to $\sec x - \cos x$ but I can't figure out how to change the $\cos x$ to $\csc x$.</p>
",calculus
"<p>Can you help me prove the identity $$\tan x\sec x= \sin^3x \sec^2x +\sin x$$
I began working on the left side and changed everything to sine and cosine terms.</p>
",calculus
"<p>I am working on a differentiation question and my answer to simplify is </p>

<p>$2x\ln \left(2x-1\right)+\frac{2}{2x-1}x^2$</p>

<p>Why cant I cancel out a x when multiplying to get 
$\frac{2x}{2-1}$= $2x$ ?</p>

<p>So my final answer would be 
$2x(\ln \left(2x-1\right)+1)$</p>

<p>Instead they factorize to get this answer
$2x\left(\frac{x}{2x-1}+\ln \left(2x-1\right)\right)$</p>

<p>I can recognize how they arrive at that final answer but is my answer wrong?</p>
",calculus
"<p>As h approaches $0$, show $\sin(x+h)=\sin(x)+h\cos(x)+o(h)$. What I've done is basically substituted $h=0$ and therefore $LHS=RHS$, but I realise I'm supposed to use limits and I somehow can't get rid of the denominator $h$ everywhere.</p>
",calculus
"<p>I just can't seem to get this one. I know the process at least what we learned is to:</p>

<p>Get all the y's on one side and the x's on another
Integrate each side
Solve for some $C$ given a $x$ and $y$ value.
I just want to know how to set up the integration.</p>

<p>$$\frac{dy}{dx} - x * e^y = 2 * e^y$$</p>
",calculus
"<p>What approach would be ideal in finding if and where $f(x)$ is continuous and/or differentiable when $f$ is a <strong>piecewise</strong> defined function?  </p>

<p>A concrete example is below, but I'm interested in <em>general strategy</em>, illustrated on this function.</p>

<p>$$
f(x) = \begin{cases}     \ln(x) &amp; : x &gt; e\\
    x/e &amp; : x \leq e
  \end{cases}
$$</p>
",calculus
"<p>How can I solve this limit.  (Here $x$ belongs to natural numbers $\Bbb{N}$.) 
$$
\lim_{x\to\infty} \dfrac{5\cdot5^x+3^x-4^x}{5^x +2^x+27\cdot9^x}$$</p>

<p>My try:  I tried using L'Hospital, expansions of all terms using Taylor's series, and did work out.  I was just thinking if there is any simpler method?</p>
",calculus
"<p>Given:</p>

<p><img src=""http://i.stack.imgur.com/5pSa7.jpg"" alt=""enter image description here""></p>

<p>How can I show that:</p>

<p>1) If $ \beta &gt;0$ , then the sequence is increasing ? </p>

<p>2) The sequence converges if and only if $0&lt;\beta \leq 1 $ </p>

<p>I tried estimating $ a_{n+1} / a_n$ , but without any success. Induction might help , but I can't prove that $a_1 &lt; a_2 $ . </p>

<p>Will you please help ? </p>

<p>Thanks in advance </p>
",calculus
"<p>I have determined a tangent plane to be
$$z = a(-b+y) + x(b-1)$$
$$ab = x(b-1) + ay - z$$
At the point (a,b)</p>

<p>I want to determine the normal to this plane as a function of a and b. I am not entirely sure as to what this means ""As a function of a and b"".</p>

<p>So I assume I will find the normal using the dot product of plane to normal = 0.
$$(b-1, a,-1) * (\zeta,\beta,\gamma) = 0$$
$$\zeta(b-1) + \beta*a - \gamma = 0$$
$$-\frac{\zeta(b-1) + \gamma,}\beta = a$$
$$\frac{a\beta - \gamma,}\zeta + 1 = b$$</p>

<p>I am not sure if this is what is wanted, or if there is a better way to solve this. If anyone can shed some light, that would be appreciated. This is from a past exam 2012S2 UQ, for course 'Multivariate Calculus and Ordinary Differential Equations'.</p>
",calculus
"<p><img src=""http://i.stack.imgur.com/nJHyr.png"" alt=""Question""></p>

<p>Really have no idea what to do. I have tried letting z = 0 = (e^iz + e^-iz)/2i but all that does is cos z = pi/2. Doesn't give me a formula for cos^-1 z and doesn't help with part (b).</p>
",calculus
"<p>Given $f(x)$ a function that has derivatives of all orders in $\Bbb R$,</p>

<p>and $R_n(x)$ the $n^{th}$ order Lagrange form of the remainder,</p>

<p>Prove or disprove:</p>

<p>if $$lim_{x \to 0} {\frac {R_n(x)} {x^n}} = 0$$
for every $n$, than the radius of convergence of the series
$$\sum_{n=0}^\infty \frac {f^{(n)}(0)} {n!} x^n$$
is larger than $\frac 12$.</p>

<p>My try:
Let 
$$a_n = \frac {f^{(n)}(0)} {n!}$$
By d'Alembert rule
$$R = lim_{n \to \infty} \left| \frac {a_n} {a_{n+1}}\right| = 
lim_{n \to \infty} \left| \frac {\frac {f^{(n)}(0)} {n!}} {\frac {f^{(n+1)}(0)} {(n+1)!}}\right| = $$
$$
 = lim_{n \to \infty} \left| 
\frac {f^{(n)}(0) \cdot  (n+1)!} {f^{(n+1)}(0) \cdot n!}
\right| = 
lim_{n \to \infty} \left| 
\frac {f^{(n)}(0) } {f^{(n+1)}(0) }\cdot  (n+1)
\right|
$$ 
stuck here.</p>

<p>Also tried Cauchy</p>

<p>$$\frac 1R = \overline {lim} \sqrt[n] {\left| a_n \right|} = 
\overline {lim} \sqrt[n] {\left| \frac {f^{(n)}(0)} {n!} \right|} = 
\overline {lim} 
\frac 
{
  \sqrt[n] {
        \left| 
           f^n(0)
        \right|
  }
} 
{
\sqrt[n] {n!}
} 
= ?
$$
again stuck.</p>

<p>Maybe the statement is false and there's a simple counter example?</p>
",calculus
"<p>Consider the surface formed by revolving $y=\sin(x)$ about the line $y=c$ from some $0\le{c}\le{1}$ along the interval $0\le{x}\le{\pi}$.</p>

<p><a href=""//i.stack.imgur.com/2ZAiQ.gif"" rel=""nofollow""><img src=""//i.stack.imgur.com/2ZAiQ.gif"" alt=""graph""></a></p>

<p>Set up and evaluate an integral to calculate the volume $V(c)$ as a function of $c$.</p>

<p>(My attempt) 
$$
\begin{align}
V &amp;= \pi\int_0^\pi[(\sin(x))^2-c^2]dx \\
  &amp;= \pi\int_0^\pi[(\sin^2(x))-c^2]dx \\
  &amp;= \pi\int_0^\pi\left[\frac12(1-\cos(2x))-c^2\right]dx \\
  &amp;= \pi\left[\frac12(x-\sin(x)(\cos(x))-\frac{c^2x}{2}\right]_0^\pi \\
  &amp;= \pi\left[\left(\frac12(\pi-\sin(\pi)\cos(\pi)-\frac{\pi c^2}{2}\right)-\left(\frac12(0-\sin(0)\cos(0)-0\right)\right]
\end{align}
$$</p>

<p>So far... is this correct?</p>

<p>The second part of the question:</p>

<p>What value of c maximises the volume $V(c)$?</p>

<p>^ no idea on that one. help appreciated.</p>
",calculus
"<p>I was given this problem by a friend:</p>

<p>$$
\def\limit{\lim_{x\to5}}
\def\top{\sqrt{x}-2}
g(x) = \frac{\top}{x-5}\\
\limit g(x) = \quad?
$$</p>

<p>This caught me by surprise, because I can't remember how to do this problem with basic Calculus. Intuitively, the limit doesn't exist since $\limit(\top) \ne 0$ but $\limit(x-5) = 0$. And the limit doesn't even approach either infinity since the bottom is an odd-power polynomial.</p>

<p>However, how can I prove this by using basic Calculus that a new Calculus student would understand?</p>

<hr>

<p>I tried to do this as follows, but it seems overly complicated:</p>

<p>I spent some time and found this function:</p>

<p>$$
f(x)=\frac1{\sqrt{x-5}}\\
f(x) &lt; \frac\top{x-5}\\
\text{when }5 &lt; x &lt; \frac{81}{16}
$$</p>

<p>And we know that $\lim_{x\to5^+} f(x) = \infty$, so therefore,</p>

<p>$$\lim_{x\to5^+} g(x) = \infty$$</p>

<p>However, $f(x)$ doesn't work for the LH limit. However:</p>

<p>$$
g(x) &gt; 0 \quad\text{if}\quad x &gt; 5\\
g(x) &lt; 0 \quad\text{if}\quad 4 &lt; x &lt; 5
$$</p>

<p>So that means that $\lim_{x\to5^-} g(x) &lt; 0 \ne \infty$ so the limit does not exist, and we can't even say that the limit is one of the infinities.</p>

<p>Isn't there an easier way to do this (assuming graphing isn't allowed)?</p>
",calculus
"<p>What is the solution to the following integral?  </p>

<p>$$\int_0^\infty\frac{x^n}{e^{ax}-e^{bx}} dx$$</p>
",calculus
"<p>$$\int \frac{1}{(1-x^2)^{\frac{1}{3}}}\,dx$$</p>

<p>$\underline{\bf{\text{My Try}}}$ Let $(1-x^2) = t^3$. then $-2x\,dx = 3t^2\,dt$ or $\displaystyle dx = -\frac{3t^2}{-2x}\,dt = \frac{3t^2}{-2\cdot \sqrt{1-t^3}}\,dt$</p>

<p>So $\displaystyle  = -\frac{3}{2}\int t^1\cdot (1-t^3)^{-\frac{1}{2}}\,dt$</p>

<p>Now our integral is converted into in this form $\int x^m\cdot(a+bx^n)^p \, dx$</p>

<p>So $m=1$ and $n=3$ and $\displaystyle p=-\frac{1}{2}$</p>

<p>Now How can I solve it</p>

<p>Help Required</p>

<p>Thanks</p>
",calculus
"<p>Consider $(\log_b(x))^p$ where $b$ is   a  constant $&gt;1$; $x, p \in \mathbb R_+$.</p>

<p>As we increase the value of $p$ (starting from 1), at specific value of $p$, the curve changes its shape from concave to convex, specifically for $x\ge 1$.  <a href=""https://www.desmos.com/calculator/1fzp8z5ris"" rel=""nofollow"">See Curve Transition</a>.</p>

<p>So the question is: </p>

<ol>
<li>At what value of $p$, in terms of $b$, the transition of curvature (from concave to convex) occurs? </li>
<li>How to find it mathematically?</li>
</ol>
",calculus
"<p>Help me please with this indefinite trigonometric integral. How can I solve this kind of integrals?</p>

<p>$$\int\limits \frac{1}{\cos^4x \cdot  \sin^2x}dx$$</p>
",calculus
"<p>This is a question from my exam in Calculus 1.</p>

<blockquote>
  <p><strong>Problem 6</strong> </p>
  
  <p>Let $f: [0,\infty[ \to \mathbb{R}$ be continuously differentiable and $\lim_{x \to \infty} f'(x) = 0$.</p>
  
  <p>a) Show that for $n \in \mathbb{N}: \lim_{n \to \infty} \left( f(n+1) - f(n)\right) = 0$.</p>
  
  <p>b) Is $f$ necessarily bounded? Justify your answer.</p>
</blockquote>

<p>I started (a) with</p>

<p>$$ \lim_{x \to \infty} f'(x) = 0 $$
$$ \lim_{x \to \infty} \lim_{h \to 0} \frac{f(x+h) - f(x)}{h} = 0 $$</p>

<p>But how does that help when $h \to 1$?</p>
",calculus
"<p>I can't grasp this concept of an instantaneous change of rate. How could a point on a function graph have a rate of change in the first place?</p>

<p>In this moment I just know that it is named the derivative and that it is the slope of the tangent line at that point. We can find that slope by finding the limit of closer and closer to the point slopes. I still don't understand what does it really represent. </p>
",calculus
"<p>So i want to prove that
$$x^2e^x=1$$ has at least one solution for $$x\in\mathbb{R}$$</p>

<p>I am kinda lost and would appreciate any help. This is suppose to be solved using basic  calculus but i am not sure what to use.</p>
",calculus
"<p><a href=""http://fooplot.com/#W3sidHlwZSI6MSwiZXEiOiIxK3Npbih0aGV0YSkiLCJjb2xvciI6IiMwMDgwY2MiLCJ0aGV0YW1pbiI6IjAiLCJ0aGV0YW1heCI6IjJwaSIsInRoZXRhc3RlcCI6Ii4wMSJ9LHsidHlwZSI6MSwiZXEiOiIxK2Nvcyh0aGV0YSkiLCJjb2xvciI6IiMwMDgwY2MiLCJ0aGV0YW1pbiI6IjAiLCJ0aGV0YW1heCI6IjJwaSIsInRoZXRhc3RlcCI6Ii4wMSJ9LHsidHlwZSI6MSwiZXEiOiIiLCJjb2xvciI6IiMwMDgwY2MiLCJ0aGV0YW1pbiI6IjAiLCJ0aGV0YW1heCI6IjJwaSIsInRoZXRhc3RlcCI6Ii4wMSJ9LHsidHlwZSI6MTAwMCwid2luZG93IjpbIi0zLjAzMTA0IiwiMy42MjQ5NTk5OTk5OTk5OTk3IiwiLTEuNTc2OTYwMDAwMDAwMDAwMSIsIjIuNTE5MDQiXX1d"" rel=""nofollow"">Fooplot graph</a>:</p>

<hr>

<p><a href=""http://i.stack.imgur.com/kK6Xx.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/kK6Xx.png"" alt=""enter image description here""></a></p>

<hr>

<p>I think the formula is</p>

<p>$$A = \frac 1 2 \int_{\alpha}^{\beta} (\text{outer})^2 - (\text{inner})^2 d\theta$$</p>

<p>where $\alpha, \beta$ are <a href=""http://www.wolframalpha.com/input/?i=sin(theta)%3Dcos(theta),%200%20%3C%3D%20theta%20%3C%3D%202pi"" rel=""nofollow"">where they intersect</a> in $[0, 2\pi]$.</p>

<p>This is what I got based on that</p>

<p>$$A = \frac 1 2 \int_{3\pi/4}^{5\pi/4} (1+\sin \theta)^2 - (1+\cos \theta)^2 d\theta$$</p>

<p>Is that right?</p>
",calculus
"<p>$ \boldsymbol x = f(\boldsymbol X,t)$ is the position of a particle in an instant of time</p>

<p>$\boldsymbol X$ is the initial position</p>

<p>$t$ time</p>

<p>$\boldsymbol u$ velocity</p>

<p>In my opnion $f$ is continuos...</p>

<p>Considering:</p>

<p>$$u_i={{\partial x_i}\over{\partial t}}$$</p>

<p>Then:</p>

<p>$${\partial \over {\partial x_j}} \left(\partial x_i \over \partial t \right) = {{\partial u_i}\over{\partial x_j}}=\boldsymbol{\nabla}\boldsymbol{u}$$</p>

<p>But we <strong>can't</strong> Invert the Order of the partial derivative, otherwise we would have:</p>

<p>$${\partial \over {\partial t}} \left(\partial x_i \over \partial x_j \right) \neq 0$$</p>

<p>That is not the same result.</p>
",calculus
"<p><a href=""http://fooplot.com/#W3sidHlwZSI6MSwiZXEiOiIyL3Npbih0aGV0YSkiLCJjb2xvciI6IiMwMDgwY2MiLCJ0aGV0YW1pbiI6IjAiLCJ0aGV0YW1heCI6IjJwaSIsInRoZXRhc3RlcCI6Ii4wMSJ9LHsidHlwZSI6MSwiZXEiOiIxMHNpbih0aGV0YSkiLCJjb2xvciI6IiMwMDgwY2MiLCJ0aGV0YW1pbiI6IjAiLCJ0aGV0YW1heCI6IjJwaSIsInRoZXRhc3RlcCI6Ii4wMSJ9LHsidHlwZSI6MTAwMCwid2luZG93IjpbIi0xMy4zMTkwOTE3OTY4NzQ5OTUiLCIxMi4wNzE1MzMyMDMxMjQ5OTUiLCItMy44MTkzMzU5Mzc0OTk5OTgyIiwiMTEuODA1NjY0MDYyNDk5OTk2Il19XQ--"" rel=""nofollow"">Fooplot graph</a>:</p>

<hr>

<p><a href=""http://i.stack.imgur.com/jC42p.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/jC42p.png"" alt=""enter image description here""></a></p>

<hr>

<p>I think the formula is</p>

<p>$$A = \frac 1 2 \int_{\alpha}^{\beta} (\text{outer})^2 - (\text{inner})^2 d\theta$$</p>

<p>where $\alpha, \beta$ are <a href=""http://www.wolframalpha.com/input/?i=10sinx+%3D+2cscx,+0+%3C%3D+x+%3C%3D+2pi"" rel=""nofollow"">where they intersect</a> in $[0, 2\pi]$.</p>

<p>This is what I got based on that</p>

<p>$$A = \frac 1 2 \int_{x}^{\pi-x} (10 \sin \theta)^2 - (2 \csc \theta)^2 d\theta$$</p>

<p>where $x= \sin^{-1}(\frac {1}{\sqrt{5}} )$</p>

<p>Is that right?</p>
",calculus
"<p><strong>QUESTION:</strong> Given function is $$E=\frac{1}{4}\cdot \frac{F^2}{m}\cdot \frac{\omega_0^2+\omega^2}{(\omega_0^2-\omega^2)^2+4\alpha^2\omega^2}$$</p>

<p>We have to maximise $E$ with respect to $\omega$.</p>

<p><strong>MY ATTEMPT FOR SOLUTION:</strong> $$E=\frac{F^2}{4m}\cdot \phi(\omega^2)$$</p>

<p>Now, $\frac{dE}{d(\omega^2)}=\frac{d\{\phi(\omega^2)\}}{d(\omega^2)}=0$ when $E$ is maximum.</p>

<p>So we have that $$\frac{(\omega_0^2-\omega^2)^2+4\alpha^2\omega^2-(\omega_0^2+\omega^2)\left[-2(\omega_0^2-\omega^2)+4\alpha^2\right]}{\left[(\omega_0^2-\omega^2)^2+4\alpha^2\omega^2\right]^2}=0$$
Or, $$(\omega_0^2-\omega^2)^2-4\alpha^2\omega_0^2+2(\omega_0^2+\omega^2)(\omega_0^2-\omega^2)=0$$
Or, $$(\omega_0^2-\omega^2)\left[(\omega_0^2-\omega^2)+2(\omega_0^2+\omega^2)\right]=4\alpha^2\omega_0^2$$
Or, $$(\omega_0^2-\omega^2)(3\omega_0^2+\omega^2)=4\alpha^2\omega_0^2$$</p>

<p>This results in a Fourth degree equation in $\omega$ and it yields a very complex result.</p>

<p>But in the book, it is given that $E$ is maximum when $\omega=\omega_0$.</p>

<p>Where did I go wrong? Please help.</p>
",calculus
"<p><a href=""http://fooplot.com/#W3sidHlwZSI6MSwiZXEiOiJzcXJ0KDhjb3MoMnRoZXRhKSkiLCJjb2xvciI6IiMwMDgwY2MiLCJ0aGV0YW1pbiI6IjAiLCJ0aGV0YW1heCI6IjJwaSIsInRoZXRhc3RlcCI6Ii4wMSJ9LHsidHlwZSI6MSwiZXEiOiIyIiwiY29sb3IiOiIjMDA4MGNjIiwidGhldGFtaW4iOiIwIiwidGhldGFtYXgiOiIycGkiLCJ0aGV0YXN0ZXAiOiIuMDEifSx7InR5cGUiOjEsImVxIjoiLXNxcnQoOGNvcygydGhldGEpKSIsImNvbG9yIjoiIzAwODBjYyIsInRoZXRhbWluIjoiMCIsInRoZXRhbWF4IjoiMnBpIiwidGhldGFzdGVwIjoiLjAxIn0seyJ0eXBlIjoxMDAwLCJ3aW5kb3ciOlsiLTcuMjIzNzc5Mjk2ODc0OTk4IiwiOS4wMjYyMjA3MDMxMjQ5OTUiLCItNS43MzE4MzU5Mzc0OTk5OTgiLCI0LjI2ODE2NDA2MjQ5OTk5OSJdfV0-"" rel=""nofollow"">Fooplot graph</a>:</p>

<hr>

<p><a href=""http://i.stack.imgur.com/zFlk1.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/zFlk1.png"" alt=""enter image description here""></a></p>

<hr>

<p>I think the formula is</p>

<p>$$A = \frac 1 2 \int_{\alpha}^{\beta} (\text{outer})^2 - (\text{inner})^2 d\theta$$</p>

<p>where $\alpha, \beta$ are <a href=""http://www.wolframalpha.com/input/?i=4+%3D+8cos(2x),+0+%3C%3D+x+%3C%3D+2pi"" rel=""nofollow"">where they intersect</a> in $[0, 2\pi]$.</p>

<p>This is what I got based on that</p>

<p>By symmetry, we have</p>

<p>$$\frac A 4 = \frac 1 2 \int_{0}^{\pi/6} (8 cos 2\theta) - (2)^2 d\theta$$</p>

<p>Is that right?</p>
",calculus
"<p>Given that an arithmetic progression is such that the 8th term is twice the second term, and the 11th term is 18.
Find:
1) The first term and common difference.
2) The sum of the first 26 terms.
3) The smallest of the progression whose values exceed 126?</p>

<p>How on earth am I meant to solve this? I'm guessing you try and find a formula for the nth term, but I have no clue how to get there.
Any suggestions?</p>
",calculus
"<p>$f(x)=\begin {cases}\sin x\ln x^2 &amp; x\neq 0\\ 0 &amp; x=0\end{cases}$</p>

<p>When I try to find the derivative on $x=0$ with the defintion I get:</p>

<p>$\displaystyle\lim_{h\to 0}\frac {f(h+0)-f(0)}{h-0}=\lim_{h\to 0}\frac {f(h)}{h}=\lim_{h\to 0}\frac {\sin h \ln h^2} h=\lim_{h\to 0}\ln h^2=-\infty$</p>

<p>But I see from the graph that the slope on $x=0$ is supposed to be finite:</p>

<p><img src=""http://i.stack.imgur.com/3iVNH.png"" alt=""enter image description here""></p>

<p>Why does the derivative definition don't work here?</p>
",calculus
"<blockquote>
  <p>Find how many solutions does $f(x)=\ln x-kx$ has for $k&gt;\frac 1 e$.</p>
</blockquote>

<p>$f&lt;0$ at $x\to \infty$ and $x\to 0$. The derivative has a solution only at $x=\frac 1 k$.</p>

<p>So place that point in $f$ and we'll want to check when $f(\frac 1 k)&gt;0$ and $f(\frac 1 k)&lt;0$</p>

<p>Now I'm getting confused here:</p>

<p>$f(\frac 1 k)&gt;0\to \ln \frac 1 k &gt; 1$ so $e^1&gt;\frac 1 k\to k&gt;\frac 1 e$ but it should be the opposite, so my question is why does the inequality 'flip'? </p>
",calculus
"<p>Intuitively, it is rather obvious that</p>

<p>$$\lim_{l\to\infty}\sum_{n=-\infty}^{\infty}f(n\Delta x)\Delta x = \int_{-\infty}^{\infty}f(x)dx \tag{1}$$</p>

<p>where $\Delta x = \frac{1}{l}$, assuming $f$ is integrable and the limit exists.</p>

<p><strong>The fact that this equality is true is the core part of deriving Fourier transform from Fourier series, see page 4, eq. 4.7 in <a href=""http://people.seas.harvard.edu/~schan/class/Su11/Chapter4.pdf"" rel=""nofollow"">this document</a>.</strong> Or maybe we cannot consider this derivation as formal, as it was never intended to be formal, but I thought n mathematics there's no place for informal thinking.</p>

<p>My question is how can we prove it's true from the definitions and properties of improper integral, definite integral and limits?</p>

<p>I've listed the important definitions below in case you would like to refer to some of these in your answers.</p>

<p>Oh, and please ignore mrf's answer - it doesn't refer to my question anymore, I've reformulated it.</p>

<hr>

<p>If function $f$ is integrable on $[a,b]$, then:
$$\int_{a}^{b}f(x)dx=\lim_{n\to\infty}\sum_{i=1}^{n}f(x_i)\Delta x \tag{2}$$
where $\Delta x = \frac{b-a}{n}$ and $x_i = a+i\Delta x$.</p>

<p>Improper integral definitions</p>

<p>$$\int_{a}^{\infty}f(x)dx=\lim_{t\to\infty}\int_{a}^{t}f(x)dx \tag{3}$$</p>

<p>$$\int_{-\infty}^{b}f(x)dx=\lim_{t\to-\infty}\int_{t}^{b}f(x)dx \tag{4}$$</p>

<p>$$\int_{-\infty}^{\infty}f(x)dx=\int_{a}^{\infty}f(x)dx + \int_{-\infty}^{a}f(x)dx \tag{5}$$</p>
",calculus
"<p>I have an integration and I am splitting this one in two parts ;</p>

<p>$\displaystyle\int_{0}^{a-b}=\int_{0}^{a}+\int_{a}^{a-b}=\int_{0}^{a}-\int_{a-b}^{a}$</p>

<p>and </p>

<p>$\displaystyle a\geq b$</p>

<p>Is it correct to write this integral in two part like this ?
The fact that bothers me is that I make the split on $a$ which is for sure greater then $a-b$.</p>
",calculus
"<p>I'm introducing myself to the $(\varepsilon, \delta)$ definition of limits, and I'm encountering a few issues.</p>

<p>When proving the $\lim_{x \to c}f(x) = L$
$$
\forall \varepsilon  &gt; 0, \ \exists \delta = \delta(\varepsilon) &gt; 0 : 0 &lt; |x - c| &lt; \delta \implies |f(x) - L| &lt; \varepsilon
$$</p>

<p>When considering $\lim_{x \to 2}(2x - 5) = -1$</p>

<p>Let $\forall \varepsilon &gt; 0$</p>

<p>Choose $\delta = \dfrac{\varepsilon}{2}$</p>

<p>Assume $0 &lt; |x - 2| &lt; \delta$</p>

<p>Then,</p>

<p>$$
|2x - 5 - (-1)| &lt; \varepsilon,
$$</p>

<p>$$
\\|2x - 4| &lt; \varepsilon
\\2|x - 2| &lt; \varepsilon
\\|x - 2| &lt; \delta
\\2|x - 2| &lt; 2\delta
\\ \therefore \delta = \dfrac{\varepsilon}{2}
$$</p>

<p>Forgive my mistakes, I'm still quite new to this. I believe that my proof is mostly accurate (do correct me if I'm wrong, please).</p>

<p>My biggest issue comes with solving this other problem:</p>

<p>I am to suppose $|f(x)-7| &lt;  0.2$ whenever $0 &lt; x &lt; 7$.</p>

<p>Find all values of $\delta &gt; 0$ such that $|f(x) - 7| &lt; 0.2$ whenever $0 &lt; |x-2| &lt; \delta$.</p>

<p>I've not got a good idea of how to approach this with an arbitrary $f(x)$.</p>
",calculus
"<p>Does it ask that we can express any positive real number as square root of something? like 4 is equal to square root of 16?</p>
",calculus
"<p>Show that the series $\sum\limits_{j=1}^\infty  = \frac{2^j+j}{3^j-j}$ converges.</p>

<p>I know that if I look at each sequential case j=1,2,3... the limit of the partial sums approaches 0 as $j \rightarrow \infty$, but how can I show that the series converges more explicitly?</p>
",calculus
"<p>I evaluated the correct answers for the limit with the function $(8+x)^{\frac{1}{x}}$ using a different method, but I do understand how L'Hopitals works, its just rewriting this function into $\frac{f(x)}{g(x)}$ I am very confused about. I am able to do so with other functions such as $x\ln(x)$, but I am not sure how to do so with an exponent. </p>
",calculus
"<p>$$
\int\frac {x^3 + 5x^2 +2x -4}{(x^4-1)}dx
$$
A bit confused with how to integrate this question. I though it was partial fractions but was unsure about the what to do after that.</p>
",calculus
"<p>Does the following series converge or diverge? 
$\sum\limits_{j=1}^\infty \frac{(1+\frac{1}{j})^{2j}}{e^j}$</p>

<p>Using the ratio test, I found $|\frac{a_{j+1}}{a_j}|$ to be $|\frac{(1+\frac{1}{j+1})^{2j+2}}{e(1+\frac{1}{j})^{2j}}|$</p>

<p>To find the lim sup of this, I looked at the ratio as $j \rightarrow \infty$, and arrived at $\frac{1}{e}&lt;1$, so by the ratio test, the series would converge absolutely.</p>

<p>Does this look valid? I wasn't sure about the step of taking the limit as $j \rightarrow \infty$ to find the lim sup.</p>

<p>Thank you!</p>
",calculus
"<p>After looking at calculations, I realized that the exponent needs to be 1/4 instead of -1/4</p>

<p>I have this equation and I am trying to solve the integral of it. </p>

<p>$$((R^2) - (y^2))^{1/4} dy$$</p>

<p>I tried to put it into wolfram alpha, and I got an answer, but I wanted to know how they arrived at the answer. </p>

<p>Any advice would be greatly appreciated. If you could please show me how to do this integral, I would be appreciate it very much. </p>

<p>I know you need to use hyper geometric functions; however, I am not sure how.</p>

<p>Thank-you very much </p>
",calculus
"<p>$$\lim_{x\to 0} \int_x^{x+1} \sqrt {\arctan {t}}\space dt$$</p>

<p>I think it does not exist because we can't talk about limit from $x\to 0^-$, but what if we just look for $\lim_{x\to 0^+}$? I see there less and less area of the graph so it should be $0$, but how we show it?</p>
",calculus
"<p>The question reads:</p>

<p>Let $f(x)$ be a function whose graph is contained in the first quadrant but does not pass through the x-axis and let $Q = (a,0)$ . Let $P=(x_o, f(x_o))$ be the point on the graph closest to Q. Prove that the line PQ is perpendicular to the tangent line to the graph at $x_o$. ($Hint:$ Recall that the slope $m'$ of a line $L'$ perpendicular to a line $L$ of slope $m$ is $m' = \frac{-1}{m}$ .)</p>

<p>Edit (second attempt):</p>

<p>$$x\geq 0, y\geq 0 $$
$$D = \sqrt{(f(x_o)-0)^2 + (x_o - a)^2}$$
$$D' = \frac{2(f(x_o))f'(x_o) + 2(x_o-a)(1)}{2\sqrt{(f(x_o)-0)^2 + (x_o - a)^2}}$$
$$D' = 0$$
$$2(f(x_o))f'(x_o) + 2(x_o-a)(1) = 0$$
$$(x_o-a)=-(f(x_o))f'(x_o)$$
$$-\frac{(x_o-a)}{f(x_o)}=f'(x_o)$$
$$-\frac{1}{f'(x_o)} = \frac{f(x_o)}{(x_o-a)}$$</p>

<p>Which is the desired result.</p>
",calculus
"<p>I am not sure if this question is appropriate here but would appreciate any help. Let $n>2$ and $x_1,\cdots,x_n$ be real numbers. What is the infimum of:</p>

<p>$$A = \sum_{i=1}^n \frac{1}{(1+x_i)^2} $$ </p>

<p>subject to the constraint $\prod_{i=1}^nx_i=1$?</p>

<p>Similar question for: </p>

<p>$$B = \sum_{i=1}^n \frac{1}{(1-x_i)^2} $$</p>

<p>Thanks in advance!</p>
",calculus
"<p>The exercise asks me to prove 2 things:</p>

<p>1) $f(x,y) $ is continuous in $(x_0,y_0)$, $f(x_0,y_0)&gt;0$ then there is a neighborhood such that $f(x,y)&gt;\frac{1}{2}f(x_0,y_0)$</p>

<p>My idea:</p>

<p>$f$ is continuous, then $|(x,y)-(x_0,y_0)|&lt; \delta\implies |f(x,y)-f(x_0,y_0)|&lt; \epsilon \implies f(x_0,y_0) -\epsilon &lt;f(x,y) &lt; f(x_0,y_0) + \epsilon$. It's true for all $\epsilon$, so if I choose $\epsilon = \frac{1}{2}f(x_0,y_0)$
we have:</p>

<p>$$\frac{1}{2}f(x_0,y_0)&lt;f(x,y) &lt; f(x_0,y_0) + \frac{1}{2}f(x_0,y_0)$$</p>

<p>2) Suppose $f$ is continuous in a domain $D$. Suppose that $f(x,y)$ is positive for at least $1$ point of $D$ and negative for at least one point of D. Then $f(x,y) = 0$ for at least one point of $D$. (suggestion: use $1$)</p>

<p>How to use $1$ to prove $2$? As I know, this can be understood as the mean value theorem for multivariables, but I couldn't find a proof that used $1$.</p>
",calculus
"<p>I need an upper bound for 
$$\frac{x+y}{ax+y}$$</p>

<p>I know that $$1\leq a&lt; 2$$ 
$x\geq 0 $ and $y\geq 0 $ . This upper bound can include just $a$ and constant numbers not $x$ or $y$.</p>

<p>thanks a lot.</p>
",calculus
"<p>$$\int \frac{\sqrt{9-4x^{2}}}{x}dx$$
How Can I attack this kind of problem?</p>
",calculus
"<p>Why is $$ \int \frac{\sin x (b-a\cos x)}{(b^2+a^2-2ab \cos x)^{3/2}}\,dx = \frac{a-b\cos x}{b^2 \sqrt{a^2-2ab\cos x + b^2}}\text{ ?}$$</p>

<p>Constant of integration omitted.</p>
",calculus
"<p>I've encountered a homework problem which has had me a little bit confused, as it doesn't <em>feel</em> as though it marries up very closely with the content in my textbook. I guess that what I'd appreciate most is if someone could verify that I have answered this correctly, and potentially clarify any errors that I've made.</p>

<p>Here is the problem statement:</p>

<blockquote>
  <p>Let $S$ define the region inside the cardioid $r=1+\sin(\theta)$, above the x-axis. Using polar coordinates, evaluate $\iint_{S}\frac{1}{\sqrt{x^2+y^2}}dA$.</p>
</blockquote>

<p>Here's my attempt at the problem:</p>

<blockquote>
  <p>Defining $S$ as $S=\{(r,\theta)\ |\ 0\le\theta\le\pi,\ 0\le r\le1+\sin(\theta)\}$,</p>
  
  <p>$\iint_{S}\frac{1}{\sqrt{x^2+y^2}}dA = \int_0^\pi \! \int_0^{1+\sin(\theta)} \frac{1}{r}r\ dr\ d\theta = \int_0^\pi \! \int_0^{1+\sin(\theta)} 1\ dr\ d\theta=\pi+2.$</p>
</blockquote>

<p>Thank you very much!</p>
",calculus
"<p>I need an upper bound for 
$$\frac{ax}{x-2}$$
I know that $1\leq a&lt; 2$ and $x\geq 0$.</p>

<p>This upper bound can include just $a$ and constant numbers not $x$.</p>

<p>thanks a lot.</p>
",calculus
"<blockquote>
  <p>$$\int_0^1\int_\sqrt[3]{x}^1 4\cos(y^4)\,\mathrm dy\,\mathrm dx$$</p>
</blockquote>

<p>What I got was</p>

<p>$\sin(1)x+\cos(x^2) dx$ and now I am stuck.</p>

<p>I suddenly froze. Could someone help me? Haven't done calculus for a long time. </p>
",calculus
"<p><img src=""http://i.stack.imgur.com/plnRC.png"" alt=""enter image description here""></p>

<p>This seems super easy. But i am just a little bit stuck here. Haven't done much calculus recently. Can someone help me out real quick?</p>

<p>Thank you in advance!</p>
",calculus
"<p>Let a, b, c be vectors, f(x, y, z) be a scalar ﬁeld, F(x,y,z) be a vector ﬁeld. Which of the
following expressions are meaningful?</p>

<p>I. (a×b)×(c×b)</p>

<p>II. |a|(b· c) +|a|(b+c)</p>

<p>III. ∇ ×(f F)</p>

<p>IV. (∇ ×F)·(f ×F)</p>

<p>I know that (I) makes sense. Vector x Vector.
(II) is not meaningful</p>

<p>I am confused about grad and curls. I know that div and curl apply to vector fields, grad to
scalar fields.</p>

<p>So. curl(f F). is (f F) scalar and is (f x F) vector? </p>
",calculus
"<p>The maximum value of the function $f(x, y) = xy$, and subject to condition $x^2+y^2=1$:</p>

<p>So do I apply Lagrange's Multiplier method to find the maximum value?
I tried to find the numbers just by applying few numbers but it doesn't seem to work.</p>
",calculus
"<p>Apologizes if I'm missing something in my question or if my question seems trivial; this is my first question on this site. As motivation for my question, consider the following standard first year calculus question.</p>

<blockquote>
  <p>Consider this piecewise function:
  $
   f(x) = \left\{
     \begin{array}{lr}
       ax^2+b &amp; \text{ if } x \le-2\\
       12x-5 &amp; \text{ if } x &gt;-2
     \end{array}
   \right.
$</p>
  
  <p>For what values of $a$ and $b$ will $f(x)$ be differentiable?</p>
</blockquote>

<p>To solve this question, I would like to propose the following theorem:</p>

<blockquote>
  <p>$\mathbf{Theorem:}$ A function $f(x)$ is differentiable iff $f'(x)$ is continuous.</p>
</blockquote>

<p>If this theorem is true, then I can solve for $a$ first by noting that:
$
   f'(x) = \left\{
     \begin{array}{lr}
       2ax &amp; \text{ if } x \le-2\\
       12 &amp; \text{ if } x &gt;-2
     \end{array}
   \right.
$</p>

<p>Thus, since by my theorem $f'(x)$ must be continuous, we have:</p>

<p>$$\begin{align*}
\lim_{x \rightarrow -2^-}f'(x) &amp;= \lim_{x \rightarrow -2^+}f'(x)\\
\lim_{x \rightarrow -2^-}2ax &amp;= \lim_{x \rightarrow -2^+}12\\
2a(-2) &amp;= 12\\
-4a &amp;= 12 \\
a &amp;= -3 \\
\end{align*}$$</p>

<p>Hence, since differentiability implies continuity, we can solve for $b$ as follows:</p>

<p>$$\begin{align*}
\lim_{x \rightarrow -2^-}f(x) &amp;= \lim_{x \rightarrow -2^+}f(x)\\
\lim_{x \rightarrow -2^-}-3x^2+b &amp;= \lim_{x \rightarrow -2^+}12x-5\\
-3(-2)^2+b &amp;= 12(-2)-5\\
b-12 &amp;= -29\\
b &amp;= -17 \\
\end{align*}$$</p>

<p>so that our differentiable function is:</p>

<blockquote>
  <p>$$
   f(x) = \left\{
     \begin{array}{lr}
       -3x^2-17 &amp; \text{ if } x \le-2\\
       12x-5 &amp; \text{ if } x &gt;-2
     \end{array}
   \right.
$$</p>
</blockquote>

<p>Anyways. My question is: <strong>Is my proposed theorem actually a thing?</strong> I've looked through my calculus textbook and it doesn't seem to explicitly state it, yet I don't know how to solve this question otherwise. If this theorem turns out to be false, how else can you solve this problem? Thanks in advance. =]</p>
",calculus
"<p>I need to find a number $x$ such that
$$\sum_{n=1}^\infty\frac{n^x}{2^n n!} = \frac{1539}{64}e^{1/2}.$$
What is the best approach to this problem?</p>
",calculus
"<p>Test for convergence the series
$$\sum_{n=1}^{\infty}\frac{1}{n^{(n+1)/n}}$$
I'd like to make up a collection with solutions for this series, and any new<br>
solution will be rewarded with upvotes.   Here is what I have at the moment</p>

<p><strong>Method 1</strong> </p>

<p>We know that for all positive integers $n$, $n&lt;2^n$, and this yields
$$n^{(1/n)}&lt;2$$
$$n^{(1+1/n)}&lt;2n$$
Then, it turns out that 
$$\frac{1}{2} \sum_{n=1}^{\infty}\frac{1}{n} \rightarrow \infty \le\sum_{n=1}^{\infty}\frac{1}{n^{(n+1)/n}}$$
Hence
$$\sum_{n=1}^{\infty}\frac{1}{n^{(n+1)/n}}\rightarrow \infty$$
<strong>EDIT:</strong>  </p>

<p><strong>Method 2</strong></p>

<p>If we consider the maximum of $f(x)=x^{(1/x)}$ reached for $x=e$<br>
and denote it by $c$, then
$$\sum_{n=1}^{\infty}\frac{1}{c \cdot n} \rightarrow \infty \le\sum_{n=1}^{\infty}\frac{1}{n^{(n+1)/n}}$$</p>

<p>Thanks!</p>
",calculus
"<p>Suppose $f(x) \in C[a,b]$ and $\varphi(x)$ is Riemann integrable and satisfy : $\int_a^b\varphi(x)\mathscr{dx}=0$.   $\int_a^bf(x)\varphi(x)\mathscr{dx}=0$       can we conclude that $f(x)\equiv c$?</p>

<p><hr>
My approach:</p>

<p>for $f$ is continuous on $[a,b]$, then there exists $M$ and $m$ in $\Bbb{R}$,satisfy: $m \leq f(x) \leq M$,so we have $M-f(x)\geq0$,so I can use the mean value theorem:
$$\int_a^b(M-f(x))\varphi(x)\mathscr{dx}=\mu\int_a^b(M-f(x))\mathscr{dx}=0 \Rightarrow \int_a^b f(x)\mathscr{dx} =M(b-a)$$
where $\inf\varphi(x)\leq\mu \leq \sup \varphi(x)$<br>
use MVT to : $$\int_a^b(f(x)-m)\varphi(x)\mathscr{dx}$$we get $\int_a^bf(x)\mathscr{dx}=m(b-a)$ this implies $m=M$,then $f$ is constant on $[a,b]$</p>

<p>Am I right?</p>

<hr>
",calculus
"<p>Let $\lambda_i \in \mathbb C$  $(i=1,2,\cdots,n)$ be $n$ different complex numbers and $p_i \in \mathbb C[t]$ $(i=1,2,\cdots,n)$ polynomials. If we have the relation
$${e^{{\lambda _1}t}}{p_1}(t) + {e^{{\lambda _2}t}}{p_2}(t) +  \cdots  + {e^{{\lambda _n}t}}{p_n}(t) = 0$$ for all $t \geq 0$, can we conclude that all $p_i(t)=0$?</p>
",calculus
"<p>In Gauss Divergence Theorem , $$\int \int_{\partial V} \textbf{F}\cdot\textbf{n}\,dS =\int \int \int_V \nabla\cdot\textbf{F}\,dx\,dy\,dz,$$ is there any restriction on the vector field $\textbf{F}$ ? Does it need to be in dimension three only ? Can I let it be $\textbf{F}=xyz$ where $x,y,z\in\mathbb{R}$ ?</p>
",calculus
"<p>i can show $\sum |x|^2=\int_a^b|f(x)|^2dx$ in term of integral, or this one  $|\sum x\overline y|^2=|\int_a^bf(x)\overline {g(x)}dx|^2$ but i don't know how to show this one $\sum_{i}^{n-1}\sum_{j=i+1}^{n}|(x_i\overline y_j-x_j\overline y_i)|^2$ in term of integral</p>

<p>$\sum_{i}^{n-1}\sum_{j=i+1}^{n}|(x_i\overline y_j-x_j\overline y_i)|^2=?$</p>
",calculus
"<p>Imagine I have this limit:</p>

<p>$$\lim_{x\to 0}\frac{\ln(1+2x)}x$$</p>

<p>Using the <em>L'Hospital's rule</em> the result is $2$.</p>

<p>Using this result is it possible to calculate</p>

<p>$$\lim_{n\to \infty}\ n\ln\bigg(1+\frac{4}{\sqrt{n}}\bigg) \quad ?$$</p>

<p>Sorry if this is an easy question, but many years have passed since I've learned calculus.</p>
",calculus
"<p>I did the following problem in class $f(x)=x\sqrt{x+2}$ and I needed to find the local maxima. I said the domain was $[-2,\infty)$ and the left end point $(-2,0)$ on the graph is a local maxima because the graph has a negative derivative there, but my instructor said that it was wrong.</p>

<p>Why is that end point not a local maxima?</p>

<p>Thanks</p>
",calculus
"<blockquote>
  <p>Solve $\space \begin{align*} \lim_ {x \to+\infty} \left [ \frac{4 \ln(x+1)}{x}\right]  
\end{align*}$.</p>
</blockquote>

<p>I did this way:</p>

<p>$$\begin{align*}
\lim_ {x \to+\infty} \left [ \frac{4 \ln(x+1)}{x}\right] &amp; = 4\lim_ {x \to+\infty} \left [\frac{1}{x} \ln(x+1) \right]= \\\\=4\lim_ {x \to+\infty} \left [ \ln(x+1)^{\frac{1}{x}}\right] &amp;= 4 \ln \left[\lim_ {x \to+\infty}(x+1)^{\frac{1}{x}}\right] =4 \cdot \ln(1)=0
\end{align*}$$</p>

<p>What is the rule behind the shift that I made between the $\ln$ and the $limit$?</p>

<p>I'm in the high school.Thanks</p>
",calculus
"<p>Is there any way to show that</p>

<p>$$\sum\limits_{k =  - \infty }^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a + k}} = \frac{1}{a} + \sum\limits_{k = 1}^\infty  {{{\left( { - 1} \right)}^k}\left( {\frac{1}{{a - k}} + \frac{1}{{a + k}}} \right)}=\frac{\pi }{{\sin \pi a}}} $$</p>

<p>Where $0 &lt; a = \dfrac{n+1}{m} &lt; 1$</p>

<p>The infinite series is equal to</p>

<p>$$\int\limits_{ - \infty }^\infty  {\frac{{{e^{at}}}}{{{e^t} + 1}}dt} $$</p>

<p>To get to the result, I split the integral at $x=0$ and use the convergent series in $(0,\infty)$ and $(-\infty,0)$ respectively:</p>

<p>$$\frac{1}{{1 + {e^t}}} = \sum\limits_{k = 0}^\infty  {{{\left( { - 1} \right)}^k}{e^{ - \left( {k + 1} \right)t}}} $$</p>

<p>$$\frac{1}{{1 + {e^t}}} = \sum\limits_{k = 0}^\infty  {{{\left( { - 1} \right)}^k}{e^{kt}}} $$</p>

<p>Since $0 &lt; a &lt; 1$</p>

<p>$$\eqalign{
  &amp; \mathop {\lim }\limits_{t \to 0} \frac{{{e^{\left( {k + a} \right)t}}}}{{k + a}} - \mathop {\lim }\limits_{t \to  - \infty } \frac{{{e^{\left( {k + a} \right)t}}}}{{k + a}} = \frac{1}{{k + a}}  \cr 
  &amp; \mathop {\lim }\limits_{t \to \infty } \frac{{{e^{\left( {a - k - 1} \right)t}}}}{{k + a}} - \mathop {\lim }\limits_{t \to 0} \frac{{{e^{\left( {a - k - 1} \right)t}}}}{{k + a}} =  - \frac{1}{{a - \left( {k + 1} \right)}} \cr} $$</p>

<p>A change in the indices will give the desired series.</p>

<p>Although I don't mind direct solutions from tables and other sources, I prefer an elaborated answer. </p>

<hr>

<p>Here's the solution in terms of $\psi(x)$. By separating even and odd indices we can get</p>

<p>$$\eqalign{
  &amp; \sum\limits_{k = 0}^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a + k}}}  = \sum\limits_{k = 0}^\infty  {\frac{1}{{a + 2k}}}  - \sum\limits_{k = 0}^\infty  {\frac{1}{{a + 2k + 1}}}   \cr 
  &amp; \sum\limits_{k = 0}^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a - k}}}  = \sum\limits_{k = 0}^\infty  {\frac{1}{{a - 2k}}}  - \sum\limits_{k = 0}^\infty  {\frac{1}{{a - 2k - 1}}}  \cr} $$</p>

<p>which gives</p>

<p>$$\sum\limits_{k = 0}^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a + k}}}  = \frac{1}{2}\psi \left( {\frac{{a + 1}}{2}} \right) - \frac{1}{2}\psi \left( {\frac{a}{2}} \right)$$</p>

<p>$$\sum\limits_{k = 0}^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a - k}}}  = \frac{1}{2}\psi \left( {1 - \frac{a}{2}} \right) - \frac{1}{2}\psi \left( {1 - \frac{{a + 1}}{2}} \right) + \frac{1}{a}$$</p>

<p>Then</p>

<p>$$\eqalign{
  &amp; \sum\limits_{k =  - \infty }^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a + k}}}  = \sum\limits_{k = 0}^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a + k}}}  + \sum\limits_{k = 0}^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a - k}}}  - \frac{1}{a} =   \cr 
  &amp;  = \left\{ {\frac{1}{2}\psi \left( {1 - \frac{a}{2}} \right) - \frac{1}{2}\psi \left( {\frac{a}{2}} \right)} \right\} - \left\{ {\frac{1}{2}\psi \left( {1 - \frac{{a + 1}}{2}} \right) - \frac{1}{2}\psi \left( {\frac{{a + 1}}{2}} \right)} \right\} \cr} $$</p>

<p>But using the reflection formula one has</p>

<p>$$\eqalign{
  &amp; \frac{1}{2}\psi \left( {1 - \frac{a}{2}} \right) - \frac{1}{2}\psi \left( {\frac{a}{2}} \right) = \frac{\pi }{2}\cot \frac{{\pi a}}{2}  \cr 
  &amp; \frac{1}{2}\psi \left( {1 - \frac{{a + 1}}{2}} \right) - \frac{1}{2}\psi \left( {\frac{{a + 1}}{2}} \right) = \frac{\pi }{2}\cot \frac{{\pi \left( {a + 1} \right)}}{2} =  - \frac{\pi }{2}\tan \frac{{\pi a}}{2} \cr} $$</p>

<p>So the series become</p>

<p>$$\eqalign{
  &amp; \sum\limits_{k =  - \infty }^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a + k}}}  = \frac{\pi }{2}\left\{ {\cot \frac{{\pi a}}{2} + \tan \frac{{\pi a}}{2}} \right\}  \cr 
  &amp; \sum\limits_{k =  - \infty }^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a + k}}}  = \pi \csc \pi a \cr} $$</p>

<p>The last being an application of a trigonometric identity.</p>
",calculus
"<p>$$x^{\frac{2}{3}}-2x^{\frac{1}{3}}-3=0$$
I need some help solving this reducible to quadratic equation.</p>
",calculus
"<p>I'm studying for a test and this question has me really stumped:</p>

<p>$f(x) = 2x^3+5x+3$. Find x if $f^{-1}(x) = 1$</p>

<p>I don't know how I am supposed to figure out the inverse of this polynomial. I used <a href=""http://www.wolframalpha.com/widgets/view.jsp?id=d08726019e4a2a15cb1d49092e4d0522"" rel=""nofollow"">this widget</a> from Wolfram|Alpha to find the inverse, and it returned an enormous and confusing formula which doesn't seem humanly possible to calculate:</p>

<p><img src=""http://i.stack.imgur.com/QbzVB.gif"" alt=""Wolfram|Alpha output""></p>

<p>(not sure if the formula image generated by the widget will get deleted or not)</p>

<p>How would one even go about solving that type of problem?</p>

<p>Thanks</p>
",calculus
"<h2><strong>Updated Question</strong></h2>

<p>Assuming I want to differentiate function using Chain Rule,  $\frac {x^5}{(3+ 2x^{8})},$ 
The Chain Rule says, $(g\circ f)'(x) = f'(x)\cdot g'(f (x))$</p>

<p>So what's the logic or steps to determine $f(x)$ and $g(x)$?</p>

<p>PS: I have the answer using Quotient Rule.</p>

<hr>

<p><strong>Here is how I solve it finally using <em>arbitrary</em> function f(x) and g(x).</strong> </p>

<ol>
<li>separate $x^{5}$ as h(x)</li>
<li>$f(x) = (3+2x^{8})$</li>
<li>$g(x) = x^{-1} = g(f(x)) = (3+2x^{8})^{-1}$</li>
<li>$\frac{d}{dx} h(x).g(x)$ = $\frac{d}{dx} x^{5}.[x^{-1}]$</li>
<li><p>using Product rule, 
$\frac{d}{dx} x^{5}.[x^{-1}] = 5x^{4}.g(x) + x^{5}.g'(x)$;
This g'(x) = the derivative of composition function, $(g\circ f)'(x)$</p></li>
<li><p>applyg Chain rule to get g'(x), the composition function,
$$(g\circ f)'(x)$$ = inside function's derivative . outside function's derivative.</p></li>
<li><p>$f'(x) = 16x^{7}$</p></li>
<li>$(g\circ f)'(x) = 16x^{7} . (-1)[x^{-2}]$</li>
<li>plug in f(x) into outside function's x,
$$(-1)[x^{-2}] = \frac{-1}{(3+2x^{8})^{2}} $$</li>
<li>Thus, 
$(g\circ f)'(x) = 16x^{7} .\frac{-1}{(3+2x^{8})^{2}} $</li>
<li>going back to where we pause at Product rule at Step 5 and applying each solved segment,
$\frac{d}{dx} x^{5}.[x^{-1}] = 5x^{4}.g(x) + x^{5}.(g\circ f)'(x) = \frac{5x^{4}}{(3+2x^{8})} -\frac{16x^{7}}{(3+2x^{8})^{2}} $</li>
</ol>
",calculus
"<p>So I have a two fold question, one I believe is simple but my algebra seems to be off, the other involves the trapezoidal rule of integration using Mathematica as an aid. Here they are:</p>

<p>$1.\quad \displaystyle \int_{-\infty}^{\infty} \frac{\operatorname{sech}(x)}{x^2+1} dx = \int_{-1}^{1} \operatorname{sech}\left(\frac{1}{1-t^2}\right)\frac{t^2+1}{t^4-t^2+1} dt$</p>

<p>I know I need to let $x = \frac{t}{1-t^2}$ and take the limits as $t \to \infty$,change the limits of integration and do the same for $t \to -\infty$ but I can't seem to nail it down. Why are my limits going to be $-1$ and $1$?</p>

<p>$2$. Space five points equally from $-1$ to $1$ and compute the four trapezoid approximation of
$\int_{-1}^{1} \mathrm{sech}(\frac{1}{1-t^2})\frac{t^2+1}{t^4-t^2+1} dt$ using Mathematica to evaluate $\operatorname{sech}(x)$. To be honest, I'm not really sure what the question is asking. Am I breaking the integral up into four integrations the first of which is from $-1$ to $-0.5$? How do I use Mathematica to evaluate? Any help is appreciated.</p>
",calculus
"<p>Why $g_n =\inf _{k \geq n} f_k $ is a nondecreasing sequence? Given that $f_k$ are non negative for all $k$?</p>

<p>I believe it is because if $m &gt; n$, then $\{f_n\} \subseteq \{ f_m \} $ and hence $\inf_{k \geq m} f_k &gt; \inf_{k \geq n} f_k $. Is this correct?</p>
",calculus
"<p>This is the integral and the solution has the following steps outlined </p>

<p>$$\int \frac{\sqrt{x+4}}{x}dx$$</p>

<p>$$u=\sqrt{x+4}$$
$$u^2=x+4$$
$$2u\,du=dx$$</p>

<p>$$\int \frac{u}{u^2-4}(2u\,du)$$
$$\int \frac{2u^2}{u^2-4}\,du$$</p>

<p>I'm very comfortable with doing all of the above... no issues there, but the next step is where I get lost:</p>

<p>$$\int \left(2+ \frac{8}{u^2-4}\right) \, du$$</p>

<p>It's probably something very small I'm overlooking, but how did they get the term $2$ and $8$ in the numerator of the other term?</p>
",calculus
"<p>So I wish to find for each of these functions a Lipschitz constant or prove that none exists. So my definition for a function to be Lipschitz is:</p>

<p>A function $f:[a,b] \rightarrow \mathbb{R}$ is Lipschitz if there exists a $L$ such that $|f(x) - f(y)| \leq L|x-y|$ for all $x,y \in [a,b]$.</p>

<ol>
<li><p>$f(x) = \frac{1}{x}$ for $x \in (0, 1]$ </p></li>
<li><p>$f(x) = e^x$ for $x \in \mathbb{R}$</p></li>
<li><p>$f(x) = \sqrt{1-x^2}$ for $x \in [-1,1]$</p></li>
</ol>

<p>My attempt for 1) to prove $f$ is not Lipschitz is via contradiction. Suppose that $x, y \in (0,1]$ and $f$ is Lipschitz. Then there exists a $L$ such that,</p>

<p>$$|\frac{1}{x} -\frac{1}{y}| = \frac{|x-y|}{|xy|} \leq L |x-y|$$ for all $x,y \in (0, 1]$. This would imply that, $\frac{1}{|xy|} \leq L$ for all $x,y \in (0, 1]$. But such a $L$ cannot exist since we can make $x, y$ as small as we like, the fraction will grow.</p>

<p>So in conclusion I attempted 1) but not sure if I am correct. I am stuck on 2 and 3. Anybody can give me some hints? I'm thinking of using the Mean Value Theorem on question 2. Other than that I have no idea how to start.</p>
",calculus
"<p>Please help with this: </p>

<p>Let 
$$f(z,b) = \begin{cases} z\sin(1/b), &amp; b \ne 0, \\ 0, &amp; b=0. \end{cases} $$</p>

<p>I'm trying to calculate the limit $f(z,b)$ for $(z,b)$ approach to $0$, in order to check if $f$ is continuously at $(0,0)$.</p>

<p>Please help with this way if is the right way...</p>
",calculus
"<p>I am trying to express the derivative of the outer product of the $(n\times m)$-matrix 
$\mathbf{A}=\mathbf{A}(\mathbf{x})$ with respect to the $p$-vector $\mathbf{x}$. This is, I want to rewrite $\frac{\partial \mathbf{A}\mathbf{A}^T}{\partial \mathbf{x}}$ using a product rule. My intuition tells me that I must have something like
$$
\frac{\partial \mathbf{A}\mathbf{A}^T}{\partial \mathbf{x}}=\mathbf{A}\otimes\frac{\partial \mathbf{A}}{\partial \mathbf{x}}+\frac{\partial \mathbf{A}}{\partial \mathbf{x}}\otimes\mathbf{A}.
$$
Any help or confirmation on this? Thanks!</p>
",calculus
"<p>For the function $$f(x)=b^x-1 = x_1 \qquad g(x)=\log(1+x)/\log(b) $$ and its iterative notation $$ x_0=x \qquad x_h=f(x_{h-1})=g(x_{h+1}) \qquad x_{-1}=g(x_0) $$ with <em>b</em> from the interval $1 \lt b \lt e$ we can define alternating series with infinitely many terms with negative as well with positive indexes. Let us denote the idea
$$A(x) = \ldots + x_{-2} - x_{-1} + x - x_1 + x_2 - \ldots $$
and define it by
$$ \begin{eqnarray}A(x) &amp;=&amp; A_n(x) + A_p(x) - x \\
\text{ where } \qquad A_n &amp;=&amp; \sum_{k=0}^\infty (-1)^k x_{-k} \\
\text{ and } \qquad A_p &amp;=&amp; \sum_{k=0}^\infty (-1)^k x_{k} \\
 \end{eqnarray} $$
With, say, $b=1.3$ and $x=3$ the series $A_p$ is convergent and $A_n$ must be evaluated using Cesaro/Euler-summation. It is obvious that this is 2-periodic, that means $$A(x)=A(x_2)=A(x_4)=...=A(x_{-2})=... $$<br>
such that it is irrelevant where I define the center $x$  as long as I choose the iterates in steps of <em>2</em>.
<hr>
I expect, that this should be true for the derivatives in the same way, but with some examples I find, that this is not the case. 
$$ ... \ne A'(x_{-2}) \ne A'(x) \ne A'(x_2) \ne ... \\  ... \ne A''(x_{-2}) \ne A''(x) \ne A''(x_2) \ne ... $$<br>
where I compute the derivatives in various ways, for instance simply by 
$$A'(x)=\lim_{h\to0} {A(x+h/2)-A(x-h/2) \over h} $$
<strong>Q:</strong> I think I must have some basic misunderstanding here (which, I think, is not specific to the given example function $f(x)$ and $g(x)$ here). Can someone explain this to me? 
<hr>
<strong>[Added:]</strong> It seems, I've found one hint myself: checking numerically I found that 
$$A(x_0)' = - x_1' \cdot A(x_1)' \quad \text{ where } \quad x_1' = \lim_{h\to0} {f(x_0+h/2)-f(x_0-h/2)\over h}$$
So at least the result is not completely random (and in particular not depending on problems with the Cesaro/Euler-summation), but my intuition is still unable to grasp this conceptually...
<hr>
Numerical example using $ b=1.3 , x_0=3.2 $
$$ \small
\begin{array} {rclll}
   &amp;   x_0 &amp;         A(x_0) &amp;         A'(x_0) &amp;  A''(x_0) \\       
    &amp; 3.20000000000 &amp; -0.00119822450167&amp; 0.0175377529574&amp; 0.000817628416425 \\
   &amp;   x_1 &amp;         A(x_1) &amp;         A'(x_1) &amp;  A''(x_1) \\       
 &amp;1.31536107268&amp; 0.00119822450167&amp; -0.0288702496568&amp; 0.0102533145478 \\
   &amp;   x_2 &amp;         A(x_2) &amp;         A'(x_2) &amp;  A''(x_2) \\
     &amp;0.412136407584&amp; -0.00119822450167&amp; 0.0779236358328&amp;   -0.129878114856
\end{array} $$</p>
",calculus
"<p>I know that's a very common theorem in calculus but when I try to prove it with $\epsilon-\delta$ definition of continuity, I found that it is not so obvious.</p>

<p>Attempts: Let $f:\mathbb{R}\to\mathbb{R}$ be a function differentiable at point $a$ $\implies$ $\forall \epsilon&gt;0, \exists \delta&gt;0 \text{ s.t. } |\frac{f(x)-f(a)}{x-a}-f'(a)|&lt;\epsilon$ for any $|x-a|&lt;\delta$. So what we want to show is $\forall \epsilon&gt;0$, we can find an $\delta&gt;0$s.t. $|f(x)-f(a)|&lt;\epsilon$ for any $|x-a|&lt; \delta$. First of all, we can applies the triangular inequality$|f(x)-f(a)|\le |f(x)-f(a)-f'(a)(x-a)|+|f'(a)(x-a)|&lt;\epsilon+|f'(a)(x-a)|$ but I found that $|f'(a)(x-a)|$ could be very large even $\epsilon$ can be any real number. Thx</p>
",calculus
"<p>I am given that $\sum\limits_{n=1}^\infty a_n$ is convergent. </p>

<p>I need to determine whether $\sum\limits_{n=1}^\infty (a_n)^\frac{1}{3}\;$ and $\;\sum\limits_{n=1}^\infty (a_n)^2\;$ are also convergent.</p>

<p>Imagine that $a_n = \dfrac{1}{n^4}.\;$ I believe that this is convergent because it's converging to $0$.</p>

<p>Following  the same thought, if $\displaystyle a_n = \left(\frac{1}{n^4}\right)^2,\;$ it's convergent because it's converging to $0$.</p>

<p>Am I doing this correctly or there is some other way to prove this?</p>
",calculus
"<p>Solve the differential equation
$$y''+(1-2x \cos x \cos 2x)y=0 \space $$</p>
",calculus
"<p>we hae a cylindrical tank which is full and depth is 10 meters. The rate at which the depth of liquid drops is proportional to the square root of the depth of the liquid. After draining for 20 minutes, the tank has now depth 5 meters. How long it takes for tank to empty?</p>

attempt:

<p>Let $H(t)$ be the height of the tank. We know $H(0)=10$ an $H(20)=5$. Also, since </p>

<p>$$ H' = \sqrt{H} \implies \int \frac{ \mathrm{d} H }{\sqrt{H}} = \int \mathrm{d} t \implies 2 \sqrt{H} = t + C$$</p>

<p>So, $2 \sqrt{5} = 20+ C $ so $C = 2 \sqrt{5}-20$. Thus,</p>

<p>$$ \sqrt{H} = \frac{t}{2} + \sqrt{5} - 10  $$</p>

<p>so, $H=0$ if $ t = \dfrac{ 10 - \sqrt{5} }{2} $</p>

<p>is this correct?</p>
",calculus
"<p>There is a nice $\exp$-like function, which can be defined on $\mathbb{R}$ by its Taylor series or by an integral:</p>

<p>$$p(x)=\sum_{k=0}^\infty \frac{x^k}{(k+1)^{k+1}}=\int_0^1 u^{-u x}du$$</p>

<p>I had a thought to define $\cos$-like and $\sin$-like functions the same way they are defined for the exponent:</p>

<blockquote>
  <p>$$pc(x)=\frac{1}{2}(p(ix)+p(-ix))=\sum_{k=0}^\infty \frac{(-1)^k x^{2k}}{(2k+1)^{2k+1}}=\int_0^1 \cos (x ~u \ln u)du$$</p>
</blockquote>

<p><a href=""http://i.stack.imgur.com/Rkzb7.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/Rkzb7.png"" alt=""enter image description here""></a></p>

<blockquote>
  <p>$$ps(x)=\frac{1}{2i}(p(ix)-p(-ix))=\sum_{k=0}^\infty \frac{(-1)^k x^{2k+1}}{(2k+2)^{2k+2}}=-\int_0^1 \sin (x~ u \ln u)du$$</p>
</blockquote>

<p><a href=""http://i.stack.imgur.com/TUp7n.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/TUp7n.png"" alt=""enter image description here""></a></p>

<p>I'm not sure how to use either of these definitions to find the zeroes (or the maxima/minima, etc) of $pc(x)$ and $ps(x)$.</p>

<blockquote>
  <p>I guess like for Bessel functions there might be no closed form expressions for these zeroes. But how to find them numerically in an effective way, without trial and error and computing either the series or the integral several times?</p>
</blockquote>
",calculus
"<p>I have the problem:</p>

<p>$$a_{n} = \frac{e^{n+5}}{\sqrt{n+7}(n+3)!}$$</p>

<p>I am told to use the ratio test to determine convergence or divergence (or the test could be inconclusive).</p>

<p>So I take the limit:</p>

<p>$$\lim_{n\to \infty} \frac{a_{n+1}}{a_{n}}$$
$$\lim_{n\to \infty} a_{n+1}\frac{1}{a_{n}}$$</p>

<p>$$\lim_{n\to \infty} \frac{e^{n+6}}{\sqrt{n+8}(n+4)n!} \frac{\sqrt{n+7}(n+3)n!}{e^{n+5}}$$
$$= (\lim_{n\to \infty} \frac{e^{n+6}}{e^{n+5}}) (\lim_{n\to \infty} \frac{\sqrt{n+7}}{\sqrt{n+8}}) (\lim_{n\to \infty} \frac{n+3}{n+4})$$</p>

<p>I reorganized and canceled the <strong><em>n!</em></strong> terms.</p>

<p>I keep getting:
$$(\lim_{n\to \infty} \frac{e^{n+6}}{e^{n+5}}) = e$$
$$(\lim_{n\to \infty} \frac{\sqrt{n+7}}{\sqrt{n+8}}) = 1$$
$$(\lim_{n\to \infty} \frac{n+3}{n+4}) = 1$$</p>

<p>So my limit is <strong><em>e</em></strong>, which indicates the series diverges. However, according both to MathWorks and WolframAlpha this is incorrect. The limit is actually 0, indicating the series converges.</p>

<p>Where am I going wrong?</p>
",calculus
"<p>Why does $$\lim_{x \to 1}\arccot\left(\frac{x^2+1}{x^2-1}\right)$$ diverge? In my textbook it says that from the positive side it's zero, and from the negative side it's $\pi$. However, when entering it into <a href=""https://www.symbolab.com/solver/step-by-step/%5Clim_%7Bx%5Cto1%7D%5Cleft(arccotan%5Cleft(%5Cfrac%7B%5Cleft(x%5E%7B2%7D%2B1%5Cright)%7D%7Bx%5E%7B2%7D-1%7D%5Cright)%5Cright)/?origin=enterkey"" rel=""nofollow"">Symbolab</a> the solution is zero (according to them, it converges). I also got $0$ in both cases, using my caveman-plug-in-the-values technique. I guess I'm solving this limit incorrectly.</p>

<p>What is the real solution? If I was analyzing this function and I messed up the vertical asymptote (which I'm doing in this particular problem), the rest of my analysis would be incorrect.</p>

<p>Can someone clear this out for me? </p>
",calculus
"<p>I'm trying to solve this integral with trigonometric substitution but am having a ton of trouble:
$$\int\limits_{0}^{a}{\frac{dx}{(a^2+x^2)^{\frac{3}{2}}}}$$</p>

<p>I tried $x=a\tan{\theta}$ and thus $dx=a\sec^2{\theta}$ but I cannot get anywhere.</p>
",calculus
"<p>Find $x$ such that 
\begin{equation}
x\tanh(x\sqrt{2\alpha})=\frac{2}{\sqrt{2\alpha}}
\end{equation}</p>
",calculus
"<p>This <em>limit</em> thing keeps coming up in my calculus textbook.  What is it?</p>
",calculus
"<p>I keep seeing this symbol $\nabla$ around and I know enough to understand that it represents the term ""gradient."" But what is a gradient? When would I want to use one mathematically?</p>
",calculus
"<p>I keep hearing about this weird type of math called calculus. I only have experience with geometry and algebra. Can you try to explain what it is to me?</p>
",calculus
"<p>I've come across statements in the past along the lines of ""function $f(x)$ has no closed form integral"", which I assume means that there is no combination of the operations:</p>

<ul>
<li>addition/subtraction</li>
<li>multiplication/division</li>
<li>raising to powers and roots</li>
<li>trigonometric functions</li>
<li>exponential functions</li>
<li>logarithmic functions</li>
</ul>

<p>which when differentiated gives the function $f(x)$. I've heard this said about the function $f(x) = x^x$, for example.</p>

<p>What sort of techniques are used to prove statements like this? What is this branch of mathematics called?</p>

<hr>

<p>Merged with ""<a href=""http://math.stackexchange.com/questions/2328/"">How to prove that some functions don't have a primitive</a>"" by <a href=""http://math.stackexchange.com/users/918/ismael"">Ismael</a>:  </p>

<p>Sometimes we are told that some functions like $\sin(x)/x$ don't have a indefinite integral, or that it can't be expressed in term of other simple functions.</p>

<p>I wonder how we can prove that kind of assertion?</p>
",calculus
"<blockquote>
  <p>Find an equation of the tangent line to the curve $2·(x^2+y^2)^2=25·(x^2−y^2)$ at the point 
  $(3,1)$.</p>
</blockquote>

<p>Any hints?</p>
",calculus
"<p>I have to draw the graphic of ""group of points given by the equation $$(|z^2|-3|z|+2)(z^4+4)=0$$ I solved the first part by factoring and obtaining $|z|=1$ and $|z|=2$ so in the graphic I have the points that stay on two circumferences with the respective radii. For the second part: $$z^4=-4 \to z=\sqrt2*i^{(1/4)}$$ so I'm sure I have 4 points that ""form a square"" but I don't know how to proceed correctly. I saw a question similar to mine but the answers were given using exponential forms that I don't know and that are not in my program. I need  a guideline that show me how to proceed when I have to solve this kind of equation or also the simpler equation form $z=v^{n/n}$, I need to have clear ideas and I'll be grateful if you can help me. Thank you in advance!</p>
",calculus
"<p>Find the Integral: </p>

<blockquote>
  <p>$$\int\limits_{0}^{\pi/6}\sin{x}\cos^2{x}\,\mathrm dx$$</p>
</blockquote>

<p>The answer is 1/3- square root of 3 over 8.</p>

<p>What method should one use to solve a problem like this?¨</p>

<p><img src=""http://i.stack.imgur.com/tSKzp.jpg"" alt=""enter image description here""></p>
",calculus
"<blockquote>
  <p><strong>Problem:</strong> Find the limit $ \displaystyle L = \lim_{x \to \infty} \left( x \ln x + 2 x \ln \sin \frac{1}{\sqrt{x}} \right) $.</p>
</blockquote>

<p>Please suggest how to proceed in this problem. I will be grateful to you. Thanks.</p>
",calculus
"<p>Problem : </p>

<p>Consider $f(x) =3x^2+2x+a$ where a is parameter such that $\frac{da}{dt}=3$ Let $a =0$, when $t =0$ and $A(t) =\int^t_0 \{f(x)\}\,dx$ ( where $\{\cdot\}$ denotes the fractional part function ). If $A(2)$ can be expressed as sum of $n$ integrals then find the minimum value of $n$.</p>

<p>My approach : </p>

<p>$$\frac{da}{dt}=3$$</p>

<p>Integrating both sides we get : </p>

<p>$$a =3t +c $$</p>

<p>Please suggest how to proceed further will be of great of help. Thanks.</p>
",calculus
"<p>Could someone please indicate precisely the difference between a scalar and a vector field? I find no matter how many times I try to understand, but I always am confused in the end. So what exactly makes them different?</p>
",calculus
"<p>$$\int_1^2 {1 \over (1-x)^2}dx$$
$$u = 1 - x$$
$$-du = dx$$</p>

<p>$$\lim_{a \to 0^-}-\int_0^{-1} {du \over u^2} = \lim_{a \to 0^-}\int_{-1}^{a} {du \over u^2}$$</p>

<p>$$\lim_{a \to 0^-} {1 \over u}|_{-1}^a $$
$$\lim_{a \to 0^-} {1 \over a} - {1 \over -1} = \infty + 1 = \infty \ = D.N.E. $$</p>
",calculus
"<p>Can I use the comparison test for the following problem?
$$\sum _{n=1}^{\infty }\:\frac{1}{n^2-6n+10}$$</p>

<p>The denominator has a negative coefficient so i'm not sure if its valid to compare it to a p-series. Does this effect anything, or is it valid to to say this is convergent because it's less than 1/n^2?</p>

<p>Should I use the integral test instead?</p>
",calculus
"<p>Evaluate $\int_0^x \frac{dt}{1+\cos^2t}$ $\forall x \in \mathbb{R}$</p>

<p>I got this question in an analysis exam, and I did what everybody does (<a href=""http://math.stackexchange.com/questions/1244055/integrate-frac11-cos2x-probably-need-using-some-trigonometric-identity"">this</a>), I made $u=\tan t$ and I got $\frac{1}{\sqrt2}\tan^{-1}\left(\frac{\tan x}{\sqrt2}\right)$ but I know this is wrong because $\tan x$ is not continuous in every $[0,x]$, <a href=""http://math.stackexchange.com/questions/638025/definite-integration-problem/638035#638035"">here</a> it's solved until $\pi$, but my limit is $x$ so I'm not sure what should I do.</p>

<p>Also, we have the integral of a positive amount, so my answer should be an increasing function...</p>

<p><a href=""http://math.stackexchange.com/questions/170885/a-little-integration-paradox"">Here</a> is explained why this happens (which I already know), and the answers there don't solve the integral between $0$ and $x$. One answer gives a possible result (that have to be adapted, since there it is indefinite), but no deduction of it. The answer given here is much more complete and perfectly address my specific question.</p>
",calculus
"<p>Show that for any finite value of $z$
$$e^z=e+e\sum_{n=1}^\infty \frac{(z-1)^n}{n!}$$</p>

<p>For $z=1$
$$f(z)=f(z_0)+\sum f^{(n)}(z_0)\frac{(z-z_0)^n}{n!}$$</p>

<p>equality is checked, but I do not know how to show for any finite value of z, I tried to apply the principle of induction but not worked well.</p>
",calculus
"<p>Let</p>

<ul>
<li>$A\in\mathbb{R}^{n\times n}$ and $b\in\mathbb{R}^n$</li>
<li>$f\in C^2(\mathbb{R}^n)$ and $\tilde{f}(x):=f(Ax+b)$ for $x\in\mathbb{R}^n$</li>
</ul>

<p>It's easy to prove that $$\nabla\tilde{f}(x)=A^T\nabla f(x)$$ But I'm not able to prove that the Hessian matrix $$\nabla^2\tilde{f}(x)=A^T\nabla^2 f(x)A$$</p>

<hr>

<p>Shouldn't we have $$\nabla^2\tilde{f}(x)=\left(\begin{matrix}\frac{\partial}{\partial x_1}\\\vdots\\\frac{\partial}{\partial x_n} \end{matrix}\right)A^T\nabla f(x)=A\left(\begin{matrix}\frac{\partial}{\partial x_1}\\\vdots\\\frac{\partial}{\partial x_n} \end{matrix}\right)\nabla f(x)=A\nabla^2f(x)\;?$$</p>
",calculus
"<p>$$\int {\sqrt{x^2-49} \over x}\,dx $$
$$ x = 7\sec\theta$$
$$ dx = 7\tan\theta \sec\theta \,d\theta$$
$$\int {\sqrt{7^2\sec^2\theta - 7^2} \over 7\sec\theta}\left(7\tan\theta \sec\theta \,d\theta\right) = \int \sqrt{7^2\sec^2\theta - 49} \left(\tan\theta d\theta\right)$$
$$ \int\sqrt{7^2(\sec^2\theta - 1)} (\tan\theta \,d\theta) = 7\int\sqrt{\sec^2\theta - 1} (\tan\theta \,d\theta)$$
$$ 7\int \tan^2\theta \,d\theta = 7\int \sec^2\theta - 1 \,d\theta  $$
$$ 7\int \sec^2\theta - 7\int d\theta $$ 
$$ 7\tan\theta - 7\theta + C  = 7(\tan\theta - \theta) + C$$</p>

<p>This makes: $$ \theta = \sec^{-1}\left(x \over 7\right)$$</p>

<p>And plugging back in to the indefinite integral:</p>

<p>$$ 7\left(\left(\sqrt{x^2-49} \over 7 \right) - \sec^{-1}\left(x \over 7 \right)\right) + C $$</p>

<p>My question really is, how can I evaluate $\sec^{-1}\left(x \over 7 \right)$ ?</p>
",calculus
"<p>I'm having trouble with this problem because it has $n$ as an exponent. Which I'm not really sure on how to deal with.</p>

<p>$$\lim_{n \to \infty} \frac{4+(-1)^n}{n^2}$$</p>
",calculus
"<p><img src=""http://i.stack.imgur.com/90mdk.png"" alt=""enter image description here""></p>

<p>Can someone help me with these limits?
At (a) I found the onesided limits and the right one was 0 and the left one was -infinite. I don't if i am correct</p>
",calculus
"<p>I need help proving that $g(x)= 1 - e^{-x}$ has unique fixed point on $[1,2]$.</p>

<p>Sorry in my previous post I accidentally type 1+e^-x, as opposed to 1-e^-x</p>
",calculus
"<p><img src=""http://i.stack.imgur.com/dBAqc.png"" alt=""enter image description here""></p>

<p>I think that it has to into specific cases but I don't really know how many cases would there be, can someone explain it even if they dont sketch it</p>
",calculus
"<p><strong>Question</strong>
Given $K_n=\cases 0$ elsewhere , $n- n^2|x|$ for $x&lt;|\frac 1n|$
,
 $f$ is continuous, $2\pi$ periodic $\Bbb R \to \Bbb C$
. </p>

<p>$f_n(x)=\int _{-\pi}^ \pi f(t)Kn(x-t)$ </p>

<p>prove that $f_n\to^uf$.</p>

<p><strong>Thoughts</strong>
I know it has something to do with Fourier series and Fejer kernel. Since this is not the same kernel - I don't really know how to handle it.</p>
",calculus
"<blockquote>
  <p>I tried to prove that it does not converge by showing that the series $b_n=\frac{\sin a_n}{a_n}$ does not converge to $0$. But I am stuck with a limit of the kind $\frac{0}{0}$. </p>
</blockquote>

<p>Thanks for helping me proceeding from here. </p>
",calculus
"<p>I trying to find Fourier series and I see a lot of times that $\int^\pi_{-\pi}$ of absolute $|\cos| \text{ and } |\sin| $ is 4.</p>

<p>for example, $\int^\pi_{-\pi} (2-|x|) \cos(x) = 4 \text{ and } \int^\pi_{-\pi} |\sin(x)| = 4$.</p>

<p>What is the trick behind integrals over $[-\pi, \pi]$ of absolute-valued cosine and sine?</p>

<p>Thanks in advance!</p>
",calculus
"<p>I would appreciate if somebody could help me with the following problem</p>

<p>Q: Find the maximum of $$f(x) =\frac{x-\ln(1+x)}{x\ln(1+x)};\quad(x&gt;0)$$</p>
",calculus
"<p>The poisson kernel is sometimes written as
$$
\frac{1}{2\pi}\int_0^{2\pi} \frac{R^2-r^2}{R^2 - 2Rr\cos(\varphi-\vartheta) + r^2} \mathrm{d}\vartheta = 1 \ , \ \ R&gt;r&gt;0
$$
Where $\varphi$ is some arbitary angle. 
This much used in complex analysis amongst other fields. Is there some basic, elementary way of showing that the integral is independent on $R$ and $r$?</p>

<p>Splitting the integral at $\int_0^\pi + \int_\pi^{2\pi}$ and using the Weierstrass substitution seems like somewhat ugly and a  messy way to approach the problem.</p>
",calculus
"<p>How do I solve:
$$ 
\frac{1}{\pi}(x \tan x) = \frac{1}{8}
$$
for $x$ where $x$ is in $[0,\pi]$?</p>

<p>The problem states: </p>

<blockquote>
  <p>""Determine if the graph of the curve $y = (1/\pi)(x\tan x)$ crosses
  the line $y = (1/8)$ at some point $x$ in $[0, \pi]$. Justify answer.""</p>
</blockquote>

<p>I have already plotted this and see that there is 2 intersection points at around ±0.588, my problem is that I cannot solve the function numerically thus unable to prove how i got to the answer.</p>

<p>Any help is appreciated.</p>

<p><a href=""http://i.stack.imgur.com/lsiAKm.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/lsiAKm.png"" alt=""graph of y""></a> (<a href=""http://i.stack.imgur.com/lsiAK.png"" rel=""nofollow"">Large version</a>)</p>
",calculus
"<blockquote>
  <p>I would like to prove
  $$ \forall x &gt;0,  \quad \sqrt{x +2} - \sqrt{x +1} \neq \sqrt{x +1}-\sqrt{x}$$</p>
  
  <ul>
  <li>I'm interested in more ways of proving it</li>
  </ul>
</blockquote>

<p><strong>My thoughts</strong>:</p>

<p>\begin{align}
\sqrt{x+2}-\sqrt{x+1}\neq \sqrt{x+1}-\sqrt{x}\\
\frac{x+2-x-1}{\sqrt{x+2}+\sqrt{x+1}}&amp;\neq \frac{x+1-x}{\sqrt{x +1}+\sqrt{x}}\\
\frac{1}{\sqrt{x+2}+\sqrt{x+1}}&amp;\neq \frac{1}{\sqrt{x +1}+\sqrt{x}}\\
\sqrt{x +1}+\sqrt{x} &amp;\neq \sqrt{x+2}+\sqrt{x+1}\\
\sqrt{x} &amp;\neq \sqrt{x+2}\\
\end{align}</p>

<ul>
<li>Is my proof correct? </li>
<li>I'm interested in more ways of proving it.</li>
</ul>
",calculus
"<p>I want to evaluate this integral:</p>

<blockquote>
  <p>$$\int{\frac{ax+b}{(x^2+2px+q)^n}}dx$$</p>
</blockquote>

<p>The book only says to integrate by parts $\int{\dfrac{1}{(x^2+2px+q)^{n-1}}dx}$,
for simplicity if $n = 2$ I get:
$\int{\dfrac{1}{(x^2+2px+q)}dx}=\dfrac{x}{x^2+2px+q}+\int{\dfrac{2x^2+2px}{(x^2+2px+q)^2}}dx$.</p>

<p>Now I don't know what to do.</p>
",calculus
"<p>Is there a not identically zero, real-analytic function $f\colon\mathbb R\to\mathbb R$, which satisfies</p>

<p>$$f(n)=f^{(n)}(a),n\in\mathbb N \text{ or }\mathbb N^+?$$</p>

<p>and $a\in \mathbb R$</p>

<p><a href=""http://math.stackexchange.com/questions/91855/is-there-a-function-with-the-property-fn-fn0/91927#91927"">I saw a special case when $a=0$</a></p>

<p>I try to solve it by :</p>

<p>$$f(x)=e^{cx}$$
$$f(n)=e^{nc}$$
$$f^{(n)}(x)=c^ne^{cx}$$
$$f^{(n)}(a)=c^ne^{ca}$$
so $$e^{nc}=c^ne^{ca}$$
<a href=""http://www.wolframalpha.com/input/?i=solve%20%28c%5En%29%2a%28e%5E%28c%28a-n%29%29%29=1%20for%20c"">so</a> $$c=\frac{nW(\frac{a-n}{n})}{a-n}$$</p>

<p>the problem is we always see  n with c 
but the special case when a=0 give </p>

<p>$$c=\frac{nW(\frac{0-n}{n})}{0-n}$$
$$c=\frac{W(\frac{-1}{1})}{-1}=-W(-1)$$</p>

<p>I think there is no solution when $a\neq 0$</p>

<p>may be there is another function can solve it</p>

<p>Is there any solution in general?</p>

<p>thanks for all</p>
",calculus
"<p>I've just read the proof of a theorem which states that if a function of several variables(two in this case) has partial derivatives in some neighborhood of a point (x,y) and these derivatives are continuous at (x,y) then the function is differentiable at that point. The proof uses the mean value theorem and ,analytically, I understand the proof but I can't feel why it is necessary to have these derivatives in a neighborhood not just in a point. Can someone experienced share his intuitive view on this question and show me some intuitive reasons for this being necessary?</p>
",calculus
"<p>By ""curved"", I mean that there is no portion of a graph of a function that is a straight line. (Let us first limit the case into 2-dimensional cases.. and if anyone can explain the cases in more than 2-dimensional scenarios I would appreciate.. but what I really want to know is the 2-dimensional case.)</p>

<p>Let us also say that a function is surjective (domain-range relationship).</p>

<p>So, can every continuous and curved function be described as a formula, such as sines, cosines, combinations of them, or whatever formula?</p>

<p>thanks.</p>
",calculus
"<p>We are given a continuous function $f \colon [0,1] \to \mathbb{R}$. What is the value, if it exists, of the limit $$\lim_{t \to +\infty} \frac{1}{t} \log \int_0^1 \cosh (t f(x))\, \mathrm{d}x \ ?$$</p>

<p>PS: this is not homework. It's a question contained in a Ph.D test, and I am unable to make progress toward the solution :-(</p>
",calculus
"<p>The sphere is </p>

<p>$x^2 + y^2 + z^2 = 81$</p>

<p>and the point is $(5,6,9)$</p>

<p>I am using Langrane multipliers , but the answers I am getting are so far off. I will post my system of equations soon. </p>

<p>I found the gradient of $F: (2(x-5), 2 (y-6), 2(z-9))$<br>
Gradient of $G: (2x, 2y, 2z)$</p>

<p>$2x-10 = 2 \lambda x$<br>
$2y-12 = 2 \lambda y$<br>
$2z-18 = 2 \lambda z$<br>
$x^2+y^2+z^2 = 81$</p>

<p>This system seems very challenging to solve.</p>
",calculus
"<p>Find equation of the straight line tangent to the curve at the point indicated:</p>

<p>$y=2x^2 -5$ at $(2,3)$</p>

<p>I think I have to use $y=m(x-x_o)+y_0$ etc but I'm not sure how to find the $m$! Thanks for tips/solutions!</p>
",calculus
"<p>Please help me to prove the identity
$$_2F_1\!\left(\frac76,\frac12;\,\frac13;\,-\phi^2\right)=0,$$
where $\phi=\frac{1+\sqrt5}2$ is the golden ratio.</p>
",calculus
"<p>Can you give me a very precise demonstration of this result please because it's very difficult for me to understand the demonstration on the pic :( </p>

<p>$$
\sum_{(p,q) \in {\mathbb{N}^*}^2 \text{, } p \land q =1} \frac{1}{p^2 q^2} = \frac{5}{2}
$$ </p>

<p><img src=""http://i.stack.imgur.com/JXdQT.png"" alt=""enter image description here""></p>

<p>Thank you ! 
Shadock </p>
",calculus
"<p>Find the area (to three decimal places) bounded by $f(x)=x^2e^x$ and $q(x)=4-x^2$</p>

<p>So far I've gotten $x^2(e^x+1)-4=0$
and the two $x$ values that make the equation $0$ are $1.027$ and $-1.86$
next I tried to integrate the function to find the area.</p>

<p>I got $A= \int(4-x^2-x^2e^x)dx= \left[4x-\frac{x^3}{3}-e^x(x^2-2x+2)\right]_{-1.86}^{1.027}$.</p>

<p>when I calculated my answer and it was 9.788. This is wrong b/c here are the choices of answers: (A)7.0 (B)7.676 (C)7.333 (D)7.555</p>

<p>Can someone help me out?</p>
",calculus
"<p>It is the indefinite integral: $\int \frac{1}{2x-6}$ </p>

<p>I am trying to understand it and looking the last step goes from $\frac12 \log(2(x-3))$ to $\frac12 \log(x-3)$</p>

<p>Can someone explain to me why the two just disappears and the answer isn't just $\frac12 \log(2x-6)$</p>
",calculus
"<blockquote>
  <p>Suppose $f$ is (Riemann) integrable over $[c,b]$ for every $c\in (a,b)$ and the improper integral $\int_{a}^{b}|f|dx$ exists. Then $\int_{a}^{b}fdx$ also exists. Does the inverse hold?</p>
</blockquote>

<p>Here is what I've tried.</p>

<p>We know $|f|=f^++f^-$ (the positive and negative part of $f$, which are integrable over any $[c,b]$). By Comparison Test, $\int_{a}^{b}f^+dx$ and $\int_{a}^{b}f^-dx$ exist. Hence the improper integral of $f=f^+-f^-$ exists.</p>

<p>Is this okay?</p>

<p>Would anyone help me with the counterexample of the inverse? I'd appreciate it so much.</p>
",calculus
"<p>I am trying to take the following limit
$$
\lim_{t\to\infty} \frac{1}{t}\exp{\left(\frac{\sqrt[4]{2} \left(\sqrt{\pi }-1\right) t^B e^{-\frac{t^{2 B}}{2 \sqrt{2}}}}{\pi }-\frac{\left(2 \sqrt{2} \left(\sqrt{\pi }-1\right) t^{2 B}+\sqrt{\pi }+2\right) \operatorname{erfc}\left(\frac{t^B}{2^{3/4}}\right)}{4 \sqrt{\pi }}+\frac{1}{2}\right)},
$$
where 
$\operatorname{erfc} \left(z\right)$ is the complementary error function given by
\begin{equation}
\operatorname{erfc}(z) = \frac{2}{\sqrt{\pi}}\int_z^{\infty} \mathrm{e}^{-t^2} \,dt 
\end{equation}
and $0 \le B \le 1$.
I have tried using Lhospital's rule but the numerator started to unwind and I was not sure how to proceed after the first derivative.
Thank you.</p>
",calculus
"<p>Evaluate $$\int \frac{3x^2+1}{(x^2-1)^3}dx$$ I tried breaking the numerator in terms of the denominator but it didn't help much. I also tried a few substitutions buy most of them were useless. Please give some hints. Thanks.</p>
",calculus
"<p>Give me some hints to <strong>start</strong> with this problem: $${\displaystyle\int}\dfrac{2x^{12}+5x^9}{\left(x^5+x^3+1\right)^3}\,\mathrm{d}x$$</p>
",calculus
"<p>Prove $$\int^\infty_0 \frac{x^{n-1}}{1+x}dx= \frac{\pi}{\sin(n\pi)}$$</p>

<p>I would like to consider two circles of radii $\epsilon &lt; 1 &lt; R$ centered at the origin and connected by a corridor of width $\delta &gt; 0$. Then I want to choose a branch of the logarithm in $ \mathbb{C}$ \ $[0,\infty]$ and study its behavior on both sides of the corridor. But I don't know how to go about this to get the final result. Any help appreciated!</p>
",calculus
"<p>Let $f(x,y)$ be a differentiable two variable function such that $f(2,-1)=4, f_{y}(2,-1)=-2 , f_{y}(2,-1)=3$. Find $g_{x}(2,-1)$ and $g_{y}(2,-1)$ if:</p>

<p>a) $g(x,y)=f(3x+4y,2xy^2-5)$</p>

<p>b) $g(x,y)=f(\frac{1}{2}f(x,y),xy+1)$</p>

<p>can someone help me with some hints as how to tackle this problem because I haven't seen this kind of exercise. Thank you.</p>
",calculus
"<p>Does this diverge or converge ?? $$\sum_{n=1}^{\infty}(\frac{H_n}{p_n}-\frac{n}{n^n})$$
where $H_n$ is the nth harmonic number, $p_n$ is the nth prime.</p>

<p>My impression is that it diverges, but I don't see how I can prove it!
I tried on wolframalpha but no clue.</p>
",calculus
"<p>Hi I am trying to calculate
$$
I:=\int_0^\pi \theta^2 \ln^2\big(2\sin\frac{\theta}{2}\big)d \theta.
$$
Here is a related  <a href=""http://math.stackexchange.com/questions/699746/integral-int-0-pi-theta2-ln2-big2-cos-frac-theta2-bigd-theta"">Integral...$\int_0^\pi \theta^2 \ln^2\big(2\cos\frac{\theta}{2}\big)d \theta$.</a>.  This paper may also be of interest to people here : <a href=""http://www.math.uwo.ca/~dborwein/cv/zeta4.pdf"">http://www.math.uwo.ca/~dborwein/cv/zeta4.pdf</a>.</p>

<p>We can expand the log in the integral to obtain three interals, one trivial, the other 2 are not so easy, any ideas? I tried doing the following
$$
\left( \ln 2 +\ln \sin \frac{\theta}{2} \right)^2=\ln^2(2)+\ln^2\sin\frac{\theta}{2}+2\ln (2)\ln \sin\big(\frac{\theta}{2}\big).
$$
We can write I as 
$$
I=\ln^2(2)\int_0^\pi \theta^2d\theta  +\int_0^\pi\theta^2 \ln^2 \sin \frac{\theta}{2}d\theta+2\ln 2 \int_0^\pi\theta^2 \ln \sin{\frac{\theta}{2}}d\theta.
$$
Change of variables $x=\theta/2$ and performing the trivial integral we obtain
$$
I=\frac{\pi^3\ln^2 2}{3}+8\int_0^{\pi/2} x^2 \ln^2 \sin x\, dx+16\ln 2\int_0^{\pi/2} x^2 \ln \sin x \, dx.
$$
I am stuck at this point, I was trying to somehow work these two integrals into the form of $$
\int_0^{\pi/2} \ln \sin x dx= \frac{-\pi\ln(2)}{2}\approx -1.08879
$$
but couldn't do so.  Thanks.</p>
",calculus
"<p>Let $f$ be a function of $x$ and $f'$ be the derivative, at a point $(x_0, f(x_0))$
the slope is $f'(x_0)$, we know from any calculus book that
the line $g(x) = f(x_0) + f'(x_0)(x - x_0)$ is tangent to the curve of $f$, 
but how do you rigorously prove it?</p>
",calculus
"<p>The devil's staircase or <a href=""https://en.wikipedia.org/wiki/Cantor_function"" rel=""nofollow"">Cantor function</a> is an awesome function that increases value but has derivative zero everywhere (or ""almost"", whatever that means).</p>

<p>I was incredibly amazed when I found out that the standard part function also seems to have derivative zero, no matter how you take it (I'll just show forwards):</p>

<p>$$
\require{cancel}
\frac{d(\text{st}\ x)}{dx}=
\text{st}\frac{\text{st}(x+dx)-\text{st}(x)}{dx}=
\text{st}\frac{\cancel{\text{st}(x)}+\text{st}(dx)\cancel{-\text{st}(x)}}{dx}=
\text{st}\frac{0}{dx}=0
$$</p>

<p>Which is odd, since the standard part function looks exactly like the identity function, $y=x$, when plotted, well, with a normal real scale. When magnified with the infinitesimal microscope, one would see a straight horizontal line, as all nonstandard numbers would be ""rounded"" to the nearest real.</p>

<p><img src=""http://i.stack.imgur.com/zVzA0.png"" alt=""Standard part function. $\delta$ is an infinitesimal""><br>

This reminds me of the floor function, but somehow this one doesn't seem to have discontinuities (it really doesn't, for any infinitesimal $\Delta x$, there's always an infinitesimal $\Delta(\text{st}\ x)=0$).</p>

<p>I'm confused, what's wrong here? Does the standard part function really have derivative zero everywhere?</p>
",calculus
"<h3>Problem statement:</h3>

<p>A plane flying with constant speed of 4 km/min passes over a ground radar station at an altitude of 6 km and climbs at an angle of 35 degrees. At what rate, in km/min, is the distance from the plane to the radar station increasing 6 minutes later? </p>

<p>Hint: The law of cosines for a triangle is $c^2=a^2+b^2− 2ab \cos(\theta)$ where $\theta$ is the angle between the sides of length $a$ and $b$.</p>

<hr>

<p>Okay, so following the typical related rates algorithm:</p>

<p>Identify the problem at hand by drawing a picture. I did that. It appears to me that after the plane passes over the ground station, we get an angle between the measures a and b of 90 + 35 degrees. </p>

<p>Awesome.</p>

<p>Now, let's build a table of values:
$$
a = 6\,\mathrm{km}\\
a' = 0 \quad \text{(duh)}\\
b = b'\cdot t = 4\cdot 6 = 24\\
b' = 4\,\mathrm{km}/\mathrm{min}\\
t' = 6min\\
c = \sqrt{a^2 + b^2} = \sqrt{36+24} = 2\sqrt{15} \approx 2.78316\\
c' = ?
$$</p>

<p>Okay, let's differentiate the law of cosines, which is given to us in form of a hint:</p>

<p>$2cc' = 2aa' + 2bb' - \frac{du}{dt}$</p>

<p>$
u = 2ab\cos(\theta)$</p>

<p>$\frac{du}{dt} = \frac{ds}{dt} \cdot \cos(\theta) - \sin(\theta)\cdot(2ab)$</p>

<p>$\frac{ds}{dt} = 0\cdot ab + (a'b + b'a)$</p>

<p>And so now we rewind:
$\frac{du}{dt} = \left[ \left(0 \cdot ab + \left(a'b + b'a \right) \right) \right] \cdot \cos(\theta) - \sin(\theta) \cdot 2ab $</p>

<p>And so: </p>

<p>$2cc' = 2aa' + 2bb' - \left[ \left(0 \cdot ab + \left(a'b + b'a \right) \right) \right] \cdot \cos(\theta) - \sin(\theta) \cdot 2ab $</p>

<hr>

<p>Boom, boom. Let's substutute what we know</p>

<p>$2\left(2 \sqrt{15} \right)(c') = 2(6)(0) + 2(24)(4) - \left[ \left(0\cdot (6)(24) + \left((0)(24) +  (4)(6) \right) \right) \right] \cdot \cos(125^\circ) - \sin(125^\circ) \cdot 2(4)(24)$</p>

<hr>

<p>Now what? Well, evaluate. Not sure if that's going to yield the right answer. But I don't think that it will. </p>

<p>Please help! I don't know how to solve this kind of problem! It seems my solution/process is incorrect!</p>
",calculus
"<p>How many solutions are there for this equation:</p>

<p>$(n+1)x-\lfloor nx \rfloor = c$</p>

<p>I can prove some basic properties of floors and ceiling, but here I'm stumped.</p>
",calculus
"<p>In the following encyclopedia, <a href=""http://m.encyclopedia-of-equation.webnode.jp/including-integral/"" rel=""nofollow"">http://m.encyclopedia-of-equation.webnode.jp/including-integral/</a></p>

<p>I found the relations below</p>

<p>\begin{eqnarray}
\int_{0}^1 \frac{1}{x} \log^3{(1-x)}dx &amp;=&amp;-\frac{\pi^4}{15} \tag{1} \\
\int_{-\pi}^{\pi} \log(2\cos{\frac{x}{2}}) dx &amp;=&amp; 0 \tag{2}
\end{eqnarray}
I tried to prove these equation, but I didn't success to prove.
How do you go about evaluating those integrals to obtain the repsective values?</p>
",calculus
"<p>I have the following function:
\begin{equation}
y=\frac{(x-1)(x+4)}{(x-2)(x-3)}
\end{equation}
It's easy to find it's domain, which is: $\mathbb{R} - \{3,2\}$. I know how to find the range of easier functions such as parabolas and such. Is there a systematic way to find the range of more difficult functions such as this one? Thank you in advance.</p>
",calculus
"<p>Say I have an infinite sequence $X=(x_i)$, $i=1,2,3,\ldots$ such that it's in $\ell^2$ space, i.e. $\sum_{i=1}^\infty|x_i|^2&lt;\infty$.  Now, this function that takes this infinite sequence to a real number:</p>

<p>$$\tag{1}F(X)=\sum_{i=1}^\infty\ln \left(1+\frac{x_i}{a_i}\right)$$</p>

<p>(let's assume that $x_i\geq0$ for all $i$ and (1) converges).</p>

<p>What can I say about the Frechet derivative at $X$?  Does the fact that $\frac{\partial F}{\partial x_i}=\frac{1}{a_i+x_i}$ exist for every $i$ tell me anything?  How do I compute it here?</p>
",calculus
"<p>How to prove $$\lim_{n\rightarrow\infty}nx^n=0$$ without L'Hôpital's rule? where $x \in [0,1)$ and $n=1,2,3,...$.</p>

<p>I know one of way to prove this is to treat $n$ is real, and $n$ and $(\frac{1}{x})^n$ as functions of $n$. Then, apply L'Hôpital's rule and it works for discrete $n$ by the definiation of limit. </p>

<p>However, I would like to skip the step we treat $n$ is real. Is there any proof for this question only using the techniques for limit of sequences? (such as the sandwich theorem, etc.)</p>
",calculus
"<p>Here's my work.</p>

<p>$$\begin{align} \lim_{y\to -2} \;\dfrac{y^3+8}{y+2} &amp;= \lim_{y \to -2}\;\require{cancel}\dfrac{(\cancel{y +2})(y^2 - 2y + 4)}{\cancel{y + 2}}\\ \\
&amp; = \lim_{y \to -2}\;\; y^2 - 2y + 4 \\ \\
&amp; = 4 + 4 + 4 \\ \\
&amp; = 12\end{align}$$</p>

<p>The answer book says that the correct answer is 4</p>

<p>What did I do wrong??</p>
",calculus
"<p>For the function $ƒ (x)=\frac{x^2}{(x−2)^2}$</p>

<p>I know the derivative is $f'(x)=-\frac{4x}{\left(x-2\right)^3}$ and $f''(x) =\frac{8\left(x+1\right)}{\left(x-2\right)^4}$</p>

<p>Critical point is $x=-1$ which is also the min.</p>

<p>I think possible inflection point are $x=1$ and $x=0$</p>

<p>I need to find:
1)Find the vertical and horizontal asymptotes of $ƒ (x)$.</p>

<p>2)Find the intervals on which $ƒ (x)‍$ is increasing or decreasing.</p>

<p>3)Find the critical numbers and specify where local maxima and minima of $ƒ (x)$ occur.</p>

<p>4)Find the intervals of concavity and the inflection points of $ƒ (x)$.</p>

<p>sorry for the long problem. Hope you can help</p>
",calculus
"<p><strong>Question</strong></p>

<p>Please help me find the derivative of $\arcsin \dfrac{(e^{2x}-1)}{(e^{2x}+1)}$</p>

<p><strong>Answer</strong></p>

<p>Using the chain rule this can be written as:</p>

<p>$$\dfrac{1}{\sqrt{1- \left( \dfrac{e^{2x}-1}{e^{2x}+1}\right)^2}} \times \dfrac{2e^{2x}(e^{2x}-1)-2e^{2x}(e^{2x}+1)}{(e^{2x} + 1)^2}$$</p>

<p>This can be simplified to:</p>

<p>$$\dfrac{1}{\sqrt{1- \left( \dfrac{e^{2x}-1}{e^{2x}+1}\right)^2}} \times \dfrac{-4e^{2x}}{(e^{2x} + 1)^2}$$</p>

<p>The correct answer should be</p>

<p>$$\dfrac{2e^{x}}{e^{2x}+1}$$</p>

<p>I can't really see how they get there...</p>
",calculus
"<blockquote>
  <p>Evaluate $$\int \frac{x^2+3}{x^6(x^2+1)}dx .$$</p>
</blockquote>

<p>I am unable to break into partial fractions so I don't think it is the way to go. Neither is $x=\tan \theta$ substitution. Please give some hints. Thanks.</p>
",calculus
"<p>Evaluate $$\int\frac{dx}{(1+x^2)^4}$$ Now I did solve it, but I used the mentioned substitution and after a lot of converting into double angles, I did it. But, it doesn't look like a good approach. Is there a better way? Thanks.</p>
",calculus
"<p>Let's say I want to evaluate the upper and lower Riemann Sums of the function $f(x)=x^2$ for the following partition on $[-1,1]$, $P = \{-1, -\frac{1}{2}, 1\}$</p>

<p>I'll start of with the definitions of upper and lower Riemann Sums, just to show you where I'm coming from, and so that you can see where any misunderstanding on my part would lie.</p>

<p>$$L(f, P) := \sum_{i=1}^{n}m_i(t_i - t_{i-1})$$
$$U(f, P) := \sum_{i=1}^{n}M_i(t_i - t_{i-1})$$
where
$$m_i = \inf\{f(x): x \in [t_{i-1}, t_i]\}$$
$$M_i = \sup\{f(x): x \in [t_{i-1}, t_{i}]\}$$</p>

<hr>

<p>This is what I did :</p>

<p>Since $f$ is continuous on $[-1,1]$, $m_i = \min\{f(x): x \in [t_{i-1}, t_i]\}$ and $M_i = \max\{f(x): x \in [t_{i-1}, t_i]\}$</p>

<p><strong>Lower Sum</strong> (Incorrectly Evaluated)</p>

<p>$\min(f(x)) = 0$ and occurs on the sub interval $[-\frac{1}{2}]$, this implies $m_i = 0$. But this has to be incorrect as it then implies $L(x^2, \{-1, -\frac{1}{2}, 1\}) = 0$. The correct answer is $\frac{1}{8}$</p>

<p><strong>Upper Sum</strong> (Correctly Evaluated) (EDIT: As it turns out due to a special case of this question)</p>

<p>$\max(f(x)) = 1$ and occurs on the sub-intervals $[-1, -\frac{1}{2}]$ and $[-\frac{1}{2}]$ at $x=-1$ and $x=1$, thus $M_i=1$</p>

<p>$$\begin{align}U(x^2 \{-1, -\frac{1}{2}, 1\}) &amp;= \sum_{i=1}^{n} 1 \cdot (t_{i} - t_{i-1})\\
&amp;= (-\frac{1}{2}-(-1)) + (1-(-\frac{1}{2}))\\
&amp;= 2
\end{align}$$</p>

<hr>

<p>I seem to have some misunderstanding, with calculating $M_i$ and $m_i$, I'm not sure why.Perhaps it's because I've computed the Riemann Sums with $m_i$ and $M_i$ as constant throughout all sub-intervals?</p>

<p>How would you evaluate the upper and lower Riemann Sums, given this function over the specified interval? Any hints would be appreciated.</p>
",calculus
"<p>I'm an engineering student, currently working my way through the fundamental mathematics courses.</p>

<p>I've done reasonably well so far&mdash;mostly A's and a couple of B's in Algebra, Statistics, Pre-Calculus, and Calculus I (I'm currently struggling quite a bit in Calculus II; so only time (and sweat; no blood or tears yet) will tell if I can maintain my academic performance after this course.</p>

<p>However, although my school is good and well-ranked among community colleges, it's still a community college. None of the courses go too in-depth on any of the topics we cover. It's all about teaching us techniques and methods for solving problems (not extraordinarily difficult problems, either). It's not that the instructors aren't good - many are quite good and certainly know their math. But there just isn't time to spend on any individual topics. We covered all of the integration techniques that are taught at this level (with the exception of improper integrals) in about 2 weeks, or 8 class meetings.</p>

<p>In spite of this (or maybe because I've realized a lot of the responsibility for learning the rest falls on me), I've really developed an awe and a love for mathematics. Not enough too switch majors; I still have an overwhelming desire to build robots. ;) </p>

<p>But I really want to <em>master</em> the subjects in mathematics I'm exposed to, to really learn them thoroughly and at a deep level&mdash;not only because the better I do that, the better an engineer I'll be (I hope), but also because I'm really blown away by how cool the math is.</p>

<p>So, my question is, how can I develop more adept mathematic thinking and reasoning skills, better math intuition?</p>

<p>None of my classes have been proof-based, yet. Would starting to learn how to build proofs help my intuitive skills to grow faster?</p>

<p>For instance, I've been studying (and struggling with a <em>lot</em>) infinite sequences and series, and how to represent functions as power, taylor, and maclaurin series. </p>

<p>I have made some progress, but I'm advancing <em>very slowly.</em> When I look at a formula like:</p>

<p>$$P_0(x) = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{2^{2n} n!^2}$$</p>

<p>or even a more simple one, like:</p>

<p>$$\sum_{n=1}^{\infty} \frac{(-1)^n 3^{n-1}}{n!}$$</p>

<p>I have a great deal of trouble seeing past the jumble of variables and constants to the pattern they describe. I want to reach the point at which I can see the matrix!  ;)  (the movie type, not the spreadsheet type).</p>

<p>That's a joke of course, but seriously, while a mathematician may look at a matrix and see a mathematical structure, I have to think very hard, and sometimes to sketch an actual structure, to see a matrix as anything more than a large table of numbers.</p>

<p>If learning to prove theorems isn't the answer, (or the whole answer), what are some things you can try to help increase your capability to think mathematically / logically about concepts in calculus, and mathematics in general?</p>
",calculus
"<p>Can cusps be considered points of inflection?</p>

<p>I'm getting conflicting information but my thought process is that cusps cannot be points of inflection?</p>

<p>Can points of inflection exist when there is a vertical tangent to the graph? Assume there is change in concavity and the function is continuous.  </p>
",calculus
"<p>(1) A curve is given by the function $$r(t)=(t^3 -3t^2 +2t +4)i + (13-5t)j +(t^2 -t-3)k$$</p>

<p>Determine a parameterization for the line which is tangent to the curve at $t=2$</p>

<p>I started by solving for when $t=2$, and got the vector $4i + 3j - k$</p>

<p>I don't know what this vector means or if this was even the correct approach. Do I need to find the vector perpendicular to this, or what should I be doing instead?</p>
",calculus
"<blockquote>
  <p>A torus (a doughnut-shaped object) is formed by revolving the circle 
  $$x^2 + y^2 = a^2$$
  about the vertical line $x = b$, where $0 &lt; a &lt; b$. Find its volume.</p>
</blockquote>

<p>I have tried to create an integral that makes sense but I keep getting it wrong. We are learning shell method and disk method if that helps. I'm just stuck at where I should even start with this problem. Any help would be appreciated!</p>
",calculus
"<blockquote>
  <p>Let $f(x)$ be continuous on $[0,2]$, and differentiable on $(0,2)$ such that $0&lt;f(1)&lt;f(0)&lt;f(2)$. Prove that $f'$ has a solution on $(0,2)$.</p>
</blockquote>

<p>Here's a little crappy sketch: </p>

<p><img src=""http://i.imgur.com/KnZ4V1d.png"" alt=""enter image description here""></p>

<p>My attempt:</p>

<p>From $f(1)&lt;f(0)&lt;f(2)$ and continuity, there's a point $c\in (1,2)$ such that $f(c)=f(0)$, $f$ is continuous on $[0,c](\subseteq[0,2])$, differentiable on $(0,c)(\subseteq(0,2))$ so from Rolle's we know that there's some $k\in (0,c)$ such that $f'(k)=0$.</p>

<p>Is this alright? Is there another way to do this? Maybe with Lagrange's MVT?</p>

<p>Note: no integration or Taylor's.</p>
",calculus
"<p>Please check my setup for this very simple $LC$ circuit. But first assume the given differential equation is correct. There is no need to open a physics or design of electric circuits book as in its very essence this is just a problem in solving a differential equation with Laplace transforms. I just need my <strong>Setup</strong> checked which comes after the section entitled <strong>Given</strong>.</p>

<p><strong>Given</strong>:</p>

<p>All elements are in series: $L=1$ $henrys$, $C=1 farads$, $v(t)=1-e^{-t}$ $volts$ for $(0&lt;t&lt;\pi)$. The emf $v(t)=0$ for all $t$ outside the given interval. We have an initial condition of $i(0)=0$ for current and zero charge on the capacitor. Our goal is to find the current $i(t)$ in the circuit once the switch is closed.</p>

<p>The following differential equation models this physical problem...</p>

<p>$$Li'+\frac{1}{C}\int i(t)dt=v(t)$$</p>

<p>Because all units are compatible with this equation we can just plug in their values to simplify this equation giving us...</p>

<p>$$i'+\int i(t)dt=v(t)$$</p>

<p>That was the ""given."" The rest is just a math problem of solving a very simple differential equation with Laplace transforms. The next section is what I need checked.</p>

<p><strong>Setup</strong>: (Please check this for me)</p>

<p>First express $v(t)=1-e^{-t}$ in terms of unit steps for $(0&lt;t&lt;\pi)$...</p>

<p>$$v(t)=(1-e^{-t})u(t)-(1-e^{-t})u(t-\pi)$$</p>

<p>$$=(1-e^{-t})u(t)+e^{-t}u(t-\pi)-u(t-\pi)$$</p>

<p>an adjustment is needed for the exponential factor in the middle term as follows...</p>

<p>$$e^{-t}=e^{-(t-\pi+\pi)}=e^{-\pi}e^{-(t-\pi)}$$</p>

<p>our short lived forcing function now looks like this...</p>

<p>$$v(t)=(1-e^{-t})u(t)+e^{-\pi}e^{-(t-\pi)}u(t-\pi)-u(t-\pi)$$</p>

<p>the following is the equation that we need to take the Laplace transform of where capital $I=\mathcal{L}\{i(t)\}$...</p>

<p>$$i'+\int i(t)dt=(1-e^{-t})u(t)+e^{-\pi}e^{-(t-\pi)}u(t-\pi)-u(t-\pi)$$</p>

<p>$$sI+\frac{1}{s}I=\frac{1}{s}-\frac{1}{s+1}+e^{-\pi(s+1)}\frac{1}{s+1}-\frac{e^{-\pi s}}{s}$$</p>

<p>$$I(s^2+1)=1-\frac{s}{s+1}+e^{-\pi(s+1)}\frac{s}{s+1}-e^{-\pi s}$$</p>

<p><strong>My Question</strong>:</p>

<p>This is actually a request. I just need the setup for this problem carefully examined more for methodical errors than simply arithmetic errors. I am especially interested in if I made the correct shift adjustments and if my resulting Laplace transforms were accurately taken. Could I have set up my unit steps better?</p>
",calculus
"<p>At time 1:06 of <a href=""http://www.youtube.com/watch?v=aNReoaONJdg&amp;t=1m6s"" rel=""nofollow"">this video by minutephysics</a>, there is a geometric representation of the product rule: </p>

<p><img src=""http://i.stack.imgur.com/t05ha.png"" alt=""enter image description here""></p>

<p>However, I don't understand how the sums of the areas of those thin strips represent $d(u\cdot v)$. The only way I can see it is that $d(u\cdot v)$ is a small change in the area of the square, and those thin strips do represent that; however, I'm not sure if this is correct and if it is, how formal of a proof is this? Thanks!</p>
",calculus
"<p>I found this in the beginning of a calculus book, so it should be solved with very basic techniques, but I really don't know how.</p>
",calculus
"<p>Given the function $f(x,a)=e^{\frac{-x^2}{2a^2}}$, show that $\lim_{a\to 0^+}\frac{f(x,a)}{a}$ is finite?</p>

<p>I was trying with l'Hospital rule but still got an undetermined case. Is there anyone out there who can see some sort of transformation or has an idea for a different approach how to show the limit exist and is finite.</p>

<p>Any references or hints are highly appreciated. Thank you.</p>
",calculus
"<p><em><strong>Problem :</em></strong></p>

<p>Let $a,b\in \mathbb{Z}$ such that $a\neq 0,b\neq 0$ ; $\left | a \right |\leq 100,\left | b \right |\leq 100$. </p>

<blockquote>
  <p>Prove that:
   $$\left | a\sqrt{2}+b\sqrt{3} \right |&gt; \frac{1}{350}$$</p>
</blockquote>

<p>Thanks :)</p>

<p>P/s : I have no ideas about this problem ! :(</p>
",calculus
"<p>Let $a,b&gt;0$:<br>
$$\mathop {\lim }\limits_{n \to \infty } {({a^n} + {b^n})^{\frac{1}{n}}}$$</p>

<p>At first look, it seemed simple, yet I couldn't evaluate it.<br>
Maybe Squeeze Thm?  </p>
",calculus
"<p>I am obliged to prove that this sequence:</p>

<p>$\large {a_n=(1+\frac{1}{3})(1+\frac{1}{9})(1+\frac{1}{27})...(1+\frac{1}{3^n})}$</p>

<p>is convergent sequence.</p>

<p>I mean I was thinking about this and I know that $\large\lim_{n \to \infty} (1+\frac{1}{3^n})=1 $
From this I know that it will be probably convergent sequence but I know that it is not well written proof, and probably does not prove anything. I would be glad for any tips how to prove this. </p>
",calculus
"<p>So, I need to test the following series for convergence or divergence:</p>

<p>$$\sum_{n=1}^\infty (-1)^{n+1}{n\over {2^n}}$$</p>

<p>I know that when you use the Alternating Series Test, the series must satisfy two conditions. Which are:</p>

<ol>
<li>$$b_{n+1} \le b_n $$</li>
<li>$$\lim_{n\to \infty} b_n =0$$</li>
</ol>

<p>I having a hard time with the first condition because if I use 1  for n then I have a problem.
This is my work so far:</p>

<p>$$ {(n+1)\over 2^{(n+1)}} ? {n\over 2^n}$$
$$ {(1+1)\over 2^{(1+1)}} ? {1\over 2^1}$$
$$ {(2)\over 2^{(2)}} ? {1\over 2^1}$$
$$ {2\over 4} = {1\over 2}$$
They end up equaling each other.
On the other hand, if I plug in 2, I get something that does satisfy the first condition.$$ {(n+1)\over 2^{(n+1)}} ? {n\over 2^n}$$
$$ {(2+1)\over 2^{(2+1)}} ? {2\over 2^2}$$
$$ {(3)\over 2^{(3)}} ? {2\over 2^2}$$
$$ {3\over 8} ? {2\over 4}$$
$$ {3\over 8} \le {1\over 2}$$</p>

<p>So... what do I do?
Thanks in advance</p>
",calculus
"<p>I have searched for a similar question on stack exchange but could not find one.</p>

<p>The definite integral: $\large\int_0^1 \frac{x^4}{\sqrt{25-x^2}}$</p>

<p>I realize that I need to use $x = 5\sinθ$ in the bottom which will get me $5\cosθ$, but after that I am at a loss for what to do. </p>
",calculus
"<p>We know that $\lim_{\theta\to0}\frac{\sin\theta}{\theta}=1$ but $\theta$ must be in radians. My first question is what happen when $\theta$ is not in radian? Is it only because in the proof we use radian so $\theta$ must be in radians?</p>

<p>Then we also know that $\lim_{x\to\pm\infty}\frac{\sin x}{x}=0$. We can also prove it using sandwich theorem: $0\le|\frac{\sin x}{x}|\le|\frac{1}{x}|$, but here we are not using the fact that $x$ must be in radian. My next question is does that mean that $\lim_{x\to\pm\infty}\frac{\sin x}{x}=0$ also works even when $x$ is in degree?</p>

<p>If we see its pretty strange, when $x$ approaches $0$, there will be a limit only when $x$ is in radian, but when $x$ approaches neg/pos infinity, the limit exists regardless whether $x$ is in radian or degree.</p>

<p>Many thanks for the helps!</p>
",calculus
"<p>The flow of water in a pipe is faster in the middle than near the outside. 
For a 2 cm diameter pipe, given that the velocity of the water as a function of 
distance from the center of the pipe is
$$v(r) = \frac {1-r^2}{\mathrm{cm}^2} \cdot 1.48 \mathrm m/\mathrm s.$$</p>

<p>Determine the total flow in the pipe in liters/second. </p>

<p><img src=""http://i.imgur.com/hk7yChc.png"" alt=""Picture of situation""></p>

<p>What I've tried: Find total flow of water if uniform flow, i.e. if all water in pipe was flowing at a rate of 1.48 m/s. </p>

<p>$$(1.48 \mathrm m/\mathrm s) \pi (0.01\mathrm{cm})^2 \xrightarrow{\text{convert to liters/sec}} \approx 0.46 \text{liters}/\text{sec}.$$ </p>

<p>Then multiply that by $\frac 2 3$ (integrate $1-x^2$ from -1 to 1) = 0.309 liters/sec.</p>
",calculus
"<p>Can someone please explain why $(x^n)'=n\cdot x^{n-1}$?</p>

<p>Sorry for not writing it in math characters, I'm new here.</p>
",calculus
"<p>How would I go about proving this?
Would I try finding a value for $x$ that will make $f(x) = 0$?</p>
",calculus
"<p>Given $f'(0) = f''(0) = 1$, $f^{(12)}$ exists, and $g\colon x \mapsto f(x^{10})$. Find $g^{(11)}(0)$. </p>
",calculus
"<p>Determine the force that the moon exerts on the earth. Note that since the 
diameter of the earth, 12,742 km, is not insignificant compared to the distance to 
the moon, 384,400 km, the gravitational field of the moon is not uniform over the 
volume of the earth. Therefore, to get an accurate result you will need to integrate 
the gravitational field ($\vec{g} = -GM_{moon}\frac{\hat{R}}{R^{2}}$) times the density of the earth over the 
volume of the earth (you may assume the earth is spherical and of uniform 
density). It may be expedient to provide arguments why certain components of the 
force can be ignored during the integration. </p>

<p>Compare you result to the approximate solution obtained by assuming that both 
the moon and earth are point masses. </p>

<p>--</p>

<p>My thoughts: I'm assuming the only component of the force that matters is the force directed radially towards the moon (if that makes any sense). </p>
",calculus
"<p>What is the precise mathematical definition of $\lim_{x\to \infty} f(x) = −∞$? As x approaches infinity.</p>

<p>I know what the general meaning is, but I heard my teacher talk about some precise mathematical definition.</p>
",calculus
"<p>How to evaluate $$\frac{\Gamma\left(\frac{n}{2}\right)}{\Gamma\left(\frac{n-1}{2}\right)}$$, where n is integer > 0?</p>

<p>I know the gamma function formula will give</p>

<p>$$ \frac{(\frac{n-2}{2})!}{(\frac{n-3}{2})!}$$ How to simplify it?</p>
",calculus
"<p><a href=""http://kruel.co/math/chainrule.pdf"" rel=""nofollow"">http://kruel.co/math/chainrule.pdf</a></p>

<p>I found this proof of the chain rule, and it looks very thorough and legitimate. I have a few questions concerning it though. </p>

<p>Is this in fact a legitimate proof of the chain rule? As the author mentions at the end of the reading, a lot of proofs in calculus books do the chain rule wrong. </p>

<p>On page 2, the author concludes that $f(g(x) + [g'(x) + v]h) = f(g(x)) + [f'(g(x)) + w] \cdot [g'(x) + +v]h$. I have stared at this line for the longest time now and I am not understanding how the author gets this. </p>

<p>Is the flawed proof wrong since he is assuming $g(x + h) - g(x)$ is nonzero? </p>
",calculus
"<p>The coordinates of the point $M(x,y)$ on $y=e^{−{∣x∣}}$ so that the area formed by the coordinates axes and the tangent at $M$ is greatest is what?</p>

<p>I tried to plot the graph but after that I'm not being able to proceed.Please help<img src=""http://i.stack.imgur.com/elEaJ.gif"" alt=""![enter image description here"">]<a href=""http://i.stack.imgur.com/elEaJ.gif"" rel=""nofollow"">1</a></p>
",calculus
"<blockquote>
  <p>Evaluation of $$\int\frac{x^7+2}{\left(x^2+x+1\right)^2}dx$$</p>
</blockquote>

<p>$\bf{My\; Try::}$ Let $$\displaystyle \mathop{I = \int\frac{x^7+2}{(x^2+x+1)^2}}dx = \int\frac{(x^7-1)+3}{(x^2+x+1)^2}dx$$</p>

<p>$$\mathop{\displaystyle  = \int\frac{x^7-1}{(x^2+x+1)^2}}+\displaystyle \int\frac{3}{(x^2+x+1)^2}dx$$</p>

<p>Now Using the formula $$\bullet x^7-1 = (x-1)\cdot \left[x^6+x^5+x^4+x^3+x^2+x+1\right]$$</p>

<p>So $$\bullet \; (x^7-1) = (x-1)\left[(x^4+x)\cdot (x^2+x+1)+1\right]$$</p>

<p>So we get $$\displaystyle I = \int\frac{(x-1)\cdot (x^4+x)\cdot (x^2+x+1)}{(x^2+x+1)^2}dx+\frac{1}{2}\int\frac{2x-2}{(x^2+x+1)^2}+3\int\frac{1}{(x^2+x+1)^2}dx$$</p>

<p>$$\displaystyle I = \underbrace{\int\frac{(x-1)(x^4+x)}{x^2+x+1}dx}_{J}+\underbrace{\frac{1}{2}\int\frac{(2x+1)}{(x^2+x+1)^2}dx}_{K}+\underbrace{\frac{3}{2}\int\frac{1}{(x^2+x+1)^2}dx}_{L}$$</p>

<p>Now  $$\displaystyle J = \int\frac{(x-1)(x^4-x)+2x(x-1)}{(x^2+x+1)}dx = \int(x^3-2x^2+x)dx+\int\frac{2x^2-2x}{x^2+x+1}dx$$</p>

<p>Now we can solve the integral Using the formulae.</p>

<p>My question is can we solve it any other way, If yes then plz explain here</p>

<p>Thanks</p>
",calculus
"<p>Suppose $a+b+c+d=k$ how to find the extremum value of any symmetric expression in a,b,c,d?For example say $abc+bcd+cda+dab$.</p>

<p>I've noticed that it usually occurs when a=b=c=d.Why does this happen?</p>
",calculus
"<p>Please, how do I write the following  as a combination of a sum and a product: </p>

<p>$$ (c-a_1)(c-a_2)(c-a_3)b_1 + (c-a_2)(c-a_3)b_2+(c-a_3)b_3 ?$$
Also, how can I generalize it? </p>
",calculus
"<p>This post was edited following a comment that rightly stated that the original question was unsensible. The edited version follows.</p>

<p>Why does the equation in the second line implicitly define the function specification of $a(x)$ which minimizes the integral in the first line? What is the formal rule that is used here?</p>

<p>$$\int_{x_1}^{x_2}{f(a(x),x) g(x) dx}$$</p>

<p>$$a(x) = \underset{a^*}{argmin} f(a^*,x)$$</p>

<p>It is indeed, as remarked by  one of the commenters, the derrivation of the bayesian mean minimum squared error estimator where $x$ is the data, $a(x)$ the estimator, $g(x)$ the marginal probability density of the data and f(a(x),x) the conditional mean squared error of the estimator. $g(x) \geq 0, \forall x\in [x_1,x_2]$</p>
",calculus
"<p>I found the following answer on Math.SE:</p>

<p><a href=""http://math.stackexchange.com/questions/73922/fourier-transform-of-unit-step"">Fourier transform of unit step?</a></p>

<p>However, it is still not clear to me and maybe somebody could explain it clearer.</p>

<h1>Problem</h1>

<p>I have the following in my notes of a theoretical physics course:</p>

<p>$$
\hat{\Theta}(\omega) = \int_{-\infty}^\infty \Theta (t) e^{i\omega t} \mathrm{d} t 
= \lim_{\varepsilon \to 0} \int_0^\infty e^{i\omega t - \varepsilon t} \mathrm{d}t
= \pi \delta(\omega) + \mathrm{P} \frac{i}{\omega},
$$</p>

<p>where the $\mathrm{P}$ denotes the Cauchy's principal value. </p>

<h1>Question</h1>

<p>I understand why I get a delta function in this computation, but I have no idea why I have $\mathrm{P} \frac{i}{\omega}$ instead of just $\frac{i}{\omega}$ in the resulting expression.</p>
",calculus
"<p>I have problem because I can't do this exercise:</p>

<blockquote>
  <p>Prove that: $\forall x&gt;1$,
  $(1+\frac{1}{x})^x&lt;e&lt;(1+\frac{1}{x-1})^x$</p>
  
  <p>and:  $\forall (p,q)&gt;0$, $\left ( 1+\frac{p}{q} \right )^q\leq e^p \leq \left ( 1+\frac{p}{q} \right )^{p+q}$</p>
</blockquote>
",calculus
"<p>Is $X_n = 1+\frac12+\frac{1}{2^2}+\cdots+\frac{1}{2^n}; \forall n \ge 0$ bounded?</p>

<p>I have to find an upper bound for $X_n$ and i cant figure it out, a lower bound can be 0 or 1 but does it have an upper bound?</p>
",calculus
"<p>What tools would you recommend me for computing the limit below?</p>

<p>$$\lim_{n\to\infty} \frac{\sqrt{n}}{4^{n}}\sum_{k=1}^{n}\frac{\displaystyle \binom{2n-1}{n-k}}{(2k-1)^2+\pi^2}$$</p>

<p>As soon as any useful idea comes to mind I'll make the proper update with the new findings.</p>
",calculus
"<p>A piece of wire $10 m$ long is cut into two pieces. One piece is bent into a square and the other is bent into an equilateral triangle. Find the maximum and minimum possible area that can be enclosed. by the wire.</p>

<p><strong>EDIT:</strong> If $x$ is the length of wire used for the triangle and $10-x$ for the square, I get this formula for the area:
$$A=\frac{(10−x)^2}{16}+\frac{x^2\sqrt{3}}{36}$$
<strong>EDIT:</strong>
and the endpoints are at $x=0$ and $x=10$.</p>

<p>What do I do next?</p>

<p>Critical point at $A=\dfrac{40\sqrt{3}}{9+4\sqrt{3}}$</p>
",calculus
"<p>I have a hard time to understand how to do it.</p>

<p>I think what blocks me, is that the Rolle's theorem is usually applied to functions, yet here there aren't any. What should I do?</p>
",calculus
"<p>Is there a continuous function constructed by elementary functions, or by integral formula involved only elementary functions (like Gamma function) that grows faster than any $e^{e^{e...^x}}$ ($e$ appears $n$ times)?</p>

<p>I ask for the answer with a single formula. Gluing continuous function together is too trivial.</p>

<p>The function need not to be defined on whole $\mathbb{R}$, the domain $(a, \infty)$ is acceptable.</p>
",calculus
"<p>I'm trying to evaluate the limit as $N\to \infty.$</p>

<p>$$\frac{  \left(\dfrac{\sin \frac{1}{N}} {\frac{1}{N}}\right)^{N}   -1 }{\frac{1}{N}}.$$</p>

<p>Note first that, using L'Hôpital, one can easily show that the numerator goes to $0.$</p>

<p>Using the Taylor series expansion for $sin$, the value of the actual limit seems to be  $-\frac{1}{6}$. But I'm not fully sure how to justify the infinite series in the numerator is $-\frac{1}{6N}+O(\frac{1}{N^2})$. You could either justify that, if I was right, or may be use some other method to tell me what the limit is?</p>

<p>Many thanks in advance!</p>
",calculus
"<p>What is a solution to the following integral:</p>

<p>$$\int_0^\infty \, \frac{\cos{kt}}{\pi}\,\mathrm{d}k\,?$$</p>

<p>I have tried to evaluate this in the usual way:</p>

<p>$$\begin{align}\frac{1}{\pi}\int_0^\infty\,\cos{kt}\,\mathrm{d}k &amp;= \frac{1}{\pi t} \left[\sin{k t}\right]\bigg|_{k\rightarrow 0}^{k\rightarrow \infty} \\ &amp;=\frac{1}{\pi t} \left[\lim_{k\rightarrow \infty}\sin{k t} - \sin 0\right]  \\ &amp;=\frac{1}{\pi t} \lim_{k\rightarrow \infty}\sin{k t},\end{align}$$</p>

<p>but $\lim_{k\rightarrow \infty}\sin{k t}$ doesn't converge within infinity. </p>

<p>What is the trick here? Note that this is a homework question, so I don't need the complete solution, just directions where to start.</p>
",calculus
"<p>I want to prove that: 
$$\lim_{n\to \infty}n(t^{\frac{1}{n}}-1)=\log(t)$$
without using L'Hôpital. So,<br/></p>

<p>let $f_n(x)=x^{\frac{1}{n}-1}\;\ \forall x\ge 1$ and let $f(x)=x^{-1}\;\ \forall x\ge 1$, then:</p>

<p><hr/>
<strong><em>Lemma1:</em></strong> $\:\ (f_n)_{n\in \Bbb N}\;\ \text{converges uniformly to}\; f$
<br/> (I'm stuck here)</p>

<p>$$\text{Let}\;\ \epsilon &gt;0, \text{lets take}\;\ N=\frac{1}{\epsilon} (\text{figuring out...}),\; \text{then for}\;\ n&gt;N
\Rightarrow\ n&gt;\frac{1}{\epsilon}&gt;\frac{x-1}{x} \frac{1}{\epsilon}
\\
$$</p>

<p>$$\big|x^{\frac{1}{n}-1}-x^{-1}\big|=x^{\frac{1}{n}-1}-x^{-1}&lt;x^{\frac{1}{n}-1}-\frac{1}{n}$$</p>

<p>and here got stuck since the only thing I can do is make $x^{\frac{1}{n}-1}\le 1...$</p>

<hr/>

<p>Now, since $\int_1^t x^{\frac{1}{n}-1}dx=nt^{\frac{1}{n}}-n=n(t^{\frac{1}{n}}-1)$, by <strong><em>Lemma1</em></strong> we get that:
$$\lim_{n\to \infty}\int_1^t x^{\frac{1}{n}-1}dx=\int_1^t \lim_{n\to \infty} x^{\frac{1}{n}-1}dx$$</p>

<p>and, thus:
$$\lim_{n\to \infty}n(t^{\frac{1}{n}}-1)=\lim_{n\to \infty}\int_1^t x^{\frac{1}{n}-1}dx=\int_1^t \lim_{n\to \infty} x^{\frac{1}{n}-1}dx=\int_1^t x^{-1}dx=\int_1^t \frac{1}{x}dx=\log(t)$$</p>

<p>I will appreciate if you could let me know if I got it right, wrong (and why) or missed something.</p>
",calculus
"<p>I know the first derivative does not exist at a cusp.</p>

<p>Does this statement also hold for the second derivative?</p>
",calculus
"<p>Find the volume of the solid that remains after a circular hole of radius a is bored through the center of a solid sphere of radius r > a. So in the picture it looks like a circle with a cylinder cut out of the middle. I am not even sure where to start with this. I know this has to do with integrals but I am not sure how to set this up to even get an integral. Any help would be greatly appreciated.</p>
",calculus
"<p>How can I determine whether the following improper integrals converge or diverge?</p>

<p>1) $\int_0^\pi \frac{x}{\sin(x)}dx$</p>

<p>2) $\int_0^{\infty} \frac{e^{\cos(x)}}{x}dx$</p>

<p>3) $\int_0^1(\log x)^{\frac{1}{3}}dx$</p>

<p>I have heard of the comparison test, but I am not sure how, if possible, to use it here.</p>
",calculus
"<p>Find the coordinates of the point on the curve $f(x)=3x^2-4x$ where the tangent is parallel to the line $y=8x$.</p>
",calculus
"<p>How would you prove that $x^2$ has exactly 1 root using the rolle's theorem?</p>

<p>If there's f(a)>0 and f(b)=0 then f(a) does not equal f(b) does that proof that there's one root?</p>
",calculus
"<p>I have yet another derivative I need help with. I have to differentiate :</p>

<p>$$\sqrt[\uproot{3}{\Large 5}]{\frac{t^3 + 1}{t + 1}}$$</p>

<p>with respect to $t$. </p>

<p>I had two thoughts about this, use the chain rule then the quotient rule and multiply out, but then I am left with a mess of:</p>

<p>$$\left(\frac{t^3+1}{t+1}\right)^{-4/5}\cdot\frac{0.6t^3+0.6t^2-0.2t^4+0.2t}{(t+1)^2}$$</p>

<p>This is turning into a real mess and the answer I should get is:</p>

<p>$$\frac{2t-1}{5(t^2-t+1)^{4/5}}$$</p>

<p>Am I going the correct way about this or should I try a different route?</p>

<p>Thanks</p>
",calculus
"<p>Let $f$ be a continuous function on $[a,b]$ such that $f(x) \geq 0 $
for every $x\in [a,b]$. Suppose $\int_a^b f = 0$ and show that $f (x) = 0$ for every $x\in [a,b]$.
 obv this is monotonic ( non-decreasing definitionaly) i would liek to show monotonic non increaseing.</p>

<p>We know that $\int_a^b f = 0$ 
i have a theorem that says S(P) = s(P) = $\sigma$ over a Partition P on [a,b] or my integral does not exists. </p>

<p>So we have $(S(P) = \sigma) \leq 0$  is this enough to make a statement that my function is monotonic non increaseing? </p>

<p>if so how can we combine monotonic non-increase and monotonic non-decreasing to show that $f(x) = 0, \forall x \in [a,b]$?</p>

<p>EDIT:
my only other trick / idea i can come up with is that $\int_a^b |f| = 0$ </p>
",calculus
"<p>Another simple question that I can't work out today, yet I would work it out two weeks ago!</p>

<p>I need to find the 1st derivative of $$\frac{2x}{\sqrt{x^2 + 1}}$$.</p>

<p>So I use the Quotient rule and I get: $$\frac{(x^2 + 1)^.5 (2) - (2x)(0.5x^2 + 0.5)^-5}{x^2+1}$$</p>

<p>Am I heading in the correct direction and do I just need to multiply and try to get rid of the exponents somehow?</p>

<p>Thanks</p>
",calculus
"<p>I need urgent help on this question. I have no clue how to solve it as it's very complicated to me. The question is the following:</p>

<p>Given
$y=\frac{2xy}{x^2 + y}$
find $\frac{dy}{dx}$.</p>
",calculus
"<blockquote>
  <p>For $ x^3+y^2= 2x^2y+2 $ Find $\frac{dy}{dx}$ and the slope of the tangent to the curve at $(-1,-1)$</p>
</blockquote>

<p>Having a little problem finding the derivative in respect to $\frac{dy}{dx}$ for $2x^2y+2.$
To my understandings I need to use implicit differentiation; thus, wherever there is a $y$, after I take the derivative of $y$, I need to attach $\frac{dy}{dx}$. However, how does one do that for $2x^2y+2$?  </p>
",calculus
"<p>I understand that we are finding the area of a curve given by some function f(x) over the area of another curve C.  (I've also successfully plugged and chugged my way through my homework, without understanding what I was doing)</p>

<p>These are some of the questions that I am a little fuzzy about:<br>
 1.  Could I use a line integral in only 2 dimensions? (for example: to find the area between the curves y=x^2 and y=2x from x is in [0,2]?  If so, how?)<br>
 2.  Moving to more dimensions, the formula my book gives me is:</p>

<p>&int;<sub>c</sub>F <sup><strong>.</strong></sup> Vds =&int;<sub>a</sub><sup>b</sup>  F(a(t)) <sup><strong>.</strong></sup>
    a'(t)dt</p>

<p>Where C is a smooth oriented curve, whose orientation is given by V and F is a continuous vector field. (I understand individually what each of these terms mean, but am having trouble understanding what this formula is finding.</p>

<p><strong>What, geometrically, is this formula finding?</strong>  </p>
",calculus
"<p>Show that </p>

<p>$$\frac{1}{z^2}=1+\sum_{n=1}^\infty (n+1)(z+1)^n$$ when $|z+1|&lt;1$</p>

<p>I'm having problems to resolve this type of exercise since my book has virtually no exercises of this type, these expressions are based on Maclaurin series?</p>
",calculus
"<p>Can someone give a simple explanation as to why the <a href=""http://en.wikipedia.org/wiki/Harmonic_series_(mathematics)""><em>harmonic series</em></a> </p>

<blockquote>
  <p>$$\sum_{n=1}^\infty\frac1n=\frac 1 1 + \frac 12 + \frac 13 + \cdots $$</p>
</blockquote>

<p>doesn't converge, on the other hand it grows very slowly? </p>

<p>I'd prefer an easily comprehensible explanation rather than a rigorous proof regularly found in undergraduate textbooks.</p>
",calculus
"<p>When I tried to approximate $$\int_{0}^{1} (1-x^7)^{1/5}-(1-x^5)^{1/7}\ dx$$ I kept getting answers that were really close to $0$, so I think it might be true. But why? When I <a href=""http://integrals.wolfram.com/index.jsp?expr=%281-x%5E7%29%5E%281%2F5%29+-+%281-x%5E5%29%5E%281%2F7%29&amp;random=false"" rel=""nofollow"">ask Mathematica</a>, I get a bunch of symbols I don't understand! </p>
",calculus
"<p><strong>I know this question was answered by using another theorem <a href=""http://math.stackexchange.com/questions/613900/assuming-forall-x-in-0-1fx-x-prove-forall-x-in-0-1fx-x"">here</a> but I wish I could get comments on my way of trying to prove it.</strong></p>

<p>We were asked to prove that for a function $f(x) &gt; x $ which is continuous in $[0,1]$ there exists an $\epsilon$ such that $f(x) &gt; x + \epsilon$ for every $x \in [0,1]$.</p>

<p>I tried a different method then suggested at the link above and would like to know if it's correct and if not what's wrong / missing.</p>

<p>I'll assume the opposite that $\forall \epsilon&gt;0 , f(x) - x &lt; \epsilon$. Also I know that $f(x) - x &gt; 0$ from $f(x) &gt; 0$ so I can deduce that $|f(x)-x| &lt; \epsilon$ that would mean that for any $x \in [0,1]$  the limit of $f$ at that point is $x$, since $f$ is continuous I also know that the limit of $f$ at any $x \in [0,1]$ is $f(x)$ so $f(x)= x$ which is a contradiction to $f(x) &gt; x$ hence there must be at least one $\epsilon$ for which $f(x) - x &lt; \epsilon$</p>

<p>Thanks for any help you can provide</p>
",calculus
"<blockquote>
  <p>Evaluate $\sum^\infty_{n=1} \frac{1}{n^4} $using Parseval's theorem (Fourier series).</p>
</blockquote>

<p>I have , somehow, to find the sum of $\sum_{n=1}^\infty \frac{1}{n^4}$ using Parseval's theorem.</p>

<p>I tried some things that didn't work so I won't post them.</p>

<p>Can you please explain me how do I find the sum of this series using Parseval's identity?</p>

<p>Thanks</p>
",calculus
"<p>I have no idea how to convert this to an integral(which has to be done as the answer is $\frac{\pi}{4}$)   I assume it may be equivalent to arctan(1).</p>
",calculus
"<p>How can I find this limit:<br>
$\displaystyle\lim_{x\rightarrow\infty} \left(\frac{x+\ln x}{x-\ln x}\right)^{\frac{x}{\ln x}}$</p>
",calculus
"<blockquote>
  <p>Let $\{x_n\}$, a sequence such that:<br>
  $\forall n \in \mathbb{N}: \left| {x_{n+2}-x_n} \right| &lt; {1 \over 2^n}; \quad  
\lim_{n \to \infty } ({x_{n + 1}} - {x_n}) = 0$</p>
</blockquote>

<p>I translated the above to:<br>
$$\begin{array}{l}
 {x_n} - \frac{1}{{{2^n}}} &lt; {x_{n + 2}} &lt; {x_n} + \frac{1}{{{2^n}}} \\ 
 {x_n} - \varepsilon  &lt; {x_{n + 1}} &lt; {x_n} + \varepsilon  \\ 
 \end{array}$$</p>

<p>But at this point I'm kinda stuck. I guess I need to ""glue"" the two statements somehow. I also considered, treating $X_{odd}$ and $X_{even}$. Would that be helpful?</p>
",calculus
"<p>If U has a $\chi^2$ distribution with v df, find E(U) and V(U).</p>

<p>By definition, $E(U)
=\int^{\infty}_{0} u\frac{1}{\gamma(\frac{v}{2})2^\frac{v}{2}}u^{\frac{v}{2}-1} e^\frac{-u}{2}\,du 
=\int^{\infty}_{0} \frac{1}{\gamma(\frac{v}{2})2^\frac{v}{2}}u^\frac{v}{2} e^\frac{-u}{2}\,du$.</p>

<p>How do I integrate this?</p>

<p>Note: This isn't a homework problem.</p>
",calculus
"<p>Let $m,\, k$ be fixed positive integers. Evaluate
$$
\lim_{n \to \infty}\left\{%
\left[\sum_{r = 1}^{k}{\left(n + r\right)^{m} \over n^{m - 1}}\right] -kn
\right\}.
$$</p>
",calculus
"<p>Let $f$ be a holomorphic function on the unit disk $D$. Suppose for any $z\in D$, $f'(z)\neq 0$. Then does $f$ have to be a conformal map from $D$ to $f(D)$?</p>
",calculus
"<p>I got this question:</p>

<p>Prove or disprove the following:</p>

<p>If the series $\sum_{k=1}^{\infty} a_k3^k$ diverges, Must the series $\sum_{k=1}^{\infty} a_k4^k$ diverge too?</p>

<p>I tried to find a couple of counterexamples but failed, I tried $a_k=1/k!$, $a_k=1/3^k$ and many more but wasn't able to find a counterexample.
Then I tried to prove this statement but I wasn't able to proceed too.</p>

<p>Thanks for any hints.</p>
",calculus
"<p>Let $g:R \rightarrow R$ be continuous and $ 2\pi$-periodic, let $m \in N$. How many solution in  class of $m$-times continuously differentiable $2\pi$-periodic functions has equation $$f^{(m)}=g ?$$</p>

<p>Edit. Obviously, if $f$ is a solution in this class and $C$ is a constant then $f+C$ is also a solution. Are there another solutions? </p>
",calculus
"<p>This question is related to this recent <a href=""http://math.stackexchange.com/questions/136067/prove-int-ab-fxdx-leq-frace2l-beta-12l-alpha-int-cd-fxdx"">other question</a>, where two intervals $[a,b] $ and $[c,d]$ were considered. Here I ask about a simpler version with just
one interval $[a,b]$.</p>

<p>Consider the following optimization problem : $f$ is a positive continuous function $[a,b] \to ]0,+\infty[$, satisfying the Lipschitz condition $|f(x)-f(y)| \leq L|x-y|$ for any $x,y \in [a,b]$. Given the constraint $\int_{a}^{b}\frac{dt}{f(t)}=\alpha$ (where $\alpha$ is a positive constant), the problem is then to find the maximum (or supremum) value $M$ of $\int_{a}^{b}f(t)dt$ under this constraint, and find the functions for which this maximum is attained, if any.</p>

<p>Although my evidence for this is still incomplete, I believe the maximum is attained when $f$ is a decreasing affine function with coefficient $-L$. In this case,</p>

<p>$$
f(t)=L\bigg(b-t+\frac{b-a}{e^{L\alpha}-1}\bigg), \
\int_a^{b} f(t)dt= L(b-a)^2\bigg(\frac{1}{2}+\frac{1}{e^{L\alpha}-1}\bigg)
$$</p>

<p>By the Stone-Weierstrass theorem, when looking for the maximum we may assume that $f$ is differentiable (we may even assume that $f$ is a polynomial). In this case, one may apply the methods explained in the abovementioned post : $|f'| \leq L$, so $|(f^2)'| =|2ff'| \leq 2L|f|$ and hence $f^2(x) \leq f^2(a)+2LF(x)$, where we put $F(x)=\int_a^x f(t)dt$. So $f(x)=\frac{f^2(x)}{f(x)} \leq \frac{ f^2(a)+2LF(x)}{f(x)}$. Putting $G(x)=f^2(a)+2LF(x)$, we deduce $\frac{G'(x)}{G(x)} \leq \frac{2L}{f(x)}$. integrating between $a$ and $b$, we obtain
${\sf ln}\big(\frac{G(b)}{G(a)}\big) \leq 2L\alpha$. Now $G(a)=f^2(a)$ and
$G(b)=f^2(a)+2L\int_a^b f(t)dt$, so that one finally obtains</p>

<p>$$
\int_a^b f(t)dt \leq \frac{e^{2L\alpha}-1}{2L}f^2(a)
$$</p>

<p>Any feedback appreciated on the following questions : what is the maximum/supremum, which functions attain equality.</p>
",calculus
"<p>This is the problem that I am having trouble with for my test review. I am completely blank and don't know what it is asking for. Can you please guide me step by step. For example: Why did constant $k$ appear all of a sudden?</p>

<blockquote>
  <p>$a$ varies directly with $b$</p>
  
  <p>Which of these equations could represent the relationship between $a$ and $b$?</p>
  
  <p>$a$ varies directly with $b$ if $a=k\cdot b$ for some constant $k$</p>
  
  <p>If you divide each side of this expression by $b$, you get $\displaystyle\frac ab=k$ for some constant $k$.</p>
  
  <p>$\displaystyle\frac ab=\frac12$ fits this pattern, with $k=\displaystyle\frac12$</p>
  
  <hr>
  
  <ul>
  <li>$a=\frac12-b$</li>
  <li>$\frac12\cdot\frac1a=b$</li>
  <li>$2\cdot\frac1a=b$</li>
  <li>$\frac12\cdot a=\frac1b$</li>
  <li>$\frac ab=\frac12$</li>
  </ul>
</blockquote>
",calculus
"<p>Show that $\ln\Big(|\frac{1+x}{1-x}|\Big)=2\sum_{n=0}^{\infty}\frac{x^{2n+1}}{2n+1},$ for $|x|&lt;1$. The previous excercise (which was within my limited reach) was to show that 
$\frac{1}{1-x^2}=\sum_{n=0}^{\infty}x^{2n},$ for $|x|&lt;1$. I suspect there is a (not overly subtle) connection here but, needless to say,  I can't see it. I don't know why the absolute value signs are included, but it might be because the solution includes integrating some power series. The excercise is contained in a chapter on derivation and integration of (convergent) power series; one is also assumed to be familiar with multiplication of power series. </p>

<p>Very thankful for any help.</p>
",calculus
"<p>Let  $x_1$, $x_2$, and $x_3$ be the roots of the equation
$$4x^3-6x^2+7x-8=0.$$
Find this value:
$$(x_1^2+x_1x_2+x_2^2)(x_2^2+x_2x_3+x_3^3)(x_3^2+x_3x_1+x_1^2)$$</p>

<p>My try:
$$x_1+x_2+x_3=\frac 3 2$$
$$x_1 x_2+x_2 x_3+x_1 x_3=\frac 7 4$$
$$x_1 x_2 x_3=2$$</p>

<p>Now I have
$$x_1^2+x_1x_2+x_2^2=(x_1+x_2)^2-x_1x_2=(\frac 3 2-x_3)^2-\frac 2 {x_3}.$$</p>

<p>But this is very ugly, and I think this problem should have a cleaner solution. Thanks.</p>
",calculus
"<p>I need to find the limit
$$
\displaystyle \lim_{n\rightarrow \infty}\left(\sqrt{n^2+n+1}-\big\lfloor  \sqrt{n^2+n+1} \big\rfloor \right),$$ where $n\in \mathbb{N}$.</p>

<p><strong>My attempt</strong>. As $\displaystyle \lim_{n\rightarrow \infty} (n^2+n+1)\approx n^2$, then $\displaystyle \lim_{n\rightarrow \infty}\sqrt{n^2+n+1}\approx \displaystyle \lim_{n\rightarrow \infty}\sqrt{n^2} = n$.</p>

<p>So $$\displaystyle \lim_{n\rightarrow \infty}\left(\sqrt{n^2+n+1}-n\right) = \displaystyle \lim_{n\rightarrow \infty}\frac{\left(\sqrt{n^2+n+1}-n\right).\left(\sqrt{n^2+n+1}+n\right)}{\left(\sqrt{n^2+n+1}+n\right)}.$$</p>

<p>So $$\displaystyle \lim_{n\rightarrow \infty}\frac{n\cdot\left(1+\frac{1}{n}\right)}{n \left(\sqrt{1+\frac{1}{n}+\frac{1}{n^2}}+1\right)} = \frac{1}{2}.$$</p>

<p>My Question is , Is my Process is Right OR Not ,OR Is there is any error .</p>

<p>If Not Then How can I Solve it</p>

<p>Help Required</p>

<p>Thanks</p>
",calculus
"<p><img src=""http://i.stack.imgur.com/vz1yh.png"" alt=""enter image description here""></p>

<p>Hi! I am currently working on some calc2 online homework problems and I am having difficulty with this problem. I was trying to use the polar coordinates (d,a)with the equation of the line thus being r=d*sec(theta-a). I tried solving for d by setting d equal to sqrt((-19)^2+(-6)^2) which then came out to be 137621/6907. I then tried solving for a by setting it equal to arctan(-6/-19) which came out to be 17.52556837. I then plugged everything into the equation of the line which i had as r=d*sec(theta-a) to get r= (137621/6907)sec(theta-17.52556837). Clearly my answer is wrong but I do not know why. If someone can help me solve this problem I would greatly appreciate it. </p>
",calculus
"<p>I'm learning single variable calculus right now and at current about integration with partial fraction. I'm stuck in a problem from few hours given in my book. The question is to integrate $$\frac{x^2 + 1}{x^2-5x+6}.$$</p>

<p>I know it is improper rational function and to make it proper rational fraction we have to divide
$$\frac{x^2 + 1}{x^2-5x+6}$$
I'm trying from sometime but couldn't find the right solution. 
<br> Please help! Thank you in advance.  </p>
",calculus
"<p>Suppose that the polynomial function $f(x)=x^n+a_{n-1}x^{n-1}+\cdots +a_0$ has $k_1$ local maximum points and $k_2$ local minimum points. Show that $k_2=k_1+1$ if $n$ is even, and $k_2=k_1$ if $n$ is odd.</p>

<p>Solution to the problem:</p>

<p>Let $l$=$k_1+k_2$ and let $a_l\lt a_{l-1}\lt \cdots a_1$ be all the local maximum and minimum points. <strong>On the intervals between these points $f$ is either decreasing or increasing.</strong> Since $\lim_{x\to \infty}f(x)=\infty$, the function $f$ must be increasing on $(a_1,\infty)$. Thus $a_1$ must be a local minimum point. Consequently, $f$ must be decreasing on $(a_2,a_1)$, which shows that $a_2$ must be a local maximum point. Continuing in this way we see that $a_k$ is a local minimum point if $k$ is odd and a local maximum point if $k$ is even. </p>

<p>Now if $n$ is even, then $a_l$ must be a local minimum point, since $\lim_{x\to -\infty}f(x)=\infty$. Thus $l$ must be odd, so $a_1,a_3,\dots,a_l$ are the local minimum points, and $a_2,\dots, a_{l-1}$ are the local maximum points. Consequently $k_2=k_1+1.$ If $n$ is odd, then $a_l$ must be a local maximum point, since $\lim_{x\to -\infty}f(x)=-\infty$. The same sort of reasoning then shows that $k_1=k_2$. QED.</p>

<p>I don't know how to prove the bold part. It's intuitively clear from the graph of a polynomial, however, I can't give a proof to this. The only information is $f'$ is zero at each $a_i$ and both $f$ and $f'$ are polynomials. I need to show that $f'$ is either positive or negative on these intervals. How can I show this? I would greatly appreciate any solutions, hints or suggestions.</p>
",calculus
"<p>use the formula $P_n(x) = \dfrac{1}{2^nn!}\dfrac{d^n}{dx^n}((x^2-1)^n)$ to show that $P_{2n}(0) = \dfrac{(-1)^n(2n)!}{4^n(n!)^2}$ and odd terms are 0.</p>

<p>I first subbed in 2n to the formula and got</p>

<p>$P_{2n}(x) = \dfrac{1}{4^n(2n)!} \dfrac{d^{2n}}{dx^{2n}}((x^2-1)^{2n})$ but I am not sure how to deal with differentiating that term $2n$ times. I have tried to use the binomial theorem but to no avail.</p>
",calculus
"<p>I was trying to solve this limit:</p>

<p>$\lim_\limits{n\to \infty} \binom {3n}{n}^{1/n} $</p>

<p>I solved it with Cesaro theorem:</p>

<p>$\lim_\limits{n\to \infty} \binom {3n}{n}^{1/n} $= $\lim_\limits{n\to \infty} \frac{((3(n+1))!}{(2(n+1))(n+1)!}\frac{2n!n!}{3n!}= \frac{27}{4}$</p>

<p>But when I have tried to use Stirling I arrived to the form $\lim_\limits{n\to\infty}(\frac{27}{4}(\frac{3}{4\pi n})^{1/2})^{1/n}=1$</p>

<p>Surely I've made a mistake. In order to arrive to the form that I have writed before I wrote the limit as $\lim\limits_{n \to \infty}(\frac{(3n)!}{n!(2n)!})$ and then I sobstituted to all the terms the Stirling approximation.</p>
",calculus
"<p>I'm doing a calculus project where we have to make a model of some graph rotated about the y axis. I am doing a fish bowl and I have most of it understood and ready. The only thing I'm not sure of is what the equation of the semicircle is if its center is at (0,2). I added a picture to help illustrate it. Thank you for your help. <a href=""http://i.stack.imgur.com/YQidm.jpg"" rel=""nofollow"">Image of semicircle</a></p>
",calculus
"<p>Showing the set $A = \{ x \in l_1 : |x_n| \leq 1/n^2  ,\forall n \}$ is closed. I had to show it is compact, and I am done showing it is relatively compact, but now I am stuck showing it is closed.</p>

<p>$l_1$ is the space of finite sequences $x = (x_1,x_2,...)$ with the norm $\|x\|_1 = \sum_k^\infty |x_k| &lt; \infty$ i.e. the set $A \subset l_1$ with sequences where each component of the sequence is bounded by $1/n^2$ for every component.</p>

<p>I done a lot of work to show it is relatively compact, so I feel as though showing it is closed should be simple - but I can't make any progress. </p>

<p>Any help please</p>
",calculus
"<p>I want to find numerically (the functional expression might become too complicated) the derivative of a complex function (to use it in a Newton-algorithm). Can I simply do something like
$$ \frac {df}{dz} = \lim_{h \to 0} {f(z+h)-f(z))\over h} + {f(z+ih)-f(z))\over h} 
$$
? Or how do I have to do this?</p>

<p><hr>
[update]           </p>

<p>By manual tests with $f(z) = \log(z)$, then $f'(z)=\frac1z$ and some examples it seems that I must do
$$ \frac {df}{dz} = \lim_{h \to 0} {{f(z+h)-f(z))\over h} + {f(z+ih)-f(z))\over ih} \over 2 }
$$
Is that formally correct?</p>
",calculus
"<p>Let $|x|&lt;1$. Define $R_n(x):=\int_{0}^{x}\frac{(x-t)^{n-1}}{(1-t)^n}dt$. How do we prove that $\lim_{n\to \infty}R_n(x)=0$? This is actually the integral remainder of the Taylor expansion of the function $f(x)=-log(1-x)$. Once I show that $R_{n-1}(x)\to 0$, then I can say that $f(x)=\sum_{k=1}^{\infty}\frac{x^k}{k}$. </p>

<p>By the way, I am using the following formula: $$f(x)=\sum_{k=0}^{n-1}\frac{f^{(k)}(0)}{k!} x^k+ R_{n-1}(x)$$ where $R_{n-1}(x)=\frac{1}{(n-1)!}\int_{0}^{x}(x-t)^{n-1} f^{(n)}(t)dt$</p>
",calculus
"<p>If $\lim h\to 0$, when finding the derivative of the function, why do you plug in the limit that is being approached. Like why would you plug in $0$ in the function $4x+2h$ (which is the derivative of $\frac{2 (x+h)^2-2x^2}{h}$</p>
",calculus
"<p>Be the equation $$\frac{dx}{dt} = a(t)*x^2+b(t)*x+c(t)$$ where $$a,b,c : I =[α,β] ⊂ R → R $$ are continuous function.</p>

<p>a) How can I found the solutions to the equation knowing a particular one $ρ_0$ ?</p>

<p>b) If $a(t)= 1, b(t)= -2e^{2t}, c(t)=e^{4t}+2e^{2t}$ and the equation admits the particular solution $ρ_0(t)= αe^2t$ what is the general solution to the equation?</p>

<p>Any help is appreciated. Thank you!</p>
",calculus
"<p>So you have the integral:
$$\int\frac{3v}{200 - 4v} dv$$
I tried to do $u$-substitution at first with $u = 200 - 4v$, but I could not get the correct answer which is:
$$-\frac{3}{4}v - \frac{150}{4}ln(200-4v) + C$$
In the worked solution, they did not use a $u$-substitution. The first integral becomes:
$$\int -\frac{3}{4} + \frac{150}{200 - 4v} dv$$
And I cannot see what technique they used to get that.  I worked out that if you actually add the 2 fractions you end up back at the first integral, but I do not see how they worked out that is the way it should be re-arranged.  I also don't understand why my $u$-substitution didn't work.  Should a $u$-substitution have worked?  I'm still trying to get my head around this integrating of fractions.</p>
",calculus
"<p>$\frac{2}{(x^2+3)^3}$.</p>

<p>I have ${dy}/{dx}$ x 2 x ${x^2+3^3}$ - 2 x ${dy}/{dx}$  x ${x^2+3^3}$ over $({x^2+3)^6}$</p>

<p>And then simplifying to $-12x^5 + 36x^2$  over $({x^2+3)^6}$</p>

<p>I'm not sure if this is right. </p>
",calculus
"<p>So the equation looks a bit complicated, but the derivation itself should be straightforward. But I'm evidently getting mixed up somewhere, because my answer is wrong.
$$ \frac{\partial ({-k_{b}T \ln(2\cosh(\frac{\epsilon}{k_{b}T}})))}{\partial T} $$
(where V is kept constant, hence the partial derivative)</p>

<p>So according to the product rule:
$$ {-k_b T} \frac{\partial ({\ln(2\cosh(\frac{\epsilon}{k_{b}T}})))}{\partial T} + {-k_b} ({\ln(2\cosh(\frac{\epsilon}{k_{b}T}}))) $$</p>

<p>Then the chain rule:
$$\frac{\partial ({\ln(2\cosh(\frac{\epsilon}{k_{b}T}})))}{\partial T} 
= \frac{\partial {(2\cosh(\frac{\epsilon}{k_{b}T}}))}{\partial T} \frac {1} {(2\cosh(\frac{\epsilon}{k_{b}T}))}
= \frac{\partial {(\frac{\epsilon}{k_{b}T}})}{\partial T} 2\sinh(\frac{\epsilon}{k_b T}) \frac {1} {(2\cosh(\frac{\epsilon}{k_{b}T}))}
= \frac {\epsilon} {k_b} 2\sinh(\frac{\epsilon}{k_b T}) \frac {1} {(2\cosh(\frac{\epsilon}{k_{b}T}))}
= \frac {\epsilon} {k_b} \tanh(\frac{\epsilon}{k_b T})$$  </p>

<p>So the final answer I'm getting is: 
$$ {-k_b T} \frac {\epsilon} {k_b} \tanh(\frac{\epsilon}{k_b T}) + {-k_b} ({\ln(2\cosh(\frac{\epsilon}{k_{b}T}})))
=  -{\epsilon}T \tanh(\frac{\epsilon}{k_b T})-{k_b} {\ln(2\cosh(\frac{\epsilon}{k_{b}T}})) $$</p>

<p>But apparently this is incorrect, and the correct answer is: 
$$ \frac {\epsilon}{T} \tanh(\frac{\epsilon}{k_b T})-{k_b} {\ln(2\cosh(\frac{\epsilon}{k_{b}T}})) $$</p>

<p>I'm probably making a stupid mistake somewhere, but I can't seem to spot it.</p>
",calculus
"<p>I'm not sure where to even begin with this...</p>

<p>Let $f(x) = \sin x$. The polynomial $p(x)= Ax^3 + Bx^2 + Cx +D$ is a function such that $p^{k} (0) = f^{k} (0)$ for $k=0,1,2,3$</p>

<p>a) Determine $p(x)$ by computing the values of $A,B,C$ and $D$ </p>
",calculus
"<p>I am reading Chapter 5 of <em>Spivaks</em>. One of his examples is the function $f$ defined as 0 if $x$ is irrational and between 0 and 1,  or $\frac{1}{q}$ if $\frac{p}{q}$ is irreducible and between $0 &lt; x &lt; 1$. Here is a copy of his proof from a previous question which I looked at before asking this question: Pedro Tamaroff (<a href=""http://math.stackexchange.com/users/23350/pedro-tamaroff"">http://math.stackexchange.com/users/23350/pedro-tamaroff</a>), What exactly is going on when we're finding a limit?, URL (version: 2013-01-10): <a href=""http://math.stackexchange.com/q/195969"">http://math.stackexchange.com/q/195969</a>. One of the things that I found confusing about the proof <em>Spivak</em> gave was how he was able to conclude that the points at which the limit could be false are finite. Spivak states, ""Let $n$ be a natural number so large that $\frac{1}{n} \leq e$. Notice that the only numbers $x$ for which the limit could be false are $1/2;1/3;2/3;1/4;3/4;...;1/n,...\frac{n-1}{n}$"" </p>

<p>Let's say the epsilon I choose is $1/10$, and my $n = 11$ (both of which satisfy his statement), then the numbers I would have to check would be: $1/2;...;1/11...10/11$. In my mind, however, there are more numbers then the ones stated by Spivak that can be used to show that the limit is false such as $1/12,...11/12;1/13...12/13$, and I don't understand why this is not the case. I recognize the other parts of the proof, except for this.Furthermore, in an example prior to this one, Spivak shows the function $f(x) = 1$ if $x$ is rational and 0 if $x$ is irrational, and states that the limit can not be found which I think I understand, but this ""new"" function has the limit of 0 at all a from $(0,1)$. I think this has to do with the $\frac{1}{q}$ aspect of this ""new"" function, but I don't really understand how or why. Any help from just helping me gain an intuition for the two functions, to links to other questions would be appreciated. Thank you.   </p>
",calculus
"<p>(a) Find the work required to pump the water out of the spout. (Use 9.8$ \frac{m}{s^2}$ for $g$. Use 1000 $\frac{kg}{m^3}$ as the weight density of water. Assume that $a$ = 1.)</p>

<p>and </p>

<p>(b)</p>

<p>(b) Suppose that the pump breaks down after $4.7 × 10^5$J of work has been done. What is the depth of the water remaining in the tank? (Round your answer to the nearest tenth.)<a href=""http://i.stack.imgur.com/vUOpw.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/vUOpw.jpg"" alt=""enter image description here""></a></p>

<p>Here is my work. But the program says it is wrong. <a href=""http://i.stack.imgur.com/9EDA9.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/9EDA9.jpg"" alt=""enter image description here""></a></p>
",calculus
"<p>Determine the equations of the tangent lines to the graph of $f(x)=3x(5x^2+1)$
that are parallel to the line $y=8x+9.$</p>

<p>I really don't know how to do this question; please help me out.</p>
",calculus
"<p>How do you sovle the equation: $\int_{-3}^{2} ( e^{-t+1} + sin (\frac{2\pi}{3}t) )  \delta(t- \frac{3}{2}) dt$</p>

<p>Because of the $\delta(t- \frac{3}{2})$ this is only non-zero at $t=\frac{3}{2}$</p>

<p>But I don't get why I can't do this: $\int_{-3}^{2} ( e^{-\frac{3}{2}+1} + sin (\frac{2\pi}{3} \times \frac{3}{2}) )  dt$</p>

<p>Why you try to solve the indefinite integral, it supposes to be:
$\int( e^{-t+1} + sin (\frac{2\pi}{3}t) ) \delta(t- \frac{3}{2}) dt = \frac{u(2t-3)-1}{\sqrt{e}} + C $. In which $u$ is the unit step function.
But I don't know how to solve this indefinite integral step-by-step.</p>
",calculus
"<p>Find the laplace transform of</p>

<p>$f(t) = t^2cos^2(t)$.</p>

<p>I'm a bit stuck on this one. I know how to do this function if both components aren't squared due to using the laplace transform table.</p>

<p>Could someone give me a hint to start off this question and put me in the right direction? Thanks in advance.</p>
",calculus
"<p>Let $B_{i,M}(x)$ be the $i^{th}$ part of the $M^{th}$ B-spline for the data-points $\{t_1,...,t_N\}$.  </p>

<p>Is there a known expression for the integral:
$$
\int_{0 \vee t_i}^{t \wedge t_{i+1}} B_{i,M}(s) \, ds?
$$</p>

<p>That is if $S_M$ is a $B$-spline curve of degree $M$ then what is the integral:
$$
\int_0^t S_M(s) \, ds
$$
equal to?</p>
",calculus
"<p>This is (hopefully) the final step in a larger proof. I would like to show that:</p>

<p>$$\vec{v}\cdot\frac{d||\vec{v}||}{dt}\hat{v} = 0\implies \frac{d||\vec{v}||}{dt} = 0$$</p>

<p>Where: $\vec{v}$ is a velocity vector and $\hat{v}$ is the the unit velocity vector, i.e. has a magnitude of 1.</p>

<p>I don't know that $||\vec{v}||$ is a constant as this is what I'm trying to show so I can't simply take it out of the dot product. However, it seems apparent that it must be a constant as the only way (that I can see) to make the dot product equal to zero is for $\frac{d||\vec{v}||}{dt} = 0$.</p>

<p>I'm hoping to find a more mathematically rigorous way of showing the desired outcome.</p>

<p>Thank you for your time and assistance.</p>

<p>Best,
Eric</p>
",calculus
"<p><strong>Question:</strong> Define $p(x) = 2x^3-7x$. Give an $\epsilon - \delta$ proof that $\lim_{x \to a} p(x)$ exists for every $a \in R$.</p>

<p><strong>My attempt:</strong>  Claim that the $\lim_{x \to a} 2x^3-7x = 2a^3 - 7a$.</p>

<p>Given an arbitrary $\epsilon &gt; 0$, $\exists\delta&gt;0$ such that $0&lt;|x-a|&lt;\delta \implies |f(x)-L|&gt;\epsilon$.</p>

<p>(i.e) $0&lt;|x-a|&lt;\delta \implies |2x^3-7x-(2a^3-7a)|&lt;\epsilon$ </p>

<p>Consider, </p>

<p>$$|2x^3-7x-(2a^3-7a)| = |2x^3-2a^3+7a-7x|$$
$$ \le |2||x^3-a^3|+|7||x-a|$$ by triangle inequality.</p>

<p>So,</p>

<p>$$|x-a|&lt; \frac{\epsilon - |2||x^3-a^3|}{|7|}$$</p>

<p>Because $|x^3-a^3|$ is a problem point, I need to control it, so the way I tried to do that is as follows:</p>

<p>If $|x-a|&lt;1$ then $$|x-a|&lt;1 \implies |x^3-a^3|&lt;|a^2+ax+x^2| (*)$$</p>

<p>Here's where I'm stuck. I'm not sure what to do with this: $|a^2+ax+x^2|$. Usually for proof like this I end up with something like $\delta = \min\left\{1, \frac{\epsilon-2(*)}{7}\right\}$ but in this case the result from $(*)$ wasn't in some form of a number, so I am not sure what to do next. If someone can help me with this that would be really appreciated.</p>
",calculus
"<p>This is my second question on the exchange. I've been wrestling with this particular problem for several weeks now, ever since I discovered a certain function, which I call the 'grum' function. I don't know if it's ever been discovered before. I'm just doing street math, pretty much.</p>

<p>In any case, the grum function gives the answer to the following question:</p>

<p>Given any right triangle, and any line segment connecting:</p>

<ul>
<li>The vertice of the angle opposite the hypotenuse, and:</li>
<li>Any point p resting on the hypotenuse, where the distance between the point p and the adjacent vertices of the triangle is given as the following ratio:</li>
<li>$d_{1} = \frac{r}{n}$</li>
<li>$d_{2} = r - \frac{r}{n}$</li>
</ul>

<p>The distance of said line segment can be found via the following function:</p>

<p>$$grum_{n}(\theta) \equiv n^{-1}\sqrt{(n-1)^{2}\cos^{2}(\theta) + sin^{2}(\theta)}$$</p>

<p>pronounced ""grum with index 'n' and evaluated at 'theta'"". The proof is fairly simple, and involves a geometric argument involving right triangles inscribed within right triangles, but that's not relevant to the question at the moment. Although, if you guys do want the proof, then I'll provide it.</p>

<p>In any case, however, my problem revolves around taking the indefinite integral of this function. I can take the derivative of grum with respect to theta like so:</p>

<p>$$\frac{d}{d\theta} n^{-1}\sqrt{(n-1)^{2}\cos^{2}(\theta) + \sin^{2}(\theta)}$$
$$\frac{-2(n-1)^{2}\cos(\theta)\sin(\theta) + 2\sin(\theta)\cos(\theta)}{2n\sqrt{(n-1)^{2}\cos^{2}(\theta) + \sin^{2}(\theta)}}$$</p>

<p>Which, if we multiply the denominator by 'n' and then simplify the expression, we get the nifty equation of:</p>

<p>$$\frac{d}{d\theta} grum_{n}(\theta) \equiv \frac{\sin(2\theta)(1 - (n-1)^{2})}{2n^{2}grum_{n}(\theta)}$$</p>

<p>So far, so good! However, I got stuck when I tried to take the indefinite integral of this function. I really want to learn not just what the indefinite integral is, but how to get it, and why it works. In any case, here's what I've gotten so far.</p>

<p>First, I draw out the constant in front of the radical, and rewrite the exponents.</p>

<p>$$n^{-1}\lmoustache ((n-1)^{2}\cos^{2}(\theta) + \sin^{2}(\theta))^{\frac{1}{2}}d\theta$$</p>

<p>Next, I rewrite $\sin^{2}(\theta)$ in the form of $1 - \cos^{2}$ and simplify the expression, which yields:</p>

<p>$$n^{-1}\lmoustache((n-1)^{2}\cos^{2}(\theta) - \cos^{2}(\theta) + 1)^{\frac{1}{2}}d\theta$$
$$n^{-1}\lmoustache(\cos^{2}(\theta)((n-1)^{2} - 1)) + 1)^{\frac{1}{2}}d\theta$$</p>

<p>Then I use the trig substitution identity $\sqrt{a^{2} + b^{2}x^{2}} = \frac{a}{b}\tan(x)$ to get the following form:</p>

<p>$$\frac{1}{n\sqrt{((n-1)^{2}-1) + 1)}}\lmoustache\tan(cos^{2}(\theta))d\theta$$</p>

<p>And... here's where I get stuck. How in hell does one calculate the indefinite integral of $\tan(cos^{2}(\theta))$? Am I even doing this the right way? In using the trigonometric substitution, I simply inserted $\cos^{2}(\theta)$ where x would have gone, but there's no guarantee that that's a valid operation.</p>

<p>If I could get some guidance, or even just a push in the right direction, I would be grateful. In the meantime, I'll keep working on it, and let you guys know if I make any progress on it.</p>

<p>Sorry for the long question, haha. I hope it was at least interesting in some small way, and I thank you very much for your time.</p>

<p>Thank you very much,</p>

<p>sincerely,</p>

<p>Druid.</p>
",calculus
"<p>I know there is such a subsequence for $b_n = \sin(n)$. What about $a_n = n\sin(n)$?</p>
",calculus
"<p>I need to solve the to following integral:
$$\int_{-1}^1\frac{1}{\sqrt{1-x^2}}\arctan\frac{11-6\,x}{4\,\sqrt{21}}\mathrm dx.$$</p>

<p>I tried this integral in <a href=""http://www.wolfram.com/mathematica"">Mathematica</a>, but it was not able to solve it. An approximate numeric integration gives $1.6449340668482264364724151666460251892189...$ that is close to $\frac{\pi^2}6$. But when I tried to increase the precision above 60 decimal digits, I began to see a tiny difference, which could be interpreted either as a numerical algorithm glitch, or as $\frac{\pi^2}6$ being just an accidentally close value and not the exact answer. Indeed, $\frac{\pi^2}6$ would be a suspiciously nice result for this integral. Anyway, I need your help with this.</p>
",calculus
"<p>I have the following task: Check whether given function series is pointwise convergent, uniformly convergent or ""almost"" uniformly convergent (<em>id est</em> $f, f_{n} : I \rightarrow \mathbb{R} $ and $ \forall_{a, b \in I} (f_{n} \downarrow _{[a;b]}) $ uniformly convergent to $ (f \downarrow _{[a;b]}) $.</p>

<p><em>I use $ \downarrow _{[a;b]} $ to say that function is cut to range $[a;b]$.</em></p>

<p>Function series: $ \sum^{+\infty}_{n=1} \frac{(-1)^n}{n+x}, x \in [0;+\infty) $</p>

<p>I have found that limit of sum argument ($n \rightarrow +\infty$) is equal 0. Is it enough to say yes, yes and yes?</p>
",calculus
"<p>How to evaluate the $\displaystyle\lim\limits_{x\to 0}\frac {2\sin(x)-\arctan(x)-x\cos(x^2)}{x^5}$, using power series? </p>

<p>It made sense to first try and build the numerator using power series that are commonly used: </p>

<p>$\displaystyle2\sin(x)=\sum_{k=0}^\infty \dfrac{2(-1)^kx^{2k+1}}{2k+1!} = 2x -\frac{x^3}{3}+\frac{x^6}{60} + \dotsb$</p>

<p>$\displaystyle-\arctan(x)=\sum_{k=0}^\infty \dfrac{(-1)^{k+1}x^{2k+1}}{2k+1} = -x +\frac{x^3}{3}-\frac{x^6}{6} + \dotsb$</p>

<p>$\displaystyle-x\cos(x^2)=\sum_{k=0}^\infty \dfrac{(-1)^{k+1}x^{4k+1}}{2k!} = -x +\frac{x^5}{2}+ \dotsb$</p>

<p>Hence, </p>

<p>$\displaystyle\lim\limits_{x\to 0}\frac {2\sin(x)-\arctan(x)-x\cos(x^2)}{x^5} =
\lim\limits_{x\to 0} \dfrac{[2x -\frac{x^3}{3}+\frac{x^6}{60} + \dotsb] + [-x +\frac{x^3}{3}-\frac{x^6}{6} + \dotsb] + [x +\frac{x^5}{2}+ \dotsb]} {x^5}$</p>

<p>In similar problems, the there is an easy way to take out a common factor that would cancel out with the denominator, resulting in an easy-to-calculate limit. Here, however, if we were to take a common factor from the numerator, say, $x^6$, then we would end up with an extra $x$</p>

<p>What possible strategies are there to solve this question? </p>
",calculus
"<p>I have this integral to evaluate</p>

<p>$$\int^x_1 \sqrt{1+ t^4}\, dt$$</p>

<p>I have tried substitution, trig identity and integration by parts, I don't have any answer.</p>

<p>Can anyone explain the method I need to work this out?</p>

<hr>

<p>Edit: I copied the following text from a now deleted answer by the OP in the hope that having it here may clarify and otherwise improve the question, JL.</p>

<p>It really is a problem that is asked to show that the function y = f (x) is a solution of the differential equation in this case would be</p>

<p>\begin{array}{rc}
\frac{1}{\sqrt{1+x^{4}} } \int ^{x}_{1}\sqrt{1+} t^{4}&amp; dt
\end{array}</p>

<p>And the ec. Dif is $$y'+\frac{2x^{3}}{1+x^{4}} y=1$$</p>
",calculus
"<p>I am starting out with the following:</p>

<p>$$
\frac{d^n}{dx^n}[g(x)^{f(x)}] = \sum_{c=0}^n g(x)^{f(x)-c}\lambda_{n,c}(x)
$$</p>

<p>Therefore:</p>

<p>$$
\frac{d^{n+1}}{dx^{n+1}}[g(x)^{f(x)}] = \sum_{c=0}^{n+1}g(x)^{f(x)-c}\lambda_{n+1,c}(x) = \frac{d}{dx}\sum_{c=0}^n g(x)^{f(x)-c}\lambda_{n,c}(x)
$$</p>

<p>$\lambda_{n,c}(x)$ is defined like so:</p>

<p>$$
\lambda_{n,c}(x) = \sum_{k=c}^n \sum_{j=0}^{k-c} {k-c \choose j} \ln(g(x))^{k-c-j} \frac{d^j}{df^j}[f(x)_c] B_{n,k}^{(f \diamond g)^c}(x)
$$</p>

<p>My goal is to find a recurrence relation for $B_{n,k}^{(f \diamond g)^c}(x)$ by setting the two expressions equal to eachother. This is my work so far:</p>

<p>$$
\frac{d}{dx}[g(x)^{f(x)-c} \lambda_{n,c}(x)] = \left((f(x)-c)\frac{g'(x)}{g(x)} + \ln(g(x)) f'(x)\right)g(x)^{f(x)-c} \lambda_{n,c}(x) + g(x)^{f(x)-c} \frac{d}{dx}[\lambda_{n,c}(x)]
$$
Note from now on i will denote $\frac{d^j}{df^j}[f(x)_c] = f_c^{(j)}$
$$
\frac{d}{dx}[\lambda_{n,c}(x)] = \sum_{k=c}^n \sum_{j=0}^{k-c} {k-c \choose j} \left(\frac{g'(x)}{g(x)}(k-c-j) \ln(g(x))^{k-c-j-1} f_c^{(j)} B_{n,k}^{(f \diamond g)^c} + \ln(g(x))^{k-c-j} \frac{d}{dx}[f_c^{(j}B_{n,k}^{(f \diamond g)^c}]\right)
$$</p>

<p>Now, for me to find an expression that will result in a recurrence relation i am going to attempt to group all the $\ln(g(x))^{k-c-j}$ together and set all these terms equal to:</p>

<p>$$
\sum_{c=0}^{n+1} g(x)^{f(x)-c} \lambda_{n+1,c}(x)
$$</p>

<p>By doing this i will have found a way to isolate the $g(x)^{f(x)-c}$ terms as well as the $\ln(g(x))^{k-c-j}$ terms.</p>

<p>To do this i will seperate each individual term and attempt to manipulate it in order to fit these conditions:</p>

<p>$$
A = f'(x) \ln(g(x)) \lambda_{n,c}(x) = f'(x) \sum_{k=c}^n \sum_{j=0}^{k-c} {k-c \choose j} \ln(g(x))^{k-c-j+1} f_c^{(j)} B_{n,k}^{(f \diamond g)^c}(x) = f'(x) \sum_{k=c+1}^{n+1} \sum_{j=0}^{k-c-1} {k-c-1 \choose j} \ln(g(x))^{k-c-j} f_c^{(j)} B_{n,k-1}^{(f \diamond g)^c}(x)
$$
Now,for $B$ i will shift over a step backwards so that instead of $c$ we will be dealing with $c-1$, this is because of the differentiation of the natural log which in turn results in $\frac{g'(x)}{g(x)}$. When we multiply $\frac{g'(x)}{g(x)}$ with $g(x)^{f(x)-c}$ we will get $g'(x) g(x)^{f(x)-c-1}$ therefore by evaluating the expression at $c-1$ we will be evaluating the part of the summation that is dealing with $g(x)^{f(x)-c}$ instead of dealing with the summation that deals with $g(x)^{f(x)-c-1}$. If there is any questions about this please do not hesitate to ask in the comments.
$$
B = g'(x) (f(x)-c+1) \lambda_{n,c-1}(x) = g'(x) (f(x)-c+1) \sum_{k=c-1}^n \sum_{j=0}^{k-c+1} {k-c+1 \choose j} \ln(g(x))^{k-c-j+1} f_{c-1}^j B_{n,k}^{(f \diamond g)^{c-1}}(x) = g'(x) (f(x)-c+1) \sum_{k=c}^{n+1} \sum_{j=0}^{k-c} {k-c \choose j} \ln(g(x))^{k-c-j} f_{c-1}^j B_{n,k-1}^{(f \diamond g)^{c-1}}(x)
$$
Now, for $C$ and $D$ i will split up the two parts in the part where i differentiated the $\lambda_{n,c}(x)$, in variable $C$ we will be using the same logic as i used for ""shifting"" the $c$ variable to $c-1$.</p>

<p>$$
C = \lambda_{n,c}'(x)_{part \space 1} = g'(x)\sum_{k=c-1}^{n} \sum_{j=0}^{k-c+1} {k-c+1 \choose j} (k-c-j+1) \ln(g(x))^{k-c-j} f_{c-1}^{(j)} B_{n,k}^{(f \diamond g)^{c-1}}(x) = g'(x)\sum_{k=c}^{n+1} \sum_{j=0}^{k-c} {k-c \choose j} (k-c-j) \ln(g(x))^{k-c-j} f_{c-1}^{(j)} B_{n,k}^{(f \diamond g)^{c-1}}(x)
$$
Now for $C$ i did a little bit of trickery, first of all, when $k=c-1$ the term is equal to zero due to the $(k-c+1)$ term and when $j = (k-c+1)$ the term is equal to zero due to the $(k-c-j+1)$ term.
$$
D = \lambda_{n,c}'(x)_{part \space 2} = \sum_{k=c}^n \sum_{j=0}^{k-c} {k-c \choose j} \ln(g(x))^{k-c-j} \frac{d}{dx}[f_c^{(j)} B_{n,k}^{(f \diamond g)^c}(x)]
$$</p>

<p>Now the problem arises when i try to add $A+B+C+D$ and set it equal to $\lambda_{n+1,c}(x)$. i have attempted to do this many times but i have hit some points where it becomes troubling or that the identity does now work at all. If someone can please help me with the issue it would be alot of help to me. Thank you all for reading this if you have gotten this far, i appreciate it a lot.</p>
",calculus
"<p>This demand is a part of a proof. It must be easy, I'm just failing showing it rigorously.  </p>

<p>Let: $\left| {x_{n+1} -x_n} \right| &lt; {1\over 2^n}$  </p>

<p>We want to prove it's a Cauchy's sequence:  </p>

<p>Without the lose of generality, Let us assume $m&gt;n$:  </p>

<p>$$\left| {{x_m} - {x_n}} \right| = \left| {{x_m} - {x_{m - 1}} + {x_{m - 1}} - {x_{m - 2}} + ... + {x_{n + 1}} - {x_n}} \right| \le \left| {{x_m} - {x_{m - 1}}} \right| + ... + \left| {{x_{n + 1}} - {x_n}} \right| \le \frac{1}{{{2^m}}} + ... + \frac{1}{{{2^n}}}$$</p>

<p>I feel like I'm on the right path. Can you help from here?  </p>
",calculus
"<p>Prove that
$$\sum\limits_{k=1}^{\infty} \frac {1}{(p+k)^2} = -\int_0^1 \frac{x^p \log x}{1-x}\,dx$$
for $p&gt;0$.</p>

<p>I tried to transform LHS as Riemann sum form but failed.</p>

<p>Can anyone give some idea? Many Thanks!</p>
",calculus
"<blockquote>
  <p>Let a sequence, $\{x_n\}$ such that: $x_{n+1}=x_n-x_n^3$ and $0&lt;x_1&lt;1$.<br>
  1) Prove $\mathop {\lim }\limits_{n \to \infty } {x_n} = 0$<br>
  2) Calculate $\mathop {\lim }\limits_{n \to \infty } n{x_n}^2$  </p>
</blockquote>

<p>So, section (1) is very easy. I didn't really bother to write it down - just show the sequence is monotonically decreasing and bounded bellow by zero.  </p>

<p>Section (2) is the real fun, I do familiar with the Lemma says: ""If $a_n$ limit is $0$ and $b_n$ is bounded then the limit of $a_nb_n$ is also zero"" - But I don't think it can work here. </p>

<p>I tried separating the limit using limits-arithmetic into two limits, but then I got:<br>
$$\mathop {\lim }\limits_{n \to \infty } n{x_n} \cdot \mathop {\lim }\limits_{n \to \infty } {x_n}$$</p>
",calculus
"<p>So far I've substituted $x=\sin t$ ; $dx = \cos t\; dt$, leaving me to integrate $\sin^2t\cos^2t\;dt$.</p>

<p>I'm stuck here. I thought to use the identity $\sin 2t = 2 \sin t \cos t$ but it looks like it doesn't lead anywhere.</p>

<p>Any tips would be greatly appreciated!</p>
",calculus
"<p>Let a>b>c>0.</p>

<p>How may one find the limit $\lim_{x \to \infty} (a^x+b^x-c^x)^{\frac{1}{x}}$?</p>

<p>It's obvious that it's bounded from below by c, so I tried to show that it's also bounded from above by c and then use sandwich (I factored out c and then tried to show that the limit is 1).</p>

<p>I also tried to use the method of $e^{ln}$, but also got nowhere... L'Hospital also didn't help.</p>

<p>Please help, thank you!  </p>
",calculus
"<p>I'm having a little difficulty understanding how to do the .05 using differentials. I'm just hoping someone can walk me through, step by step, and explain why they are during it that way.</p>

<p>$$\sqrt[3] {27.05}$$</p>

<p><em>Edit</em>
Apologies to all, I wasn't very clear on what I was asking. </p>

<p>I was looking for someone to explain how to find an approximate answer to the equation above using differentials. (such as @Arturo has done)</p>

<p>@Sasha @Ross  I apologize for wasting your time when answering the question using series. </p>
",calculus
"<p>$x = 0, x = 9 - y^2$ rotated about $x = -1$</p>

<p>I'm having a lot of trouble deciding whether to use the disc method or the shell method. Intuitively, it makes sense that the shell method would be simpler when you are rotating horizontally, like around the y-axis or x = -1.</p>

<p>I know that the shell method is:</p>

<p>$[circumference][height][width]$, where $C = 2\pi r$, $h = f(x)$, and $w =
 \Delta x$</p>

<p>I must find the radius of the solid about the line $x = -1$.</p>

<p>So, I see that the radius must be $y - (-1) \rightarrow r = y + 1$</p>

<p>Therefore, $C = 2\pi (y + 1)$, right?</p>

<p>The height varies with $f(y) = 9 - y^2$.</p>

<p>Here is where things get really muddled for me.</p>
",calculus
"<p>I sometimes see Cauchy's Mean Value Theorem stated as follows:</p>

<blockquote>
  <p>Let $f,\ g:\mathbb{R}\rightarrow\mathbb{R}$ be continuous on $[a,\ b]$ and differentiable on $(a,\ b)$. Suppose that $g(b) \neq g(a)$. <strong>Then there exists $c\in(a,\ b)$ such that $g'(c)\neq 0$</strong> and such that $$\frac{f(b) - f(a)}{g(b) - g(a)} = \frac{f'(c)}{g'(c)}$$</p>
</blockquote>

<p>I have never once seen a proper proof of the bolded fact and I'm beginning to wonder about the validity of it. Is the assumption $g(b) \neq g(a)$ really enough to prove the existence of such a $c$?</p>

<p>Edit: I think my question is being misunderstood. I am <strong>not</strong> asking for a standard proof of the Cauchy Mean Value Theorem. The proofs I see assume that $g'(x) \neq 0\ \forall\ x\in(a,\ b)$. This version also claims $g'(c) \neq 0$ when $g(b) \neq g(a)$ (along with the standard continuity/differentiably conditions of course). How can we guarentee there exists such a $c$?</p>
",calculus
"<p>I need to prove the following:</p>

<blockquote>
  <p>Let $\delta &gt; 0$. Then $$
\sin \pi x \geq \frac{\pi}{2}\delta\;.
$$ holds for $x \in [\delta, 1-\delta]$.</p>
</blockquote>

<p>I tried to deduce the inequality using the definition of the sine as a power series, however, to no avail. Is there any quick way or hint to deduce this inequality?</p>

<p>Thanks a lot!</p>
",calculus
"<ol>
<li><p>Is there some general method for finding such curves? Let's say I have a planar curve, how can I project it onto a sphere?</p></li>
<li><p>I am interested in a curve that starts at the south pole of a sphere, then wraps it in spiral motion and ends at the north pole. Is it possible to construct?</p></li>
</ol>
",calculus
"<p>One of the first things ever taught in a differential calculus class:</p>

<ul>
<li>The derivative of $\sin x$ is $\cos x$.</li>
<li>The derivative of $\cos x$ is $-\sin x$.</li>
</ul>

<p>This leads to a rather neat (and convenient?) chain of derivatives:</p>

<pre>
sin(x)
cos(x)
-sin(x)
-cos(x)
sin(x)
...
</pre>

<p>An analysis of the shape of their graphs confirms <em>some</em> points; for example, when $\sin x$ is at a maximum, $\cos x$ is zero and moving downwards; when $\cos x$  is at a maximum, $\sin x$ is zero and moving upwards.  But these ""matching points"" only work for multiples of $\pi/4$.</p>

<p>Let us move back towards the original definition(s) of sine and cosine:</p>

<p>At the most basic level, $\sin x$ is defined as -- for a right triangle with internal angle $x$ -- the length of the side opposite of the angle divided by the hypotenuse of the triangle.</p>

<p>To generalize this to the domain of all real numbers, $\sin x$ was then defined as the Y-coordinate of a point on the unit circle that is an angle $x$ from the positive X-axis.</p>

<p>The definition of $\cos x$ was then made the same way, but with adj/hyp and the X-coordinate, as we all know.</p>

<p>Is there anything about this <strong>basic</strong> definition that allows someone to look at these definitions, alone, and think, ""Hey, the derivative of the sine function with respect to angle is the cosine function!""</p>

<p>That is, from <strong>the unit circle definition alone</strong>.  Or, even more amazingly, the <strong>right triangle definition alone</strong>.  Ignoring graphical analysis of their plot.</p>

<p>In essence, I am asking, essentially, ""Intuitively <em>why</em> is the derivative of the sine the cosine?""</p>
",calculus
"<p>I've sort of gotten a grasp on the Chain rule with one variable.  If you hike up a mountain at 2 feet an hour, and the temperature decreases at 2 degrees per feet, the temperature would be decreasing for you at $2\times 2 = 4$ degrees per hour.</p>

<p>But I'm having a bit more trouble understanding the Chain Rule as applied to multiple variables.  Even the case of 2 dimensions </p>

<p>$$z = f(x,y),$$ </p>

<p>where $x = g(t)$ and $y = h(t)$, so</p>

<p>$$\frac{dz}{dt} = \frac{\partial z}{dx} \frac{dx}{dt} + \frac{\partial z}{dy} \frac{dy}{dt}.$$</p>

<p>Now, this is easy enough to <em>""calculate""</em> (and figure out what goes where).  My teacher taught me a neat tree-based graphical method for figuring out partial derivatives using chain rule.  All-in-all, it was rather hand-wavey.  However, I'm not sure exactly how this works, intuitively.</p>

<p>Why, intuitively, is the equation above true?  Why <strong>addition</strong>?  Why not multiplication, like the other chain rule?  Why are some multiplied and some added?</p>
",calculus
"<blockquote>
  <p>$$\lim\limits_{ x \rightarrow 0}{f(g(x))}=f(\lim\limits_{ x
 \rightarrow 0}g(x))$$</p>
</blockquote>

<p>I have seen this step in a derivation of a result which is not the point of interest here.</p>

<p>The book wrote the reason for it was that it is when $f$ is continuous.</p>

<p>I wonder how one can write so. Does there exist any proof? Any hint to the proof is more appreciated.</p>
",calculus
"<p>Why does it converge conditionally?
$$\sum_{k=1}^{\infty} \frac {(-1)^{k-1}}{k}$$</p>
",calculus
"<p>I am trying to find $$\lim_{x\to0}\frac{\sin5x}{\sin4x}$$</p>

<p>My approach is to break up the numerator into $4x+x$. So,</p>

<p>$$\begin{equation*}
\lim_{x\to0}\frac{\sin(4x+x)}{\sin4x}=\lim_{x\to0}\frac{\sin4x\cos x+\cos4x\sin x}{\sin4x}\\
=\lim_{x\to0}(\cos x +\cos4x\cdot\frac{\sin x}{\sin4x})\end{equation*}$$</p>

<p>Now the problem is with $\frac{\sin x}{\sin4x}$. If I use the double angle formula twice, it is going to complicate the problem.</p>

<p>The hint says that you can use $\lim_{\theta\to0}\frac{\sin\theta}{\theta}=1$.</p>

<p>I have little clue how can I make use of the hint.</p>

<p>Any helps are greatly appreciated. Thanks!</p>
",calculus
"<p>can someone give me an example of Differentiable function at x=4 and funcstions who dont Differentiable function at x=4?</p>

<p>$f(x) = 2x-7$</p>

<p>$k(x) = 100x^7-55x^5+10000x^2$</p>

<p>$g(x) = 23$</p>

<p>Those are Differentiable function at x-4, right?</p>

<p>$q(x) = x/(x-4)$</p>

<p>$y(x) = 78x^2/(x^2-8x+16)$</p>

<p>$p(x) = 2/(x^2+16)$</p>

<p>and those are not Differentiable function?</p>

<p>Am I right?</p>

<p>Thanks for help</p>
",calculus
"<p>I have downloaded a book about Calculus from <a href=""http://ocw.mit.edu"" rel=""nofollow"">MIT OCW</a>. In that book, there is a section ""A Thousand points of Light"". (You can download the relevant section from <a href=""https://drive.google.com/file/d/0BytxARWilliKdFpVeDRGcVZ1dFU/edit?usp=sharing"" rel=""nofollow"">here</a>.)</p>

<p>In that section, it is written that the graph of $y=\sin x$ is different from the graph of $y=\sin n$.</p>

<p><img src=""http://i.stack.imgur.com/NKArE.png"" alt=""Book Image""></p>

<p>However, I cannot understand this thing.  Why will the graph of $y=\sin n$ be different from the graph of $y=\sin x$? How can you change a graph by changing a variable in the function? And how have they plotted the graph in the book?</p>
",calculus
"<p>Does there exist a sequence $\left(a_n\right)_{n\ge1}$ with $a_n &lt; a_{n+1}+a_{n^2}, \forall n=1,2,3,\ldots$ such that the series $\displaystyle{\sum_{n=1}^{\infty}a_n}$ converges? </p>

<p>This is the <strong>first</strong> part of <a href=""http://math.stackexchange.com/questions/242190/does-there-exist-a-sequence-a-n-n-ge1-with-a-n-a-n1a-n2-such"">this</a> question which has an (accepted) answer for its <strong>second</strong> part only:<br>
The last sentence of the <a href=""http://math.stackexchange.com/a/245596/39722"">answer</a> is: <br> ""Now we note that $\sum_{i=1}^{\infty}a_i\geq\sum_{k=0}^{\infty}\sum_{i\in J_k}a_i&gt;\sum_{k=0}^{\infty}a_n$, so the sum diverges.""<br>
For the inequality $\sum_{i=1}^{\infty}a_i\geq\sum_{k=0}^{\infty}\sum_{i\in J_k}a_i$ to be valid, we have to assume the positivity of $(a_n)_{n\in\mathbb N}$ since $\displaystyle{\bigcup_{k\in\mathbb N}J_k\neq\mathbb N}$.</p>

<p>According to the <a href=""http://math.stackexchange.com/questions/242190/does-there-exist-a-sequence-a-n-n-ge1-with-a-n-a-n1a-n2-such?lq=1#comment556592_242190"">comments</a> the first part is a difficult question.</p>
",calculus
"<p>Is there a continuous function on R such that $f(f(x))=e^{-x}$? I have tried to take derivative of the two sides,but I can't get anything I want.what can I do?</p>
",calculus
"<p>Express the volume $V$ of a regular tetragonal pyramid as a  function of its altitude $x$ and the edge of a lateral face (lateral edge) $y$ </p>

<p>The answer given by the book is $\frac{2}{3} (y^2 - x^2) x $. But,I've found the lateral edge is $2 \sqrt{y^2 - x^2 } $ and I thought that the area of the basis is $ 4(y^2 - x^2)$. What am I doing wrong?</p>

<p>Thanks for your help!</p>
",calculus
"<p>So I tried this out and got stuck with this:</p>

<p>$$0 = 3x^{(7/6)} + 2x - 10$$</p>

<p>I didn't think I could use a quadratic for this since its to the power of $7/6$</p>

<p>Here is the working I did:</p>

<p>We know its a critical point when f'(a) = 0</p>

<p>So I found the derivative of f(x) which is $$2*(5-x)/3x^{1/2} - x ^{2/3}$$ </p>

<p>So I set this equal to 0</p>

<p>$$2*(5-x)/3x^{1/2} - x ^{2/3} = 0$$ 
$$2*(5-x)/3x^{1/2}=x ^{2/3}$$ 
$$2*(5-x)=x ^{2/3}\times3x^{1/2}$$ 
$$10-2x=3x ^{2/3 +1/2}$$ 
$$10=3x ^{7/6} + 2x$$ </p>

<p>But this would be such a messy answer, so I think I have done something wrong with my working. Do you have any ideas?</p>
",calculus
"<p>I just read <a href=""http://www.npr.org/2014/04/20/303716795/far-from-infinitesimal-a-mathematical-paradoxs-role-in-history"" rel=""nofollow"">this article</a> on npr, which mentioned the following question:</p>

<blockquote>
  <p>You can keep on dividing forever, so every line has an infinite amount
  of parts. But how long are those parts? If they're anything greater
  than zero, then the line would seem to be infinitely long. And if
  they're zero, well, then no matter how many parts there are, the
  length of the line would still be zero.</p>
</blockquote>

<p>It further mentions that</p>

<blockquote>
  <p>Today, mathematicians have found ways to answer that question so that
  modern calculus is rigorous and reliable.</p>
</blockquote>

<p>Can anyone elaborate on the modern answers to this question? </p>
",calculus
"<blockquote>
<p> Let $ \zeta(s) $be the riemann zeta function, then

$$ \prod_{n=2}^{\infty}n^{\zeta(n)-1} &lt;1+\frac{\pi^2}{6}$$
</p>
</blockquote>

<p>The problem is difficult, I don't know how to go started</p>

<p>Thank you very much!</p>
",calculus
"<p>Can anyone help me with finding the volume of a solid of revolution of f(x) about the x axis for the interval [1,6].  It's supposed to be able to be done without needing calculus but I am having trouble figuring it out.</p>

<p>$f(x) =
\begin{cases}
1  &amp;  1 \leq x&lt; 2\\ 
1/2 &amp;  2 \leq x&lt; 3\\ 
. &amp;          .\\ 
. &amp;          .\\
1/n &amp;  n\leq x&lt; n+1\\ 
\end{cases}$</p>

<p>I know the volume would be found like this $\pi$ $\int_{1}^{6}(f(x))^2dx$ but I am unsure about how to go about it with this function.</p>

<p>Any help is appreciated.
Thanks</p>
",calculus
"<p>I have the following series which gives me Pi.</p>

<p><img src=""http://i.stack.imgur.com/qEjCP.png"" alt=""Pi series""></p>

<p>I need to figure out how many terms of the series I need to be accurate (with respect to Pi) up to 4 decimals.</p>

<p>I also need a formula to figure out how many terms of the series I will need to be accurate to n decimal places of accuracy. If I can find this formula, I should be able to answer the above question easily.</p>

<p>I believe I should be using the error bounds to determine this.</p>

<p><img src=""http://i.stack.imgur.com/HHfPp.png"" alt=""Error bounds equation""></p>

<p>However, I don't understand exactly how this will tell me how many terms I need to be accurate to n decimals of Pi.</p>

<p>For example, how many terms would I need to be accurate to 100 decimal places using the equations above?</p>
",calculus
"<p>I have a question here $\frac{d}{dx}\left(\frac{8}{e^{1-4x}}\right)$</p>

<p>I simplify this  $8\left(\frac{1}{\left(e^{1-4x}\right)^2}\right)\left(-4e^{1-4x}\right)$ to  $\left(\frac{32}{e^{1-4x}}\right)$ </p>

<p>but I am being told this is wrong am I missing out a step ?</p>
",calculus
"<p>$$
\begin{align}
DFS[x^*(-n)] &amp;= \frac{1}{N}\sum^{N-1}_{n=0}x^*(-n)e^{-j2\pi kn/N}\\
&amp;= \left[\frac{1}{N}\sum^{N-1}_{n=0}x(-n)e^{j2\pi kn/N}\right]^*\\
&amp;= \left[\frac{1}{N}\sum^{N-1}_{p=0}x(p)e^{-j2\pi kp/N}\right]^*\\
&amp;= c^*_k
\end{align}
$$</p>

<p>(<a href=""http://i.stack.imgur.com/2P5nK.png"" rel=""nofollow"">Source</a>)</p>

<p>In the given series we have substituted $p=-n$ and limit for $n$ is from $0$ to $N-1$. Therefore, the limit for $p$ should be from $0$ to $1-N$, but limit is still the same. Can anyone explain why?</p>
",calculus
"<p>the real analysis book says that 
$$f:\mathbb{R}_+ \rightarrow \mathbb{R}_+$$ where $f$ is strictly increasing and concave function. it has the following property
$$f(ax+(1-a)y) \le f(ax) + f((1-a)y)$$
where $a \in [0,1]$.</p>

<p>This property seems wrong. As far as I know, that property is for convex function, not concave function. I do not think the textbook is wrong. Can you please explain it?</p>

<p>The textbook used it to show the function $d(x,y)$ is a matric in $\mathbb{R}$</p>
",calculus
"<p>While I was <a href=""http://math.stackexchange.com/a/1402835/153012"">working</a> on <a href=""http://math.stackexchange.com/q/879854/153012"">this question</a> by @Vladimir Reshetnikov, I've found the following relations between Gaussian hypergeometric function values and the Baxter constant:</p>

<blockquote>
  <p>$$\begin{align}{_2F_1}\left(\begin{array}c\tfrac13,\tfrac13\\1\end{array}\middle|\,-1\right) &amp;\stackrel{?}{=} \frac{1}{2^{\small2/3}}\,C^2_\text{B4CC},\\
{_2F_1}\left(\begin{array}c\tfrac23,\tfrac23\\1\end{array}\middle|\,-1\right) &amp;\stackrel{?}{=} \frac{1}{2}\,C^2_\text{B4CC},\\
{_2F_1}\left(\begin{array}c\tfrac13,\tfrac13\\1\end{array}\middle|\,\frac19\right) &amp;\stackrel{?}{=} \frac{1}{\sqrt[3]{3}}\,C^2_\text{B4CC},\\
{_2F_1}\left(\begin{array}c\tfrac23,\tfrac23\\1\end{array}\middle|\,\frac19\right) &amp;\stackrel{?}{=} \frac{\sqrt[3]{3}}{2}\,C^2_\text{B4CC},\\
{_2F_1}\left(\begin{array}c\tfrac13,\tfrac13\\1\end{array}\middle|\,9\right) &amp;\stackrel{?}{=} \frac{3-i\sqrt3}{6}\,C^2_\text{B4CC},\\
{_2F_1}\left(\begin{array}c\tfrac23,\tfrac23\\1\end{array}\middle|\,9\right) &amp;\stackrel{?}{=} -\frac{i}{2\sqrt3}\,C^2_\text{B4CC},\\
\end{align}$$</p>
</blockquote>

<p>where ${_2F_1}$ is the <a href=""http://mathworld.wolfram.com/HypergeometricFunction.html"" rel=""nofollow"">Gaussian hypergeometric function</a>, and</p>

<blockquote>
  <p>$$
C^2_\text{B4CC} = \frac{3}{4\pi^2}\Gamma^3\left(\tfrac{1}{3}\right) \approx 1.460998486206318358158873117846059697\dots
$$</p>
</blockquote>

<p>is <a href=""http://mathworld.wolfram.com/BaxtersFour-ColoringConstant.html"" rel=""nofollow"">Baxter's four-coloring constant</a>.</p>

<p>The first two identity are known, but with the last four relations I've never met before.</p>

<blockquote>
  <p>How could we prove these identities?</p>
</blockquote>

<p>In this <a href=""http://arxiv.org/pdf/1203.4498.pdf"" rel=""nofollow"">paper</a>, there is another connection between a hypergeometric value and Baxter constant.</p>
",calculus
"<h2><strong>Derivation/equation for solid angle factor correction</strong></h2>

<p><strong><em>Summary</em></strong>: I want to determine a correction for the Solid Angle Factor (SAF) due to partially overlapping 'outer' spheres (of different sizes), as perceived/viewed from the center of a 'central' sphere. The distances of these spheres from the 'central sphere' are not equal, i.e. they are not equidistant. The coordinates, distances and relatives angles of all the spheres can be determined via software, i.e. they are known.</p>

<hr>

<p>“The Solid Angle Factor (SAF) is defined as the solid angle of the ligand cone comprising the metal at the apex and the primary coordinating atom or group (the first-order SAF) or the whole ligand (the second-order SAF) divided by 4π. <strong>Geometrically, it refers to the ratio of the projected area to 4π, i.e. the area of the sphere surface.</strong> It actually represents the size of the ligand as viewed from the metal centre towards the ligand. The sum of the values of SAF of all the ligands coordinated to the metal centre represents the total occupancy of the ligands in the coordination sphere. It is apparent that this occupancy should not reach unity because there are gaps and holes among the ligands.” (Polyhedron Vol. 6, No. 5, pp. 104-1048, 1987) (See <a href=""https://www.dropbox.com/s/g2f97bn97yq56vu/xi-zhang1987.pdf?dl=0"" rel=""nofollow"">https://www.dropbox.com/s/g2f97bn97yq56vu/xi-zhang1987.pdf?dl=0</a>)</p>

<p>In other words the solid angle is related to the projection of an 'outer' 'ligand' (sphere of known radius) onto the surface of a central ('metal' atom) sphere, as viewed from the center of the central sphere.
<strong>Solid angle factor (SAF) equation</strong>:</p>

<p>$$SAF=\frac{2\pi (1-\cos \Theta )}{4\pi } = \frac{1}{2}(1-\cos \Theta)$$</p>

<p>$$\theta =\sin^{-1}(\frac{\nu }{\iota })$$</p>

<p>, where ν = radius of the sphere of ligand/coordinating atom (This is known),
l = distance between the center of the 'ligand' spheres to the center of the metal atom/ 'sphere'.</p>

<p>A correction (approximation) has been supplied for the case where 2 identical  'ligand' spheres (i.e. the spheres have identical radii) are partially overlapping and are equidistant from the metal center:</p>

<p>$$\Delta SAF = \frac{2(\frac{2\varphi (\pi \nu ^{2})}{360}-d\nu \sin \varphi )}{4\pi (\iota \cos \eta )^{^{2}}}$$</p>

<p>(See link above and the following link:
<a href=""https://www.dropbox.com/s/7w3kyvf1xq9e320/Solid%20angle%20factor_details_1_2%20%281%29.pdf?dl=0"" rel=""nofollow"">https://www.dropbox.com/s/7w3kyvf1xq9e320/Solid%20angle%20factor_details_1_2%20%281%29.pdf?dl=0</a> . These diagrams/equations illustrate what I understand of the the given correction equation, as well as the definition of the above symbols)</p>

<hr>

<p><strong>Derivation/equation for solid angle factor correction</strong>:
However, since there are multiple 'ligand' spheres around the metal several may partially overlap (or be perceived to overlap as viewed from the central 'metal' sphere) due to their close proximity to the metal, thereby resulting in the ‘observed’ solid angle factor being different from the calculated solid angle factor (without correction) from the metal.
The correction must consider:</p>

<ol>
<li>The distance from the central 'metal' sphere to the center of each 'ligand' sphere. (They are not necessarily equidistant)</li>
<li>The radius of each 'ligand' sphere (since they may have different (known) radii).</li>
</ol>

<p><strong>How would such an equation be derived and what would the equation be?</strong> Perhaps by considering 2 'ligand' spheres at a time? I am interested in the corrected (i.e. accurate) sum of all the SAF (known as the <strong>Solid Angle Sum (SAS)</strong>) of all the surrounding 'ligand' spheres, which should be &lt; or = 1.0.</p>

<p>I look forward to any helpful responses.
$$Thank you$$</p>
",calculus
"<p>According to <em>Mathematica</em>, we have that </p>

<p>$$\int_0^{\infty } \frac{\arctan(x)}{x \left(x^2+1\right)^5} \, dx=\pi  \left(\frac{\log (2)}{2}-\frac{1321}{6144}\right)$$
that frankly speaking looks pretty nice.</p>

<p>However <em>Mathematica</em> shows that </p>

<p>$$\int \frac{\arctan(x)}{x \left(x^2+1\right)^5} \, dx$$
$$=-\frac{1}{2} i \text{Li}_2\left(e^{2 i \tan ^{-1}(x)}\right)-\frac{1}{2} i \tan ^{-1}(x)^2+\tan ^{-1}(x) \log \left(1-e^{2 i \tan ^{-1}(x)}\right)-\frac{65}{256} \sin \left(2 \tan ^{-1}(x)\right)-\frac{23 \sin \left(4 \tan ^{-1}(x)\right)}{1024}-\frac{5 \sin \left(6 \tan ^{-1}(x)\right)}{2304}-\frac{\sin \left(8 \tan ^{-1}(x)\right)}{8192}+\frac{65}{128} \tan ^{-1}(x) \cos \left(2 \tan ^{-1}(x)\right)+\frac{23}{256} \tan ^{-1}(x) \cos \left(4 \tan ^{-1}(x)\right)+\frac{5}{384} \tan ^{-1}(x) \cos \left(6 \tan ^{-1}(x)\right)+\frac{\tan ^{-1}(x) \cos \left(8 \tan ^{-1}(x)\right)}{1024}$$</p>

<p>and this form doesn't look that nice. </p>

<p>Having given the nice form of the closed form I wonder if we can find a <strong>very nice and simple way</strong> of   getting the answer. What do you think?</p>

<p><em>A supplementary question</em>:</p>

<p>$$\int_0^{\infty } \frac{\arctan^2(x)}{x \left(x^2+1\right)^5} \, dx=\frac{55}{108}-\frac{1321}{12288}\pi^2+\frac{\pi^2}{4} \log (2)-\frac{7 }{8}\zeta (3)$$</p>
",calculus
"<p>I'm trying to find the integral of $$\int\frac{1}{x* (\sqrt{4x^4 - 9})}$$</p>

<p>Attempt:</p>

<p>I assumed that the integral would be some sort of inverse trigonometric function. Because of this, I did the following</p>

<p>Let $$u = 2x^2$$
$$du = 4x$$
$$\frac14 du = xdx$$</p>

<p>The reason why I did this was because I wanted to make it into the form of 
$$\int \frac{1}{\sqrt{a^2 - u^2}}$$ since this would be equal to $$\sin(\frac ua) +c$$</p>

<p>The problem I have encountered is that I have a - in between of my a and u values instead of a positive. I know that if there was a u variable in front of my radical in the bottom then the answer would be some sort of inverse secant. </p>

<p>This is my first time asking a question so I hope I'm being clear enough about the question and what I've said I think the answer would be like.</p>

<p>Thank you in advance!</p>
",calculus
"<p>I am a beginner in calculus and I want to know what is the difference between sum and integral. More specifically I came across this example:</p>

<blockquote>
  <p>Compare $$\sum^\infty_1\frac1x\space \text{and} \space \int_1^\infty\frac1xdx$$</p>
</blockquote>

<p>It would be really helpful if someone explains this to me. I want to know the difference between the two.</p>

<p>Thanks for any help!!</p>
",calculus
"<p>I'm trying to solve this equation
$$
\left \lfloor{x +\frac{1}{100}}\right \rfloor + \left \lfloor{x +\frac{2}{100}}\right \rfloor + ... + \left \lfloor{x +\frac{223}{100}}\right \rfloor = 521
$$</p>

<p>I haven't faced until now problems like this one... How can I find $x$? 
Rather than a specific solution, I'm looking for the intuition to use in order to set up a solution to problems like this one.</p>
",calculus
"<p>Given a function $f:\mathbb{R} \to \mathbb{R}$ such that 
$$f(x)=x+\int_{0}^{x}f(t)\,dt$$ then what is the relation between $f(x+y)$, $f(x)$ and $f(y)$</p>

<p>My Try: we have $$f(x+y)=x+y+\int_{0}^{x+y}f(t)dt$$ $\implies$</p>

<p>$$f(x+y)=x+y+\int_{0}^{x}f(t)dt+\int_{x}^{x+y}f(t)\,dt$$ $\implies$</p>

<p>$$f(x+y)=f(x)+y+\int_{x}^{x+y}f(t)\,dt$$ $\implies$</p>

<p>$$f(x+y)=f(x)+y+\int_{0}^{y}f(x+t)\,dt$$ Unable to proceed further.Help required</p>
",calculus
"<p>I have a set $S\subset\mathbb {R}^2$ with the following property</p>

<p>(P) $\forall x,y\in S$, $\forall\mathscr{C}$ a convex set that contains $x$ in its interior, $bd\mathscr{C}\cap [x,y]\subset \overline{bd\mathscr{C}\cap S}$.</p>

<p>Here $[x,y]$ denotes the segment with end-ponts $x$, $y$, $bd\mathscr{C}$ denotes the boundary of $\mathscr{C}$, and ""$\overline{\ \ \ \ \ }$"" stands for closure. </p>

<p>In other words the inclusion says </p>

<p>$\forall z\in bd\mathscr{C},\ z=tx+(1-t)y$, for some $0&lt;t&lt;1$, there is $(z_n)_n\subset bd\mathscr{C}\cap S,\ z_n\to z$.</p>

<p>This feels like $S$ is dense in an orderly fashion in the segment $[x,y]$ (on every boundary of a convex set). </p>

<p>Conjecture: If $S$ has (P) then $S$ is pathwise connected (meaning there is a continuous path within $S$ that connects any two points in $S$). </p>

<p>My try: For fixed $x,y\in S$ define the multi-function $F:[0,1]\rightrightarrows\mathbb{R}^2$, $$F(t):=\cup\{bd\mathscr{C}\cap S\mid tx+(1-t)y\in bd\mathscr{C}\ {\rm and}\ \mathscr{C}\ {\rm is\ a\ convex\ set\ that\ contains\ } x \ {\rm in\ its\ interior}\}$$</p>

<p>If one could use a continuous selection theorem to get a continuous selection of $F$ then it would be done. Unfortunately, I cannot show that, for example, $F$ has convex values to use Michael's selection theorem. </p>

<p>P.S. Of course evey locally pathwise connected set of $\mathbb {R}^2$ has (P). The current question is exactly the converse of that fact.</p>

<p>Any remark is greatly appreciated.</p>
",calculus
"<p>Given $f$ is function with continous derivatives, how do I obtain $f(x)$ in terms of $x$ from the equation below? Thanks in advance. </p>

<p>$$
f(x)=\lim_{t\to 0} \frac{1}{2t} \int_{x-t}^{x+t} s f'(s) ds
$$</p>
",calculus
"<p>Taylor expansion about $(x,y)$ of $f(x + a,\; y + k\; f(x + b,\; y + c))$</p>

<p>I do not understand what happens to the second $f$ inside. The inspiration for this question is Runge-Kutta methods.</p>
",calculus
"<blockquote>
  <p>If $x^2+ax-3x-(a+2)=0\;,$ Then $\displaystyle \min\left(\frac{a^2+1}{a^2+2}\right)$</p>
</blockquote>

<p>$\bf{My\; Try::}$ Given $x^2+ax-3x-(a+2)=0\Leftrightarrow ax-a = -(x^2-3x-2)$</p>

<p>So we get $$a=\frac{x^2-3x-2}{1-x} = \frac{x^2-2x+1+1-x-4}{1-x} = \left[1-x-\frac{4}{1-x}+1\right]$$</p>

<p>Now $$f(a) = \frac{a^2+1}{a^2+2} = \frac{a^2+2-1}{a^2+2} = 1-\frac{1}{a^2+2}$$</p>

<p>So $$f(x) = 1-\frac{1}{\left[(1-x)-\frac{4}{1-x}+1\right]^2+2}$$</p>

<p>Now put $1-x=t\;,$ Then we get $$f(t) =1- \frac{1}{\left(t-\frac{4}{t}+1\right)^2+2}$$</p>

<p>Now How can I maximize $\displaystyle \frac{1}{\left[(1-x)-\frac{4}{1-x}+1\right]^2+2, }\;,$ Help Required, Thanks</p>
",calculus
"<p>I'm trying to determine whether or not </p>

<blockquote>
  <p>$$\sum_{k=1}^\infty \frac{2+\cos k}{\sqrt{k+1}}$$ </p>
</blockquote>

<p>converges or not. </p>

<p>I have tried using the ratio test but this isn't getting me very far. Is this a sensible way to go about it or should I be doing something else?</p>
",calculus
"<blockquote>
  <p>Show, for $x_0=0$, that $\ln(\frac{1-x}{1+x})=-2\big[x+\frac{x^3}{3}+\dots+\frac{x^{2n-1}}{2n-1}+R_{2n}(f,0)(x)\big]$, with $$R_{2n}(f,0)(x)=-\frac{x^{2n+1}}{2n+1}\bigg(\frac{1}{(1+\theta x)^{2n+1}}+\frac{1}{(1-\theta x)^{2n+1}}\bigg)$$
  with $\theta\in(0,1)$</p>
</blockquote>

<p>I did already show the $-2\sum_{k=1}^n -\frac{x^{2k-1}}{2k-1}$ part, but I have struggle finding the Residual. We know that $$R_n=\frac{f^{n+1}(\theta)}{(n+1)!}(x-x_0)^{n+1}, \theta\in(x_0, x)$$</p>

<p>So, using the fact that $\ln(\frac{1-x}{1+x})=\ln(1-x)-\ln(1+x)$
and $\frac{d^n}{dx^n}\ln(1-x)=-\frac{(n-1)!}{(1-x_0)^n}$, $\frac{d^n}{dx^n}\ln(1+x)= (-1)^{n+1}\frac{(n-1)!}{(x+1)^n}$,</p>

<p>we obtain
$$R_{2n}(f,0)(x)=-\frac{x^{2n+1}}{2n+1}\bigg(\frac{1}{(1+\theta )^{2n+1}}+\frac{1}{(1-\theta)^{2n+1}}\bigg)\neq -\frac{x^{2n+1}}{2n+1}\bigg(\frac{1}{(1+\theta x)^{2n+1}}+\frac{1}{(1-\theta x)^{2n+1}}\bigg)$$</p>

<p>Could anyone explain me where I made a mistake?</p>
",calculus
"<p>Good morning, i have a problem when i go to calculate the partial sum of this series:</p>

<p>$S = 2+\frac{2}{3}+\frac{2}{9}+\frac{2}{27}+...+\frac{2}{3^{n-1}}$</p>

<p>I make this:</p>

<p>If this an geometric series then $a=2$ and $r=\frac{1}{3}$</p>

<p>then</p>

<p>$S={\displaystyle \sum_{i=1}^{n}2(\frac{1}{3}})^{i-1}$</p>

<p>but, i cannot calculate the partial sum, please help me!</p>
",calculus
"<blockquote>
  <p>I would like to know how to show that :
  $$\lim_{X \to -k}\:\prod_{j\neq k}\left(X+j \right)=(-1)^{k}k!\left(n-k \right).$$</p>
</blockquote>

<p>This is came from solution of exercise that he said :</p>

<ul>
<li>what is Partial fraction decomposition of :</li>
</ul>

<p>$$F(X)=\dfrac{n!}{\prod_{k=0}^{n}\left(X+k \right)}$$</p>

<p>indeed,</p>

<p>PFD of F:</p>

<p>$$F(X)=\sum_{k=0}^{n}\dfrac{a_k}{X+k} $$</p>

<p>$$\left(X+k\right)F(X)=\dfrac{n!}{\prod_{j\neq k}\left(X+j \right)}$$
and 
$$\prod_{j\neq k}\left(X+j \right)=(-1)^{k}k!\left(n-k \right)$$ then :</p>

<p>$$a_k=(-1)^{k}{n \choose k} $$</p>

<p>Finaly:</p>

<p>$$F(X)=\sum_{k=0}^{n}(-1)^{k}{n \choose k}\dfrac{1}{X+k} $$ </p>
",calculus
"<p>I am struggling to understand the derivation of an equation in a paper (<a href=""http://robots.stanford.edu/papers/diebel.surface.pdf"">A Bayesian Method for Probable Surface Reconstruction and Decimation</a>, specifically Eqn. 16). </p>

<p>Basically they define three vertices of a facet: $x_k, x_{k'},x_{k''}$ 
The normalized facet normal is defined as: $n_i = \dfrac{(x_{k'}-x_k) \times (x_{k''}-x_k)}{|(x_{k'}-x_k) \times (x_{k''}-x_k)|}$</p>

<p>So far so good. The problem is then that they need to compute $\frac{\partial n_i}{\partial x_k}$. Firstly ${n_i}$ and ${x_k}$ are both vectors, hence I'd expect that this partial derivative notation means in effect the Jacobian of ${n_i}$ wrt. ${x_k}$? In that case that is a 3x3 matrix. However the formula below (see Eqn 16) implies that the result is a 3x1 vector?? (confused!)</p>

<p>$\frac{\partial n_i}{\partial x_k} = \frac{I - n_in_i^T}{|(x_{k'} - x_k) \times (x_{k''} - x_k)|} (x_{k''} - x_{k'}) \times x_k$</p>

<p>I was hoping someone could shed some light on the dimensionallity confusion and also how that formula was derived, or if incorrect what is the correct forumation for $\frac{\partial n_i}{\partial x_k}$?  Thanks for the help!</p>
",calculus
"<p>What's the best way to evaluate an antiderivative like this one $$\int \frac{\sqrt{x-2}}{x+1}dx\ ?$$</p>

<p>I tried a $u$ substitution with $x-2$ and $x+1$ and neither got me a nicer looking integrand.  There are no squared terms so a trig sub doesn't leap out to me.  What's the way to do this?</p>
",calculus
"<p>I need advice on my studies of mathematics... I'm really depressed because it's impossible for me to understand many important parts of books such as Tenenbaum &amp; Pollard ""Ordinary Differential Equations"" or Kreyszig's ""Differential Geometry"", even after having got an A at a rigorous course in calculus (construction of the reals, limits with epsilon-delta arguments, proofs of almost all theorems presented...).</p>

<p>The reason is that these books on DE and DG use thinks like multiply the two sides of the equation by dx, or integrate dt, consider an infinitesimal displacement, etc, to arrive at conclusions... I really can't understand this reasonings... And I'm now looking at books on mechanics (for engineers) and it's even worse, because they talk about ""virtual work"", and other impossible-to-understand (for me) things...</p>

<p><strong>What should I do? Relearn calculus from some textbook that teach these things or maybe search other books for learning differential equations, mechanics, and differential geometry? I'm feeling really dumb.</strong></p>

<p>Thanks in advance.</p>
",calculus
"<p>I need to find the max of $$f(x)=\sqrt{(x^2-4)^2+(x-5)^2}-\sqrt{(x^2-2)^2+(x-1)^2}$$</p>

<p>When $x$ is a real number.</p>

<p>What i did is to simplify: $$f(x)=\sqrt{x^4-7x^2-10x+41}-\sqrt{x^4-3x^2-2x+5}$$.</p>

<p>Then i compute: $$f'(x)=\frac{-5-7x+2x^3}{\sqrt{41-10 x-7 x^2+x^4}}+\frac{1+3x-2x^3}{\sqrt{5-2 x-3 x^2+x^4}}$$.</p>

<p>But failed to solve $f'(x)=0$ for finding $f(x)_{max}$.</p>

<p>I would be glad for your help.</p>

<p>Thanks.</p>
",calculus
"<p>I am having a hell of time trying to differentiate the following function with respect to x. Do you have any suggestions</p>

<p>$f(x) = \frac{ w(i)^x}{  \sum\limits_{j} w(j)^x }$</p>

<p>where $w$ is a vector
Basically I don't get how to handle the vector in the denominator. Any help would be appreciated.</p>

<p>Thanks!</p>

<p>Also follow up: </p>

<p>$g(\hat{x}) = \sum\limits_{i} a* \hat{x}(i)$</p>

<p>what would be the derivative with respect to $\hat{x}$.</p>

<p>Again, thanks so much, I come from a CS background so still trying to wrap my head around the calculus of neural networks.</p>
",calculus
"<p>I'm having a bit of trouble with this problem. I tried writing down the first few terms explicitly but that doesn't seem to be working.</p>

<p>This is the sequence for when n is approaching infinity:</p>

<p>$\frac{25}{20^{n}} + 16\mathrm{arctan}(n^{6})$</p>
",calculus
"<p>The reason why I'm having trouble with this problem is because it involves natural log (ln) and I need to find the limit.</p>

<p>I need to find $\lim_{n\to\infty} \ln(3n+7)-\ln(n)$.</p>

<p>I noticed that as $n$ approaches infinity, $-\ln(n)$ should be approaching $-\infty$ but I'm having trouble finding the limit since $\ln(3n+7)$ is in the sequence.</p>
",calculus
"<p>In definition of limits why can't we have "" there exist delta for all epsilon"" instead of  "" for all epsilon there exist delta""</p>
",calculus
"<p>Normally I would just divide both sides by the number $4$ because it's not good in there, but I can't do it for </p>

<p>$$4x^2+y^2=1$$</p>

<p>I must have $$\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$$</p>

<p>So what's the easiest way?</p>
",calculus
"<p>How to prove whether there does exist a differentiable map $f: \mathbb{R}^{2} \rightarrow \mathbb{R}^{2}$ so that it maps the $X$-axis to the $ S = \{ (x, y): y=|x| \}$?</p>

<p>For example, i got an attempt to build something, which should looks like an example: 
$f(x) = \begin{cases} x &amp;\mbox{if } |x|&gt;\frac{1}{n} \\ 
x^{2}+\frac{n-1}{n^{2}}&amp; \mbox{if } |x| \le \frac{1}{n} \end{cases} $
Does this seem to be an appropriate one?</p>

<p>Any help would be much appreciated.</p>
",calculus
"<p>Compute the limit $\lim\limits_{n\to\infty}a_n$ for the following sequences:</p>

<p>(a) $a_n=e^{5\cos((\pi/6)^n)}$</p>

<p>(b) $a_n=\frac{n!}{n^n}$</p>

<p>For part (a) do I just take the limit of the exponent part and then the answer would be $e$ raised to whatever the limit is?</p>

<p>And would the limit be $1$ or $-1$? because $\cos$ goes between those two.</p>

<p>For part $b$ it is in the form of infinity over infinity but how do you take the derivative of $n!$? Will it ever break out of infinity over infinity?</p>
",calculus
"<p><img src=""http://i.stack.imgur.com/H0aEv.png"" alt=""enter image description here""></p>

<p>how do you determine if a series converges or diverges? Do you just look at their behavior?</p>
",calculus
"<p><img src=""http://i.stack.imgur.com/T6fxv.png"" alt=""enter image description here""></p>

<p>Compute the limit of the series $$\sum\limits_{n=4}^\infty 3\frac{2^{n+1}}{5^{n-2}}$$</p>

<p>How do you approach these types of problems?</p>

<p>I'm thinking that this one is in indeterminate form, is that correct?</p>
",calculus
"<p>Hey guys this was given to me as an exercise question and its really confusing. I'm not really sure where to start with this one, and I am assuming that the derivative isn't just $e^{-t^2}  dt$. Anyways, any help is appreciated, thank you!.</p>

<p>Find the derivative of $$\int \limits_x^{x^2} e^{-t^2}dt $$</p>
",calculus
"<p>I've got a complex equation with 4 roots that I am solving. In my calculations it seems like I am going through hell and back to find these roots (and I'm not even sure I am doing it right) but if I let a computer calculate it, it just seems like it finds the form and then multiplies by $i$ and negative $i$. Have a look: <a href=""http://www.wolframalpha.com/input/?i=%288%2asqrt%283%29%29/%28z%5E4%2b8%29=i"" rel=""nofollow"">http://www.wolframalpha.com/input/?i=%288*sqrt%283%29%29%2F%28z%5E4%2B8%29%3Di</a></p>

<p>Here's me going bald: <img src=""http://i.stack.imgur.com/oFE1P.jpg"" alt=""enter image description here""></p>
",calculus
"<p>So I'm trying to get this:</p>

<p><a href=""http://www.wolframalpha.com/input/?i=%288%2asqrt%283%29%29/%28z%5E4%2b8%29=i"" rel=""nofollow"">http://www.wolframalpha.com/input/?i=%288*sqrt%283%29%29%2F%28z%5E4%2B8%29%3Di</a></p>

<p>And I've calculated $z^4=16 \left( \cos (\frac{- \pi}{3})+ \sin ( \frac{- \pi}{3}) \right)$</p>

<p>So I'm trying to find the roots using the formula:</p>

<p>$ r^{1/n} = \left( \cos ( \frac { \theta + 2 \pi \cdot k}{n}) + i \cdot \sin ( \frac{ \theta + 2 \pi \cdot k}{n}) \right) $</p>

<p>But my result does not equal. Take a look:</p>

<p><a href=""http://www.wolframalpha.com/input/?i=16%5E%281/4%29%2a%28cos%28%28%28-pi/12%29%29/4%29%2bi%2asin%28%28%28-pi/12%29%29/4%29%29"" rel=""nofollow"">http://www.wolframalpha.com/input/?i=16%5E%281%2F4%29*%28cos%28%28%28-pi%2F12%29%29%2F4%29%2Bi*sin%28%28%28-pi%2F12%29%29%2F4%29%29</a></p>

<p>This is for $k=0$.</p>

<p>What am I doing wrong?</p>
",calculus
"<p>$$∂u/∂x + ∂u/∂y = 1,$$</p>

<p>$$u(x,0) = \mathrm{e}^x$$</p>

<p>My prof hasn't explained how to solve these very well.  I think it has something to do with the method of characteristics, but I'm not entirely sure what that is or how to employ it.  I'd really appreciate any help.  Thanks in advance.</p>
",calculus
"<p>I am working on the following calculus problem. Would you guys help me how to integrate the following function:</p>

<p>$$
\int^1_0 x^2\sin\left(\frac{\pi}{2}x^2\right)dx
$$</p>

<p>I was struggling to compute this. I really appreciate your help in advance.</p>
",calculus
"<p>I'm pretty sure the sum converges by Abel or Dirichelet, I just have no idea how to tackle the numerator. Any tips would be appreciated!</p>
",calculus
"<p>I have the following problem:</p>

<p>$$(t+2)dx=2x^2dt$$</p>

<p>First I divide both sides by $t+2$ to get:
$$dx = \frac {2x^2}{t+2}\,dt $$
Then, divide by $2x^2$ to gey:
$$\frac{dx}{2x^2}=\frac{dt}{t+2}$$
This will end up to:
$$\int \frac1{2x^2}dx=\int\frac{dt}{t+2}$$</p>

<p>From now on I am not sure how to continue! I ended up having this equation:
$$\frac 1 5 x^3 = \ln (t+2)+c$$</p>

<p>I need to find $x(t)$ now. Can somone help please?</p>

<p><strong>update</strong> 
This is how I got $\frac 1{5} x^3$:
I said because $\int \frac 1{2x^2}dx$ is $\frac 12 \int x^-2$</p>

<p>isnt it right?</p>
",calculus
"<p>Suppose that we have following second order differential equation
$$\frac{d^2y}{dx^2}-\frac{dy}{dx} = 2(1-x).$$
When I saw this  equation in the book, it was said that solution is of the form
$$y(x)=x(a_1+a_2 x).$$
My assumption about this is that because the right-hand side of the differential equation is the linear function $2(1-x)=2-2x$, it means  that a function $y(x)$ whose second and first derivative is linear must be  quadratic, or in other words
$$y(x)=ax^2+bx+c.$$
Is this right? I have posted this question because I wanted to be sure that my assumption is correct. Thanks guys.</p>
",calculus
"<p>A rectangular page is to have a printed area of 62 square inches. If the border is to be 1 inch wide on top and bottom and only 1/2 inch wide on each side find the dimensions of the page that will use the least amount of paper</p>

<p>Can someone explain how to do this?</p>

<p>I started with:</p>

<p>$$A = (x + 2)(y + 1) $$</p>

<p>Then I isolate y and come up with my new equation:</p>

<p>$$A = (x+2)\left(\frac{62}{x + 2}{-1}\right)$$    </p>

<p>Then I think my next step is to create my derivative, but wouldn't it come out to -1?</p>

<p>Anyways, I would appreciate if someone could give me a nudge in the right direction.</p>

<p><strong>EDIT</strong> </p>

<p>How does this look for a derivative?</p>

<p>$$A = \left(\frac{x^2-124}{x^2}\right)$$ </p>

<p>Then to solve:
$$ {x} = 11.1 $$ </p>

<p>$$ y = 98 / 11.1  $$</p>

<p>Does that seem about right?</p>

<p>If not, the only thing I would have left is setting it to 0 and solving.</p>
",calculus
"<blockquote>
  <p><strong>Proposition 3 (<a href=""http://www.ssc.wisc.edu/~bhansen/718/Anderson2003.pdf"" rel=""nofollow"">ABDL03</a>):</strong>
  If a special semimartingale process $X$ is square integrable with respect to the natural filtration of a standard Brownian motion $W$, then one can write</p>
  
  <p>$X_t - X_0 = \int_0^t \! \mu_u \, \mathrm{d}u + \int_0^t \! \sigma_u \, \mathrm{d}W_u$</p>
  
  <p>where $\mu,\sigma$ are predictable processes. </p>
</blockquote>

<p>(Note: I modified the statement of the proposition quite a bit.)</p>

<p>I know that if $X$ is a local martingale, this proposition holds with $\mu \equiv 0$. This is just the martingale representation theorem. </p>

<p><strong>Q:</strong> What if $X$ is a finite variation process? Does this proposition hold with $\sigma\equiv 0$? If so, can the sufficient condition of square integrability be relaxed? Is there some standard set of necessary and sufficient conditions for when one can write a finite variation process as $\int_0^t \! \mu_u \, \mathrm{d}u$ with $\mu$ predictable?</p>

<hr>

<p><strong>UPDATE #1:</strong></p>

<p><strong>Partial Answer:</strong> So, if the paths of $X$ are continuously differentiable and bounded on compacts (almost surely?) then by the fundamental theorem of calculus we can write </p>

<p>$X_t - X_0 = \int_0^t \mu_u \, \mathrm{d}u $</p>

<p>where $\mu$ is the continuous, bounded <strong>derivative</strong> of $X$ (almost surely?) with respect to $t$. </p>

<p><strong>Remaining Q:</strong> Have I done this right? Is the existence of a bounded, continuous derivative for the paths of $X$ (a finite variation process) necessary and sufficient for writing it as $\int_0^t \mu_u \, \mathrm{d}u$ with $\mu$ predictable?</p>

<hr>

<p><strong>UPDATE #2:</strong> We might be able to relax this to just <em>differentiable</em> (rather than <em>continuously differentiable</em>) since $X$ already has finite variation. </p>
",calculus
"<p>Akhil showed that the <a href=""http://math.stackexchange.com/questions/477/cardinality-of-set-of-real-continuous-functions/479#479"">Cardinality of set of real continuous functions</a> is the same as the continuum, using as a step the observation that continuous functions that agree at rational points must agree everywhere, since the rationals are dense in the reals.</p>

<p>This isn't an obvious step, so why is it true?</p>
",calculus
"<p>I'm looking for hints on how to efficiently solve this inequality:  $$\left( \frac {|x|-|1-x|}{|x|}  \right)^{2x-1}   \gt   \left(\frac {|x|-|1-x|}{|x|} \right)^{8-x} $$</p>
",calculus
"<p>A cylindrical tank with radius 5 cm is being filled with water at rate of 3 cm^3 per min. how fast is the height of the water increasing?</p>

<p>I dont want this question solved, but please help me correct my working out:</p>

<ul>
<li>radius = 5</li>
<li>dv/dt =  3</li>
<li>dh/dt = dh/dv * dv/dt</li>
<li>v=(pi)(r^2)(h)</li>
</ul>

<p>because r is constant you could write: V=(pi)(5^2)(h) and then find the derivative...</p>

<p>but is there an alternate method where we can derive dv/dh without first substituting r=5?? </p>
",calculus
"<p><img src=""http://i.stack.imgur.com/oK6Wy.png"" alt=""enter image description here""></p>

<p>Is there a simpler way of solving this then calculating</p>

<p>x1(h)+x2(h)+x3(h)+x4(h) by using the given y values (in this case h, the height is one, because the length of each rectangle is one) </p>

<p>because it could take a while if the heights were all different, and there were many more rectangles... is there a CAS (calculator/graphing) method... something more efficient.</p>

<p>Can you calculate L/R area approximation using a formula, without drawing the graph.. so imagine the graph wasn't part of the question... could you solve this alternatively with a formula?</p>

<p>Does anyone have an efficient method to solve L/R area approximation </p>
",calculus
"<p><img src=""http://i.stack.imgur.com/BMapu.png"" alt=""enter image description here""></p>

<p>long method: Determine an equation for each and solve using average value formula</p>

<p>alternative methods? </p>

<p>How could you prove the average value to be C over an interval [a,b] if you are given a graph.... looking for most efficient/unique methods. </p>
",calculus
"<p>If $f''(x)$ exists on $[a,b]$ and $f'(a)=f'(b)$, then :</p>

<p>$$f(\frac{a+b}{2})=\frac 1 2[f(a)+f(b)]+\frac{(b-a)^2}{8}f''(c)$$</p>

<p>for some $c\in(a,b)$.</p>

<p>I tried but was unable to think of a function and was unable to use the given condition except for Rolle's Theorem which does not yield anything useful(yet). </p>

<p>Any hints or help will be appreciated.</p>
",calculus
"<p>Applying the <a href=""http://mathworld.wolfram.com/CopsonsInequality.html"" rel=""nofollow"">Copson's inequality</a>, I found:
$$S=\displaystyle\sum_{k=1}^{\infty }\left(\Psi^{(1)}(k)\right)^2\lt\dfrac{2}{3}\pi^2$$ where
$\Psi^{(1)}(k)$ is the polygamma function.
Is it known any sharper bound for the sum $S$?
Thanks.</p>
",calculus
"<p>According to the fundamental theorem of calculus, if $f$ is continuous and $F$ is defined as $F(x)=\int_a^x f(t) dt$ then $F'=f$. But what happens if $x$ appears inside the integral? I'm trying to find the derivattive of</p>

<p>$$f(x)=\int_0^x \frac{e^{xy}}{y}dy$$</p>

<p>I read about the Libniz integral rule, but when I try to use it I get</p>

<p>$$\frac{df(x)}{x}=\int_0^x e^{xy} dy + \frac{e^{x^2}}{x}-\frac{1}{0}\cdot0$$</p>

<p>Is this because $\frac{e^{xy}}{y}$ is not defined when $y=0$? Also, is the Leibniz rule the only way to solve problems like this one?</p>
",calculus
"<p>Solve: $ 5&lt; \left\vert\dfrac{x+10}{x-10}\right\vert&lt;6$</p>

<p>attempt at a solution: </p>

<p>Dividing into two: </p>

<p>$5&lt;\left\vert \dfrac{x+10}{x-10}\right\vert  $     And  $\left\vert \dfrac{x+10}{x-10}\right\vert&lt;6  $ </p>

<p>For first we solve: 
 $ \dfrac{x+10}{x-10}&lt;-5  $  or $ \dfrac{x+10}{x-10} &gt;5  $  which yields $( -∞,15)$</p>

<p>For Second: </p>

<p>$  -6&lt;\dfrac{x+10}{x-10}  $  and $ \dfrac{x+10}{x-10} &lt;6  $  which yields $(14, ∞)$</p>

<p>intersecting the two we get $(14,15)$</p>

<p>This solution was deemed wrong by the text book. 
Is there any other way of solving this? Is there a mistake in this method of solution? </p>
",calculus
"<p>So there is a stool, the legs are apart from each other in a triangle fashion (isosceles triangle). The length between the points is 5 , 5 and 6.</p>

<p>We want to stabilise this shaky stool by putting wire between the legs, in an upside down Y fashion. (see image for clear example)<img src=""http://i.stack.imgur.com/0XXst.png"" alt=""enter image description here""></p>

<p>So This is how I tired to start:</p>

<p>1 said lets label the wire a,b,c.</p>

<p>a is the bit between the 5'st</p>

<p>$$height = \sqrt(34)$$ which is not useful.</p>

<p>$$area = 17.48$$</p>

<p>Can i assume that the wires are isosceles triangle since the legs form an isosceles triangle or is that a bit of a stretch? </p>
",calculus
"<p>Could anyone guide me step by step how to solve this problem or give me some pointers. I recently came across it and I can't seem to solve it. </p>

<p>Here's the entire problem: </p>

<p>Suppose that the function $f\colon\mathbb{R}\to\mathbb{R}$ is continuous at all real numbers $x,x\neq 0$, and satisfies the condition $\displaystyle \left\vert f(x)\right\vert \leq \frac{1}{\left\vert x\right\vert}$ for all $-1\leq x\leq 1$. Show that the function $g\colon\mathbb{R}\to\mathbb{R}$, given by $g(x)=x^2f(x)$, is continuous on $\mathbb{R}$.</p>

<p>Thank you. </p>
",calculus
"<p>Ok guys, I'm reading a book and I'm not getting quite well a concept.
If I have to expand $U'(Y_0(1+r_i))$ around $Y_0(1+r_f)$, why I get this:</p>

<p>$\mathbb{E}[U'(Y_0(1+r_i))(r_i-r_f)]=U'[Y_0(1+r_f)]\mathbb{E}(r_i-r_f)+U''[Y_0(1+r_f)]\mathbb{E}(r_i-r_f)^2Y_0$</p>

<p>Any step-by-step explanation would be greatly appreciated, since I can't get the same result by applying Taylor. Thanks in advance!</p>
",calculus
"<p>I know the answer is $-10$ but I don't know where the negative sign is coming from.</p>

<p>This is what I ended up with.    $$\frac{(x-25)(\sqrt{x}+5)}{x-25}   =  (1)\sqrt x+5 = 10
$$                                   </p>

<p>Like I said I'm not sure where the negative sign comes from.</p>
",calculus
"<p><a href=""http://i.stack.imgur.com/pyAeN.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/pyAeN.jpg"" alt=""enter image description here""></a></p>

<p>Not getting the right answer for this, can someone point me to where I'm going wrong? </p>
",calculus
"<p>Once upon a time, I memorized the following formula out of laziness. </p>

<p>Let $k(x)=\frac{f(x)^{g(x)}h(x)+i(x)}{j(x)}$. Then $k'(x)$ is as follows. </p>

<p>$k'(x)=\frac{j(x)(g(x)h(x)f(x)^{g(x)-1}f'(x)+f(x)^{g(x)}(h(x)log(f(x))g'(x)+h'(x)+i'(x))-j'(x)(h(x)f(x)^{g(x)}+i(x))}{j(x)^2}$</p>

<p>(as confirmed by <a href=""http://www.wolframalpha.com/input/?i=(f(x)%5Eg(x)h(x)%2Bi(x))%2Fj(x)"" rel=""nofollow"">wolframalpha</a>)</p>

<p>This was because I did not want to bother with logarithmic functions or the chain rule to find the derivatives of functions such as $x^{sin(x)}$</p>

<p>After some considerable time and effort, I had managed to memorize the formula. </p>

<p>However, I had trouble actually applying this formula to tests for $f'(x)$, mostly because the formula is too long and complicated, and started to wonder if I had wasted my time and effort. </p>

<p>This suspicions were heightened when I made several mistakes while using this formula. </p>

<p>Would memorizing such a formula actually prove useful for tests?</p>

<p>Any advice would be appreciated. </p>
",calculus
"<p>I have a question where I am asked to find the amount of terms required in a Maclaurin polynomial to estimate $\cos(1)$ to be correct to two decimal places.</p>

<p>So far what I have done is used Taylor's Theorem to get the follow:</p>

<p>$$|R_n(x)| = (|f^{(n)}*x^n|)/n! &lt; (x^n)/n! &lt; 0.005$$</p>

<p>I think so far this is my best attempt but I am not really sure how to proceed from this point to calculate a value of $n$. I did write out a Maclaurin polynomial for $f(x) = \cos(x)$ and attempt to see if I plugged numbers into that to see what came out and compare that to $\cos(1)$ but was unable to make any sense of my answers there.</p>

<p>I am not sure if I am on the right track here and any feedback would be greatly appreciated, </p>
",calculus
"<p>Given the following definite integral</p>

<p>$$\int_0^4 \left[\left(1/2x^2 - 2x +8\right)-\left(1/4x^2+x\right)\right]\;\mathrm dx$$
I have done in the following process.</p>

<p>$$\int_0^4 \left[\left(1/2x^2 - 2x +8\right)-\left(1/4x^2+x\right)\right]\;\mathrm dx$$
$$\implies \int_0^4 [1/4x^2 -3x+8)]\;\mathrm dx\\ \implies {{{{1\over 4}x^3}\over 3} - {3x^2\over 2} + 8x}\\ \implies {{16\over 3} - 24 + 16} \\ \implies {2{2\over 3}}$$
I didn't get the right answer. Is there any mistake in the process I have done.</p>
",calculus
"<p>I need help on problem based on integration calculus.</p>

<p>Q: how to integrate
$$\int\frac{dx}{1+\sin(x)\tan(x)}$$
Wolfram and integrate calculator does not help me.</p>
",calculus
"<p><img src=""http://i.stack.imgur.com/RfiTj.png"" alt=""enter image description here""></p>

<p>Hi! I am currently working on some calc2 online homework problems and I am having difficulty with this particular question. To be completely honest I am not sure how to even approach this problem, so if someone would be kind enough to help me solve this one I would really appreciate it, Thank you! </p>
",calculus
"<blockquote>
  <p>$$\lim_{x \to 0}x^x$$</p>
</blockquote>

<p>I know the answer is one but I have no idea how to get there.  I tried taking a natural log and I think I need lhopitals rule but I keep going In circles.</p>
",calculus
"<p>If $g$ is of rapid decrease, that is $\displaystyle\sup_{x\in\mathbb{R}}|x|^{l\geq 0}|g^{(k\geq 0)}(x)|&lt;\infty$, then we have: $$\displaystyle\sup_{x\in\mathbb{R}}|x|^{l\geq 0}|g^{(k\geq 0)}(x-y)|\leq A_{l,k}(1+|y|)^{l}$$
where $A_{l,k}\geq 0$ is a constant dependent on $l,k$.</p>

<p>How can I induce the above inequality? </p>
",calculus
"<p>I was working through a physics problem related to magnetic flux, but was confused at the math the solution uses. I understand up till the last line:</p>

<p>$
c=1.65-.12t\\
A=c^2/4\pi\\
\Phi_B=BA=(\frac{B}{4\pi})c^2\\
|\varepsilon|=|\frac{d\Phi_B}{dt}|=(\frac{B}{2\pi})c|\frac{dc}{dt}|
$</p>

<p>I'm unclear of the exact steps that allow this to go from $\frac{B}{4\pi}\frac{dc^2}{dt}$ to $(\frac{B}{2\pi})c|\frac{dc}{dt}|$</p>
",calculus
"<p>Suppose somebody is modeling a solution (or set of solutions) to a particular partial differential equation (Navier-Stokes maybe) via some software that makes use of some numerical method(s) to solve the partial differential equation. That software will 'converge' to a particular solution to the differential equation.</p>

<p>Shouldn't that be pretty much sufficient to show existence and uniqueness to that differential equation, given that the partial differential equation itself didn't involve any bad operations (dividing by zero maybe)? </p>

<p>I'm sure the answer is no, so what I'm really asking for is why not?</p>
",calculus
"<p>I want to show that $f(x)=e^{-x^2/4k}$ (where $k&gt;0$ is fixed) is continuous using an $\epsilon$,
$\delta$ argument. I've been trying to choose $\delta$ using $\ln$ somehow and I've also been trying to write $|f(x)-f(y)|$ in a form with $|x-y|$ in the exponent so that I can complete the proof, but I have gotten stuck. </p>
",calculus
"<p>The problem said:</p>

<blockquote>
  <p>A caterer must supply 110 napkins on Monday, 90 on Tuesday, 130 on
  Wednesday, and 170 on Thursday. The caterer initially has no napkins
  on hand. New napkins can be bought for 7 cents each. Used napkins can
  be laundered for use the next day at 4 cents/napkin or laundered for
  use in 2 days or more at 2 cents/napkin. At the end of the week, all
  used napkins have no value. How can the caterer meet these demands at
  minimal cost? (Hint> consider this as a transportation problem with
  four sources-the new-napkin outlet and the first 3 days' collections
  of used napkins.)</p>
</blockquote>

<p>I try to setup the tableu but I can't apply the algoritm to find the correct distribution due, I can not be able to figure out the correct supply and demand in each extrem of the tableau.</p>

<p>Below, is the my tableu so far:</p>

<p><a href=""http://i.stack.imgur.com/2YCNv.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/2YCNv.png"" alt=""enter image description here""></a></p>

<p>7 -cost of new napking
4- fast laundry
2- slow laundry</p>

<p>The minimal cost (show in book said): $22.4</p>

<p>I really apreciate any help, in set up this tablaeu.</p>
",calculus
"<p><a href=""http://i.stack.imgur.com/royGT.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/royGT.png"" alt=""enter image description here""></a></p>

<p>So the clinician I spoke to told me it should be a simple operation like 
$$(0.05)^n/n - 0.25^n &lt; .0001$$</p>

<p>Which gave me some the value .996 which is obviously a non-nonsensical answer for a  question asking how many terms of a series are necessary to essentially be accurate to the true value to 3 decimal places. How do I restart my effort of this problem? </p>
",calculus
"<p>The following is the graph of $y=\cos10x+\cos21x$.<a href=""http://i.stack.imgur.com/FJkSY.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/FJkSY.jpg"" alt=""enter image description here""></a></p>

<p>You can see that there seems to be four curves that can touch this graph. I tried $y=\cos(x/2+\pi/2\pm\pi)+1$ and $y=-\cos(x/2\pm\pi/2)-1$:
<a href=""http://i.stack.imgur.com/brVkZ.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/brVkZ.jpg"" alt=""enter image description here""></a></p>

<p>But unfortunately, they cut the graph. What actually are that four curves touching the graph? Thanks.</p>
",calculus
"<p>I am trying to show explicitly that the partial sums (for the series $\sum \frac{1}{j(j+1)}$ from j=1 to $\infty$) converge. Would it be sufficient to say that by looking at $\sum \frac{1}{j(j+1)}$ = $\frac{1}{j}-\frac{1}{j+1}$ and $\frac{1}{j}-\frac{1}{j+1} \rightarrow 0$ as $j \rightarrow \infty$? </p>

<p>There is a theorem in the book that says that if $\sum a_j$ converges, then $a_j \rightarrow 0$ as $j \rightarrow \infty$, but I dont know if this is an iff condition that holds the other way.</p>
",calculus
"<p>Show that if $\int_0^1 h(x)\cos(n \pi x)dx=0$, $n=1,2,\ldots$, then $h(x)$ is constant.</p>

<p>I know that if the index $n$ starts with zero then $h(x)$ is a zero function since in that case the system of function $\{\cos(n \pi x)\}_{n=0}^\infty$ is an complete orthormal system in $L_2$. However, in the question the system of function is $\{\cos(n \pi x)\}_{n=1}^\infty$ and not a complete system. </p>
",calculus
"<p><strong>Somos's quadratic recurrence constant</strong></p>

<p>The Somos's Quadratic recurrence constant is defined by the sequence $g_n=ng_{n-1}$ with initial value of $ g_0= 1$</p>

<p>The value of $\sigma=1.661687...$</p>

<p>An infinite product from maths world $\sigma=\prod_{k=1}^{\infty}k^{\frac{1}{2^k}}$</p>

<p>We found another infinite product involving the factorial numbers by experiments on a sum calculator.</p>

<p>$$\sigma=\prod_{n=1}^{\infty}(n!)^{\frac{1}{2^{n+1}}}$$
Where n! is valid for non-negative integers and defined by</p>

<p>$n!=n(n-1)(n-2)\cdots2\cdot1$</p>

<p>Can somebody help us to prove this </p>
",calculus
"<p>In <a href=""http://math.stackexchange.com/a/1776286/72031"">this answer</a> I established the following characterization of $\exp(x)$:</p>

<p><em>If $f:\mathbb{R} \to \mathbb{R}$ is a function such that</em></p>

<ul>
<li><em>$f(x) \geq 1 + x$ for all $x \in \mathbb{R}$</em></li>
<li><em>$f(x + y) = f(x)f(y)$ for all $x, y \in \mathbb{R}$</em></li>
</ul>

<p><em>then $f(x) = \exp(x)$.</em></p>

<p>Actually I established in the linked answer that $f(0) = 1, f'(0) = 1$ and this implies $f'(x) = f(x)$ so that the characterization of $f$ as the exponential function is complete.</p>

<p>Similarly it can be proved that the following characterization for $\log x$ holds:</p>

<p><em>If $g: \mathbb{R}^{+} \to \mathbb{R}$ is a function such that</em></p>

<ul>
<li><em>$g(x) \leq x - 1$ for all $x \in \mathbb{R}^{+}$</em></li>
<li><em>$g(xy) = g(x) + g(y)$ for all $x, y \in \mathbb{R}^{+}$</em></li>
</ul>

<p><em>then $g(x) = \log x$.</em></p>

<p>These characterizations don't mention anything about continuity or differentiability and instead rely on inequalities and the functional equation. </p>

<blockquote>
  <p>Do we have any other characterizations of exponential and logarithmic functions which don't rely on analytic properties (continuity, derivatives etc) and instead rely on properties which are purely algebraic in nature?</p>
</blockquote>

<p>I am thinking of monotone nature. If we augment the functional relation with the requirement that the function is strictly increasing on its domain, will it be sufficient to determine the functions $f, g$ uniquely? I guess it does not work. The function $f(x) = a^{x}$ with $a &gt; 1$ is strictly monotone and satisfies the functional equation, so we still don't get uniqueness. My bad!</p>
",calculus
"<p>I need to find the sum of an alternating series correct to 4 decimal places. The series I am working with is: $$\sum_{n=1}^\infty \frac{(-1)^n}{4^nn!}$$ So far I have started by setting up the inequality: $$\frac{1}{4^nn!}&lt;.0001$$Eventually I arrived at $$n=6$$ giving the correct approximation, which is approximately equal to $$\frac{1}{2,949,120}$$ But this is not the answer WolframAlpha gets.</p>
",calculus
"<p>The problem states:
Let $f(x),g(x)$ be Riemann integrable over $[a,b]$.
Define $h:[a,b]\rightarrow\mathbb{R}$ as:
$$h(x)=\max(f(x),g(x))$$</p>

<p>Prove that $h(x)$ is Riemann integrable over [a,b]</p>

<p>-I know that because $f$ and $g$ are integrable, then:</p>

<p>$\forall \epsilon&gt;0$, there exists a partition P so that: $U(f,P)-L(f,P)&lt;\epsilon$</p>

<p>$\forall \epsilon\prime&gt;0$, there exists a partition P$\prime$ so that: $U(g,P\prime)-L(g,P\prime)&lt;\epsilon\prime$</p>

<p>I also know that: $maxf(x)\le\sup f(x)$ and $maxg(x)\le\sup g(x)$ where both functions are defined.</p>

<p>Any hints on how should Iaproach this proof? Thanks</p>
",calculus
"<p>Use implicit differentiation to determine $\frac{\partial z}{\partial x}$ in $yz=ln(x+z)$ and $ \sin(xyz)=x+2y+3z$.</p>

<p>Here is my answer:</p>

<p>$$ yz=ln(x+z) $$
$$ yz'=(1+z')\frac{1}{x+z} $$
$$ z' = \frac{1}{yx+yz-1} $$</p>

<p>and</p>

<p>$$ \sin(xyz)=x+2y+3z $$
$$ y(z+xz')\cos(xyz)=1+3z' $$
$$ yz\cos(xyz)+xyz'\cos(xyz) = 1+3z' $$
$$ yz\cos(xyz) - 1 = z'(3-xy\cos(xyz)) $$
$$ z' = \frac{yz\cos(xyz) - 1}{3-xy\cos(xyz)} $$</p>

<p>is that right?</p>
",calculus
"<p>three questions about integrals for you.</p>

<p>1)'Given that f(x) is even on $R$, show that $F(x) = \int^x_0f(t)dt $ is odd.'</p>

<p>Was I right in doing the following:
 Given that $f(x)$ exists, this implies that $f(-x)$ exists (symmetry along $y$ axis). Due to this, $$\int^x_0 f(t) dt = \int^0_{-x}f(t)\, dt$$  </p>

<p>which implies</p>

<p>$$\int^x_0 f(t) \, dt = -\int^{-x}_0 f(t) \,dt$$</p>

<p>Thus,</p>

<p>$$F(x) = -F(-x)$$</p>

<p>which shows an odd function.</p>

<p>2) 'Given that $f(x) \le g(x)$ on $[a,b]$, show that $\int_a^b f(x)\,dx \le \int_a^bg(x)\,dx$ using the Riemann definition of a definite integral.'</p>

<p>First I stated the definition: </p>

<p>$$\lim_{x\to \infty} \sum_{i=1}^n f(x^*)\,\Delta x_i$$</p>

<p>At this point I sorta bs'd my way through it. Since $f(x) \le g(x)$ on $[a,b]$, the height of the rectangles (of $f(x)$) forming the area under $f(x)$ will always be less than or equal to the height of the rectangles (of $g(x)$) forming the area under $g(x)$. Therefore, this will ensure that the sum of the areas of the rectangles of $f(x)$ will always be less than or equal to the sum of the areas of the rectangles of $g(x)$, thus making the entire area under $f(x)$ $\le$ to that of $g(x)$.</p>

<p>3) 'Differentiate $\int^x_a\sec^2t \, dt$'</p>

<p>I used the FTC1 which states that $F'(x) = f(x)$ when $F(x)$ is an integral function. After some differentiating I got $\sec^2x$ I believe. </p>

<p>I'm not sure that's correct, but it's my best guess. </p>

<p>Thanks for your help.</p>
",calculus
"<p>Evaluate all first order partial derivative of $f(x,y,z)=x^\frac{y}{z}$</p>

<p>Here is my attempt:</p>

<p>$y$ and $z$ are constant, so we use the power rule to evaluate $f_x$:
$$ f_x = \frac{y}{z}x^{\frac{y-z}{z}}$$</p>

<p>since for any positive constant $c$ the derivative of $f(x)=c^x$ is $f'(x)=c^x \ln c$, we have:</p>

<p>$$ f(x,y,z) = (x^\frac{1}{z})^y \implies f_y = x^\frac{y}{z}\ln x^\frac{1}{z} $$</p>

<p>if we write $g(x)=\frac{1}{x}$ and $h(x)=c^x$ we have that $(h(g(x)))'=g'(x)h'(g(x)) = \frac{-1}{x^2}c^\frac{1}{x}\ln (c)$ by the chain rule. Combining this argument with the previous one we have:</p>

<p>$$f_z = \frac{-1}{z^2}(x^y)^\frac{1}{z}\ln(x^y)$$</p>

<p>of course we can simplify these expressions.</p>

<p>Is my solution right?</p>
",calculus
"<p>SO I am trying to figure out the points of intersection from the interval <strong>0 to pi/2</strong> and mathematically, I set both equations equal to one another and solved for x.</p>

<p>I did $$cosx = sin2x$$ and then got $$1/2 = sinx$$ which gave me $$pi/6$$
This is not completely right, since in the book, it says there are two points of intersection and the one I am missing is $$pi/2$$. How do I get that point without graphing?</p>
",calculus
"<p>I need help finding the length of the curve represented by the following relation:
$$x = 5\,cos^3\theta; y = 5\,sin^3 \theta$$</p>

<p>Here is what I've tried:
$$s = \int_0^{2\pi} \sqrt{(\frac{d\theta}{d\theta})^2 + (\frac{d\theta}{d\theta})^2}\,d\theta$$
$$\frac{d\theta}{d\theta} = -15\,sin\theta\,cos^2\,\theta$$
$$\frac{dy}{d\theta} = 15\,sin^2\theta\,cos\,\theta$$</p>

<p>Plugging in,</p>

<p>$$s = \int_0^{2\pi} \sqrt{(-15\,sin\theta\,cos^2\,\theta)^2 + (15\,sin^2\theta\,cos\,\theta)^2}\,d\theta$$
$$s = \int_0^{2\pi} \sqrt{225\,sin^2\,\theta\,cos^4\,\theta + 225\,sin^4\,\theta\,cos^2\,\theta}\,d\theta$$
$$s = \int_0^{2\pi} \sqrt{225\,sin^2\,\theta\,cos^2\,\theta\,(cos^2\,\theta + sin^2\,\theta)}\,d\theta$$
$$s = \int_0^{2\pi} \sqrt{225\,sin^2\,\theta\,cos^2\,\theta}\,d\theta$$
$$s = \int_0^{2\pi} 15\,sin\,\theta\,cos\,\theta\,d\theta$$
$$s = 15\,\int_0^{2\pi} \,sin\,\theta\,cos\,\theta\,d\theta$$</p>

<p>And there I am stumped... The textbook says that the answer should be 30, and my graphing application corroborates that number. I know I can't get to 30 from here. What am I doing wrong?</p>
",calculus
"<p>I have this scenario:</p>

<blockquote>
  <p>1 animal with 30% probability of be moved to Japan. <br> 1 animal with
  30% probability of be moved to Japan. <br> 1 animal with 30%
  probability of be moved to Japan. <br> 1 animal with 30% probability
  of be moved to Japan. <br> 1 animal with 30% probability of be moved
  to Japan. <br> 1 animal with 30% probability of be moved to Japan.
  <br> 1 animal with 30% probability of be moved to China. <br> 1 animal
  with 30% probability of be moved to Japan. <br> 1 animal with 80%
  probability of be moved to Brazil. <br> 1 animal with 30% probability
  of be moved to Japan. <br> 1 animal with 20% probability of be moved
  to Brazil. <br> 1 animal with 30% probability of be moved to Japan.
  <br> 1 animal with 50% probability of be moved to Mexico. <br> 1
  animal with 30% probability of be moved to Japan. <br> (...)</p>
</blockquote>

<p>Resuming, 10 animals with 30% of probability of being moved to Japan.</p>

<p>Is that ""right"" to expect that 3 animals gonna be moved to Japan?</p>

<p>The formula is:
30/100 * 10 = 3</p>

<p>Can I use <strong>Binomial Distribution</strong> for this scenario?
If yes, how to elaborate the formula?</p>

<p>Thanks a lot!</p>
",calculus
"<p>The velocity $v$ of blood that flows in a blood vessel with radius $R$ and length $L$ at a distance $r$ from the central axis is
$$v(r) = \frac{P}{4\eta L}(R^2 − r^2)$$
where $P$ is the pressure difference between the ends of the vessel and $\eta$ is the viscosity of the blood (See Example.). Find the average velocity (with respect to $r$) over the interval $0 \leq r \leq R$. </p>

<p>$v_{\text{ave}} =$______</p>

<p>Compare the average velocity $v_{\text{ave}}$ with the maximum velocity $v_{\text{max}}$.</p>

<p>$\dfrac{v_{\text{ave}}}{v_{\text{max}}}=$_____</p>

<p>This problem is driving me crazy, I understand average value and have no problem with solving average value problems.  However I do not know what the question is asking of me, I have tried many different answers on web assign with no luck.</p>

<p>I am given a link to an explanation of blood velocity with an example in it giving me numbers $R=.008~\text{cm}$, $L= 2~\text{cm}$, $\eta =.027$ and $P =4000~\frac{\text{dynes}}{\text{cm}^3}$ and an example radius of $r =.002~\text{cm}$.  </p>

<p>Thank you for any help.</p>
",calculus
"<p>The problem is an alternating series, that looks like this:
<img src=""http://i.stack.imgur.com/PgGWG.png"" alt=""Alternating series""> </p>

<p>I am given the series:
<img src=""http://i.stack.imgur.com/jk5KX.png"" alt=""Given series""></p>

<p>The book mentions the Alternating Series Estimation Theory, however it seems like there is a definite answer by the wording of the question.</p>
",calculus
"<blockquote>
  <p>Assume that the sequence ${a_n}$ is defined recursively by $a_{n+1} = \sqrt{3a_n + 1}$ for all $n \in \mathbb N$, with $a_1 = 1$. Use mathematical induction to prove that $a_n \leq a_{n+1}$ for all $n \in \mathbb N$.</p>
</blockquote>

<p>I've gotten most of the way, but I need help with the last bit. I've proven the base case, and gotten as far as:</p>

<p>Assume $P(k)$ is true. That is, $a_k \leq a_{k+1}$ for any $k \in \mathbb N$.
Prove $P(k+1)$. That is, $a_{k+1} \leq a_{k+1+1}$.</p>

<p>And now I'm stuck.  </p>
",calculus
"<blockquote>
  <p>I'm asked to find the equation of plane satisfying the given conditions:</p>
  
  <ul>
  <li>Passing through the line given by:
  \begin{cases}
x+y=2 \\
y-z=3
\end{cases}</li>
  <li>Perpendicular to the plane:
  $$
2 x+3 y+4 z=5
$$
  Knowing that the normal to the plane is 
  $2 i+3 j+4 k$</li>
  </ul>
</blockquote>

<p>I would have hade no problems finding this out if I was given the point. However I am not able to figure it out.
My first tought was to find the point where these lines intersect and then use this point to create the plane with these coinditions, 
$$
x+y-2=y-z-3\Rightarrow z=-x-1
$$</p>

<p>Which I could have expected since I am dealing with tree variables. </p>

<p>Now how could I solve this?</p>

<p>Answer should be $x+6 y-5 z=17$</p>
",calculus
"<p>$\displaystyle \lim_{x\to 7^-} \frac{\left|x-7\right|}{x-7} = $</p>

<p>Writing absolute value as:</p>

<p>$x-7 &gt; 0$</p>

<p>$x &gt; 7$</p>

<p>which means</p>

<p>$x - 7$ when $x &gt; 7$</p>

<p>then:</p>

<p>$ -(x - 7) &lt; 0$</p>

<p>$-x + 7 &lt; 0$</p>

<p>$-x &lt; - 7$</p>

<p>$x &gt; 7$</p>

<p>which means</p>

<p>$-x + 7 $ when $x &gt; 7$</p>

<p>So when $x &gt; 7$ what equation should I use?</p>

<p>$x - 7$ </p>

<p>or </p>

<p>$-x + 7 $</p>
",calculus
"<p>Please calculate $$I=\int_0^1 dx \int_0^x dy \int_0^y \frac{\sin z}{(1-z)^2}dz$$</p>

<p>Any hints? Thank you!</p>
",calculus
"<blockquote>
  <p>$$ \ln(Y) = \ln(A) + \frac{\ln[\alpha K^\gamma + (1-\alpha) L^\gamma]}{\gamma}$$</p>
  
  <p>can be taken to the limit by applying l'Hôpital's rule:</p>
  
  <p>$$\lim_{\gamma\rightarrow 0} \ln(Y) = \ln(A) + \alpha \ln(K) + (1-\alpha) \ln(L).$$</p>
</blockquote>

<p>I am not sure how l'Hopital's rule was used - differentiating by $\gamma$ produces some weird results.</p>
",calculus
"<p>prove that
$$\int_{0}^{\infty}\sin{x}\sin{\sqrt{x}}dx=\dfrac{\sqrt{\pi}}{2}\sin{\left(\dfrac{3\pi-1}{4}\right)}$$</p>

<p>I have some question,use the <a href=""http://www.wolframalpha.com/input/?i=%5Cint_%7B0%7D%5E%7B%5Cinfty%7Dsinxsin%28sqrt%28x%29%29dx"" rel=""nofollow"">http://www.wolframalpha.com/input/?i=%5Cint_%7B0%7D%5E%7B%5Cinfty%7Dsinxsin%28sqrt%28x%29%29dx</a></p>

<p>find this integral is not converge,I'm wrong?
Thank you everyone</p>
",calculus
"<p>I need to evaluate:<br>
$$\lim_{x \to 0} \left( \frac{\ln (\cos x)}{x\sqrt {1 + x}  - x} \right)$$</p>

<p>Now, it looked to me like a classic <a href=""http://en.wikipedia.org/wiki/L&#39;H%C3%B4pital&#39;s_rule"" rel=""nofollow"">L'Hôpital's rule</a> case. Indeed, I used it (twice), but then things became messy and complicated.  </p>

<p>Am I missing the point of this exercise? I mean, there must be a ""nicer"" way.
Or should I stick with this road?</p>

<h2>EDIT:</h2>

<p>Regarding Yiorgos's answer: Why is the following true? 
$$\ln\left(1- {x^2 \over 2}\right) \approx -{x^2 \over 2}$$</p>
",calculus
"<p>I make a big fuss that my calculus students provide a ""continuity argument"" to evaluate limits such as $\lim_{x \rightarrow 0} 2x + 1$, by which I mean they should tell me that $2x+1$ is a polynomial, polynomials are continuous on $(-\infty, \infty)$, and therefore $\lim_{x \rightarrow 0} 2x + 1 = 2 \cdot 0 + 1 = 1$.</p>

<p>All the examples they encounter where it is <em>not</em> correct to simply evaluate at $a$ when $x \rightarrow a$ fall into one of two categories:</p>

<ul>
<li>The function is not defined at $a$.</li>
<li>The function is piecewise and expressly constructed to have a discontinuity at $a$.</li>
</ul>

<blockquote>
  <p>I'd like to find a function $f$ with the following properties:</p>
  
  <ul>
  <li>$f(a)$ exists</li>
  <li>$f(a)$ is not (obviously) piecewise defined</li>
  <li>$f(x)$ is not continuous at $a$</li>
  <li>$f$ is reasonably familiar to a Calculus I student - trigonometry would be admissible, but power series would not (though they might
  still make for interesting reading)</li>
  </ul>
</blockquote>

<p>The best example I know is $f(x) = \frac{|x|}{x}$, but the natural definition of $|x|$ is essentially piecewise ($\sqrt{x^2}$ is cheating).</p>
",calculus
"<p>You are standing on a cliff at a height $h$ above the sea. You are capable of throwing a stone with velocity $v$ at any angle $a$ between horizontal and vertical. What is the value of $a$ when the horizontal distance travelled $d$ is at a maximum?</p>

<p>On level ground, when $h$ is zero, it's easy to show that $a$ needs to be midway between horizontal and vertical, and thus $\large\frac{\pi}{4}$ or $45°$. As $h$ increases, however, we can see by heuristic reasoning that $a$ decreases to zero, because you can put more of the velocity into the horizontal component as the height of the cliff begins to make up for the loss in the vertical component. For small negative values of $h$ (throwing up onto a platform), $a$ will actually be greater than $45°$.</p>

<p>Is there a fully-solved, closed-form expression for the value of $a$ when $h$ is not zero?</p>
",calculus
"<p>How do we know if a particular function can be represented as a power series? And once we have come up with a power series representation, how does one figure out its radius of convergence ?</p>
",calculus
"<p>When differentiated with respect to $r$, the derivative of $\pi r^2$ is $2 \pi r$, which is the circumference of a circle.</p>

<p>Similarly, when the formula for a sphere's volume $\frac{4}{3} \pi r^3$ is differentiated with respect to $r$, we get $4 \pi r^2$.</p>

<p>Is this just a coincidence, or is there some deep explanation for why we should expect this?</p>
",calculus
"<p>I am working on computing phase diagrams for alloys.  These are
blueprints for a material that show what phase, or combination of
phases, a material will exist in for a range of concentrations and
temperatures (see <a
href=""http://web.cos.gmu.edu/~tstephe3/talks/SIAMMaterialsScience2010.pdf"" rel=""nofollow"">this
pdf presentation</a>).  </p>

<p>The crucial step in drawing the boundaries that separate one phase
from another on these diagrams involves minimizing a free energy
function subject to basic physical conservation constraints.  I am
going to leave out the chemistry/physics and hope that we can move forward
with the minimization using Lagrange multipliers. </p>

<p>The free energy that is to be minimized is this:</p>

<p>$\widetilde{G}(x_1, x_2) = f^{(1)}G_{1}(x_1) + f^{(2)}G_{2}(x_2),$</p>

<p>subject to:</p>

<p>$f^{(1)}x_1 + f^{(2)}x_2 = c_1,$</p>

<p>$f^{(1)} + f^{(2)} = 1. $</p>

<p>(and also that the $x_{i} > 0$ and $f^{(i)} > 0$, for $i=1,2$.)</p>

<p>The Lagrange formulation is:</p>

<p>$L(x_1,x_2,f^{(1)},f^{(2)},\lambda_1, \lambda_2, \lambda_3) =
f^{(1)}G_{1}(x_1) + f^{(2)}G_{2}(x_2)$  </p>

<p>$- \lambda_{1}(f^{(1)}x_1 + f^{(2)}x_2 - c_1)$</p>

<p>$- \lambda_{2}(f^{(1)} + f^{(2)} - 1) $</p>

<p>The minimization of $\widetilde{G}$ follows from finding the $x_{i}$'s  that satisfy $\nabla L = 0:$</p>

<p>$\frac{\partial L}{\partial x_{1}}   = f^{(1)}G_{1}'(x_1) - \lambda_{1}f^{(1)} = 0$</p>

<p>$\frac{\partial L}{\partial x_2}     = f^{(2)}G_{2}'(x_2) - \lambda_{1}f^{(2)} = 0$</p>

<p>$\frac{\partial L}{\partial f^{(1)}} = G_{1}(x_1) - \lambda_{1}x_{1} - \lambda_2 = 0$</p>

<p>$\frac{\partial L}{\partial f^{(2)}} = G_{2}(x_2) - \lambda_{1}x_{2} - \lambda_2 = 0$</p>

<p>which yields:</p>

<p>$(*) f^{(1)}\left[G_{1}'(x_1) - \lambda_1 \right] = 0$       </p>

<p>$(**) f^{(2)}\left[G_{2}'(x_2) - \lambda_1 \right]= 0 $       </p>

<p>$(***) G_{1}(x_1) - G_{2}(x_2) = \lambda_1 \left[ x_1 - x_2\right]$ </p>

<p>Because $f^{(1)}$ and $f^{(2)}$ are not to be zero, from (*) and (**) we have that </p>

<p>$G_{1}'(x_1) = G_{2}'(x_2) = \lambda_{1}.$</p>

<p>And, a manipulation of equation (***) looks like </p>

<p>$\frac{G_{1}(x_1) -G_{2}(x_2)}{x_1 - x_2} = \lambda_{1}.$</p>

<p>Now, think of $G_{i}$ as an even degree polynomial (which it isn't, but
it's graph sometimes resembles one) in the plane.  Let the points $x_1$
and $x_2$ be locations along the x-axis that lie roughly below the
minima of this curve.  The constraints (*),(*<em>), and (*</em>*) describe the
condition that the line drawn between $(x_1,G_{1}(x_1))$ and $(x_2,G_{2}(x_2))$ form a common tangent
to the ""wells"" of the curve.  It is these points $x_1$ and $x_2$,
which represent concentrations of pure components in our alloy, that
become mapped onto a phase diagram.  It is essentially by repeating this procedure for many
temperatures that we can trace out the boundaries in the desired phase diagram.</p>

<p><strong>The question is:</strong>  Looking at this from a purely analytic geometry
perspective, <strong>how would one derive the ""variational"" approach to find a common tangent line that we seem to have found using the above Lagrangian?</strong>  (warning: I don't really know how to
model things using variational methods.)  </p>

<p><strong>And, secondly:</strong> I have presented a model of a binary alloy, meaning
two variables to keep track of representing concentrations.  I have
been working on ternary alloys, where this free energy $\widetilde{G}$
is a function of three variables (two independent: $x_1,x_2,x_3$,
where $x_3 = 1- x_1 - x_2$) and is therefore a surface over a Gibbs
triangle.  Then $\nabla L = 0$ produces partial derivatives that no
longer ""speak geometry"" to me, although the solution is a common tangent
plane.  (I have attempted to characterize a common tangent plane
based purely in analytic geometry - completely disregarding the
Lagrangian - and have come up with several relations between
directional derivatives... <strong>How might directional derivatives relate
to the optimality conditions set forth by the Lagrangian?</strong>)</p>

<p><strong>EDIT:</strong>  Thank you Greg Graviton for wading through this sub-optimal notation and pointing out several mistakes in the statement of the problem.  (Also, thank you for the <a href=""http://math.stackexchange.com/questions/632/validating-a-mathematical-model-lagrange-formulation-and-geometry/1245#1245"">excellent discussion below</a>.)</p>
",calculus
"<p>I just came back from my Introduction to Rotational Kinematics class, and one of the important concepts they described was <em>Rotational Inertia</em>, or <em>Moment of Inertia</em>.</p>

<p>It's basically the equivalent of mass in Netwon's $F = m a$ in linear motion.  The equivalent rotational equation is $\tau = I \alpha$, where $\tau$ is rotational force, $\alpha$ is rotational acceleration, and $I$ is rotational inertia.</p>

<p>For a point about an axis, $I$ is $m r^2$, where $r$ is the distance from the point to the axis of rotation.</p>

<p>For a continuous body, this is an integral -- $I = \int r^2 \,dm$.</p>

<p>This really doesn't make any sense to me...you have two independent variables?  I am only used to having one independent variable and one constant.  So I would solve this, using my experience with calculus (which encompasses a read through the Sparks Notes packet) as $ I = m r^2 $</p>

<p>But obviously, this is wrong?  $r$ is not a constant!  How do I deal with it?  Do I need to replace $r$ with an expression that varies with $m$?  But how could $r$ possibly vary with $m$?  Isn't it more likely the other way around?  But how can $m$ vary with $r$?  It's all rather confusing me.</p>

<p>Could someone help me figure out what to do with all these substitutions for, example, figuring out the Moment of Inertia of a hoop with no thickness and width $w$, with the axis of rotation running through its center orthogonal to its plane?</p>
",calculus
"<p>For equation below:</p>

<p>$$(t+1) \, dx=4(x+4) \, dt$$</p>

<p>After separation  I ended up with:</p>

<p>$$(x+4)dx = \frac 4{t+1}dt $$</p>

<p>Resulting in:</p>

<p>$$\int x+4 \,dx = 4 \int \frac 1{t+1} \,dt$$</p>

<p>So:</p>

<p>$$\frac 12 x^2  + 4x + C = 4\ln(t+1) + C$$</p>

<p>Now I have to express this as $x(t)$ and I have no clue how to. Also I am not sure if I did the above steps correctly. Any help will be appriciated!</p>

<p><strong>UPDATE</strong></p>

<p>As gerry pointed my mistake now I have:</p>

<p>$$ \int \frac {1}{x+4}\,dx = 4\int \frac{1}{t+1}\,dt  $$</p>

<p>Then:</p>

<p>$$ \ln(x+4) = 4 \ln(t+1) + C$$</p>

<p>Still not able to express this as x(t)...how to?!</p>
",calculus
"<p>Find the point on the line $y = x + 2$ that is nearest to the point $(1,1)$. The shortest distance from point to point.</p>

<p>I honestly don't even know where to begin with this one.</p>
",calculus
"<p>I am scratching my head to figure out a way to separate variables of the following equation:</p>

<p>$$(t+3)(t-2)dx = (t+tx^2)dt$$</p>

<p>Doesn't matter how many times I divide and multiply, I always get $x$ and $t$ on one side. Is there a trick applicable here?!</p>
",calculus
"<p>I'm trying to find the area in the curve $r^2=2\cos \theta$ and out of $r=2(1-\cos \theta)$</p>

<p>The intersections are at $\theta=\frac{\pi}{3}$ and $\theta=\frac{-\pi}{3}$, then, the integral to find the area is:</p>

<p>$$A=\frac{1}{2} \int_{\frac{-\pi}{3}}^{\frac{\pi}{3}} (\sqrt{2 \cos{\theta}})^2-(2-2\cos{\theta})^2  d\theta=9\sqrt{3}-4\pi$$</p>

<p>Using the result that the area of ​​a region in polar coordinates is given by:</p>

<p>$$\frac{1}{2} \int_{\theta_1}^{\theta_2} (f(\theta))^2 d\theta$$</p>

<p>Is this correct?</p>

<p>Thanks for your help.</p>
",calculus
"<p>I don't understand why the following is true, explanation would be greatly appreciated!
Suppose $$E(x,y)=\gamma x^{2n}+{y^2\over a}$$ where $\gamma &gt;0, a&gt;0,n\in \mathbb Z^+$.</p>

<p>And we define $$\alpha = {1\over 2\pi}\oint y\,\,\,dx$$ where the path is where $E, \gamma$ are constants.</p>

<p>Why then does it follow that $$a^{n\over n+1}E=\gamma^{1\over n+1}\left({n\pi\alpha\over f}\right)^{2n\over n+1}$$ where $f=\int_0^1(1-u)^{1\over 2}u^{1-2n\over 2n}\,\,du$?</p>

<hr>

<p>I first tried making $y$ the subject then substitute its expression in terms of $E$ and $x$ into the integral of $\alpha$. Here I can take $E, \gamma$ to be constants, since they are so on the path. This gives $$\alpha = {\sqrt a\over 2\pi}\oint (E-\gamma x^{2n})^{1\over 2}dx$$. But what next? Or perhaps there is a different approach to begin with?</p>
",calculus
"<p>Suppose $f = \frac{(1/2)^n}{1+(1/2)^n}$ where $n \geq 1 $ I wanted to give an upper bound the function.</p>

<p>So I did</p>

<p>$f = \frac{(1/2)^n}{1+(1/2)^n} \leq \frac{(1/2)^n}{(1/2)^n} = 1$</p>

<p>Which is right, but then I also did</p>

<p>$f = \frac{(1/2)^n}{1+(1/2)^n} \leq \frac{(1/2)^n}{(1)} = (1/2)^n$ and as $n\to \infty$, the function is bounded by $0$ and this makes no sense at all. I have no idea what I am doing wrong in my algebra, but the solution makes no sense ot me, I couldn't interpret the answer at all</p>
",calculus
"<p>$$\displaystyle \begin{align*}
  &amp; \int_{0}^{+\infty }{\frac{\text{d}x}{1+{{x}^{n}}}} \\ 
 &amp; \int_{-\infty }^{+\infty }{\frac{{{x}^{2m}}}{1+{{x}^{2n}}}\text{d}x} \\ 
 &amp; \int_{0}^{+\infty }{\frac{{{x}^{s-1}}}{1+x}\text{d}x} \\ 
\end{align*}$$</p>
",calculus
"<p>Suppose that the function $f(x)$ satisfies $f(0)=0$, $f'(0)=0$ and $f''(0)&gt;0$.</p>

<p>(a) Show that there exists $d&gt;0$ such that $\frac{f'(x)-f'(0)}{x-0}&gt;0$ for every non-zero $x$. </p>

<p>(b) Use Rolle's Theorem to show that $f(x)$ is not equal to $0$ for all non-zero x in $(-d,d)$.</p>

<hr>

<p>I'm okay with part (a). </p>

<p>My problem with part (b) is that using  Rolle's Theorem here assumes continuity on some closed intervals, say $[a,0]$ and $[0,b]$, and differentiability on the corresponding open intervals $(a,0)$ and $(0,b)$. Obviously $f(x)$ is continuous at $x=0$, but how does that guarantee the conditions needed for the application of Rolle's theorem? I have completed part (b) by assuming the required conditions but would like to know if/why I am justified in doing so.</p>
",calculus
"<p>The original problem is: </p>

<p>""Find the volume of the solid obtained by rotating about the x axis the region enclosed by the curves $y = \frac{9}{x^2 + 9},y=0,x=0,\,$and $x = 3$""</p>

<p>I set up the following integral $$81\pi\int_0^3\frac{1}{(x^2 + 9)^2}dx$$ using the cylinder method (I believe it's called like that) and when I calculated it using a computer I obtained the correct answer but I have been having difficulties in solving it manually.  I tried the shell method as well and I didn't see it any easier to solve but I may be wrong of course. </p>
",calculus
"<p>When integrating over a certain variable $x$, we make sure to end the integral with $dx$, like so:</p>

<p>$$\int_{1}^{\infty}\frac{1}{x^2}dx$$ The reason for this of course becomes more clear as one goes deeper into single- and especially multivariable calculus, where one discovers that it does't just signify which variable to integrate.</p>

<p>But is there <strong>no</strong> valid reason to write, for example, the sum $1+1/4+1/9+\dots$ in this fashion:</p>

<p>$$\sum_{1}^{\infty} \frac{dn}{n^2}$$</p>

<p>Instead of the usual:</p>

<p>$$\sum_{n=1}^{\infty} \frac{1}{n^2}$$</p>

<p>Has it ever been done?</p>
",calculus
"<p><a href=""http://math.stackexchange.com/questions/7892/comparing-pie-and-e-pi"">Comparing $\pi^{e}$ and $e^{\pi}$</a></p>

<p>I read the answer there but I didn't understand one thing. How I should know to put $\dfrac{π}e-1$ instead of $x$? If I had this question on a test, I had no idea what to put instead of $x$. I mean, why the first thing I need to think about is to calculte when $x=\dfrac{π}e-11$ .</p>

<p>I hope you understand my question.</p>

<p><strong>Note :</strong></p>

<p>This is not a duplicate - I'm not asking what is bigger - I don't understand the answer, that's all!</p>
",calculus
"<p>Evaluate the derivative of $x^3 - 3x +1$ using the $\lim_{x \to a} \frac{f(x) - f(a)}{x - a}$ definition to find the tangent of the curve at the point $(2, 3)$.</p>

<p>I already calculated this derivative using $ x = a + h$ for the above mentioned definition and this is what I got, for what it's worth:</p>

<p>$$\lim_{h \to 0} \frac{((2+h)^3 - 3(2+h) +1) - 3)}{h}$$</p>

<p>$$=\lim_{h \to 0} \frac{h(9 + 6h)}{h} = 9$$</p>

<p>The problem I encounter when using the $\lim_{x \to a} \frac{f(x) - f(a)}{x - a}$ definition is that I can't factor the numerator of $\lim_{x \to 2} \frac{x^3 - 3x +1 - 3}{x - 2}$ to get rid of that $(x-2)$ in the denominator.</p>

<p>Can anybody give me a hint as to what trickery I can use to factor that numerator?</p>
",calculus
"<p>How can one find this limit:
$$\lim_{n \to \infty} \frac{n^3}{(3n)!^\frac{1}{n}}$$</p>

<p>Hospitals is out of the question, in this case, because n! is not a differentiable function.</p>
",calculus
"<p>My professor said that </p>

<p>$$\lim_{\delta \to 0}(1-\lambda \delta)^{t/\delta}=e^{-\lambda t}$$</p>

<p>can be shown with L'Hospital's rule. I don't know what he meant. What is the best way to show this (or, more simply, $\lim_{\delta \to 0}(1-\lambda \delta)^{1/\delta} = e^{-\lambda}$)?</p>

<p>If I try as follows </p>

<p>$$\lim_{\delta \to 0}\left(1-\lambda\delta \right)^{1/\delta} = \lim_{\eta \to \infty} \frac{(\eta-\lambda)^\eta}{\eta^\eta},$$</p>

<p>then I'm getting led into confusion trying LHR on the last one.</p>
",calculus
"<p>What is the equation of the tangent and normal lines to this function at the point p</p>

<p>$f(x)$ = $x^3$ at the point $p = (2,8)$</p>
",calculus
"<p>When a mortar shell is ﬁred with an initial
velocity of v0 ft/sec at an angle α above the
horizontal, then its position after t seconds is
given by the parametric equations
$x = (v0 \cos \alpha)t$ , $y = (v0 \sin \alpha)t − 16t^2$</p>

<p>If the mortar shell hits the ground 4900 feet
from the mortar when α = 75◦, determine v0.</p>

<p>So I've tried various forms of:
\begin{align*}
t = {} &amp; 4900/(v0 \cos 75) \\
0 = {} &amp; (v0 \sin 75)(4900/(v0 \cos 75)) - 16(4900/(v0 \cos 75))^2 \\
4900(v0 \sin 75)/(v0 \cos 75) = {} &amp; 384160000/(v0 \cos 75)^2 \\
v0 \sin 75 = {} &amp; 78400/(v0 \cos 75) \\
v0 = {} &amp; 78400/\sin 75 * v0 * \cos 75 \\
v0^2 = {} &amp; 78400/\sin 75 * \cos 75 \\
v0 = {} &amp; 468.33...i
\end{align*}</p>

<p>which doesn't seem right. And the answer choices are:</p>

<ol>
<li>v0 = 530 ft/sec</li>
<li>v0 = 560 ft/sec</li>
<li>v0 = 520 ft/sec</li>
<li>v0 = 550 ft/sec</li>
<li>v0 = 540 ft/sec</li>
</ol>
",calculus
"<p>Suppose we have a smooth surface in 3D, called $S$. ${\bf n}$ is the unit normal vector. Suppose locally, we have curvilinear coordinates $s,t$ such that ${\bf s}={\bf r}_s$, ${\bf t}={\bf r}_t$ and $\{{\bf s},{\bf t},{\bf n}\}$ forms an orthonormal basis. Without loss of generality, assume ${\bf r}(0,0)={\bf 0}$.
Consider a smooth extension of ${\bf n}$ into a ball $B({\bf 0},\epsilon)$ for some $\epsilon&gt;0$ and $|{\bf n}|=1$. One possible example is ${\bf n}=\nabla\varphi/|\nabla\varphi|$ where $\varphi$ is the signed distance function.</p>

<p>$({\bf t}\cdot\nabla{\bf n})\cdot{\bf s}$ and $({\bf s}\cdot\nabla{\bf n})\cdot{\bf t}$(evaluated at $s=0,t=0$) are independent of the extension, where ${\bf t}\cdot\nabla{\bf n}$ is defined to be $t_i\partial_i{\bf n}$ with Einstein summation convention used.<br>
Actually, one can simply consider ${\bf t}\cdot\nabla n_1=\frac{\partial}{\partial t}n_1({\bf r}(s,t))|_{s=0,t=0}$. This is only determined by the values of $n_1$ on the surface. Then, ${\bf t}\cdot\nabla{\bf n}$ is independent of the extension.</p>

<p>Then, let's consider $g=({\bf t}\cdot\nabla{\bf n})\cdot{\bf s}-({\bf s}\cdot\nabla{\bf n})\cdot{\bf t}=[{\bf t}\cdot(\nabla{\bf n}-\nabla{\bf n}^T)]\cdot{\bf s}
=-{\bf t}\cdot[(\nabla\times{\bf n})\times{\bf s}]=-(\nabla\times{\bf n})\cdot{\bf n}$ at ${\bf 0}$, which should be independent of the extension as well.</p>

<p>Let's use the extension ${\bf n}=\nabla\varphi/|\nabla\varphi|$. Then, $\nabla\times{\bf n}=\nabla(1/|\nabla\varphi|)\times\nabla\varphi$ which is perpendicular with ${\bf n}$. This means $g=0$ or ${\bf n}\cdot(\nabla\times{\bf n})=0$ on the surface for any extension.</p>

<p>However, consider ${\bf v}=(x-z,y-z,-2z)$. At point, $(1,0,0)$, in a neighborhood, we can find a smooth surface such that ${\bf v}/|{\bf v}|$ is the normal vector of that surface. This seems to suggest ${\bf v}\cdot(\nabla\times({\bf v}/|{\bf v}|))=0$ at $(1,0,0)$. This means
$\frac{1}{|{\bf v}|}{\bf v}\cdot(\nabla\times{\bf v})=0$. One can verify directly that this is not true. Where does the argument fail?</p>
",calculus
"<p>Here we $D_2 f(1,y)$ means we have to calculate the partial derivative w.r.t $y$, so I have applied one short tricks that I have put $x=1$ in the equation then $f(1,y)= 1+0=1$ so the $D_2(f(1,y)=0$. Now my question is that the way I have gone is it correct or not. Please comment and give solution if I am wrong.</p>
",calculus
"<p>I know $\frac{dy}{dx}\frac{dx}{dy} = 1$ because the chain rule says $1 = \frac{dy}{dy} = \frac{dy}{dx}\frac{dx}{dy}$.  But does $\frac{d^2 y}{dx^2} \frac{d^2 x}{dy^2} = 1$?  Or would that be too good to be true?</p>
",calculus
"<p>Let:</p>

<p>$$ A = \int_0^1 \frac{e^t}{1+t} dt$$</p>

<p>Then what is the value of:</p>

<p>$$ \int_{a-1}^a \frac{e^{-t}}{t-a-1} dt$$</p>

<p>I tried using the property:</p>

<p>$$ \int_a^b f(x) dx =\int_a^b f(a+b-x) dx$$ </p>

<p>But that was of no help</p>
",calculus
"<p>Is $f(x,y)=ax^2+by^2$ a bijection between $\mathbb R^2 \to \mathbb R$ ?</p>

<p>How about $f(x,y,z)=\frac{x^2}{a^2} + \frac{y^2}{b^2}+ \frac{z^2}{c^2}? ( \mathbb R^3 \to \mathbb R )$</p>

<blockquote>
  <p>What confuses me now is this: My professor defined the function
  $f(x,y)=x^2+y^2$ then stating : $f^{-1}((1,2))=\{(x,y)\in \mathbb R^2:
 1 &lt; f(x,y)&lt;2\}$ Then, what I can assume the logic: since $(1,2)$ is
   open in $\mathbb R $ then $f^{-1}((1,2)) $ is open in $\mathbb R^2.$
  What are your thoughts on this?</p>
</blockquote>

<p>And also, if a have a bijective between two topologies, are the following statements correct:</p>

<p>1.)If a subset in one topology is open/closed its map is  open/closed as well in the respected topology.</p>

<p>2.)If a subset is nor open nor closed in one topology its map is nor open nor closed in the respected topology.</p>

<p>3.) If a subset is open and closed in one topology then it's map is open and closed in the respected other topology. </p>
",calculus
"<p>Consider the function $x : \mathbb{R} \to \mathbb{R}$ given by 
$$x(t) = \frac{1}{30000} \frac{1}{\mathrm{e}^t}+ \frac{2}{30000} \mathrm{e}^{\frac{t}{2}} \cos \left(\frac{\sqrt{3}}{2}t\right), \quad t\in \mathbb{R}.$$
Arrange the roots of this function $x$ in increasing order. Let $t_n$ denote the $n$th root of the function. The sequence $\{t_n\}_{n = 1}^\infty$ begins with (rounded to one decimal place)
$$1.8, 5.4, 9.1, 12.7, 16.3, \ldots$$</p>

<p>Based on plotting some graphs using Wolfram Alpha, the function $x$ appears to have infinitely many roots. Does there exist a positive integer $N$ such that, for each positive integer $n \ge N$, 
$$t_{n + 1} \le t_n + 5?$$ </p>
",calculus
"<p>$\lim_{(x,y)\to(0,0)}\frac{x^2y^2}{\sin(x)\cos(y)}$  is it allowed to split a multi-variable limit into its component variables as in the next step?</p>

<p>$= (\lim_{x\to0}\frac{x^2}{\sin(x)})(\lim_{x\to0}\frac{y^2}{\sin(y)})$ this is an indeterminate form and now I use L'Hopital</p>

<p>$=(\lim_{x\to0}\frac{2x}{\cos(x)})(\lim_{x\to0}\frac{2y}{\cos(y)})$</p>

<p>$=(\frac{0}{1})(\frac{0}{1})=0$</p>
",calculus
"<p>I know that this is a pretty basic limit, I found this limit in this forum but not the way I did, so I need to know if this is right:</p>

<p>We know that </p>

<p>$$\lim_{x \to \infty}\left(1 + \frac{1}{x} \right)^x = e$$</p>

<p>ans I was wondering how to calculate </p>

<p>$$\lim_{x \to \infty}\left(1 + \frac{a}{x} \right)^x$$</p>

<p>The way I tough was like this:</p>

<p>$$\lim_{x \to \infty}\left(1 + \frac{a}{x} \right)^x = \lim_{ax \to \infty}\left(1 + \frac{a}{ax} \right)^{ax} = \left[\lim_{ax \to \infty}\left(1 + \frac{1}{x} \right)^x\right]^a = e^a$$</p>

<p>Can I make this $ax$ substitution in the limit? I was wondering about this, and for me is ok, because I'm considering the entire $ax$ thing going to infinity. </p>
",calculus
"<p>Let $S=\sum\limits_{n=1}^\infty a_n$ be an infinite series such that $S_N=4-\frac{2}{N^2}$.</p>

<p>(a) Find a general formula for $a_n$. </p>

<p>(b) Find the sum $\sum\limits_{n=1}^\infty a_n$. </p>

<p>Can you explain to me how I can convert the partial sum to the general equation?</p>

<p>(a) What are the values of
$\sum\limits_{n=1}^{10} a_n$ and $\sum\limits_{n=4}^{16} a_n$?</p>

<p>$\sum\limits_{n=1}^{10} a_n=23433271/635040$</p>

<p>$\sum\limits_{n=4}^{16} a_n= 15799025474051/259718659200 $</p>

<p>(b) What is the value of $a_3$?
$167/18$</p>

<p>Why aren't these values correct as well?</p>
",calculus
"<p>I have recently read about convergence and divergence. However, I am having trouble understanding how something can converge/diverge ""slowly"" or ""fast"". If you sum up two series (that converge to the same number) infinitely, they will converge, not at any particular rate, but just to the number- this is how I see it.</p>

<p>So what does it <strong>mean</strong> for a series to converge (or diverge) slowly?</p>
",calculus
"<p>What approach would be ideal in solving for a number $k$ when the area about the $x$ axis and under the graph of the function $f(x) = \frac1x$  from interval $x = [2, k]$ is equal to $\ln(4)$?</p>
",calculus
"<p>How to integrate $\frac{\sqrt{x}}{1-\sqrt{x}}$?</p>

<p>I tried by using integration by parts, but always got sucked. Should be very easy...</p>
",calculus
"<p>I have a function, 
  $$F(r) = \int_0^r |c x^2 + {(2 a + b - 4 a r - 3 b r - 2 c r) x^2\over2 r} + b x^3 +
  a x^4| dx$$</p>

<p>a, b and c are constants. I want to determine r such that $f=F'(r) = k$. Integrating with an absolute value is nasty, so my first thought was to use the First Fundamental Theorem of Calculus, which states:</p>

<p>if $F(x) = \int_a^x f(t) dt$ then $F'(x) = f(x)$</p>

<p>But what I have is more like $F(x) = \int_a^x f(t, x)dt$ and so I'm not quite sure if/how the theorem applies. Is there any way to compute $F'(r)$ without first solving for $F(r)$ (which requires breaking the integrand apart into a piecewise function to remove the absolute value)?</p>
",calculus
"<p>I'm taking calculus and we're up to areas between curves. Thing is that unless I do a table of values and graph, or I'm given an easy transformation, its really hard to figure out which graph is the top and bottom so I can do</p>

<p>$A=\int_a^b \! F_{top} - F_{bottom} \, \textrm{d}x$ or $A=\int_c^d \! F_{right} - F_{left} \, \textrm{d}x$</p>

<p>Also, what's a quick way of determining a problem in which I'll have to add two integrals and when I only need to solve one?</p>
",calculus
"<p>I have a vector of size $n$ x $1$ named $\alpha$. Let $f(\alpha) = u\cdot\mathbf 1^{\!\top}ln(\alpha)$ where $u$ is scalar.</p>

<p>What is the $f'(\alpha)$ and $f''(\alpha)$ and equivalent <strong>Matlab</strong> code?</p>

<p>According to me the first derivative is</p>

<p>$$f'(\alpha) = u/\alpha$$</p>

<p>and equivalent MATLAB code is --</p>

<p><code>f_a_1 = u ./ a</code></p>

<p>and for the second derivative</p>

<p>$$f''(\alpha) = u\cdot(Diag(\alpha)*Diag(\alpha))^{-1}$$</p>

<p>Equivalent MATLAB code is</p>

<p><code>f_a_2 = u*inv(diag(a)*diag(a))</code></p>

<p>Is my inference correct?</p>
",calculus
"<p><a href=""http://i.stack.imgur.com/j5OHj.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/j5OHj.jpg"" alt=""enter image description here""></a></p>

<p>What's the thought process when confronted with a question like this.
After a year this is the first time I've seen a question like this, in C1.</p>

<p>I've worked out $$y'' =  \frac{3}{2x^{1/2}}$$</p>

<p>How do I then go to the equation including k, where does the k even come from?</p>
",calculus
"<p>I've found the following exercise in one of my courses. How can I solve the 
following Cauchy equation?</p>

<p>$$\frac{dx}{dt} = x^2 -2e^{2t}x + e^{4t} + 2e^{2t}, (t,x) ∈ R^2$$
$$x(0)=2$$</p>

<p>Any help is appreciated!</p>
",calculus
"<p>$$\int_{0}^{1}\frac{x}{\sqrt{4-x}}dx=$$
I used a substitution like so: $t=x^{2}$, and got to 
$$\frac{1}{2}\int_{0}^{1}\frac{dt}{\sqrt{4-\sqrt{t}}}=\frac{1}{2}\left (\arcsin\frac{\sqrt[4]{1}}{2}-\arcsin\frac{\sqrt[4]{0}}{2}  \right )=\frac{\pi }{12}$$
But the correct answer is doing a different substitution: $t=4-x$  and it ends up with this value- $$-6\sqrt{3}+10\tfrac{2}{3}$$</p>

<p>Notice the two answers are very close - mine is $\sim 0.26$ and the other is $\sim 0.27$.</p>

<p>Was my way wrong? If so, why?</p>
",calculus
"<p>I have to prove that the bound of the following relation is $\theta(n^2)$ by induction-</p>

<p>$$T(n) = T(n-1) +  n$$</p>

<ol>
<li>should i seprate my induction into two sections - 
to claim  that $T(n) = O(n^2)$ and $T(n) = \Omega(n^2)$ and prove each case, or should i expand the relation and then formulate my claims ?</li>
<li>should my two equations be the same , but with diffrent sign  -->   $\leq$ and $\geq$</li>
</ol>

<p>Thanks!</p>
",calculus
"<p>Let  $f:[0,1]\rightarrow R$, a continuous function such that $f(0)=f(1)=0$.</p>

<p>Assume that there exists an M such that:
$$
\max \{ f(x) \mid x \in [0,1] \} = M &gt; 0
$$
Prove that for every $ 0 \lt \lambda \lt M $ there exists $x_1,x_2 \in [0,1]$ that fulfill the following requirements:</p>

<p>1.) $x_1 \ne x_2$</p>

<p>2.) $f(x_1)=f(x_2)=\lambda $</p>

<p>I'm leaning towards picking $a,b \in [0,1]$ such that $ -1\lt a \lt b \lt1$. f is then also continuous in [a,b] because it is a subgroup of [-1,1]</p>

<p>Here I'm having difficulties figuring out where to continue with this train of thought (if it's even correct.), so I'd appreciate any hints.</p>
",calculus
"<p>Recall the definitions of the <a href=""http://mathworld.wolfram.com/SineIntegral.html"" rel=""nofollow"">sine</a> and <a href=""http://mathworld.wolfram.com/CosineIntegral.html"" rel=""nofollow"">cosine integrals</a>:
$$\operatorname{Si}(x)=\int_0^x\frac{\sin t}t dt,\quad\operatorname{Ci}(x)=-\int_x^\infty\frac{\cos t}t dt.$$
Both functions are oscillating, with a countably infinite number of minima and maxima.</p>

<p>Note that
$$\lim_{x\to\infty}\operatorname{Si}(x)=\frac\pi2,\quad\lim_{x\to\infty}\operatorname{Ci}(x)=0.$$
Consider the following function:
$$f(x)=\sqrt{\left(\operatorname{Si}(x)-\frac\pi2\right)^2+\operatorname{Ci}(x)^2}.$$
<a href=""http://i.stack.imgur.com/NClxo.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/NClxo.png"" alt=""Function graph""></a>
It appears that the function $f(x)$ and all its derivatives are monotonic  for $x&gt;0$. Specifically, the function itself and all its derivatives of an even order are strictly decreasing, and all its derivative of an odd order are strictly increasing. </p>

<p>Is it actually true? If so, then how can we prove it?</p>
",calculus
"<p>How to solve the definite integration as showed in the title.
And $m$ is an arbitrary natural number, $a$ is a non-negative number.
Many thanks in advance.</p>
",calculus
"<blockquote>
  <p>Prove that $$\lim\limits_{h\to 0}\frac{f(x+h)-2f(x)+f(x-h)}{h^2}=f''(x)$$</p>
</blockquote>

<p>Is the following a correct proof:</p>

<blockquote>
  <p>$f''(x)=$$\lim\limits_{h\to 0}\frac{f'(x)-f'(x-h)}{h}=\lim\limits_{h\to 0}\frac{\frac{f(x+h)-f(x)}{h}-\frac{f(x)-f(x-h)}{h}}{h}=\lim\limits_{h\to 0}\frac{f(x+h)-2f(x)+f(x-h)}{h^2}$</p>
</blockquote>

<p>I would really love input on this proof. The book ""Berkeley Problems in Mathematics"" solves it differently.</p>
",calculus
"<p>This is taken from ""Undestanding Analysis""- Abbot,</p>

<p><strong>Exercise 4.5.8</strong>: Imagine a clock where the hour hand and the minute hand are indistinguishable from each other. Assuming the hands move continuously around the face of the clock, and assuming their positions can be measured with perfect accuracy, is it always possible to determine the time?</p>

<p>From my point of view, I think we CAN tell the time because if you observe for, say, 5 minutes, you can see that the minute hand moves faster than the hour hand. Having that, you can determine which one is the hour hand and which one is the minute hand, and hence, you can easily deduct the exact time. However, this is not very mathematical, and although there is a solution for this question, I do not want to look at it so it would be better that I come up with my own original solution. </p>

<p>So, please help me, did I answer this question correctly? How do I move up my argument to a solid proof statement? I thank you very much for your help.</p>
",calculus
"<blockquote>
  <p>Definition: A partition of the interval $[a, b]$ is a <strong>finite</strong> collection of points in $[a, b]$, one of which is $a$ and one of which is $b$. The points in a partition can be numbered $t_0, ...., t_n$ such that $a = t_0 &lt;t_1 &lt; ... &lt; t_{n-1} &lt; t_n =b$.</p>
</blockquote>

<p>I've quoted the above definition of a partition for a reason, as you will see soon. From the definition of a partition, with $P = \{t_0, t_1, ... , t_n{-1}, t_n \}$ we can define the lower and upper Riemann Sums like so:</p>

<p>$$L(f, P) := \sum_{i=1}^{n}m_i(t_i - t_{i-1})$$
$$U(f, P) := \sum_{i=1}^{n}M_i(t_i - t_{i-1})$$
where
$$m_i = \inf\{f(x): t_{i-1} \leq x \leq t_i\}$$
$$M_i = \sup\{f(x): t_{i-1} \leq x \leq t_i\}$$</p>

<p>So essentially what the partition is doing, is selecting <em>sampling points</em> to break up the real field over the interval $[a, b]$ into $n$ sub-intervals, $[t_0, t_1],\  [t_1, t_2],\  ...\ , \ [t_{n-2}, t_{n-1}], \ [t_{n-1}, t_{n}]$, correct?</p>

<p>Is is then mathematically correct to rewrite $m_i$ and $M_i$ as the following:</p>

<p>$$m_i = \inf\{f(x): x \in [t_{i-1}, t_i]\}$$
$$M_i = \sup\{f(x): x \in [t_{i-1}, t_i]\}$$</p>

<p>where $[t_{i-1}, t_i] \subset \mathbb{R}$. (and where $[t_{i-1}, t_i]$ is a continuous interval)? </p>

<p>And if $f$ is assumed to be continuous, then $m_i = \min\{f(x) : x \in [t_{i-1}, t_{i}]\}$, and $M_i = \max\{f(x) : x \in [t_{i-1}, t_{i}]\}$ (in words: $m_i$ will be the minimum value $f$ takes on over the $n$ sub-intervals and $M_i$ will be the maximum value $f$ takes on over the $n$ sub-intervals)?</p>

<p>If what I've said above is correct, just out of curiosity why is the $a \leq x \leq b$ notation preferred over the interval notation $x \in [a, b]$?</p>

<hr>

<p>I really do apologize if what I'm writing is blatantly obvious, I asked a question earlier, and I think only now I realized that what the partition was doing, was just selecting sampling points to break up the real field into sub-intervals.</p>
",calculus
"<p>I'm signing up for University soon (Compsci program) as a mature student. It's been a long time since I've done any math, and I went as far as grade 11 in high school. So, I'm looking for a book that will review the essentials of high school math, starting from the basics, and prepare me for Uni.</p>

<p>Any recommendations? I know many of you recommended ""Mathematics: Its Content, Methods and Meaning"" in the past, but I'm not sure if it's beginner-friendly. Perhaps I should buy one of those GED preparation books?</p>
",calculus
"<p>Let $g : [a, b] → \mathbb{R}$ be a continuous function on $[a, b]$. Given any $n \in \mathbb{N}$ and
$x_1, . . . , x_n ∈ [a, b]$, show that there exists $x_0 ∈ [a, b]$ such that
$g(x_0) =(g(x_1) + · · · + g(x_n))$.</p>

<p>I am very confused on how to start here. I know that there is the basic epsilon delta proofs for continuity, but I don't how how or even if that should be applied here. </p>
",calculus
"<p>I am used to seeing integral notation like this, which means the integral over the domain from a to b.</p>

<p>$$
\int_{a}^{b}
$$</p>

<p>But now I am looking at a statistics book that says ""let A be an event"" and then shows the probability of that event like this</p>

<p>$$
\int_{A} fx(X)dx = P(X ∈ A)
$$</p>

<p>How do I interpret the notation when only the bottom symbol is given? </p>
",calculus
"<p>want to evaluate $$\int\frac{1}{\sqrt{x^2+y^2+z^2}}dxdydz$$ over entire $\mathbb{R}^3$ except $(0,0,0)$.</p>

<p>I did this using polar coordinate and got $$\lim\limits_{a\rightarrow0}\int\limits_a^\infty\int\limits_0^{\pi}\int\limits_0^{2\pi}r\sin\phi d\theta d\phi dr$$ but I think this diverges.</p>

<p>where am I wrong? help me please</p>
",calculus
"<p>I am looking for all real-valued continuous functions f, on R, which satisfy</p>

<p>$$ f(x)*f(y) = f(x_1)f(y_1) $$ 
for all x,y, $x_1$, $y_1$,  such that $$x^2 + y^2 = (x_1)^2 +(y_1)^2.$$</p>

<p>I don't have much idea on how to solve this problem.  The only thing that comes to mind, which doesn't help very much, is the fact that if I let g(x,y) = f(x)*f(y), then since the function g factorizes into two functions of a single variable, we have that the integral of g is the product of the single-variable integrals of f(x)dx and f(y)dy.</p>

<p>Thanks,</p>

<p>Edit:  This is not a homework problem.  It is a problem that dates back to 2007, as far as I know, and there is a not-so-good solution to it that basically says ""guess that the function is Guassian and let's force it to be Guassian.""  I am looking for another solution to this problem.  Thanks.</p>
",calculus
"<p>When it comes to taking a derivative, what does $\displaystyle \frac{d^2 u}{dt^2}$ mean ? Does it mean taking derivative of the function twice with respect to $t$. If yes, why is then $d^2 u$ squared? Thanks in advance!</p>
",calculus
"<p>Prove that:</p>

<p>$\displaystyle \sum_{k=1}^{\infty} \frac{H_k}{k^q} = (1 + \frac{q}{2})\zeta(q + 1) - \frac{1}{2}\cdot \sum_{n=1}^{q-2}\zeta(k+1)\zeta(q-k)$</p>

<p>It looks tough just to start off with. </p>

<p>Any ideas on approach?</p>
",calculus
"<p>I know the answer but I don't understand the steps to integrate.</p>

<p>$$  \int \frac{\cos x\,d x}{1 + (\sin x)^{2}} $$</p>
",calculus
"<p>Let $f(x)=x^4+x^3-x-1$. Use Rolle's theorem to prove $4x^3+3x^2-1=0$ has at least one real root in [-1,1].</p>

<p>Do I have to let $f(x)=\sin(x)$ and continue to do it? I have no idea how to use the Rolle's theorem as this can be easily mixed up with LaGrange theorem.</p>
",calculus
"<p>In my notes I have a step that I don't understand:</p>

<p>$$x\sqrt{1+{x^\prime}^2}=\text{constant}$$
$$x' = \tan s\quad\quad\text{?????}$$</p>

<p>Firstly, I don't get clarification for what $s$ is. Second, how did they deduce this?</p>
",calculus
"<p>Integrate the following :</p>

<p>$ \int _{ 0 }^{ 1 }{ { sec }^{ 2 } } \frac { \pi x }{ 4 } \quad dx $</p>
",calculus
"<p>Can someone explain to me how I find the real and the imaginary part of $e^{\theta i}$?</p>

<p>I'm learning complex numbers but I don't quite understand how $e$ is intertwined in all this.</p>
",calculus
"<p>Consider the function $f(x,y,z)=2y^{2}+2xy+2xz+2yz$, Find a symmetric matrix $A$ such that $f(x,y,z)$ can be written in the form $(Ax)x=(Ax)^{T}x$, where $x^T = [x y z]$. </p>
",calculus
"<p>Assume $f : [0, 1] \to \mathbb{R}$ is continuous and arbitrarily often differentiable on $(0, 1)$ (i.e.
$f$ is smooth). Denote by $f^{m}$ the $m\text{-th}$ derivative of $f$ with $m∈\mathbb{N}$ and set $f^{0}:=f$.
Prove via induction that the following formula holds for arbitrary $m∈\mathbb{N}$,</p>

<p>$$\frac{1}{n!}\int_0^1x^nf(x)dx =\sum_{r=1}^{m}\frac{(-1)^{r-1}f^{r-1}(1)}{(n+r)!}+(-1)^m\int_0^1 
\frac{x^{n+m} f^m(x)}{(n+m)!}dx$$</p>

<p>where $n∈\mathbb{N}$ is fixed.</p>
",calculus
"<p>I need your help</p>

<p>Find an enumeration of positive rational numbers, $a_n$ say, such that $\lim\limits_n a_n^{\frac{1}{n}}=1$</p>
",calculus
"<p>I have been using Lagrange multipliers in constrained optimization problems, but I don't see <em>how</em> they actually work to simultaneously satisfy the constraint <em>and</em> find the lowest possible value of an objective function.</p>
",calculus
"<p>I read <a href=""http://math.stackexchange.com/questions/625/why-is-the-derivative-of-a-circles-area-its-perimeter-and-similarly-for-spheres"" rel=""nofollow"">this question</a> the other day and it got me thinking: the area of a circle is $\pi r^2$, which differentiates to $2 \pi r$, which is just the perimeter of the circle. </p>

<blockquote>
  <p>Why doesn't the same thing happen for squares? </p>
</blockquote>

<p>If we start with the area formula for squares, $l^2$, this differentiates to $2l$ which is sort of right but only <em>half</em> the perimeter. I asked my calculus teacher and he couldn't tell me why. Can anyone explain???</p>
",calculus
"<p>I was coming back from my Driver's Education class, and something mathsy really stuck out to me.</p>

<p>One of the essential properties of a car is its current speed.  Or speed at a current time.  For example, at a given point in time in my drive, I could be traveling 40 mph.  But what does that <em>mean</em>?</p>

<p>From my basic algebra classes, I've learned that speed = distance/time.  So if I travel ten miles in half an hour, my average speed would be $20$ mph ($\frac{10 mi}{25 h}$).</p>

<p>But instantaneous velocity...you aren't measuring average speed for a given amount of time.  You're measuring instantaneous speed over an...instantaneous amount of time.</p>

<p>That would be something like (miles) / (time), where time = $0$?  Isn't that infinite?</p>

<p>And perhaps, in a difference of time = $0$, then I'd be travelling $0$ miles.  So would I be said to be going $0$ mph at an instantaneous moment in time?  I'd like to be able to tell that to any cops pull me over for ""speeding""!</p>

<p>But then if miles = $0$ and time = $0$, then you have $\frac00$?</p>

<p>This is all rather confusing.  What does it <strong>mean</strong> to be going $40$ mph at a given moment in time, exactly?</p>

<p>I've heard this explained using this strange art called ""calculus"" before, and it's all gone over my head.  Can anyone explain this using terms I (a High School Algebra and Geometry and Driving student) will understand?</p>

<p>(I figured that my problem had numbers in it, and therefore has to do with Maths.)</p>
",calculus
"<p>What are some particularly well-known functions that exhibit pathological behavior at or near at least one value and are particularly useful as examples?</p>

<p>For instance, if $f&#39;(a) = b$, then $f(a)$ exists, $f$ is continuous at $a$, $f$ is differentiable at $a$, but $f&#39;$ need not be continuous at $a$.  A function for which this is true is $f(x) = x^2 \sin(1/x)$ at $x=0$.</p>
",calculus
"<h1>Problem</h1>

<p>Consider the trigonometric equation:
$$
a\sin x+b\cos x-\cos x\sin x=0\qquad(0\le x&lt;2\pi)\tag{*}
$$
try to analyze the number of solutions to equation (*) with parameters $a,b$, i.e, let $A=a^{2/3}+b^{2/3}-1$, we have:</p>

<ol>
<li>$A&lt;0$, there are four distinct solutions.</li>
<li>$A&gt;0$, there are two distinct solutions.</li>
</ol>

<h1>Endeavors</h1>

<p>Let $f(x)=a\sin x+b\cos x-\cos x\sin x$, we have $f^\prime(x)=a\cos x-b\sin x-\cos2x$. It seems no advance to calculate the derivative, because $f^\prime$ is as hard as $f$.</p>

<p>Let $u=\cos x$ and $v=\sin x$, we have $u^2+v^2=1$ and $av+bu=uv$. We can work on these equations, but I prefer the trigonometric way, i.e, analyze the properties of $f(x)$.</p>

<p>I want to illustrate some details about $f(x)$, which might be useful. Let $a=r\cos\phi$ and $b=r\sin\phi$, where $r=\sqrt{a^2+b^2}$, we have
$f(x)=r\sin(x+\phi)-\frac12\sin2x$. It's a linear combination of $\sin(x+\phi)$ and $\sin2x$. I don't know whether there's a systematical way to deal with it.</p>

<p>Any idea? Thanks!</p>
",calculus
"<p>$$ \ X_n=\frac{1}{\sqrt{n^3+1}}+\frac{2}{\sqrt{n^3+2}}+\cdots+\frac{n}{\sqrt{n^3+n}}$$ Find $\displaystyle\lim_{n\to\infty} X_n$ using the squeeze theorem</p>

<p>I tried this approach:<br>
$$
\frac{1}{\sqrt{n^3+1}}\le\frac{1}{\sqrt{n^3+1}}&lt;\frac{n}{\sqrt{n^3+1}}
$$
$$
\frac{1}{\sqrt{n^3+1}}&lt;\frac{2}{\sqrt{n^3+2}}&lt;\frac{n}{\sqrt{n^3+1}}$$
$$\vdots$$
$$\frac{1}{\sqrt{n^3+1}}&lt;\frac{n}{\sqrt{n^3+n}}&lt;\frac{n}{\sqrt{n^3+1}}$$</p>

<p>Adding this inequalities:</p>

<p>$$\frac{n}{\sqrt{n^3+1}}\leq X_n&lt;\frac{n^2}{\sqrt{n^3+1}}$$</p>

<p>And this doesn't help me much. How should i proced?</p>
",calculus
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://math.stackexchange.com/questions/115501/sqrtc-sqrtc-sqrtc-cdots-or-the-limit-of-the-sequence-x-n1-sq"">$\sqrt{c+\sqrt{c+\sqrt{c+\cdots}}}$, or the limit of the sequence $x_{n+1} = \sqrt{c+x_n}$</a>  </p>
</blockquote>



<p>Some time ago I was playing with a calculator and I found the following relation
$$2 = \sqrt{2 + \sqrt{2 + \sqrt{2 + \sqrt{2 + \cdots}}}}$$
In fact I found more, I found that
$$r = \sqrt{r(r - 1) + \sqrt{r(r - 1) + \sqrt{r(r - 1) + \sqrt{r(r - 1) + \cdots}}}}$$
if $r &gt; 1$, but I couldn't give a formal proof and I still can't.</p>

<p><strong>Note</strong>: If you solve $r(r - 1) = 1$ then you'll find an interesting property of the golden number.</p>
",calculus
"<p>I have a system of equations $xy=3$ and $4^{x^2}+2^{y^2}=72$ whose solution I know is $x=y=\sqrt 3$, but what are the steps to solve it?</p>
",calculus
"<p>Evaluate $$\lim_{x\to0} \frac{\sin(x^2)}{\sin^2(x)}.$$</p>

<p>Using L'Hospital twice, I found this limit to be $1$. However, since the Taylor series expansions of $\sin(x^2)$ and $\sin^2(x)$ tell us that both of these approach $0$ like $x^2$, I'm wondering if we can argue that the limit must be 1 via the Taylor series formal way?</p>
",calculus
"<p>I want to know a rigorous method to prove that </p>

<p>If $a&gt;1$, $\displaystyle\lim_{n \rightarrow \infty } a^n = \infty$</p>
",calculus
"<p>The vector field is obviously conservative on every closed domain that doesn't encompass the point $(0,0)$, so there must be a potential function.</p>

<p>I've got $\arctan(\frac{x}{y})$ for $x$ unequal to zero and $\arctan(\frac{y}{x})$ for $y$ unequal to zero.</p>

<p>However, when I try to find the line integral of the given field from point $(1,0)$ to point $(0,1)$ I get $\frac{\pi}{2}$, but when I try to find the result by using the potential function I get $0$.</p>

<p>What am I doing wrong?</p>

<p>Thanks in advance.</p>
",calculus
"<p>I am trying to integrate:
sin^5(3x)
What I did is as follows:</p>

<p>sin^6(3x)/(-cos3x*3*6)</p>

<p>is this the right way to do it?</p>
",calculus
"<p>The square of the side opposite a MUNDANGLE in a triangle is equal to the sum of the squares of the other two sides added to the product of these two sides multiplied by $\sqrt{3}$. What is MUNDANGLE?</p>

<p>This was an extra credit problem on my test, but my teacher said we had to do it for homework.</p>

<p>If anyone could support me and lead me to through the problem that would be great</p>
",calculus
"<p>If $c≠0$ and $\lim_{x→c}⁡〖f(x)〗=L$, prove that $\lim_{x→1/c}⁡〖f(1/x)〗=L$</p>

<p>I know that meaning for all $ε&gt;0$, there exist a $δ&gt;0$ such that $0&lt;|x-c|&lt;δ$  implies $|f(x)-L|&lt;ε$. How can I use these to prove the conclusion.</p>
",calculus
"<p>I have this function. I noticed that it can be written as: $ $x$ $y$^2 +$y$(1-$x$^2) + ($x$ - 2) = 0 $, so this is a quadratic in y.
Thus
\begin{equation}
y=\frac{(x^2-1)\pm \sqrt[2]{(x^2-1)^2 -4x(x-2)}}{2x}
\end{equation}
So i notice that this is not actually a function since it maps two $y$ values given one $x$ value. Anyway, the domain is $x$ $\neq$ 0 and from the expression inside the square root i find: $ $x$^4 -6$x$^2 +8$x$ + 1 \geqslant 0 $ which i can't solve. I don't know how to find the range either. From graphing this on WolframAlpha it <a href=""http://www.wolframalpha.com/widget/widgetPopup.jsp?p=v&amp;id=b0160688b805d84769cebe1afb71895&amp;title=Domain%20and%20Range%20calculator&amp;theme=blue&amp;i0=(x%5E2-1%2B((x%5E2%20-%201)%5E2%20-4x(x-2))%5E(1%2F2)%20))%2F(2x)&amp;podSelect="" rel=""nofollow"">gives</a> the domain but not the range. 
How did it find the domain? And what about the range?
Can somebody help? Thanks in advance.</p>
",calculus
"<blockquote>
  <p>Find a power series representation for $\displaystyle\left(\frac{x}{2-x}\right)^3$</p>
</blockquote>

<p>My approach is in finding something similar to $\displaystyle\left(\frac{x}{2-x}\right)^3$ to which I can easily find the power series representation of. </p>

<p>I use $\displaystyle\frac{1}{2-x}$, noting that $\displaystyle\left(\frac{1}{2-x}\right)'=\frac{1}{(2-x)^2} \text { and } \left(\frac{1}{2-x}\right)''=\frac{2}{(2-x)^3}$.</p>

<p>So 
$$\displaystyle \frac{1}{2-x}=\int\frac{1}{(2-x)^2}dx \iff \frac{1}{2}\sum^{\infty}_{n=0}\left(\frac{x}{2}\right)^n=\int\frac{1}{(2-x)^2}dx$$</p>

<p>and differentiating both sides, I get the power series representation of the first derivative</p>

<p>$$\frac{1}{2}\sum^{\infty}_{n=1}n\left(\frac{x}{2}\right)^{n-1}=\frac{1}{(2-x)^2}$$</p>

<p>for the second derivative, </p>

<p>$$\frac{1}{(2-x)^2}=\int\frac{2}{(2-x)^3} \iff \frac{1}{2}\sum^{\infty}_{n=1}n\left(\frac{x}{2}\right)^{n-1}=\frac{1}{2}\sum^{\infty}_{n=0}(n+1)\left(\frac{x}{2}\right)^n=\int\frac{2}{(2-x)^3}dx$$</p>

<p>differentiating both sides, I get the power series representation of the second derivative</p>

<p>$$\displaystyle \frac{1}{2}\sum^{\infty}_{n=1}(n+1)n\left(\frac{x}{2}\right)^{n-1}=\frac{2}{(2-x)^3}$$</p>

<p>Is this so far correct? If it is, in the end I would multiply the power series representation of $\displaystyle\frac{2}{(2-x)^3}$ by $\displaystyle\frac{x^3}{2}$ to cancel out the $2$ and get the power series for $\displaystyle\left(\frac{x}{2-x}\right)^3$.</p>
",calculus
"<p>I have been trying to understand this proof for the product rule of sequences, where the author makes use of some properties for infinitesimals, to prove this theorem. This is quite a long question, but please answer it as explicitly as you possibly can.</p>

<p>""A sequence ($y_nz_n$) is convergent to $ab$ if sequences ($y_n$) and($z_n$) are convergent to $a$ and $b$, respectively.""</p>

<ul>
<li>First of all how would <strong>you</strong> prove this.</li>
<li>The author uses an important property described earlier in the book:
That for any convergent sequence ($y_n$) there corresponds an infinitesimal    sequence ($\alpha_n$) where $\alpha_n$ = $y_n$- $a$. <strong>Why is this true, is there any intuition/ a precise reason behind this?</strong> Explain this property please.</li>
<li>Lastly after initial steps are taken we get:<br>
($y_nz_n$) = ab + $\gamma_n$ where $\gamma_n$ = $b\alpha_n$+$a\beta_n $+ $\alpha_n\beta_n$</li>
</ul>

<p>The author then states:</p>

<p>the sequences 
($b\alpha_n$) , ($a\beta_n $) , ($\alpha_n\beta_n$) are infinitesimal as well.</p>

<ul>
<li><strong>Why?</strong> Is it true that if we multiply a <strong>limit</strong> with a <strong>infinitesimal</strong>, we get another infinitesimal as $n\to\infty$? Explain please.</li>
</ul>
",calculus
"<p>I'm having a hard time finding the arc length of one section of the polar equation $r=\sin(3\theta)$. </p>

<p>I thought I had a good understanding but the integration seems to be a nightmare. Unless I'm not doing something correctly.</p>
",calculus
"<p>Here are basically my two problems, which I have the answer from WolframAlpha:
$$
\lim_{n\to\infty}(1-\sqrt 2-\sqrt{n+1}+\sqrt{n+2})=1-\sqrt 2
$$
$$
\lim_{n\to\infty}(\sqrt n-2\sqrt{n+1}+\sqrt{n+2})=0
$$</p>

<p>I have no idea how to actually solve them on my own though. At this moment it's gonna be inf - inf (and inf - 2 inf + inf for the second one) which I can't do nothing with (am I remembering correctly that you can't subtract infinity from infinity?). I need to simplify them somehow.</p>
",calculus
"<p>What is the value of the following sum?  </p>

<blockquote>
  <p>$$\sum_{i=1}^{2000}\gcd(i,2000)\cos\left(\frac{2\pi\ i}{2000}\right)$$  </p>
  
  <p>where </p>
  
  <ul>
  <li>$\gcd$ is the greatest common divisor.</li>
  </ul>
</blockquote>
",calculus
"<p>Let $g(x) = f(x)/(x+1)$, where $f(x)$ is differentiable on $x\in[0,5]$, such that $f(0)=4$ and $f(5)=-1$. What is the range of values $g'(c)$ for a $c$ belonging to $[0,5]$?</p>

<p>Considering values of $f(x_i)$, $f(x)$ must decrease at least once from $0$ to $5$. But that is all the information I can use here. Is there anything I am missing?</p>
",calculus
"<p>I'm solving a couple of integration problems using the method of changing variables, and would like assistance with two particular problems that I can't seem to solve. I completed rest of the problems in this problem set without much effort, but these two seem impossible.</p>

<p>I've tried changing a few different variables in both problems, and I tried to calculate the solution with Wolfram Alpha, but neither of those had any avail.</p>

<p>$$\int x^{e^{x^{2}}}dx$$</p>

<p>and</p>

<p>$$\int \frac{dx}{x+ ln^2x}$$
are the problems that I'm trying to solve. Any help is much appreciated.</p>
",calculus
"<p>I need to solve $$\frac{\partial u^2}{\partial x\partial y}=0$$ with the boundary conditions: $u(x,y=x^3)=\sin(x^6)$ and $\frac{\partial u}{\partial x}(x,y=x^3)=0$.</p>

<p>I got a particular solution, I thing which is $u_p=A\sin(y^2)$, where $A\in\mathbb{R}$, that satisfies the two boundary conditions, but it is rather a guess.</p>
",calculus
"<p>This is the question: <a href=""http://i.stack.imgur.com/wqjGC.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/wqjGC.jpg"" alt=""enter image description here""></a></p>

<p>I first found $\frac{dv}{ds}=6s^2+5$, then I tried to find $\frac{ds}{dt}$ by messing about a little with implicit differentiation, but I had no luck and I therefore couldn't apply the chain rule (i.e. $a=\frac{dv}{dt}=\frac{ds}{dt}\frac{dv}{ds}$) to find acceleration. The back of my book tells me the answer is $(6s^2+5)(2s^3+5s)$, but I fail to see how this is true as it would imply that $\frac{ds}{dt}=v$, which I can't exactly understand. Can anyone tell me what I am doing wrong?</p>
",calculus
"<blockquote>
  <p>Compute the indefinite integral
  $$
\int\ln(\tan x)\,dx
$$</p>
</blockquote>

<p><strong>My Attempt:</strong></p>

<p>Using $\sin x = \frac{e^{ix}-e^{-ix}}{2i}$ and $\cos x = \frac{e^{ix}-e^{-ix}}{2}$ and remembering that $\ln(\tan x) = \ln(\sin x) - \ln(\cos x)$, we have</p>

<p>$$
\begin{align}
\int\ln(\tan x)dx &amp;= \int \ln(\sin x)\,dx - \int \ln (\cos x)\,dx\\
&amp;= \int \ln \left(\frac{e^{ix}-e^{-ix}}{2i}\right)\,dx - \int \ln \left(\frac{e^{ix}-e^{-ix}}{2}\right)\,dx\\
&amp;= \int (e^{ix}-e^{-ix})\,dx-\int \ln(2i)\,dx-\int \ln \left(e^{ix}-e^{-ix}\right)\,dx+\int \ln(2)\,dx
\end{align}
$$</p>

<p>What should I do next to get to the solution?</p>
",calculus
"<p>What approach would be ideal in finding $\frac{dy}{dx}$ for $\sqrt{xy} = 1$?</p>
",calculus
"<p>A large vase has a square base of side length $6 \text{ cm}$, and flat sides slopingoutwards at an angle of $120^{\circ}$ with the base. Water is flowing in at $12 \text{ cm}^3/\text{s}$. Find, to three significant figures, the rate at which the height of water is rising when the water has been flowing in for $3$ seconds. </p>

<p>Spent around an hour trying to do it, but I keep getting the answer wrong. I think I'm not getting the right volume function.</p>
",calculus
"<p>I seem to be stuck trying to prove the following integral
$$
\int\frac{\cos^mx}{\sin^nx}dx = -\frac{\cos^{m+1}x}{(n-1)\sin^{n-1}x}-\frac{m-n+2}{n-1}\int\frac{\cos^mx}{\sin^{n-2}x} dx + C\,\,(n \neq 1)
$$
My thinking so far has been that if I take
$$
I = \int\frac{\cos^mx}{\sin^nx}dx
$$
I have been able to prove that
$$
I = -\frac{\cos^{m-1}x}{(n-1)\sin^{n-1}x}  - \frac{m-1}{n-1}\int\frac{\cos^{m-2}x}{\sin^{n-2}x}\,dx+C\,\,\,\,\,(1)
$$
and
$$
I = \frac{\cos^{m-1}x}{(m-n)\sin^{n-1}x} + \frac{m-1}{m-n}\int\frac{\cos^{m-2}x}{\sin^nx}\,dx+C\,\,\,\,\,(2)
$$
but showing that 
$$
I = -\frac{\cos^{m+1}x}{(n-1)\sin^{n-1}x}-\frac{m-n+2}{n-1}\int\frac{\cos^mx}{\sin^{n-2}x} dx + C
$$
seems to be eluding me. I attempted to apply a similar technique what I used on $(1)$ to get $(2)$ to try to obtain this integral, but it didn't seem to work.<br/>
I can also show that
$$
I = -\frac{\cos^{m+1}x}{(m+1)\sin^{n+1}x} - \frac{n+1}{m+1}\int\frac{\cos^{m+2}x}{\sin^{n+2}x}\, dx + C\,\,\,\,\,(3)
$$
but there's obviously more to it.</p>

<p>Any broad hints would be more than welcome.</p>
",calculus
"<p>What would be the ideal approach in finding the integral for:</p>

<p>$$
\int 2^{\sin{x}}\cos{x}\;\mathrm{d}x
$$</p>
",calculus
"<p>My integral is
$$I=\int\sqrt[3] {\frac{1}{(x+1)^2(x-1)^4}} dx$$
and hence
$$I=\int\frac{1}{(x-1)(x+1)}\sqrt[3] {\frac{x+1}{x-1}}dx $$
$\cos2\theta$ substitution wont be helpful here because of the cube root. Should I apply by parts ?</p>
",calculus
"<p>Do these series coverage or diverge? What test would you use to show this? Find the sum of the series when possible.
I am stuck with this one and I don't know how to go about it.</p>

<p>$$\sum_{i=1}^\infty [cos(\frac{1}{n+1})-cos(\frac{1}{n})]$$</p>
",calculus
"<p>I have a function $ f(x,y) = \begin{cases}
(x^2+y^2)\sin(\frac{1}{x^2+y^2}),  &amp; (x,y)\neq(0,0) \\
0, &amp; (x,y)=(0,0)
\end{cases}$</p>

<p>and I need to show that $f(x,y)$ is differentiable, even though it doesn't have partial derivatives at the point $(0,0)$. </p>

<p>I have proven that the function is continuous in $(0,0)$, and even though I understand that the function may have discontinuity in parital derivatives, it can be differentiable, but I am unable to prove it. </p>
",calculus
"<blockquote>
  <p>The acceleration as a function of time $a(t)$ (in m/s$^2$) and the initial velocity $v(0)$ are given for a particle moving along a line:
  $$a(t) = 2t + 4, \hspace{4mm}v(0) = −5, \hspace{8mm} 0 \leq  t \leq 4.$$
  (a) Find the velocity at time $t$. ($v(t) =  t^2+4t−5$)</p>
  
  <p>(b) Find the distance traveled during the given time interval.</p>
</blockquote>

<p>I was able to solve part (a) but have been having issues with part (b). It's a webassign assignment and the ""master it"" section only gives me the first portion and it hasn't allowed me to see other problems so I could try and figure it out by example. Is anyone able to explain to me how to do this?</p>
",calculus
"<p>I've been at this problem for days. </p>

<p>Forgot most of my series from calculus, so I started to review series and sequence for numerical methods and approximations. </p>

<p>$$\sum_{n=5}^{\infty} \frac{12}{16n^2+40n+21}$$</p>

<p>How can I evaluate this series using telescoping method?</p>
",calculus
"<p>Consider the parametric curve: $x(t)=1+4t-t^2$,  $y(t)=2-t^3$ for $t\in\mathbb{R}$. </p>

<p>What is the equation of the tangent line at the point $(x(1),y(1))$?</p>

<p>I got the slope by using the equation $\frac{\frac{dy}{dt}}{\frac{dx}{dt}}$ and I found that $y = -\frac{3}{2}x + 7$. Is it correct? </p>
",calculus
"<p>Could someone please give an intuition about the usage of the Hessian Matrix in multivariate optimization?</p>

<p>I know that it consists of all second order partial derivatives of a multivariate function and that it's used, for example, in the Newton-Raphson-Method. This method is intuitive for a function with a single variable but it's confusing to see the inverted Hessian in the expression for multiple variables.</p>
",calculus
"<blockquote>
  <p><strong>Problem:</strong> Consider partitioning $f(x)=x^2$ on $[-1,1]$ into $n$equal sub-intervals. We seek to derive an expression for $L(f, P)$ and $U(f, P)$ in terms of $n$, where $n$ is even.</p>
</blockquote>

<p>Now the question seemed a bit vague to me, but non the less this is what I did and arrived at:</p>

<hr>

<p>Given $P = \{x_0, x_1, ..., x_n \}$</p>

<p>$$L(f, P) := \sum_{i=1}^{n}m_i(x_i - x_{i-1})$$
$$U(f, P) := \sum_{i=1}^{n}M_i(x_i - x_{i-1})$$
where
$$m_i = \inf\{f(x): x \in [x_{x-1}, x_i]\}$$
$$M_i = \sup\{f(x): x \in [x_{i-1}, x_{i}]\}$$</p>

<p>Now since we wish to partition $f$ over $[-1, 1]$ into $n$ <strong>equal</strong> sub-intervals</p>

<p>$$\implies L(f, P) = (x_n - x_{n-1})\sum_{i=1}^{n}m_i$$
$$\implies U(f, P) = (x_n - x_{n-1})\sum_{i=1}^{n}M_i$$</p>

<p>And since we know $n$ is even, $\exists k \ni 2k =n$. This allows us to break our partition $P$ into two separate partitions $P_1$ and $P_2$ over two intervals $[-1, 0]$ and $[0, 1]$. Thus</p>

<p>$$\begin{align}P_1 &amp;= \{x_1, x_2, ...., x_k\} \ &amp; \text{where} &amp;&amp; \ x_1 = -1 &lt; x_2 &lt; ... &lt; x_k = 0 \\
P_2 &amp;= \{x_{k}, x_{k+1}, ...., x_{2k}\} \ &amp; \text{where} &amp;&amp; \ x_k = 0 &lt; x_{k+1} &lt; ... &lt; x_{2k} = 0
\end{align}$$</p>

<p>Since $f$ is continuous on $[-1,1]$, $m_i = \min(f : [x_{n-1}, x_n] \to \mathbb{R})$ and $M_i = \max(f : [x_{n-1}, x_n] \to \mathbb{R})$. </p>

<p>Therefore for $P_1$: $m_i = f(x_n)$ and $M_i = f(x_{n-1})$, and for $P_2$: $m_i = f(x_{n-1})$ and $M_i = f(x_n)$. </p>

<p>Finally putting all this together allows us to rewrite $L(f, P)$ and $U(f, P)$ as follows:</p>

<p>$$\implies L(f, P) = (x_n - x_{n-1})\left(\sum_{n=1}^{k}f(x_n) + \sum_{n=k}^{2k}f(x_{n-1})\right)$$</p>

<h2>$$\implies U(f, P) = (x_n - x_{n-1})\left(\sum_{n=1}^{n}f(x_{n-1}) + \sum_{n=k}^{2k}f(x_{n})\right)$$</h2>

<p>But I'm assuming when they say 'derive an expression' they want a closed form solution for the Riemann Sum,and I'm not sure how to convert what I've arrived at into a closed form, or if it is even possible to convert into closed form as the summand is varying.</p>

<p>Can a closed form solution for these lower and upper Riemann Sums be found?</p>
",calculus
"<blockquote>
  <p><strong>Problem:</strong></p>
  
  <p>Let $f(x,y)=x-\ln x - y +\ln y$ for $x,y&gt;0$. Prove that there exists a $\delta&gt;0$ and a function $\varphi : (-\delta, \delta)\to \mathbb{R}:\ \varphi \in C^1,\ \varphi(0)&lt;0,\ \forall_{x\in (1-\delta, 1+\delta)}\ f(x,1+(x-1)\varphi(x-1))=0$</p>
</blockquote>

<p>I came up with a bit of a solution but there must be an easier way. Also, I'd like find out if mine is correct and how to finish it.</p>

<p>Ok, it is easy to see that IFT won't work for the function $f$ because its derivative is zero on the line $y=x$. My idea is to modify the function.</p>

<p>Let $g(x) = x-\ln x$ and $F(x,y)=\frac{g(x)-g(y)}{x-y}$. We have $F=0 \Rightarrow f=0$. By Lagrange Theorem $F(x,y)=g'(c)$ where $c\in [x,y]$, thus by taking limit with $(x,y)\to (a,a)$ we have $F(a,a)=g'(a) = 1-\frac{1}{a}$. Hence $F$ is continuous on $\mathbb{R}^2_+$.</p>

<p>Now let's show that it's $C^1$ class. We only need to show that derivative is continuous on the line $x=y$. We have 
\begin{eqnarray*}
&amp;\frac{\partial F}{\partial x}(x,y) = \frac{(x-y)g'(x) -(g(x)-g(y))}{(x-y)^2}
\end{eqnarray*}
Thus
\begin{eqnarray*}
&amp;\lim _{h\to 0}\frac{\partial F}{\partial x}(x+h,x) = 
\lim_{h\to 0} \frac{hg'(x+h) -(g(x+h)-g(x))}{h^2} =\\
&amp;\lim_{h\to 0} \frac{hg'(x) + h^2g''(x)- hg'(x) - \frac{1}{2}h^2g''(x) +o(h^2)}{h^2}=\frac{1}{2}g''(x)= \frac{1}{2x^2}
\end{eqnarray*}
We can do the same for $\frac{\partial F}{\partial y} \Rightarrow$ F has continuous paritial derivatives, hence is of class $C^1$. Moreover $DF(x,y)=(0,0) \Rightarrow \frac{\partial F}{\partial x} + \frac{\partial F}{\partial y}=0 \Rightarrow \frac{g'(x)-g'(y)}{x-y}=0 \Rightarrow x=y$ but $DF(x,x)\neq (0,0)$ for $x&gt;0$ (which was proven above). So, $DF(x,y)\neq (0,0)$ for all $(x,y)$.</p>

<p>Hence we can apply IFT: there exists a $\delta &gt;0$ and $C^1$ class function $h:(1-\delta,1+ \delta):\ F(1+x,h(1+x))=0 \Rightarrow f(1+x,h(1+x))=0$. Now we can define $\varphi(x) := \frac{h(x+1)-1}{x}$. All we need o do is to check that $\varphi$ satisfies task conditions. We can write Taylor series for $h$ around the point $(x,y)=(1,1)$ (since we know that $DF(1,1)=(\frac{1}{2},\frac{1}{2})$) and obtain: $\frac{h(x+1)-1}{x} = \frac{1+2x+o(x)-1}{x} \to 2$ as $x\to 0$. </p>

<p>Here the trouble begins:
$\varphi$ doesn't satisfy the conditions but it would suffice to take $\bar{F}=-F(x,y)$ instead of $F(x,y)$ and $\bar{h}:\bar{F}(x,\bar{h}(x))=0$, then $\phi := \frac{\bar{h}(x+1)-1}{x} \to -2$ as $x\to 0$ so we can handle this problem. But how to show that $\varphi$ has continuous derivative at $x=0$? Do we have to compute the second Taylor polynomial for $h$? It's possible but seems like a lot of calculations..</p>

<p>I came across this problem on my calculus exam two days ago and it was only a part of a bigger one, so I don't believe the answer is that convoluted. It is the only thing I couldn't figure out so I would appreciate any help. </p>

<p><strong>EDIT:</strong> BTW: It should be true for any locally non-constant $C^1$ function $f$, that around it's local maxima/minima there exists a non-identity $C^1$ function $g$ that $f(a+x)=f(a+xg(x))$ for $x$ from neighbourhood of that maxima/minima - $a$. So the task is only a special case of this theorem, am I right?</p>
",calculus
"<p>A few days back I was asked this question in my class.</p>

<blockquote>
  <p><strong>Is $f:\mathbb{R}^2\to\mathbb{R}$ differentiable?</strong></p>
</blockquote>

<p>$f(x,y)=x+y$</p>

<p>My course of action was </p>

<p>$$\lim_{(\xi,\eta)\to(0,0)}\frac{f(x+\xi,y+\eta)-f(x,y)}{\sqrt{\xi^2+\eta^2}}=\lim_{(\xi,\eta)\to(0,0)}\frac{\xi+\eta}{\sqrt{\xi^2+\eta^2}}$$ which does not exist. </p>

<blockquote>
  <p>It is equal to $1$ if we take one of the variables $\xi$ or $\eta$ zero. (i.e. directional derivatives along the axes). If we take derivative along $x=y$, we get $\sqrt{2}$</p>
</blockquote>

<p>But someone told me that I was wrong and differentiability in $\mathbb{R}^2\to\mathbb{R}$ is determined only by the directional derivatives along the axes. Is it true? If yes, could someone explain? I am fairly new to the subject. Thanks!</p>
",calculus
"<p>I try with a simple example </p>

<p>I put $$f(x)=2x$$ </p>

<p>and $$f(2x)=4x$$</p>

<p>so </p>

<p>$$f(x)-f(2x)=-2x$$</p>

<p>and I try to solve the last equation </p>

<p>$$f(x)-f(2x)=-2x$$</p>

<p>by put $$f(x)=e^{mx}$$</p>

<p><a href=""http://www.wolframalpha.com/input/?i=solve%20e%5E%28mx%29-e%5E%282mx%29=-2x%20for%20m"" rel=""nofollow"">then the solution</a> $$e^{mx}=\frac{1}{2}\pm \sqrt{2x+\frac{1}{4}}\neq 2x$$</p>

<p>I know that $$e^{mx}-e^{2mx}=\frac{1}{2}\pm \sqrt{2x+\frac{1}{4}}-(\frac{1}{2}\pm \sqrt{2x+\frac{1}{4}})^{2}=-2x$$</p>

<p>but $$\frac{1}{2}\pm \sqrt{2x+\frac{1}{4}}\neq 2x$$</p>

<p>where is the wrong </p>

<p>and any way how to solve equation like $$f(x)\pm f(g(x))=m(x)$$</p>
",calculus
"<p>how to solve it answer is $0$, but $\frac 1{\infty + \infty}$ is indeterminate form</p>

<p>$$\lim_{x \to \pi/2} \frac 1{\sec x + \tan x}$$</p>
",calculus
"<p>I know that $x^x$ for all $x&gt;0$ </p>

<p>but what is negative values for that function which give a real number</p>

<p>for example  $$f(-1)=(-1)^{-1}=-1\in R$$</p>

<p>I try to put sequence for that but i faild </p>

<p>is there any help </p>

<p>thanks for all</p>
",calculus
"<p>I am trying to optimize the output of a given neural network with a single hidden layer.  To accomplish this, I intend to find solve for all combinations of inputs where the derivative of the neural network = 0 and select the input vector with the highest (or lowest, depending on the problem) neural network output.  It uses the activation function</p>

<p>$$
H_i,_j = \frac{1}{(1 + e^{-t})}
$$</p>

<p>where </p>

<p>$$
t = X_i\theta_j
$$</p>

<p>for a given input vector i and hidden node j. </p>

<p>The activation values of each hidden node are multiplied by a separate weight matrix to produce the outputs.  The output k of a given input vector i is the product of the hidden node activation values i and the weight vector k.</p>

<p>$$
O_i,_k = H_iW_k
$$</p>

<p>Could someone please explain the steps I would use to create the derivative formula for an input vector of arbitrary length, an arbitrary number of hidden nodes, a single hidden node layer, and a given output k?  Thank you so much.</p>
",calculus
"<p>I figured out that the top is (2x-1) and that the difference between the denominator ends up being (2x-1), just not sure how to figure out what the series is.</p>

<p><img src=""http://i.stack.imgur.com/WmZdl.png"" alt=""alternating series""></p>
",calculus
"<p>It's too much hassle to post it here as latex, to so here's <a href=""http://i.imgur.com/oa6RswP.png"" rel=""nofollow"">the screenshot</a>.</p>

<p>I don't understand why |cos(c)| = 1</p>

<p>Why 1? Why not $\frac {\sqrt{3}}{2}$? Why absolute value assumes the max value a function can take?
Shouldn't it be like:</p>

<p>$\cos(c) &gt; 0$</p>

<p>and $-\cos(c) &lt; 0$</p>

<p>?</p>
",calculus
"<p>I have a field of measured vectors, see example of four vectors in image below. If there was no noise they would all point outward exactly from one ""central point"". i.e. there would be a circle whose tangent is perpendicular to all vectors. Unfortunately there is some noise in the measurement, I am looking for the best approximation for the center of this circle.</p>

<p>Thanks for your ideas!</p>

<p><img src=""http://i.stack.imgur.com/M6Ym2.png"" alt=""Field of measured vectors""></p>
",calculus
"<p>$$\quad\quad \lim_{ x \to 0} \frac {\sin 5 x } {\sin 2 x } $$</p>

<p>I don't know how to start, should I multiply by something... to simplify the expression or ...?</p>
",calculus
"<p>I'm having trouble understanding the following progression of equalities.</p>

<p>$\begin{align*}
\ddot{x} &amp;= \frac{dv}{dt}\\
&amp;= \frac{dv}{dx} \frac{dx}{dt}\\
&amp;= v \frac{dv}{dx} \tag{1}\\
&amp;= \frac{1}{2} \frac{dv^2}{dx} \tag{2}
\end{align*}$</p>

<p>I understand up to $(1)$. In the previous line, I realize that $v=\frac{dx}{dt}$, but shouldn't $(1)$ have then been $\frac{dv}{dx} v$? Why is it acceptable to move $v$ to the left side of the differential; $v$ depends on $x$ and so will be operated on by it, won't it?</p>

<p>Accepting $(1)$, I don't understand how to get to $(2)$. I expect it has something to do with integrating $v$ so it can be moved to the right side; that would account for the $\frac{1}{2}$ and $v^2$, but I don't know the principle that makes $\frac{dv}{dx} v^2 = \frac{dv^2}{dx}$.</p>

<p>Trying to reach conceptual understanding by substituting in an example term, I do this, where $v=x^2$
$\begin{align*}
v \frac{d}{dx}v &amp;= \frac{1}{2} \frac{d}{dx} v^2\\
(x^2)(2x) &amp;= \frac{1}{2} (4x^3)\\
2x^3 &amp;= 2x^3
\end{align*}
$</p>

<p>I see that they are equal, but I don't understand. With my reasoning about the integration, this would have happened</p>

<p>$
\begin{align*}
v \frac{d}{dx} v &amp;= \frac{d}{dx}v \frac{1}{2}v^2\\
&amp;= \frac{1}{2} \frac{d}{dx} v^3
\end{align*}
$</p>

<p>which does not give equal answers.</p>

<p>Hopefully I've made my deficit of knowledge obvious and someone can prod me helpfully in the right direction. :)</p>
",calculus
"<p>Prove the identity:</p>

<p>$$n(n-1)2^{n-2}=\sum_{k=1}^n {k(k-1) {n \choose k}}$$</p>

<p>I tried using the binomial coefficients identity $2^n = \sum_{k=1}^n {n \choose k}$  but got stuck along the way.</p>
",calculus
"<p>In physics I ran into some nasty integrals involving characteristic functions $\chi$.</p>

<p>The ones are given by </p>

<p>$$\int_{\mathbb{R}^2} \left(E - \frac{p^2}{2m}-\frac{q^2 \omega^2}{2} \right)^{n-1} \chi_{[0,E]} \left( \frac{p^2}{2m}+\frac{q^2 \omega^2}{2} \right) \frac{p^2}{2m} dq dp,$$</p>

<p>$$\int_{\mathbb{R}^2} \left(E - \frac{p^2}{2m}-\frac{q^2 \omega^2}{2} \right)^{n-1} \chi_{[0,E]} \left( \frac{p^2}{2m}+\frac{q^2 \omega^2}{2} \right) \frac{q^2 \omega^2}{2}  dq dp,$$</p>

<p>where all constants are positive(!).</p>

<p>If anything is unclear, please let me know.</p>
",calculus
"<p>Since $\infty&gt;0$, so $1/\infty &gt;0$, thus I think $1/\infty$ should be infinitesimal, but the calculus book says 
$$\lim_{x \to \infty} \frac{1}{x}= 0$$</p>

<p>So is $1/\infty$ zero or infinitesimal ?</p>

<p>P.S. I mean are $1/\infty$ and $\lim_{x \to \infty} 1/x$ the same thing here?</p>
",calculus
"<p>I am suppose to differentiate </p>

<p>$y=(\sin x)^{\ln x}$</p>

<p>I have absolutely no idea, this was asked on a test and I just do not know how to do this I have forgotten the tricks I was suppose to memorize for the test.</p>
",calculus
"<p>=Could anyone help me show that:</p>

<p>$$
f(x) = -x^2 + 2x
$$</p>

<p>using</p>

<p>$$
f(ax + (1-a)y) \geq af(x) + (1-a)f(y)
$$
is CONCAVE in $(0,1)$? I am trying to solve it by directly substituting to the general theorem but I sem to prove just the opposite.</p>

<p>Update:</p>

<p>I managed to get:</p>

<p>$$
-(ax + (1-a)y)^2 \geq -ax^2 - y^2 + ay^2
$$</p>

<p>Anyone?</p>
",calculus
"<p>I have a $3$-D sphere of radius $R$, centered at the origin. </p>

<p>$(x_1,y_1,z_1)$ and<br>
$(x_2,y_2,z_2)$ are two points on the sphere. </p>

<p>The Euclidean distance is easy to calculate, but what if I were to restrict myself to traveling on the surface of the sphere?  </p>

<p>Two approaches come to mind: use <a href=""http://en.wikipedia.org/wiki/Arc_length"" rel=""nofollow"">arc-length</a> in some way, or simply use trigonometry: calculate the angle between the two points and get a distance from that.  </p>

<p>Will both/either of these methods work? Which would be easier?</p>

<p>Somewhat related to <a href=""http://math.stackexchange.com/questions/720/how-to-calculate-a-heading-vector-on-the-earths-surface"">this question</a>. Maybe it will inspire someone to go answer it!</p>
",calculus
"<p>Wind resistance -- upwards acceleration, typically varies either linearly or quadratically by the current velocity.</p>

<p>There is a constant downward acceleration due to gravity.</p>

<p>How can we model the velocity over time of a falling object, subject only to wind resistance and downwards gravity?</p>

<p>I don't have much experience with differential equations, but I do know that this answer necessarily involves it, so could you possibly explain every step?</p>

<p>Thank you.</p>
",calculus
"<p>What is the volume of intersection of the three cylinders with axes of length $1$ in $x, y, z$ directions starting from the origin, and with radius $1$?</p>
",calculus
"<p>There is a  theorem of Riemann to that effect. How to prove it?</p>

<p>Note: This was asked by Kenny in the beta for ""calculus"".</p>
",calculus
"<p>What class of Partial Differential Equations can be solved using the method of separation of variables?</p>
",calculus
"<p>There are so many available bases. Why is the strange number $e$ preferred over all else?</p>

<p>Of course one could integrate $\frac{1}x$ and see this. But is there more to the story?</p>
",calculus
"<p>There are quite simple, intuitive and straightforward expressions for evaluating the area or volume of a figure. But why is the expression for the length of a curve so complicated?</p>
",calculus
"<p>""Find the derivative of $y=x\sqrt{9-x}$.""</p>

<p>So this is what I have and now I'm stuck.</p>

<p>\begin{align}
y' &amp;= x \frac{d}{dx}\left[(9-x)^{1/2}\right] + (9-x)^{1/2} \frac{d}{dx}(x)\\
   &amp;= x \left[\frac{1}{2}(9-x)^{-1/2}\right] + (9-x)^{1/2} (1)
\end{align}</p>

<p>So I now that I need to multiply and simplify but I don't know where to start. Help!</p>

<p>This problem is actually part of a homework question where I have to analyze a graph and find critical points and min and max.</p>
",calculus
"<blockquote>
  <p>Does the graph of the function $f$ have tangent line at the given points? If yes, what is the tangent line?</p>
  
  <p>$f(x)=(x+2)^{3/5}$ at $x=-2$</p>
</blockquote>

<p>solution: yes, $x=-2$</p>

<p>The derivative I found:</p>

<p>$$f'(x)=\frac 3{5(x+2)^\frac 25}$$</p>

<p>and then I get $f'(-2)=\frac 3{5\cdot 0}=\frac 30$ which is undefined.</p>

<p>anyone know how to go about this problem? I got the slope or whatever to be undefined or something, any tips/solution appreciated!</p>
",calculus
"<p>The function has 2 parts: </p>

<p>$$f(x) = \begin{cases} -\sin x &amp; x \le 0 \\ 2x &amp; x &gt; 0\end{cases}$$</p>

<p>I need to calculate the integral between $-\pi$ and $2$.
So is the answer is an integral bewteen $-\pi$ and $0$ of $f(x)$ and then and $0$ to $2$.
but why the calculation of the first part of $-\pi$ and $2$ aire on $-\sin x$ and the second part of the intgral is on $x^2$, which is part of the $F(x)$.</p>

<p>I'd like to get some help over here, I'm lost </p>
",calculus
"<p>$$\int_{1}^{\infty} \frac{\ln{(2x-1)}}{x^2} dx$$</p>

<p>My approach is to calc
$$\int_{1}^{X} \frac{\ln{(2x-1)}}{x^2} dx$$ and then take the limit for the answer when $X \rightarrow \infty$</p>

<p>However, I must do something wrong. The correct answer should be $2\ln(2)$.</p>

<p>$$\int_{1}^{X} \frac{\ln{(2x-1)}}{x^2} dx = \left[-\frac{1}{x} \ln (2x-1) \right]_{1}^{X} + \int_{1}^{X} \frac{1}{x} \times \frac{2}{2x-1} dx = -\frac{1}{X}\ln(2X-1) + 2\int_{1}^{X} -\frac{1}{x} + \frac{2}{2x-1} dx = -1\frac{1}{X}\ln(2X-1)-2\ln X+2\ln(2X-1) $$</p>

<p>Am I wrong? If I'm not, how to proceed? </p>

<p>=== EDIT ===</p>

<p>After the edit I wonder if this is the correct way to proceed:</p>

<p>$$ - \frac{1}{X}\ln(2X-1)-2\ln X+2\ln(2X-1) $$ The first part will do to zero because of $\frac{1}{X} $ so we ignore that one, the second and third part: </p>

<p>$$ -2\ln X+2\ln(2X-1) = 2\ln \left( \frac{2X-1}{X}\right) = 2\ln \left( 2-\frac{1}{X}  \right) = 2\ln (2)$$</p>
",calculus
"<p>Which of the following statements are ??</p>

<p>a. Let $\phi$ be a non-negative and continuously differentiable function on $(0,\infty)$ such that $\phi'(x)\le\phi(x)$ for all $x$ $\in (0,\infty)$. Then </p>

<p>$$lim_{x\to \infty}\phi(x)=0$$ </p>

<p>b. Let $\phi$ be a non-negative function continuous on $[0,\infty)$ and differentiable on     $(0,\infty)$ such that $\phi(0)=0$ and such that   $\phi'(x)\le\phi(x)$ for all $x$ $\in   (0,\infty)$. Then $\phi=0$.</p>

<p>c. Let $\phi$ be a non-negative function continuous on $[0,\infty)$ and such that 
      $$\phi(x) \le \int_{0}^{x}\phi(t) dt$$ for all $x \in [0,\infty)$. Then $\phi=0$.</p>
",calculus
"<p>Give an $\epsilon$-$\delta$ proof to show that for any positive integer $n$ we have $\begin{align} \lim \frac{1}{x^n} =0 \end{align}$ as $x→\infty$.</p>

<p>How would you incorporate $\epsilon$-$\delta$ formalism to prove this limit?</p>

<p>Also on a side note, if one part of a limit of the function is approaching negative infinity, and on the right side of the limit it's a point, would it be considered as a infinite discontinuity?</p>
",calculus
"<p>Let $\mathcal{S}_{x}=\{x_{1,},x_{2},\ldots x_{n}\}$ be a set of $n$
indeterminates. The $h^{th}$elementary symmetric polynomial is the
sum of all monomials with $h$ factors
\begin{eqnarray*}
e_{h}(\mathcal{S}_{x}) &amp; = &amp; \sum_{1\leqslant i_{1}&lt;i_{2}&lt;\ldots&lt;i_{h}\leqslant n}x_{i_{1}}x_{i_{2}}\ldots x_{i_{h-1}}x_{i_{h}}
\end{eqnarray*}
which, from a generating function standpoint, can be built up as the
coefficients of the $h^{th}$ power of the following linear factorization
\begin{eqnarray*}
\prod_{i=1}^{n}(1+x_{i}z) &amp; = &amp; (1+x_{1}z)(1+x_{2}z)(1+x_{3}z)\ldots(1+x_{n}z)\\
 &amp; = &amp; \sum_{h=0}^{n}e_{h}(\mathcal{S}_{x})z^{h}
\end{eqnarray*}</p>

<blockquote>
  <p>Some usual specializations of the set $\mathcal{S}_{x}$ lead to
  known families of numbers and multiplicative identities: binomial
  coefficients for $x_{i}=1_{i}$, to $q$-binomial coefficients for
  $x_{i}=q^{i}$ and Stirling numbers of the first kind for $x_{i}=i$;</p>
</blockquote>

<p>(i) For $\mathcal{S}_{1}=\{1_{1},1_{2},1_{3},\ldots,1_{n}\}$ 
\begin{eqnarray*}
(1+z)^{n} &amp; = &amp; (1+1_{1}z)(1+1_{2}z)(1+1_{3}z)\ldots(1+1_{n}z)\\
 &amp; = &amp; \sum_{h=0}^{n}{n \choose h}z^{h}
\end{eqnarray*}
binomial coefficients arise $e_{h}(\mathcal{S}_{1})={n \choose h}$</p>

<p>(ii) For $\mathcal{S}_{q^{i}}=\{q,q^{2},q^{3}\ldots,q^{n-1},q^{n}\}$
\begin{eqnarray*}
\prod_{i=1}^{n}(1+q^{i}z) &amp; = &amp; (1+q^{1}z)(1+q^{2}z)(1+q^{3}z)\ldots(1+q^{(n-1)}z)\\
 &amp; = &amp; \sum_{h=0}^{n}{n \choose h}_{q}q^{{h+1 \choose 2}}z^{h}
\end{eqnarray*}
we get the $q$-binomial coefficients (or Gaussian coefficients) $e_{h}(\mathcal{S}_{q^{i}})={n \choose h}_{q}q^{{h+1 \choose 2}}$</p>

<p>(iii) And for $\mathcal{S}_{i}=\{1,2,3,\ldots n-1\}$
\begin{eqnarray*}
\prod_{i=1}^{n-1}(1+iz) &amp; = &amp; (1+1z)(1+2z)(1+3z)\ldots(1+(n-1)z)\\
 &amp; = &amp; \sum_{h=0}^{n}\left[\begin{array}{c}
n\\
n-h
\end{array}\right]z^{h}
\end{eqnarray*}
Stirling numbers of the
first kind arise $e_{h}(\mathcal{S}_{i})=\left[\begin{array}{c}
n\\
n-h
\end{array}\right]$</p>

<blockquote>
  <p>In this context, are there other specializations of the set $\mathcal{S}_{x}=\{x_{1,},x_{2},\ldots x_{n}\}$
  which lead to other families of numbers or identities?</p>
</blockquote>
",combinatorics
"<p>A graph property is <em>hereditary</em> if it is closed under taking induced subgraphs (equivalently, if it is closed under removing vertices).  A graph property is <em>monotone</em> if it is closed under taking subgraphs.  (Note that ""monotone"" is sometimes used in different ways from what I've just written.)  Thus, every monotone property is hereditary (but not conversely).  Every monotone property can be characterized by a set of forbidden subgraphs, and every hereditary property can be characterized by a set of forbidden induced subgraphs.  (In each case, the set of forbidden graphs may be infinite.)</p>

<p>Given a (monotone or hereditary) property $\mathcal{P}$, it's easy to define a set $\mathcal{F}$ of forbidden subgraphs (or forbidden induced subgraphs): if $\mathcal{U}$ is the set of all finite unlabeled graphs, set $\mathcal{F} = \mathcal{U} \setminus \mathcal{P}$.  However, this is not very useful.  Many hereditary properties can be characterized by simpler set of forbidden subgraphs: for example, perfect graphs are exactly the graphs with no induced $C_{2k+1}$ or $\overline{C_{2k+1}}$ for any $k \geq 2$.</p>

<p>However, I'm having a harder time coming up with examples of monotone properties that have ""non-trivial"" characterizations in terms of forbidden subgraphs.  Of course, for any graph $H$, the class of $H$-free graphs is trivially characterized by taking $\mathcal{F} = \{H\}$.  The only other example that comes to mind is bipartite graphs, which are characterized by forbidding odd cycles.</p>

<p>What other examples are there?</p>
",combinatorics
"<p>Hi all,</p>

<p>Let be $G_n=(V_n,E_n)$ a finite graph, where 
$V_n= \{0,1,\ldots, n\} \times\{0,1,\ldots,n\}$ </p>

<p>and $E_n\subset V_n^{(2)}$ is the edge set of the nearest neighbors in the $\ell^1$ norm, that is,
$\ E_n=\{\ \{z,w\}\subset V_n; \ \sum_{i=1}^2 |z_i-w_i| =1 \ \}.$ </p>

<p>Fix a vertex $x=(x_1,x_2)\in G_n$ such that $x_2&gt;x_1$ (up-diagonal). 
I would like to know if it is true the following inequality:</p>

<p>$\sharp[m,p]_{x}\leq \sharp[p,m]_x$, whenever $p &lt; m$</p>

<p>where $[m,p]_{x}$ is the set of all spanning subgraphs of $G_n$ 
satisfying the following properties:</p>

<p>1- the spanning subgraph has $m$ horizontal edges and $p$ vertical edges;</p>

<p>2- the vertices $(0,0)$ and $x=(x_1,x_2)$ are in the same connected component,</p>

<p>and $\sharp A$ is the cardinality of $A$.</p>

<p>In other words, if I have avaliable more vertical edges than horizontal ones is it true that I can find more configurations connecting
$0$ and $x$ if $x$ is up-diagonal than in case that the quanties of horizontal and vertical are inverted ?   </p>

<p>Thanks in advance for any idea or reference.</p>
",combinatorics
"<p>$\bf Note.$ This question had a bounty, so at the end I accepted the best (and only) answer but in fact it is still open. It is (hopefully) equivalent to <a href=""http://mathoverflow.net/questions/15204/space-bounded-communication-complexity-of-identity"">this question</a>, if you have any ideas, please post them there.</p>

<p>$\bf Question.$
Fix n. We are interested in the biggest t for which there exist two families of functions, $P_i,Q_i$, of size t from [n] to [n] such that for any $i,j$ whenever we consider the infinite sequence $P_i(Q_j(P_i(Q_j\ldots P_i(3))\ldots)$ (where the number of iterations tends to infinity), it contains no 2's and infinitely many 1's if $i=j$ and it contains no 1's and infinitely many 2's if $i\ne j$.</p>

<p>$\bf A lower bound.$
I know a construction that shows that $t\ge 2^{\frac n2-O(1)}.$ For every subset $S$ of [n] that contains exactly one of $2k$ and $2k+1$ for $2\le k\le \frac n2-2$ we construct a pair of functions, $P_S,Q_S$ as follows. For any number m denote by $m^+$ the smallest element of $S$ that is bigger than m or if all elements of $S$ are at most m then define it to be 1.
$P_S(1)=1, P_S(2)=2$ and for bigger $m$'s $P_S(m)=m^+$, while $Q_S(1)=1, Q_S(2)=2$ and for bigger $m$'s $Q_S(m)=m$ if $m\in S$ and $Q_S(m)=2$ if $m\notin S$. This way we go through all the elements of S and end in 1 if the functions have the same index, but we are pushed to 2 if they differ.</p>

<p>$\bf Upper bound.$
It is of course true that $t\le n^n$. So can you do better than $2^n$?</p>
",combinatorics
"<blockquote>
  <p>What is the length $f(n)$ of the shortest nontrivial group word $w_n$ in $x_1,\ldots,x_n$ that collapses to $1$ when we substitute $x_i=1$ for any $i$?</p>
</blockquote>

<p>For example, $f(2)=4$, with the commutator $[x_1,x_2]=x_1 x_2 x_1^{-1} x_2^{-1}$ attaining the bound.  </p>

<p>For any $m,n \ge 1$, the construction $w_{m+n}(\vec{x},\vec{y}):=[w_m(\vec{x}),w_n(\vec{y})]$ shows that $f(m+n) \le 2 f(m) + 2 f(n)$.</p>

<p>Is $f(1),f(2),\ldots$ the same as sequence <a href=""http://oeis.org/A073121"">A073121</a>:
$$ 1,4,10,16,28,40,52,64,88,112,136,\ldots ?$$</p>

<p><strong>Motivation:</strong> Beating the iterated commutator construction would improve the best known bounds in <a href=""http://mathoverflow.net/questions/15022/size-of-the-smallest-group-not-satisfying-an-identity/15065#15065"">size of the smallest group not satisfying an identity</a>.</p>
",combinatorics
"<p>I've been searching for the answer for many years, both by researching by myself and reading about the subject. Now I'm wondering if this has a solution.</p>

<p>The problem can be stated as follows.</p>

<p>Given a M x N grid of points, how many triangles with vertices in the grid can be formed?
Note that you can't select two points that coincide or three collinear points because that wouldn't conform a triangle (area would be 0)</p>

<p>OK, I know a bit of programming and could manage to code a program that solves this, but would REALLY like to know if there is a general form depending on M and N.
I suspect it has to do with prime numbers... (Perhaps I totally missed heheh)</p>

<p>Thanks for your time!
Manuel</p>
",combinatorics
"<p>Consider the polynomial $(1+x)(1+x^2)\dots (1+x^n)=1+x+\dots+x^{n(n+1)/2}$, which enumerates subj. How to prove that it's coefficients increase up to $x^{n(n+1)/4}$ (and hence decrease after this)? Or maybe this is false? </p>

<p>This problem was proposed long ago on some Russian high school competition, but nobody managed to solve, including jury.</p>
",combinatorics
"<p>I am having trouble verifying the following claim in Van Vu's 2000 paper ""On a refinement of Waring's problem"". First we define a few things.</p>

<p>Let $m \in \mathbb{N}_0$ and $r \geq 2, r \in \mathbb{N}$ be fixed. Choose $P_j \in $ {$2, 4, \cdots, 2^t$} where $t$ is chosen so that $2^t$ is the smallest integer power of 2 bigger than $m^{1/r}$. Suppose that $l \in \mathbb{N}$ is sufficiently large. Let $\mathcal{P}$ denote the set of $l$-tuples {$P_1, \cdots, P_l$} with $2 \leq P_1 \leq \cdots \leq P_l$. For each $A \in \mathcal{P}$, write $P_A = \prod_{P_j \in A} P_j$. Then verify the inequality
$$\displaystyle \sum_{A \in \mathcal{P}} P_A^{r/l} = O(m)$$</p>

<p>The idea here is that if $P_A$ is as large as possible, then $P_A^{r/l} = O(m^{l/r \cdot r/l}) = O(m)$, and the other terms are not so significant since the number of summands is small. However, how do I rigorously show that we indeed have the bound $O(m)$ instead of say, $O(m^{1 + \epsilon})$?</p>
",combinatorics
"<p>Are there any theorems related to the product of Jacobi/Legendre Polynomials and/or Hypergeometric functions? Specifically, I'm interested in the product of ${}\_{2}F_{1}[-n,-n+1;2;x]$ and ${}\_{2}F_{1}[-n-1,-n+3;2;x]$ hoping to obtain it in some form ${}_{p}F_{q}$.</p>

<p>I've found some stuff in Bailey (1928,1935), but it has solutions only for some special cases. I've also obtained the coefficient of k'th term $\frac{x^k}{k!}$. I get (in case I didn't make any mistakes)</p>

<p>$\sum_{m=0}^{k} \binom{k}{m} \binom{n}{m}\binom{n-1}{m}\binom{n+1}{k-m}\binom{n-3}{k-m} \frac{m!(k-m)!}{(m+1)(k-m+1)}$, but I don't quite see what to do next. </p>
",combinatorics
"<p>This question is a hacky way to create some tags for you to use. Move along.</p>
",combinatorics
"<p>I'm wondering whether the following polynomial of a single indeterminate has been studied: take the (partial) Bell polynomial $B_{n,k}$, which is a polynomial in indeterminates $x_1$, $x_2$, …, $x_{n-k+1}$, and replace each indeterminate $x_i$ by the falling factorial $(x)_i=x(x-1) \dots (x-i+1)$. Call this polynomial $N(n,k)$.</p>

<p>I conjecture the following matrix identity. Assemble the polynomials into an infinite lower-triangular matrix $N$. Let $s$ be the lower-triangular matrix of Stirling numbers of the first kind. Let D be the diagonal matrix with entries $x$, $x^2$, $x^3$, ….</p>

<p>Conjecture: $Ns=sD$</p>
",combinatorics
"<p>For $X=\lbrace 0,\ldots,n-1\rbrace$, let $F\subseteq 2^X$ be a family of subsets of $X$ such that, for every $x\in X$, the singleton $\lbrace x\rbrace$ is the intersection of some elements of $F$. I am interested in the minimal families that have this property, in particular whether it is possible to have $|F|&lt; n$. Can anyone (a) give an example where $|F|&lt; n$, (b) provide an argument for why $|F|\ge n$, or (c) point me in the direction of some existing results.</p>

<p>Bonus question: For any $k&lt; n$, the family $F= \lbrace \lbrace x,x+1,\ldots,x+k-1 \rbrace:x\in X \rbrace$, where addition is carried out modulo $n$, satisfies the stated condition (minimally) and contains exactly $n$ elements, so $|F|= n$ is always achievable. How does the structure of a general minimal family relate to these highly regular families? Is a minimal family always a disjoint union of some regular families?</p>
",combinatorics
"<p>I have been recently learning a lot about Macdonald polynomials, which have been shown to have probabilistic interpretations, more precisely the eigenfunctions of certain Markov chains on the symmetric group. </p>

<p>To make this post more educational, I will define these polynomials a bit. Consider the 2-parameter family of Macdonald operators (indexed by powers of the indeterminate $X$) for root system $A_n$, on a symmetric polynomial $f$ with $x = (x_1, \ldots, x_n)$:</p>

<p>$$D(X;t,q) = a_\delta(x)^{-1} \sum_{\sigma \in S_n} \epsilon(\sigma) x^{\sigma \delta}\prod_{i=1}^n (1 + X t^{(\sigma \delta)_i} T_i),$$</p>

<p>(mathoverflow doesn't seem to parse $T_{q,x_i}$ in the formula above, so I had to use the shorter symbol $T_i$, which depends on q).</p>

<p>where $\delta$ is the partition $(n-1,n-2,\ldots, 1,0)$, $a_\delta(x) = \prod_{1 \le i &lt; j \le n} (x_i - x_j)$ is the Vandermonde determinant (in general $a_\lambda(x)$ is the determinant of the matrix $(a_i^{\lambda_j})_{i,j \in [n]}$). </p>

<p>$x^{\sigma \delta}$ means $x_1^{(\sigma \delta)_1} x_2^{(\sigma \delta)_2} \ldots x_n^{(\sigma \delta)_n}$.</p>

<p>Also $(\sigma \delta)_i$ denotes the $\sigma(i)$-th component of $\delta$, namely $n-i$. </p>

<p>Finally the translation operator $T_i = T_{q,x_i}$ is defined as
$$ T_{q,x_i}f(x_1, \ldots, x_n) = f(x_1, \ldots, x_{i-1}, q x_i , x_{i+1} ,\ldots, x_n).$$</p>

<p>I like to think of the translation operator as the quantized version of the differential operator $I + \partial_i$, where $q-1$ is analogous to the Planck constant(?). </p>

<p>If we write $D(X;q,t) = \sum_{r=0}^n D_{n-r}(q,t) X^r$, then 
Macdonald polynomials $p_\lambda(q,t)$ are simply simultaneous eigenfunctions of these operators. When $q=t$ they become Schur polynomials, defined by $s_\lambda = a_{\delta  +\lambda} / a_\delta$. When $q= t^\alpha$ and $t \to 1$, we get Jack symmetric polymomials, which are eigenfunctions of a Metropolis random walk on the set of all partitions that converge to the so-called Ewens sampling measure, which assigns probability proportional $\alpha^{\ell(\lambda)} z_\lambda^{-1}$. When $q = 0$, they become the Hall-Littlewood polynomials and when $t=1$ they become the monomial symmetric polynomials etc. </p>

<p>I was told repeatedly by experts that Macdonald polynomials exhaust all previous symmetric polynomial bases in some sense. Does anyone know a theorem that says that every family of symmetric polynomial under some conditions can be obtained from Macdonald polynomials by specializing the $q$ and $t$? </p>
",combinatorics
"<p>I've been wrestling with a certain research problem for a few years now, and I wonder if it's an instance of a more general problem with other important instances. I'll first describe a general formulation of the problem, and then I'll reveal my particular instance.</p>

<p>Let $S_n$ denote a set of objects of size $n$. I am interested in subsets $G_n\subseteq S_n$ with two properties:</p>

<ol>
<li><p>There are natural probability distributions on $S_n$ for which a random member lands in $G_n$ with high probability, so $G_n$ is ubiquitous in some sense. </p></li>
<li><p>It seems rather difficult (and it might be impossible) to efficiently construct a member of $G_n$ along with a certificate of its membership which can be verified in polynomial time.</p></li>
</ol>

<p><strong>Question:</strong> Do you have an example of $G_n$ which satisfies both of these?</p>

<p>Here's my example: Let $S_n$ denote the set of real $m\times n$ matrices with $1\leq m\leq n$, fix a constant $C&gt;0$, and say $\Phi\in G_n$ if the following holds for each $k$ satisfying $m\geq Ck\log(n/k)$: If $x\in\mathbb{R}^n$ has $k$ nonzero entries, then</p>

<p>$$\frac{1}{2}\|x\|^2\leq\|\Phi x\|^2\leq\frac{3}{2}\|x\|^2.$$</p>

<p>(This is essentially what it means for $\Phi$ to satisfy the restricted isometry property.) In this case, $G_n$ satisfies 1 above (provided $C$ is sufficiently large) by considering matrices with iid subgaussian entries. The fact that $G_n$ is plagued with 2 above is the subject of <a href=""http://terrytao.wordpress.com/2007/07/02/open-question-deterministic-uup-matrices/"">this blog entry by Terry Tao</a>.</p>
",combinatorics
"<p>Fix $C&gt;0$. I am interested in graphs with the following mixing property:</p>

<p>$$\Big|E(S,T)-\frac{1}{2}|S||T|\Big|\leq C\sqrt{|S||T|\max\{|S|,|T|\}}$$</p>

<p>for every disjoint $S,T\subseteq V$. Note that this is stronger than what the <a href=""http://en.wikipedia.org/wiki/Expander_mixing_lemma"" rel=""nofollow"">expander mixing lemma</a> guarantees for expander graphs with $d=n/2$.</p>

<p>Has this particular property been studied already?</p>
",combinatorics
"<p>Let me state a standard result first. Let a $A\subset \mathbb{R}^d$ be a set of fixed volume. Define $A_t$ to be the set of all points at distance at most $t$ from $A$. Then the volume of $A_t$ is minimal if $A$ is a ball of the prescribed volume.</p>

<p>Another way to define $A_t$ is by $A_t=A+B(0,t)$, where $B(0,t)$ is the centered ball of radius $t$. We shall think of it as the union of translates of $A$ by all vectors in $B(0,t)$.</p>

<p>I am interested in extending such a result to the discrete setting. Say, we translate $A$ only in the $d$ orthogonal directions. That is, we look at the union $U(A)=\cup_v (A+v)$, where $v$ is either the zero vector or $\pm e_i$, where $e_i$ is an element of the standard orthonormal basis.</p>

<p>Given that the volume of $A$ is fixed, which $A$ minimize the volume of $U(A)$? </p>
",combinatorics
"<p>For $m \geq 1$, define a <strong>link</strong> to be a zero-one word $w=d_0d_1 \ldots d_k$, where $d_0=0$ and $k=2^m-1$ , such that the words</p>

<p>$$ w_0=0^{m-1}d_0, w_1=w_0d_1, w_2=w_1d_2, \ldots, w_k = w_{k-1}d_k $$</p>

<p>include as subwords every zero-one word of length $m$.  How many links are there, and how can they be produced?  If the answer is known, all I need is a reference.  Otherwise, the question extends naturally to links of words on the alphabet from $0$ to $n&gt;1$. </p>

<p><strong>Example:</strong>  For $m = 3$ two links are $01011100$ and $01110100$.  The first link codes the following words: 
$$w_0 = 000, w_01, w_010, w_0101, w_01011, w_010111, w_0101110, w_01011100, w_010111000, $$
in which all $8$ zero-one words of length $3$ occur as the final $3$ letters of the words.  (The final word, $w_010111000$, is shown as the first word in a second link in an infinite chain.)  </p>
",combinatorics
"<p>This is not a math question as much as a process question. For the first time in my (very short) career, I find myself doing one of those messy calculations, where each 'line' of the calculation can spread over a page or three. Essentially all of the calculation is trivial if I'm willing to write some reasonable inequalities in places, and all of these choices are obvious as they're being made, but I am having a rough time keeping the assumptions on term sign required for the various inequalities and the calculations themselves even close to organized, and the copying errors are a nightmare.</p>

<p>Does anybody have any good suggestions on how to stay organized for this sort of trivial-in-theory but messy-in-practice calculation? What do you actually <em>do</em> in these situations? This is especially directed at people in areas like statistical physics or mathematical statistics where these sorts of things show up frequently, and there must be some way of dealing with them. Clever renaming of variables, latexing as you go, good use of Maple...?</p>
",combinatorics
"<p>Suppose we have a finite, 100-uniform system of sets such that any point is contained in at most 3 sets. Is it true that we can color the points such that every set contains 50 red and 50 blue points?</p>

<p>The question is by Thomas Rothvoss. A positive answer would solve the <a href=""http://www.math.sc.edu/~cooper/combprob.html"">Three permutations problem of Beck</a>, so a simple answer would be a counterexample...</p>
",combinatorics
"<p>In the book ""A = B"" by Petkovesk, Wilf, and Zeilberger, <a href=""http://www.math.upenn.edu/~wilf/Downld.html"">(downloadable here)</a>, the authors provide several algorithmic methods for finding closed forms or recurrences for sums involving e.g. binomial coefficients.  Even more exciting, their methods provide seemingly short certificates for the truth of these computer-verified claims.  In particular, the WZ method prints a single rational function as such a certificate.</p>

<p>In more detail, here is the broad outline of the WZ method, where I directly quote from page 25 of ""A = B"":</p>

<blockquote>
  <ol>
  <li>Suppose that you wish to prove an identity of the form $\sum_k t(n, k) = rhs(n)$,
  and let’s assume, for now, that for each n it is true that the summand $t(n, k)$
  vanishes for all $k$ outside of some finite interval.</li>
  <li>Divide through by the right hand side, so the identity that you wish to prove
  now reads as $\sum_k F (n, k) = 1$, where $F (n, k) = t(n, k)/rhs(n)$.</li>
  <li>Let $R(n, k)$ be the rational function that the WZ method provides as the proof
  of your identity (this is described in Chapter 7 of ""A=B""). Define a
  new function $G(n, k) = R(n, k)F (n, k).$</li>
  <li>You will now observe that the equation
                   $$F (n + 1, k) − F (n, k) = G(n, k + 1) − G(n, k)$$
  is true. Sum that equation over all integers $k$, and note that the right side
  telescopes to 0. The result is that
                             $$\sum_k F (n + 1, k) =    \sum_k F (n, k),$$
  hence we have shown that         $\sum_k F (n, k)$ is independent of $n$, i.e., is constant.         </li>
  <li>Verify that the constant is $1$ by checking that        $F (0, k) = 1$.</li>
  </ol>
</blockquote>

<p>What I want to know is:</p>

<blockquote>
  <p>Are there known bounds on the length of these certificates $R(n, k)$, in terms of the length of the description of the combinatorial sum in question?  If so, what are they?</p>
</blockquote>
",combinatorics
"<p>Let G(q) be the generating function for partitions such that if k is a part, then it occurs once and k+1 is not a part. </p>

<p>Let H(q) be the generating function for partitions with the same condition plus that 1 is not a part.</p>

<p>These are the left-hand sides of the Rogers-Ramanujan Identities.</p>

<blockquote>
  <p>$G(q)=\displaystyle\sum_{n=0}^\infty\frac{q^{n^2}}{(q;q)_n}=\frac{1}{(q;q^5)_\infty(q^4;q^5)_\infty}$</p>
  
  <p>$H(q)=\displaystyle\sum_{n=0}^\infty\frac{q^{n^2+n}}{(q;q)_n}=\frac{1}{(q^2;q^5)_\infty(q^3;q^5)_\infty}$</p>
</blockquote>

<p>I am intrigued by the following unreferenced statement in the wikipedia <a href=""http://en.wikipedia.org/wiki/Rogers%E2%80%93Ramanujan_identities#Modular_functions%20%22page%22"" rel=""nofollow"">page</a>:</p>

<blockquote>
  <p>If q = e<sup>2πiτ</sup>, then q<sup>−1/60</sup>G(q) and q<sup>11/60</sup>H(q) are modular functions of τ.</p>
</blockquote>

<ol>
<li><p>Do modular forms shed any light on the Rogers-Ramanujan Identities, or is the connection (as far as we know) a curious coincidence?</p></li>
<li><p>Is there some class of modular forms whose Fourier series count natural collections of partitions such as those counted by the left-hand sides of the Rogers-Ramanujan Identities? In particular I have in mind the seemingly ""non-local"" condition that if k is part, then it is distinct and also k+1 is not parts.</p></li>
<li><p>In general, how does one tell if a certain generating function (that counts partitions of a certain type, say) is related (by a multiplicative factor like above) to a modular form of some weight for some group (maybe even with some character)?</p></li>
</ol>
",combinatorics
"<p>I am trying to prove $\sum\limits_{j=0}^{k-1}(-1)^{j+1}(k-j)^{2k-2} \binom{2k+1}{j} \ge 0$. This inequality has been verified by computer for $k\le40$.</p>

<p>Some clues that might work (kindly provided by Doron Zeilberger) are as follows:</p>

<ol>
<li><p>Let $Ef(x):=f(x-1)$, let $P_k(E):=\sum_{j=0}^{k-1}(-1)^{(j+1)}\binom{2k+1}{j}E^j$;</p></li>
<li><p>These satisfy the inhomogeneous recurrence $P_k(E)-(1-E)^2P_{k-1}(E) =$ some binomial in $E$;</p></li>
<li><p>The original sum can be expressed as $P_k(E)x^{(2k-2)} |_{x=k} $;</p></li>
<li><p>Try to derive a recurrence for $P_k(E)x^{(2k-2)}$ before plugging in
$x=k$ and somehow use induction, possibly having to prove a more general statement to facilitate the induction.</p></li>
</ol>

<p>Unfortunately I do not know how to find a recurrence such as suggested by clue 4.</p>
",combinatorics
"<p>Let $X$ be a random variable following the hypergeometric distribution with parameters $N,K,n$, where 
\begin{equation}
Pr(X=k) = \frac{\binom{K}{k}\binom{N-K}{n-k}}{\binom{N}{n}}.
\end{equation}
To make things easier, we bring symmetry and avoid the boundry issues by letting $K=\frac{N}{2}$ and $n&lt;K$. For an odd $n$, we know by symmetry
\begin{equation}
Pr(X~even)=Pr(X~odd).
\end{equation}
For an even $n$, my conjecture is that 
\begin{equation}
\vert Pr(X~even)-Pr(X~odd) \vert \leq \frac{\binom{N}{n/2}}{\binom{N}{n}}. 
\end{equation} 
I ran some simulations and the result shows that it should be true, but I have not been able to prove it so far. Could someone help me with that? </p>

<p>If this question is answered, a subsequent question is the case where $K$ is roughly $\frac{N}{2}$ but not exact. A corresponding condition is $\vert K-\frac{N}{2}\vert \leq c N$, for a constant $0&lt;c&lt;0.5$. We still assume $n&lt;min (K, N-K)$ to avoid boundary issues. The conjecture is still the same in this case.</p>

<p>I try not to be greedy and will be much satisfied if only the first question is answered. Many thanks in advance! </p>
",combinatorics
"<p>In a prior <a href=""http://mathoverflow.net/questions/226583/densest-graphs-with-unique-perfect-matching"">post</a> regarding perfect matching, it was stated that the densest graph with a unique perfect matching cannot have more than $n^2$ edges, if graph has $2n$ vertices.</p>

<p>Analogously, what is the densest bipartite graph with unique Hamiltonian cycle?</p>
",combinatorics
"<p>What would be the closed-form expression defining number of all possible labelled connected bipartite graphs given $\mid X \mid = m,  \mid Y \mid = n - m $? </p>
",combinatorics
"<p>Given a multi-set of pairs $((a_i,b_i))_{i \in Y}$ of positive numerator and denominator terms (i.e. each pair has one numerator term and one denominator term), my general problem is to find the optimal combination of pairs defined by $I^* \subseteq Y$, which maximizes an objective of the form</p>

<p>$\max_{I \subseteq Y} F(\sum_{i \in I} a_i) / G(\sum_{i \in I} b_i)$</p>

<p>where $F,G$ are positive strictly increasing for positive inputs. I have some specific examples I've encountered in my past research. One is</p>

<p>$F(x) = x, G(x) = x + A$</p>

<p>where $A$ is positive. For this, it is very easy to show that there is a fast solution, namely sort all pairs $(a,b)$ according to $a/b$ in decreasing order, and then try all subsets of the first $k$ pairs in sorted order, for all $k$. Whatever $k$ gives the best solution gives the global optimal combination of pairs.</p>

<p>Interestingly, in another application I found that the exact same algorithm works for a more complicated case:</p>

<p>$F(x) = x, G(x) = \sqrt{x}$</p>

<p>and the proof is a bit harder, but not too bad, and it's surprising (at least to me) that you sort pairs $(a,b)$ according to $a/b$ even though the denominator function is non-linear (my original conjecture was that you sort according to $a/\sqrt{b}$ but this doesn't work). So this got me thinking, is there a general class of pairs of functions $F,G$ where this algorithm works when you sort according to $a/b$, or perhaps where you sort pairs according to $H(a,b)$ where $H$ depends on $F$ and $G$? I know that for arbitrary positive strictly increasing $F,G$ (i.e. $F,G$ are part of the input, even if given by a finite description instead of an oracle) the optimization problem is NP-hard because you can reduce the subset-sum problem to it.  So I'm basically looking for as general of a class of pairs of functions $F,G$ as possible, where the sort-and-scan approach works.</p>
",combinatorics
"<p>Say you have $m$ boxes each of which is colored with one of $n$ colors. What should $m$ be so that the probability that there is atleast $k$ boxes with one same color is strictly greater than $\frac{1}{2}$?</p>

<p>If $k = \Theta(n^{c})$, then what is $m$ if $c &lt; 1$, $c &gt; 1$? Is $m = \Omega(n^{c+1})$ in general?</p>

<p>I was trying to generalize birthday paradox problem. By Pigeon hole I can get only $m=\Omega(n^{2})$ if $k=O(n)$ for 'certainty'. Using pigeon hole I cannot give a probabilistic argument here. Was curious for general sizes of $m$, $n$ and $k$ and what would replace pigeon hole?</p>

<p><a href=""http://www.math.ucsd.edu/~tkemp/180A/180A.LectureNotes.pdf"" rel=""nofollow"">http://www.math.ucsd.edu/~tkemp/180A/180A.LectureNotes.pdf</a> says answer for $n=365$ and general $k$ was not known till $1995$ but does not provide reference. </p>

<p>In this problem, there are two cases: $k &lt; n$ and $k &gt; n$.</p>
",combinatorics
"<p>The recent question <a href=""http://mathoverflow.net/questions/206832/euclidean-minimum-spanning-trees-restricted-to-one-vertex-per-grid-cell"">""Euclidean Minimum Spanning Trees Restricted to One Vertex Per Grid Cell""</a> can be restated in terms of ""minimum spanning trees intersecting each (closed) lattice square of an $n\times n$ lattice"".  </p>

<p>I am wondering whether there is a substantial change if we require the trees to intersect <em>every</em> axis-parallel unit square contained in the big $n\times n$ square, not only lattice squares. Note that in both examples of the other thread, much bigger squares can be squeezed between the branches without intersecting them. </p>

<p>If we denote by $a(n)$ the minimal length of such a tree in the original question and by $b(n)$ the minimal length in the modified question, we have obviously $a(n)\le b(n)$. For $n=2^k+1$, we have $b(n)\le\dfrac{4^k-1}3(\sqrt{3}+1)$, and I would think intuitively that this inequality is sharp.  </p>

<blockquote>
  <p>Can it be shown that $b(2^k+1)=\dfrac{4^k-1}3(\sqrt{3}+1)$?  </p>
</blockquote>

<p>The construction achieving that has a 'base tree' (i.e. one of the two minimal Steiner trees connecting the 4 unit square corners) in each square $(i,j)$ which has $\nu_2(i)=\nu_2(j)$. Here $0&lt;i,j&lt;2^k$ and $\nu_2(\cdot)$ is the 2-adic exponent, e.g. for $k=3$, the pattern in the $9\times9$ square is</p>

<pre><code>X   X   X   X 
  X       X
X   X   X   X 
      X     
X   X   X   X 
  X       X
X   X   X   X 
</code></pre>

<p>where each 'X' denotes a base tree, so diagonally adjacent such cells have a common vertice. (Think of the space-filling ""X-fractal"" obtained by iterating this pattern in the obvious way.) Such a tree contains each lattice point, i.e. all corners of the $n\times n$ lattice squares, thus it intersects each unit square.  </p>

<blockquote>
  <p>Likewise: Can it be shown that $a(2^{k+1})=2\dfrac{4^k-1}3(\sqrt{3}+1)$, using the same pattern but with the base trees twice as large?  </p>
</blockquote>

<p>I have no idea if for $k=2$ the $b(5)$ tree has a bigger length than the $n=5$ ""candidate"" given in the other thread. Probably it has, so:</p>

<blockquote>
  <p>Is it true that for all $n\ge4$, $a(n)&lt; b(n)$? What about $\lim\limits_{n\to\infty}\dfrac{a(n)}{b(n)}$?</p>
</blockquote>
",combinatorics
"<p>For $k \ge 1$, let $f_d(k)$ be the largest possible number of points $p_i$
in $\mathbb{R}^d$ that determine at most $k$ distinct (Euclidean) distances,
$\|p_i-p_j\|$.</p>

<p><em>Example</em>. For points in the plane $\mathbb{R}^2$, 
$f_2(1)=3$ via an equilateral triangle, and
$f_2(2)=5$ via the regular pentagon.
<hr />
<img src=""http://i.stack.imgur.com/W9kiX.jpg"" alt=""RegPentagon"">
<hr />
It is clear that $f_d(k)$ is finite: it is not possible to ""pack"" an infinite
number of points into $\mathbb{R}^d$ while only determining a finite
number of point-to-point distances.</p>

<blockquote>
  <p><strong><em>Q</em></strong>. What is the growth rate of a reasonable upper bound for $f_d(k)$?</p>
</blockquote>

<p>I am particularly interested in $\mathbb{R}^3$. 
$f_3(1)=4$ via the regular simplex.
I am not even certain what is $f_3(2)$. Does anyone know?
Certainly $f_3(2) \ge 6$ just by placing one point immediately above the 
centroid of the pentagon.</p>

<p>But regardless of exact values, I would be interested in an upper bound
for $f_3(k)$.
As well as pointers to results in the literature.
This question has an Erdős-like flavor, and undoubtedly has been considered previously.
Thanks!</p>
",combinatorics
"<p>I have been thinking about some set that is equidistributed modulo $q$,
uniformly in $q$ in some sense. I was starting to think this particular condition, which I describe below, is too strong and that I am starting to doubt if any such set even exists.</p>

<p>However, I haven't been able to prove no such set exists. I was wondering if someone
could tell me how to prove that such set does not exist (or that does exist). I would
also appreciate any input or discussion on whether such set exists or not. It would be great if I could get a better understanding! Thank you very much! </p>

<p>Let $\gamma &gt;\theta &gt;0$, and some $\epsilon &gt;0$ small.  Let $B \subseteq  \mathbb{N}$ and $B \cap [1,X] \sim X^{\gamma}$. Suppose given any 
$q \in \mathbb{N}$ and any partition of the residue class
modulo $q$, $\{ J_l \}_{l=1}^L$, such that $|J_l|X^{\gamma}/q &gt; X^{\epsilon}$,
we have
$$
\sum_{l=1}^L| \  \# \{ u \in B : u \leq X, u \equiv J_l (\text{mod }q) \} - (|J_l|X^{\gamma})/q \ |
\ll X^{\gamma - \theta}.
$$ 
I am wondering does such a set $B$ exist?
If $J = \{ r_1, .., r_k \}$, by
$u \equiv J (\text{mod }q)$, I mean $u \equiv r_j (\text{mod }q)$
for some $j \in \{1, ..., k \}$. Thanks!</p>
",combinatorics
"<p>Background of my question is, that I would like to store flags indicating the relation between a pairs of non-adjacent edges of a graph (that relation could for example be, whether the edges <em>cross</em>, i.e. whether the pair of edges constitutes to a maximal matching of the sub-graph induced by the four adjacent vertices).<br>
My idea is to first calculate the ordinal number $o(\{v_1,v_2,v_3,v_4\})$ corresponding to the set of the integer-labels of the adjacent vertices and from that calculate the the ordinal number of the pair of edges:<br>
$$o(\{\{v_1,v_2\},\{v_3,v_4\}\}) := 3\times o(\{v_1,v_2,v_3,v_4\}))$$
$$o(\{\{v_1,v_3\},\{v_2,v_4\}\}) := 3\times o(\{v_1,v_2,v_3,v_4\}))+1$$
$$o(\{\{v_1,v_4\},\{v_2,v_3\}\}) := 3\times o(\{v_1,v_2,v_3,v_4\}))+2$$</p>

<p>Questions:  </p>

<ul>
<li><p>is there a general formula, that only depends on the cardinality $k$ and on the $k$ elements itself of a finite set of integers, which yields the ordinal number of that set in the lexicographically sorted sequence of integer-sets with k elements (for a specific $k$ the formula could be obtained by polynomial interpolation, but I want a formula that contains $k$ as a parameter)?  </p></li>
<li><p>is there a compact notation for  ""integer sets of cardinality $k$"" (for cartesian products there is the nice way of writing $\mathbb{N}^k$; I would like something analogous for sets instead of cartesian products)?  </p></li>
</ul>

<p>Being able to calculating the ordinal number of integer sets would to me be an important building block for calculating more elaborate ordinal numbers for use in graph theoretic algorithms, as indicated above.  </p>
",combinatorics
"<p>Given a fixed integer $n &gt; 0$ and $0 \le m \le n$ let us define the numbers</p>

<p>$$f_{n,m} = \sum_{i=\lfloor m/2 \rfloor}^m {n-2i \choose n - m -i}{i+1 \choose m - i +1}.$$</p>

<p>For example $f_{n,0} = 1,f_{n,1} =2$ and $f_{n,2} = n+1.$ What I am interested in is the following inequality</p>

<p>$$\sum_{m=0}^k (n-m+1)f_{n,m} \geq f_{n+2} \ge \frac{(\frac{1+\sqrt{5}}{2})^{n+1}}{\sqrt{5}} \; \; \; (1),$$</p>

<p>where $f_n$ is the $n$th Fibonacci number.</p>

<p>More specifically, I would like a lower bound for the least number $k$ such that the inequality is satisfied. </p>

<p>For example if $k = 3$ then the sum on the left is just $(n+1)^2-5$ which is clearly smaller than $f_{n+2}$ (for large enough $n$'s.)</p>

<p>Now the only way that I know for attacking this is to estimate $f_{n,m}$ by using the well known  bound ${n \choose k} \geq (\frac{n}{k})^k$ and use the integral inequality for summations. Unfortunately Mathematica (and hence I) cannot compute the definite integral of the obtained function and hence I am wondering:</p>

<blockquote>
  <p>Is there some other way to analyze this inequality? What would be a
  good bound for $k$ such that $(1)$ holds? Can the theory of generating functions help us?</p>
</blockquote>
",combinatorics
"<p>Consider the following one-dimensional version of the game battleships.  There is a battleship somewhere on $\mathbb N$, i.e., a interval $N,\ldots,N+k$.  Your task is to find whether this battleship lies in the interval $1,\ldots,n$ using the minimal number of tests (on can ask if the battlship includes $i$ for any $1\leq i \leq n$). One does not know the value of $k$ (nor a bound on it).  The battleship may not be in the test interval at all.</p>

<p>Intuitively I think that one choses a permutation of $\{1,\ldots,n\}$ so that after testing the first $m$, the remaining intervals of untested points in $1,\ldots,n$ are as small as possible.  Example: if $n=5$ then $1,5,3,2,4$ would give an optimal strategy, as would $5,1,3,2,4$.  </p>

<p>It is easy enough to work out an algorithm to generate such permutations</p>

<ul>
<li>maintain a sorted list of intervals, put $[2,n-1]$ in it</li>
<li>maintain a results array and put $1$ and $n$ on it</li>
<li>pop the largest interval from the sorted list, divide into two, push the division point onto the results array, push the divided intervals into the sorted list if they are not singletons</li>
</ul>

<p>For my problem, $n&lt;100$, so the above will probably suffice in terms of performance, but it occurs to me that such permutations might arise in other contexts, and there might be a more efficient way of generating them.  Any takers?</p>

<p>Motivation:  This arises in a non-convex global optimisation code which uses a ""subdivide and reject"" method.  The battleship is a region around the global maximum, the tests are (rather expensive) function evaluations.  If the global maximum is in the region of interest I must subdivide, if not then I can reject.  Obviously I want to find whether the global maximum is in the region as soon as possible, since this saves me function evaluations.</p>

<p>[edit]</p>

<p>Thank you for the replies.  I think that Douglas Zare's answer points in the right direction. After testing the end points one knows that the target is in the interior of the region (if it is there at all).  Then the uniform insertion strategy seems to be the best one (possibly some chages will be needed to handle the integer location of the samples, but I don't think this is a big deal).</p>

<p>Incidentally, I just tested the simple strategy $1,n,2,\ldots,n-1$ on my code (i.e., test the end points, then the interior) and it gives a 2% reduction in evaluations --- well worth having. I will post the improvement with uniform insertion here when it is implemented. </p>
",combinatorics
"<p>Given an n-by-m square grid graph, how many ways are there to choose a subset of the vertices which is simply connected?  Here, a subset of vertices is simply connected if the vertices, together with any edges or interior faces connecting them amongst themselves, form a contractible subregion of the grid. More formally, we can naturally embed the grid graph into the plane.  Then I want to count subsets of vertices such that the union of the dual 2-cells forms a simply connected region in the plane.  </p>

<hr>

<p>Let me try to be a little bit clearer this time.  Let's work directly with the dual, since that is easier to visualize.  Hence, my question is: </p>

<blockquote>
  <p>Consider a grid of square tiles of dimensions n-by-m, with each of the nm tiles distinctly labeled.  How many distinct (labeled) simply connected subsets of tiles are there as a function of n and m?  </p>
</blockquote>

<p>Because the tiles are labeled, rotation or translation to get the same polyomino isn't allowed.  I'm trying to count <em>all</em> subsets.  Commenter JBL points out the sequence for m=n at Sloane's, which also links to a lot of work by Artem M. Karavaev on this problem.</p>
",combinatorics
"<p>Suppose you have a deck of $n$ cards; e.g., $n{=}12$:
$$
(1,2,3,4,5,6,7,8,9,10,11,12) \;.
$$
Cut the deck into $k$ equal-sized pieces, where $k|n$;
e.g., for $k{=}4$, the $12$ cards are partitioned into
$4$ piles, each of $m=n/k=3$ cards:
$$
\left(
\begin{array}{ccc}
 1 &amp; 2 &amp; 3 \\
 4 &amp; 5 &amp; 6 \\
 7 &amp; 8 &amp; 9 \\
 10 &amp; 11 &amp; 12 \\
\end{array}
\right) \;.
$$
Now perfectly shuffle them by selecting the top card from stack $1$,
the top card from stack $2$, and so on, 
walking down the columns of the matrix above,
resulting in this shuffled deck of cards:
$$
(1,4,7,10,2,5,8,11,3,6,9,12) \;.
$$
Continue in this manner until the deck of cards returns to its initial sorting:
$$
\left(
\begin{array}{cccccccccccc}
 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 &amp; 11 &amp; 12 \\
 1 &amp; 4 &amp; 7 &amp; 10 &amp; 2 &amp; 5 &amp; 8 &amp; 11 &amp; 3 &amp; 6 &amp; 9 &amp; 12 \\
 1 &amp; 10 &amp; 8 &amp; 6 &amp; 4 &amp; 2 &amp; 11 &amp; 9 &amp; 7 &amp; 5 &amp; 3 &amp; 12 \\
 1 &amp; 6 &amp; 11 &amp; 5 &amp; 10 &amp; 4 &amp; 9 &amp; 3 &amp; 8 &amp; 2 &amp; 7 &amp; 12 \\
 1 &amp; 5 &amp; 9 &amp; 2 &amp; 6 &amp; 10 &amp; 3 &amp; 7 &amp; 11 &amp; 4 &amp; 8 &amp; 12 \\
 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 &amp; 11 &amp; 12 \\
\end{array}
\right) \;.
$$
Here, for $n{=}12$ cards partitioned into $k{=}4$ parts, it requires $s{=}5$ 
perfect shuffles to
cycle.
Let us say that $f(n,k)=s$, i.e., $f(12,4)=5$.
Similarly I can calculate that 
$$
f(8,2)=3,\; f(18,3)=16,\; f(33,3)=8, \; f(52,2)=8,
$$
etc. The last represents a perfect ""outer-shuffle"" of a standard
$52$-card deck, which is known to take $8$ shuffles to cycle.
It seems likely this function is known to combinatorialists:</p>

<blockquote>
  <p><strong><em>Q</em></strong>. What is $f(n,k)$?</p>
</blockquote>
",combinatorics
"<p>I'm a PhD student in image processing, where I've stumbled into a problem that seems to be essentially number theory.  I've hunted around online and while I've found many results on similar problems, this particular problem I cannot seem to find a solution to:</p>

<p>Given a line in the plane passing through the origin making angle $\theta$ with the $x$-axis, I am trying to determine the closest nonzero Gaussian integer $n+im$ to the line obeying $|n+im| \le r$.</p>

<p>I have a conjecture which is backed up by numerous computer tests, but no proof.  The conjecture is as follows:  </p>

<p>Let $\Theta(r) = \{\theta_1,\theta_2,...,\theta_N\}$ denote the set of angles representable using Gaussian integers of this form.  That is, each $\theta_k=Arg(n+im)$ for some non-zero Gaussian integer $n+im$ of norm at most $r$.</p>

<p>Find $\theta_k, \theta_{k+1}$ straddling $\theta$, i.e. $\theta_k \le \theta &lt; \theta_{k+1}$.  Let $n+im$ be a Gaussian integer that solves our minimization problem.  Then either $Arg(n+im)=\theta_k$ or $Arg(n+im)=\theta_{k+1}$.</p>
",combinatorics
"<p>Koebe–Andreev–Thurston theorem (known also as the circle packing theorem) says that any planar graph can be realized by a set of (interior-) disjoint disks corresponding to vertices, such that two discs are tangent iff the corresponding vertices are connected to each other.</p>

<p>Where can I find the/a proof of this theorem, and what should I learn to understand it?</p>

<p>I prefer proofs which are elementary, but other proofs are welcome too.</p>
",combinatorics
"<p>How difficult is the problem of reducing the number of terms in a sum of binomial expressions? Formally:</p>

<p>Given $a_1, a_2, a_3, … a_n$, and $b_1, b_2, b_3, ... , b_n$, where $a_i, b_i \in \mathbb{Z}$, $a_i, b_i \geq 0$, consider</p>

<p>$$\sum\limits_{i=1}^n {s-a_i \choose r-b_i}$$</p>

<p>For all integers $s, r \geq max(a_1, a_2, a_3, … a_n, b_1, b_2, b_3, ... , b_n)$, where ${x \choose y}=0$ for all $y&gt;x$, and ${x \choose 0}=1$ for all $x \geq 0$.</p>

<p>Goal: Find the smallest size $m$ such that, for $c_1, c_2, c_3, … c_m, d_1, d_2, d_3, ... , d_m$, where $c_i, d_i \in \mathbb{Z}$, $c_i, d_i \geq 0$</p>

<p>$$\sum\limits_{i=1}^n {s-a_i \choose r-b_i} = \sum\limits_{i=1}^m {s-c_i \choose r-d_i}$$</p>

<p>For all integers $s, r \geq max(a_1, a_2, … a_n, b_1, b_2, ... , b_n, c_1, c_2, ..., c_m, d_1, d_2, ... d_m)$.</p>

<p>Alternatively, find $c_i$ and $d_i$ such that $m$ is as small as possible.</p>

<p>For example:</p>

<ul>
<li>${s-1 \choose r-1} + {s-1 \choose r} = {s \choose r}$ (Using Pascal's Triangle)</li>
<li>Any linear dependence $\sum\limits_{i=1}^n α_i {r−a_i \choose s−b_i}=0$ valid for all sufficiently large $r$,$s$ is a linear combination of the Pascal triangle identities ${r−a+1 \choose s−b+1} − {r−a \choose s−b+1} − {r−a \choose s−b}=0$</li>
</ul>

<p>Do we know if any complexity bounds/computability bounds are known for this problem in general?</p>

<p>I'm also interested in the alternate problem where we're allowed integer constants $e_i, f_i \geq 0$, and we're still interested in finding the smallest size $m$ such that</p>

<p>$$\sum\limits_{i=1}^n {s-a_i \choose r-b_i} = \sum\limits_{i=1}^m {e_i\cdot s-c_i \choose f_i\cdot r-d_i}$$</p>

<p>However I'm primarily interested in the first problem - I just mention this second problem partially in case there is a trivial solution to the first that I'm not aware of.</p>
",combinatorics
"<p>This is a boring, technical question that I stumbled upon while making a contribution to Sage. I would still like to hear a constructive answer so hopefully the question does not get closed. </p>

<p>The question is the following.</p>

<blockquote>
  <p>How many spanning trees does the empty graph $E$ have?</p>
</blockquote>

<p>According to Sage it has 1, while Mathematica claims $\tau(E) = 0.$ Now the only subgraph of $E$ is $E$ hence this question can be rephrased as</p>

<blockquote>
  <p>Is $E$ a tree?</p>
</blockquote>

<p>One characterization says that a tree is a connected graph with $n$ vertices and $n-1$ edges and would imply that $E$ is not a tree. However if we define a tree as a connected acyclic graph then $E$ is clearly a tree.</p>

<p>It appears that as far as Kirchhoff is concerned any value would do since $$\rm{adj}(\mathcal{L}(E)) = \mathcal{L}(E) = k\mathcal{L}(E)$$ for any $k.$</p>

<p>Hence what I am wondering is</p>

<blockquote>
  <p>Are there any wider reasons in defining $E$ to (not) be a tree?</p>
</blockquote>
",combinatorics
"<p>First I'll phrase the question as a riddle, and than as a general math problem. </p>

<p>We have 12 lettered vases $(A,B,...,L)$, in each vase there are 30 numbered balls (1-30). In each ball there is some random amount of money between 1-1000 dollars (the distribution of the money in the balls is some IID). Now we have two options:</p>

<p>1) We can ask which number (1-30) contains in average the largest amount of money, and than we get 12 balls of that number, we open them all and we take the ball with the highest amount of the 12.</p>

<p>2) We can ask which vase (A-L) contains the largest sum of money, and than we get 30 balls from that vase, we open them all and we take the ball with the highest amount of the 30.</p>

<p>What is the better strategy, assuming that we want a lot of money...</p>

<p>Now to phrase it more generally:</p>

<p>Let  $ A \in\mathbb{N}^{m\times n} , n&gt;m$,</p>

<p>Let $x_{ij}$ be i.i.d. (real) random variables with mean 0 and variance 1</p>

<p>Let $X_1=\max_{1\leq i\leq m}{\sum_{1\leq j\leq n}a_{ij}}$</p>

<p>and let $X_2=\max_{1\leq j\leq n}{\sum_{1\leq i\leq m}a_{ij}}$</p>

<p>What is larger (in average, or the expected value of) $X_1$ or $X_2$?
That is, what we should take first, the maximum value of the rows and than the highest value in that row, or the maximum value of the columns and than the highest value in that column?</p>

<p><strong>Another question</strong> (more combinatorial): We can ask in a case where all of the values in the matrix are different and between 1 to $m\cdot n$. So we have a pure combinatorial question about the possible $m\cdot n!$ permutations of the numbers in the matrix.</p>

<p>The riddle is of course like this:</p>

<p>Let  $ A \in\mathbb{N}^{12\times 30}$ ,$1\leq a_{ij} \leq 1000$ (by i.i.d distibution)</p>

<p>Let $X_1=\max_{1\leq i\leq 12}{\sum_{1\leq j\leq 30}a_{ij}}$ (Option 1)</p>

<p>and let $X_2=\max_{1\leq j\leq 30}{\sum_{1\leq i\leq 12}a_{ij}}$ (Option 2)</p>

<p>Thanks!
David</p>

<p>Edited. Thanks for the comments of Yemon, Gerry and James.</p>
",combinatorics
"<p>Given the set of all binary strings of length n, I am looking at the ""middle"" of these strings, weight-wise.</p>

<p>Namely, I am trying to calculate how many words are there whose weight is between n/2 - sqrt(n) and n/2 + sqrt(n).</p>

<p>Clearly this term can also be described as a sum of binomial coefficients, but I don't know how to simplify it. I am less interested in the exact outcome (Although it would be great if I could get it), and more interested in the asymptotical lower bound. (Is this about Omega(2^n)? Omega(2^sqrt(n))? Something else?)</p>
",combinatorics
"<p>The following arose as a side issue in a project on graph reconstruction.</p>

<p><strong>Problem:</strong> Let $a(n)$ be the greatest order of the automorphism group of a 3-connected cubic graph with $n$ vertices.  Find a good upper bound on $a(n)$.</p>

<p>There is a <a href=""http://arxiv.org/abs/math/0608645"" rel=""nofollow"">paper of Opstall and Veliche</a> that finds the maximum over all cubic graphs, but the maximum occurs for graphs very far from being 3-connected.</p>

<p>I foolishly <strong>conjecture</strong>: for $n\ge 16$, $a(n) &lt; n 2^{n/4}$.</p>

<p>When $n$ is a multiple of 4 there is a vertex-transitive cubic graph achieving half the conjectured bound, so if true the bound is pretty sharp.</p>

<p>The maximum does not always occur for vertex-transitive graphs. There is no vertex-transitive counterexample to the conjecture with less than 1000 vertices.</p>

<p>Any bound for which the exponential part is $2^{cn}$ for $c&lt;\frac12$ is potentially useful.</p>

<p><strong>Added:</strong> As verret pointed out in a comment, a <a href=""http://arxiv.org/abs/1010.2546"" rel=""nofollow"">paper of Potočnik, Spiga and Verret</a>, together with the computation I mentioned, establishes the conjecture for vertex-transitive graphs, so the remaining problem is whether one can do better for non-transitive graphs. For 20, and all odd multiples of 2 vertices from 18 to at least 998 (but not for 4-16 or 24 vertices) the graph achieving the maximum is not vertex-transitive.</p>
",combinatorics
"<p>Hello, can anyone recommend good combinatorics textbooks for undergraduates? I will be teaching a 10-week course on the subject at Stanford, and I assume that the students will be strong and motivated but will not necessarily have background in subjects like abstract algebra or advanced calculus.</p>

<p>I intend to focus on the enumerative side of the subject and do permutations and combinations, generating functions, recurrence relations, Stirling and Catalan numbers, and related topics. However, this hasn't been set in stone and I also welcome advice for what topics to include.</p>

<p>I would be grateful if people would not only suggest names of books but also say a little bit about their merits. Thank you!</p>
",combinatorics
"<p>Given a regular tesselation, i.e. either a platonic solid (a tesselation of the sphere), the tesselation of the euclidean plane by squares or by regular hexagons, or a regular tesselation of the hyperbolic plane.</p>

<p>One can consider its isometry group $G$. It acts on the set of all faces $F$. I want to define a symmetric coloring of the tesselation as a surjective map from $c:F\rightarrow C$ to a finite set of colors $C$, such that for each group element $G$ there is a permutation $p_g$ of the colors, such that $c(gx)=p_g\circ c(x)$. ($p:G\rightarrow $Sym$(C)$ is a group homomorphism).</p>

<p>Examples for such colorings are the trivial coloring $c:F\rightarrow \{1\}$ or the coloring of the plane as an infinite chessboard.
The only nontrivial symmetric colorings of the tetrahedron, is the one, that assigns a different color to each face. For the other platonic solids there are also those colorings that assign the same colors only to opposite faces. </p>

<p>So my question is: Does every regular tesselation of the hyperbolic plane admit a nontrivial symmetric coloring?</p>

<p>I wanted to write a computer program, that visualizes those tesselations, but i didnt find a good strategy which colors should be used. So i came up with this question.</p>
",combinatorics
"<p>The Dushnik&ndash;Miller <a href=""http://en.wikipedia.org/wiki/Order_dimension"">dimension of a partial order</a> $(P,{\leq})$ is the smallest possible size $d$ for a family ${\leq_1},\ldots,{\leq_d}$ of total orderings of $P$ whose intersection is ${\leq}$, i.e. $x \leq y$ iff $x \leq_i y$ holds simultaneously for all $i = 1,\ldots,d$. Equivalently, the dimension is the smallest $d$ such that $P$ embeds in $L^d$ of some total ordering $L$, where $L^d$ is endowed with the coordinatewise partial ordering.</p>

<p>Since chains have dimension 1 and antichains have dimension 2, <a href=""http://en.wikipedia.org/wiki/Dilworth%27s_theorem"">Dilworth's Theorem</a> guarantees that every poset of size $n$ contains a $2$-dimensional subposet of size at least $\sqrt{n}$. Is this optimal? In general, what can we say about subposets of dimension $d$?</p>

<hr>

<p>Tom Goodwillie's argument below shows that for sufficiently large $n$, every poset of size $n$ either has an antichain of size $\sqrt{dn}$ or a $d$-dimensional subposet of size $\sqrt{dn}$. This result is optimal for $d = 1$; stated this way, this could also be optimal for $d &gt; 1$ too. For $d = 2$, this improves my lower bound $\sqrt{n}$ above by a factor of $\sqrt{2}$.</p>

<p>In view of this, let me reformulate the question as follows. Let $F_d(n)$ be the largest integer such that every poset of size $n$ has a $d$-dimensional subposet of size $F_d(n)$. Note that $F_1(n) = 1$ for all $n$ and, when $d &gt; 1$, $F_d(n) \geq \sqrt{dn}$ for large enough $n$.</p>

<blockquote>
  <p>Is $F_2(n) \leq C\sqrt{n}$ for some constant $C$? In general, what is the asymptotic behavior of $F_d(n)$?</p>
</blockquote>
",combinatorics
"<p>What is the smallest number <em>S(k,n)</em> of unlabeled graphs on <em>k</em> vertices such that every simple graph on <em>n</em> vertices contains at least one of these as an induced subgraph?</p>

<p>I'd like to avoid exhaustive search over all unlabeled graphs on <em>n</em> vertices. In my setting, the search can be pruned if I know that a certain induced subgraph on <em>k</em> vertices is forced to occur. For instance, <em>S(3,5)=3</em> since the set consisting of the empty graph, <em>K3</em> and one more graph on three vertices is ``unavoidable'' in this sense. Of course, Ramsey's Theorem (specialized to two-colorings of complete graphs) implies that <em>S(k,n)=2</em> for <em>n</em> sufficiently large, but what happens for smaller values of <em>n</em>? If a set of graphs on <em>k</em> vertices is unavoidable for graphs on <em>n</em> vertices, then it must include both the complete graph and empty graph on <em>k</em> vertices. Finally note that we can replace all the graphs in our set by their complements and obtain another unavoidable set.</p>

<p>It's quite likely this has been studied before. What is the right terminology and what are the earliest references?</p>
",combinatorics
"<p>The classical definition of regular polytopes is recursive. It says that a polytope is regular if its facets and vertex figures (both smaller-dimensional polytopes) are regular.</p>

<p>The modern definition goes as follows. Let $P\subseteq\mathbb{R}^n$ be a polytope centered at the origin and let $\mathrm{Aut}(P)\leq O(n)$ be its automorphism group. We say that $P$ is regular if its automorphism group acts transitively on maximal flags of faces.</p>

<p>However, there are many equivalent definitions of regularity. Let's say that a polytope is $d$-regular if its automorphism group is transitive on $d$-dimensional faces. The following theorem is stated in several places (for example in McMullen and Schulte's ""Abstract Regular Polytopes"", pages 9-10):</p>

<p>Theorem: Let $P$ be an $n$-dimensional polytope. If $P$ is $d$-regular for all $0\leq d\leq n-1$ then $P$ is regular.</p>

<p>All statements of this theorem I've seen refer to Peter McMullen's 1968 thesis from the University of Birmingham, which I don't have access to.</p>

<p>So here's my question: Does anyone know where I can find a proof of this theorem or how to gain access to Peter McMullen's thesis?</p>

<p>Bonus Problem: How dependent/independent are the notions of $d$-regularity for different $d$?</p>

<p>Thanks.</p>
",combinatorics
"<p>Consider the space $X_1$ of closed subsets not containing a pair of antipodal points of the unit circle. Here we have a kind of degenerate Morse function, defined by the <em>diameter</em> of the pointset. Namely, this is the maximal distance among pairs of points of the set. Then the extrema of the Morse function are precisely the sets of vertices of odd regular polygons, and they are in 1-1 correspondence with the connected components of $X_1$ (each odd polygon is the unique critical point in its connected component). </p>

<p>A similar description holds for the space $X_2$ of subsets of the unit 2-sphere, of diameter smaller than that of an equilateral triangle inscribed in the equator. Again there are infinitely many connected components, and each component contains a unique extremum. This was proved <a href=""http://link.springer.com/article/10.1007/BF02187719"" rel=""nofollow"">here</a>. Here an extremum is of a very special ""selfdual"" form, e.g., its convex hull has as many vertices as faces.</p>

<p>It is obvious how to generalize this to $n$ dimensions but I will stick with the 3-sphere. Thus, consider the space $X_3$ of subsets of the unit 3-sphere of diameter smaller than that of the regular tetrahedron inscribed in an equatorial 2-sphere. Here again there are infinitely many connected components. Is it true that there is a unique extremum in each? </p>
",combinatorics
"<p>Let $A$ be a matrix with entries either 0 or 1, where each column contains at least one 1, to remove trivial degenerations.</p>

<p>Let $P$ be the <em>convex hull of all integer vectors</em> $x$ that satisfy $Ax \leq y$, and $x\geq 0$, where $y$ is some non-negative integer vector. Clearly, $P$ is an integral polytope.</p>

<p>For example (to address David Speyers comment), when 
$$A=\begin{pmatrix} 1 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 1 \end{pmatrix}, y=(1,1,1)$$
then $P$ is the convex hull of the solutions to $Ax\leq y$, so $P$ is the convex hull of $(0,0,0),(1,0,0),(0,1,0),(0,0,1)$, the standard simplex. </p>

<p>Doing some computer experiments, I believe the following:</p>

<p><em>Conjecture:</em> P is integrally closed, i.e., every <em>integer</em> point $p \in kP$
can be expressed as $p=p_1+p_2+\dots+p_k$ where all $p_i$ are <em>integer</em> points in $P$,
whenever $k$ is a natural number.</p>

<p>In the example above, this is known to be integrally closed.</p>

<p>Note that there are no conditions on the minors of $A$.</p>

<p>Is this a known result? This seems hard, since we do not have a nice description of $P$, that is, the supporting hyperplanes, nor the vertices, are explicitly known.</p>
",combinatorics
"<p>Suppose a set of generators and relations of a monoid (possibly infinite) is given. How do you show that the monoid is non-zero ? I mean is there an easy way to produce a non-zero element ? </p>
",combinatorics
"<p>I have attempted to calculate the number of unlabelled bipartite graphs as follows:</p>

<blockquote>
  <p>Let $G = (V_1, V_2, E)$ be a bipartite graph on $n$ vertices with $|V_1| = m$ and $|V_2| = n-m$. Assume without loss of generality that $|V_1| \leq |V_2|$ so $m \leq \left\lfloor \frac{n}{2} \right\rfloor$. If $G$ is complete bipartite then it has $m(n-m)$ edges since each of the vertices in $V_1$ is connected to each in $V_2$. Thus, the total number of bipartite graphs with parts of size $m$ and $n-m$ is $2^{m(n-m)}$. In order to find the total number of possible bipartite graphs on $n$ vertices we sum over all possible $m$:
  \begin{align}
\sum^{\left\lfloor \frac{n}{2} \right\rfloor}_{m=1} 2^{m(n-m)}
\end{align}</p>
</blockquote>

<p>However, I notice that I have counted labelled bipartite graphs where I need the number of unlabelled graphs. I'm struggling to see how to account for this.</p>
",combinatorics
"<p>How does one enumerate the distinct orbit classes of independent sets of the hypercube modulo symmetries of the hypercubes? </p>

<p>The counting of the number of independent sets in an n-dimensional hypercube modulo symmetries of the hypercube has been done up to n=5 by D.Eppstein as seen in the <a href=""http://oeis.org/A060631"" rel=""nofollow"">OEIS</a>. We do have a bound on the number of independent sets of a regular graph as found by <a href=""http://yufeizhao.com/papers/indep_reg.pdf"" rel=""nofollow"">Y.Zhao</a>. But I'm not aware of other results to this old problem of mine.</p>

<p>Does anyone know of a resource on how to go about this enumeration? I've already coded a brute-force program to do this listing and had reproduced Eppstein's results up to n=5. The n=6 took too much time and memory space on my personal computer that it always crashed. But this was years ago. I was just reminded of this recently, so here's my first post on MO.</p>
",combinatorics
"<p>If I randomly sample with replacement $P$ times from a set of all possible binary strings of length $L$, what is a good lowerbound on the expected minimum Hamming distance between any two of my $P$ strings?  Can we generalize this for larger ternary/etc. string alphabets?</p>
",combinatorics
"<p>In Azuma's Inequality, is the statement true when $|X_k - X_{k-1}| &lt; c_k$ almost surely rather than with probability 1? If not, is there another result which gives strong concentration when the above inequality (for each $k$) holds with high probability?</p>
",combinatorics
"<p>Consider the multi-index $\gamma=(\gamma_1,\ldots, \gamma_n)$. Is there a closed form for the sum $\sum_{|\gamma|=k} \gamma!$ in terms of $n$ and $k$? Asymptotics, or good upper bounds are also very helpful.</p>

<p>Here is what I have tried. Let $f(x)=\sum_{i=0} i! x^{i+2}$. This generating function satisfies the ODE $x^2f'(x)=f(x)-x$. Then the sum $\sum_{|\gamma|=k} \gamma!$ is the coefficient of $x^{k+2n}$ in $f(x)^n$. However I don't have any means to find this coefficient.</p>
",combinatorics
"<p>Let $(V,E)$ be a finite oriented directed graph, with vertices and edges ordered, and $M$ the $|V|\times |E|$ matrix with entries
$$ m_{ve} = \begin{cases} 1 &amp;\text{if $e$ points at $v$}\\
-1 &amp;\text{if $e$ points from $v$}\\
0 &amp;\text{otherwise.} \end{cases} $$
If $(V,E)$ is a tree, then this matrix has one more row than being square.</p>

<blockquote>
  <p>If we erase the row corresponding to a vertex $v$, the resulting square matrix is easily seen to have determinant $\pm 1$ or $0$. Is there a simple, known formula for its determinant? (Surely!)</p>
</blockquote>

<p>Example: consider $1 \stackrel{1}{\to} 2 \stackrel{2}{\to} 3$, with matrix
$ \begin{pmatrix} -1&amp;0\\ 1&amp;-1\\ 0&amp;1 \end{pmatrix}$. Then the three choices $v=1,2,3$ give the determinants $1,-1,1$ respectively.</p>
",combinatorics
"<p>In number theory there are several operators like ‎addition, ‎multiplication and ‎exponentiation defined from ‎$‎‎‎\omega‎‎\times‎‎\omega‎$ ‎to ‎‎$‎‎‎\omega‎$. Each ‎of ‎them ‎is defined as an ‎iteration of ‎‎‎the other. ‎The sequence of building such iterated operators can go further to define faster and faster <a href=""http://en.wikipedia.org/wiki/Hyperoperation"">hyperoperators</a>‎. The first of them is <a href=""http://en.wikipedia.org/wiki/Tetration"">tetration</a> which is defined as iterated exponentiation. Let ‎$‎‎m\uparrow n$ ‎denote the tetration of ‎$‎‎m$ and ‎$‎n‎$‎ ‎that ‎is‎ ‎‎$‎‎\underbrace{m^{m^{m^{.^{.^{.}}}}}}_{n - times}$. This operator appears in several interesting occasions in logic, computations and combiantorics, for example see these Wikipedia articles on <a href=""http://en.wikipedia.org/wiki/Graham%27s_number"">Graham's number</a>, <a href=""http://en.wikipedia.org/wiki/Ackermann_function"">Ackermann's function</a>, <a href=""http://en.wikipedia.org/wiki/Graham%27s_number"">busy Beaver function</a> and <a href=""http://en.wikipedia.org/wiki/Kolmogorov_complexity#Chaitin.27s_incompleteness_theorem"">Chaitin's incompleteness theorem</a>.<br>
‎</p>

<p>Now consider the infinitary case. ‎In set theory ‎addition, ‎multiplication ‎and ‎exponentiation are defined for  ‎cardinal ‎numbers. ‎</p>

<blockquote>
  <p><strong>Question 1.</strong> What ‎about ‎‎$‎‎‎\kappa‎‎\uparrow‎‎\lambda‎$? ‎How should we define this? ‎
  ‎</p>
</blockquote>

<p>Intuitively, we expect to define ‎$‎‎\aleph_0‎\uparrow‎\aleph_0$ ‎to be  ‎‎$‎\aleph_0^{‎‎\aleph_0^{‎‎\aleph_0^{.^{.^{.}}}}}.$  </p>

<p>But this intuitive definition of tetration  has some counter-intuitive properties, as then ‎we ‎expect ‎to ‎have ‎‎$‎‎‎‎\aleph_0^{(‎‎\aleph_0‎\uparrow‎\aleph_0)}=‎‎\aleph_0‎\uparrow‎\aleph_0$ which is ‎impossible ‎by ‎Cantor's ‎theorem which says ‎$‎‎‎\forall ‎‎\kappa‎\geq\aleph_0\;\;\;\aleph_0^{‎\kappa‎}&gt;‎\kappa‎$.</p>

<p>Note that for the cases of addition, multiplication and exponentiation, we have quite natural operations $f_+, f_\times$ and $f_e$ such that given cardinals $\kappa, \lambda$, we have $f_+(\kappa,\lambda)=\kappa+\lambda, f_\times(\kappa, \lambda)=\kappa\times \lambda$ and $f_e(\kappa,\lambda)=\kappa^\lambda.$ </p>

<blockquote>
  <p><strong>Question 2.</strong> Is there a natural operation $f_t$ defined so that for all natural numbers $m,n$ we have $f_t(m,n)= ‎‎‎m\uparrow n$, and so that its definition is so natural that it also works for infinite cardinal numbers?</p>
</blockquote>

<p>The next question is taken from Noah's answer, where an answer to it may help in defining the tetration for higher infinite.</p>

<blockquote>
  <p><strong>Question 3.</strong> What is $m\uparrow n$ counting?</p>
</blockquote>

<p>See also <a href=""http://math.stackexchange.com/questions/1012260/what-combinatorial-quantity-the-tetration-of-two-natural-numbers-represents"">What combinatorial quantity the tetration of two natural numbers represents?</a>. But note that the answers given in the above question are so that they are not suitable for treating infinite cardinals.</p>
",combinatorics
"<p>Let $G$ be a ribbon graph (sometimes called fat graph) with $v$ vertices and $e$ edges. Furthermore each vertex is of degree $d$. </p>

<p><strong>Q) What is the number of $G$ with the above properties? I mean does there exist a closed formula for the number of such $G$ in terms of $v$, $e$, and $d$.</strong> </p>

<p>I don't know any reference or result in this area. I searched but I could not find anything of this type. Any reference, link, suggestion will be helpful.</p>

<p>Thanks in advance. </p>
",combinatorics
"<p>Given a countable coloring of the plane, is it always possible to find a monochromatic set of points $\left\{ \left(x,y\right),\left(x+w,y\right),\left(x,y+h\right),\left(x+w,y+h\right)\right\} $ (the corners of a rectangle)?</p>
",combinatorics
"<p>I originally posted this question here:<br>
<a href=""http://math.stackexchange.com/questions/1296199/combinatorial-formula-for-the-number-of-different-words"">http://math.stackexchange.com/questions/1296199/combinatorial-formula-for-the-number-of-different-words</a> :</p>

<p>I am interested in the asymptotic behaviour of the following quantity:</p>

<p>Suppose we have $m$ distinct letters and we are allowed to use each letter at most $d$ times. What is the number of distinct words of length $k$ that can be formed? </p>

<p>Indeed, one can find a recurrence formula, but I do not quite see how one can find  a uniform asymptotic for all $m,d,k.$</p>

<p><strong>Edit:</strong> After discussion in the comments, I can reduce my problem to the range, $m\ge k$ and $d\ll m.$</p>
",combinatorics
"<p>What is the average minimum required number of independent $k$-sparse (having at most $k$ non-zero elements) random vectors belonging to $\mathbb{F}_2^n$ to span the whole space of $\mathbb{F}_2^n$? Any such vector is uniformly probable to be chosen among the total $\sum_{j=0}^k \binom{n}{j}$ vectors. </p>

<p>Here are the two extreme cases: </p>

<ol>
<li>If $k=n$, this average value is $n+1.6067$ as proved <a href=""http://math.stackexchange.com/questions/589725/expected-number-of-random-binary-vectors-to-make-matrix-of-order-n"">here</a>.</li>
<li>If $k=1$, using coupon collector problem this average value is proved to be larger than $\Theta(n \log n)$.</li>
</ol>

<p>Can we prove that if $k = \Theta(\log n)$, then this average value is $\Theta(n)$? or something similar? My simulation results show that for a pretty large range of $k$ this average value is $\Theta(n)$. </p>
",combinatorics
"<p>Is there any infinite family of $v$ for which all the $(v,k,\lambda)$-cyclic difference sets with $k-\lambda$ a prime power coprime to $v$ have been determined? </p>

<p>A subset $D=\{a_1,\ldots,a_k\}$ of $\mathbb{Z}/v\mathbb{Z}$ is said to be a $(v,k,\lambda)$-cycic difference set if for each nonzero $b\in\mathbb{Z}/v\mathbb{Z}$, there are exactly $\lambda$ ordered pairs $(a_s,a_t)\in D^2$ such that $a_s-a_t=b$. For a $(v,k,\lambda)$-difference set $D$, $k-\lambda$ is called the order.</p>

<p>Let $C_{v,n}$ be the set consisting of all cyclic difference sets of $\mathbb{Z}/v\mathbb{Z}$ with order $n$, and 
$$
C_v=\bigcup\limits_{\text{$n&gt;1$ is a prime power coprime to $v$}}C_{v,n}.
$$ 
For a fixed $v$, $C_v$ can be explicitly written down if $v$ is not too large. <strong>My question</strong> actually is: have we already know $C_v$ for infinitely many $v$s'? </p>

<p>I would pose <strong>another question</strong> related to this: does there exist an $N$ such that for all $v&gt;N$, $|C_v|&gt;0$?    </p>
",combinatorics
"<p>For $n\geq 5$, let $\mathcal {P}_n$ be the set of all isomorphism classes of graphs with n vertices. Give this set the poset structure given by $G \le H$ if and only if $G$ is a subgraph of $H$.</p>

<blockquote>
  <p>Is it true that $\mathcal {P}_n$ has no nontrivial automorphisms?</p>
</blockquote>

<p><strong>Remarks:</strong></p>

<p>This follows if one can recognize a graph from the set of isomorphism classes of its edge-deleted subgraphs. However, since recognizing a graph from the set of isomorphism classes of its edge-deleted subgraphs is stronger than edge reconstruction, I'm wondering if there is an alternative way of proving this.</p>
",combinatorics
"<p>Let $[n]$=$\{1,\dots,n\}$ be a set of players in a round-robin tournament. Each player $i$ has an associated skill parameter, $\lambda_{i}$, and the probability that player $i$ defeats player $j$ is $\frac{\lambda_{i}}{\lambda_{i}+\lambda_{j}}$ (ordinary Bradley-Terry comparison). Once a tournament has concluded the players are ranked by their score, with ties being broken at random, so if a score vector was $(3,2,3,0,2)$ then a valid rank vector would be $(4,2,5,1,3)$.</p>

<p>The expected score for player $i$ is $\mathbb{E}[\lambda_{i}]=\sum\limits_{j\not=i}{\frac{\lambda_{i}}{\lambda_{i}+\lambda_{j}}}$. Is there a closed form expression for the expected rank?   </p>
",combinatorics
"<p>Consider all polygons whose vertices are lattice points and edges are parallel to the axes such that no more than two edges meet at a vertex. For two polygons A and B, define A+B be to the set of polygons which can be partitioned into two poygons congruent to A and B.</p>

<p>Given two polygons A and B of same area. Do there always exist a polygon P such that , there is a polygon X in A+P and Y in B+P such that X is congruent to Y? What can we say about area of P? </p>

<p>Edit: I wanted to ask a more general question. If such a P exists, how will one go on constructing it?,And how to characterize the pairs for which such a P does not exist? Is this a known problem?? etc</p>
",combinatorics
"<p>Let $p(n)$ denote count of lattices on finite set $G$, $|G|=n$ (without isomorphism). It's know closed formula for $p(n)$?</p>

<p>It's clear, that $1 \leq p(n)$ and also that $p(n-1) \leq p(n)$ for $n \geq 2$. My other estimates are $p(n) \leq 2^{\frac{(n-1)(n-2)}{2}}$ (also $p(n) \leq 2^{\frac{(n-1)}{2}}$) and $p(n-1) &lt; p(n)$ for $n \geq 4$. Better lower bound for $p(n)$ is $\min(1,n - 2) \leq p(n)$</p>

<p>If there are not closed formula for $p(n)$, what we are able say about that function?</p>

<p>Thanks for help. (Sorry for my bad English)</p>
",combinatorics
"<p>The short version of this question is:</p>

<blockquote>
  <p>If $G$ is a graph whose nodes are associated with squares of a chessboard, such that no two nodes in the same row or column of the board are adjacent, we want to associate rooks with the vertices of $G$, such that at most one rook appears in each row and column of the chessboard under the constraint that the vertices containing the rooks induce a connected subgraph of $G$ (thus, the rooks are connected to each other with a lifeline, or lifegraph if you want to be specific).</p>
  
  <p>A <em>maximal</em> configuration of rooks is such that no rooks can be added to the chessboard without violating the constraint that each column/row contain only one rook.</p>
  
  <p><em>Question</em>: A back-tracking depth first search will find all maximal configutions. Will a back-tracking breadth-first search do the same?</p>
</blockquote>

<p>Let's consider an $m \times n$ chessboard that will be inhabited by rooks. As is usual with chess problems in graph theory, each square is represented by a vertex: let $v_{s,t}$ represent the square at row $s$ and column $t$ of the board. Now, let $G$ be an arbitrary graph on the set of vertices $V$ that comprise the squares of the chessboard.</p>

<p>We want to fill the chessboard with rooks (said another way: we want to associate rooks with vertices), such that:</p>

<ul>
<li>Every row and every column contain at most one rook (more formally, if a rook is associated with a vertex $v_{i,j}$, then no rook will be associated with $v_{i,s}$ for $s \in \{1,\ldots,n\}$) or $v_{t,j}$ for $t \in \{1,\ldots,m\}$),</li>
<li>The vertices with rooks must induce a connected subgraph of $G$ (hence the reference to a ""lifeline"" that must connect all rooks).</li>
</ul>

<p>An example of a chessboard with a single rook (indicated by the black vertex) is shown here</p>

<p><a href=""http://i.stack.imgur.com/VLUCx.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/VLUCx.png"" alt=""enter image description here""></a></p>

<p>The gray squares show the area covered by the rook - no other rook can be placed on any of the gray squares. Note that I have neglected to color the squares themselves black and white as they should appear on a real chessboard. Edges are indicated by red lines.</p>

<p>Let's consider how we might extend the neighborhood of the black node - call it $v$. There are three vertices adjacent to $v$, but we can only place rooks on at most two of them at a time without violating the constraint that only a single rook cover a given row/column. In fact, there are two ways of placing the rooks, as shown here:</p>

<p><a href=""http://i.stack.imgur.com/YXJIp.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/YXJIp.png"" alt=""enter image description here""></a></p>

<p>and <a href=""http://img257.imageshack.us/img257/118/option2m.png"" rel=""nofollow"">here</a> (broken link).</p>

<p>A <em>maximal</em> configuration is a valid placement of rooks (according to our constraints) that cannot be extended by the addition of another rook without violating the constraints.</p>

<p>We can enumerate all maximal configurations by performing a back-tracking depth-first search  from each node (i.e. each square on the chessboard). With a depth-first search, we only add one rook to the chessboard at a time.</p>

<blockquote>
  <p>Suppose that we perform a back-tracking breadth-first search instead. At each step, we add as many rooks the board as possible. Of course there possibly are many different ways of adding as many rooks as possible at each step. This is exactly what is done in the two images above: the maximum number of rooks are added in both possible configurations.</p>
  
  <p>Will this strategy also enumerate all maximal configurations?</p>
</blockquote>
",combinatorics
"<p>Given a closed (possibly singular) projective variety $V$ with a symplectic structure and a torus action, there is a moment map 
$\mu: V \rightarrow Lie(T)^*$. Note that the dimension of $T$ could be much smaller than the dimension of $V$. </p>

<p>How much can we say about the fibers of this moment map $\mu$? Any references?</p>

<p>I am most interested in the case where the variety $V$ is an MV cycle in an affine Grassmannian for an algebraic group $G$. The maximal torus $T \subset G$ acts on the affine Grassmannian. A $T-$equivariant moment map $\mu$ would send an MV cycle to the corresponding MV polytope. What are the fibers of $\mu$ in this case?</p>
",combinatorics
"<p>While studying some seemingly unrelated topological questions, I have experimentally discovered what appears (to me) to be a remarkable sum over partitions.  I was wondering if anyone knows how to prove it.</p>

<p>Fixing $n \geq 1$, it can be stated as follows:</p>

<p>$$1=\sum_{(a_1^{k_1},\ldots,a_p^{k_p}) \vdash n} \left(\frac{1}{(a_1^{k_1}) (k_1 !)}\right) \left(\frac{1}{(a_2^{k_2}) (k_2 !)}\right)\cdots\left(\frac{1}{(a_p^{k_p}) (k_p !)}\right).$$
Here the sum is over all unordered partitions of $n$, and the symbol $(a_1^{k_1},\ldots,a_p^{k_p})$ denotes the partition where $a_1$ appears $k_1 \geq 1$ times, where $a_2$ appears $k_2 \geq 1$ times, etc, and where $a_1 &gt; a_2 &gt; \cdots &gt; a_p &gt; 0$.</p>

<p>I have numerically verified this up to $n=6$.</p>
",combinatorics
"<p>A <a href=""http://en.wikipedia.org/wiki/Difference_set"">difference set</a> of a group $G$ is a subset $D\subseteq G$ with the property that there exists an integer $\lambda&gt;0$ such that for every non-identity member $g$ of $G$, there exist exactly $\lambda$ ordered pairs $(a,b)\in D\times D$ such that $g=ab^{-1}$. Note that $D=G$ is a difference set with $\lambda=|G|$, and so we typically only consider nontrival difference sets.</p>

<p><a href=""http://scholar.google.com/scholar?cluster=16666554031641448939"">Davis</a> showed that $(\mathbb{Z}/n\mathbb{Z})^2$ admits a nontrivial difference set when $n$ is a power of $2$. Are there any known difference sets when $n$ is odd? Perhaps cyclotomic difference sets?</p>

<p>As far as I know, the <a href=""http://en.wikipedia.org/wiki/Difference_set#Known_difference_sets"">Paley-type construction</a> Douglas Zare suggests in the comments (letting $D$ be the set of nonzero perfect squares in $\mathrm{GF}(n^2)$ when $n$ is prime) is only guaranteed to work when $n^2$ is $3\bmod 4$ (which never happens). However, there are hopefully weaker sufficient conditions for $n$ to satisfy, and I think the literature discusses this in the context of ""cyclotomic difference sets,"" but I am not familiar with these results.</p>
",combinatorics
"<p>After seeing that some positivity problems get their solutions on MO,
I am quite enthusiastic of posing my (and not only) problem of positive flavour.</p>

<p>In order to state it, I have to introduce the standard $q$-notation:
$$ (x ; q)_n = \prod _ {j = 1} ^n (1-q^{j-1} x) $$
which is seen to be a polynomial in both $x$ and $q$ for any <em>finite</em> $n=0,1,2,\dots$
(the empty product for $n=0$ has to be interpreted as $1$) but is also
meaningful for $n=\infty$ if $|q|&lt;1$.</p>

<p>""My"" polynomials are
$$
P _n(q)
=\sum _{r=1}^n \frac{ q^{r^2} (q;q) _{3n-r} (q^3;q^3) _{r-1} }{ (q;q) _r (q;q) _{2r-1} (q^3;q^3) _{n-r} }.
$$
To convince you that they are indeed polynomials I write them as
$$
P _n(q)
=\sum _{r=1}^n(1+q^r)q^{r^2}\left[\begin{matrix} 3n-r \cr 2r\end{matrix}\right] _q
\frac{(q^3;q^3) _{r-1}}{(q;q) _{r-1}}(q;q^3) _{n-r}(q^2;q^3) _{n-r}
$$
where
$$
\left[\begin{matrix} a \cr b\end{matrix}\right] _q
=\frac{(q;q) _a}{(q;q) _b(q;q) _{a-b}}
$$
are the $q$-binomial coefficients, or the Gaussian polynomials.</p>

<p>What I can show for the polynomials $P _n(q)$ is that their degree is $3n^2-1$,
they are reciprocal (that is, $P _n(q)=q^{3n^2}P _n(1/q)$) and involve only
powers of $q$ not divisible by 3.</p>

<p>What I cannot show is that the coefficients of these polynomials
are nonnegative. Note that, for $r=1,\dots,n$, the polynomials
$$
(1+q^r)q^{r^2}\left[\begin{matrix} 3n-r \cr 2r\end{matrix}\right] _q
\frac{(q^3;q^3) _{r-1}}{(q;q) _{r-1}}
$$
have nonnegative coefficients (as the Gaussian polynomials do) but the
additional multiple
$$
(q;q^3) _{n-r}(q^2;q^3) _{n-r}
=\prod _{j=1}^{n-r}(1-q^{3j-2})(1-q^{3j-1})
$$
changes the picture drastically.</p>

<p>An additional note in favour of the expected positivity is the limiting case
$n\to\infty$:
$$
P _\infty(q)
=\frac{(q;q) _\infty}{(q^3;q^3) _\infty}
\sum _{r=1}^\infty\frac{q^{r^2}(q^3;q^3) _{r-1}}{(q;q) _r(q;q) _{2r-1}}.
$$
This series is the sum of two Virasoro characters and is thus
a positive series. The latter can be also shown hypergeometrically
and/or using the theory of modular forms (as $P _\infty(q)$ is a modular form).</p>

<p>So, why do the polynomials $P _n(q)$ have nonnegative coefficients?
Any thoughts/links are greatly appreciated and acknowledged in advance.</p>
",combinatorics
"<p>I have a vertex set $V$ and a collection of disjoint arc sets $E_1, \ldots, E_t$ such that $$G_i = (V, E_i),\quad\forall i = 1, \ldots t,$$ are directed acyclic graphs (DAGs) and $$G = (V, E_1 \cup \ldots \cup E_t)$$ is a tournament. We note that the individual DAGs may be disconnected and that $G$ may not be acyclic. However, suppose there exists a bipartition of the arc set indices $\alpha \cup \beta$ such that $$G' = (V, E_\alpha\cup E_\beta^T)$$ is an <b>acyclic</b> tournament where $$E_\alpha = E_{\alpha_1} \cup \ldots \cup E_{\alpha_p}$$ and $$E_\beta = E_{\beta_1} \cup \ldots \cup E_{\beta_q}$$ and $E^T$ is the transpose of $E$ (all the arcs are reversed).</p>

<p>Does anybody know of any results relating to the above? In particular, does anybody know of a method of determining a bipartition $\alpha \cup \beta$, given that at least one exists, other that enumerating all possible bipartitions and checking if the resulting $G'$ is acyclic?</p>
",combinatorics
"<p>Suppose we have a convex hull computed as the solution to a linear programming problem (via whatever method you want). Given this convex hull (and the inequalities that formed the convex hull) is there a fast way to compute the integer points on the surface of the convex hull? Or is the problem NP?</p>

<p>There exist ways to bound the number of integer points and to find the number of integer points inside convex hull, but I specifically want the points on the hull itself.</p>

<p>EDIT: Suppose the set of inequalities (the linear program) have integer coefficients /EDIT</p>
",combinatorics
"<p>I have the following sum
$\sum_{j=1}^K {K \choose j} (-1)^{j+1}/j$. Now I can write this as the integral $\int_{-1}^0 \frac{(1+x)^K - 1}{x} dx$. However, I wonder whether there is a closed form expression for that integral? Thanks.</p>
",combinatorics
"<p>Edit: I realize the mathematics below is lacking a precise phrasing. I hope that the intuitiion behind the question is clear enough that a reader will understand the question and provide guidance. The question is essentially to what extent a degeneration of tropical curves reflects an actual degeneration of complex tropical curves in $(\mathbb{C}^*)^2$ More precisely, On page 10 of his paper, </p>

<p><a href=""http://arxiv.org/pdf/math/0312530v4.pdf"" rel=""nofollow"">http://arxiv.org/pdf/math/0312530v4.pdf</a> </p>

<p>Mikhalkin discusses the degeneration of a smooth tropical curve to a nodal tropical curve. Given such a local degeneration, which we assume occurs in a one dimensional real family paramaterized by $t$, via some reconstruction process, we can associate for each $t$ an actual hypersurface in $(\mathbb{C}^*)^2$ (either a curve in some degenerated complex structure or a complex tropical curve), whose tropicalization is the tropical curve $\Pi_t$. Is it true that the limiting curve over the nodal tropical curve is nodal?</p>

<p>To be more demanding, can one associate to this degeneration in a canonical way a fibration of curves in $(\mathbb{C}^*)^2$, </p>

<p>$H_t \to Spec(\mathbb{C}[\tau,\tau^{-1}])$</p>

<p>such that one fiber has a nodal curve and the rest of the fibers are smooth? The following example makes me believe this may be possible: In the local model corresponding to Mikhalkin's example, we may consider the family of hypersurfaces:</p>

<p>$$\tau+x+y+xy $$</p>

<p>when $\tau$ is not $0,1$, the smooth tropical curve is a smooth deformation retract of the amoebaas of curves in this family. The singular tropical is the (tropical) amoeba of:</p>

<p>$$ 1+x+y+xy=(1+x)(1+y) $$</p>
",combinatorics
"<p>In combinatorics there are there are special kind of sequences, in which their terms represent the number of different ways that we can draw chords with some properties.   </p>

<p>Actually my question is motivated by the following examples of what I have mentioned earlier. </p>

<blockquote>
  <ol>
  <li><p><a href=""http://en.wikipedia.org/wiki/Motzkin_number"" rel=""nofollow"">Motzkin number</a> (The number of different ways of drawing non-intersecting chords on a circle between n points)</p></li>
  <li><p><a href=""http://en.wikipedia.org/wiki/Bell_number"" rel=""nofollow"">Bell number</a> (the number of partitions of a set of size n, in this case the drawing of the chords is described in the link)</p></li>
  <li><p><a href=""http://en.wikipedia.org/wiki/Catalan_number"" rel=""nofollow"">Catalan number</a>(number of non <a href=""http://en.wikipedia.org/wiki/Noncrossing_partition"" rel=""nofollow"">crossing partitions</a> of some sets)</p></li>
  </ol>
</blockquote>

<p>My question is that, can you, please, tell me similar sequences?  </p>
",combinatorics
"<p>Hi. I have a  question. </p>

<p>Definition. Delzant polytope $P$ is a rational convex simple polytope with the smooth condition. Here, ""smooth"" means that for each vertex $v$, the $n$ edges containing $v$ form an element of $SL(n,\mathbb{Z})$, where $n$ is a dimension of $P$.</p>

<p>(If you wonder why this condition is called smooth, See Fulton. Introduction to toric variety chap I)</p>

<p>My question is as follow. </p>

<p>Can dodecahedron be the Delzant polytope?
I mean, is there a symplectic toric manifold whose moment map image is combinatorially equivalent to a dodecahedron?</p>

<p>Delzant's classfication theorem of compact symplectic toric manifold is surely very strong. But I think it is very hard to check whether the given polytope (having many faces)
is of Delzant type or not. If you know any reference of give me any comment, I really appriciate for your help. </p>

<p>Thank you.</p>
",combinatorics
"<p>Let $G=(V,E)$ be a (simple) finite graph such that every vertex has degree at least 1. Then it is easy to see that there is a subset $E'$ of $E$ such every vertex in $G'=(V,E')$ still has degree at least 1 and all paths (with no repeating edges) in $G'$ are of (edge-wise) length at most 2. (I just keep removing middle edges of paths of length 3 until I'm done.) My question is, does this hold for infinite graphs ?</p>

<p>EDITED: tried to make the question more clear, as comments suggested</p>
",combinatorics
"<p>We know the inequalities $x_ix_j &gt;\theta_{ij}$ or $x_ix_j&lt;\theta_{ij}$ for some $\theta_{ij}$>0, some $i,j\in\{1,\cdots,n\}$, $i\neq j$ defines the easiest semi algebraic set in $R^n_{\geq 0}$, i.e the all coordinates positive quadrant of $R^n$, and obviously it is connected as we only consider positive quadrant.</p>

<p>My question is:
  whether finite intersection of semi algebraic sets defined by above inequalities is still connected or not?</p>

<p>Personally, I believe it is connected by checking several examples by hand, but still have not idea about how to give general proof. Thanks a lot.</p>
",combinatorics
"<p>I'm looking for something making tractable the sum, over all partitions into k terms of an integer n, of the product of the factorials of all the terms.
Thanks,</p>
",combinatorics
"<h2>Problem</h2>

<p>I'm looking for an upper bound for the number $k(G)$ of a finite group $G$, defined as follow:</p>

<blockquote>
  <p>Let $\mathcal{F}_k$ be the family of subsets of $G$ with size $k$, and we
  define $k(G)$ be the minimum $k$ such that every subset $X \in \mathcal F_k$
  contains a non-empty sum-full set $S$, which is a set satisfies 
  $$ S \subseteq S+S := \{ x+y \mid x,y \in S \}. $$</p>
</blockquote>

<p>Note that the inequality $k(G) \leq |G|$ holds trivially since there is only one
subset in $\mathcal F_{|G|}$ which is $G$ itself, and $G$ is a semigroup indeed.</p>

<p>Are there any papers or references about this number $k(G)$? Does it have a name? I'm interesting in particularly upper bounds of $k(G)$, but any related results are fine.</p>

<hr>

<h2>Motivation</h2>

<p>The <strong>restricted Davenport number</strong> $\hat{D}(G)$ of a group $G$, is defined as the smallest number $d$ such that given a subset $A \in \mathcal F_d$, there exists a <strong>zero-sum</strong> non-empty subset $S \subseteq A$, that is, </p>

<p>$$ \sum_{x \in S} x = 0, $$</p>

<p>where $0$ is the identity in $G$.
In the paper ""On a conjecture of Erdos and Heilbronn"", Szemeredi has proved:</p>

<p>$$\hat{D}(G) = O(\sqrt{|G|}). $$</p>

<p>Hamidoune and Zemor set a precise bound $\sqrt{2}$ on the constant of the big-O notation.</p>

<p>I'm trying to provide a link between $\hat{D}(G)$ and the number $k(G)$; it seems to me that the size of sum-full sets in $G$ may related to the zero-sum problem. I'll provide the justification in another post, which is highly related.</p>
",combinatorics
"<p>For $A\subset [n]$ denote by $a_i$ the $i^{th}$ smallest element of $A$.</p>

<p>For two $k$-element sets, $A,B\subset [n]$, we say that $A\le B$ if $a_i\le b_i$ for every $i$.</p>

<p>A $k$-uniform hypergraph ${\mathcal H}\subset [n]$ is called a {\em shift-chain} if for any hyperedges, $A, B \in {\mathcal H}$, we have $A\le B$ or $B\le A$. (So a shift-chain has at most $k(n-k)+1$ hyperedges.)</p>

<p>We say that a hypergraph  ${\mathcal H}$ has Property B if we can color its vertices with two colors such that no hyperedge is monochromatic.</p>

<p>Is it true that shift-chains have Property B if $k$ is large enough?</p>

<p>$\bf Remarks.$ The problem was investigated on the 1st Emlektabla Workshop for some partial results, see the <a href=""http://www.renyi.hu/~emlektab/index_booklet.html"" rel=""nofollow"">booklet</a>.</p>

<p>The question is motivated by decomposition of multiple coverings of the plane by translates of convex shapes, there are many open questions in this area. (For more, see my <a href=""http://www.cs.elte.hu/~dom/cikkek/thesis.pdf"" rel=""nofollow"">brand new thesis</a>.)</p>

<p>For $k=2$ there is a trivial counterexample: (12),(13),(23).</p>

<p>A very magical counterexample was given for $k=3$ by Radoslav Fulek with a computer program:</p>

<p>(123),(124),(125),(135),(145),(245),(345),(346),(347),(357),</p>

<p>(367),(467),(567),(568),(569),(579),(589),(689),(789).</p>

<p>If we allow the hypergraph to be the union of two shift-chains (with the same order), then there is a counterexample for any $k$.</p>

<p>$\bf Edit.$ I crossposted the question at <a href=""http://cstheory.stackexchange.com/questions/2917/do-shift-chain-have-property-b"">cstheory.SE</a>.</p>
",combinatorics
"<p>For some positive integer $r$, by an $r$-vector I will mean an $r$-tuple $(a_1,a_2,\dots,a_r)$ with $a_1,\dots,a_r$ nonnegative integers not all zero, and I will call it odd if $a_1,\dots,a_r$ are all odd. An odd partition of an $r$-vector $(a_1,a_2,\dots,a_r)$ is a multiset of odd $r$-vectors whose sum is equal to $(a_1,a_2,\dots,a_r)$. Note that when $r=1$, this is just the partition of a number into odd numbers. </p>

<p>Let $Q_r(a_1,\dots,a_r)$ be the number of odd partitions of the $r$-vector $(a_1,a_2,\dots,a_r)$. What is known about the sequence $Q_r(n,n,\dots,n)$, ($n=1,2,\dots$)? Especially is there any estimation or asymptotic for it? Of course the first case I'm interested in is $r=2$ since it is the classical theory of partitions for $r=1$.</p>
",combinatorics
"<p>I need to count the number of perfect matchings of a certain family of graphs. This family of graph is non planar and a type of snark. For the initial cases, it seems that this number is growing exponentially. My request is different from the one <a href=""https://en.wikipedia.org/wiki/FKT_algorithm"" rel=""nofollow"">here</a> because right now, I have no interest in knowing what these perfect matchings are.</p>

<p>The <a href=""https://en.wikipedia.org/wiki/FKT_algorithm"" rel=""nofollow"">FKT</a> algorithm gives a polynomial time algorithm for a planar graph and I am wondering if there is anything similar for non planar graphs. Does anyone have any ideas?</p>
",combinatorics
"<p>Let $S=\{1,2,\dots,m+n-1\}$.</p>

<p>An $m\times n$ matrix($\in S^{m\times n}$) is called silver matrix if</p>

<p>(a) There is no same numbers in the row or column. (like latin square)</p>

<p>(b) {$i$ th row}$\cup${$i$ th column}=S for all $1\leq i\leq min(m,n)$</p>

<p>Does silver matrix exist for all $m\neq n$ ?</p>

<p>If this conjecture is true, $d(K_m\times K_n, m+n-1) = mn-min(m,n)$ ($m\neq n$)</p>

<p>($d$ is defining number, $\times$ is cartesian product)</p>
",combinatorics
"<p>This question is motivated by the ongoing discussion under my answer to <a href=""http://mathoverflow.net/questions/29271/algebraic-geometry-used-externally-in-problems-without-obvious-algebraic-struc"">this</a> question.  I wrote the following there:</p>

<blockquote>
  <p>A $(p, q, r)$ Steiner system is a collection of $q$-element subsets $A$ (called blocks) of an $r$-element set $S$ such that every $p$-element subset of $S$ is contained in a unique element of $A$.  Good examples come from considering as blocks the set of hyperplanes in $\mathbb{A}^n$ or $\mathbb{P}^n$ over a finite field.  For example, $\mathbb{A}^2$ over $\mathbb{F}_3$ gives a $(2, 3, 9)$ Steiner system:  it contains $9$ ($\mathbb{F}_3$-rational) points, and let the blocks be the lines, each of which consists of $3$ points.  Then any $2$ points are contained in a unique line.  This is the unique $(2, 3, 9)$ Steiner system.</p>
</blockquote>

<p>In general, considering lines in $\mathbb{A}^n$ or $\mathbb{P}^n$ gives an analogous Steiner system, and papers such as <a href=""http://www.springerlink.com/content/62157221j2718857/"">this one</a> contain similar constructions.</p>

<p>Loosely, my question is:  which Steiner systems come from similar constructions?  I'll make this more precise in a bit.</p>

<p>An artificial construction allows us to realize any Steiner system as the points of a variety in $\mathbb{A}^n$ over $\mathbb{F}_2$, the blocks of which are given by the intersection of the variety with some specified hyperplanes, as follows.  (This construction is due to Jeremy Booher.)  Say we have a $(p,q, r)$ Steiner system with $k$ blocks; consider the subvariety of $\mathbb{A}^k$ containing the point $y_j=(a_i)_{1\leq i\leq k}$ with $a_i=0$ if the $j$-th element in our Steiner system is in block $i$ and $1$ otherwise.  Then the intersections with the hyperplanes $x_i=0$ give our blocks.  And this subset is a variety as any subset of $\mathbb{A}^k$ is a variety, as it is finite.</p>

<blockquote>
  <p>So let us try for something harder:  Which Steiner systems $(p, q, r)$ come from a subvariety $X$ of $\mathbb{A}^n$ or $\mathbb{P}^n$ containing $r$ ($\mathbb{F}_s$-rational) points, with the blocks given as the intersections with <em>all</em> $p+1$-dimensional hyperplanes?  A slightly weaker version: when is there a subvariety $X$ of $\mathbb{A}^n$ or $\mathbb{P}^n$ with $r$ $\mathbb{F}_s$-rational points such that every $p+1$-plane intersects $X$ at $q$ points?  In particular, this requires that any $p$ points in $X$ be in general position, so things like rational normal curves are natural candidates.</p>
</blockquote>

<p>This is probably too hard, so perhaps the simpler question is tractable:</p>

<blockquote>
  <p>Can you prove that some Steiner system does not come from this construction?</p>
</blockquote>

<p>EDIT:  One way of doing this might be to find a Steiner system with $b$ blocks, where $b$ is not a $q$-binomial coefficient with $q$ a prime power; such systems exist for $p=1$ but I am looking for a non-trivial example.</p>
",combinatorics
"<p>Is there any suggestion about how could one construct a model that uses semidefinite programming that minimizes sum of k smallest eigenvalues of Laplacian matrix?
I found two papers that have done something for the just bound not for optimization.</p>
",combinatorics
"<p>What is the number of strongly regular graphs on $n$ vertices? or at least how many non-isomorphic strongly regular graphs can exist?</p>
",combinatorics
"<p>Is there any known formula for the number of compositions of an integer k (partitions with considering the order of the parts) of length m (exactly m parts) where the parts do not exceed a given integer n? 
Without limitation of the parts there is, of  course, a well-known formula (binomial k-1 over m-1). Introducing the limitation I worked out a formula but I don´t know whether it´s already published anywhere ... </p>
",combinatorics
"<p>Let $G$ be a graph without any hole or antihole of odd length at least 5 (i.e. $G$ is a Berge graph and so by the Strong Perfect Graph Theorem, $G$ is perfect). 
Assume further that $G$ has no antihole of length 6 and also it has no even hole or antihole of length at least 8. Also suppose that $G$ has no induced path $P_6$ of length 6. </p>

<p>Thus  graphs in question are perfect and $P_6$-free  with a slightly stronger property that they have no antihole of length 6.</p>

<p>Is there a classification of such graphs?</p>

<p>Of course one may expect that by docomposion results due to [M. Chudnovsky, N. Robertson, P.D. Seymour, R.Thomas, V. Chvátal, N. Sbihi, M. Conforti, G. Cornuéjols, and K. Vušković] for perfect graphs and also by the results due to [R. Mosca, Pim van 't Hof and DaniÄel Paulusma] on P6-free graph, it may be possible to find a characterization or even a classification; but, for a lazy man as me, it is better to know first if such a characterization has been aleardy seen or used.</p>

<p>The motivation is <a href=""http://mathoverflow.net/questions/104137/can-the-friendship-graph-be-determind-by-its-adjacency-spectrum"">this</a> question of mine about graphs $G$ which are cospectral with a friendship graph. Such a graph $G$ has no induced subgraph with two eigenvalues greater than 1 and also no induced subgraph of $G$ has two eigenvalues less than -1. The latter follows from the interlacing lemma.<br>
Thus it is easily seen that such graphs $G$ are perfect and $P_6$-free and they have no antihole of length 6. </p>
",combinatorics
"<p>Are there any well studied graph theoretic properties that are common to all subgraphs of the boolean hypercubes that have a given VC dimension d.  </p>
",combinatorics
"<p>Given a finite group $G$, write $K(G)$ for the complete digraph on the elements of $G$.  Label the edge from $g$ to $h$ by element $g^{-1}h$.</p>

<p><strong>Question</strong>:  For what groups does there exist a Hamiltonian path in $K(G)$ whose edge labels exhaust the elements of $G$, apart from the identity?</p>

<p>Some observations:</p>

<ol>
<li><p>If $G={\Bbb Z}/12{\Bbb Z}$, mathematical music theory calls such paths ""all-interval rows.""</p></li>
<li><p>No such paths exist for cyclic groups of odd order greater than 1 because the sum of all elements in such a group equals the identity.  More generally, when $G$ abelian has such a path, I believe that $G$ must have exactly one factor of even order when expressed as a product of cyclic groups, or equivalently, a unique element of order 2.  I don't know the status of the converse.  </p></li>
<li><p>Any Hamiltonian path determines a sequence of $|G|-1$ non-identity edge labels.  Heuristically, a random such sequence has probability  $(|G|-1)!/ {(|G|-1)}^{|G|-1}$ of having no repeated labels.  This predicts that the desired paths exist in great profusion, at least absent any global obstruction as in the previous comment.  Where I have made exhaustive searches either no desired paths turned up at all, or I saw a total reasonably consistent with the heuristic.  Can one prove or disprove anything along these lines?  Even-order cyclic groups have paths of the desired sort, but I don't have any interesting bounds on the total counts even in this case.</p></li>
<li><p>The case of dihedral times ${\Bbb Z}/2{\Bbb Z}$ has mathematical music theory interest.
Paths exist in profusion with the dihedral group factor having order 6, 8, 10, 12 or 24 (the musically most interest case!), but I've yet to see any desired paths searching orders 14, though this might simply reflect the vast size of the search space.  (I have now found examples for 24, but only by using an ad hoc hack whose effectiveness I don't understand.)</p></li>
</ol>
",combinatorics
"<p>In class, we recently saw that the sum of 2 two-sided nil ideals is a nil ideal. We were asked to show that the sum of a niplotent left ideal and a nil left ideal is a nil left ideal.</p>

<p>I am having trouble with this. Can anyone help?</p>
",combinatorics
"<p>I pick a random subset $S\subseteq\lbrace1,\ldots,N\rbrace$, and you have to guess what it is. After each guess $G$, I tell you the number of elements in $G \cap S$. How many guesses do you need to determine the subset? (If there is only one possibility left, then you can omit the last guess.)</p>

<p>There is an obvious strategy that requires only $N$ guesses. Guess $\lbrace1\rbrace$, then guess $\lbrace2\rbrace$, then guess $\lbrace3\rbrace$, and so on. But there is a <a href=""http://math.stackexchange.com/questions/25270/guessing-a-subset-of-1-n"">clever strategy</a> that requires only $\lceil 4N/5 \rceil$ guesses.</p>

<p>We know that the minimum number of guesses is at least $\left\lceil \frac{N}{\log_2{(N+1)}}\right\rceil$, because each guess reveals at most $\log_2(N+1)$ bits of information. I seek a proof or disproof of the conjecture that the number of guesses $g(N)$ is sublinear, i.e. $\lim_{N\to\infty} g(N)/N = 0$. </p>

<p>I will donate $100 to the American Red Cross if a proof or disproof is posted to this thread by April 30, 2011. For this purpose, I will accept an argument as correct if I believe it to be correct; or if a user with reputation above 1000 asserts that it is correct, and no user with reputation above 1000 denies that it is correct. Naturally, I would welcome improved upper bounds, even if they are linear.</p>
",combinatorics
"<p>The question on games and mathematics that appeared recently on mathoverflow
(<a href=""http://mathoverflow.net/questions/13638/which-popular-games-are-the-most-mathematical"">Which popular games are the most mathematical?</a>)
reminded me of a problem I encountered some time ago : starting with the insane
dream of completely solving the game of bridge with a nice mathematical theory,
I ended up considering extremely simplified versions of bridge. One of them was 
as follows : there are only 2 players instead of 4, and instead of the usual
deck there are only 2n cards numbered from 1 to 2n. Each player holds half 
of the deck, so this is a ""complete information"" game : each player knows exactly
what is in his opponent's hand. There are no bids, just a sequence of n moves
where each player drops a card ; as in bridge the strongest card wins the trick
and the winner of the game is the player with the largest number of tricks
in the end (take n odd to avoid draws). Also, the winner of the preceding
trick is the first to play (for the very first move the first player is determined
by some rule, random or other ; this is immaterial to the subsequent discussion).</p>

<p>This looks like a very basic kind of game, especially amenable to 
mathematization : for example the set of all initial positions is nicely indexed
by the subsets $I$ of $\lbrace 1,2, \ldots , 2n\rbrace$ whose cardinality is $n$
(say $I$ is the set of cards held by the first player). I was
however unable to answer the following questions :</p>

<ul>
<li><p>Is there an algorithm which, given the initial position, finds out which player
will win if each one plays optimally ? What is the best strategy ?</p>

<ul>
<li>Has this game already been studied by combinatorialists ?</li>
</ul></li>
</ul>
",combinatorics
"<p>I have n sectors, enumerated 0 to n-1 counterclockwise. The boundaries between these sectors are infinite branches (n of them).</p>

<p>These branches meet at certain points (junctions). Each junction is adjacent to a subset of the sectors (at least 3 of them). </p>

<p>By specifying what sectors my junctions are adjacent to, I can completely recover the tree.
This seems like something known, but I would like a reference to it.</p>

<p>The number of trees with n branches is given by 
<a href=""http://www.oeis.org/A001003"" rel=""nofollow"">http://www.oeis.org/A001003</a>
and this is quite easy to prove. </p>

<p>Furthermore, if I order the sectors in the description of the junctions, I can make this representation unique.</p>

<p>Example:
(0,1,2,3,4,5) represents the tree with only one vertex, and 6 branches connected to this junction.</p>
",combinatorics
"<p>Let A be a non-negative integer square matrix with eigenvalues x<sub>1</sub>, x<sub>2</sub>, ... x<sub>n</sub>.  Any symmetric function of these eigenvalues with integer matrices is an integer.  I'm aware of the following results regarding the combinatorial interpretation of these integers:</p>

<ul>
<li><p>If A is the adjacency matrix of a finite directed graph G, the power symmetric functions of the eigenvalues count closed walks on A with a distinguished starting point.</p></li>
<li><p>Similarly, the complete homogeneous symmetric functions of the eigenvalues count non-negative integer linear combinations of aperiodic closed walks on A.  </p></li>
<li><p>(Gessel-Viennot-Lindstrom) If A<sub>ij</sub> is the number of paths from source i to sink j on, say, a 2-D lattice where the only permissible moves are to the right and up, then the elementary symmetric functions of the eigenvalues count the number non-intersecting k-tuples of paths from the sources to the sinks.  In particular det A is the number of non-intersecting n-tuples of paths.</p></li>
</ul>

<p>Do these results generalize to give a nice combinatorial interpretation of the value of the Schur function associated to an arbitrary partition evaluated at x<sub>1</sub>, x<sub>2</sub>, ... x<sub>n</sub> in terms of some combinatorial object attached to A?  What conditions need to be placed on A so that the Schur functions are always non-negative?</p>

<p>Feel free to either talk about the GL(n) perspective or to frame your discussion entirely in terms of tableaux.</p>
",combinatorics
"<p>How I arrived at this question is a rather long story having to do with the honors calculus class I am teaching. At this point it's sheer curiosity on my part. Here is the game.</p>

<p>$\newcommand{\bZ}{\mathbb{Z}}$</p>

<p>We start with a finite collection of stones placed  at random  somewhere on the set of nodes $\newcommand{\eN}{\mathscr{N}}$ $$\eN=\{2,3,4,\dotsc\}. $$      We can view a distribution  of stones as a  function $s:\eN\to\bZ_{\geq 0} $ with finite support, $s(n)=$ the number of stones at $n$. Its <em>weight</em>  is the nonnegative integer</p>

<p>$$|s|=\sum_{n\in\eN} s(n). $$</p>

<p>We say that a distribution $s$ is <em>overcrowded</em>  if $s(n)&gt; 1$ for some $n\in\eN$. A node $n$ is called  <em>occupied</em> (with respect to $s$) if there is at least one stone at $n$, $s(n)&gt;0$. </p>

<p>We are allowed the following moves:  choose an occupied node $n$. Then   you move one stone from location $n$ to location $n+1$ and add a new stone at location $n^2$.    Note that such a move increases the weight by $1$.</p>

<p>Now comes the question.</p>

<blockquote>
  <p>Is it true that for any  initial distribution of stones $s:\eN\to\bZ_{\geq 0}$ and any positive integer $N$   there exists a finite sequence of  allowable moves   such that after these moves we obtain a  new distribution of stones  which (i) is <strong>not</strong> overcrowded, and (ii) no node $n&lt;N$ is occupied.   </p>
</blockquote>

<p>Empirical evidence leads  me to believe that the answer to this question is positive. However, I have failed to find a conclusive argument.I'm hoping  someone  in the MO community will have more luck.</p>

<p><strong>Remark 1.</strong> (<em>Inspired by David Eppstein's answer.</em>) I want to show that if the function $n\mapsto n^2$ in the definition of an allowable move is replaced by something else the answer to the question can be  negative.   In other words, any proof for  the positive answer, would have to take into account some features of the map $n\mapsto n^2$.</p>

<p>Here is the example. Fix an integer $k&gt;1$ and  define $f:\eN\to\eN$, $f(n)=n+k$.   Now change the definition of an allowable move as  follows.</p>

<blockquote>
  <p>Pick an occupied node $m$. Move a stone from location $m$ to $m+1$ and
  add a stone  at the node $f(m)$.  We will  denote by $T_m$ this move.</p>
</blockquote>

<p>Let $s_0:\eN\to\bZ_{\geq 0}$ be the configuration consisting of a single stone located at $n=2$. <em>I claim that there exists  $N&gt;0$ such that $s_0$ cannot be moved past $N$ without overcrowding.</em>   </p>

<p>The proof is based on a conservation law suggested by David Eppstein's answer.  Consider the polynomial $P(x)=x^k+x-1$. Note that $P(0)&lt;0$ and $P(1)&gt;0$ so  $P$ has at least one root  in the interval $(0,1)$. Pick one such root $\rho$.  We use $\rho$ to define the <em>energy</em> of a configuration $s:\eN\to\bZ_{\geq 0}$ to be</p>

<p>$$ E(s):=\sum_{n\in \eN} s(n)\rho^n. $$</p>

<p>If $m$ is an occupied location of a configuration $s:\eN\to\bZ_{\geq 0}$, then</p>

<p>$$E(T_m s)= E(s)-\rho^m+\rho^{m+1}+\rho^{m+k}=E(s)+\rho^mP(\rho)=E(s). $$</p>

<p>Thus allowable moves do not change the energy of a configuration.</p>

<p>Let $N$ be a positive integer such that</p>

<p>$$\rho^{N-2}&lt;1-\rho. \tag{1} $$</p>

<p>Suppose now that using allowable move we can transform  $s_0$ to a configuration $s$ such that</p>

<p>$$ s(n)=0,\;\;\forall n&lt;N,\;\;s(n)\in \{0,1\},\;\;\forall n\geq N. $$</p>

<p>Then</p>

<p>$$\rho^2= E(s_0)=E(s)\leq \sum_{n\geq N}\rho^n=\frac{\rho^N}{1-\rho}. $$</p>

<p>This last inequality violates the assumption (1), thus confirming my claim.</p>

<p><strong>Remark 2.</strong> The example in the previous remark has the following  obvious  generalization. Suppose that $f:\eN\to\eN$ is a function  such that $f(n)&gt;n+1$, $\forall n \in \eN$ and there exists a probability measure $\pi$ on $\eN$ such that</p>

<p>$$ \pi\bigl(\; f(n)\;\bigr)+\pi(n+1)-\pi(n)\geq 0,\;\;\forall n\in\eN. \tag{2}$$</p>

<p>Using  $f$ to define the allowable  moves, one can show that  there exists $N&gt;0$ such that $s_0$ cannot be moved past $N$ without overcrowding.   The proof uses the <em>entropy</em></p>

<p>$$E_\pi(s)=\sum_{n\in\eN}s(n)\pi(n). $$</p>

<p>Note that this entropy  is precisely the expectation of $s$ with respect to the probability measure $\pi$, and it <em>does not decrease</em> as we apply allowable moves</p>

<p>$$E(s)\leq E(T_m s), \;\;\forall s. $$</p>

<p>For $f(n)=n+k$ we can define</p>

<p>$$ \pi(n)=(1-\rho)\rho^{n-2}. $$</p>

<p>This remark raises the following natural  question.</p>

<blockquote>
  <p>Find the functions $f:\eN\to \eN$ such that $f(n)&gt;n+1$, $\forall n\in \eN$,
  and there exists a probability measure $\pi$ on $\eN$ satisfying
  (2). How fast can such a function grow as $n\to \infty$?</p>
</blockquote>

<p><strong>Remark 3.</strong> (a) For $f(n)=n^2$ the condition (2) reads</p>

<p>$$ \pi(n^2)+\pi(n+1)\geq \pi(n). \tag{3} $$</p>

<p>One can show that a  series   $$\sum_{n\geq 1}p(n) $$ with  nonnegative terms satisfying (3) is  divergent if not all the terms are trivial. (This was the rather tricky honors calculus problem that prompted the present question.)  Hence,  for the function $f(n)=n^2$, there do not exist  probability measures  satisfying (2), suggesting indirectly that the original question could have  a positive answer.</p>

<p>(b) If $f(n)=n +1+ \lfloor \sqrt{n}\rfloor$,   $\alpha&gt;1$ is sufficiently close to $1$ and </p>

<p>$$\pi(n)=\frac{C}{n^\alpha}, \;\;C\sum_{n\geq 2}\frac{1}{n^\alpha}=1,$$</p>

<p>then the condition (2) is satisfied so  moving without overcrowding is not possible if the allowable moves use the function $f(n)$.</p>

<p><strong>Remark 4.</strong> Have a look at Michael Stoll's superb answer. </p>
",combinatorics
"<p>I'm trying to find the exact asymptotics of a sum:</p>

<p>$$A = \sum^n_{i=0} \begin{pmatrix} 2n \\ i \end{pmatrix} x^{i} y^{2n-i} $$</p>

<p>as $n\rightarrow\infty$. Here $x,y$ are complex numbers, $|x|\leq1, |y|\leq1$. I also have $|x+y|&lt;1$ and $|4xy|\leq1$. My strategy is to write the sum as an integral.
Rewrite this sum as:
$$ A = (x+y)^{2n} - 
\sum^{n-1}_{i=0} \begin{pmatrix} 2n \\ i \end{pmatrix} x^{2n-i} y^i \quad\quad\quad\quad (1) $$</p>

<p>Note that this is a remainder for the $(n-1)$-order Taylor expansion so can use the integral formula for the remainder:</p>

<p>$$ A = \begin{pmatrix} 2n \\ n \end{pmatrix} y^n \int^1_0 (x+(1-t)y)^n nt^{n-1} dt $$</p>

<p>Changing variables and introducing $z=x/y$ get:</p>

<p>$$  A =  \begin{pmatrix} 2n \\ n \end{pmatrix} (xy)^n \int^1_0 (1+(1-u^{\frac{1}{n}})z)^n du  $$</p>

<p>In this integral the integrand converges to $u^{-z}$. Then for $Re(z)&lt;1$ the integral converges and I get (using Stirling's formula) the following asymptotic expression:</p>

<p>$$ A \sim \frac{(4xy)^n}{\sqrt{n}}\frac{1}{1-z} $$</p>

<p>On the other hand, I can approximate the <strong>second</strong> term in $(1)$ as the Taylor remainder thus interchanging the roles of $x,y$ and then get for $Re(1/z)&lt;1$ that </p>

<p>$$ A \sim (x+y)^{2n} - \frac{(4xy)^n}{\sqrt{n}}\frac{1}{1-1/z} $$</p>

<p>However, now I have something very strange: when both $Re(z)&lt;1$ and $Re(1/z)&lt;1$ are valid, both asymptotic expressions have to agree, which means that it must be $|x+y|^2 &lt; |4xy|$. But it's clearly not true - take for example $x=-1/2$ and $y=1/100$ which satisfy the conditions on $Re(z)$ and $Re(1/z)$. Where have I made a mistake?</p>
",combinatorics
"<p>Let $R(k)$ denote the diagonal Ramsey number, i.e. the minimal $n$ such that every red-blue colouring of the edges of $K_n$ produces at least one monochromatic $K_k$. </p>

<blockquote>
  <p>Is it possible that there exists an absolute constant $C&gt;0$ and polynomial $p\in \mathbb{Q}[x]$ such that for all $k$ (or perhaps for all sufficiently large $k$)
    $$ R(k) = C^kp(k)? $$</p>
</blockquote>

<p>Even the asymptotic behaviour of $R(k$) is not known (it is known that $\sqrt{2}^{k(1+o(1))}\leq R(k)\leq 4^{k(1+o(1)}$.) So a proof of such an exact result is certainly out of reach. But showing that there cannot be such a formula might be possible.</p>

<p>There are exact formulas known for related Ramsey-type functions (e.g. fractional Ramsey numbers [2] and Ramsey numbers restricted to various classes of graphs, such as planar graphs, line graphs, and perfect graphs [1,3].) As far as I can see, however, the question of an exact formula for the classical Ramsey numbers has not been considered.</p>

<p>[1] Belmonte, Heggernes, van't Hof and Saei, Ramsey numbers for line graphs and perfect graphs, Computing and combinatorics, 204–215, Lecture Notes in Comput. Sci., 7434, Springer, Heidelberg, 2012.  <a href=""http://link.springer.com/chapter/10.1007%2F978-3-642-32241-9_18"">http://link.springer.com/chapter/10.1007%2F978-3-642-32241-9_18</a></p>

<p>[2] Brown and Hoshino, Proof of a conjecture on fractional Ramsey numbers,  J. Graph Theory 63 (2010), no. 2, 164–178. <a href=""http://onlinelibrary.wiley.com/doi/10.1002/jgt.20416/pdf"">http://onlinelibrary.wiley.com/doi/10.1002/jgt.20416/pdf</a></p>

<p>[3] Steinberg and Tovey, Planar Ramsey numbers, 
J. Combin. Theory Ser. B 59 (1993), no. 2, 288–296</p>
",combinatorics
"<p>This question arose from an <a href=""http://mathoverflow.net/a/207571/41291"">answer</a> to my recent question <a href=""http://mathoverflow.net/q/207540/41291"">How many traces are there on Temperley-Lieb, Fuss-Catalan, Iwahori-Hecke, Birman-Wenzl-Murakami-Kauffman, ... algebras?</a></p>

<p>What I need from that answer here is combination of the following facts.</p>

<p>0) Let $V$ be the standard (2-dimensional) representation of the Lie algebra $\mathfrak{sl}_2$ (over complex numbers, say). </p>

<p>1) Dimension of the algebra $\operatorname{End}_{\mathfrak{sl}_2}(V^{\otimes n})$ is $C_n$, the $n$-th Catalan number.</p>

<p>2) Let $V^{\otimes n}=m_{n,0}\mathbf{1}\oplus m_{n,1}V\oplus m_{n,2}S^2(V)\oplus m_{n,3}S^3(V)\oplus\cdots$ be the decomposition into irreducible representations of $\mathfrak{sl}_2$, then the above endomorphism algebra decomposes accordingly into the product of full square matrix algebras $\operatorname{Mat}_{m_{n,0}}\times\operatorname{Mat}_{m_{n,1}}\times\operatorname{Mat}_{m_{n,2}}\times\cdots$.</p>

<p>3) It follows easily from the formula $V\otimes S^k(V)\cong S^{k-1}(V)\oplus S^{k+1}(V)$ used in the above answer that the numbers $m_{n,k}$ form the <a href=""https://oeis.org/A053121"" rel=""nofollow"">Catalan triangle</a></p>

<pre><code>1
0   1
1   0   1
0   2   0   1
2   0   3   0   1
0   5   0   4   0   1
5   0   9   0   5   0   1
</code></pre>

<p>That is, $m_{n,k}=m_{n-1,k-1}+m_{n-1,k+1}$ for $k\geqslant0$ (starting from $m_{0,0}=1$ and with $m_{n,k}=0$ for $k&lt;0$ or $k&gt;n$).</p>

<p>It thus follows from the above matrix algebra decomposition that the sum of squares of the numbers in the rows of this triangle are the Catalan numbers.</p>

<p>The latter fact seems to be well known. At least it is mentioned at the OEIS page to which my above link points. At that page there also is the formula $m_{n,k}=\frac{k+1}{n+1}\binom{n+1}{\frac{n-k}2}$ (for $n\equiv k\mod 2$, otherwise it is zero).</p>

<p>My question is whether a combinatorial interpretation of this is known. Specifically, whether there are some combinatorial objects enumerated by $m_{n,k}$ such that $C_n$ equals the number of pairs of such objects with equal $k$'s.</p>

<p>LATER</p>

<p>After much hesitation I decided to accept the answer by Qiaochu Yuan. The reason is purely egotistic - that answer helped me personally better to understand the picture (which I reflected in my own answer).</p>
",combinatorics
"<p>I have a result for graphs whose stability number=clique cover number, which naturally includes the perfect graphs, but I'm curious about if there are other known and well-definable graph classes which fit the bill.</p>

<p>Thanks</p>
",combinatorics
"<p>Given a square integer matrix $A \in M_n(Z)$ and two subsets $I, J \subset \{ 1, \ldots, n\}$, we define $A_{I,J}$ as the sub-matrix of $A$ containing the rows (resp. columns) whose index is in $I$ (resp. $J$).</p>

<p>I wonder if there is a fast algorithm for finding maximal sets $I$ and $J$, $I \cap J = \emptyset$ such that $\det(A_{I,J}) = \pm 1$.</p>

<p>Note: Obviously, $I$ and $J$ have the same cardinal.</p>
",combinatorics
"<p>Suppose $p &lt; q$, $s = p^{d}$ for some fixed $d \in (0,1)$, let $p$ goes to infinity, define the following quantity,
\begin{aligned}
\quad f(j) = \sum_{i = 0}^{\min(j,s)}{s \choose i}{p-s \choose i}{s \choose j-i}{q-s \choose j-i}
\end{aligned}
How to lower bound $\frac{f(j+1)}{f(j)}$? That is
\begin{aligned}
   \frac{f(j+1)}{f(j)} \geq \;?
\end{aligned}</p>
",combinatorics
"<p>I was partitioning jigsaw puzzle pieces with some friends yesterday and we noticed that there are 6 types of pieces:</p>

<ol>
<li>All 4 sides have a knobby bit sticking out</li>
<li>1 side has a knobby bit sticking out</li>
<li>2 adjacent sides have knobby bits</li>
<li>2 opposite sides have knobby bits</li>
<li>3 sides have knobs</li>
<li>0 sides have knobs -- they're all concave</li>
</ol>

<p>With a hypothetical 3-D puzzle with cubic pieces and each face being either concave or convex (or male/female), I think there are 10 types of pieces. With 1-D pieces there are 3 types (both ends concave, both ends convex, or mixed).</p>

<p>The question: How many types of jigsaw pieces in n dimensions?</p>

<p>Said another way, how many distinct hypercubes are there if each face can be one of two types, up to rotation?</p>

<p>Conjecture: $\dfrac{(n+1)(n+2)}2$ (the triangular numbers)</p>
",combinatorics
"<p>Using Euler's formula ($V-E+F = 2$ where $V$, $E$ and $F$ are the number of vertices, edges and faces), we can easily count the number of edges in maximal graphs that are embeddable in plane: 3n-6. I have a similar question but for CW-complexes that are realizable in $R^3$ (let us call them spacial complexes). 
For spacial complexes, Euler's formula dictates $V-E+F-C = 0$ where $C$ is the number of 3-D cells. I can also see that, for spacial complexes to be maximal (by adding faces until if we add any other face in it then can not be embedded in $R^3$), they should be tetrahedralized. 
For each cell (tetrahedron) we have 4 faces and for each face we have 2 cells, therefore $4C = 2F$. That is, the number of cells is half the number of faces but still I do not know how to find the maximum number of edges as a function of the number of vertices.</p>
",combinatorics
"<p>We can easily test the commutativity of a binary operation on a set of  $\ n\in\mathbb{N}\ $ elements by observing the symmetry of the $\ n\times n\ $ multiplication table.</p>

<p>I was looking for a similar test for the associativity  of a binary operation. Since it should work on ""triples"", I don't expect to find anything in a square table.</p>

<p>I tried with a $\ n\times n\times n\ $ table, only in the case of binary operations on a set of two elements (I can only use a pencil), and it turned out that there are cubic tables for associative operations equal to cubic tables for non-associative operations.</p>

<p>So, do you happen to know a ""model"" to represent a binary operation from which it is clearly visible the associativity of the operation? Thanks!</p>
",combinatorics
"<p>I recently proved an inequality relating some of the eigenvalues of a regular graph with each other, and I was wondering if it is already known. I was unable to find it online, and a quick skim through Spectra Of Graphs by Brouwer and Haemers did not locate it. The inequality is as follows:</p>

<p>Let $G$ be a connected $k$-regular graph on $n$ vertices which is not complete. Let $\theta$ be the second largest eigenvalue of (the adjacency matrix of) $G$, and let $\tau$ be its minimum eigenvalue. Then,
$$\theta \ge \frac{k(n+\tau-k)}{\tau - n\tau - k}$$
with equality if and only if $G$ is strongly regular.</p>

<p>I came upon the inequality in a very roundabout way, but then found a quite simple proof, so I thought it may already be known. It is probably not a very useful inequality since it only relates eigenvalues to each other and not to any other parameters of the graph. Perhaps this is why it is hard to find online if it is indeed already known.</p>
",combinatorics
"<p>I would like to know whether the problem described below has appeared in the literature and/or whether similar questions have been studied. I would be very happy to find some references or, if none exist, other people that might enjoy thinking about these questions.</p>

<p>Fix a finite abelian group $G$. The <em>Davenport constant</em> $D(G)$ is the smallest integer $m$ such that for any sequence $g_1, \ldots, g_m$ of elements of $G$ (repetitions allowed), there is some non-empty subsequence with sum zero, that is $\exists  J \subseteq [m]$ with $J \neq \emptyset$ and $\sum_{j \in J} g_j = 0$.</p>

<p>There is a very neat folklore proof showing that $D(G) \leq |G|$: given any sequence of $|G|$ elements, let $s_k$ denote the sum of the first $k$ entries of the sequence. If one of the $s_k$ is zero, we are done. Otherwise by the pigeon-hole principle, two of them are equal, say $s_i = s_j$ for $i &lt; j$. But then $J = (i+1, \ldots, j)$ does it.</p>

<p>For cyclic groups, this bound is easily seen to be tight. In the general case, the situation is much more difficult and the determination of $D(G)$ is still an open problem. What I want to get at is the following: The proof above shows more than just the existence of <em>any</em> subsequence with sum zero, it tells us that we can find one among a much smaller collection of candidates, namely all the subsequences of consecutive elements! Quantitatively, this narrows the exponential-size collection of all subsequences down to one of quadratic size (wrt $|G|$ in both cases).</p>

<p>Taking a small step of abstraction, let's call a hyper-graph (a collection of non-empty subsets of some finite set $V$) $G$-zero if for every labelling $f$ of its vertices with the elements of $G$ (repetitions allowed), there is some hyper-edge $e$ such that $\sum_{v \in e} f(v) = 0$. By definition, the hyper graph of all non-empty subsets of $V$ is $G$-zero if and only if $|V| \geq D(G)$. By the proof above, the hyper graph of all subpaths of a path on $n$ vertices is $G$-zero for $n \geq |G|$ (it is not hard to show that this is also necessary). The Erdos-Ginzburg-Ziv Theorem asserts that the hyper graph of all $n$-element subsets is $\mathbb{Z} / n\mathbb{Z}$-zero if $|V| \geq 2n-1$.</p>

<p>The question I am asking is: Given $G$ and $n \geq D(G)$, what is the minimum number $m_G(n)$ of edges in a $G$-zero hyper graph with $n$ vertices? How does this quantity behave as a function of $n$? What are the extremal hyper graphs?</p>

<p><strong>EDIT:</strong> Maybe I should add some more detail. </p>

<p>(1) <em>What to aim for</em>: Since determining $D(G)$ is in general very hard, a complete solution might be out of reach (although it is conceivable that minimising this parameter is much easier). But solving it for some restricted classes of groups might be possible; for example for cyclic groups of prime order there is quite a lot of algebraic machinery that might help.</p>

<p>(2) <em>Some easy observations</em>: The argument presented above shows that there is a $G$-zero hyper graph on $\binom{|G|+1}{2}$ edges. For a lower bound on $m_G(n)$, let $H$ be a $G$-zero hyper graph on $n$ vertices. Just as with vertex-colorings of graphs, it is easy to show that $H$ must have a sub-hypergraph with minimum-degree at least $|G|$. Unfortunately, the edges might be very large and so double-counting only gives us
$$
|E(H)| \geq |G| + \frac{1}{n-1}(|G|-1).
$$
Hence roughly speaking, $m_G(n)$ always lies somewhere between $|G|$ and $|G|^2$. In the case of $G = (\mathbb{Z}/2\mathbb{Z})^m$, the complete hyper graph on $D(G) = m+1$ vertices is a surprisingly good candidate with only $2|G| - 1$ edges, almost matching the lower bound. For cyclic groups, on the other hand, this hyper graph is quite terrible.</p>
",combinatorics
"<p>Apologies for the length question. Those acquainted with the analytics industry will know that the next big thing in the information technology world will be the Big Data revolution where huge volumes of data will be processed. Big Data revolution will imply huge requirement of storage space/memory hence it is critical to store data as efficiently as possible. We want to store data in the smartest way that requires the least amount of storage. The following question is on the application of mathematical ideas to reduce the amount of storage memory required to store information of a particular kind.</p>

<p><strong>Problem</strong>: This is a consumer information storage problem. There are $k$ customers and $n$ books. Each customer can buy one or more books (<strong>without repetition</strong>). We want to identify the book purchased by a given customer using the minimum number of memory required for storage. <em>We do not seek to improve the time complexity, we only seek to reduce storage space required</em>.</p>

<p><strong>Method 1 - Traditional approach</strong>: This is the common and default approach. Give each book a $d$ digit code and create a field in the data base where the code of the books purchased by the customer in entered, separated by commas. So in the worst case when a customer has brought all $n$ books, we will need $D = nd+d-1$ characters to store this information (including $d-1$ commas) about the customer. </p>

<p><strong>Method 2. Using prime numbers</strong>: Assign a unique prime number to each of the books, 2 denotes the first book, 3 the second, $\ldots$ and $p_n$ denotes the $n$-th. Every customer $C_i$ assigned a number $N_i$ which is equal to the product of the prime numbers corresponding to books purchased. By factoring $N_i$, unique factorization theorem ensures that we can identify the exactly the books purchased by the customer. More over two customers will have a common book if and only if they have a common factor. The greater the number of common factors, the greater is the similarity between the customers. This this method in principle carries more business information. Let us do the heuristics for the number of characters needed. In the worst case when the customer $C_i$ has purchased all the $n$ books,
$$
N_i = p_1 p_2 \ldots p_n &lt; p_n^n.
$$
(<em>This inequality can be strengthened using the estimates of the Chevyshev function of the first kind but right now, that is not the objective as I only want to demonstrate the underlying idea</em>). Hence the number of characters required is
$$
D_i = \log_{10} N_i &lt; n\log_{10}p_n &lt; nd + d - 1
$$</p>

<p>for $p_n &lt; 10^d$ which is a safe assumption since most of the UPC code numbers given to products sold in the market have multiple digits. Hence with a small number of books say $&lt;100$ we expect method 2 to use lesser number of character (hence memory) to store the same information. For example if I have 10 books them to store the information about a customer who purchased all the 10 books, method one with a 2 digit code for each book will require 21 characters where as method 2 will require only 10 characters. Unfortunately when there are a large number of books, the products of primes grows very fast and we may end up requiring more memory space than in method 1. Hence this method is not scale-able.</p>

<p><strong>Method 3</strong>: We can do better than method 2. Let the $k$-th book be given the number $2^{k}$. Every time a customer buys a unique book, we add its corresponding number. Since a number can be decomposed as the sum of non-repeating powers of two in only one way, we can identify the exact books purchased by the customer $C_i$ by decomposing his/her total sum $S_i$. For example if the sum of the book numbers for a customer is 154, since $154=2^7 + 2^4 + 2^3 + 2^1$, we know that the customer has purchased the first, third, fourth and the seventh book. So instead of storing the code of these four books or the product of three primes, I can just store the three digit number 154 which will give me the same information. In the worst case when the customer has purchased all the n books,</p>

<p>$$
S_i = 2^1 + 2^2 +\ldots + 2^n = 2^{n+1} - 2
$$</p>

<p>$$
D_i &lt; \log_{10}(2^{n+1}-2) &lt; n\log_{10}2 + 1
$$</p>

<p>Thus with method 3, we can store the same information using the least number of characters thus far. Also two customers will have a book in common if and only if the decomposition of their sum contains an identical power of 2.</p>

<p><strong>Questions</strong>: Is there are better method of identifying the books uniquely using less than $n\log_{10}2$ characters? I think that if there is indeed a better method, it could possible be using some of the property of integers.</p>
",combinatorics
"<p>in the paper ""expander graphs with applications"" an intriguing problem was posed 
Fix an integer $d ≥ 3$ and consider large random $(n, d)$-graphs.  What can be said about the distribution of the coordinates of $v_2$? Specifically, does $v_2$ tend to be uniformly distributed on the unit sphere (in which the
distribution of these coordinates is nearly normal)?</p>

<p>Does anyone know some advances on this problem?</p>
",combinatorics
"<p>Is there any closed formula for 
$$
\sum_{k=0}^n\frac{\binom{2k}{k}^2}{2^{4k}}
$$
?
This sum of is made out of the square of terms $a_{k}:=\frac{\binom{2k}{k}}{2^{2k}}$ </p>

<p>I have been trying to verify that $$
\lim_{n\to\infty} (2n+1)\left[\frac{\pi}{4}-\sum_{k=0}^{n-1}\frac{\left(\sum_{j=0}^k a^2_{j}\right)}{(2k+1)(2k+2)}\right] -\frac{1}{2}{\sum_{k=0}^na^2_{k}}=\frac{1}{2\pi},
$$
which seems to be true numerically using Mathematica.</p>

<p>The question above is equivalent to finding some formula for $$b_{n}:=\frac{1}{2^{2n}}\sum_{j=0}^n\frac{\binom{2n+1}{j}}{2n+1-j}.$$ This is because one can verify that 
$$(2n+1)b_n=2nb_{n-1}+a_n,\qquad a_{n+1}=\frac{2n+1}{2n+2}a_n,$$
and combining these two we get
$$(2n+2)a_{n+1}b_{n}-(2n)a_nb_{n-1}=a_n^2$$
Summing we get
$$\sum_{k=0}^na_k^2=(2n+1)a_nb_n.$$</p>

<p>I also know that 
$$
\frac{\binom{2n}{n}}{2^{2n}}=\binom{-1/2}{n},
$$
so that
$$
\sum_{k=0}^{\infty}\frac{\binom{2k}{k}}{2^{2k}}x^k=(1-x)^{-1/2},\quad |x|&lt;1.
$$
I have also seen the identity
$$
\sum_{k=0}^n\frac{\binom{2k}{k}}{2^{2k}}=\frac{2n+1}{2^{2n}}\binom{2n}{n}.
$$</p>
",combinatorics
"<p>Let $X$ be an infinite set, and let $G$ be the symmetric group on $X$.  I want to understand $G$ by putting a topology on it, without imposing any more structure on $X$.  What 'interesting' possibilities are there and what is known about them?</p>

<p>In particular, I have heard of the pointwise convergence topology (an open neighbourhood of g is a set of permutations that agree on some specified finite set of points), and found some papers on this, but are there any other topologies that have been studied?</p>

<p>What if I take the coarsest topology compatible with the group operations such that either a) the stabiliser of any subset is closed, b) the stabiliser of any partition is closed, or c) both are closed?  I think these will be coarser than the pointwise convergence topology, because in the pointwise convergence topology the stabiliser of any first-order structure is closed.  Is there a useful characterisation of the open subgroups and/or closed subgroups?</p>
",combinatorics
"<p>Maximal Biclique: A complete bipartite subgraph, that isn't a subgraph of another complete bipartite subgraph.</p>

<p>Given a bipartite graph $G=(V_{1}\cup V_{2}, E)$ where $|V_{1}|=|V_{2}|$ with probability $p$ of there being an edge from any $a\in V_{1}$ to any $b\in V_{2}$, what is the expected number of maximal bicliques?</p>

<p>What I have worked out is the upper and lower bounds:</p>

<p>Lower Bound: 1 or 2. If $|E|$ is divisible by $n$, then $\frac{|E|}{n}$ nodes can be connected to completely to $\frac{|E|}{n}$ other nodes, making one maximal biclique. Otherwise, connect $\frac{|E|}{n}$ nodes completely to $\frac{|E|}{n}$ nodes and connect one node to $|E|(mod\ n)$ nodes. </p>

<p>Upper Bound: There are $2^n$ unique subsets, the empty set and the entire set not included, leaves $2^n-2$ subsets. Therefore, there can be at most $2^n-2$ maximal bicliques. This upper bound is achievable when there are $n^2-n$ edges (I can prove this if anyone wants me to).</p>

<p>Both of these results are also easily extended to bipartite graphs where $|V_{1}|\neq |V_{2}|$.</p>

<p>The upper and lower bounds are both fairly trivial for the most part and it's the expected number of maximal bicliques that I've had the most trouble with. I've done a little work analyzing simple cases and brute forcing the expected number for small values of $n$ (I suppose I could write a program to brute force larger values of $n$), but it hasn't amounted to anything worth saying.</p>

<p>I'd appreciate any suggestions for methods of attacking the problem or references that I might find useful.  </p>
",combinatorics
"<p>Let $T_G(x,y)$ denote the Tutte polynomial of a graph. Of course we may have $T_G(x,y) = T_H(x,y)$ for $G$ and $H$ non-isomorphic graphs.</p>

<p>Now let $c(G)$ denote the <em>cone graph</em> of $G$, i.e., the graph obtained from $G$ by adding a new vertex connected by an edge to every vertex of the original graph $G$. Let $c^{n}(G)$ denote the graph obtained by coning over $G$ $n$ times.</p>

<p>Note that we can have $T_G(x,y) = T_H(x,y)$ but $T_{c(G)}(x,y) \neq T_{c(H)}(x,y)$. For instance, take $G = K_{1,3}$ the star with three edges, and $H = P_3$ the path with three edges. Then $T_G(x,y) = T_H(x,y)$ because all trees on the same number of edges have the same Tutte polynomial, but $T_{c(G)}(x,y) \neq T_{c(H)}(x,y)$ because for instance $c(G)$ has $20$ spanning trees and $c(H)$ has $21$ spanning trees (and the number of spanning trees of any connected graph is the Tutte polynomial evaluated at $(1,1)$.)</p>

<p><strong>Question</strong>: Is it the case that if $G$ and $H$ are non-isomorphic graphs then $T_{c^n(G)}(x,y) \neq T_{c^n(H)}(x,y)$ for some $n$? If so, are there some effective bounds on this $n$?</p>
",combinatorics
"<p>Let $L$ be a (non-restricted) Lie algebra over a field of prime characteristic $p,$ $UL$ be its universal enveloping algebra and $a_1,\dots, a_p \in L$ (the number of elements is equal to the characteristic). I can prove that the element $\sum_{\sigma \in S_p} a_{\sigma(1)}\cdot{}\dots{}\cdot a_{\sigma(p)}$ of $UL$ lies in $L.$ But I want to have an evident formula for this element on the language of commutators. </p>

<p><strong>Question:</strong> Is it true that 
$$\sum_{\sigma \in S_p} a_{\sigma(1)}\cdot{}\dots{}\cdot a_{\sigma(p)}  = \sum_{\sigma\in S_p\ :\  \sigma(1)=1} [a_{1},a_{\sigma(2)},\dots,a_{\sigma(p)}]$$
?</p>

<p>Here $S_p$ denotes the symmetric group and $[x_1,\dots,x_n]=[[x_1,\dots,x_{n-1}],x_n].$ I can prove this formula for $p=2,3.$</p>

<hr>

<p><strong>Answer:</strong> Yes, it is true. This formula can be found here: 
<a href=""http://msp.org/agt/2006/6-5/agt-v6-n5-p08-p.pdf"" rel=""nofollow"">http://msp.org/agt/2006/6-5/agt-v6-n5-p08-p.pdf</a>
on page 2252, line 6 (without prove). Jie Wu explained me a prove. </p>
",combinatorics
"<p>The following problem is somehow hidden in <a href=""http://mathoverflow.net/questions/204020/is-the-set-aaa-always-at-least-as-large-as-aa"">this recently asked question</a>, but I believe that it deserves to be asked explicitly.</p>

<blockquote>
  <p>Is it true that for any finite set $A$ of real numbers, and any real $\lambda\notin\{0,-1\}$, one has
    $$ |A+\lambda A| \ge |A+A| $$
  (where $\lambda A=\{\lambda a\colon a\in A\}$ is the dilate of $A$ by the factor $\lambda$, and $A+B=\{a+b\colon a\in A,\ b\in B\}$ is the sumset of $A$ and $B$)?</p>
</blockquote>

<p>The energy version seems equally interesting to me. Let $T_A(\lambda)$ denote the number of representations of $\lambda$ in the form $\frac{a_1-a_2}{a_3-a_4}$ with $a_1,a_2,a_3,a_4\in A$. It is easily seen that $T_A(-\lambda)=T_A(\lambda)$ and $T_A(\lambda)&lt;T_A(0)=|A|^2(|A|-1)$ for any real $\lambda\ne 0$.</p>

<blockquote>
  <p>Is it true that for any finite set $A$ of real numbers, and any real $\lambda\ne 0$, one has
    $$ T_A(\lambda) \le T_A(1) ? $$</p>
</blockquote>

<p>I have not done any computations, so maybe it is possible to find a counterexample just by a computer search.</p>

<hr>

<p>Both questions have now received nice and exhaustive answers thanks to Boris Bukh, Kevin Costello, and Terry Tao (who has actually answered even before the question got asked). Unfortunately, I cannot accept more than one answer; so, I am accepting only that which, for some reason, got less votes.</p>
",combinatorics
"<p>It is a classical theorem. For given integer $n \ge 1$, among ${n\choose{n/2}} = 2^{(1-o(1)n)}$ strings in the cube $\{0, 1\}^n$ with weights $n/2$, i.e., $n/2$ indices are 1, there are at least $2^{cn}$ of these strings such that each pair has Hamming distance at least $n/4$, where $c$ is a constant between $0$ and 1.</p>

<p>This is for sure a known result. I hope to be aware of its name.</p>
",combinatorics
"<p>I am interested in counting the following.  How many words using $n-1$ copies of $u$ and ${n \choose 2} - n+1$ copies of $d$ begin with $uu$ and, in general, the $k^{th}$ $u$ is among the first ${k \choose 2} + 1$ letters in the word?</p>

<p>This is a generalization of a Dyck path.  I need to start at the origin, end at $(n-1,2(n-1)-{n \choose 2})$, and always stay above the corresponding curve.</p>

<p>I'm looking for a reference or an argument that gives a formula analogous to the Catalan numbers.  I can write down the answer as a messy sum.</p>

<p>Thanks!</p>
",combinatorics
"<p>I asked this question on <a href=""http://math.stackexchange.com/questions/1772398/union-closed-family-generated-by-n-2-sets"">Stackexchange</a>, but I got no answer, so I ask it here.</p>

<p>Let us define a $2$-set as a set with exactly $2$ elements. For a natural number $n$, let $l(n)$ denote the least possible number of members of a union-closed family of sets generated by $n$ distinct $2$-sets. I'm interested in a useful formula or minoration for $l(n)$.</p>

<p>There are easy majorations, for example $l({r\choose 2}) \leq 2^{r} - 1 - r$ and (for $r \geq 1$) $l({r\choose 2}+1) \leq 2^{r} + 2^{r-1} - 1 - r$, and these upper bounds seem to be exact values for small values of $r$, but I would avoid the task of handling this question if there is literature about it. Do you know ? Thanks in advance.</p>

<p>Note : there is a similar question here :
<a href=""http://mathoverflow.net/questions/75585/kruskal-katona-type-question-for-union-closed-families-of-sets"">Kruskal-Katona type question for union-closed families of sets</a></p>

<p>but not identical.</p>
",combinatorics
"<p>I'll use another way to give the question besides the title.</p>

<p>Define
$$ A_k(n) = \frac{1}{2 \pi \mathrm{i}} \int_{|q|=1} \left( \frac{1}{2 \pi \mathrm{i}}\int_{|z|=1}\prod_{j=-n}^{n}(1+qz^j) \frac{dz}{z} \right) \frac{1}{q^k} \frac{dq}{q}.$$</p>

<p>By some numeral calculation buy a simple program, I note that if we freeze $k$, then $A_k(n)$ always satisfies a linear recurrence relations.</p>

<p>How to make a proof? Or anyone could give a counterexample? (A ""appropriate"" counterexample may be a sequence $A_l(1), A_l(2), \cdots, A_l(m)$ for large enough $m$.)</p>

<p>Thanks for reading my problem. : )</p>
",combinatorics
"<p>Let $ c_{n,k} $ be the Simsun permutations$^1$ defined by the following relations: $\displaystyle c_{n,0} = 1, \hspace{0.1cm} (n \ge 1);$ 
$$ c_{n,k} = (k+1) c_{n-1,k} +(n-2k+1) c_{n-1,k-1}, \hspace{0.5cm} (1 \leq k \leq \lfloor n/2 \rfloor);$$
and $ c_{n,k} = 0, \hspace{0.1cm} ( k&gt; \lfloor n/2 \rfloor). $</p>

<p>Now, let $n=2p.$ I am trying to find the value of 
\begin{eqnarray}
A_p:=\sum_{k=0}^{p} c_{2p,k} \hspace{0.1cm} \frac{(2p-2k)!}{2^{p-k} (p-k)!}.
\end{eqnarray}
or at least a sharp upper bound for it. We know$^2$ that $$ \sum_{k=0}^{p} c_{2p,k} \hspace{0.1cm} 2^{2p-k} = (2p+1)!.$$</p>

<p>From this identity we can easily obtain the bound $$  A_p \leq 2^{-p} p!(2p+1)! $$ for $ A_p $ which is a big upper bound.</p>

<p>Additionally, we know$^2$ that $ \sum_{k=0}^{p} c_{2p,k} = T_{p+1}$, where $  T_n= \frac{2^{2n}(2^{2n}-1) |B_{2n}|}{2n} $ is the sequence of tangent numbers$^3$ (defined by the Bernoulli numbers $B_n$), appearing in the Taylor series expansion of tan($x$): $$\text{tan}(x)=\sum_{n=1}^{\infty} T_n \frac{x^{2n-1}}{(2n-1)!}.$$</p>

<p>Motivation: In a part of my research (in quantum statistical mechanics) I need to show convergence of a series. I have reduced the initial problem to finding the value of $ A_p $, or at least a good upper bound for $ A_p $.</p>

<p>Any hint or idea would be greatly appreciated! Thanks in advance!</p>

<ol>
<li>For Andre and Simsun permutations see <a href=""http://oeis.org/A094503"" rel=""nofollow"">here</a> and <a href=""http://oeis.org/A113897"" rel=""nofollow"">here</a>.</li>
<li>See <a href=""https://www.google.ca/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=increasing%20trees%20and%20alternating%20permutations%20Kuznetsov."" rel=""nofollow"">here</a> for the paper ""increasing trees and alternating permutations"" by G. Kuztensov, I. Pak, and A.E. Postnikov. In this paper, the Andre permutations are denoted by $ d_{n,k} $.</li>
<li>See <a href=""http://oeis.org/A000182"" rel=""nofollow"">here</a>.</li>
</ol>
",combinatorics
"<p>Let $\mathcal{A}$ be an uncountable almost disjoint family (not necessarily maximal) of infinite subsets of $\mathbb{N}$. Denote by $\mathcal{A}_{\subseteq}=\{ B\subseteq\mathbb{N}:|B|=\omega \wedge \exists A\in\mathcal{A}(B\subseteq A) \}$.</p>

<p>Question 1: Must there exist a $B\in\mathcal{A}_{\subseteq}$ such that for any $n$, $\{C\in\mathcal{A}:|C\cap B|\geq n\}$ is uncountable?</p>

<p>If this is true, then:</p>

<p>Question 1':  Must there exist a $B\in\mathcal{A}_{\subseteq}$ such that for any $n$, $\{C\in\mathcal{A}:B\upharpoonright n\subset C\}$ is uncountable? (By $B\upharpoonright n$, I mean the first $n$ elements of $B$ listed in increasing order.)</p>

<p>I don't have an intuition as to whether this should be true or false, but the question stems from the observation that for any uncountable family $\mathcal{A}$ of subsets of $\mathbb{N}$, there is an $n\in\mathbb{N}$ such that $\{A\in\mathcal{A}:n\in A\}$ is uncountable.</p>

<p>EDIT: As seen in the solutions below, the passage to $\mathcal{A}_{\subseteq}$ is unnecessary.</p>

<p>EDIT: In light of the positive answer to the questions above, I'll add an additional question that I am interested in.</p>

<p>Question 2: Must there be a <em>sequence</em> $(A_n)_{n\in\omega}$ of distinct elements of $\mathcal{A}$ (or elements of $\mathcal{A}_{\subseteq}$ which are below pairwise distinct elements of $\mathcal{A}$) such that for any $n$, $\{B\in\mathcal{A}:\forall i\leq n(A_i\upharpoonright n\subset B)\}$ (or $\{B\in\mathcal{A}:\forall i\leq n(A_i\upharpoonright n-i\subset B)\}$) is uncountable. (Again, $A \upharpoonright n$ means the first $n$ elements of $A$ listed in increasing order, it does <em>not</em> mean the elements of $A$ below $n$ here.)</p>
",combinatorics
"<p>first the relevant definitions:</p>

<p>A complex $\Delta \subset 2^{[n]}$ is a family of subsets of $[n]$ that is closed downwards, i.e. if $A \subset B$ and $B \in \Delta$, then $A \in \Delta$.</p>

<p>A complex is shifted if for any $A \in \Delta$, if we replace $i \in A$ with some $j \notin A$, such that $j &lt; i$, then the set is still in the complex.</p>

<p>A complex is a threshold complex if there are some non-negative weights $w_1,\ldots,w_n,c$ such that $A \in \Delta \iff \sum_{i\in A} b_i \leq c$. Note that if the weights are in increasing order, this will be a shifted complex.</p>

<p>A facet of a complex is a member $A \in \Delta$ such that no supersets of $A$ are in $\Delta$.</p>

<p>Also given $B$ we define $\bar{B}$ as the family of subsets of $B$(including B).</p>

<p>A shelling of a complex $\Delta$ is an ordering $F_1,F_2,\ldots$ of the facets of $\Delta$, such that $\left(\cup_{i=1}^{k-1} \bar{F_i}\right) \cap \bar{F_k}$ is a complex in which all facets have size $|F_k|-1$.</p>

<p>It is known that shifted complexes(and in particular threshold complexes) have shellings, one of which is given by the reverse lexicographical ordering of the facets. Let's say that a particular shelling gives the decomposition
$ \Delta = \cup_{i=0}^t \bar{F_i}$, and I define the partial shelling $\Delta_k = \cup_{i=0}^k \bar{F_i}$ for $k=1,\ldots, t$. Can we find a shelling that makes $\Delta_k$ shifted(threshold)?</p>
",combinatorics
"<p>Let $n$ be a positive integer and partition a grid of $4n$ by $4n$ unit squares into $4n^2$ squares of sidelength $2$. (The squares with sidelength $2$ have all of their sides on the gridlines of the $4n$ by $4n$ grid.) What's the minimum number of unit squares that can be shaded such that every square of sidelength $2$ has at least one shaded square, and there exists a path between any two shaded squares going from shaded squares to adjacent shaded squares? (Two squares are adjacent of they share a side.)</p>

<p>I think the answer is $6n^2-2$. I got it by partitioning the $4n$ by $4n$ unit squares into $n^2$ squares of sidelength $4$, shading in the four center unit squares of each sidelength $4$ square (so that every square with sidelength $2$ has at least one shaded square), and connecting the shaded squares to another. There are $4n^2$ center unit squares, and a connection between any two groups of center squares requires two squares. There are $n^2$ groups of center squares, so for the shaded squares to be connected, we need at least $n^2-1$ connections. (Similar to how a connected graph on $n$ vertices needs at least $n-1$ edges.) Each connection is two squares, so we need to shade an additional $2(n^2-1)$ squares. Adding this to $4n^2$ gives $6n^2-2$.</p>

<p>This is by no means a proof. There are of course valid configurations in which some square with sidelength $4$ does not have the center $4$ squares shaded in. Could someone help me prove that $6n^2-2$ is the minimum? Thanks.</p>
",combinatorics
"<p>Suppose we have an undirected graph with integer valued nodes where $0&lt;|i-j|\le 2$ implies nodes $i$ and $j$ are connected. Let $c_n$ be the number of self-avoiding walks on this graph of length $n$ starting at origin. Define the connective constant as</p>

<p>$$\mu = \lim_{n\to \infty} c_n^{\frac{1}{n}}$$</p>

<p>What is known about $\mu$? This quantity seems to be related to the transition temperature of an Ising model on such graph, has such model been studied?</p>
",combinatorics
"<p>Suppose there are $L$ types of coupons, the probabilities that they appear are $a_1,a_2,\ldots,a_L$ respectively, $\sum_i^La_i=1$. Each of them is associated with a constrain number $d_i,i=1,\ldots,L$. We assume that $d_1\leq d_2\leq\ldots\leq d_L$. We require that, when collecting coupons, only the first $d_i$ coupons of type $i$ collected are considered <em>valid</em>. For example, the $(d_i-1)$th, $d_i$th collected coupons of type $i$ are both valid, but the $(d_i+1)$th collected coupon of type $i$ is invalid, invalid coupons are just discarded.</p>

<p>We stop after $M$ coupons when we have collected $N$ valid coupons of all types, $d_L\leq N\leq \sum_i^Ld_i$. Then the question is, what is the expected number of trials we need to do, i.e. $\mathrm{E}[M]$?</p>

<p>Hope I have make it clear. Any comments, suggestions, or references are highly appreciated. Thanks sincerely.</p>
",combinatorics
"<p>Let us consider the matrix $A$ with its rows and columns enumerated by the elements of $S_n$ with $A_{\sigma\tau}=x^{c(\sigma\tau^{-1})}$ where $c()$ is the number of cycles in a permutation's decomposition. I'm interested in $|A|$. More specifically I aim to prove that all of its roots as of a polynomial in $x$ are integers between $-n+1$ and $n-1$ but the roots' multiplicities would also be nice to know.</p>
",combinatorics
"<p>Let $w_1$ and $w_2$ be two permutations of $\{1, \cdots , k\}$ such that for all $1\leq i \leq k$, $w_1(i)\neq w_2(i)$. Let $m$ and $n$ be two relatively prime integers. Then is there exist two diagonal matrices $D_1, D_2 \in M_k(\mathbb{Z})$, with $\gcd(\text{det}D_1, n)=1$, $\gcd(\text{det}D_2, m)=1$ such that $\text{det}\big(D_1m(w_1I) + D_2n(w_2I)\big)=1$.</p>

<p>Here $\text{det}$ stands for determinant and $I$ is a $k\times k$ identity matrix.
$w_iI$ is the permutation matrix corresponding to $w_i$.</p>
",combinatorics
"<p>$\newcommand{\lm}{\lambda}$ $\newcommand{\bR}{\mathbb{R}}$ Let $m$ be  an integer $&gt;1$. Define</p>

<p>$$ I_m:\bR^m\to  \bR,\;\; I_m(\lm_1,\dotsc, \lm_m)=\int_{S^{m-1}}\exp\Bigl(-\sum_{j=1}^m \lm_j^2x_j^2\;\Bigr)\; |dA(x)|,  $$</p>

<p>where $S^{m-1}$ is the unit sphere in $\bR^m$  and $|dA(x)|$ denotes the  ""area"" element on $S^{m-1}$.</p>

<p>The function $I_m$  is real analytic  and symmetric in  the variables $\lm_1^2,\dotsc, \lm_m^2$ and in fact  it has a Taylor expansion</p>

<p>$$I_m (\lm_1,\dotsc, \lm_m)=2\sum_{h=0}^\infty\frac{(-1)^h}{\Gamma(\frac{m}{2}+h)}\sum_{h_1+\cdots+h_m=h}\frac{\Gamma(h_1+\frac{1}{2})\cdots \Gamma(h_m+\frac{1}{2})}{h_1!\cdots h_m!} \lm_1^{2h_1}\cdots \lm_m^{2h_m}. $$</p>

<p>In particular, $I_m$ can be expressed  as a function of  the  symmetric polynomials</p>

<p>$$s_k =\sum_{j=1}^m \lm_j^{2k},\;\; k=1,\dotsc, m. $$</p>

<p><strong>Question 1.</strong> Is there  a more compact  description   of $I_m$ of the form</p>

<p>$$I_m(\lm_1,\dotsc, \lm_m)=F_m(s_1,\dotsc, s_m), $$</p>

<p>where $F_m$ is some ""<em>classical</em>"" function?</p>

<p><strong>Question 2.</strong> $\DeclareMathOperator{\diag}{Diag}$ $\DeclareMathOperator{\tr}{tr}$ Consider the symmetric  matrix</p>

<p>$$\Lambda=\diag(\lm_1,\dotsc, \lm_m). $$</p>

<p>Is there  some  function $V_m:\bR\to \bR$ such that</p>

<p>$$ I_m(\lm_1,\dotsc, \lm_m)=e^{-\tr V_m(\Lambda)} ? $$</p>

<p>Can one describe such a $V_m$ explicitly? I'm vague about the term explicit, but I would be very pleased if $V_m$ were a  ""special"" function.</p>

<p>The  second question may suggest  the origin of $I_m$.     I stumbled  onto $I_m$ when I bumped into  a certain  ensemble of random real,  symmetric $m\times m$ matrices.  (The story is too bushy to include it here.)  </p>
",combinatorics
"<p>Let us fix a natural number $N&gt;1$ and $a_1, \ldots, a_n$ natural numbers satisfying $0 \leq a_i &lt; N$, with the property that $1+ \sum a_i$ is divisible by $N$. Let $\phi$ be the Euler totient function (defined with the convention $\phi(1)=0$). I define the following quantity:
$$
\psi(a_1, \ldots, a_n; N):= \sum_{i=1}^n \psi_i := \sum_{i=1}^n \phi(\gcd( a_1, \ldots, a_i +1, \ldots, a_n; N)).
$$
I would like to have a closed formula (or an inductive one) for $\psi$ in terms of the initial data (I imagine it should depende on the prime decomposition of $N$).</p>

<p>For example, when $N= p^{\alpha}$ for $p$ a prime number, we have that one of the $a_i$, wlog $a_n$, is coprime with $N$. By defining $p^{\beta}$ to be $\gcd(a_1, \ldots, a_{n-1}, a_n+1, p^{\alpha})$, we have
$$
\psi(a_1, \ldots, a_n; p^{\alpha})= \phi(p^{\beta})=p^{\beta}(1-\frac{1}{p})
$$
when $\beta &gt;0$ and $0$ otherwise.</p>
",combinatorics
"<p>Consider a ""random"" bipartite directed graph where (1) on each side, the set of vertices has cardinality n and (2) for each vertex i, we add one (and only one) directed edge i->j at random (drawn uniformly over the n possible directed edges).</p>

<p>Clearly, for all n, and any possible realization of the random graph, there is at least one cycle. </p>

<p>But what's the expected number of cycles when n tends to infinity? Given k (even), what's the expected number of cycles of size k when n tends to infinity?</p>

<p>I suppose this problem is standard... I would be greatful if one could give me references on this.</p>

<p>Thanks!</p>
",combinatorics
"<p>Let X_n be the ""random Fibonacci sequence,"" defined as follows:</p>

<p>$X_0 = 0, X_1 = 1$;</p>

<p>$X_n = \pm X_{n-1} \pm X_{n-2}$, where the signs are chosen by independent 50/50 coinflips.</p>

<p>It is known that |X_n| almost surely grows exponentially by a (much more general) theorem of Furstenberg and Kesten about random matrix products:  the base of the exponent was determined explicitly by Viswanath to be $1.13\ldots$ </p>

<p>I am not too proud to say that I learned all this from Wikipedia:</p>

<p><a href=""http://en.wikipedia.org/wiki/Random_Fibonacci_sequence"">http://en.wikipedia.org/wiki/Random_Fibonacci_sequence</a></p>

<p>What I did not learn from Wikipedia, or any of the references I gathered therefrom, was:  </p>

<p><strong>Question</strong>: what, if anything, do we know about the probability that X_n = 0, as a function of n? </p>
",combinatorics
"<p>Hello,
    I'd like to find the expected number of Bernoulli trials that I'll need before I will get <em>exactly</em> n more heads than tails, given a coin which gets a heads with probability p. </p>

<p>My approach for this problem has been as follows:
a) The probability of getting n more heads is equal to getting any permutation of N+r-1 heads and r tails, followed by a single head, thus  $\sum_{r=0}^{\infty} p^{n+r}(1-p)^{r}$ ${n+2r-1}\choose{r}$</p>

<p>b) To find the expected number, I'll just have consider $\sum_{r=0}^{\infty} (n+2r) p^{n+r}(1-p)^{r}$ ${n+2r-1}\choose{r}$</p>

<p>c) I need to find the expectation over the trial lengths of $\gamma^{l}$ ($\gamma$ is a constant $&lt;1$), i.e. $\sum_{r=0}^{\infty} \gamma^{n+2r} p^{n+r}(1-p)^{r}$ ${n+2r-1}\choose{r}$</p>

<p>Another way of phrasing the problem (which is the context in which I would like to solve it) is: Suppose you are at a distance n from a goal, and with probability p you move towards it, and 1-p away from it. What is the expected number of steps you will need to reach the goal?</p>

<p>I don't know how to evaluate any of those summations. I only need an approximate answer - as a function of $p$ and $n$. Is there any other way than by using Stirling's formula for the binomial coefficients (which gets quite messy)?</p>
",combinatorics
"<p>Let $A$ be a set of objects where $|A|=n$. We want to count all the possible ways that we can arrange these objects into $n$ bags with exactly $n$ objects in each. We can reuse any object, however, no repetition is allowed inside the bags. </p>

<p>With $A=\{a,b,c\}$, for example, $[(a,b,c), (a,b,c), (b,c,a)]$ is a valid outcome.</p>

<p>Obviously there are $(n!)^n$ ways to do this. </p>

<p>Now we want to add two extra constraints:</p>

<ul>
<li>The order of bags is not important. </li>
</ul>

<p>For example, $[(a,b,c), (a,b,c), (b,c,a)]$ would be identical to $[(b,c,a), (a,b,c), (a,b,c)]$.</p>

<ul>
<li>The label of objects inside the bags do not matter. Only the relative positions are important.</li>
</ul>

<p>For example, $[(a,b,c), (a,b,c), (b,c,a)]$ would be identical to $[(c,b,a), (c,b,a), (b,a,c)]$ and is identical to $[(a,c,b), (a,c,b), (c,b,a)]$ etc.</p>

<p>Questions are:</p>

<ul>
<li>How many ways can we set these bags given the above constrains ?</li>
<li>Is there any algorithm to output all these possible combinations?</li>
</ul>
",combinatorics
"<p>I am looking for a (already-studied or interesting) class of Matroids such that
- Class of Gammoids are contained in it</p>

<p>One example would be Strongly-base-orderable Matroids. I would also be grateful if someone knows a class of Matroids such that</p>

<ul>
<li>Class of Gammoids are contained in it AND</li>
<li>It is contained in the class of ""Strongly-base-orderable"" Matroids.</li>
</ul>

<p>By the way, strongly-base-orderable is a property such that :
GIven any two bases I,J of the Matroid, there exists a bijection \pi between I-J and J-I such that given any subset H of I-J, I- H +\pi(H) and J - \pi(H) + H is a base in the Matroid. (In Oxley's ""Matroid theory"" pp410 )</p>

<p>Motivation :
Well, I have something I can show for Gammoids but cannot for Strongly-base-orderable Matroids, although computational evidence suggests that it holds for general Matroids.</p>
",combinatorics
"<p>The $n$th Catalan number can be written in terms of factorials as 
$$ C_n = {(2n)! \over (n+1)! n!}. $$
We can rewrite this in terms of gamma functions to define the Catalan numbers for complex $z$:
$$ C(z) = {\Gamma(2z+1) \over \Gamma(z+2) \Gamma(z+1)}. $$
This function is analytic except where $2n+1, n+2$, or $n+1$ is a nonpositive integer -- that is, at $n = -1/2, -1, -3/2, -2, \ldots$.</p>

<p>At $z = -2, -3, -4, \ldots$, the numerator of the expression for $C(z)$ has a pole of order 1, but the denominator has a pole of order $2$, so $\lim_{z \to n} C(z) = 0$.  </p>

<p>At $z = -1/2, -3/2, -5/2, \ldots$, the denominator is just some real number and the numerator has a pole of order 1, so $C(z)$ has a pole of order $1$.</p>

<p>But at $z = -1$:
- $\Gamma(2z+1)$ has a pole of order $1$ with residue $1/2$; 
- $\Gamma(z+2) = 1$;
- $\Gamma(z+1)$ has a pole of order $1$ with residue $1$.
Therefore $\lim_{z \to -1} C(z) = 1/2$, so we might say that the $-1$st Catalan number is $-1/2$.</p>

<p>Is there an interpretation of this fact in terms of any of the countless combinatorial objects counted by the Catalan numbers?</p>
",combinatorics
"<p>The following problem cropped up whilst considering generalised quadrangles with a product structure, and it boils down to a simple number theoretic problem. Let $s$ be an integer greater than 2 and suppose the geometric series $(s^r-1)/(s-1)$ is a nontrivial power of a positive integer. It seems the following is true:</p>

<p>If $r=3$, then $s= 18$.<br>
If $r=4$, then $s = 7$.<br>
If $r=5$, then $s = 3$.<br>
If $r&gt;5$, there are no solutions.</p>

<p>Does anyone know a proof of this curious property?</p>
",combinatorics
"<p>In the middle of page 9 of 
<a href=""http://arxiv.org/PS_cache/arxiv/pdf/1011/1011.4105v1.pdf"" rel=""nofollow"">http://arxiv.org/PS_cache/arxiv/pdf/1011/1011.4105v1.pdf</a>.</p>

<p>They said "" Now we select a random subset....choosing lines independently with
probability $\frac{Q}{100}$.  With positive probability....</p>

<p>I can not see why there is positive probability...</p>

<p>Could any one explain a bit about what is going on there? I feel they are applying large
number law, but I can not see it clearly, for example what is the probability measure space,
what is the random variables, how the law is used?..</p>
",combinatorics
"<p>Suppose we have a graph G. Is it true that we can map its vertices to the plane such that when connecting neighboring vertices with segments, then any induced cycle of G that has length at least 4 will have two edges that intersect?</p>

<p>What if I want each induced cycle of length at least 4 to be in a non-convex position? (If we write a bigger number instead of 4, then this would be some kind of strengthening of the theorem of Erdos-Szekeres.)</p>

<p>What if I want k induced cycles that do not intersect (any other or themselves)?</p>

<p>I suspect that the answer to all these questions is negative, i.e. there is a graph that we cannot linearly map with ruining all its induced cycles. I would also be very interested in any related results.</p>

<p>*<strong>Update March 19.</strong> I realized that I can show that there is a dense graph whose embedding will have an induced $C_4$ in convex position (whose edges might intersect). For a proof sketch, see my answer.</p>

<p>*<strong>Update April 3.</strong> Now I realized that if the graph is sparse in the sense that its degeneracy is constant, then its chromatic number is also constant, in which case we can put the vertices that belong to the same color class close to each other, which would mean that it is not possible to have too many disjoint cycles. So a graph with a linear number of edges has a drawing with at most a constant number of disjoint cycles.</p>

<p>*<strong>Remaining Question.</strong> Is there a method that guarantees non-crossing cycle(s) and does not use a counting argument but rather some topology?</p>
",combinatorics
"<p>We have a flat family of projective varieties with a torus $T$ action, over $\mathbb{A}^1$. </p>

<p>How do the moment map images of the fibers change when we pass from the generic fiber to the special fiber at $0$? </p>

<p>In particular, how should the moment map images of the one-dimensional $T-$orbits change?</p>

<p>Any suitable references? Thanks!</p>
",combinatorics
"<p>Given a partition &lambda; = (&lambda;<sub>1</sub>, &lambda;<sub>2</sub>, ..., &lambda;<sub>n</sub>) denote with s<sub>&lambda;</sub> the associated Schur function.
There exists a nice product formula for the principal specializations:
<p>s<sub>&lambda;</sub>(1, q, q<sup>2</sup>, ..., q<sup>n-1</sup>) = &Pi;<sub>i&lt;j</sub> (q<sup>&lambda;<sub>i</sub>+n-i</sup> - q<sup>&lambda;<sub>j</sub>+n-j</sup>) / (q<sup>j-1</sup> - q<sup>i-1</sup>).
<p>Is a similar evaluation known for specializations of the type s<sub>&lambda;</sub>(1, 2, ..., n)?</p>
",combinatorics
"<p>That's very poor wording, so let me be more precise.  Suppose $L$ is an unambiguous regular language on an alphabet $\{a_1, \dots, a_n\}$, and suppose to each letter of the alphabet we associate two non-negative integers $(x_i,y_i)$ which are not both zero.  Associate to a word $w$ the sum of the pairs of integers associated to each of its letters; call this $M(w) = (x, y)$.</p>

<p>Let $L'$ be the language consisting of all words such that $M(w) = (x, x)$ for some $x$.  Is $L'$ an unambiguous context-free language?</p>
",combinatorics
"<p>I've occasionally heard it stated (most notably on Terry Tao's blog) that ""the Cauchy-Schwarz inequality can be viewed as a quantitative strengthening of the pigeonhole principle."" I've certainly seen the inequality put to good use, but I haven't seen anything to make me believe that statement on the same level that I believe that the probabilistic method can be used as a (vast) strengthening of pigeonhole. </p>

<p>So, <em>how</em> exactly can Cauchy-Schwarz be seen as a quantitative version of the pigeonhole principle? And for extra pigeonholey goodness, are there similarly powered-up versions of the principle's other generalizations? (Linear algebra arguments [particularly dimension arguments], the probabilistic method, etc.)</p>
",combinatorics
"<p>This question is based on <a href=""http://qchu.wordpress.com/2009/08/12/krafts-inequality-for-prefix-codes/"" rel=""nofollow"">a blog post of Qiaochu Yuan</a>. </p>

<p>Let P be a locally finite* graded poset with a minimal element, and w be a weight function on the elements of P. Suppose that the total weight of the elements of rank k is bounded by 1. Then is the total weight of any antichain bounded by 1, or some constant c (independent of P or w?) The answer, of course, is no, and it's not hard to construct a counterexample. So what are the minimal conditions on P and/or w needed for such a result?</p>

<p>Note that this should specialize to several well-known theorems. Taking the poset to be a Boolean lattice and w to be 1/(n \choose k), we obtain the LYM inequality, hence the question title. Taking the poset to be the set of finite-length binary words with X \leq Y if X is a prefix of Y, and w to be 1/2^k, we get back Kraft's inequality. And finally, for arbitrary P and setting w to be the constant function 1, we get back (half of a special case of) Dilworth's theorem.</p>

<p>A secondary question: assuming such a result exists, is there a probabilistic proof of it, similar to the probabilistic proofs of Kraft and LYM?</p>

<p>Edit 4: Most of the counterexamples I've constructed thus far have had trees as the underlying poset (i.e., if X \leq Z and Y \leq Z, then either X \leq Y or Y \leq X). This subcase seems to simplify the analysis somewhat, so it might be worth considering only trees.</p>

<p>In fact, here's a toy problem which itself seems rather difficult: Can we characterize the weight functions on the infinite rooted binary tree, with the weight of each graded part equal to 1, that satisfy the strong property that the weight of any antichain is at most 1? </p>

<p>*Edit: Actually we want something somewhat stronger than local finiteness, namely that every element is covered by finitely many elements, so that there are are only finitely many elements of any given rank.</p>

<p>Edit^2: Of course we also want the weight function to be nonnegative, or else scary bad things can start happening. </p>

<p>The obvious restriction on the weight function requires it to be dependent only on the rank; interestingly, this is neither necessary nor sufficient for the strong form of the conjecture (i.e. the maximal weight of any antichain \leq the maximal weight of all the elements of rank k) to hold. (Counterexamples available upon request.) I'm still searching for a counterexample in this situation to the weak form of the conjecture (Edit^3: Counterexample found.), where every rank has bounded total weight but there are arbitrarily heavy antichains.</p>
",combinatorics
"<p>The OEIS entries <a href=""http://oeis.org/A019538"" rel=""nofollow"">A019538</a>, <a href=""http://oeis.org/A049019"" rel=""nofollow"">A049019</a>, and <a href=""http://oeis.org/A133314"" rel=""nofollow"">A133314</a>, relate a refinement of the face polynomials of the <a href=""http://en.wikipedia.org/wiki/Permutohedron"" rel=""nofollow"">permutohedra</a> (A049019) to partition polynomials (A133314) defined by multiplicative inversion of an exponential generating function (or surjections as noted in A049019 and A133314).</p>

<p>For example, with the Taylor series expansion of an analytic function (or formal power series, or e.g.f.)</p>

<p>$$f(x) = a_0 + a_1 x + a_2 \frac{x^2}{2!} + ... = \exp[a.x]$$</p>

<p>where $a.^n = a_n$, the series expansion of the reciprocal is formally </p>

<p>$$\frac{1}{f(x)}= a_0^{-1} + a_0^{-2} [-a_1] x + a_0^{-3} [2a_1^2 - a_2a_0] \frac{x^2}{2!} + a_0^{-4}[-6 a_1^3 + 6 a_1 a_2 a_0 - a_3 a_0^2 ] \frac{x^3}{3!} +  a_0^{-5} [24 a_1^4 - 36 a_1^2 a_2 a_0 + (8 a_1 a_3 + 6 a_2^2) a_0^2 - a_4 a_0^3] \frac{x^4}{4!}+ ... = \exp[Pt.(a_0,a_1,..)x]\; ,$$</p>

<p>and the unsigned coefficients of the partition polynomial $Pt_4(a_0,a_1,a_2,a_4)$ for the fourth order term with partitions of the integer four characterize the $P_3$ permutohedron depicted in Wikipedia with 24 vertices (0-D faces), 36 edges (1-D faces), 8 hexagons (2-D faces), 6 tetragons (2-D faces),  and 1 3-D permutohedron. Summing coefficients over like dimensions gives A019538 and <a href=""http://oeis.org/A090582"" rel=""nofollow"">A090582</a>. </p>

<p><strong>Question</strong>: Is there a bijective mapping between the integer partitions and the different polytopes of the n-D faces of the permutohedra for higher dimensions? </p>
",combinatorics
"<p>Assume $A = \prod_{i=1}^n\{0,1\}$, i.e. element $(a_1,\cdots,a_n)=a\in A$ is n-tuples like $(1,0,1,\cdots)$. </p>

<p>There is an obvious partial order on the $A$: say $a &lt; b$ for $a,b\in A$ if and only if  $\forall i\in \{1,\cdots,n\}$ $a_i\leq b_i$. Note this is only a partial order.</p>

<p>We define the order-preserved partition $(A_1,A_2)$ of $A$: $A_1 \cup A_2 = A$, $A_1\cap A_2 = \emptyset$, and for any $a\in A_1,b\in A_2$, we have  $a\ngeq b$, i.e. there is no element in $A_1$ bigger than any element in $A_2$. We also denote the pair as $A_1 &lt; A_2$.</p>

<p>We define an increasing function on the partial ordered set $A$:
$f((a_1,\cdots,a_n))=\prod_{i=1}^np_i^{1-a_i}$, where $0 &lt; p_1,p_2\cdots,p_n &lt;1$.</p>

<p>The question is that for any fixed order-preserve partition $(A_1,A_2)$ of $A$ whether we can find a positive number $\theta &gt;0$  and $f$ of above form such  that $A_1 \subset\{ f&lt;\theta\}$ and  and $A_2 \subset \{f&gt;\theta\}$ or not.</p>

<p>In some sense, I want to know whether order-preserve partition can be obtained geometrically by above certain type function $f$.</p>

<p>I tried $n\leq 3$ case, above question has easy positive answer.</p>

<p>Thanks a lot</p>
",combinatorics
"<p>Let $P$ be a poset, or partially ordered set. Let $\le$ denote the reflexive order on $P$, and $&lt;$ the corresponding irreflexive order. Let the phrase ""<em>a maximal pair</em>"" in $P$ refer to an
ordered pair $(u,v)$ of elements in $P$ such that</p>

<ul>
<li>$u&gt;v$,</li>
<li>$u$ is a maximal element of $P$, and</li>
<li>$v$ is a maximal element of the subposet $P\setminus\{u\}$.</li>
</ul>

<p>We say a subposet $P'$ of $P$ is <em>obtained by elementary collapse</em> from $P$, if
$P' = P \setminus \{u,v\}$ for some maximal pair $(u,v)$ of $P$. We say $P$ is <em>collapsible</em> if there is a sequence
$$
P = P_0 \supset P_1 \supset \cdots \supset P_{k-1} \supset P_k = 
\left\{\ast\right\}
$$
of subposets of $P$, in which $P_i$ is obtained by elementary collapse from $P_{i-1}$ for $i=1,2,\ldots,k$.</p>

<p>My questions are:</p>

<ul>
<li>I needed to prepare by myself the terminology for <em>maximal pairs</em>, <em>elementary collapse</em>, and <em>collapsiblity</em>; is there any better, more common way to refer to them?</li>
<li>I am working on proving collapsibility for a class of posets, <strong>conjecturally</strong> being the face posets of some convex polytopes. Are there any general ways to prove collapsibility of a poset, assuming or not assuming realizations as convex polytopes?</li>
</ul>
",combinatorics
"<p>Let $S$ be a zero-free subset of the group ${\bf Z}_2^n$ and $\Gamma={\rm Cay}({\bf Z}_2^n,S)$ be a bipartite Cayley graph. For some choices of $S$, the graph $\Gamma$ has $4$ distinct eigenvalues, but for other choices of $S$ with the same cardinality, $\Gamma$ could have $5$ or $6$ distinct eigenvalues. How can I find different $S$ of the same cardinality such that the resulting Cayley graphs have different numbers of distinct eigenvalues?</p>

<p>If there are any hints or references I'd appreciate it if you give them. If there is any proof that one cannot find such $S$, please mention it.</p>
",combinatorics
"<p>Given a circular code $X$ (for example: $X=\{ w,b \}$) with generating function $u(z)=\sum\limits_{k=0}^{\infty}{u_k z^k}$ (in this example : $u(z)=2z$), the generating function $p(z)=\sum\limits_{k=0}^{\infty}{p_k z^k}$ counts all words with a conjugate in $X^{*}$ which is given by $p(z)=\frac{z u'(z)}{1-u(z)}$. For more details, you can see ""Handbook of Enumeration"" (edited by Miklos Bona, chapter 8.3) or part one of the combinatorics book which is written by Stanley (Proposition 4.7.13).</p>

<p>In our example, $X=\{w,b \}$, $p_n$ would count all necklaces with white and black points having in total $n$ points (not up to rotation). If we want to count $c_n$, the number of such necklaces up to rotation, then $c_n$ and $p_n$ are in general related by $c_n= \frac{1}{n} \sum\limits_{d | n}^{}{\phi(\frac{n}{d}) p_d}$.
Now I want to do all this in a weighted situation, so for example I want to take how many points are black into considerations. Thus, I need multivariable generating function. In the example $X= \{w, b \}$, this would be $u(x,y)=x+y$. What are the generalizations to the weighted (multivariable) situation for the formulas: $p(z)=\frac{z u'(z)}{1-u(z)}$ and $c_n= \frac{1}{n} \sum\limits_{d | n}^{}{\phi(\frac{n}{d}) p_d}$? Is there a reference?
Of course for $X= \{w,b \}$ everything is easy but there are more complicated things like $X= \{b,baa,baaaa,baaaaaa,.... \}$, which by the way has a nice solution in the one-variable case: <a href=""https://oeis.org/A001350"" rel=""nofollow"">https://oeis.org/A001350</a> .</p>
",combinatorics
"<p>Given the $n\times m$ rectangle, I want to compute the minimum number of integer-sided squares needed to tile it (possibly of different sizes).
Is there an efficient way to calculate this?</p>
",combinatorics
"<p>Hurwitz's encoding counts the number of branched self-coverings of a sphere, with prescribed ramification degrees at the critical points, as numbers of factorizations of the identity in a symmetric group with given cycle lengths. My question is:</p>

<p>Is there a classification of all ""Hurwitz data"" (namely, degrees at critical points) for which the covering is determined uniquely?</p>

<p>For example, if the branch data are {d,d}, then the map has to be $z^d$, up to Möbius transformations. A few other cases I found out are:</p>

<ul>
<li>if the data are {d,m,(d+1-m)}, then the map has to be $\int z^{m-1}(1-z)^{d-m}$;</li>
<li>if the data are {d,m+(d-m),2}, then the map has to be $z^m(1-z)^{d-m}$;</li>
<li>if the data are {n+n,2+...+2,2+...+2}, then the map has to be $z^n/(1+z^n)^2$;</li>
<li>if the data are {m+n,m+n,3}, the map is $z^m((m-n)z-(m+n))^n/((m+n)z+(m-n))^n$.</li>
</ul>

<p>On the other hand, if all critical values are simple (so the data is {2,2,...,2}), then there are exponentially many branched coverings (something like a Catalan number).</p>

<p>I'm aware of various combinatorial tools to compute the number of coverings, including ""integration on the Deligne-Mumford stack"", but all the literature I was able to google up was concerned about cases where there are no branched coverings, or lots.</p>
",combinatorics
"<p>I am looking for a copy of the paper in the title, appeared in the proceedings</p>

<p>""Combinatorics and algebra (Boulder 1983), Contemp. Math., 34""</p>

<p>and reprinted in</p>

<p>""Gian-Carlo Rota on Combinatorics, Birkhäuser, 1995"".</p>

<p>I have no way to get it.
Does anyone have a scanned copy of it ? Thanks very much in advance.</p>
",combinatorics
"<p>Observe $\mathbb{Z}_q^n = \mathbb{Z}_q \times \cdots \times\mathbb{Z}_q$ as a module over $\mathbb{Z}_q\equiv\mathbb{Z}/q\mathbb{Z}$, for general $q$.
I am interested in the following questions:</p>

<p>How many submodules of size $q^k$, $k\leq n$, does it have? How many of them are free? Can something be said about the ratio of these two numbers when $n\to\infty$ and $k=\lambda n$, $\lambda\in(0,1)$?</p>

<p>Can someone give me a reference where such or similar problems have been studied? Or else provide pointers how to tackle them?</p>
",combinatorics
"<p>Let $(W, S)$ be a Coxeter system.  Soergel defined a category of bimodules $B$ over a polynomial ring whose split Grothendieck group is isomorphic to the Hecke algebra $H$ of $W$.  Conjecturally, the image of certain indecomposable (projective?) bimodules in $B$ is the well-known Kazhdan-Lusztig basis of $H$.  Assuming the conjecture, Soergel showed that the coefficients of the Kazhdan-Lusztig polynomials of $W$ are given by the dimensions of certain Hom-spaces in $B$.  It follows that these coefficients are non-negative, which was already known by work of Kazhdan-Lusztig in the Weyl group case by linking these coefficients to intersection cohomology of the corresponding Schubert varieties.</p>

<p>Soergel proved this conjecture in 1992 for $W$ a Weyl group, and Härterich proved it in 1999 for $W$ an affine Weyl group.  Unfortunately, I can't access the first paper, and the second paper is in German, so I don't know anything about either of these proofs.  </p>

<p><strong>Question:</strong>  Do these proofs depend on the relationship of the coefficients of the K-L polynomials to intersection cohomology, or are they independent of the corresponding machinery?</p>

<p>(The reason I ask is that I am potentially interested in relating known combinatorial proofs of positivity to Soergel's work, and I want to get an idea of how much machinery I would need to learn to do this.)</p>

<p><strong>Edit:</strong>  Soergel's 1992 paper is <a href=""http://www.reference-global.com/doi/abs/10.1515/crll.1992.429.49"">here</a>, if only I had the appropriate journal access.  If anybody does and would like to send me this paper, that would be excellent - my contact information is at a link on my profile.</p>
",combinatorics
"<p>I know of 2(.5) proofs of Ramsey's theorem, which states (in its simplest form) that for all $k, l\in \mathbb{N}$ there exists an integer $R(k, l)$ with the following property: for any $n&gt;R(k, l)$, any $2$-coloring of the edges of $K_n$ contains either a red $K_k$ or a blue $K_l$.</p>

<p>Both the finite and the infinite versions (the latter being--a 2-coloring of the edges of $K_\mathbb{N}$ contains an infinite monochrome $K_\mathbb{N}$) are proven on <a href=""http://en.wikipedia.org/wiki/Ramsey%2527s_theorem#Proof_of_the_theorem"">Wikipedia</a>, and one may deduce the finite version from the infinite one by compactness, or equivalently using Konig's lemma.  The infinitary proof does not give effective bounds on $R(k, l)$, but can be converted to one that does as follows (this is the .5 proof): </p>

<p>Consider a $2$-coloring of the edges of a complete graph on $N=2^{k+l}$ vertices, $v_1, ..., v_N$.  Let $V_0$ be the set of all vertices, and let $V_i$ be the largest subset of $V_{i-1}$ connected to $v_i$ by edges of a single color, $c_i$.  After $k+l$ steps, at least $k$ of the $c_i$ are read or $l$ of the $c_i$ are blue by pigeonhole; let the set of indices for which this happens be denoted $S$.  Then $(v_i)_{i\in S}$ is the desired subgraph.</p>

<p>My question is:</p>

<blockquote>
  <p>Does anyone have a fundamentally different proof of this theorem?  In particular, I am curious to know if there are any of a less combinatorial flavor.</p>
</blockquote>
",combinatorics
"<p>As a sort of dual question to <a href=""http://mathoverflow.net/questions/29427/noncombinatorial-proofs-of-ramseys-theorem"">this</a> question, I am wondering what proofs people know of lower bounds on Ramsey numbers $R(k, k)$.  I know of two proofs:  there is Erdos's beautiful probabilistic argument, given <a href=""http://en.wikibooks.org/wiki/Combinatorics/Bounds_for_Ramsey_numbers#Lower_bound"" rel=""nofollow"">here</a> for example, as well as the following:</p>

<p>(This is a sketch; it's worth working out the details.)  Represent a two-coloring of the edges of a complete graph on $n$ vertices as the upper triangle (strictly above the diagonal) of an $n\times n$ matrix of zeroes and ones (that is, ${n\choose 2}$ bits).  We may rewrite this representation by noting which vertices are contained in our monochrome subgraph and what color it is, as well as including all the remaining edge data, using some special characters to block off this data.  If Ramsey numbers are small, this sends each string of bits under an appropriate encoding to a smaller string of bits, which is impossible by pigeonhole.  (I am being purposely vague about the encoding--pick your own, anything goes essentially--because it's a bit boring).  The bound this argument gives is essentially the same as the probabilistic one, and indeed it seems to me to be essentially a ""derandomization"" of that argument.</p>

<p>My question is:</p>

<blockquote>
  <p>Does anyone know a proof of a similarly good lower bound using a fundamentally different method?</p>
</blockquote>
",combinatorics
"<p>I have a $d$-uniform hypergraph on $n$ vertices with $k$ hyperedges, where $d &lt;&lt; k$ and $n = 4k d^2$ or so.
The hyperedges are placed independently uniformly at random.  I would like to have a handle on the behavior of the sizes of the connected components.  By ""size"" I refer to the number of edges in the component, but understanding the number of vertices would be fine too.</p>

<p>For instance, if $X$ is the size of the component containing the first hyperedge, it seems like we should have $\Pr[X &gt; t] &lt; 1/2^t$.  This is because each hyperedge has a less than $1/4$ chance of intersecting any other hyperedge, so this seems like some sort of exponentially decaying branching process.</p>

<p>Furthermore, it seems like there should be a negative association among component sizes: the larger one component is, the smaller the other ones are.  Suppose I give each component in the graph a unique random label in $[k]$, and let $Y_i$ be the size of the component labeled $i$ (or 0 if no component has label $i$).  Then I expect that $E[Y_i | Y_j = t]$ for $j \neq i$ is decreasing in $t$.  Moreover, I expect that the random variable $(Y_i | Y_j = t)$ is decreasing in $t$: the variable with small $t$ dominates the variable with large $t$.</p>

<p>But I'm not sure how to rigorously show either property.</p>
",combinatorics
"<p>Let $M\subset\mathbb{N}$ be a finite set. For every positive integer $n$ set
$$D_n(M)=\{W\subset \mathbb{N} \text{ finite }|\ \forall\ i=0,\ldots,n-1\ \exists\ w\in W: w\in M+i\},$$ where $M+i=\{m+i|\ m\in M\}$. I would like to understand
$$d_n(M)=Min\{|W|\ | \ W\in D_n(M)\}.$$
I am mainly interested in the asymptotic behaviour of the $d_n(M)$'s. So I would like to know $$d(M)=\lim_{n\to\infty}\frac{d_n(M)}{n}.$$</p>

<p>For example, for $M=\{1,2\}$ we have $(d_1(M),d_2(M),\ldots)=(1,1,2,2,3,3,\ldots)$ and so $d(M)=\frac{1}{2}$.</p>

<p>My question is, if this is (related to) a known combinatorial problem? It seems a fairly natural problem to me, so I could well imagine that it has been treated in the literature. I encountered it when trying to explicitly compute some value in an algebraic-geometric example.</p>

<p>I would like to know things like, is the sequence of first differences $\Delta d_n(M)=d_n(M)-d_{n-1}(M)$ always periodic?  </p>
",combinatorics
"<p>For a given integer $k\ge3$, tile the unit square with $k$ rectangles so that the longest of the rectangles' diagonals be as short as possible. Call such a tiling <em>optimal</em>. The solutions are obvious in the easy cases when $k$ is the square of an integer and for a few small values of $k$ only (unpublished). In each of the solved cases, the sides of all rectangles turn out to be rational and their diagonals are equal.</p>

<p>Question. In an optimal tiling, must the sides of all rectangles be rational and their diagonals be equal?</p>

<p>The analogous question for tiling the $n$-dimensional cube with rectangular boxes can be asked for every $n\ge3$ as well.</p>
",combinatorics
"<p>The first of my questions may be entirely elementary, but the second (closely related) question may be of appropriate interest for this site.</p>

<p>Suppose that we are given $w_1, w_2, \cdots, w_n$ of positive integers which are co-prime. Let $H &gt; 1$ be a positive parameter. I am interested in evaluation the sum</p>

<p>$$\displaystyle \sum_{w_1 x_1 + \cdots + w_n x_n \leq H} (w_1 x_1 + \cdots + w_n x_n)$$</p>

<p>I think the sum can be expressed in the form $c_0 H^{n+1} + O(H^{n})$ for some positive constant $c_0 &gt; 0$, and if this is the case then I want to know what $c_0$ is in terms of the weights $w_1, \cdots, w_n$.</p>

<p>Second question is for general weights $w_1, \cdots, w_n$, where these are positive real numbers (but not necessarily integers), can we obtain the same result? Since a counting argument is not so clear here, what would be the way to show it?</p>

<p>Thanks for any insights.</p>
",combinatorics
"<p>Following up on the previous MO question <a href=""http://mathoverflow.net/questions/17523/are-there-any-important-mathematical-concepts-without-discrete-analog"">""Are there any important mathematical concepts without discrete analogue?""</a>, I'd like to ask the opposite: what are examples of notions in math that were not originally discrete, but have good discrete analogues?  While a few examples arose in the answers to that earlier MO question, this wasn't what that question was asking, so I'm sure there are many more examples not mentioned there or at least not really explained there.  What reminded me of this older MO question was seeing an MO question <a href=""http://mathoverflow.net/questions/54986/why-is-the-laplacian-ubiquitous"">""Why is the Laplacian ubiquitous?""</a>, since that is an instance of an important notion which has a discrete analgoue. </p>

<p>In an answer, it would be interesting to hear about the relationship between the continuous and discrete versions of the notion, if possible, and references could also be helpful.  Thanks!</p>
",combinatorics
"<p>I'm teaching an introductory graph theory course in the Fall, which I'm excited about because it gives me the chance to improve my understanding of graphs (my work is in topology). A highlight for me will be to teach the Matrix-Tree Theorem, which I think is the only place that linear algebra is used in the course.</p>

<p>Let &#954;(G) denote the number of spanning trees of G (the <em>complexity</em> of G), and let L(G) denote the Laplacian matrix of G. Finally, for a vertex v of G, let L(v|v) denote the Laplacian matrix with the row and column corresponding to v deleted.</p>

<blockquote>
<b>Matrix-Tree Theorem:</b> &#954;(G)= det L(v|v).  
</blockquote>

<p>It seems a shame for Linear Algebra to be a prerequisite for my course. Anyway, I don't expect most of my students to be great Linear Algebra experts. Because my students might not remember things like Cauchy-Binet, but mainly so that I myself feel that I can really understand what I'm teaching, I wonder how the Matrix-Tree Theorem could be proven without ever mentioning matrices. On a planet with strong combinatorics and where linear algebra had not been discovered, how would they prove the Matrix-Tree Theorem?</p>

<p>The RHS of the Matrix-Tree Theorem makes sense without ever mentioning matrices, via the <a href=""http://en.wikipedia.org/wiki/Lindstr%C3%B6m%E2%80%93Gessel%E2%80%93Viennot_lemma"">Lindstr&ouml;m-Gessel-Viennot</a>(-Karlin-MacGregor) Lemma. Construct a graph H,  with a source and a sink corresponding to each vertex of G, so that the signed sum of edge weights gives the entries of the Lagrangian matrix for G (surely there's a clever standard way to do this!) and define the determinant of H to be the signed sum of all n-tuples of non-intersecting paths from the sources to the sinks. This interpretation of the determinant seems a nice topic to teach. Maybe there's even an easier way.</p>

<p>Cauchy-Binet becomes an elementary property of sets of non-intersecting paths in H, but I can't see how to free the rest of the proof of the Matrix-Tree Theorem from linear algebra.</p>

<blockquote>

<b>Question:</b> Is there a proof of the Matrix-Tree Theorem which makes no mention of matrices? Is it simple enough that one could teach it in an introductory graph theory course?

</blockquote>

<p><b>Note 1</b>: If the purpose of the Matrix-Tree Theorem is to efficiently calculate the complexity of a graph, then dodging linear algebra is surely counterproductive, because a determinant can efficiently be calculated in polynomial time. But, quite beside from my interest in ""correctly-tooled"" proofs and my teaching goals, I have vague dreams which are almost certainly nonsense about better understanding the Alexander polynomial as a quantum invariant along the lines of <a href=""http://mathoverflow.net/questions/9847/why-is-the-alexander-polynomial-a-quantum-invariant"">this question</a> which might conceivably factor through the Matrix-Tree Theorem (or rather some version of Kirchhoff's formula), and I think I clearly want to stay in the diagrammatic world.</p>

<p><b>Note 2</b>: <a href=""http://qchu.wordpress.com/2009/11/17/the-lindstrom-gessel-viennot-lemma/"">This excellent post</a> by Qiaochu Yuan suggests that the answer to my question is in Aigner. I'm travelling right now, and the relevant section isn't on Google Books, so I don't have access to Aigner for the next few weeks. If memory serves, Aigner still uses linear algebra, but maybe I'm wrong... anyway, if the answer turns out to be ""look in Aigner"" then please downvote this question, or if you could summarize how it's done, I would be happier. The answer will surely turn out to be ""look in [somewhere]"" anyway, because surely this is easy and well-known (just I don't know it)...</p>
",combinatorics
"<p>There is a graph on $n$ vertices. Any $m$ distinct vertices of that graph,have exactly one common neighbor. Find all $(m,n)$ such that this kind of graph exists. </p>

<p>I guess that such a graph exists iff $m \mid n-1$. This is true by the friendship theorem for $m=2$ and it is easily seen to be true for $m= n-1$. But I don't have any plan of proof or construction of the graph for any other values of $m$. Also is it true, that if the graph exists, it is unique ? (Again true for $m=2$ and $m= n-1$ )</p>

<p>Thank you!</p>
",combinatorics
"<p>Hi,</p>

<p>I believe it is just an easy question, but I have not found the answer: Is the optimization / decision problem DOMINATING SET NP-complete when restricted to regular graphs? Where can I find a proof of that?</p>

<p>Thank you, MO users.</p>
",combinatorics
"<p>Apparently, the closest thing I've found would be normal number <a href=""http://mathworld.wolfram.com/NormalNumber.html"">http://mathworld.wolfram.com/NormalNumber.html</a> </p>

<p>But requiring that every finite words occurs is weaker than this property. So I'm wondering if there are any study on this topic.</p>

<p>My original goal is to find a criterion for a Büchi automaton not to recognize some infinite word like this. There's been a post here <a href=""http://mathoverflow.net/questions/145375/proof-that-the-omega-language-consisting-of-all-words-containing-every-finite"">Proof that the $\omega$-language consisting of all words containing every finite word as a factor is not rational/regular</a> , but there were no references to such a class of words.</p>

<p>Maybe all this is obvious to specialists, but I couldn't find anything with our universal friend google :)</p>

<p>Thank you!</p>
",combinatorics
"<p>I am curious to collect examples of equivalent axiomatizations of mathematical structures.  The two examples that I have in mind are </p>

<ol>
<li><p><strong>Topological Spaces.</strong> These can be defined in terms of open sets, closed sets, neighbourhoods, the Kuratowski closure axioms, etc.</p></li>
<li><p><strong>Matroids</strong>.  These can be defined via independent sets, bases, circuits, rank functions, etc.</p></li>
</ol>

<p>Are there are other good examples? </p>

<p>Secondly, what are some advantages of multiple axiomatizations?</p>

<p>Obviously, one advantage is that one can work with the most convenient definition depending on the task at hand.  Another is that they allow different generalizations of the object in question.  For example, infinite matroids can be axiomatized by adapting the independent set axioms, but it is unknown how to axiomatize them via the circuit axioms.  An acceptable answer to the second question would be an example of a proof in one axiom system that doesn't translate easily (not sure how to make this precise) into another axiom system.  </p>
",combinatorics
"<p>This question is not about elements of $S_n$ that consist of a single $n$-cycle, though naturally it's related.  </p>

<p>Instead, consider permutations modulo the action of $(123\ldots n)$.  That is, we want ABCD to be the same as BCDA and CDAB and DABC.  (It's optional whether this also is the same as DCBA, but for now let's say it's not.)  I am primarily interested in the graph that these generate, sort of like the Cayley graph for $S_n$ with generators $(12),(23),\ldots (n-1 n),(n1)$, but with vertices and edges identified.  (I don't think this is a Cayley graph of a quotient of $S_n$; I don't even think this set is identifiable with a group since that subgroup isn't normal, if I recall correctly.)</p>

<p>What are these things called, and are there references to them in the literature?  (Say to their symmetry groups, rep. theory, or whatever else.) I can't imagine there aren't, but because 'cyclic permutations' nearly always means something else, it's frustrating to look for this.  I found pages of MathSciNet references to those terms, and none were about this.  Not surprisingly!  But presumably combinatorics experts have studied them - not just counted them, though Polya enumeration immediately comes to mind.</p>

<p>Edit: For a concrete example, imagine people around a dinner table, where you don't care which chair you sit in, you just care what the arrangement is.  Maybe it's been thought of that way before?</p>

<p>Edit: Well, I have to say that Tilman and Mark Sapir both have been very helpful, but I guess Tilman answered the actual question.  </p>

<p>Very oddly, I can only find ONE paper on MathSciNet that actually deals with the object I am interested in directly - Woodall's ""Cyclic-order graphs and Zarankiewicz's crossing-number conjecture"" proves some basic facts.  Nearly every reference to such things is about using cyclic orders without considering all of them (in graph theory or queueing theory), is using them to create ribbon graphs, or is about extending partial cyclic orders to complete cyclic orders.</p>
",combinatorics
"<p>I was alluded to the fact that there is no connection between the growth rate of the number of nonisomorphic finite models of a theory and the fact wether there are countably or uncountably many nonisomorphic countably infinite models. </p>

<p>There seem to be four types of theories (the examples are from answers and comments to my MSE question <a href=""http://math.stackexchange.com/questions/27398/how-many-countable-graphs-are-there"">How many countable graphs are there?</a>):</p>

<p><strong>Type 1:</strong> Low growth rate of finite models (less than exponential), countably many infinite models<br/>
<em>Example:</em> theories with unary predicates only</p>

<p><strong>Type 2:</strong> Low growth rate of finite models, uncountably many infinite models<br/>
<em>Example:</em> groups, fields</p>

<p><strong>Type 3:</strong> High growth rate of finite models (at least exponential), countably many infinite models<br/>
<em>Example:</em> graphs with finitely many edges</p>

<p><strong>Type 4:</strong> High growth rate of finite models, uncountably many infinite models<br/>
<em>Example:</em> graphs</p>

<p>All examples are first order theories except ""graphs with finitely many edges"" since finiteness cannot be defined in a first order language.</p>

<p>So my questions are:</p>

<blockquote>
  <p>What is a first order example of a Type 3
  theory?</p>
  
  <p>How can these types of theories be
  characterized?</p>
</blockquote>

<p>One thing holds for all theories of Type 2 to 4: They must have ""more"" than unary predicates, for example a binary relation. (Could a unary <em>function</em> suffice?)</p>
",combinatorics
"<p>This question was initially proposed to me by two friends. Given an integer $n$, how many isomorphism classes are there for semidirect products $\mathbb{Z}/n\mathbb{Z}\rtimes\mathbb{Z}/2\mathbb{Z}$?</p>

<p>Maybe this is a really trivial question. I can tell that a semidirect product is the same as an integer $r\in\mathbb{Z}/n\mathbb{Z}$ with $r^2=1\mod[n]$, but are there isomorphisms between some of them? What happens for instance when n is squarefree, thus the product of fields.</p>
",combinatorics
"<p>This question is motivated by the following well-known theorems:</p>

<blockquote>
  <p><strong>Thm (Plünnecke):</strong> If $A$ is a finite nonempty subset of an abelian group, then for every $n$ we have $|A^n| \le \frac{|AA|^n}{|A|^n}|A|$.</p>
  
  <p><strong>Thm (Ruzsa):</strong> If $A$ is a finite nonempty subset of a group, then for every $n$ we have $|A^n| \le \frac{|AAA|^{2n}}{|A|^{2n}}|A|$.</p>
</blockquote>

<p>Here by $A^n$ I mean the set of all products of $n$ elements of $A$, so $A^2 = AA$ and $A^3 = AAA$.</p>

<p>I would like to know if there is any similar generalization to cancellative semigroups. Specifically:</p>

<blockquote>
  <p><strong>Question:</strong> Do there exist integers $k, c$ such that for every finite nonempty subset $A$ of any cancellative semigroup and for every $n$, $|A^n| \le \frac{|A^k|^{cn}}{|A|^{cn}}|A|$?</p>
</blockquote>

<hr>

<p><strong>Edit:</strong> There is a counterexample in the non-cancellative case. For any $n$, let $E_n = \langle e \mid e^{n+2} = e^{n+1}\rangle$. For any group $G$, let $S$ be the quotient of $(G \times E_n)\cup\{0\}$ where we identify $(g,e^{n+1})$ with $0$ for every $g\in G$. Let $A$ be the image of $G\times \{e\}$ in $S$. Then $|A| = |AA| = \cdots = |A^n| = |G|$, but $|A|^{n+k} = 1$ for every $k \ge 1$. Taking a product of many examples like this and a free semigroup, we can arrange that $|A| = |AA| = \cdots = |A^n|$, but $|A^{n+k}| = |A|^{(n+k)/n}$ for every $k \ge 1$.</p>

<p>Here's an easy result which actually uses cancellativity:</p>

<blockquote>
  <p><strong>Thm:</strong> If $A$ is a subset of a cancellative semigroup $S$, then there is a subset $P \subseteq AA$ with $|P| \ge \frac{|A|}{2}$ such that for any subsets $C,B$ of $S$, we have $|CPB| \le 2\frac{|CA|}{|A|}\frac{|AB|}{|A|}|AA|$. In particular, $|AP^nA| \le 2^n\frac{|AA|^{2n}}{|A|^{2n}}|AA|$.</p>
</blockquote>

<p>To prove this, take $P$ to be the set of products in $AA$ which can be written as a product in at least $\frac{|A|^2}{2|AA|}$ ways (the ""popular"" products) and write down a clever injection.</p>
",combinatorics
"<p>Let $G$ be a finite abelian group of odd order, let $D\subseteq G$, and $\epsilon \in (0,1)$.
For $S\subseteq G$ define
$$
\Lambda(S) = \frac{1}{|S||G|} \sum_{s\in S}\sum_{g\in G} 1_S(s)1_S(s+g)1_S(s+2g)
$$
(i.e., a normalized count of the number of 3-term APs in $S$)
and define
$$
\Lambda_D(S) = \frac{1}{|S||D|} \sum_{s\in S}\sum_{d\in D} 1_S(s)1_S(s+d)1_S(s+2d),
$$
(i.e., a normalized count of the number of 3-term APs in $S$ whose common difference lies in $D$).</p>

<p>Suppose that
$
|\Lambda(S) - \Lambda_D(S)| \leq \epsilon
$
holds for every set $S\subseteq G$.
How large must $|D|$ be?<br>
The Cayley graph Cay$(G, \{d, 2d: d\in D\})$ has expansion properties that imply $|D| \geq c\log |G|$ for some $c = c(\epsilon)&gt;0$.
Does a significantly stronger bound in fact hold true?</p>
",combinatorics
"<p>Let $G,H$ be infinite simple undirected graphs with the property that for any graph $X$ we have $|\text{Hom}(X,G)| = |\text{Hom}(X,H)|$. Does this imply that $G$ is isomorphic to a subgraph of $H$, and vice versa?</p>

<p>(Note that in the finite case the condition above implies $G\cong H$, see <a href=""http://www.maths.qmul.ac.uk/~pjc/csgnotes/hom1.pdf"">here</a>.)</p>
",combinatorics
"<p>Erdős's 1947 probabilistic trick provided a lower exponential bound for the Ramsey number $R(k)$. Is it possible to explicitly construct 2-colourings on exponentially sized graphs without large monochromatic subgraphs?</p>

<p>That is, can we explicitly construct (edge) 2-colourings on graphs of size $c^k$, for some $c&gt;0$, with no monochromatic complete subgraph of size $k$?</p>
",combinatorics
"<p>Pretty much exactly what it says on the tin. Let G be a connected graph; then the Tutte polynomial T_G(x,y) carries a lot of information about G. However, it obviously doesn't encode everything about the graph, since there are examples of non-isomorphic graphs with the same Tutte polynomial.</p>

<p>My question is, what information exactly does the Tutte polynomial encapsulate? I'm aware of a few answers to this question, but I don't find any of them particularly satisfying. For instance, T_G(x,y) can be characterized as ""the universal Tutte-Grothendieck invariant,"" but the definition of Tutte-Grothendieck invariants is just as unintuitive as the definition of the Tutte polynomial (because it's essentially the same definition!) One can also define the coefficients as counting certain spanning trees of G, but this doesn't make apparent the fact that the Tutte polynomial specializes to the chromatic polynomial, or the notion that it carries most of the information one can obtain via linear algebra methods.</p>

<p>So is there a nice way of thinking about what data about G the Tutte polynomial encodes?</p>

<p>ETA: Okay, here's a very rough conjecture. Suppose that there's some ""computationally simple"" (i.e., testing membership is in NP) class of graphs such that there are two connected graphs G, H with the same Tutte polynomial, and G is in the class and H is not. Then there are spanning trees S, T of G, H respectively, such that S is in the class and T is not.</p>

<p>This would mean, in a sense that I can't make entirely rigorous, that the information about a graph G not encoded in the Tutte polynomial is just information about the structure of spanning trees of G. (Update: As Kevin Costello points out in a comment, this idea appears to be severely limited by the existence of certain pairs of co-Tutte graphs. In particular, we would need to count spanning trees with multiplicity for it to have even a chance of being true.)</p>

<p>As stated, the above conjecture is false for trivial reasons. But is there a way of making it true, perhaps by requiring the property to be, in some sense, natural? Is there a broad notion of ""graph properties"" for which it is true? Can we at least state a conjecture along these lines which does seem to be true?</p>
",combinatorics
"<p>Let $n$ be a positive integer. A subset of $[n] := \{1,2,...,n\}$ having $k$ elements will be called a $k$-subset.</p>

<p>For $n,k \in \mathbb{N}$ with $k \leq \lfloor n/2 \rfloor$, it is clear that one can associate bijectively $(n-k)$-subsets with $k$-subsets through complements: $S \mapsto \bar{S}$. However, the image is never a subset of the element being mapped (far from it). I would like a bijection $\iota$ between (n-k)-subsets and k-subsets such that $\iota(S) \supseteq S$, for every $S$ (n-k)-subset.</p>

<p>I tried imposing a total order on $[n]$ and playing with lexicographic ordering of the characteristic vectors, but it didn't work. I also thought about showing that the obvious bipartite graph satisfies Hall's condition. Does anyone have either an explicit bijection or a proof that Hall's condition is fulfilled? Actually, I would also be interested in a proof that such bijection does not exist, but I don't believe this to be true.</p>
",combinatorics
"<p>While applying the algorithm to solve the max flow of the network with minimal requirements on edges, I have encountered a problem. 
The algorithm states:</p>

<p>For graph G</p>

<ul>
<li>create an edge from target to source with infinite capacity</li>
<li>create two new source S' and target T'</li>
<li>for every demand d of an edge E we create two edges, one leading from the new source S' to the target node of the edge E and one to the new target T' from the source node of the edge E, both with capacity d. We subtract the capacity d from the capacity of the edge E.</li>
<li>find a saturating max flow from S' to T' (so all new edges are saturated)</li>
<li>transform graph back</li>
</ul>

<p>The problem is, that we can find a saturating flow, even when there is no feasible solution. Let's see the following graph.</p>

<p><img src=""http://i.stack.imgur.com/pcOfO.png"" alt=""basic graph""></p>

<p>It can be transformed to the following graph, then a max flow can be found.</p>

<p><img src=""http://i.stack.imgur.com/WELxo.png"" alt=""transformed graph with max flow""></p>

<p>So the result is the cycle saturated with flow 2.</p>

<p>But it is not feasible because of the edges with capacity 1.
Why doesn't it work? What to do to repair the algorithm so it would work? I did not see any mentions of this problem in the papers.</p>
",combinatorics
"<p>The number of Dyck paths from the origin to $(2n,0)$ which touch the $x$-axis $k+2$ times ($k$ internal touches) is given by
$$\frac{k}{2n-k}{2n-k \choose n}.$$</p>

<p>The number of Dyck paths from the origin to $(2n,0)$ which have $b$ peaks (i.e. local maxima) is given by the Narayana numbers
$$\frac{1}{n}{n \choose b}{n \choose b-1}.$$</p>

<p>My questions is: What is the number of Dyck paths from the origin to $(2n,0)$ which have both $k$ returns and $b$ peaks?</p>

<p>I have not been able to find any published work on this.</p>

<p>Thanks!</p>
",combinatorics
"<p>I seem to have chanced upon a new characterization for Kravchuk polynomials.
[<a href=""http://en.wikipedia.org/wiki/Kravchuk_polynomials]"" rel=""nofollow"">http://en.wikipedia.org/wiki/Kravchuk_polynomials]</a>.</p>

<p>To begin with, let us define the function $\omega(n,p)$ as [Assuming $\binom{a}{b}=0$ when $b&gt;a$].,</p>

<p>$\omega \left( {n,p} \right) = \sum\limits_{i = 0}^{\,\frac{{n - 1}}{2}} {{{\left( { - 1} \right)}^i}} \left( {\begin{array}{*{20}{c}}
  {n - p} \\ 
  i 
\end{array}} \right)\sum\limits_{k = 0}^{\left( {\frac{{n - 1}}{2}} \right) - i} {\left( {\begin{array}{*{20}{c}}
  p \\ 
  k 
\end{array}} \right)} $.</p>

<p>The result I seek to prove is, for $0 \leqslant p \leqslant n - 1$, $\omega \left( {n,p} \right) = {\rm K}\left( {n - 1,\left( {\frac{{n - 1}}{2}} \right),n - p - 1} \right)$, where, ${\rm K}(.,.,.,)$ is the Kravchuk polynomial defined by,
$\begin{gathered}
  {\rm K}\left( {N,k,x} \right) = \sum\limits_{j = 0}^{\,k} {{{\left( { - 1} \right)}^j}} \left( {\begin{array}{*{20}{c}}
  x \\ 
  j 
\end{array}} \right)\left( {\begin{array}{*{20}{c}}
  {N - x} \\ 
  {k - j} 
\end{array}} \right) \\
  \quad \quad \quad \quad \;\, = \sum\limits_{j = 0}^{\,k} {{{\left( { - 2} \right)}^j}} \left( {\begin{array}{*{20}{c}}
  {N - j} \\ 
  {k - j} 
\end{array}} \right)\left( {\begin{array}{*{20}{c}}
  x \\ 
  j 
\end{array}} \right)  \\
  \quad \quad \quad \quad \;\, = \sum\limits_{j = 0}^k {{{\left( { - 1} \right)}^j}{2^{k - j}}\left( {\begin{array}{*{20}{c}}
  {N - k + j} \\ 
  j 
\end{array}} \right)\left( {\begin{array}{*{20}{c}}
  {N - x} \\ 
  {k - j} 
\end{array}} \right)}   \\ 
\end{gathered} $.</p>

<p>So, in short, I need to prove that the summation on the LHS is the same as one of the 3 on the RHS:</p>

<p>$\begin{gathered}
  \sum\limits_{i = 0}^{\,\frac{{n - 1}}{2}} {{{\left( { - 1} \right)}^i}} \left( {\begin{array}{*{20}{c}}
  {n - p} \\ 
  i 
\end{array}} \right)\sum\limits_{k = 0}^{\left( {\frac{{n - 1}}{2}} \right) - i} {\left( {\begin{array}{*{20}{c}}
  p \\ 
  k 
\end{array}} \right)}  = \sum\limits_{j = 0}^{\,\frac{{n - 1}}{2}} {{{\left( { - 1} \right)}^j}} \left( {\begin{array}{*{20}{c}}
  {n - p - 1} \\ 
  j 
\end{array}} \right)\left( {\begin{array}{*{20}{c}}
  p \\ 
  {\left( {\frac{{n - 1}}{2}} \right) - j} 
\end{array}} \right) 
  \quad \quad \quad \quad \;\quad \quad \quad \quad \;\,\quad \quad  = \sum\limits_{j = 0}^{\,k} {{{\left( { - 2} \right)}^j}} \left( {\begin{array}{*{20}{c}}
  {n - 1 - j} \\ 
  {\left( {\frac{{n - 1}}{2}} \right) - j} 
\end{array}} \right)\left( {\begin{array}{*{20}{c}}
  {n - p - 1} \\ 
  j 
\end{array}} \right) 
  \quad \quad \quad \quad \;\quad \quad \quad \quad \;\quad \quad  = \sum\limits_{j = 0}^k {{{\left( { - 1} \right)}^j}{2^{\left( {\frac{{n - 1}}{2}} \right) - j}}\left( {\begin{array}{*{20}{c}}
  {\left( {\frac{{n - 1}}{2}} \right) + j} \\ 
  j 
\end{array}} \right)\left( {\begin{array}{*{20}{c}}
  p \\ 
  {\left( {\frac{{n - 1}}{2}} \right) + j} 
\end{array}} \right)}   
\end{gathered} $.</p>

<p>Any help/clues/tricks would be much appreciated. I tried using the 2f1 hyper-geometric function based results for the partial 'pascal-sum' on the LHS and it all became real messy soon without achieving much headway.</p>

<p>In case you want to verify this numerically, here is a MATLAB script for the same:
clear all;
clc;
% k=0,1,..., n.
% n being positive integer
% x : variable</p>

<p>n=15;
for p=0:n-1</p>

<pre><code>N=n-1;
k=(n-1)/2;

x=n-p-1;

% q=2;
for j=0:(n-1)/2
    s_RHS(j+1)=(-1)^j*nCk(n-p,j)*T_mn(p,(n-1)/2-j);
    % The Kravchuk polynomial has following alternative expressions:
    s_LHS_1(j+1) = (-1)^j * nCk(x,j)* nCk((n-1)-(n-p-1),((n-1)/2)-j);
    s_LHS_2(j+1)=(-2)^j * nCk((n-1)-j,((n-1)/2)-j)* nCk((n-p-1),j);
    s_LHS_3(j+1)=(-1)^j* 2^(((n-1)/2)-j)* nCk(((n-1)/2)+j,j)* nCk(p,((n-1)/2)-j) ;
end
[s_RHS' s_LHS_1' s_LHS_2' s_LHS_3']
[  sum([s_RHS' s_LHS_1' s_LHS_2' s_LHS_3'])]
</code></pre>

<p>end</p>

<p>% function x=nCk(n,k)
% if(k>n)
%     x=0;
% else
%     x=nchoosek(n,k);
% end</p>

<p>Thanks!</p>
",combinatorics
"<p>Given an undirected graph G with $n$ nodes, we can compute its number of spanning trees in polynomial time using <a href=""http://en.wikipedia.org/wiki/Kirchhoff%27s_theorem"" rel=""nofollow"">Kirchhoff's matrix-tree theorem</a>. Now consider a more complicated setting, in which each of the $n$ nodes in the graph has $m$ versions and each version has different connectivity with the other nodes of the graph. The connectivity between different versions of different nodes can be encoded with a 4-dimensional array <code>A</code> where <code>A[i][k][j][l]</code> is 1 iff the $k$-th version of node $i$ is connected by an edge with the $l$-th version of node $j$. Therefore we have $m^n$ different graphs. We want to compute the total number of spanning trees in these $m^n$ graphs. The brute-force approach that computes the number of spanning trees in each graph separately would require exponential time. My question is whether we can derive a simplified form of the total number such that it can be computed in polynomial time.</p>
",combinatorics
"<p>I have posted this question before but i don't feel i expressed my confusion clearly enough. So i would like to try and explain again. This is a proof of the minimum vertex cover for unit disk graphs being NP-complete.</p>

<p>The following lemma 2.1 is used </p>

<p>Lemma 2.1 (Valiant [19]). A planar graph $G$ with maximum degree 4 can be embedded in the plane using $O(|V|)$ area in such a way that its vertices are at integer coordinates and its edges are drawn so that they are made up of line segments of the form $x=i$ or $y=j$,for integers $i$ and $j$.</p>

<p>So in particular i'm now reading the section on UD vertex cover being NP hard (page 172)</p>

<p>THEOREM: UD Vertex cover is NP-Complete</p>

<p>Proof. The reduction is from PLANAR VERTEX COVER with maximum degree 3, which was shown NP-complete in [4]. As before, we transform the planar graph $G$ with maximum degree 3 to a unit disk graph $G’$ such that $G$ has a vertex cover $S$ with $|S|\leq k$ if and only if $G’$ has a vertex cover $S’$ with $|S'|\leq k’$.</p>

<p>We draw $G$ in the plane using Lemma 2.1. We then replace each edge $\{u, v\}$ by a path having an even number $2k_{uv}$,, of intermediate vertices, in such a way that an intersection model can be constructed. (This is clearly easy to do. Note, however, that a grid graph embedding will not be possible unless G is bipartite, which is why this construction does not work for grid graphs.)
It is straightforward to verify that $G$ has a vertex cover $S$ such that $|S| &lt;k$ if and only if $G’$ has a vertex cover $S’$ such that $|S'|\leq k+\sum_{uv \in E(G)} K_{uv}$.</p>

<p>So here is my confusion, they say the construction doesn't work for grid graphs, grid graphs here are unit disk graphs placed at integer co-ordinates on a grid with radius $1/2$. Firstly i want to make clear that i understand that the vertex cover problem on a grid graph is solvable in polynomial time as it is a bipartite graph. My question is if i placed a vertex at every integer point on the line between vertices $u$ and $v$ (similar to how they place $2k_{uv}$ disks on these lines) i would obtain a grid graph, so why is the problem so fundamentally different? Why does the condition that  $G$ has a vertex cover $S$ such that $|S| &lt;k$ if and only if $G’$ has a vertex cover $S’$ such that $|S'|\leq k+\sum_{uv \in E(G)} K_{uv}$ work for their construction but not for the construction i mentioned i.e where every edge is subdivided by integer co-ordinates to form a grid.</p>
",combinatorics
"<p>Let $A_1,A_2,\ldots,A_m,B_1,B_2,\ldots, B_m$ be (not  necessarily distinct) subsets of $[n]=\{1,2,\ldots,n\}$. Suppose that each $i\in [n]$ appears in at least  $k$ of these $2m$ sets. </p>

<p>I want to find a family of $m$ sets $\{C_i\}_{1\le i\le m}$ to cover $[n]$ (that is $C_1\cup\cdots\cup C_m=[n]$), where $C_i=A_i$ or $C_i=B_i$ for each $1\le i\le m$.</p>

<p>How large $k$ (as a function of $n$) is sufficent for the existence of such a family $\{C_i\}_{1\le i\le m}$. I wonder whether $k&gt;\log_2(n)$ is sufficient.</p>

<p>Is it an 'old' problem? Are there any references?
Thanks in advance for any suggestions.</p>
",combinatorics
"<p>Four Color Theorem is equivalent to the statement: ""Every cubic planar bridgeless graphs is 3-edge colorable"". There is computer assisted proof given by Appel and Haken. Dick Lipton in of his <a href=""http://rjlipton.wordpress.com/2009/04/24/the-four-color-theorem/"">beautiful blogs</a>
<a href=""http://rjlipton.wordpress.com/2009/04/24/the-four-color-theorem/""></a> posed the following open problem:</p>

<blockquote>
  <p>Are there non-computer based proofs of the Four Color Theorem?</p>
</blockquote>

<p>Surprisingly, While I was reading this paper, 
Anshelevich and Karagiozova, <a href=""http://portal.acm.org/citation.cfm?id=1250790.1250849"">Terminal backup, 3D matching, and covering cubic graphs</a>
<a href=""http://portal.acm.org/citation.cfm?id=1250790.1250849""></a>, the authors state that Cahit  proved that ""every 2-connected cubic planar graph is edge-3-colorable"" which is equivalent to the Four Color Theorem (I. Cahit, Spiral Chains: The Proofs of Tait's and Tutte's Three-Edge-Coloring Conjectures. arXiv preprint, math CO/0507127 v1, July 6, 2005).</p>

<blockquote>
  <p>Does Cahit's proof resolve the open problem in Lipton's blog by providing non-computer based proof for the Four Color Theorem?</p>
</blockquote>

<p>Cross posted on cstheory.stackexchange.com as <a href=""http://cstheory.stackexchange.com/questions/2597/human-checkable-proof-of-the-four-color-theorem-closed"">Human checkable proof of the Four Color Theorem?</a>
<a href=""http://cstheory.stackexchange.com/questions/2597/human-checkable-proof-of-the-four-color-theorem-closed""></a> </p>
",combinatorics
"<p>Is the following a standard problem in combinatorics? Where can I find reference for it?</p>

<p>Consider $n$ particles in a circle, $k$ white and $n-k$ black, otherwise indistinguishable so that the number of dispositions is $n!/(n-k)!k!$. Different dispositions will have a different number of white/black/white/black... clusters. How many dispositions $d(N,K,C)$ have C clusters?</p>

<p>Example. $n=4, k=2$ I get:</p>

<p>$d(4,2,2) = 4$</p>

<p>$d(4,2,4) = 2.$</p>
",combinatorics
"<p>Consider a <a href=""http://mathworld.wolfram.com/StronglyConnectedDigraph.html"">strongly connected directed graph</a> $G$.  I have been stuck on the following question:  can you assign real numbers in $[0,1]$ to each edge of $G$ so that the geometric mean of all cycles are equal?  Also, I would like all outgoing edges to sum to 1.</p>

<p>For example, $p=\varphi^{-2}$ is a solution for the graph shown below, where $\varphi$ is the <a href=""http://mathworld.wolfram.com/GoldenRatio.html"">Golden ratio</a>.</p>

<p><a href=""http://i.stack.imgur.com/nmtNX.jpg""><img src=""http://i.stack.imgur.com/nmtNX.jpg"" alt=""enter image description here""></a></p>

<p>The geometric means for the two cycles are $(p\cdot1)^{1/2}=\varphi^{-1}$ and $(1-p)=(1-\varphi^{-2})=\varphi^{-1}$.  The appearance of the Golden ratio here can be explained by observing the relation to sequences with no consecutive 1's (the number of such sequences of length $n$ is approximately $\varphi^n$).</p>

<p>Even though the number of constraints is much larger than the number of variables, I have not been able to construct a counterexample and I also don't know of a simple/direct proof of existence (I am aware of a purported indirect proof that exploits the ergodicity of the Markov chain - I would like to generalize this).  I came across this question in my study of Markov chains.  I have tried many numerical examples, and such a solution always exists (and is unique in my experience).</p>

<p>Any ideas, hints or references would be greatly appreciated!</p>

<p>Question is also on <a href=""http://math.stackexchange.com/questions/1545412/equalizing-geometric-means-of-graph-cycles?noredirect=1#comment3148937_1545412"">math.stackexchange</a> (with some comments, but no answers).</p>
",combinatorics
"<p>For integers $n\ge2$ and $k\ge2$, fix the notation
$$
[m]=\sin\frac{\pi m}{nk+1} \quad\text{and}\quad
[m]!=[1][2]\dots[m], \qquad m\in\mathbb Z_{&gt;0}.
$$
Consider the following trigonometric numbers:
$$
a_i=\frac{[i+k-2]![n-i+k-2]!}{[k-2]![n+k-2]!},
\qquad i=1,2,\dots,n-1.
$$
Is it possible for any $n$ to express the quantities
$$
A_j=1-\frac{[k-1]\cdot [n+k-1]}{[j+k-1]\cdot [n-j+k-1]},
\qquad j=1,2,\dots,n-1,
$$
as a product/quotient of terms of the form
$(1-\text{product of some }a_i)$? If not (for $n\ge4$),
is it possible to prove that?</p>

<p>The affirmative answer is known for $n=2$ and $n=3$.
Namely, if $n=2$ so that we have only one $a_1$ and one $A_1$, then
$$
A_1=1-a_1.
$$
If $n=3$, then
$$
A_j=(1-a_j)(1-a_1a_2) \quad\text{for } j=1,2.
$$
(The last formula is a nice trigonometric identity, by the way.)</p>

<p>My question is motivated (in a very sophisticated way) by a recent
<a href=""http://mathoverflow.net/questions/29117/"">question on Rogers--Ramanujan identities</a>.
The latter one reminded me about the problem of possible $\mathfrak{sl}_n$ generalizations of RRs
in their classical form ""a $q$-sum""=""a $q$-product"". The only cases $n=2$ and $n=3$ are known;
these are the Andrews--Gordon identities and the Andrews--Schilling--Warnaar identities
(see <a href=""http://arxiv.org/abs/math/0410592"">[S. Ole Warnaar, <em>Adv. in Math.</em> <strong>200</strong> (2006) 403--434]</a>).
An indirect implication of such identities is the family of (highly nontrivial)
numerical identities for the dilogarithm function; these come as the limit $q\to1$ specialisation
and some multivariate asymptotics. The trigonometric identities above come into
play from these considerations for $n=2$ and $n=3$; any answer for $n&gt;3$ can shed
some light on the existence of new RRs.</p>
",combinatorics
"<p>It is well-known that the number of surjections from a set of size n to a set of size m is quite a bit harder to calculate than the number of functions or the number of injections. (Of course, for surjections I assume that n is at least m and for injections that it is at most m.) It is also well-known that one can get a formula for the number of surjections using inclusion-exclusion, applied to the sets $X_1,...,X_m$, where for each $i$ the set $X_i$ is defined to be the set of functions that never take the value $i$. This gives rise to the following expression: $m^n-\binom m1(m-1)^n+\binom m2(m-2)^n-\binom m3(m-3)^n+\dots$.</p>

<p>Let us call this number $S(n,m)$. I'm wondering if anyone can tell me about the asymptotics of $S(n,m)$. A particular question I have is this: for (approximately) what value of $m$ is $S(n,m)$ maximized? It is a little exercise to check that there are more surjections to a set of size $n-1$ than there are to a set of size $n$. (To do it, one calculates $S(n,n-1)$ by exploiting the fact that every surjection must hit exactly one number twice and all the others once.) So the maximum is not attained at $m=1$ or $m=n$. </p>

<p>I'm assuming this is known, but a search on the web just seems to lead me to the exact formula. A reference would be great. A proof, or proof sketch, would be even better.</p>

<p><strong>Update.</strong> I should have said that my real reason for being interested in the value of m for which S(n,m) is maximized (to use the notation of this post) or m!S(n,m) is maximized (to use the more conventional notation where S(n,m) stands for a Stirling number of the second kind) is that what I care about is the rough size of the sum. The sum is big enough that I think I'm probably not too concerned about a factor of n, so I was prepared to estimate the sum as lying between the maximum and n times the maximum.</p>
",combinatorics
"<p>The short version of my question is:</p>

<blockquote>
  <p>1)For which positive integers $k, n$ is there a solution to the equation $$k(6k+1)=1+q+q^2+\cdots+q^n$$ with $q$ a prime power?</p>
  
  <p>2) For which positive integers $k, n$ is there a solution to the equation $$(3k+1)(2k+1)=1+q+q^2+\cdots+q^n$$ with $q$ a prime power?</p>
</blockquote>

<p>Now for some motivation.  In <a href=""http://mathoverflow.net/questions/29281/which-steiner-systems-come-from-algebraic-geometry"">this question</a> I ask for an algebra-geometric construction of certain Steiner systems (there's background on what Steiner systems are and on the details and motivation for the construction in that question).  In particular, if the construction can be carried out for a $(p, q, r)$ Steiner system, the blocks of the Steiner system would be given by the $p-1$-plane sections of some variety $X$ in affine or projective space over a finite field $\mathbb{F}_q$.  If $X$ is in affine $n+1$-space and $p=2$, the number of blocks would be given by $1+q+\cdots+q^n$.  Now the number of blocks in a $(2, 3, 6k+1)$ system is $k(6k+1)$ and the number of blocks in a $(2, 3, 6k+3)$ system is $(3k+1)(2k+1)$ (a $(2, 3, n)$ Steiner system is realizable iff $n=1, 3$ mod $6$, $n &gt; 3$).  So the question comes from setting these two quantities equal.</p>

<p>In other words, these equations must be solvable for all $k$ if the algebra-geometric construction of Steiner systems is to go through for all $(2, 3, n)$ systems (the Steiner triple systems) in affine space.</p>

<p>The most general form of this question (which covers both the affine and the projective versions) is:</p>

<blockquote>
  <p>For integers $n, 1 &lt; p &lt; q &lt; r$, when is there a prime power $q$ such that $$\frac{r!(q-p)!}{q!(r-p)!}=\left[n \atop p-1\right]_q$$ or $$\frac{r!(q-p)!}{q!(r-p)!}=\left[n \atop p\right]_q?$$</p>
</blockquote>

<p>Of course, I only expect answers to concentrate on the numbered questions (1) and (2) at the top of the page.</p>

<p>EDIT:  Note that e.g. $k=4$ has no solutions for the first equation.</p>
",combinatorics
"<p>Matthias Lederer and I are studying a deformation of the Littlewood-Richardson product of Schur functions. It's a bit complicated to define (and work in progress) so I won't give the full definition here, but nonetheless my question is: </p>

<blockquote>
  <p>Has the following deformation appeared before?</p>
</blockquote>

<p>We believe the rule for multiplying by a single box is
$$ S_{\square} S_\lambda = \sum_{\nu \supset \lambda,\ \nu\ \subseteq \lambda_+} S_\nu 
$$
where $\lambda_+$ is defined as follows, for $\lambda$ an English partition: draw the $i=j$ line from the NW corner of the partition to where it meets $\lambda$ at $(p,p)$, push all the edges on the NE side of $(p,p)$ one step to the right, all edges on the SW side one step down, and push $(p,p)$ out to $(p+1,p+1)$.</p>

<p>Examples: if $\lambda = (k)$, i.e. a single row, then $\lambda_+ = (k+1,2)$. 
$(3,1,1) \mapsto (4,2,1,1), (3,3,1) \mapsto (4,4,3,1)$.</p>

<p>(There's a similar rule for the $K$-theory product, where $\lambda_+$ is $\lambda$ plus boxes
at all its inner corners. That's not the $\lambda_+$ above.)</p>
",combinatorics
"<p>I would like to know a closed formula for
$\sum_{j=0}^{p-n } (-1)^j\binom{n^2}{p-n-j}
\binom{n+j-1}j\binom{2n+j}{n+j+1}$, especially in the
case $p$ is near $n^2/2$. Similarly, I would like a closed formula for:
setting  $q=2\cdot\lceil\frac{n(n+1)}{4}\rceil -1$,
and setting 
$p=\lceil\frac{q}{2}\rceil-1$,
what is the sum
$
\sum_{j=0}^{p-n } (-1)^j\binom{q}{p-n-j}
\binom{n+j-1}j\binom{2n+j}{n+j+1}
$? </p>

<p>In either case I would be happy for an estimate of the growth of the
sum (divided by $\binom {n^2-1}p$ in the first case, and divided  by
$\binom{q-1}p$ in the second).</p>
",combinatorics
"<p>Consider a big finite rescaled piece of $\mathbb{Z}^2$, i.e. consider a unit square with a thick grid. Famous Wilson's method allows to generate a colored spanning tree of such a graph in a uniform way by popping out the cycles: if the mesh-size tends to 0, then the interesting fractal structure occurs: one can read about this in  <em>R.Lyons, Y. Peres Probability on Trees and Networks</em>. It is said there, that this fractal structure is not yet explained. Could someone point to me some works connected to this question, if there are any?</p>
",combinatorics
"<p>Szekeres and Turán found in 1937 a formula for the sum of the squares and the sum of the fourth powers of determinants of all $n$ by $n$ matrices with $\pm 1$ entries. (The sum of squares case follows easily from Cauchy-Binet identity.) Later Turán <a href=""http://www.ams.org/mathscinet-getitem?mr=73555"">published</a> a simpler proof for the sum of the fourth powers but in Chinese. I vaguely remember that there are simpler probabilistic proofs for both cases. </p>

<p>My question is about simple proofs for these identities, especially the one for 4th powers. </p>

<p>Is there a formula for the 6th power? </p>
",combinatorics
"<p>Is there any known improvement on the Kahn-Kalai-Linial inequality (on the influences of boolean functions) in the special case in which $f$ is the indicator function of an <em>intersecting</em> monotonic set system? More concretely, is there an absolute constant $C&gt;0$ such that the following statement holds:</p>

<blockquote>
  <p>If $f:\mathcal{P}([n]) \to \lbrace 0,1\rbrace$ is the indicator of an intersecting upset, then there exists $x\in [n]$ such that $I_x(f)\geq C/\sqrt{n}$.</p>
</blockquote>

<p>(Note that the ""tribes"" example of a half-sized system in which all influences are $\ll \log n /n$ is certainly not intersecting.)</p>

<p>Background: The $x$th influence of a boolean function $f$ is defined as</p>

<p>$$I_x(f) = \mathbf{E}(f(X)\neq f(X \Delta \lbrace x\rbrace),$$</p>

<p>($\Delta$ is symmetric difference) where $X$ is drawn randomly and uniformly from $\mathcal{P}([n])$. In particular, if $f$ is the indicator of a monotonic set system $\mathcal{U}\subset\mathcal{P}([n])$ (monotonic meaning $X\subset Y$ and $X\in\mathcal{U}$ implies $Y\in\mathcal{U}$), $I_x(f)$ is the number of sets $X\in \mathcal{U}$ containing $x$, minus the number of such sets not containing $x$, divided by $2^{n-1}$.</p>
",combinatorics
"<p>Consider Helly Theorem, taken from <a href=""http://www.math.ucla.edu/~pak/geompol8.pdf"" rel=""nofollow"">notes by Igor Pak</a>:</p>

<blockquote>
  <p>Let $X_1, \dots, X_n \in {\mathbb{R}}^2$ be convex regions in the plane such that any triple interesects $X_i \cap X_j \cap X_k \neq 0$.  Then there is a point in all the sets, $X_1 \cap \dots \cap X_n \neq \varnothing$.</p>
</blockquote>

<p>This result is not obvious (although Pak's proof is short).  However, any explicit collection of sets I build such that three of them intersect, have a clear total intersection.  How about this simpler result, also from Pak's book:</p>

<blockquote>
  <p>Let $P_1, \dots, P_n \in {\mathbb R}^2$ be rectangles with sides parallel to the coordinate axes, such that any two intersect each other.  Then all the rectangles have a nonempty intersection.  </p>
</blockquote>

<p>By Helly's theorem, we only need $n = 3$.  What happens if we don't use Helly's theorem and try to prove this result directly?</p>

<blockquote>
  <p>Let $[x_1, x_1']\times [y_1, y_1'], \dots, [x_n, x_n']\times [y_n, y_n'] \in {\mathbb R}^2$ be rectangles in the plane, sides parallel to the $x,y$-axes, such that:</p>
  
  <p>$x_i &lt; x_j &lt; x_i' &lt; x_j'$ (or vice-versa) and $y_i &lt; y_j &lt; y_i' &lt; y_j'$ (or vice-versa).</p>
  
  <p>Then $x_i &lt; x_j'$ for all $i,j$ and $y_i &lt; y_j'$ for all $i,j$.  So $[\mathrm{max} (x_i) , \mathrm{min} (x_i')] \times [\mathrm{max} (y_i) , \mathrm{min}( y_i')]$ is a rectangle that works.</p>
</blockquote>

<p>Here, it wasn't hard to find that intersection point even without the reduction from Helly's theorem. </p>

<p><hr> What kind of interesting collections of convex sets result in non-trivial uses of Helly's theorem?</p>

<p><img src=""http://s15.postimage.org/8pjy7dfcp/rectangles.gif""/></p>
",combinatorics
"<p>Question. Consider $n \geq 5$ lines in a general position (i.e. no two lines are parallel and no triple intersections are allowed) in $\mathbb{R}^2$. Let $T(n)$ denote the maximal number of empty triangles (here empty triangle means that it does not contain other triangle). What would be best upper and lower bounds for $T(n)$? I know $(n-2) \leq T(n)$ holds, but I am hoping for a better lower bound. Is it true that $n \leq T(n)$? Also, is it possible to compute $T(n)$ it for small $n$ (where small means $6 \leq n \leq 10$)? I think $T(6) = 6$, but I am not able to show $6$ is an upper bound as well.</p>
",combinatorics
"<p>In many problems of enumerative combinatorics, one finds the solution formula that involve complex roots of unity, $\cos(\frac{n \pi }{ k})$ and $\sin(\frac{n \pi }{k})$. Can someone highlight any combinatorial interpretation of such expressions. I haven't find any book or paper highlighting this except some rudiments in papers by Arthur T.Benjamin. (If this question is not appropriate for MathOverflow, I am extremely sorry.)</p>
",combinatorics
"<p>The question is as given in the title:</p>

<blockquote>
  <p>Which finite groups are not the automorphism group of some rooted finite tree?</p>
</blockquote>

<p>A rephrasing could be: Is any finite group representable as the automorphism group of a finite tree? If not, what is typically unrepresentable?</p>

<p>In case of ambiguity: 
a homomorphism of finite rooted trees must preserved the root, and so does an isomorphism which is called an automorphism.</p>

<p><strong>Context</strong>:<br>
The motivation/spirit of the question is as follows. I make the isomorphism classes of finite graphs smaller by specifying a group acting on the graph's vertices, that is an isomorphism must now respect the group action (instead of the bigger $S(n)$ action).
Do I lose something by restricting myself to tree automorphisms instead of considering the group action?</p>
",combinatorics
"<p>Is it true that given a finitely presented group $G$, either all primes
or only finitely many of them occur as orders of elements of $G$?</p>
",combinatorics
"<p>We have a regular graph $G$ of degree $m$  on $n$ vertices and we label each of its vertices with the number $1$ through $n$. What can we say about the maximum difference between the numbers of two adjacent vertices. What is the maximum and minimum, what is the minimum for a specific graph?</p>
",combinatorics
"<p>The question is the following: how many subsets of size $5$ from a set $A$ of size $16$ do we need so that any subset of size 2 of $A$ is also a subset of one of the selected subsets of size $5$?</p>

<p>How does this the required number change as we change 16 to another number and if we change $5$ to another number? Perhaps an even harder question is if we change $2$ to another number.</p>
",combinatorics
"<p>We are given $n$ coins, some of which are ""real"" and weigh $1$ and some of which are ""fake"" and weigh $0$.  We have one ""spring scale"" which can weigh any subset of the coins. A classic question asks what the minimum number of weighings is that will separate the real coins from the fake ones.  This question is essentially identical to <a href=""http://mathoverflow.net/questions/157634/number-of-vectors-so-that-no-two-subset-sums-are-equal/157650"">Number of vectors so that no two subset sums are equal</a> and the optimal number of weighings is known to be asymptotic to</p>

<p>$$\frac{2n}{\log_2{n}}.$$</p>

<p>The linked question contains a reference to <a href=""http://www.cs.mcgill.ca/~colt2009/papers/004.pdf"" rel=""nofollow"">Bshouty</a> where further details and an interesting historical account can be found.  The original paper of Erdős and R\'enyi discussing this coin weighing problem is also <a href=""http://combinatorica.hu/~p_erdos/1963-12.pdf"" rel=""nofollow"">available</a>.</p>

<p>For a fixed $n$, a (non-adaptive) solution to this coin weighing problem can be written as a $(0,1)$-matrix, with each column corresponding to a coin and each row corresponding to a single weighing. The number of rows is then the number of weighings.   In order for such a matrix to solve the problem, it must not contain any non-zero $n$-dimensional $(-1,0,1)$-vector in its kernel. Clearly, the identity matrix, for example, always satisfies this property and is a trivial solution for any $n$. </p>

<p>In my setting, I would like to solve the same coin weighing problem but I need any solution matrix to be (partial) ciculant. For example, consider $n=4$ and the following partial ciculant solution.</p>

<p>\begin{pmatrix}
0&amp;1&amp;1&amp;1\\
1&amp;0&amp;1&amp;1\\
1&amp;1&amp;0&amp;1
\end{pmatrix}</p>

<p>This tells us that it is possible to solve the problem with $3$ weighings when $n=4$ and in fact this is optimal. </p>

<p>For this new circulant variant of the coin weighing problem I don't know anything except for particular small values of $n$ where I have manually computed the answer.  However, these results are not particularly revealing except to tell us that the optimal number of weighings is not identical to the general case. For example, the problem can be solved in $7$ weighings for $12$ coins in the general case but you need $8$ weighings for the circulant case.</p>

<p>We know of course that an asymptotic lower bound is still $2n/\log_2{n}$.  But an upper bound seems much less clear. As a first question:</p>

<blockquote>
  <p>Is the optimal number of weighings sublinear in $n$?</p>
</blockquote>

<p>If this is true, then it would very interesting to know if the asymptotics differ from the general case.</p>

<blockquote>
  <p>Is the optimal number of weighings still $O(n/\log_2{n})$?</p>
</blockquote>

<p>This question is related to the second part of <a href=""http://mathoverflow.net/questions/207043/two-conjectures-about-zero-inner-products-and-dissociated-sets"">Two conjectures about zero inner products and dissociated sets</a> and can be seen as a variant of Conjecture 2.</p>

<hr>

<p>A helpful answer was given with respect to a sparse version of this problem. However, I am really interested in the general non-sparse version where  a solution matrix is guaranteed always to be able to separate the real and the fake coins.</p>

<hr>

<p><strong>Added 25 June 2015</strong></p>

<p>Before addressing the questions above, is it possible to answer the following potentially easier question?</p>

<blockquote>
  <p>Does there exist a number of coins $n$ such that the optimal number of
  weighings is less than $n/2$?</p>
</blockquote>
",combinatorics
"<p>[Question edited and changed a little on June 14 2015]</p>

<p>Consider an $n$-dimensional vector $v$ with $v_i \in \{-1,1\}$.  Now consider an $n$-dimensional vector $w$ with  $w_i \in \{-1,0,1\}$.  The elements $w_i$ are sampled independently so that $P(w_i = -1) = P(w_i = 1) = 1/4$ and $P(w_i=0) = 1/2$. The elements $v_i$ are sampled independently so that $P(v_i = -1) = P(v_i = 1) = 1/2$.   </p>

<p>Indexing from $0$, we now define $C_i = \sum_{j=0}^{n-1} w_j v_{i+j \bmod n}$ to be the  inner product between $w$ and the $i$th rotation of $v$.  It may be helpful to think of both $v$ and $w$ as lying on a discrete circle of circumference $n$ so that the rotation of a vector has a natural visual interpretation. We know that $P(C_i = 0) \sim 1/\sqrt{\pi n}$.</p>

<p>I would like to understand the probability that $C_i = 0$ for many consecutive values of $i$. </p>

<p>To this end we can look at </p>

<p>$$z_i=P(C_i = 0 \mid \forall j &lt; i \; C_j=0 ).$$</p>

<p>Let us define $z_0 = P(C_i = 0) \sim 1/\sqrt{\pi n}$ and we know that $z_{n} = 1$.  With a little effort we can also see that </p>

<p>$$z_1 \sim \frac{2}{\sqrt{\pi n}}.$$</p>

<p>The value $z_i$ gives us some indication of the degree of independence of the events $(C_i=0)$.  In particular, my current intuition is that the events $(C_i=0)$ are not too far from being independent for the first few values of $i$ and then once you have a lot of previous zero inner products they become highly dependent. </p>

<p>It appears numerically that $z_2 \sim 2/\sqrt{\pi n}$ although I don't know how to prove this.  This leads to my first question:</p>

<blockquote>
  <p>Assuming $n$ is large, for which $i$ can we approximate $z_i$?</p>
</blockquote>

<p>I am particularly interested in $i \leq n/\log_2{n}$. We know that the probability that all $n$ inner products are zero must be at least $2^{-n}$ as that is the probability that $w$ is all zeros. Therefore there cannot be many more than $n/\log_2{n}$  values of $i$ such that $z_i \approx C/\sqrt{n}$.  If there were there would be a contradiction. My guess is that in fact all the first approximately $n/\log_2{n}$ values of $z_i$ are approximately of this form, This leads to my second question. </p>

<blockquote>
  <p>Does there exist a constant $c\geq 1$ so that for all sufficiently large $n$,  $$P{\left(\forall i \leq \frac{n}{\log_2{n}}, C_i = 0\right)} \leq  2^{-\frac{n}{c}}.$$</p>
</blockquote>
",combinatorics
"<p>Let $q$ be a power of a prime.  It's well-known that the function $B(n, q) = \frac{1}{n} \sum_{d | n} \mu \left( \frac{n}{d} \right) q^d$ counts both the number of irreducible polynomials of degree $n$ over $\mathbb{F}_q$ and the number of <a href=""http://en.wikipedia.org/wiki/Lyndon_word"">Lyndon words</a> of length $n$ over an alphabet of size $q$.  Does there exist an explicit bijection between the two sets?</p>
",combinatorics
"<p>This is a simple question I asked in math.SE last month but unfortunately no one gives any comment. So I decided to try some luck here.
<strong>You can skip examples below and read from ""General setting"" at the bottom</strong>.</p>

<p>Given a smooth arc (part of an ellipse actually) on the complex plane by </p>

<blockquote>
  <p>$z=\cos t + 0.5 i \sin t,\; t\in[\pi/10,\pi/5] $ , </p>
</blockquote>

<p>and a non-analytic function 
$f(z) = \text{Re } z $  defined on the arc.
Obviously, $f(z) = g(t) := \cos t.$<br>
Suppose we compute the ""derivatives"" of $f$ on the arc recursively by<br>
$f'(z) = g'(t)/z'(t),\quad$
$f''(z) = \dfrac{df'(z)}{dt}\dfrac{1}{z'(t)},\quad$
$f'''(z) = \dfrac{df''(z)}{dt}\dfrac{1}{z'(t)},\quad \dots$</p>

<p>Is there an estimate on the upper bound of magnitude of $n^\text{th}$ order derivative of  $f$ ? 
For example, can we show something like </p>

<blockquote>
  <p>$|f^{(n)}(z)|\leq C n! r^n $, where $C$ and $r$ are positive constants independent of $n$  ?</p>
</blockquote>

<p>Note that in the case above the form of $f$ is really simple. 
If $f$ is more complicated, for  example, $f\circ z(t) := \frac{|z'(t)|}{z'(t)}$,
what can we say about $|f^{(n)}(z)|$ ?</p>

<p><strong>Update:</strong> According To Fedor's answer, function $f$ in first example actually coincides with an analytic function on the arc. I need to modify the curve  so that it is not easy to find an analytic function that coincides with $f$ on the curve.</p>

<p><strong>New curve:</strong>
Suppose the smooth arc is given by </p>

<blockquote>
  <p>$z(t) = [1+0.5\cos(4t)]\cos t + i [1+0.5\sin(4t)]\sin t,\quad t\in[\frac{\pi}{8},\frac{3\pi}{8}],$</p>
</blockquote>

<p>and the function $f$ defined on the arc is given by  </p>

<blockquote>
  <p>$f\circ z(t) := \frac{|z'(t)|}{z'(t)}$.</p>
</blockquote>

<p>With derivatives for $f$ defined recursively as before, can we derive an upper bound for $\lvert f^{(n)}(z) \rvert$ as above ?</p>

<p><strong>General setting:</strong><br>
Given a smooth Jordan arc parametrized by $z(t)$ 
on complex plane with $z'(t)\neq 0,\; t\in [0,1]$,
and a smooth function $f$ defined on the arc in the sense that $f\circ z(t) \in C^\infty$. 
Define derivatives of $f$ recursively as above, namely, let $g(t):=f\circ z(t)$,</p>

<blockquote>
  <p>$f'(z):= g'(t)/z'(t), \quad f''(z):= \dfrac{df'(z(t))}{dt}\dfrac{1}{z'(t)},\quad f'''(z) = \dfrac{df''(z(t))}{dt}\dfrac{1}{z'(t)},\quad \dots$</p>
</blockquote>

<p>and we ask if there is an estimate</p>

<blockquote>
  <p>$||f^{(n)}(z)||_\infty \leq C n! r^n $, where $C$ and $r$ are positive constants independent of $n$  ?</p>
</blockquote>

<p>In addition, suppose there exists an analytic function $F$ that equals $f$  on the arc as in Fedor's answer. Can we derive the upper bound on $||f^{(n)}(z)||_\infty$ only using recursive definition for $f^{(n)}(z)$ above instead of resorting to Cauchy's formula ? 
Why we want to do this  is because if we use Cauchy's formula, 
then the constant $C$ in the estimate will depend on function values of $F$ outside the arc $\gamma$, which are unknown unless an explicit expression for $F$ is derived and also $r$ must depend on the region of analyticity of $F$, which is again not so traceable. It is to be hoped that the inequality can be proved in a manner such that  the dependence of $C,r$ on $f,\gamma$ can be shown.</p>
",combinatorics
"<p>Let $q_i$ for $i=1,\ldots,m$ be the columns of the matrix $Q\in\mathbb{R}^{n\times m}$, $n\geq 2m$, which are pairwise orthonormal ( i.e.
$q_i^\top q_j = \begin{cases} 1 &amp; \text{if}\quad i=j \\ 0 &amp; \text{otherwise} \end{cases})$.</p>

<p>Further let $P\in\{0,1\}^{n\times n}$ be a permutation matrix and
$$M=Q^\top P^\top Q\;.$$
How does the permutation $P$ has to be designed, so that the maximum singular value
$$\sigma_{\text{max}}(M)&lt;1\text{ ?}$$</p>

<p><em>Background</em></p>

<p>$\sigma_{\text{max}}(M)=\cos(\theta_{\text{min}})$, where $\theta_{\text{min}}$ is the minimal principal angle between the spaces spanned by the columns of $Q$ and $P^\top Q$. So, if $P$ is the identity matrix the columns of $Q$ and $P^\top Q$ span the same space, so that $\theta_{\text{min}}=0$ and $\sigma_{\text{max}}(M)=1$. Of course, there are other permutation which lead to $\sigma_{\text{max}}(M)&lt;1$. So I could also ask: How to choose $P$, so that the minimal angle between $\mathcal{R}(Q)$ and $\mathcal{R}(P^\top Q)$ is $\theta_{\text{min}}&gt;0$ ? ($\mathcal{R}=$ range) </p>
",combinatorics
"<p>In the mathoverflow question <a href=""http://mathoverflow.net/questions/222793/how-large-can-a-subset-of-1-ldots-n-be-if-all-pairwise-lcms-of-its-elemen"">here</a> the asymptotic growth of antichains in the divisibility poset ${\cal P}_n$ of the set of natural numbers $\{1,\ldots,n\}$ is considered. I have a somewhat dual question.</p>

<p>Consider a ``packing'' of disjoint singly generated ideals (upsets) ${\cal C}_x$ where $${\cal C}_x=\{x,y_1 x, y_1 y_2 x, \ldots \} \in \{1,2,\ldots,n\}$$ with $y_i$ natural numbers greater than 1. To be precise, an ideal $\cal C$ is a collection of sets such that if $A\in {\cal C}$ and $A \subset B$ we have $B \in {\cal C}$. I consider only ideals generated by a single integer $x,$ which I call ${\cal C}_x$ and I consider only the integers $\{1,\ldots,n\}$ not the whole set of natural numbers.</p>

<p>Thus, $x$ is the minimal element in the ideal ${\cal C}_x$ and I require that
${\cal C}_{x'}\cap {\cal C}_x=\emptyset$ whenever $x \neq x'.$ The cost of an ideal ${\cal C}_x$ is simply </p>

<p>$f({\cal C}_x)=1/x $ </p>

<p>where $x$ is its minimal element. I want to find a collection of disjoint ideals ${\cal M}=\{C_{x_1},\ldots,C_{x_m}\}$ which <strong>maximizes</strong> the cost $$f({\cal M})=\sum_{i=1}^m f(C_{x_i})=\sum_{i=1}^m \frac{1}{x_i}$$ for large $n$.</p>

<p><strong>Edit 1:</strong> There is a side condition to the maximization, which I forgot to write, sorry. To be able to include both $x\neq x'$ in $\cal M$ they must not divide each other in addition to their LCM being strictly greater than $n$. </p>

<p><strong>Edit 2:</strong> It seems to me the condition in Edit 1 is superfluous, since if  $LCM(x,x')$ is strictly larger than $n$ the condition of either of $x,x'$ not dividing the other is automatically satisfied. However, subsets of $\{1,\ldots,n\}$ where no element of the subset divides another have been investigated for a long time, under the terminology ``primitive sets''. So I suppose I am asking about how small can $f({\cal M})$ be, in comparison to primitive sets which achieve $f$ of $O\left(\frac{\log n}{\sqrt{\log \log n}}\right)$</p>

<p>An upper bound of $\lceil \frac{n+1}{2}\rceil$ is known on the <strong>size</strong> of a collection obeying this LCM condition, see this previous MO question <a href=""http://mathoverflow.net/questions/222793/how-large-can-a-subset-of-1-ldots-n-be-if-all-pairwise-lcms-of-its-elemen"">here</a>.
However, the size maximizing sets that are easy to find are essentially mostly integers from $[n/2,n]$ and the value of $f$ they give is constant (since it is $H_n-H_{n/2}$). However, it is known that for so called <strong>primitive sets</strong> in $\{1,\ldots,n\}$ considered by Behrend, Erdos and others (sets of integers satisfying the non-divisibility conditions) the value of $f$ is proved to be asymptotically $\frac{\log n}{\sqrt{\log \log n}}$. </p>

<p>It seems like some pruning of primitive sets by removing their members in $[2,\sqrt{n+1})\cap \mathbb{N}$ and pruning multiples of small primes we should get a collection with cost $f$ possibly not much lower than primitive sets.</p>
",combinatorics
"<p>This question is closely related to MO <a href=""http://mathoverflow.net/questions/4347/ffxexpx-1-and-other-functions-just-in-the-middle-between-linear-and-expo"">f(f(x))=exp(x)-1 and other functions “just in the middle” between linear and exponential.</a> Consider $e^{e^x-1}$, this is the generating function of the Bell numbers. A more general way to look at Bell numbers is as rooted trees, hierarchies of height 2. Given $g(x)=e^x-1$, $g^n(x), n \in \mathbb{N}$ is the generating function of hierarchies of height n. See page 107 - 110 of <a href=""http://algo.inria.fr/flajolet/Publications/books.html"" rel=""nofollow"">Analytic Combinatorics</a>. The ECS should have the integer sequences associated with hierarchies of different heights. Also see OEIS </p>

<pre>
    Integer sequence                      height OEIS
    {1,1/2,1/8,0,1/32,-7/128,1/128,159/256}  1/2 A052122
    {0,1,1,1,1,1,1,1,1}                        1
    {1,2,5,15,52,203,877,4140}                 2 A000110
    {1,3,12,60,358,2471,19302,167894}          3 A000258
    {1,4,22,154,1304,12915,146115,1855570}     4 A000307
    {1,-1,2,-6,24,-120,720,-5040}             -1 A000142
    {1,-2,7,-35,228,-1834,17582,-195866}      -2 A003713 
</pre>

<p>Several solutions for $f(f(x))=e^x-1$ have been proposed on MO, but the work of <a href=""http://www.ams.org/mathscinet-getitem?mr=97532"" rel=""nofollow"">I.N. Baker</a> is cited as proving that $f(x)$ has no convergent solution, ""even in an ϵ-ball around 0."" I am currently trying to read the original German, to understand Baker's proof.</p>

<p><strong>Question 1</strong> Could someone summarize Baker's proof? It is frequently referred to and an explanation in English would be wonderful. </p>

<p><strong>Question 2</strong> Formal power series can contain useful information, even if the are divergent. It seems that divergent series are not treated with quite the contempt they used to be. I believe on the Tetration Forum that someone raised the possibility of $f(x)$ being Borel summable. What are the potential options for ""rehabilitating"" a series that is not nicely convergent.</p>

<p><strong>Question 3</strong> If $g(x)=e^x-1$, $g^n(x), n \in \mathbb{N}$ is the generating function of hierarchies of height n, doesn't $g(x)=e^x-1$, $g^n(x), n \in \mathbb{R}$ consists of labeled rooted trees of fractional height? So shouldn't $f(x)=g^\frac{1}{2}(x)$ be the generating function for labeled rooted trees of height $\frac{1}{2}$?<br>
Doesn't the divergence of $f(x)=g^\frac{1}{2}(x)$ imply that a label rooted tree of height $\frac{1}{2}$ have infinitely many leaves, that the width of the tree is infinite. Can't be use the fact that we are working with a labeled rooted tree to constrain the width of the tree from becoming infinite?</p>
",combinatorics
"<p>It is well discussed in many graph theory texts that it is somewhat hard to distinguish non-isomorphic graphs with large order. But as to the construction of all the non-isomorphic graphs of any given order not as much is said. So, it follows logically to look for an algorithm or method that finds all these graphs. </p>

<p>A Google search shows that a paper by <a href=""http://www.moreheadstate.edu/files/colleges/science/mcs/mejam/dewet.pdf"" rel=""nofollow"">P. O. de Wet</a> gives a simple construction that yields approximately $\sqrt{T_n}$ non-isomorphic graphs of order n.</p>

<p>( $\{T_n}$ being the number of labeled graphs of order n.)</p>

<p>So, I have the followings to ponder over: </p>

<p>(1) Are there such algorithms or has there been an improvement on the aforementioned algorithm?</p>

<p>(2) Where can I find a collection of non-isomorphic graphs of a given order?  </p>

<p>If you allow me, I would also like to extend my question to connected graphs. </p>

<p>Many thanks. </p>

<p>(I am a beginner in Graph theory, so please give answers in not-very-specialized terms.)</p>
",combinatorics
"<p>Define a 2 x n array of positive integers where the first row consists 
of some distinct positive integers arranged in increasing order, and the second row consists of any positive 
integers in any order.  Create a new array where the first row consists of all the integers that occur in the first array,
arranged in increasing order, and the second row consists of their multiplicities.<br>
Repeat the process.   For example, starting with the 
2 x 1 array [1; 1], the sequence is:
[1; 1] -> [1; 2] -> [1, 2; 1, 1] -> [1, 2; 3, 1] -> [1, 2, 3; 2, 1, 1]
-> [1, 2, 3; 3, 2, 1] -> [1, 2, 3; 2, 2, 2] -> [1, 2, 3; 1, 4, 1] -> 
[1, 2, 3, 4; 3, 1, 1, 1] -> [1, 2, 3, 4; 4, 1, 2, 1] -> [1, 2, 3, 4; 3, 2, 1, 2]
-> [1, 2, 3, 4; 2, 3, 2, 1], and we now have a fixed point (loop of one array).</p>

<p>Does the process always result in a loop of 1, 2, or 3 arrays?</p>
",combinatorics
"<p>Let $q \geq 2$.  What does the expression $(q^n-1)(q^n-q)(q^n-q^2)(q^n-q^3)\ldots(q^n-q^{n-1})/n!$ count?  If $q$ is a prime power, then this is
the number of bases of an $n$-dimensional vector space over a field with $q$ elements.</p>
",combinatorics
"<p>Consider a rectangular $(m \times n)$ matrix $\underline E_1$ with $m &lt; n$ that has only $0$ or $1$ entries. It has exactly one $1$ entry in each row and not more than one $1$ entry in each column. Consider it being a selection of $m$ rows out of a $(n \times n)$ permutation matrix $\underline P$.</p>

<p>Given $\underline E_1$ I'm looking for an elegant way to describe the set $\mathcal{P}$ of $((n-m) \times n)$ matrices so that any $\underline E_2 \in \mathcal{P}$ combined with $\underline E_1$, like so</p>

<p>$\underline E = \begin{pmatrix} \underline E_1 \\\ \underline E_2 \end{pmatrix}$</p>

<p>forms a valid $(n \times n)$ permutation matrix $\underline E$, i.e. something like $\mathcal{P} = \operatorname{percomp}_n( \underline E_1 )$ (there are $(n-m)!$ elements in $\mathcal{P}$)</p>

<p>Is there anything like this used in mathematical parlance already?</p>
",combinatorics
"<p>This is a crosspost of <a href=""http://math.stackexchange.com/questions/446470/combinatorics-of-resultants"">http://math.stackexchange.com/questions/446470/combinatorics-of-resultants</a> which received no answer. [<strong>EDIT:</strong> I deleted the initial copy of the question on MathSE].</p>

<p>Let $f(z)=\sum_{i=0}^{D_f}x_iz^i$ and $g(z)=\sum_{i=0}^{D_g}y_iz^i$ be two polynomials. I would like to know the number of monomials (in the variables $x_i$ and $y_i$) in the resultant in $z$ of $f$ and $g$. Equivalently, this is the number of monomials in the determinant of the Sylvester matrix:
$$
\left(
\begin{array}{ccccccccc}
x_0 &amp; x_1 &amp; x_2 &amp; \cdots &amp; x_{D_f} &amp; 0 &amp; 0 &amp; \cdots &amp; 0\\
0 &amp; x_0 &amp; x_1 &amp; \cdots &amp; x_{D_f-1} &amp; x_{D_f}&amp; 0 &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \ddots &amp;\cdots &amp;\ddots &amp;\ddots &amp; \ddots &amp;\cdots &amp;\vdots\\
y_0 &amp; y_1 &amp; y_2 &amp; \cdots &amp; y_{D_g} &amp; 0 &amp; 0 &amp; \cdots &amp; 0\\
0 &amp; y_0 &amp; y_1 &amp; \cdots &amp; y_{D_g-1} &amp; y_{D_g}&amp; 0 &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \ddots &amp;\cdots &amp;\ddots &amp;\ddots &amp; \ddots &amp;\cdots &amp;\vdots\\
\end{array}
\right).
$$</p>

<p>I think there is a classical answer to this problem (I even seem to recall having seen it once) but I can't find a pointer to it. Can anyone point me either to a closed form or even better a tight and simple upper bound on this number of monomials ?</p>
",combinatorics
"<p>Inspired by this <a href=""http://mathoverflow.net/questions/137109/generating-functions-for-reduced-words"">question</a>, I have been wondering if there are any useful generating functions with all non-zero coefficients equal to one. Obviously, the trivial generating function $\frac{1}{1-x}$ has significant applications, as do monomial symmetric functions but for the purposes of this question, we should ignore them. As Graham has commented, indicator functions also fall into this category. The best formulation I can think of for why these should be ignored is that they are most interesting for the purpose of taking products of generating functions, rather than being directly used for computation.</p>

<p>More specifically, such a generating function would (in my mind) have to be multi-variate, enumerate some object of interest and facilitate computations related to that object in a situation where direct computation is not straightforward. As an example of what I would consider cheating, by specializing many variables to one, the generating function in the aforementioned question allows for computing joint distributions of entries in a reduced word with great ease. However, to compute the generating function, it seems to me one would have to enumerate all such words anyways, hence no labor is saved. Were this not the case, this function would be an excellent example.</p>

<p>What would be an example of such a generating function where computation is assisted without being embedded in constructing the generating function? Even if the generating function serves as a useful book keeping device, that would be okay.</p>

<p>Please comment below with any suggested improvements for what should define a ""useful"" generating function. Explanations for why such a function cannot exist are welcome as well.</p>

<p>Edit 1: Added Graham's comment on indicator functions.</p>
",combinatorics
"<p>Let $V$ be a real representation of a finite group $G$.</p>

<p>Define  $\mathbb Z[I]_{I\leq G}$ to be the ring over the integers generated by subgroups of $G$ with multiplication corresponding to intersection of subgroups.</p>

<p>Associate an element $\sigma_V\in \mathbb Z[I]_{I\leq G}$ so that 
$$\sigma_V= \sum_{I\leq G} n_II$$
and for all subgroups $H$ of $G$, the following equality holds:
$$\sum_{I\geq H}n_I=(-1)^{dim V^H}$$</p>

<p>Question: Is $\sigma_V$ some standard representation theoretic thingy? (My knowledge of representation theory doesn't go much further than Wikipedia...)</p>

<p>I am using $\sigma_V$ as a kind of generalized sign of the determinant of complex conjugation on $V\oplus iV$. I think that it has the following nice properties:
$$\sigma_{V\oplus W}=\sigma_V\sigma_W$$
$$\sigma_V^2=1G$$</p>

<p>If $I\leq G$ is normal, then $n_I$ is an integer divisible by the index of $I\leq G$.
A second question: is $n_{\{1\}}$ always $0$ or $\pm \lvert G\rvert$? This is the case in the few examples I have computed, but I have no general reason to expect it to be true.</p>

<p>For example: if $G=S_n$, and $\rho$ is the representation which permutes the coordinates of $\mathbb R^n$, then $n_I=(-1)^k k!$ if $I$ is a subgroup of $S_n$ corresponding to partitioning $\{1,\dotsc,n\}$ into $k$ nonempty subsets, and $n_I=0$ otherwise. </p>
",combinatorics
"<p>An easy question that I have never been able to answer.
Suppose we have the CA on $\{ 0,1,2 \}^{\mathbb{N}}$ with local rule given by $f(x,y)=A_{x,y}$ and $A$ the $3\times 3$ matrix $A=(0,1,2,0,1,2,1,2,0).$ For example $(0,1,2,0,0,0,1,2,0,\ldots)\mapsto (1,2,1,0,0,1,2,1,\ldots),$ It is like a shift if the coordinate before is $0$ or $1$ and $x+1$ mod 3 if not.
My question is, are there any invariant probability measures full supported other that the Haar measure? I have never seen an idea to solve this problem, so any reference is welcome.</p>
",combinatorics
"<p>We have a simple graph with vertices $\{v_1, v_2, ... v_n\}$.</p>

<p>The adjacency matrix of this graph is $A= (a_{ij})$ so that</p>

<ul>
<li><p>$a_{ij}=1$    if      $i+j$ belongs to the Fibonacci sequence;</p></li>
<li><p>$a_{ij}=0$   if      $i+j$ doesn't belong  to the Fibonacci sequence.</p></li>
</ul>

<p>We claim that the determinant of this matrix is $0$ when $n$ is odd. And that when $n$ is even, it is $1$, $-1$ or $0$.</p>

<p>How can we prove this claim?  </p>

<p><strong>Edit:</strong> <a href=""http://math.stackexchange.com/questions/300379/prove-the-determinant-of-this-matrix"">on MSE</a>, the OP added that $a_{ii}=0$ along the diagonal which is confirmed by the OP's observation that the determinant should be zero in the odd case (e.g. $n=1,3$ do yield $0$ then). So in particular, this is not a Hankel transform.</p>
",combinatorics
"<p>Let $G=(V,E)$ be an undirected graph and $p \colon E \mapsto (0,1]$ defines weights of its edges.</p>

<p>Let's fix two connected vertices $v_1, v_2 \in V$.</p>

<p>Random graph $G'=(V,E')$ is obtained from $G$ by removing each edge $e \in E$ with probability $1-p(e)$.</p>

<p>What is the probability that connectivity between $v_1$ and $v_2$ is preserved in $G'$?</p>
",combinatorics
"<p>Let $X$ be an alphabet and denote by $X^{\omega}$ the set of all infinite sequences (i.e. words) in $X$. A subset $L \subseteq X^{\omega}$ is called <a href=""http://en.wikipedia.org/wiki/Omega-regular_language"" rel=""nofollow"">$\omega$-regular</a> if it is acceptable by some Büchi-Automaton, equivalently if it is of the form 
$$
 L = \bigcup_i^n U_i V_i^{\omega}
$$
for <a href=""http://en.wikipedia.org/wiki/Regular_language"" rel=""nofollow"">regular languages</a> $U_i, V_i$ in the usual sense, also $L$ is regular iff it is acceptable by a Müller-Automata (see <a href=""http://en.wikipedia.org/wiki/%CE%A9-automaton"" rel=""nofollow"">Wikipedia</a>).</p>

<p>Let $\xi \in X^{\omega}$ be some infinite word, denote by $A(\xi)$ the set of its prefixes,
these are finite words and so $A(\xi) \subseteq X^*$, likewise define $F(\xi)$ to be the set of factors of $\xi$.</p>

<p>Now define the following language operator (called <em>adherence</em>) on $X^{\omega}$:
$$
 \mbox{Adh}(L) := \{ \xi \in X^{\omega} : A(\xi) \subseteq A(L) \}.
$$
It is $\xi \in \mbox{Adh}(L)$ iff every prefix of $\xi$ is the prefix of some word from $L$. Now if $L$ is $\omega$-regular, $A(\xi)$ is $\omega$ regular too, if given a Büchi-Automata for $L$ just declare every state on an acceptance path (i.e. a path having an infinite number of final states) a final state too, the automata with the usual acceptance condition for finite words accepts $A(\xi)$. Now $\mbox{Adh}(L)$ is accepted by this automaton according to the Büchi-condition.</p>

<p>I want to generalise this, define the operator
$$
 \mbox{Adh}_F(L) = \{ \xi \in X^{\omega} : F(\xi) \subseteq F(L).
$$
It is $\xi \in \mbox{Adh}_F(L)$ iff every factor of $\xi$ is a factor of some word from $L$. Now I want to know</p>

<blockquote>
  <p>If $L$ is $\omega$-regular, is $\mbox{Adh}_F(L)$ also $\omega$-regular?</p>
</blockquote>

<p>I conjecture that in general not to be true, because to test an infinite word $\xi$ for this condition, if the automaton would read the $n$-te symbol, it need to trace back to 
to all the position $1,2,\ldots, n$ of $\xi$ and test from them if the factor starting at this position and ending at the $n$-th position is contained in $F(L)$, but in general a finite automata can not save the last $n$-th positions for abitrary $n$.</p>

<p>On the other side I am not able to represent some known non-regular languages as $\mbox{Adh}_F(L)$, and furthermore for a regular set $L$ the set $F(L)$ is regular too (given an automata for $L$ on every path which is final, i.e. leads to a final state, put an <a href=""http://en.wikipedia.org/wiki/Nondeterministic_finite_automaton_with_%CE%B5-moves"" rel=""nofollow"">$\varepsilon$-transition</a> from the start state to that state). So maybe I have overlooked some property of factor sets which make $\mbox{Adh}_F$ regular...</p>
",combinatorics
"<p>For given $g$, consider the family of graphs which may be embedded to the compact orientable surface of genus $g$. For this family, consider maximal clique $\alpha(g)$, maximal chromatic number $\chi(g)$ and maximal choice number $cn(g)$. Famous results are $\alpha(g)=\chi(g)=[(7+\sqrt{1+48g})/2]$ for all $g$ (Heawood conjecture), and $cn(0)=5$ (upper bound due to Thomassen). What is known for values of $cn(g)$ with $g&gt;0$?</p>
",combinatorics
"<p>I'm interested in knowing if finding the edge-chromatic number of a $k$-uniform $k$-partite hypergraph is NP-hard for $k\geq 3$ Could anyone provide a reference for the result? By edge-chromatic number i mean the smallest number of colours assigned to the edges such that incident edges receive different colours.</p>
",combinatorics
"<p>I was wondering if anyone could provide references on the following:</p>

<ol>
<li>Is determining the chromatic number of a bounded degree graph APX-complete? </li>
</ol>

<p>2.I've seen the result that states it is NP-hard to decided whether a $4$ bounded graph is $3$ colourable. In general for a $d$ bounded degree graph which positive integers $k$ is it NP-hard to determine whether the graph is $k$-colourable?</p>
",combinatorics
"<p>Does a positive real number $k\geq1$ exist such that for every finite set $P$ of points in the plane (with the property that no three points of $P$ lie on a common line and $|P|\geq3$), one can choose a subset $Q$ of $P$ with
$|Q| \geq |P|/k$
points and with the property that there exist two different points $a$ and $b$ in $Q$ such that no line $\overline{(p,q)}$ through two different points $p,q$ of $Q\backslash\{a,b\}$ crosses the interior of the segment $(a,b)$?</p>

<p>If such a number exists, what is the smallest integer $k$, fulfilling the property?</p>

<p>If you take a set $P=\{a,b,c\}$ with three points, then you can set $P=Q$ since no line crosses the interior of the segment $(a,b)$. However, a counterexample for $k=1$ is given below by Reid Barton.</p>
",combinatorics
"<p>The Frobenius coin problem guarantees that if $(a,b)=1$, then
$$ax+by$$ does not represent exactly $\frac{(a-1)(b-1)}2$ numbers all below $g(a,b)=ab-a-b$ if $x,y\geq0$ holds.</p>

<p>Assume $m\in[0,ab-a-b]$ and assume $\max\big(\frac a b,\frac ba\big)&lt;2$.</p>

<p>Approximately what fraction of numbers less than $m$ is represented by $ax+by$? In other words what is a good point-wise approximation to the function
$$f_{a,b}(m)=\big|\{n\in\Bbb N_{\leq m}:\exists x,y\in\Bbb N_{\leq\min(a,b)}\cup\{0\}\mbox{ }\mathsf{ with }\mbox{ }ax+by=n\}\big|?$$</p>

<p>For instance, I am looking for an approximation that will explain the fact that every integer $m\in[1,\min(a,b)]$ is not represented. There seems to be more smaller non-representable numbers than larger ones.  It seems lower the $m$, there are more non-representable numbers and there should be comparatively more representable numbers close to $g(a,b)$ to get upto half the numbers to be representable. What exactly is this distribution?</p>
",combinatorics
"<p>Let $G = (V, E)$ be a planar bipartite graph such that there is a partition $(V1, V2)$ of $V$  where $V1$ induces a tree and $V2$ induces an independent set.</p>

<p>Is there a characterization of such graphs in the literature? </p>
",combinatorics
"<p>This was also posted in <a href=""http://math.stackexchange.com/q/1549745/294077"">stackexchange</a>. However, I have no idea how difficult it is. All hints or references are appreciated!</p>

<p>Consider a set $S$ of $n$ red balls and $m$ blue balls. It is well known that the number of partitions of this set is the Bell number $B_{n+m}$.</p>

<p>We say that a partition $P \subset \mathcal{P}(S)$ of $S$ is <em>good</em> if it has the following property: If there are at least two red (blue) balls in $A \in P$, there also is at least one blue (red) ball in $A$. Let $\xi_{n+m} \leq B_{n+m}$ be the number of good partitions of $S$.</p>

<p>Is there a chance for obtaining a closed form for the number $\xi_{n+m}$? Alternatively, is it possible to construct an algorithm to calculate it for large $n$ and $m$?</p>

<p>What happens if we introduce other colors and alter the definition of a good partition: We say that a partition $P \subset \mathcal{P}(S)$ of $S$ is <em>good</em> if it has the following property: If there are at least two balls of the same color in $A \in P$, there also is at least one ball in $A$ with a different color.</p>

<p>EDIT: In a related post, <a href=""http://math.stackexchange.com/questions/289016/partitions-and-bell-numbers"">http://math.stackexchange.com/questions/289016/partitions-and-bell-numbers</a>, they find an expression for partitions of an $n$-element set with no singletons. I'm not sure, however, if this problem can be solved as an application of that. </p>
",combinatorics
"<p>Given:<br>
$G:=\{V= \{v_1,\ ...\ v_n\},E\subset V\times V\}, n&lt;\infty$, a symmetric complete, simple graph<br>
$w:=\ \ E \ni e_{ij}\mapsto \mathbb{R}^+$, a weight function for the edges of $G$<br>
$K:=\{c_1,\ ...\ c_m\},\ 2\le m\ll n$, a set of colors to be assigned to the vertices of $G$  </p>

<p>Question:<br>
Are there any algorithms known, that color the vertices in $V$ with colors from $K$ in a way that minimizes some norm of the vector of nearest color-neighbor distances;  </p>

<p>i.e. if $c(j)$ is the color assigned to $v_j$ and, $\mu_{ik} := \min\limits_{c(v_j)=c_k}w_{ij}$ the least weight of the edges that connect vertex $v_i$ to a vertex $v_j$ of color $c_k$, are algorithms known, that minimize $\|(\mu_{1,1}\ ,\ ...,\ \mu_{1,k}\ ,\ ...,\ \mu_{n,1},\ ...,\ \mu_{n,k})\|$?<br>
In the context of this question a vertex is considered to be none if its neighbors, but feel free to assume the contrary.  </p>
",combinatorics
"<p>Many years ago, I discovered the remarkable array (apparently originally discovered by Ramanujan)</p>

<pre><code> 1
 1    3
 2   10   15
 6   40  105  105
24  196  700 1260  945
</code></pre>

<p>which is defined by $S(i,j) = i\ S(i-1,j) + (i+j)\ S(i-1,j-1)$ and $S(0,1)=1$, and $S(i,j)=0$ if $j&lt;1$ or $j&gt;i+1$. This array has the remarkable property that the sum of the numbers in the $i$'th row is $(i+1)^{i+1}$. This is not easy to prove. There are three approaches I know to proving this</p>

<ol>
<li>Generating functions.</li>
<li>Counting subclasses of labeled trees.</li>
<li>Generalizing to a 3-dimensional array of numbers. There are recurrences on two sets of parallel planes, which intersect in the rows. One set of parallel planes contains the array above, and the other set contains a recurrence from which one can immediately deduce the row sums. Proving that these two different sets of recurrences give the same array is straightforward (albeit tedious without computer algebra) using induction. </li>
</ol>

<p>(See <em>SIAM Review</em>, Problems and Solutions column, <a href=""http://siamdl.aip.org/getpdf/servlet/GetPDFServlet?filetype=pdf&amp;id=SIREAD000021000002000258000001&amp;idtype=cvips"">Vol. 21, pp. 258-260 (1979)</a>.)</p>

<p>The third approach is reminiscent of Wilf and Zeilberger's A = B theory of combinatorial identities, except there you have 3-dimensional arrays with recurrences on <em>three</em> sets of parallel planes. Wilf and Zeilberger's theory does not appear to shed any light on this recurrence.</p>

<p>My question is: does anybody know any other 3-dimensional arrays which have recurrences on two sets of parallel planes, but which do not fall under the A = B theory (so you cannot find a recurrence on a third set of parallel planes)? I would especially be interested in recurrences whose coefficients are polynomials in the coordinates $i,j,k$.</p>

<p>For more information about the connection with labeled trees, although this isn't directly connected with my question, see the papers <a href=""http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6W9D-45CWMXY-9&amp;_user=501045&amp;_coverDate=08%2F31%2F2001&amp;_fmt=abstract&amp;_orig=search&amp;_origin=search&amp;_cdi=6680&amp;view=c&amp;_acct=C000022659&amp;_version=1&amp;_urlVersion=0&amp;_userid=501045&amp;md5=6fbdd2d50300b97d329d550ca10bdde0&amp;ref=full"">Chen and Guo, Bijections behind the Ramanujan polynomials</a> and <a href=""http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6W9D-4K4PSF3-2&amp;_user=501045&amp;_coverDate=07%2F31%2F2007&amp;_rdoc=1&amp;_fmt=high&amp;_orig=search&amp;_origin=search&amp;_sort=d&amp;_docanchor=&amp;view=c&amp;_rerunOrigin=scholar.google&amp;_acct=C000022659&amp;_version=1&amp;_urlVersion=0&amp;_userid=501045&amp;md5=fae6f5f5c28269c1165c6fd70163313f&amp;searchtype=a"">Guo and Zeng, A generalization of the Ramanujan polynomials and plane trees</a>, as well as the references in them.</p>
",combinatorics
"<p>A <a href=""http://en.wikipedia.org/wiki/Zonohedron"" rel=""nofollow"">zonotope</a> is a linear combination of m vectors with coefficients in [0,1]: $Z = \{ \sum \lambda_i v_i : 0 \leq \lambda _i \leq 1 \}$.  The fancy way is to say it's the <a href=""http://en.wikipedia.org/wiki/Minkowski_addition"" rel=""nofollow"">Minkowski sum</a> of line segments in <b>R</b><sup>n</sup>.</p>

<p>One step in a certain geometric construction is to find the boundary faces of a  zonohedron (3D).  The boundary points all have &lambda;=0 or 1 but that requires finding 2<sup>m</sup> points.  It's also not clear which ones are within the polygon and which ones are corners.  It might be possible to do it faster inductively.</p>

<p>In two dimensions you can arrange the set $\{ v_i, -v_i: i = 1 \dots m\}$ in a circle and add them in clockwise order.  In 3D, I might arrange the vectors in a sphere, but then I'm not sure in which order to add the vectors.  I read somewhere, this is like integrating a discrete version of the <a href=""http://en.wikipedia.org/wiki/Gauss_map"" rel=""nofollow"">Gauss map</a>.</p>
",combinatorics
"<p>Consider a set-valued, finite-valued map $F$ from a set $X$ to subsets of $X$. Consider the following property: $|F(x)| \geq |F(y)|$ for all $x,y$ such that $y \in F(x)$. 
I have defined this property myself in a specific context but I am not sure what name to give it. I would like to know if there is a standard name for this property or similar property in set-valued analysis or otherwise. Any suggestions for names would also be appreciated.</p>
",combinatorics
"<p>It seems that the Fulkerson prize has been attributed to Thomas Hales for this work. What is the present status of the conjecture, then?</p>
",combinatorics
"<p>Starting somewhere on an infinite square grid, is it possible to visit every square exactly once, if at move $n$, one must jump $a_n$ steps in one of the directions north,south,east or west, and mark the ending square as visited?</p>

<p>If $a_n=n$ or if $a_n=n^2$?</p>

<p>Allowing diagonal moves as well, is there a general algorithm, given $a_n$, to check if a path exists?</p>

<p>Note:
I am asking if given $a_n$, there exists an infinite sequence of directions, $d_n\in(N,S,W,E)$, such that for all $(x,y)\in  Z^2$, there exists a finite integer $k(x,y)$, such that starting at the unit square with center $(0.5,0.5)$, marked as visited, we have after moving sequentially $a_i$ steps in direction $d_i$, for $i=1,2,3,...,k$, visited $k+1$ different unit squares, and are situated at $(x+0.5,y+0.5)$.</p>
",combinatorics
"<p>First  let me define <em>Difference multiset</em> for a set of integers 
$$P=\{p_1,p_2, \dots,p_K\} ,\quad p_i \in\{1,2,\dots,N\},\quad p_i\ne p_j
$$
as below:
$$
D = \{p_i-p_j \mod N ,\quad i \ne j\}
$$
I know that the minimum of $f(x)$ is same for all $P$'s having same difference multiset (homometric $P$'s) &amp; and also the optimal $x$ (minimizing $f$) is same for all of them up to permutation of elements, (also for all homometric $P$'s same $l$ is the inner maximizer) , where $f(x)$ is a real function which is defined as:</p>

<blockquote>
  <p>$$\large
f(x) = \max_{1 \leq l \leq N-1}
{\sum_{j=1}^K \sum_{k=1}^K x_j x_k e^{\frac{i2\pi l(p_j-p_k)}N} \over \left( \sum_{i=1}^K x_i\right)^2 } = \max_{1 \leq l \leq N-1}
{ \sum_{i=1}^K x_i^2 + \sum_{j,k} x_j x_k cos(\frac{2\pi l(p_j-p_k)}N) \over \left( \sum_{i=1}^K x_i\right)^2 }
$$
  $x_i$'s are positive variables</p>
</blockquote>

<p>I achieved this result from simulations. I'm looking for a proof or even a justification which helps me prove it.</p>

<p>Let me give you an example of my simulations if it helps:</p>

<p>suppose $(N,K)= (6, 4)$</p>

<p>$$
P = \{1,2,3,5\} \Rightarrow D = \{1,1,2,2,2,3,3,4,4,4,5,5\}
$$
minimizing $f(x)$ with $p_i$'s being members of $P$, led to this $x=(4,5,4,4)$</p>

<p>and for 
$$
P' = \{1,2,4,6\} \Rightarrow D' = \{1,1,2,2,2,3,3,4,4,4,5,5\} = D
$$
minimizing $f(x)$ with $p_i$'s being members of $P'$, led to this $x=(5,4,4,4)$</p>

<p>Also note that $f(x) $ is independent of $||x||_2$ and is just function of angle of vector $x$.</p>

<p>I've also asked this on <a href=""http://math.stackexchange.com/questions/450065/how-to-prove-that-homometric-sets-lead-to-same-result-in-this-problem-any-just"">ME</a></p>
",combinatorics
"<p>Suppose $G=(V,E)$ is a simple but not necessarily finite graph, and let $E',E''$ be a disjoint partitioning of $E$ into two (not necessarily finite) subsets, so that $G$ is the edge disjoint union of the graphs $G'=(V,E')$ and $G''=(V,E'')$.</p>

<p><strong>My (admittedly vague) question is:</strong> when can the maximum clique size of $G$ be related to the maximum clique sizes of $G'$ and $G''$? In the case that $G$ is infinite, is it even clear that maximum clique size of $G$ and $G'$ both finite implies that the maximum clique size of $G$ is finite?</p>

<p>I'm guessing that in complete generality probably little can be said, because a clique of $G$ need not a priori respect the clique structures of $G'$ and $G''$. But in my setting, I have a particular pair of graphs $G', G''$ that I know a little bit about- both are infinite and locally infinite, both have finite maximum cliques (and I know these sizes explicitly), both have finite chromatic number, they're bi-lipschitz equivalent to each other, etc. So I'd also be happy with results that assume extra structure (but not finiteness) on $G,G',G''$.</p>

<p>Thanks for reading; any ideas would be greatly appreciated.</p>
",combinatorics
"<p>Let ${\bf N}^\omega = \bigcup_{m=1}^\infty {\bf N}^m$ denote the space of all finite sequences $(N_1,\ldots,N_m)$ of natural numbers.  For want of a better name, let me call a family ${\mathcal T} \subset {\bf N}^\omega$ a <em>blocking set</em> if every infinite sequence $N_1,N_2,N_3,N_4,\ldots$ of natural numbers must necessarily contain a blocking set $(N_1,\ldots,N_m)$ as an initial segment.  (For the application I have in mind, one might also require that no element of a blocking set is an initial segment of any other element, but this is not the most essential property of these sets.)</p>

<p>One can think of a blocking set as describing a machine that takes a sequence of natural number inputs, but always halts in finite time; one can also think of a blocking set as defining a subtree of the rooted tree ${\bf N}^\omega$ in which there are no infinite paths.  Examples of blocking sets include</p>

<ol>
<li>All sequences $N_1,\ldots,N_m$ of length $m=10$.</li>
<li>All sequences $N_1,\ldots,N_m$ in which $m = N_1 + 1$.</li>
<li>All sequences $N_1,\ldots,N_m$ in which $m = N_{N_1+1}+1$.</li>
</ol>

<p>The reason I happened across this concept is that such sets can be used to pseudo-finitise a certain class of infinitary statements.  Indeed, given any sequence $P_m(N_1,\ldots,N_m)$ of $m$-ary properties, it is easy to see that the assertion</p>

<blockquote>
  <p>There exists an infinite sequence $N_1, N_2, \ldots$ of natural numbers such that $P_m(N_1,\ldots,N_m)$ is true for all $m$.</p>
</blockquote>

<p>is equivalent to</p>

<blockquote>
  <p>For every blocking set ${\mathcal T}$, there exists a finite sequence $(N_1,\ldots,N_m)$ in ${\mathcal T}$ such that $P_m(N_1,\ldots,N_m)$ holds.</p>
</blockquote>

<p>(Indeed, the former statement trivially implies the latter, and if the former statement fails, then a counterexample to the latter can be constructed by setting the blocking set ${\mathcal T}$ to be those finite sequences $(N_1,\ldots,N_m)$ for which $P_m(N_1,\ldots,N_m)$ fails.)</p>

<p>Anyway, this concept seems like one that must have been studied before, and with a standard name.  (I only used ""blocking set"" because I didn't know the existing name in the literature.)  So my question is: what is the correct name for this concept, and are there some references regarding the structure of such families of finite sequences?  (For instance, if we replace the natural numbers ${\bf N}$ here by a finite set, then by Konig's lemma, a family is blocking if and only if there are only finitely many finite sequences that don't contain a blocking initial segment; but I was unable to find a similar characterisation in the countable case.)</p>
",combinatorics
"<p>Starting from a question in probability, one is eventually lead to the following optimization problem. </p>

<p>Let $I:=[0,\\, 1],$ and let $A$ be a Lebesgue measurable subset of the $n$-dimensional cube, $A\subset I^n.$ Consider, correspondingly, the set
$$\hat A:= \{x\in I^{n+1}:\\, (x_1,\dots,x_n)\in A,\\, (x_2,\dots,x_{n+1})\notin A\}=A\times I\\,\cap\\, I \times A^c.$$</p>

<blockquote>
  <p><strong>Problem.</strong> Maximize the $(n+1)$-dimensional Lebesgue measure
  of $\hat A$ over all measurable
  $A\subset I^n$:
  $$\lambda_n:=\sup_{A\subset I^n}\vert\hat A\vert.$$</p>
</blockquote>

<p>If $n=1,$ we have $|\hat A|=|A|(1-|A|),$ whence $\lambda_1=1/4.$ For $n=2$ the maximizing set is the triangle below the diagonal, giving $\lambda_2=1/3.$ The sequence $\lambda_n$ is increasing, and converges to $1/2.$ If $n$ is even, one finds $$\lambda_n=\frac{1}{2}\left(1-\frac{1}{n+1}\right).$$
(I will edit and provide the details of the computation at request). However, as a consequence of a computation by Trotter and Winkler (<em>Ramsey theory and sequences of random variables</em>, Probability, Combinatorics and Computing 7 (1998), 221-238), the formula can't hold true for all odd $n,$ for one has $\lambda_5&gt;\frac{1}{2}\left(1-\frac{1}{6}\right)=5/12.$ </p>

<p>I would be very grateful for any suggestion or reference useful to shed light on the case of odd $n.$ </p>
",combinatorics
"<p>It is relatively easy to show that
$$
\sum_{a_1 + \cdots + a_k=\ell} \binom{\ell}{a_1,\ldots,a_k} = k^\ell
$$
where $\binom{\ell}{a_1, \ldots, a_k} = \frac{\ell!}{a_1!\cdots a_k!}$. What can be said if we want to compute the restricted sum
$$
s(\ell,k) = \sum_{a_1 + \cdots + a_k=\ell} \binom{\ell}{a_1,\ldots,a_k}
$$
where we now restrict the summation to those $a_k$ which are odd? At the least, of course, we need that $\ell \geq k$ and that $\ell \equiv k \pmod 2$. Is this sum known in the literature?</p>

<p>The simplest case of $s(2k,2) = 2^{2k-1}$ can be easily verified, but I believe that this is an anomoly based on the fact that these are (secretly) binomial coefficients.</p>

<p>This arises in computing the coefficients of the power series of $\big(\sin(x)\big)^k$.</p>
",combinatorics
"<p>Consider a subset of $n$ points in an equilateral triangular lattice. Draw all the edges between nearest-neighbor points.</p>

<p>What is the maximum, over all such subsets, of the number of edges? This sequence appears to start 0, 1, 3, 5, 7, 9, 12, 14, 16...</p>

<p>What is the maximum number of triangular lattice cells? (Not the number of all triangles, just the number of smallest possible equilateral triangles in the lattice.) This sequence appears to start 0, 0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 13...</p>

<p><a href=""http://oeis.org/A047932"" rel=""nofollow"">http://oeis.org/A047932</a> is related to the first sequence but I have no proof it's the same. (There might be some other way of arranging the pennies that yields a higher number of contacts. A047932 is a lower bound on my sequence.) I can't find any OEIS sequences relevant to the second one.</p>
",combinatorics
"<p>For those who are unfamiliar with the terminology, I'll explain a little.</p>

<p>The symmetric group $S_n$, as a type A Coxeter group, has generators $\{s_1,\ldots,s_{n-1}\}$ with relations (1) $s_i^2$ for all $i$; (2) $(s_is_j)^2$ for $|i-j|&gt;1$; and (3) $(s_is_j)^3$ for $|i-j|=1$.
For $\pi\in S_n$, we denote by $\ell(\pi)$ the length of a shortest word (product of generators) $s_{i_1}\cdots s_{i_\ell}$ which is equal to $\pi$.
The <em>right weak Bruhat order</em> on $S_n$ is the partial order defined as the transitive closure of the cover relations:
 $\pi&lt;\pi s_i$ if $\ell(\pi)&lt;\ell(\pi s_i)$ for some generator $s_i$.
 For any partially ordered set, we say that a subset $C$ of its elements is <em>convex</em> if, whenever $x,y\in C$ with $x&lt;y$ it happens that the entire interval $[x,y]\subset C$.</p>

<p>If we write our permutations in one-line format, the usual right action of the generator $s_i$ is to swap the entries in positions $i$ and $i+1$.
E.g. if $\pi=632514\in S_6$ in one-line format, then $\pi s_3 = 635214$.
An <em>elementary Knuth transformation</em> associates two permutations which differ by one of these generators under the following conditions, described in terms of their one-line notations:
$$
\ldots xyz \ldots \quad\sim\quad 
\begin{cases}
\;\ldots xzy \ldots &amp;\text{if } y&lt;x&lt;z \text{ or } z&lt;x&lt;y \\
\;\ldots yxz \ldots &amp;\text{if } y&lt;z&lt;x \text{ or } x&lt;z&lt;y 
\end{cases}
$$
For example, $632514\sim 635214$ and $635214\sim 635241$.
The transitive closure of these associations, denoted $\sim$, is called <em>Knuth equivalence</em> or <em>plactic equivalence</em>.</p>

<p>Now the question:  If $C$ is a plactic equivalence class of permutations viewed as a subset of $S_n$, with $S_n$ having the weak right Bruhat order, is $C$ necessarily convex?
It is true for the examples I have worked out by hand. 
If it is true in general, then is it a known result?
If so, could someone provide a citation?</p>
",combinatorics
"<p>Context: Many resources, like</p>

<p><a href=""http://math.mit.edu/~fox/MAT307-lecture22.pdf"">http://math.mit.edu/~fox/MAT307-lecture22.pdf</a></p>

<p>state the theorem in the general case, but then prove it only for the bipartite case.
The full case is supposedly proved in Pinsker's 1973 paper. However, I can't dig up a copy.</p>

<p>Anyone know of a proof for the general case (i.e. d-regular, undirected, not-necessarily-bipartitite graph)?</p>

<p>Thanks!</p>
",combinatorics
"<p>Hi. I was reading the paper ""On the foundations of combinatorial theory (VI): The idea of a generating function"" by Doubilet, Rota and Stanley, and there is a relation treated which is very reminiscent of the relation between ideals in a polynomial ring  and affine algebraic varieties (i won't go more specific in the definitions).</p>

<p>It goes as follows (everything quoted from the above paper): Let $P$ be a finite poset (can be generalized to locally finite), and consider its incidence algebra $I(P,K)$, consisting of all the functions from the intervals in $P$ to some field $K$ (of characteristic zero). Sum and product by scalars are inherited from $K$, and product of two functions $f,g \in P$ is defined as the convolution:
\begin{equation}
(f*g)(x,y)=\sum_{x\leq z \leq y}f(x,z)g(z,y)
\end{equation}</p>

<p>Some special elements in $I(P,K)$ needed to state the connection are the units:</p>

<p>\begin{equation}
\delta_{x,y}(u,v)=\begin{cases}1&amp;\text{if $u=x$ and $v=y$,}\\\\0&amp;\text{otherwise.}\end{cases}
\end{equation}</p>

<p>Now, the (two sided) ideals in this algebra and the <em>varieties</em> have a very nice relation just very similar to the one from commutative algebra and algebraic geometry. But in this case the relation is tighter, because varieties have an algebraic structure coming from a natural partial ordering.</p>

<p>Define the support of and ideal $J$, $\Delta (J)$, as the set of all the units $\delta_{x,y}$ belonging to $J$. It turns out that every ideal $J$ in $I(P,K)$ consists of all the functions $f$ for which $f(x,y)=0$ whenever $\delta_{x,y}\notin \Delta(J) $.
On the other hand, define $Z(J)$ as the set of all intervals $\[ x,y \]$ such that $f(x,y)=0$ for all $f\in J$ (this would be the <em>variety</em>). $Z(J)$ is an order ideal of the poset of all intervals of $P$ (ordered by inclusion).</p>

<p><strong>Theorem:</strong> Let $P$ be a finite poset and $S(P)$ the poset of its intervals, ordered by inclusion. Then there is a natural anti-isomorphism between the lattice of ideals of $I(P,K)$ and the lattice of order ideals of $S(P)$.</p>

<p>(For more details and background, check the paper, or ""Enumerative Combinatorics Vol.1"" by Stanley)</p>

<blockquote>
  <p><strong>My question is:</strong> Does anyone know if this ideal-variety duality has been exploited or studied further in the context of posets from an algebraic geometry point of view? (apart from the material in the mentioned paper). </p>
</blockquote>
",combinatorics
"<p>The graph <a href=""http://en.wikipedia.org/wiki/Reconstruction_conjecture"">reconstruction conjecture</a> claims that (barring trivial examples) a graph on n vertices is determined (up to isomorphism) by its collection of (n-1)-vertex induced subgraphs (again up to isomorphism).</p>

<p>The way it is phrased (""reconstruction"") suggests that a proof of the conjecture would be a procedure, indeed an algorithm, that takes the collection of subgraphs and then ingeniously ""builds"" the original graph from these.</p>

<p>But based on some experience with a related conjecture (the vertex-switching reconstruction conjecture), I am led to wonder whether this is something that is simply true ""by accident"". By this I mean that it is something that is just overwhelmingly unlikely to be <em>false</em> ... there would need to be a massive coincidence for two non-isomorphic graphs to have the same ""deck"" (as the collection of (n-1)-vertex induced subgraphs is usually called).  In other words, the only <em>reason</em> for the statement to be true is that it ""just happens"" to not be false.</p>

<p>Of course, this means that it could never actually be proved.. and therefore it would be a very poor choice of problem to work on!</p>

<p>My question (at last) is whether anyone has either formalized this concept - results that can't be proved or disproved, not because they are formally undecidable, but just because they are ""true by accident"" - or at least discussed it with more sophistication than I can muster.</p>

<p>EDIT:  Apologies for the delay in responding and thanks to everyone who contributed thoughtfully to the rather vague question. I have accepted Gil Kalai's answer because he most accurately guessed my intention in asking the question. </p>

<p>I should probably not have used the words ""formally unprovable"" mostly because I don't really have a deep understanding of formal logic and while some of the ""logical foundations"" answers contained interesting ideas, that was not really what I was trying to get at.</p>

<p>What I was really trying to get at is that some assertions / conjectures seem <em>to me</em> to be making a highly non-obvious statement about combinatorial objects, the truth of which depends on some fundamental structural understanding that we currently lack. Other assertions / conjectures seem, again, <em>to me</em>, to just be saying something that we would simply expect to be true ""by chance"" and that we would really be astonished if it were false.</p>

<p>Here are a few unproved statements all of which I believe to be true: some of them I think should reflect structure and others just seem to be ""by chance"" (which is which I will answer later, if anyone is still interested in this topic).</p>

<p>(1) Every projective plane has prime power order</p>

<p>(2) Every non-desarguesian projective plane contains a Fano subplane</p>

<p>(3) The graph reconstruction conjecture</p>

<p>(4) Every vertex-transitive cubic graph has a hamilton cycle (except Petersen, Coxeter and two related graphs) </p>

<p>(5) Every 4-regular graph with a hamilton cycle has a second one</p>

<p>Certainly there is a significant chance that I am wrong, and that something that <em>appears</em> accidental will eventually be revealed to be a deep structural theorem when viewed in exactly the right way. However I have to choose what to work on (as do we all) and one of the things I use to decide what <em>NOT</em> to work on is whether I believe the statement says something real or accidental.</p>

<p>Another aspect of Gil's answer that I liked was the idea of considering a ""finite version"" of each statement: let S(n) be the statement that ""all non-desarguesian projective planes of order at most n have a Fano subplane"". Then suppose that all the S(n) are true, and that for any particular n, we can find a proof - in the worst case, ""simply"" enumerate all the projective planes of order n and check each for a Fano subplane. But suppose that the length of the shortest possible proof of S(n) tends to infinity as n tends to infinity - essentially there is NO OTHER proof than checking all the examples. Then we could never make a finite length proof covering all n. This is roughly what I would mean by ""true by accident"".</p>

<p>More comments welcome and thanks for letting me ramble!</p>
",combinatorics
"<p>Let $\Gamma$ be a Coxeter group on some generating set $S$, with reflection representation $V$. Then $\Gamma$ has two standard partial orders, the weak and strong Bruhat orders.</p>

<p>Moreover, if $\lambda \in V$ is chosen generically (any free orbit will do), then the covering relations in weak order are given exactly by the edge graph of the convex hull of $\Gamma\cdot \lambda$.</p>

<blockquote>
  <p>Let $[u,v]$ be an interval in strong Bruhat order. Has the edge graph of the polytope $hull([u,v]\cdot \lambda)$ been studied?</p>
</blockquote>

<p>For example, the polytope $hull([123,321] \cdot (1,2,3))$ is a
hexagon, and the strong Bruhat cover $231 &gt; 132$ defines an edge
through the middle of this hexagon, so not a weak cover. Whereas
the polytope $hull([132,321] \cdot (1,2,3))$ is a trapezoid, 
one edge of which connects $231$ and $132$.</p>

<p>EDIT: perhaps I should admit the geometry here. If $\Gamma$ is a Weyl group of a Lie group $G$ -- and I am happy to make this assumption, albeit I want $G$ Kac-Moody -- and $V$ the corresponding weight lattice, and $\lambda$ a dominant weight, then $hull(W\cdot \lambda)$ is the moment polytope for $G/B$ bearing the Borel-Weil line bundle ${\mathcal L}_\lambda$. Within $G/B$ we have the Richardson variety $\overline{BuB}/B \cap \overline{B_- vB}/B$, and $hull([u,v]\cdot \lambda)$ is the moment polytope of that.</p>
",combinatorics
"<p>I am reading Andrew Granville's <a href=""http://www.dms.umontreal.ca/~andrew/PDF/Anatomy.pdf"" rel=""nofollow"">Anatomy of Integers and Permutations</a> where it is argued the factorization of a permutation into disjoint cycles is analogous to the factorization of a number into prime factors.  </p>

<p>In the <a href=""http://terrytao.wordpress.com/2013/09/21/the-poisson-dirichlet-process-and-large-prime-factors-of-a-random-number/"" rel=""nofollow"">blog-sphere</a> you can find these two ways of defining partitions of unity:</p>

<ul>
<li>$m = p_1\cdots{p_k} \in \mathbb{Z}$ and $\{ \frac{\log p_1}{\log m}, \dots, \frac{\log p_k}{\log m}\}$.</li>
<li>$\sigma = C_1\dots C_k \in S_n$ and $\{ \frac{|C_1|}{n}, \dots, \frac{|C_n|}{n}  \} $</li>
</ul>

<p>One can prove both of these converge to the <a href=""http://www.stats.ox.ac.uk/~griff/pd.pdf"" rel=""nofollow"">Poisson-Dirichlet process</a>.  It looks like $n \approx \log m$ in this analogy and $\mathbb{Z} \simeq S_n $. </p>

<p>This is a correspondence between partitions, but what could be permuted in the $\mathbb{Z}$ side?</p>

<hr>

<p>It seems necessary to clarify, that the analogy between $\mathbb{Z}, \mathbb{F}_q[t],\mathbb{C}(z)$ has gotten attention recently and I have not read them closely enough:</p>

<ul>
<li><a href=""http://quomodocumque.files.wordpress.com/2013/01/jmm-2013-plenary-talk.pdf"" rel=""nofollow"">how to count with topology</a></li>
<li><a href=""http://arxiv.org/abs/0912.0325"" rel=""nofollow"">Homological stability for Hurwitz spaces and the Cohen-Lenstra conjecture over function fields</a></li>
<li><a href=""http://math.stanford.edu/~akshay/research/evicm.pdf"" rel=""nofollow"">Statistics of Number Fields and Function Fields</a></li>
</ul>

<p>I have found many individual parts of these papers difficult to grasp - and they are put together - and I maybe I can ask more questions on these topics later?</p>

<p>Today, my question may have to do with the last link... suppose we do have this machine comparing statistics on the function field $\mathbb{F}_q[t]$ to statistics of $S_n$ as Qiaochu say.  How do we ""<a href=""http://ncatlab.org/nlab/show/Maslov+dequantization"" rel=""nofollow"">dequantize</a>"" to get a result in $\mathbb{Z}$?  The implication is there is some kind of permutation group action on the integers and I was wondering what it could be.</p>

<p>Maybe it's $q \to 1$ limit?</p>
",combinatorics
"<p>One of Barany's most intriguing conjectures is about the $f$-vectors of convex polytopes. It asks:</p>

<blockquote>
  <p>Let $P$ be a convex $d$-polytope. Is it always true that $f_k \geq \min(f_0, f_{d-1})$?</p>
</blockquote>

<p>A <strong><em>convex $d$-polytope</em></strong> is the convex hull of finitely many vertices $v_1, \ldots, v_n \in \mathbb{R}^d$. A <strong><em>face</em></strong> of the polytope is whatever you can shave off with a hyperplane. Its dimension is the dimension of the affine hull it generates. The number of faces are collected in the so-called $f$-vector $f = (f_0, \ldots, f_{d-1})$, where $f_k$ denotes the number of $k$-dimensional faces. Further information on polytopes can be found in Ziegler's ""Lectures on Polytopes"".</p>

<p>My question is</p>

<blockquote>
  <p>What's the status of Barany's conjecture? For which classes of polytopes is it known to hold?</p>
</blockquote>

<p>Here is what I know:</p>

<p>By double counting it is easy to see that the conjecture is true for simple and simplicial polytopes. Furthermore, it is nothing but a boring calculation to prove that the basic polytope constructions like taking products, prisms, pyramids, etc. retain the the conjectured inequality.</p>

<p>Given that the face lattice of a convex $d$-polytope is a graded, atomic, coatomic lattice of rank $d+2$, it makes sense to ask a far more general question: Given such a lattice, denote the number of elements of the $k$th level again by $f_k$. Is it still true that $f_k \geq \min(f_0, f_{d-1})$? Here the answer is no since I was able to construct a counterexample. But if the lattice also has what Ziegler calls the ""diamond property"" (every interval of length two looks like a diamond), then I don't know the answer.</p>
",combinatorics
"<p>Here's a mathematical modeling problem I came across while working on a hobby project.</p>

<p>I have a website that presents each visitor with a list of movie titles. The user has to rank them from most to least favorite. After each visit, I want to create a cumulative ranking that takes into account each visitor's individual ranking. Normally I would just take the mean ordinal rank: e.g., if Person A rated ""Avatar"" 10th and Person B rated it 20th, its cumulative rank would be 15th. However, new movies will be added to the list as the website grows, so each person will have ranked only a subset of the full movie list.</p>

<p>Any thoughts on how I can define ""average rank"" when some rankings do not cover the whole set? My best idea so far is to model this as a directed graph, where nodes are movies and weighted edges are preferences (e.g. ""10 people ranked 'Avatar' right above 'District 9'""), and then finding sinks and sources. How else could one go about this?</p>

<p>(Sorry if this question is too applied.)</p>
",combinatorics
"<p>Consider you want to properly edge color a graph such that it has no bi-colored cycle. Denote by $\alpha'(G)$ the least number of colors required to color the edges of $G$ in such a way.</p>

<p>It is well known that $\alpha'(G)$ is linear in $\Delta(G)$ and the best current bound seems to be $$\alpha'(G) \leq 4\Delta(G)-4,$$ <a href=""http://arxiv.org/abs/1206.1535"" rel=""nofollow"">obtained</a> by what they call the entropy compression method.</p>

<p>Now consider you want to properly edge color your graph such that no 5-path is bi-colored and denote this number by $\beta'(G).$ Repeating the same argument with entropy compression one obtains an upper bound of order $O(\Delta(G)^{1.5})$ for $\beta'(G).$</p>

<p>If we consider the complete graph then it follows from <a href=""http://arxiv.org/abs/1011.3376"" rel=""nofollow"">here</a> that $$\beta'(K_n) \leq n^{1+\epsilon}$$ for any fixed $\epsilon &gt; 0.$</p>

<p>So while a linear number of color suffices to properly edge color a graph avoiding bi-colored cycles of <strong>any</strong> lenght it seems that the same problem is already much more complicated if we want to avoid just bi-colored 5-paths.</p>

<p>Given this I am wondering</p>

<blockquote>
  <p>Can you properly edge color $K_n$ such that no $5$-path is bi-colored and so that only a number of colors that is linear in $n$ is used?</p>
</blockquote>
",combinatorics
"<p>Let $A$ be a set of $k&gt;1$ distinct elements from a semigroup.  We wish to compute the product
$$ p=b_1 b_2 \cdots b_n$$
where each $b_i\in A$.
Clearly $n-1$ multiplications suffice to compute $p$; can we do it with fewer?  </p>

<p>Let $m=m(b_1,...,b_n)$ be the minimum number of multiplications required to compute $p$.  My specific questions are:</p>

<ol>
<li>Can we compute $m$ in polynomial time?</li>
<li>Can we answer question #1 constructively, i.e. actually figure out which $m$ terms can be multiplied together to compute $p$?  If not, can we do it with some approximation guarantee (like ""at worst we use $2m$ terms""?)</li>
</ol>

<p>The interesting case (for my application, anyway) occurs when $n\gg k$ (so there are many common subexpressions) but the semigroup is noncommutative (so you cannot simply rearrange terms and use repeated doubling).</p>

<p>Let me outline one simple (but insufficient) approach.  Suppose that we begin by computing all products of (not necessarily distinct) pairs from $A$.  Then we can compute $p$ with $k^2+(\lceil n/2 \rceil -1)$ multiplications by multiplying the terms two at a time.  If $k^2\ll n$, then we have essentially halved the number of multiplications.  Analogous reasoning can be extended to provide roughly an $\lfloor \log_k(n)-\log_k(\log_k(n)) \rfloor -1$ improvement in the number of multiplications.  However, for highly repetitive strings we could do much better still.</p>

<p>This problem arose in the context of parallel inference algorithms for hidden Markov models; the noncommutative semigroup in question consists of non-negative matrices over the reals.</p>
",combinatorics
"<p>Aside from the Desargues graph, are there nice (at least vertex-transitive), small (say, less than 60 vertices), cubic, bipartite graphs with girth at least 6 and no 8-cycles? (or, even better, no cycles of length congruent to 0 mod 4.) </p>

<p>Bonus: any idea how to use Mathematica to pull these out of its list of graphs it's got data for in Mathematica 7?</p>
",combinatorics
"<p>You are given a multigraph $G$ with $n$ vertices as follows: <br/>
$V := (v_1, v_2, \dots ,v_n)$<br/>
$C := \{c_1, c_2, \dots\}$, be an infinite set of colors. <br/>
$f: V \rightarrow \mathbb{P}_{\le m}(C) $, a function that maps each vertex to a subset of colors of size $\le m$. <br/>
We define the set of edges of the graph as:
$E := \big\lbrace \small\{ \normalsize v_i, v_j, c_k \small\} \normalsize \mid c_k \in f(v_i) \cap f(v_j) \big\rbrace$, i.e. there is an edge colored with a given color between every pair of vertices that share that color. Note that a pair of vertices may have more than one edge if they share multiple colors.</p>

<p>It is guaranteed that every pair of vertices has at least one edge in common. i.e. $\forall v_i, v_j \in V$  there exists $c_k \in C$ such that $\{v_i, v_j, c_k\} \in E$.</p>

<p>Define $F(n,m) = s$ such that for any graph with $n$ vertices, each vertex colored with $\le m$ colors as above, there is a clique of order $s$ where each edge is colored with the same color. Another way of phrasing this is that there is a subset of size $s$, $S \subseteq V$, $|S| = s$, all vertices of which share a color. i.e. $\exists c_k \in C$ such that $\forall v_i \in S, c_k \in f(v_i)$.</p>

<p>So a few simple examples: $F(n,1)=n$, clearly because every vertex has to have the same color. It is easy to show that, $F(n,2)=n−1$ and $F(n,n-1)=2$.</p>

<p>One can show that $F(9,3)=5$ by applying the pigeonhole principle repeatedly.</p>

<p>What method can be used to solve this for general $n$ and $k$? Or how can this problem be represented as a known problem in graph-theory/combinatorics.</p>

<p><em>Note:</em> This function can be represented as an inverse to resemble the Ramsey numbers as follows:
$G(s, m) = n$, where $n$ is the smallest number where any graph with $n$ vertices, each vertex colored with at most $m$ colors as above contains a clique of order $s$. But that is harder since $F$ only gives us bounds on $G$.</p>
",combinatorics
"<p>Are there any <strong>internally 6-connected</strong> planar triangulations other than the icosahedron all of whose distinct 4-colorings consist of exactly 6 Kempe chains, one for each of the 6 color-pairs?</p>

<p>Addendum: I should have mentioned that each of the Kempe chains will be a tree because the existence of a Kempe chain that is a cycle or that has a cycle as a subgraph will necessarily break what might otherwise have been a Kempe chain of the complementary color-pair. The icosahedron has 10 distinct colorings, all of which have the stated property. The tetrahedron also has the coloring property, but it is not internally 6-connected. Both the triangle and the octahedron have the coloring property but with 4-colorings replaced by 3-colorings and 6 color-pairs replaced by 3 color-pairs. Clearly neither of those is internally 6-connected. There is a (non-regular) planar triangulation of order 5 that also has the coloring property (it has a unique 4-coloring), but it is only 3-connected. </p>
",combinatorics
"<p>Let  $\mathcal{L}$ be a  finite distributive lattice, then it is known that it can be embedded into a finite boolean lattice (see  theorem 8.5. p91 in <a href=""http://www.math.hawaii.edu/~jb/math618/os8uh.pdf"" rel=""nofollow"">this note</a>).  </p>

<p>Let $n$ be the length of $\mathcal{L}$  and let $\mathcal{B}_n$ be the boolean lattice of rank $n$.</p>

<p><em>Question</em>:  Can $\mathcal{L}$ be embedded into $\mathcal{B}_n$?</p>
",combinatorics
"<p>Let $a,b,c,d\in\Bbb N$ with $c&lt;b$.</p>

<p>Let $N_+(a,b,c,d)$ be the number of monic polynomials $f\in \Bbb Z[x]$of degree $d$ with non-negative coefficients such that $$f(a)=b$$ $$f(0)=c$$</p>

<p>What is the value of $$\sum_{d=0}^tN_+(a,b,c,d)?$$</p>

<p>Are there sharp estimates?</p>
",combinatorics
"<p>I have encountered in a problem some polynomials given by $P_k(x) = \prod_{j=0}^{k-2} (kx-j)$.  I need to understand if these polynomials are known, and if they have certain special properties, as this might be important for my problem.</p>

<p>They appeared when calculating the Taylor series of the implicit function $s(x) = 1 - \mu\beta x s(x)^{\beta}$ at $x = 0$ for some parameters $0 &lt; \mu$, $0 &lt;\beta &lt; 1$.  I wasn't able to find this explicit form by direct calculation, but Maple gave a very clean expression:
$$s(x) = 1 - \mu\beta x + \sum_{k=2}^{n} \frac{1}{k!}\left[\prod_{j=0}^{k-2}(k\beta - j)\right] (-\mu\beta x)^{k}.$$
Any help would be very much appreciated.</p>
",combinatorics
"<p>Let $G, H$ be simple, undirected graphs without loops. We say that $G, H$ have the same homomorphism fingerprint if $|\text{Hom}(X, G)| = |\text{Hom}(X, H)|$ for all graphs $X$. (By graph homomorphisms I mean edge preserving maps; so for instance $\text{Hom}(X,K_2)=\emptyset$  if $\chi(X) &gt; 2$).</p>

<p>From Lovasz [1] we have the following theorem: If $G, H$ are finite and they have the same homomorphism fingerprint, then $G\cong H$.</p>

<p>Are there non-isomorphic infinite graphs that have the same homomorphism fingerprint?</p>

<p>[1] L. Lovasz, Operations with structures,Acta Math. Hungar. 18(1967),
321–328</p>
",combinatorics
"<p>Let us consider the limit $\lim_{n\to \infty}\prod_{p=1}^n N(p,a)$ where $N(n,a)$ is the number of fixed <a href=""http://mathworld.wolfram.com/Necklace.html"" rel=""nofollow"">necklaces</a> of length $n$  composed of $a$ types of beads. </p>

<p>Let's rewrite the product in a way like 
$f(a,n)\prod_{p=1}^n \frac {1-a^p} {1-a} \approx \prod_{p=1}^n N(p,a)$. I think it's possible to have the representation if we can to constract the function $f(a,n)$ in a way to satisfay the approximate equality.</p>

<p>I guess it's unlikely to describe $f(a,n)$ for finite $n$, but what we can say about the function for $n \to \infty$?</p>

<p>First of all we could calculate $\prod_{p=1}^n N(p,a)$ and $\prod_{p=1}^n \frac {1-a^p} {1-a}$ to see the difference for quite large $n$ ( for eg. $n=100$, is it large for the case?). For eg. for $n=100$, $a=5$ we could get an error of about $0.01$% ( if no mistakes in numerical calculations). What does it mean for larger $n$ and what is the behaviour of $f(a,n)$ for $n \to \infty$?</p>

<p>Thank you for any help to investigate the case for infinity. </p>

<p>PS This question is related to a previous <a href=""http://mathoverflow.net/questions/103716/necklaces-and-the-generating-function-for-inversions"">one</a> asked 2 years ago when I was not sure about a mistake in the formula and asked about the influence of symmetric groups. By now I realised a mistake. This is why I am trying to improve the formula.</p>
",combinatorics
"<p>Suppose we are talking about graphs with $n$ labeled vertices. Which graphs are more common: connected or non connected?</p>
",combinatorics
"<p>Given a $n\times m$ integer matrix $A$, we can consider its row span $span(A)$, that is, the minimal sublattice of $\mathbb{Z}^m$ containing all rows of $A$.</p>

<p>Given a subset of the rows of $A$ it is possible to check in polynomial time whether they already span $span(A)$. Hence one can determine whether a given row subset is minimal (with regard to inclusion) with the property that it spans the row space of $A$ (simply try removing any row and see if the result still spans the row space of $A$). But since we work over the integers, it is possible that there are other, strictly smaller row subsets with the same property. As an example, consider the ""vectors"" 2, 3 and 1. Then {2,3} and {1} both are minimal generating sets for $\mathbb{Z}$ of differing size. This leads to my first question:</p>

<blockquote>
  <p>Is there a polynomial time algorithm
  to verify whether a given subset of
  rows spanning the row space of $A$ is
  <em>globally</em> minimal with this property?</p>
</blockquote>

<p>With ""globally"" minimal I mean that no other subset of smaller size with the desired property exists. And regarding ""polynomial time"",  I know that I am a bit vague here;  but I'd already be happy if there was something polynomial in $nm$, never mind the size of the coefficients in $A$.</p>

<p>I have the suspicion that this is the not the case. But if it is, then the natural next questions is:</p>

<blockquote>
  <p>Is there a polynomial time algorithm
  which, given $A$, computes a
  <em>globally</em> minimal subset of rows which span the full row space of $A$?</p>
</blockquote>

<p>An interesting special case arises for $m=1$:</p>

<blockquote>
  <p>Given a set $N$ of integers, is there
  a polynomial algorithm for computing a
  globally minimal subset $M$ of $N$
  such that $gcd(N)=gcd(M)$ ?</p>
</blockquote>

<p>The context where this problem arises for me is that of abelian groups: Given a set of generators of an abelian group, how can one find a globally minimal subset of these generators which still generate the whole group? Finding a minimal generating set in this case is easy, but the restriction that I need to use a subset of the original generators seems to make things quite a bit more difficult.</p>
",combinatorics
"<p>The Tverberg Theorem states the following: Let $x_1,x_2,\dots, x_m$ be points in $R^d$ with $m \ge (r-1)(d+1)+1$. Then there is a partition $S_1,S_2,\dots, S_r$ of $\{1,2,\dots,m\}$ such that $\cap _{j=1}^rconv (x_i: i \in S_j) \ne \emptyset$.</p>

<p>The bound of $(r-1)(d+1)+1$ in the theorem is sharp because there are point configurations with $(r-1)(d+1)$ points that do not have a Tverberg partition of length $r$.</p>

<p>My question is about lowering this bound by imposing some structure to the points. That is: if we have a full dimensional point configuration $S$ with $m$ points in $R^d$ such that $m\leq(r-1)(d+1)$, can we put conditions on $S$ which still guaratee the existence of a Tverberg partition of length $r$?</p>

<p>Gil Kalai has some very nice posts on the Tverberg Theorem in his blog: <a href=""http://gilkalai.wordpress.com/2008/11/24/sarkarias-proof-of-tverbergs-theorem-1/"" rel=""nofollow"">http://gilkalai.wordpress.com/2008/11/24/sarkarias-proof-of-tverbergs-theorem-1/</a> , <a href=""http://gilkalai.wordpress.com/2008/11/26/sarkarias-proof-of-tverbergs-theorem-2/"" rel=""nofollow"">http://gilkalai.wordpress.com/2008/11/26/sarkarias-proof-of-tverbergs-theorem-2/</a> and <a href=""http://gilkalai.wordpress.com/2008/12/23/seven-problems-around-tverbergs-theorem/"" rel=""nofollow"">http://gilkalai.wordpress.com/2008/12/23/seven-problems-around-tverbergs-theorem/</a> .</p>
",combinatorics
"<p>A set system $\mathcal{U}\subset P([n])$ is</p>

<ul>
<li>an <em>upset</em> if $B\supset A \in \mathcal{U}$ implies $B\in \mathcal{U}$,</li>
<li><em>intersecting</em> if $A,B\in\mathcal{U}$ implies $A\cap B \ne \emptyset$.</li>
</ul>

<p>Note that a nonnegative linear combination of (indicator functions of) upsets is just an increasing function $f:P([n])\to[0,\infty)$, and it is a straightforward task to decompose any such $f$ back into its constituent upsets: just remove an appropriate multiple of $\mathcal{U}_1 = \lbrace A: f(A)&gt;0 \rbrace$ and repeat.</p>

<p>However, given a nonnegative linear combination $f$ of <em>intersecting</em> upsets, how can one find appropriate intersecting upsets $\mathcal{U}_i$ and coefficients $\lambda_i$ such that $f = \sum \lambda_i \mathcal{U}_i$?</p>
",combinatorics
"<p>Let $A_n$ be the average number of comparisons to sort $n$ keys by merging them in a top-down fashion (see any algorithm textbook). It can he shown that
$$
A_0 = A_1 = 0;\quad A_n = A_{\lfloor{n/2}\rfloor} + A_{\lceil{n/2}\rceil} + n - \frac{\lfloor{n/2}\rfloor}{\lceil{n/2}\rceil+1} - \frac{\lceil{n/2}\rceil}{\lfloor{n/2}\rfloor+1}.
$$
(See Knuth's AOCP, for instance.)
Flajolet and Golin in 1993 used complex analysis (Mellin transforms) and Fourier analysis to find a precise asymptotic approximation of $A_n$. I am interested in finding lower and upper bounds on $A_n$ of the form $n\lg n + \alpha n + \beta$, where $\lg n$ is the binary logarithm, <em>not</em> using these powerful but complicated analytical approaches.</p>

<p>By distinguishing on the parity of $n$, we simply get
$$
A_{2p} = 2 A_{p} + 2p - 2 + \frac{2}{p+1};\quad A_{2p+1} = A_{p} + A_{p+1} + 2p - 1 + \frac{2}{p+2}.
$$
I tried difference equations, by letting $\Delta_n := A_{n+1} - A_{n}$, yielding
$$
\Delta_{2p} = \Delta_{p} + 1 + \frac{2}{p+2} - \frac{2}{p+1};\quad \Delta_{2p+1} = \Delta_p + 1.
$$
Then, I am stuck.</p>

<p>The same study for the maximum number of comparisons leads to simpler difference equations: $\Delta_{2p} = \Delta_{2p+1} = \Delta_{p} + 1$, which implies $\Delta_n = \lfloor{\lg n}\rfloor + 1$, to wit, the number of bits in the binary expansion of $n$. From there, a closed form for the maximum cost $\sum_{k=1}^{n-1}\Delta_k$ follows relatively easily (see Flajolet and Sedgewick, for instance).</p>

<p>Any idea how to bound $\Delta_k$ and $\sum_{k=1}^{n-1}\Delta_k$ in the present case?</p>
",combinatorics
"<p>I had posted an <a href=""http://mathoverflow.net/questions/29606/what-is-being-counted-closed"">urn probability problem</a> that didn't have good motivation.  I'd like to try to explain the motivation here, and reintroduce the problem.</p>

<p>Consider binary sequences of length $2n$.  Let's say we put a marker in such a sequence as soon as we see a total of $n$ 0's or $n$ 1's, reading left to right.  For example, if $n=4$, then the sequence 00101011 would receive a marker thus:  001010|11.  Now write down the bits to the right of the marker.  In the case of our example, this would be 11.  Do this for every binary sequence of length $2n$.  We observe that we have written down 
$2n\binom{2n}{n}$ bits, half 0's and half 1's.  It is possible to prove this observation using binomial coefficient identities, but I wonder whether there is a simple bijective proof.  </p>

<p>The previous urn problem was an equivalent probabilistic formulation of the case $n=5$.</p>
",combinatorics
"<p>Goal:</p>

<p>I want to generate a r-regular graph with n vertices. rn = 2m.</p>

<p>Current best:</p>

<pre><code>(1) take n vertices; randomly pick a vertex v of degree &lt; r.
(2) S = set of all vertices of degree &lt; r, and not a neighbor of v.
(3) create an edge between v and a random element of S.
(4) repeat.
</code></pre>

<p>Question:</p>

<p>Is there a more parallel way to do this?</p>

<p>Clarification:</p>

<p>Suppose I wanted to randomly pick an element in [1...n].
  I could do it sequentially like:</p>

<pre><code>take 1 w/ prob 1/n
else take 2 w/ prob 1/n-1
else take 3 w/ prob 1/n-2
...
</code></pre>

<p>Or I could do it ""one shot"" by generating a random element between [1...n].</p>

<p>Similarly, I want to generate a r-regular graph ""one shot"" rather than an single edge at a time.</p>

<p>Goal:</p>

<p>This is to build mental intuition of what it means to ""uniformly pick a r-regular graph.""</p>

<p>Thanks!</p>
",combinatorics
"<p>Consider $9n$ pencils through non-collinear points $p_1, \ldots , p_{9n}$ in $R^2$ each consisting of at most $n$ concurrent lines. Define the intersection $S$ of these pencils to be the set of points which lie on at least one line in each of the $9n$ pencils. Is it true that $|S|$ is $O(n)$? </p>
",combinatorics
"<p>The set of $n\times n$ real, nonnegative matrices whose rows and columns sum to one forms the well-known <a href=""http://en.wikipedia.org/wiki/Birkhoff_polytope""><em>Birkhoff polytope</em></a></p>

<p>Recently someone asked me if I knew</p>

<blockquote>
  <p>How to sample (in polynomial time) uniformly at random, from the Birkhoff polytope?</p>
</blockquote>

<p>Clearly, modulo a few hacks, I did not have a good answer, so am repeating the above question here (the hacks included trying to exploit that every doubly stochastic matrix is a convex combination of permutation matrices).</p>
",combinatorics
"<p>Let $m_1,\ldots, m_n$ be pairwise coprime natural numbers $\geq 1$. We consider the product $$G(m_1,\ldots,m_n) := \prod_{i=1}^{n} \mathbb{Z} / m_i \mathbb{Z}.$$ We define $M(n)$ as the set $n$-tuple of natural numbers $\geq 1$ with the property that the entrys are pairwise coprime. We define $l : M(n) \rightarrow \mathbb{N}_0$ by $$l(m_1,\ldots,m_n) = \max_{(x_1,\ldots,x_n) \in G(m_1,\ldots,m_n)} \min \{ k \in \mathbb{N}_0 | x_i+k \neq 0 \forall 1 \leq i \leq n \},$$
hence $l(m_1,\ldots,m_n)$ may be regarded as the maximal distance of the elements of $G$ from the elements which have no identity in their entrys. It is clear, that $l(m_1,\ldots,m_n)$ is always a natural number.</p>

<p>The question is now: Does there exist a real number $r$, such that $$r \cdot n \cdot \ln (n) \geq \sup_{(m_1,\ldots,m_n) \in M(n)} l(m_1,\ldots,m_n)$$ holds for all $n &gt;&gt; 0$ and is it possible to take $r=2$ ?</p>
",combinatorics
"<p>So let $S_N$ be the symmetric group of degree $N$. We think of it as a permutation group via its
natural action on the set $T=\{1,2,\ldots,N\}$.</p>

<p>Say that $H\leq S_N$ is a subgroup which acts transitively on $T$. However, I DONT'T WANT to assume necessarily that $H$ is primitive (that is the whole point of my question). Assume furthermore that there is an onto group homomorphism
$$
f:H\rightarrow S_n
$$
where $n=\lfloor{N/2}\rfloor$. In fact, as was pointed out by Schmidt, the existence of this onto group homomorphism implies that $H$ is imprimitive.</p>

<p>In general, one cannot rule out the existence of such an $H$. For example 
one could have $H=S_n\ltimes\mathbf{F}_2^n$ where $N$ is even and $n=\frac{N}{2}$.
We let $H$ act on $T$ in the following way: We divide $T$ in $n$ disjoint blocks of size $2$. We let $S_n$ permute the $n$ blocks without swapping the pair in each block, and we let $\mathbf{F}_2^n$ permute (resp. acts like the identity) the two elements in the i-th block if the i-th coordinate of an element $\sigma\in \mathbf{F}_2^n$ is $\overline{1}$ (resp. $\overline{0}$). It thus follows that $H$ acts transitively (but imprimitively) on $T$.</p>

<p>Furthermore, suppose that I can produce "" a lot of elements "" in  $H$ which contain a cycle of length $r$ in their cycle presentations (their writing as a product of disjoint cycles of $T$) for $r&gt;n$. Then may I conclude that such an $H$ does not exist?</p>

<p>Q1: Is there some kind of results that would allow me to conclude that $H\supseteq A_N$, so that this would contradict the imprimitivity and therefore rule out the existence of such an $H$?</p>

<p>For example here is one key result which is good to know: if $H$ is assumed to be primitive and contains a cycle of length $\ell$ with $2\leq \ell\leq N-7$ ($\ell$ not necessarily prime) then combining classical results on permutation group theory one may show that $H\supseteq A_N$. However, since in my setting $H$ is imprimitive I cannot apply this result.</p>

<p>Q2: Do we have a good understanding of the tree of subgroups of $S_N$, especially
the maximal subgroups? </p>

<p>Q3: Is there some kind of probabilistic result that could be used in my context?</p>
",combinatorics
"<p>Let $\Gamma=(G,E)$ be a connected undirected graph, with no loops or multiple edges. $G$ is finite or countably infinite.  For each edge $e=\{x,y\}\in E$, we assign a positive, symmetric edge weight $c_e := c_{\{x,y\}} = c_{xy} = c_{yx}$.  I would like to know for which graphs $\Gamma$ it is possible to choose $(c_e)_{e\in E}$ so that for each $x\in G$,</p>

<p>\begin{equation*}
\sum_{y\sim x} c_{xy} = 1.
\end{equation*}</p>

<p>For example, this is possible on any $d-$regular graph if one sets $c_e \equiv 1/d$.  The graph with vertex set $\{x,y,z\}$ and edges $\{x,y\}$ and $\{y,z\}$ shows that it is not always possible.</p>
",combinatorics
"<h2>Question</h2>

<blockquote>
  <p>Are there efficient algorithms to check if a finite simplicial complex defined in terms of its maximal facets is shellable? </p>
</blockquote>

<p>By efficient here I am willing to consider anything with smaller expected complexity than the exponential mess one gets by naively testing all possible orderings of maximal facets.</p>

<h2>Background</h2>

<p>Let $\Delta$ be a simplicial complex and for each simplex $\sigma \in \Delta$ let $\bar{\sigma}$ denote the subcomplex generated by $\sigma$ and all its faces. Fix an ordering of its maximal facets $F_1,\ldots,F_K$, pick some $k \in \lbrace 1,\ldots,K\rbrace$ and define $\Delta_k$ to be the subcomplex generated by $\bigcup_{1\leq j \leq k} F_j$, i.e., all facets up to and incluing the $k$-th one. </p>

<p><strong>Definition:</strong> We call this ordering of maximal facets a <em>shelling</em> if the intersection $\overline{F_{k+1}} \cap \Delta_k$ is a simplicial complex of dimension $\dim (F_{k+1}) - 1$ for each $k \in \lbrace 1,\ldots,K-1\rbrace$.</p>

<p>In general, the complex $\Delta$ need not be a combinatorial manifold or have a uniform top dimension for its maximal facets. It is known that <em>if</em> $\Delta$ is shellable <em>then</em> there exists a shelling by maximal facets ordered so that the dimension is decreasing along the order. So one method to simplify the computational burden is to test only those orderings $F_1,\ldots,F_K$ of maximal facets so that $\dim F_i \geq \dim F_j$ whenever $i \leq j$, but of course in the worst case all these facets could have the same dimension.</p>

<h2>Motivation</h2>

<p><a href=""http://en.wikipedia.org/wiki/Shelling_%28topology%29"">Shellability</a> is an extremely useful notion in topological combinatorics: many interesting simplicial complexes and posets in this field turn out to be shellable. I refer you to the works of Anders Bjorner and others for details, see <a href=""http://www.jstor.org/stable/1999359"">here</a> or <a href=""http://www.combinatorics.org/Volume_16/PDF/v16i2r1.pdf"">here</a> or... Since every shellable complex is a wedge of spheres, establishing shellability leads to all sorts of interesting conclusions. Among other things, shellable complexes must lack torsion in homology of all dimensions.</p>
",combinatorics
"<p>Let $k&lt;N$ and $P_1, ..., P_{2k+1}, \lambda_1, ..., \lambda_k$ be elements of a finite group $G$ of size $N$.</p>

<p>Find the minimum number of solution of the system </p>

<p>$$P_{2i} + P_{2i+1} = \lambda_i, \forall i\leq k$$</p>

<p>with the condition that the $P_1, ..., P_{2k+1}$ are pairwise distinct.</p>

<p>The law ""+"" on the $n-$bits strings is the ""xor"" ie we consider the n-bit strings as element of $(\mathbb{Z}/2\mathbb{Z})^n$.</p>
",combinatorics
"<p>I found the following closed form solution for the abovementioned problem:</p>

<p>$${1\over k^n}\cdot{k!\over (k-m)!}\cdot{\{{n\over m}\}}$$ with ${\{{n\over m}\}}$ being the Stirling Number of the second kind.</p>

<p>Although it seems to have some intuition and seems to work for a sample problem for which I have the solution this closed form is not from a trusted source. Unfortunately I can't find any other source.</p>

<p><strong>My question</strong>: Could anyone acknowledge this closed form solution and/or give me a hint where to find a citable source.</p>
",combinatorics
"<p>Given two positive integers $n, m$, let $A$ be a multiset of $n$ integers taken from { $ 1,2,\cdots, m$ }, and $B$ be a multiset of $m$ integers taken from { $1,2,\cdots,n$ }.</p>

<p>Is it always possible to choose two nonempty subsets from $A$ and $B$ respectively, such that their sums are equal?</p>

<p>I cannot either prove or disprove it. Trying some examples made me conjecture that it is true.</p>
",combinatorics
"<p>By a graph I mean a pair $G = (V, E)$ where $V$ is a set and $E \subseteq \mathcal{P}_2(V) := \{\{a,b\}: a\neq b \in V\}$. We write $V(G) := V$.</p>

<p>If $S, T$ are disjoint subsets of $V(G)$ we say that $S, T$ are <em>connected to each other</em> if there is $s\in S, t\in T$ such that $\{s,t\}\in E(G)$. If $G,H$ are graphs, we say $H$ is a <em>minor</em> of $G$ (in symbols $G \geq_{\text{min}} H$) if there is a family ${\cal S}$ of pairwise disjoint connected subsets of $V(G)$ and a bijection $\varphi:V(H)\to {\cal S}$ such that whenever $\{v,w\}\in E(H)$ then $\varphi(v)$ and $\varphi(w)$ are connected to each other.</p>

<p>Let $C$ be the set of graphs such that $V(G)=\mathbb{N}$. We set $$E = \big\{\{G,H\}: (G,H\in C) \land (G\geq_{\text{min}} H \lor H \geq_{\text{min}} G)\big\}.$$
Let $G_{\mathbb{N}} = (C,E)$ and let ${\cal I}$ be the collection of independent sets in $G_{\mathbb{N}}$.</p>

<p><strong>Question</strong>: Set $\kappa = \text{sup}\{|I|: I\in {\cal I}\}$. What is the value of $\kappa$, and does $G_{\mathbb{N}}$ have an independent set $I_0$ such that $|I_0| =\kappa$?</p>
",combinatorics
"<p>Let $G= (V,E)$ be a finite, undirected and unweighted graph with $V = \{v_1,\ldots, v_n\}$. Denote by $d_i$ the degree of $v_i$, i.e. the number of vertices that are adjacent to $v_i$. Let $A$ be the adjacency matrix of $G$ and $D = diag(d_1, \ldots d_n)$. Then the Laplacian of $G$ is defined to be 
$$L = D - A$$ 
and the normalized Laplacian
$$\Delta = I - D^{-1}A$$
(I assume that $d_i \neq 0$ for all $i$). Denote by $\lambda_0 \leq \lambda_1 \leq \ldots \leq \lambda_{n-1}$ the eigenvalues of $\Delta$. Then $\lambda_0 = 0$ and $\lambda_{n-1} \leq 2$.</p>

<p>Most results in spectral graph theory focus on $\lambda_1$ and $\lambda_{n-1}$ as they determine global properties of $G$ very nicely. I'm also familiar with some results that show a connection between $\lambda_k$ and how hard it is to partition $G$ into $k+1$ subgraphs. </p>

<p>However, looking at some examples it seems to me that there should be some characterization of when $\Delta$ has EV $1$. I believe that this is connected to the occurrence of special subgraphs but I'm having a hard time finding papers/literature that deal with that topic. So my question is: Are there papers dealing with characterizing non-extremal eigenvalues of $\Delta$ and especially $\lambda = 1$?</p>
",combinatorics
"<p>Let $D$ be the digraph on $2^d$ vertices with $d2^d$ edges that we obtain by directing each edge of the $d$-dimensional hypercube in both directions.</p>

<blockquote>
  <p>Can we partition the edges of $D$ into $d$ directed Hamiltonian cycles?</p>
</blockquote>

<p>An alternative formulation would be to ask whether the hypercube has a so-called directed double cover by Hamiltonian cycles.</p>

<p>For $d\le 2$ the statement holds but quite embarrassingly I'm stuck already at $d=3$.</p>
",combinatorics
"<p>I have a list (vector) of positive integer numbers, including repetitions. For example,
$L = [1, 1, 4, 1, 3]$;
I want to calculate the number of different sums obtained by using the elements of $L$, according to their multiplicities.</p>

<p>For example, if $L = [10, 30, 100]$, these sums are
$$
sum = \{0, 10, 30, 40, 100, 110, 130, 140\}
$$
because
$$
sum = \{0,10,30,10+30,100,100+10, 100+30, 100+10+40\}
$$</p>

<p>The problem is to determine the cardinality of the $sum$ set.</p>

<p>In the last case, $|sum| = 2^3 = 8 $; however, if 
$L = [1,1,1,1]$, then
$$
sum = [0,1,2,3,4]
$$
and $|sum| = 5$.</p>

<p>Must I check all possible $2^k$ ways of sum the elements of $L$ (where $k$ is the length of $L$) in order to calculate $|sum|$?</p>
",combinatorics
"<p>Suppose we have a simple connected graph $G=(V,E)$. Then let $A$ be its $|E|\times |V|$ incidence matrix. Here I am considering the unoriented incidence matrix. I want to known when the row span of $A$ contains the all ones vector in $\mathbb{R}^{|V|}$. I believe this happens if and only if $G$ has a spanning regular subgraph. One direction is of course clear. Does anyone know if this is true/ have a  counterexample?</p>
",combinatorics
"<p>The <em>Levenshtein distance</em> or <em>Edit distance</em> $$ lev(U,V) $$ between two strings $U$ and $V$ over a finite alphabet $\Sigma$ of size $ \left| \Sigma \right| = \sigma ,$ is the minimal number of insertions, deletions  and replacements  to make the strings equal.</p>

<p>For $k \in \mathbb{N} $ and $U \in  \Sigma^*$ we define :</p>

<p>$$ N_k(U) = \{ V \in  \Sigma^* : lev(U,V)  \leq k \}  $$</p>

<p>For example if $\Sigma = \{A,B,L\}$ : </p>

<p>\begin{eqnarray*}
 N_1(AAA) &amp;=&amp; \{ AAA, AA, AAB, AAL, ABA, ALA, BAA, LAA, AAAA, BAAA,  \\ &amp;&amp;LAAA, ABAA, ALAA, AABA, AALA, AAAB, AAAL \}  \\
N_1(LAB) &amp;=&amp; \{LAB, LA, AB, LB, AAB, BAB, LBB, LLB, LAA, LAL, ALAB, \\
&amp;&amp;BLAB, LLAB, LAAB, LBAB, LALB, LABA, LABB, LABL\} 
\end{eqnarray*}</p>

<p>My goal is to compute for $\Sigma, n $ and $k$ fixed  :</p>

<p>$$ \max_{U \in  \Sigma^* , ~ \left| U \right|  = n}  \left|N_k(U) \right| $$</p>

<p>or an upper bound $f(\Sigma,k,n)$.</p>

<p>I conjecture that the maximum is reached for the words of the form :</p>

<p>$$ c_1c_2 \dots c_{\sigma}c_1c_2 \dots c_{\sigma}\dots $$</p>

<p>where $\Sigma = \{  c_1,c_2, \dots,c_{\sigma}  \}. $</p>

<p>Does anyone have an idea of how to compute $ \max_{U \in  \Sigma^* , ~ \left| U \right|  = n}  \left|N_k(U) \right| $ or to prove this conjecture?</p>

<p>A special case has already been studied in the section 6 of the paper <strong>What's Behind Blast</strong> by Gene Myers.</p>
",combinatorics
"<p>Let $n$ be an even positive integer and $W_n$ be the class of all $n\times n$ matrices with entries from the set $\{-1,0,1\}$ satisfying all row sums and column sums are equal to $0$.</p>

<p>For any $M\in W_n$, let $k(M)$ be the number of $1$ in $M$. I think the number of $M\in W_n$ with $k(M)$ is even is much bigger than the number of $M\in W_n$ with $k(M)$ is odd, am I right?</p>
",combinatorics
"<p>For $i=1,2,\dots,l$, let $\mathbf{v}_i =(v_{i1},v_{i2},\dots,v_{in}) \in \mathbb{F}_2^n$ be a sparse vector in GF(2) such that all $v_{ij}$'s are independent for all $1 \le i \le l, 1 \le j \le n$ and  $$\mathrm{Pr}[v_{ij}=1] = \frac{\log(n)}{n}, \qquad 1 \le i \le l, 1 \le j \le n \\\mathrm{Pr}[v_{ij}=0] = 1-\frac{\log(n)}{n}, \quad 1 \le i \le l, 1 \le j \le n$$ 
Let $\mathbf{e}_1 = (1,0,0,\dots,0) \in \mathbb{F}^n_2$ be a base vector in GF(2) in which the only non-zero element is the first element. What can we say about the probability that this base exists in the span of the vectors $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_l$?
$$\mathrm{Pr}[~\mathbf{e}_1 \in \mathrm{Span}\{\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_l\}~] = ~?$$
This probability quickly approaches 1 as $l$ approaches $n$ but is it possible to find a closed form for this probability in terms of $l$ and $n$? If not, can we find good upper and/or lower bounds for this probability in terms of $l$ and $n$? </p>
",combinatorics
"<p>Is there a classification of groups having the property that any set of $d$ elements (say including the identity) is contained in a proper subgroup?</p>

<p>It is appealing to call the maximum such integer (when finite) some sort of ""dimension"" or measure of being ""not cyclic"".  As one example, we have elementary abelian groups of order $p^d$.  I haven't thought much about nonabelian groups, but there are examples.</p>

<p>Disclaimers:  Apologies if this is either a trivial classification or not of much research interest.  It is perhaps well-studied already, but I don't know what to call this property.  I thought I'd try to ask, since this is a group-theoretic analog of something else which interests me.  Should I try group pub forum instead?</p>

<p>Thanks in advance.</p>
",combinatorics
"<p>Here is a group theoretic phrasing of a special case of the union closed conjecture:</p>

<blockquote>
  <p><strong>Question:</strong> Given a finite group $G$, is there an element of prime power order which is contained in <em>at most</em> half the subgroups of $G$?</p>
</blockquote>

<p><strong>Motivation</strong>: 
Frankl's <a href=""http://en.wikipedia.org/wiki/Union-closed_sets_conjecture"">union closed sets conjecture</a> has an equivalent phrasing in terms of lattices. It says that in every finite lattice there is a join irreducible element which is less than or equal to at most half the elements in the lattice. </p>

<p>Finite lattices are always isomorphic to intervals of subgroups $[H,G]$ for groups $H,G$ (i.e. the lattice of subgroups $H\subseteq K \subseteq G$, with the subgroup relation). <a href=""http://mathoverflow.net/questions/85724/given-a-lattice-l-with-n-elements-are-there-finite-groups-h-g-such-that-l-c?rq=1"">It is not known</a> whether it suffices to take $H$ and $G$ to be finite. I wonder if anything about Frankl's conjecture is known for the case when $H$ is the trivial group. And that is precisely what is asked above. Notice that the elements of prime power order are in correspondence with the join irreducibles of the lattice of subgroups of $G$.</p>

<p>Is the answer to the question above known? Is this known for special classes of groups?</p>
",combinatorics
"<p>I've been trying to find a definition of an <em>infinite permutation</em> on-line without much success. Does there exist a canonical definition or are there various ways one might go about defining this?</p>

<p>The obvious candidate I guess would be a bijection p : {1,2,...} -> {1,2,...} between the natural numbers. One might also try to use the Robinson-Schensted correspondence between permutations of length n and pairs of standard Young tableaux of size n. Then one would need a definition of infinite Young tableaux.</p>

<p>Another correspondence that might be used is between permutations and permutation matrices.</p>
",combinatorics
"<p>I am interested in any and all articles about chromatic numbers applying to constrained colorings of a graph.  For example, if a graph must be (properly) colored so that there is a 2-color path between a specified pair of nonadjacent vertices, the chromatic number may be greater than if the constraint were not imposed.  I have in mind a particular constraint of that type described in the following.</p>

<p>In the article <a href=""http://arxiv.org/abs/1511.06872"">http://arxiv.org/abs/1511.06872</a>, I provide strong support for the conjecture presented below. The conjecture is interesting because if true then the 4-color theorem is obviously true.  But it is also interesting for another reason just as significant.  If it is true, then one can prove the 4-color theorem by means of Kempe exchanges alone for all internally 6-connected planar triangulations other than the icosahedron. The reason for the failure of Kempe exchanges in the case of the icosahedron lies with the coloring property that I described in my previously posted question. The article referenced above discusses this topic by means of equivalence classes under Kempe exchanges.</p>

<p><strong>Definition.</strong> An ""a-graph"" is an almost-triangulated-graph; its sole non-triangular face has size 4.</p>

<p><strong>Definition.</strong> Let $G$ be an a-graph with boundary cycle $uxvy$. The ""chromatic number $\chi_{G}(u,v;x,y)$"" is the minimum number of colors required to properly color $G$, subject to the constraint that there is a 2-color path between $x$ and $y$ that does not use the color(s) of $u$ and $v$.</p>

<p><strong>Conjecture.</strong> Let $uv$ be any edge in an internally 6-connected planar triangulation $T$ and let $G$ be the a-graph obtained by deleting $uv$ to form a 4-face with boundary cycle $uxvy$. Then $max[\chi_{G}(u,v;x,y),\chi_{G}(x,y;u,v)] &gt; 4$ if and only if $T$ is isomorphic to the icosahedron.</p>
",combinatorics
"<p>An order-$n$ magic square is an $n \times n$ matrix over the numbers $\{1, ... ,n^2\}$, each appearing exactly once, whose row and column sums are all equal. Sometimes the sums of the diagonals are required to be equal too.</p>

<p>These objects have a rich history, and they are hugely popular in recreational math. I remember being fascinated by constructions of magic squares when I was 10. It seems natural to ask how many order-$n$ magic squares are there? An exact formula is probably too much to hope for, but it is probably possible to give some asymptotic bounds.</p>

<p>Has anybody asked this question before? Are there known bounds on the number of order-$n$ magic squares?</p>
",combinatorics
"<p>Given $n$, what is the largest set of consecutive integers in $[n,2n]$ can we have so that each integer is divisible by a distinct element from $[\log n,2\log n]$ (no partiular order)? So apriori I am asking if we can achieve the maximum of $\log n$ consecutive integers.</p>
",combinatorics
"<p>For any set $X$ we set $[X]^2 = \big\{\{a,b\}: a, b\in X\text{ and } a\neq b\big\}$.</p>

<p>We say a simple undirected graph $G=(V,E)$ is an $n$-<em>clique graph</em> if there are $S_1,\ldots,S_n\subseteq V$ such that</p>

<ol>
<li>$|S_k| = n$ for all $k=1,\ldots, n$;</li>
<li>$V = \bigcup_{k=1}^n S_k$;</li>
<li>$i\neq k \in \{1,\ldots,n\}$ implies $|S_i \cap S_k| = 1$.</li>
<li>$E = \bigcup_{k=1}^n [S_k]^2$ (that is, all the $S_k$ are complete, and there are no edges between different $S_k$.)</li>
</ol>

<p>Let $c(n)$ be the maximum length of an <a href=""https://en.wikipedia.org/wiki/Induced_path"" rel=""nofollow"">induced cycle</a> that any $n$-clique graph $G$ can have. Is there an explicit formula for $c(n)$, and if not, what is $\lim_{n\to\infty}\frac{c(n)}{n}$?</p>
",combinatorics
"<p>We all know Hall's marriage theorem as following:</p>

<blockquote>
  <p>A bipartite graph $G$ with bipartition $\{ A,B \}$ contains a matching of $A$ if and only if $|N(S)|\geq |S|$ for all $S\subseteq A$.</p>
</blockquote>

<p>And I am thinking about a generalized theorem of it.</p>

<blockquote>
  <p>A bipartite graph $G$ with bipartition $\{ A,B \}$ contains a $k$-matching of $A$ if and only if$|N(S)|\geq k|S|$ for all $S\subseteq A$. (A $k$-matching means a subgraph $G'$ of $G$ which $A\subseteq G'$ and $d_{G'}(A_i)=k$ and for $i\neq j$, $neighbor(A_i) \cap neighbor(A_j)=\varnothing$)</p>
</blockquote>

<p>Is it right? How to prove?</p>

<p>See a math.SE post: <a href=""http://math.stackexchange.com/questions/1481389/a-generalized-theorem-of-halls-marriage-theorem"">http://math.stackexchange.com/questions/1481389/a-generalized-theorem-of-halls-marriage-theorem</a></p>
",combinatorics
"<p>Let's say that the linear form $ax+by$ represents $n$ if $ax+by=n$ for some positive integer $x$ and $y$. </p>

<p>Call a pair $(a,b)\in\Bbb N\times\Bbb N$ with $\mathsf{gcd}(a,b)=1$ <em>good</em> if,
for any $r,s,u,v&gt;1$ with each of $rs,uv,ru,sv,rv,su&lt;(a-1)(b-1)$ (the Frobenius number of $(a,b)$), there is at most one set from among $\{rs,uv\}$, $\{ru,sv\}$ and $\{rv,su\}$ with both components representable by $ax+by$.</p>

<p>Do good pairs exist at all?</p>

<p>If they do, then is it true that for every sufficiently large integer $l$, there is a good pair $(a,b)$ with $a,b\in[l,2l]$?</p>

<hr>

<p>A bad pair example:</p>

<p>$a=22,b=21,s = 16, t = 17,r = 19,u = 15$</p>

<p>$$10a+4b=rs$$
$$8a+7b=rt$$
$$9a+2b=su$$
$$3a+9b=tu$$</p>

<hr>

<p>Related <a href=""http://mathoverflow.net/questions/225047/chain-divisibility-constraints-in-frobenius-coin-problem"">Chain divisibility constraints in Frobenius coin problem</a></p>
",combinatorics
"<p>Is there an explicit formula for the following quantity?</p>

<p>$$f_m(a_1,\ldots,a_n):=\sum_{\substack{k_1+\ldots+k_n=m \\ k_1,\ldots,k_n\in \mathbb{N}}} k_1^{a_1}\ldots k_n^{a_n}\ ,\hspace{1cm} m,a_1,\ldots,a_n\in \mathbb{N}$$</p>

<p>(for instance $f_m(0,\ldots,0)$ is simply the number of compositions of m into n parts, $f_m(1,1)=\frac{m(m+1)(m-1)}{6}$ and so on). I would like an answer both for the case where the $k_i$'s can and cannot attain the value $0$, if possible.</p>
",combinatorics
"<p>Imagine a vector $\boldsymbol{v}$ composed of integers, and the set $S$ of all integer vectors within a hyper-rectange, with one corner at the origin and other at $\boldsymbol{m}$.  In other words: $S = \{\boldsymbol{u} : m_i \gt u_i \ge 0 \} $.  Alternately, you may think of $S$ as the Cartesian product of a multiple integer ranges $[0, m_i)$.  At any rate, imagine the set of all dot products $P = \{\boldsymbol{v} \cdot \boldsymbol{u} : u \in S\}$.  Given a specific $\boldsymbol{v}$ and $\boldsymbol{m}$, what can be said of the cardinality of $P$? </p>

<p>For example: if $\boldsymbol{v} = \{1, 1, 10\}$, and $\boldsymbol{m} = \{3,3,3\}$, $P = 6 * 3 = 18$.  This is because the first two dimensions of $\boldsymbol{m}$ both project to overlapping regions, while the final dimension does not.  </p>

<p>In general, I'm curious if there is a faster way to compute $|P|$ than brute force, particularly for low dimensions (say &lt; 10), but potentially large values of $m$ such that the total number of elements in $S$ is very large. Also, any literature references would be great. I feel like this belongs to some subproblem of integer latices, but I can't seem to get the right keywords.</p>
",combinatorics
"<p>For a set $C\subseteq \mathbb F_2^n$, let $2C=C+C:=\{\alpha+\beta\colon \alpha,\beta\in C\}$.
I want to find $C$ of the smallest possible size such that $2C=\mathbb F_2^n$. Let $m(n)$ be the size of a minimal $C$. I have found the following bounds:
  $$m(n) \ge B(n):=\frac{1+\sqrt{2^{n+3}-7}}{2} $$
and
  $$ m(n) \le A(n) := \left\{\begin{array}{ll} 2^{\frac{n+2}{2}}-2 &amp; {\rm if}\, n\ge4\,{\rm is}\, {\rm even},\\
2^{\frac{n+1}{2}}+2^{\frac{n-1}{2}}-2 &amp; {\rm if}\, n\ge5\,{\rm is}\, {\rm odd}.
\end{array}\right. $$</p>

<p>It is easy to see that $$\lim_{n\rightarrow\infty}{\frac{A(2n)}{B(2n)}=\sqrt{2}},\quad\lim_{n\rightarrow\infty}{\frac{A(2n+1)}{B(2n+1)}}=\frac{3}{2}.$$The last equations show that there might be some improvements for lower or/and upper bounds. </p>

<p>Also I have found the following results if it can help:$$m(1)=1,m(2)=3,m(3)=5,m(4)=6,m(5)=10,m(6)\in\{12,13,14\}.$$</p>

<p>With great probability $m(6)=14$ (actually I am using randomized algorithm to find possible solutions and it didn't find better results for $n=6$ than 14)․ This
sequence could be either <a href=""https://oeis.org/A099190"">https://oeis.org/A099190</a> or <a href=""https://oeis.org/A176747"">https://oeis.org/A176747</a>. But unfortunately both are excluded, because for $n=7$ they can't match with it. Also I would like to mention that upper bounds are not the best. For example for $n=7$ computer found $C$ such that $|C|=20$. Also better results were found for $n=8,9,10$.</p>

<p>Actually this problem is related with my thesis and I understand that I should do it myself but I have been thinking about it for about two months and I can't find any clever method to get better bounds. Any hints and suggestions would be very appreciated.</p>

<p>Thanks!</p>
",combinatorics
"<p>This question is pretty simple to state: given two linear functions on a polygon, I'm looking for a formula for the integral of their product which depends only on the values at the (unlabelled) edges and on the shape of the polygon. However, the motivation comes from a problem I've been investigating for a while, so I thought I might as well elaborate for the sake of context (the previous question in the series is <a href=""http://mathoverflow.net/questions/78996"">here</a>). My understanding of the problem is gradually progressing, and with it the way in which I formulate it. Quick recap:</p>

<p>I'm interested in variations of piecewise linear surfaces in ℝ<sup>3</sup> (which need not be triangulated). Fixing the ""combinatorial type"" of a surface - i.e. the way vertices, edges and faces are joined together - I have found that the space of variations has dimension E + 3χ, with E the number of edges and χ the Euler characteristic. For surfaces homeomorphic to a sphere, we get E+6 with 6 dimensions corresponding to translations and rotations.</p>

<p>I would like to find an inner product on the space of variations, with the following caveat. There are operations which change the combinatorial structure of a surface but not its actual shape - such as adding a ""flat"" edge across a non-triangular face, or an edge of zero length at a vertex where more than three faces meet. In such cases there is a natural inclusion of the variations of the original surface into the variations of the new one, and I would like my inner product to be preserved under this inclusion.</p>

<p>I've been proceeding by analogy with the smooth case: each variation induces a unique normal vector field on every face, so we can take the pointwise product of these and then integrate. This inner product is intuitively consistent in the sense described in the previous paragraph.</p>

<p>Because variations must preserve linearity of the faces, the vector fields are linear on each face - so we can write them, and their product, in terms of the vertices or edges. In particular, for a triangular face the inner product is the average of the (pointwise) products on the centres of the edges, multiplied by the area of the face.</p>

<p>This is promising: for triangulated surfaces, I now have an expression which depends only on the edges. But I'm having trouble extending this to non-triangular faces. I've tried triangulating a polygon in various specific and generic ways, and so far all I've got is a mess. But maybe I'm being stupid. Any suggestions?</p>
",combinatorics
"<p>Consider the general polynomial $P_1(t) = \prod_{j=1}^n (t+x_j)$.
Construct $P_k(t) = \prod_{\sigma \subset [n], |\sigma|=k} (t+x_{\sigma_1}x_{\sigma_2}\cdots x_{\sigma_k})$
where the product is over all subsets of size $k$ of the numbers $1,2,\dots,n.$
The coefficients of $P_1(t)$ will be the elementary symmetric polynomials in $x_1,\dots,x_n$
and it is easy to argue that the coefficients in $P_k(t)$ are polynomials in
the coefficients of $P_1.$</p>

<p>Now, my question is rather vague but I seek references to areas where these types of polynomials appear. I suspect they are related somehow to Schur-polynomials,
representation theory, and determinants of band-matrices.</p>
",combinatorics
"<p>What conditions would be sufficient for a generalization of Cauchy-Davenport for simple groups? I can see two possible difficulties with a generalization for general groups:</p>

<ol>
<li>The sets could both be part of a subgroup of the group.</li>
<li>The sets could both be cosets of a normal subgroup. This is impossible for simple groups.</li>
</ol>

<p>Are these the only ways Cauchy-Davenport can fail, or are there other ways?</p>

<p>In particular, would it be possible to generalize the proof of Cauchy-Davenport given in <a href=""http://arxiv.org/pdf/math/0308286v6.pdf"">http://arxiv.org/pdf/math/0308286v6.pdf</a> with a more general version of the uncertainty principle used in that paper?</p>

<p>I haven't used mathoverflow before, so apologies if this question isn't appropriate for this website.</p>
",combinatorics
"<p>This question is related to my previous questions, say, <a href=""http://mathoverflow.net/questions/37529/covers-of-zk""> this one</a> and <a href=""http://mathoverflow.net/questions/85090/coloring-mathbbzk-and-a-fixed-point-theorem"">this one</a>. Let $G$ be an infinite graph of bounded degree, and $\lambda&gt;0$. Let $k=k_G(\lambda)$ be the minimal number of colors such that we can color $G$ in $k$ colors and all monochromatic $\lambda$-paths without repeating vertices have bounded lengths. (A $\lambda$-path is, by definition, a sequence of vertices such that the distance between two consecutive vertices in $G$ is at most $\lambda$, the length of a $\lambda$-path is the number of vertices in it.) </p>

<p><b> Question </b> Is there a $G$ such that for some $\lambda&gt;0$, the sequence $k_{G^n}(\lambda)$ grows faster than $n^{\alpha}$ for some $\alpha&gt;0$? Would  that be true if $G$ were the infinite binary tree? Here $G^n$ is the $n$-th direct power of $G$, i.e. the direct product of $n$ copies of $G$.</p>

<p>In the question cited above, $G$ was the line.  </p>
",combinatorics
"<p>I believe I have read or heard somewhere that the Kakeya conjecture would follow from appropriate lower bounds for the minimal size of a subset of $\{ 1 , \cdots , N\}$ which contains a translate of every k-term arithmetic progression contained in $\{ 1 , \cdots , N\}$. </p>

<p>This may be well-known to experts (what I'm not) and I have been unable to locate an appropriate reference ...</p>
",combinatorics
"<p>An interval graph is an intersection graph of real intervals, that is, an undirected graph whose vertices can be labeled with real intervals so that there is an edge between two vertices iff their intervals intersect.</p>

<p>A comparability graph is an undirected graph that connects elements that are comparable in some partial order, i.e., it is a graph whose edges can be oriented in such a way that the resulting binary relation is transitive and antisymmetric.</p>

<p>Given any interval graph, $G$, it is known that its complement is a comparability graph, and in particular, the comparability graph of an interval order, that is, a strict partial order on intervals where $[x,y] &lt; [z,w]$ iff $y &lt; z$. Our question asks in what cases the complement of a comparability graph is also a comparability graph for some order.</p>

<p>For example, consider the case where vertices are identified with intervals and an edge is drawn when one interval is a subset of another but shares no endpoints. This forms a comparability graph for the so-called ""interval containment"" order, and we know that its complement is also a comparability graph for a product order on $\mathbb{R}^2$. </p>

<p>So, our general question is: under what conditions is the complement of a comparability graph also a comparability graph? We have a more particular example in mind and that is when the comparability graph is that of an interval order (as defined above) for all intervals in a range from 1 to some given N. The complement of this graph is clearly an interval graph (since in the complement, intervals are connected if they intersect). And one can think of this as a ""complete"" interval graph as all intervals in a range are represented. The question is: is it also a comparability graph?</p>

<p>Is this a known fact? If so, where might I find it? Or maybe it is an open question?</p>
",combinatorics
"<p>Suppose $B$ is a bipartite graph on $n$ vertices with minimum degree $\delta$. It can be shown fairly easily that if $4 \delta &gt;n$, we have the nice property that any two vertices in the same bipartition of $B$ must share at least one common neighbor.</p>

<p>In this question, we look at a generalization. Suppose we have an arbitrary graph $G$ on $n$ vertices. Is there a ""big enough"" value of $\delta$ so that any two vertices not connected by an edge must share a common neighbor (i.e. if $k\cdot \delta &gt;n$, this property holds). </p>

<p>Now, what if we start putting restrictions on $G$. We know that if $G$ is bipartite, $k=4$ does in fact suffice. But what if we say $G$ is triangle free,or 5-cycle free. What can we say about $k$.</p>

<p>Any help would be great, tell me if I was confusing anywhere!</p>
",combinatorics
"<p><strong>Definition.</strong> An $m\times n$ matrix is said to be a partial Hadamard matrix (let's say PHM) if its entries are chosen from $\lbrace -1, 1 \rbrace$ such that the dot product of each pair of row vectors is $0$.</p>

<p><strong>Details.</strong> This of course relates to the famous Hadamard conjecture which looks at $m=n$, but I am interested in the weaker $m&lt;n$ case. Specifically, I am wondering about how many distinct $m\times n$ PHM exist given some, say $2$, of the row vectors, up to row permutation - as well as their construction.</p>

<p><strong>Questions.</strong> What are some good resources on results known about PHM? Are there iconic papers in the field?</p>
",combinatorics
"<p>Assume: 
$$
P \subseteq \{1,2,\dots,N\},\quad |P| = K, \qquad x \in \mathbb{R}_+^K , \qquad w = e^{-j\frac{2\pi}N}
$$
and,
$$
f(l) = \sum_{i=1}^K \sum_{j=1}^K x_i x_j w^{(p_i-p_j)l}
$$
I am going to find $x$ and $P$ such that these equalities are satisfied:
$$
f(1) = f(2) = \cdots = f(N-1)
$$
We can change this problem to an easier problem by defining : 
$$
S_d = \{(i,j) \quad | \quad p_i - p_j \mod N = d\}, \qquad d=0,1,\cdots,N-1
$$</p>

<p>So :</p>

<p>$$
f(l) = \sum_{d=0}^{N-1} \underbrace{\sum_{(i,j) \in S_d} x_i x_j}_{g[d]} \space w^{ld}
$$</p>

<p>Now suppose :
$$
S =S_1 \cup S_2 \cup \cdots \cup S_{N-1} =  \{(i,j), \quad 1\leq i,j \leq K, \quad i \ne j \}
$$</p>

<p>Using properties of Discrete Fourier Transform it can be shown that this problem turns to the problem :</p>

<blockquote>
  <p>$$
g[d] = \sum_{(i,j) \in S_d} x_i x_j = \frac1{N-1} \sum_{(i,j) \in S} x_i x_j\quad, \qquad d=1,2,\cdots,N-1
$$</p>
</blockquote>

<p>i.e. the problem becomes finding partition(s) of $S$ and $\{x_i\}_{k=1}^K$ (up to a scale!) satisfying the above equalities.</p>

<p>If for simplicity we set the values $x_1=x_2=\cdots=x_K = 1$, the problem will reduce to this:</p>

<p>$$
|S_d|=\frac{K(K-1)}{N-1}, \quad d=1,2,\cdots,N-1
$$
so, for the case of $\frac{K(K-1)}{N-1}$ being integer, the solution for $x$ and cardinality of partitions is found. Any idea for the case it is not integer?
Even finding cardinality of partitions would be great!</p>

<p>Any contribution would be appreciated.</p>

<p>Edit: I reached the result that the solution of this problem for $|S_d|$ is $\{|S_d|\}$ with minimum variance under constraint of $\sum_{d=1}^{N-1}|S_d| = K(K-1)$ which leads to some of them being $\lfloor \frac{K(K-1)}{N-1}\rfloor$ and the others $\lfloor \frac{K(K-1)}{N-1}\rfloor+1$.</p>
",combinatorics
"<p>I am sorry if this is a very stupid question, but I am new in the topic and I was not able to find either a solution or relevant literature. (I am so new that I really don't know even what the right tags are!)</p>

<p>I have a system of two linear recurrences. In particular, the first recurrence is $x_n=998x_{n-1}+995y_{n-1}$; the second recurrence is $y_n=1000x_{n-1}+996y_{n-1}$. The initial conditions are $x_1=\frac{1993}{2}$ and $y_1=998$.</p>

<p>Can one write $x_n$ and $y_n$ in closed form?</p>

<p>More specifically, I am interested in understanding the limit of $\frac{x_n}{x_n+y_n}$. It sound like being very close to $\frac{1}{2}$. Related to this, does $\frac{x_n}{y_n}$ converges to 1?</p>

<p>Thank you in advance for any help.</p>

<p>Valerio</p>
",combinatorics
"<p>It is well known that isoperimetric inequalities on a hypercube are closely related to influences, but all the theorems I'm aware of deal with monotone sets. Now suppose we have an arbitrary set $X \subset \{0, 1\}^n$, and let us color all vertices of a hypercube that lie in $X$ in black, others in white. The boundary edges (which have their endpoints colored in different colors), are of two types: going in positive direction we either go from white to black (positive influence) or from black to white (negative influence). Let us denote these edge sets by $D^+$ and $D^-$.</p>

<p>Now, the question follows:</p>

<p>Suppose that every node in $X$ is connected to $(1,1,...,1)$ (which belongs to $X$ as well) by a path that consists of only increasing edges (that is, following such path we always switch some coordinate from $0$ to $1$ and not otherwise). Suppose also that $P(X) = 1/2$, assuming the uniform measure on a hypercube. Moreover, let $X$ be symmetric. Is it true that $|D^+|-|D^-| &gt; 0$? If not, what additional conditions should be posed on $X$ to make it true?</p>

<p>More generally, can one bound $|D^+|-|D^-|$ to get an analog of sharp threshold results for symmetric but not necessary increasing events?</p>
",combinatorics
"<p>Let $N$ be a positive integer. 
We want to find a completely multiplicative functions $f(n)$ with values $\pm 1$ for $n \le N$ such that the discrepancy 
$$D=\max_{n \le N} |\{\sum_{i=1}^nf(i)\}|$$
is as small as possible. This is Erdős Discrepancy problem for multiplicative functions.</p>

<p>Consider the following greedy algorithm:</p>

<p>After you assigned the values $f(2),f(3),\dots f(p_i)$  for the first $i$ primes assign the value $f(p_{i+1})$ so as to minimize the maximum discrepancy $|\{\sum_{i=1}^nf(i)\}|$ in every partial sum where unassigned entries of $f$ get the value zero.</p>

<blockquote>
  <p>Question:  How does this greedy algorithm perform?</p>
</blockquote>

<p>Experimental or heuristic answers as well as rigorous proofs are welcomed.</p>

<p>For more background and related questions see <a href=""http://gowers.wordpress.com/2012/08/22/edp22-first-guest-post-from-gil-kalai/"" rel=""nofollow"">this post </a>.</p>

<h2>Variation</h2>

<p>Consider the same greedy algorithm when you impose the condition that $f(m)=0$ unless $m$ is square free. (If $m$ is not square free $f$ is multiplicative and has values $\pm1$.)</p>

<blockquote>
  <p>Question: How does our greedy algorithm performs on the square-free version?</p>
</blockquote>

<p>Namely, we would like to understand the behavior of the discrepancy of the function obtained by our greedy algorithm. While for EDP there are known examples with $\log N$ discrepancy, this is not known for the square-free version.</p>

<h2>Update:</h2>

<p>The very nice answer by rlo suggests that the greedy algorithm gives discrepancy close to $n^{1/3}$ or so, and rlo expects it also for the square free variation. Can an upper bound of $N^{1/2-\epsilon}$ be proved? What about a lower bound of $N^{\epsilon}$. Another interesting question is if you can improve the greedy algorithm to get lower discrepancy. Our greedy ignore 0's in intervals. A greedy algorithm that ignore intervals with 0's was considered in polymath5 and to the best of my memory achieve discrepancy $n^{1/2}$. Maybe a clever interpolation between these two variants will do a better job than both? </p>

<h2>Further meditation and a new variant</h2>

<p>It seems that in our greedy algorithm the decisions we make for small primes are fairly irrelevant. A way to check it: </p>

<blockquote>
  <p>Run the algorithm for N and test what is the discrepancy for an interval [1,T] where T is, 
  say, $\sqrt N$. I would expect the answer to be roughly $\sqrt T$.</p>
</blockquote>

<p>So now we can think about the following variation: </p>

<p>Let $a&gt;1$ be a real number. We run the greedy algorithm above but our decision for $f(p)$ is based only on intervals $[1,n]$ where $n \le p^a$. (Of course we consider only $n \le N$. </p>

<blockquote>
  <p><strong>Questions: Can this variant lead to lower discrepancy?</strong></p>
  
  <p><strong>What is the optimal value of $a$?</strong></p>
</blockquote>
",combinatorics
"<p>I have a graph $G=(V,E)$ with $|V|=n$ nodes. Define a markov chain matrix P on G (e.g. Metropolis-Hastings). I have $k$ random walkers which are deployed at time $t=0$ on the vertices of $G$ at random based on the stationary distribution of $P$ (for simplicity). If more than one walkers fall in the same node, they are placed in a buffer. At time $t=1$, the top walker in each non-empty node's buffer leaves that node and makes a random transition to a neighbour. </p>

<p>The problem is how to characterize the statistics of the markovian random vector of buffer sizes. This is equivalent to a repeated experiment of throwing k balls in n bins, with probabilities indicated by the stationary distribution of P (at least if $G$ is complete). </p>

<p>Notice that if two walkers at nodes i and j move to the same node r, then in the next step only one of the two can leave r and the other is buffered. Thus the markov chain describing the evolution of the buffer size vector is non-reversible.</p>
",combinatorics
"<p>Incidentally I've obtained a hypergeometric identity that I've not seen before:</p>

<p>$${}_3F_2(-m,-n,m+n; 1, 1; 1) = \frac{m^2+n^2+mn}{(m+n)^2} {\binom{m+n}{m}}^2$$</p>

<p>So, I wonder if it is well-known and possibly represents a particular case of something more general?</p>

<p>P.S. I've tried to simplify() the l.h.s. in Maple but it did not succeed, giving a hope that the identity is not completely trivial. ;)</p>

<p>EDIT: There seems to be a bug in formula rendering, so I'm repeating it below in plain LaTeX:</p>

<p>{}_3F_2(-m,-n,m+n; 1, 1; 1) = \frac{m^2+n^2+mn}{(m+n)^2} {\binom{m+n}{m}}^2</p>
",combinatorics
"<p>Here is a very natural question:</p>

<p>Q: Is it always possible to generate a finite simple group with only $2$ elements?</p>

<p>In all the examples that I can think of the answer is yes.</p>

<p>If the answer is positive, how does one prove it? Is it possible to prove it without using the
classification of finite simple groups?</p>
",combinatorics
"<p>Let $G$ be an undirected, simple graph, and let $\alpha(G)$ denote the independence number of $G$, i.e., the size of a maximum independent set (stable set) in $G$. A graph is $\alpha$-critical if for every edge $e$ of $G$, we have $\alpha(G - e) &gt; \alpha(G)$.</p>

<p>Conjecture: for every $\alpha$-critical graph $G$ without isolated vertices, for every maximum independent set $S$ in $G$, there is a maximum independent set $S'$ in $G$ that is disjoint from $S$.</p>

<p>The conjecture is true for the simplest classes of $\alpha$-critical graphs, the graphs $K_n$ ($n \geq 2$) and the odd cycles. It also seems to be true for the list of <a href=""http://link.springer.com/chapter/10.1007%2FBFb0019428"">minor-minimal obstructions to having a vertex cover of size at most five</a>, which are also $\alpha$-critical. Is it true in general? </p>

<p>Thanks in advance!</p>
",combinatorics
"<p><a href=""http://en.wikipedia.org/wiki/Alan_Sokal"">Alan Sokal</a> proved that <a href=""http://dx.doi.org/10.1017/S0963548303006023"">chromatic roots are dense in the whole complex plane</a>.  I.e., if $P(G;z)$ denotes the chromatic polynomial of a finite simple graph $G$ evaluated at $z \in \mathbb{C}$, then $$\bigcup_G \big\{z \in \mathbb{C}:P(G;z)=0\big\}$$ is a dense subset of $\mathbb{C}$.  Generalizing this...</p>

<blockquote>
  <p><em>Question</em>: Is, for all fixed $c \in \mathbb{C}$, $$\bigcup_G \big\{z \in \mathbb{C}:P(G;z)=c\big\}$$ is a dense subset of $\mathbb{C}$?</p>
</blockquote>

<p>Comments:</p>

<ul>
<li><p>For any $c$, the subset will be a countable subset of $\mathbb{C}$.</p></li>
<li><p>It doesn't seem straightforward to edit a graph $G$ with chromatic root $z$, to give a graph $G'$ with $P(G';z)=c$.  (Although, maybe I'm missing something.)  This would rule out an obvious approach.  (It still might be possible to modify Sokal's method to find an answer, but this would be lengthy.)</p></li>
<li><p>Real chromatic roots are not dense in $\mathbb{R}$.  So probably there's a big difference between the two cases ($\mathbb{C}$ and $\mathbb{R}$) here too.</p></li>
</ul>
",combinatorics
"<p>I want to build numbers set(one of possible) that meet following criteria</p>

<p>We are given <strong>n</strong>-bit numbers.
Select subset(<strong>X</strong>) of them that have exactly <strong>m</strong> bits set to 1.
Then I need to build subset(<strong>Y</strong>) of this set that meet following criteria:
1) For any number x and y(x!=y) in <strong>Y</strong>, (x &amp; y) have exactly one bit set.
2) You can not extend <strong>Y</strong> with any new number from <strong>X</strong> so it still match (1) (Set <strong>Y</strong> is ""full"")</p>

<p>Given <strong>n</strong> and <strong>m</strong>, I need method to build set <strong>Y</strong> matching this criteria.
While there is multiple sets that can match this criteria i need method that can build only one set(any of matching)</p>
",combinatorics
"<p>It is proved <a href=""http://mathoverflow.net/questions/162173/placing-numbers-1-2-ldots-n3-in-a-cube-so-that-numbers-of-any-two-adjacent-u"">HERE</a> that there is a natural number $N$ such that for any $n &gt; N$ it is possible to place numbers $1,2,\cdots, n^2$ is an $n\times n$ square such that the numbers in any two adjacent square (having a mutual edge) are coprime. How can one estimate $N$ !? My guess is that the least such $N$ is equal to $1$. </p>
",combinatorics
"<p>In the course of some recent research, I've sketched out a proof of the following result. My basis question is: is the result interesting?</p>

<blockquote>
  <p><strong>Proposition</strong> There exists an absolute constant $c$ such that, if $A$ is any symmetric subset of a finite field $\mathbb{F}_q$ with $|A|\geq 2$, then there are elements $g_1,\dots, g_n\in \mathbb{F}_q$ with
  $$Ag_1+\cdots Ag_n = \mathbb{F}_q$$
  and $n\leq c\log(q)/\log|A|$.</p>
</blockquote>

<p>Please note that I haven't checked every detail of the proof! I think it works but you never know... I also haven't tried to optimise the constant $c$ but it seems like $34$ works. Finally, although I need the fact that $A$ is symmetric for my proof, I would imagine that the same bound holds without this (symmetric here means that $A=-A$).</p>

<p>When I say ""is this interesting?"" I mean, first, that I'd like to know whether this proposition is easy-peasy for any one with a modicum of knowledge in algebraic combinatorics and, if this is not the case, whether there might be any applications.</p>

<p><strong>Background</strong>: I stumbled on this result while trying to prove a statement about width in finite simple groups. There is a famous conjecture in this area due to Liebeck, Nikolov and Shalev (""The Product Decomposition Conjecture"") which says the following:</p>

<blockquote>
  <p><strong>Conjecture</strong>: There exists an absolute constant $c$ such that if $G$ is a finite simple group and $S$ is a subset of $G$ of size at least two, then $G$ is a product of $n$ conjugates of $S$, and $n \leq c \log|G|/ \log |S|$.</p>
</blockquote>

<p>The proposition I state at the top is basically the same statement but for the group $G=\mathbb{F}_q\rtimes\mathbb{F}_q^*$ (where we restrict $A$ to be in the normal subgroup $\mathbb{F}_q$).</p>

<p>One of the things that surprises me is that one (conjecturally) has a bound on the width of two families of groups that look completely different - i.e. finite simple groups, and $\mathbb{F}_q\rtimes\mathbb{F}_q^*$. Of course these families are also the settings in which the most famous growth statements have been proven (cf. work of Helfgott, Pyber, Szabo, Breuillard, Green, Tao, Bourgain, Katz and many others), so perhaps this is not surprising. Note, though, that the bounds connected to width (i.e. multiplication by conjugates) are much stronger than those given by growth so the connection between the two is not entirely obvious...</p>
",combinatorics
"<p>Hello,</p>

<p>I have been working on this problem for several months now but have not made much progress. It concerns the set of all <a href=""http://en.wikipedia.org/wiki/Integer_partitions"" rel=""nofollow"">integer partitions</a> of n. </p>

<p>Let the vertices of the graph G=G(n) denote all the p(n) integer partitions of n. There is an edge between two partitions if and only if one can be transformed into another by only moving one dot between rows in their Ferrers diagram representations. </p>

<p>So, for example, the partitions (3,2,1) and (3,3) of 6 are linked because we can move the dot in the last row to the second row.</p>

<pre><code>OOO               OOO
OO      --------  OOO
O   
</code></pre>

<p>My question: for what values of n does G(n) have a Hamiltonian path from (n) to (1,1,...,1)? </p>

<p>That is, is it possible to go through, without repetition, all the partitions of n by simply moving around the dots in the Ferrers diagrams? </p>

<p>Is there a determinate way to construct such paths?</p>

<p>I have only been able to construct paths for n = 1 to 6.</p>

<p>n=1 (trivial)</p>

<p>n=2: 
(2) => (1,1)</p>

<p>n=3:<br>
(3) => (2,1) => (1,1,1)</p>

<p>n=4:<br>
(4) => (3,1) => (2,2) => (2,1,1) => (1,1,1,1)</p>

<p>n=5:
(5) => (4,1) => (3,2) => (2,2,1) => (3,1,1) => (2,1,1,1) => (1,1,1,1,1)</p>

<p>n=6:
(6) => (5,1) => (4,1,1) => (4,2) => (3,3) => (3,2,1) => (2,2,2) => (2,2,1,1) => (3,1,1,1) => (2,1,1,1,1) => (1,1,1,1,1,1)</p>

<p>None of the basic theorems about Hamiltonian paths have not helped me here. </p>
",combinatorics
"<p>I've only played with this a little for the past day or so, and haven't thought about it too hard, so it might be obvious. Obviously it's not fair to ask for a ""combinatorial proof"" of an inequality involving real numbers, so we'll ask that the vectors be in $\mathbb{N}^n$. More concretely:</p>

<p>Given n boxes subdivided into a ""right half"" and a ""left half"" with $a_i$ objects in the right half of box $i$, and $b_i$ in the left half of box i, is there a natural injective function from</p>

<blockquote>
  <p>Two pairs (ordered, with replacement) of objects, with each pair containing one object from the left half and one object from the right half of a fixed box</p>
</blockquote>

<p>to</p>

<blockquote>
  <p>A pair (ordered, with replacement) from the right half of some box, and a pair (O,WR) from the left half of some (possibly different) box?</p>
</blockquote>

<p>(Sorry if this is a double; my wireless is being strange.)</p>
",combinatorics
"<p>Alon's (or Alon and Tarsi's?) combinatorial nullstellensatz is a powerful algebraic tool with many applications in combinatorics and number theory. See <a href=""http://www.tau.ac.il/~nogaa/PDFS/null2.pdf"">this</a>, <a href=""http://arxiv.org/abs/1310.6482"">this</a>, <a href=""http://arxiv.org/abs/1008.2901"">this</a> and <a href=""http://mathoverflow.net/questions/43317/how-to-recognise-that-the-polynomial-method-might-work"">this mathoverflow question</a>. </p>

<p>I am looking for good examples of results that were proved using combinatorial nullstellensatz (or its generalisation) but have no other known proof. </p>
",combinatorics
"<p>I'll start with a couple important definitions. I'm not sure how well-known any of them are.</p>

<p>Firstly, if $G$ is a graph, and $u, v \in V(G)$, say that $u$ is <em>maximally distant</em> from $v$, denoted $u\ MD\ v$, if $d(u, v) \geq d(n, v)$ for any $n \in N(u)$, the open neighbourhood of $u$. Say that $u$ and $v$ are <em>mutually maximally distant</em> if $u\ MD\ v$ and $v\ MD\ u$, and denote this by $u\ MMD\ v$.</p>

<p>Now define the <em>strong resolving graph of $G$</em>, denoted $G_{SR}$, to be such that $V(G_{SR}) = V(G)$ and $(u, v) \in E(G_{SR}) \iff u\ MMD\ v$.</p>

<p>Next, define a <em>cycle with non-crossing chords</em> to be a cycle graph along with any number of chords such that it is outerplanar. Alternatively these are just the outerplanar hamiltonian graphs.</p>

<p>Finally, on to the problem. Are there any classes of graphs which anyone thinks can easily (or not-so-easily) be shown to contain, be contained in, or be equivalent to the class of strong resolving graphs of cycles with non-crossing chords?</p>

<p>I have been able to show that this class of graphs contains arbitrary odd cycles, along with induced copies of $K_n$ for any $n$, and I even found one containing an induced copy of $K_{2,3}$.</p>
",combinatorics
"<p>In my answer to <a href=""http://mathoverflow.net/questions/145555/why-is-there-a-connection-between-enumerative-geometry-and-nonlinear-waves/181534#181534//"">MO-Q: Enumerative geometry and nonlinear waves</a>, I outline the relation between the refined face polynomials of the Stasheff polytopes (associahedra) and the partition polynomials for the compositional inverse of a formal power series, noted by Loday in his paper referenced in the answer.</p>

<p>Who was the first to note this relation?</p>

<p>(Cross-posted from HSM.)</p>

<p>Ancillary question: Who was the first to note the relation between the dissections of convex polygons (or, closely related, Cayley trees depicting the repeated action of $g(x)D_x$) and compositional inversion?</p>
",combinatorics
"<p>For $n\in\mathbb{N}$ let $S_n$ denote the set of permutations on the set $\{1,\ldots,n\}$. Set $$E_n = \big\{\{\pi_1, \pi_2\}: \pi_1,\pi_2\in S_n \land \exists k_1 &lt; k_2 &lt;\ldots &lt;k_r\leq n: \pi_2=(k_1 \cdots k_r)\circ \pi_1\big\}.$$
(In other words, $\pi_2$ can be generated from $\pi_1$ with a <strong>monotonic</strong> (or monotonic like) cyclic permutation.)</p>

<p>Let $G_n=(S_n, E_n)$. Given $n\in\mathbb{N}$, what is $\chi(G_n)$?</p>
",combinatorics
"<p>Say $\sigma_1, \sigma_2, \dots, \sigma_m$ are i.i.d distributed $\pm1$ variables. How do i show that for any choice of $S_1, S_2, \dots, S_d$ subsets of $\{1, 2, \dots, m\}$, the expectation of the supremum over $S_i$ of the absolute value of the sum of the $\sigma$'s with indices in $S_i$ is bounded above by $\sqrt{2m \log d}$.</p>
",combinatorics
"<p><img src=""http://i.stack.imgur.com/7WNTa.jpg"" alt=""Example""></p>

<p>Rules-
1) At-least 4 and at-max 9 dots must be connected.
2) There can be no jumps<img src=""http://i.stack.imgur.com/cpTQH.png"" alt=""enter image description here""></p>

<p>3) Once a dot is crossed, you can jump over it. </p>
",combinatorics
"<p>I'm reading <a href=""http://rads.stackoverflow.com/amzn/click/3642743439"" rel=""nofollow""><em>Distance Regular Graphs</em></a> by Brouwer, Cohen, and Neumaier. In section 1.8, they explained <a href=""http://mathworld.wolfram.com/HadamardGraph.html"" rel=""nofollow"">Hadamard graphs</a>.</p>

<h2>Conversion from a Hadamard Matrix into a Hadamard Graph</h2>

<p>An $n$-Hadamard graph $G$ is a graph on $4n$ vertices defined in terms of a <a href=""http://en.wikipedia.org/wiki/Hadamard_matrix"" rel=""nofollow"">Hadamard matrix</a> of order $n$ $H_n = h_{ij}$ as follows:</p>

<ol>
<li>Define $4n$ symbols $r_i^+$, $r_i^-$, $c_i^+$, and $c_i^-$, where $r$ stands for <em>row</em> and $c$ stands for <em>column</em> and take these as the vertices of the graph.</li>
<li>Then add two types of edges between row vertices and column vertices based on the sign of $h_{ij}$:
\begin{equation*}
\text{parallel edges $(r_i^+, c_j^+)$ and $(r_i^-, c_j^-)$ if $h_{ij} = +1$} \\
\text{crossing edges $(r_i^+, c_j^-)$ and $(r_i^-, c_j^+)$ if $h_{ij} = -1$}
\end{equation*}</li>
</ol>

<p>Then the graph $G$ will be a bipartite graph where the set of vertices is partitioned into <em>row vertex set</em> of $2n$ vertices and <em>column vertex set</em> of $2n$ vertices. And there will be $2n^2$ edges.</p>

<h2>Equivalence between Graph and Matrix</h2>

<p>In theorem 1.8.1 in their book, they showed that $G$ is a <a href=""http://en.wikipedia.org/wiki/Distance-regular_graph"" rel=""nofollow"">distance-regular graph</a> with an intersection array
$\{n,n-1,\frac{n}{2},1;1,\frac{n}{2},n-1,n\}$ if and only if the matrix $H$ is Hadamard matrix of order $n$. </p>

<h2>My Question</h2>

<p>Their proof of this theorem seems rather brief and I have hard time in understanding the equivalence. Especially, I don't understand what role two orthogonal rows or columns in the matrix $H_n$ play in the graph $G$ so that distance-regularity is achieved. The book cited three papers for the proof, but I cannot find any of them in the Internet.</p>

<p>Can anyone explain what's the idea or intuition behind the proof of equivalence?</p>
",combinatorics
"<p>I am searching for a result in the literature that I am sure must be known, but I just fail to find it.</p>

<p>Let us starts with a simple example:
Let $A, B\subset \mathbb{Z}$ be a finite sets of integers such that $|A|=|B|=2m+1$ and denote by $I$ the set $\{-m,...,m\}$. I want to show that for all $k,l \geq 0$ we have 
$$\sum_{|i|\leq k, |j|\leq l}|(A+i)\cap(B+j)|\leq \sum_{|i|\leq k, |j|\leq l}|(I+i)\cap(I+j)|.$$</p>

<p>And, more generally, for any finite collection of sets $A_1,\ldots,A_t$ of the same odd cardinality $2m+1$ and all numbers $i_1,\ldots, i_t\geq 0$ we have
$$\sum_{|j_1|\leq i_1,\ldots, |j_t|\leq i_t}|(A_1+j_1)\cap\ldots \cap(A_t+j_t)|\leq \sum_{j_1|\leq i_1,\ldots, |j_t|\leq i_t}|(I+j_1)\cap\ldots \cap(I+j_t)|.$$</p>

<p>Thank you for your attention!</p>
",combinatorics
"<p>Let's say that the linear form $ax+by$ represents $n$ if $ax+by=n$ for some positive integer $x$ and $y$. </p>

<p>Call a pair $(a,b)\in\Bbb N\times\Bbb N$ with $\mathsf{gcd}(a,b)=1$ <em>excellent</em> if linear form $ax+by$ has following property: For each composite $n&lt;(a-1)(b-1)$ (the Frobenius number of $(a,b)$) represented by the linear form there is exactly one collection of divisors starting from some $t_j\geq t_1&gt;a,b$ to $t_s\geq t_j$ at every $i\geq1$ those $t_{i}$ with $t_j|t_{i}$ in $a,b&lt;t_1&lt;\dots&lt;t_s\leq n$ is represented by the linear form and no other divisors are represented.</p>

<p>Do excellent pairs exist at all?</p>

<p>If they do, then is it true that for every sufficiently large integer $l$, there is a excellent pair $(a,b)$ with $a,b\in[l,2l]$?</p>

<p>Note that every <em>excellent</em> pair is a <em>good</em> pair in <a href=""http://mathoverflow.net/questions/224953/problem-related-to-frobenius-coin-problem"">Problem related to Frobenius coin problem</a> and so <em>excellent</em> pair is a stronger condition.</p>
",combinatorics
"<p><a href=""http://i.stack.imgur.com/oqYAv.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/oqYAv.png"" alt=""enter image description here""></a></p>

<p>For example look at the number 9. It has prime-prime matching at 3,5, and 7.</p>

<p>For example the sequence of 13 has matchings at 1,3,7,11,13.</p>

<p>For example 15 has the matchings(crossings) at 3,5,11,13.</p>

<p>Is there an odd number for which the prime prime matchings do not occur?</p>
",combinatorics
"<p>Given k-distinct permutations $\sigma_1,\sigma_2,...,\sigma_k \in S_n$ where $k \leq 2^{\sqrt{n}}$ and $k &gt;1$ (note that k is much smaller than number of possible permutations on [n]), </p>

<p>What is the number N of disjoint sets of size 2 from [n] such that for each $\sigma_i$ , $i \in [k]$ the maximum stack depth is $O(n^{0.9})$ when processing following sequence of push and pops obtained from these sets and $\sigma_i$ (ie, upper bound on maximum number of elements in the stack at any time is $O(n^{0.9})$). </p>

<p>for each set $S_l= \{a,b\}, l\in [N]$,  if replace 'a' (let 'a' appears first when we scan the permutation $\sigma_i$ left to right, i.e, $\sigma_i(1),\sigma_i(2),...,\sigma_i(n)$) by push({a,b}) and 'b' (in the left to right scan 'b' appears after 'a') by pop({a,b}). We ignore all elements $e \in [n]$ which does not belong any of this disjoint sets.</p>

<p>When processing a pop({a,b}), if {a,b} is not top, then we pop all elements until we pop {a,b} and push back all popped elements except {a,b}.</p>

<p>Note that: 
(1) Across permutations, disjoint sets $S_1,...,S_N$ are fixed.
(2) The stack depth condition should hold for each of the permutation $\sigma_i, i\in [k]$.</p>

<p>We may apply some process like choosing a permutation $\rho$ from set of all permutations (it can depend on the given permutations) and look for these N sets in $\rho.\sigma_1,\rho.\sigma_2,...,\rho.\sigma_k \in S_n$  instead of in the original permutations $\sigma_1,\sigma_2,...,\sigma_k \in S_n$, but we are not allowed to use different processes for different permutations.</p>

<p>For any stack depth D, where $\sqrt{n} \leq D \leq  n^{1-\epsilon}$, where $0&lt;\epsilon&lt;1/2$ is a constant, 
Is it possible to get N to be $\Omega(D.n^{\delta})$, where $\delta&gt;0$ is a constant? </p>
",combinatorics
"<p>A partition regular system is a linear system of equations of the form $A\cdot x=0$, which satisfies a Ramsey-type result (namely, that for each $r&gt;0$ whenever we colour the integers in $r$ classes, there is a class which contains a monochromatic solution). The well-known Rado's theorem gives a characterization of such matrices, but we are not interested on this here.</p>

<p>An strong condition of this notion is density regular: a matrix $A$ is density regular if for every $\varepsilon&gt;0$ and $Y\subset \{1,\dots,n\}$ with $|Y| \geq \varepsilon n$, then $Y$ contains a solution to the equation $A\cdot x=0$. This is the strong counterpart of Rado's theorem, and it was proven by Frankl, Rödl and Graham that $A$ is density regular iff the vector $x=(1,\dots, 1)$ is a solution of the system (namely, the columns vectors of $A$ sum 0). For instance, the matrix equation associated to $k$-APs satisfies this condition, so Szemerédi's theorem is covered by this result.</p>

<p>After this, it comes my question. Take the Schur equation (x+y=z), which is partition regular but NOT density regular. Easily, there are sets of linear size (for instance, take the odd numbers) which are solution-free. However, it is very easy to show that if $X\in \{1,\dots,n\}$ satisfies $|X|\geq \left({\frac{1}{2}+\varepsilon}\right) n$, then $X$ contains a Schur triple.</p>

<p>My question is the following: is a similar result true for general partition regular systems? In other words, is it true the following statement?: let $A$ be a partition regular system. Then there exists $C:=C(A)&lt;1$ such that for $n$ large enough every subset $X\subset \{1,\dots, n\}$ with $|X|&gt; C n$ contains a solution to the equation $A \cdot x=0$. </p>
",combinatorics
"<p>There are a collection of definitions of ""combinatorial Euler characteristic"", which is different from the ""homotopy Euler characteristic"".  I will describe a few of them and give some references, and then ask how far they can be generalized.</p>

<ul>
<li><p>A good place to start is <a href=""http://en.wikipedia.org/wiki/Hadwiger%27s_theorem"">Hadwiger's theorem</a>.  Define a ""Hadwiger measure"" <em>m</em> on <strong>R</strong><sup>n</sup> to be a thing that assigns (possibly negative) real numbers to (nice?) subsets of <strong>R</strong><sup>n</sup> in such a way that the assignment is invariant under rigid transformations (i.e. isometries) and satisfies the ""inclusion-exclusion"" principle that <em>m</em>(_A_ &cup; <em>B</em>) = <em>m</em>(_A_) + <em>m</em>(_B_) - <em>m</em>(_A_ &cap; <em>B</em>); Hadwidger measures are also required to satisfy some analytic properties.  Then Hadwidger proves that the space of measures on <strong>R</strong><sup>n</sup> is precisely (<em>n</em>+1)-dimensional, and has a basis <i>m<sub>i</sub></i> with <i>m<sub>i</sub></i>([0,1]<sup>i</sup>) = 1 and <i>m<sub>i</sub></i>(&lambda; <em>A</em>) = &lambda;<sup>i</sup> <i>m<sub>i</sub></i>(<em>A</em>), where &lambda; <em>A</em> is the set rescaled by a factor of &lambda; in every direction.  In particular, <i>m</i><sub>0</sub> of a finite set counts the number of points, and agrees with Euler characteristic for compact regions; the function <i>m</i><sub>0</sub> is the ""combinatorial Euler characteristic"".  It is not homotopy-invariant: <i>m</i><sub>0</sub>([0,1]) = 1 whereas <i>m</i><sub>0</sub>(<strong>R</strong>) = -1.  It is multiplicative.<br><br>Incidentally, Hadwiger's paper is in German and so I cannot read it.  Apparently all this material is in Rota's book ""Introduction to Geometric Probability"", but I have been away from a library and haven't read it yet.  Thus I don't know the precise statement of ""nice"".</p></li>
<li><p>Schanuel in MR1173024 various ""geometric categories"".  Namely, say that a subset of <strong>R</strong><sup>n</sup> is a ""polyhedron"" if it is the positive locus finitely many affine maps to <strong>R</strong>; close the collection of polyhedra under union, intersection, and complement, and thus recover the notion of ""polyhedral set"" (so that a polyhedral set is actually a pair (<em>n</em>,_S_) where <em>S</em> is a subset of <strong>R</strong><sup>n</sup> satisfying certain properties).  Then  morphism of polyhedral sets is a set-theoretic function whose graph (as a subset of <strong>R</strong><sup>n</sup> x <strong>R</strong><sup>m</sup>) is polyhedral.  Then it's straightforward to check that a morphism is an isomorphism if it is a set-theoretic bijection &mdash; morphisms allow gluing and cutting.<br><br>Or replace the word ""affine"" with ""polynomial"" and thus recover the notion of ""semi-algebraic set"".  Or restrict your attention to bounded polyhedral sets.  Anyway, each of these geometric categories has well-behaved product and coproduct, and so a ""Burnside Rig"" (ring without negation) whose elements are isomorphism classes of objects.  Schanuel computes each of these Burnside rigs, and shows that the universal cancelative quotient of each is the integers; this map to <strong>Z</strong> is the combinatorial Euler characteristic.</p></li>
<li><p>Apparently there are also more analytic definitions.  Schanuel in MR842922 (wonderful but only trying to develop intuition and motivation) suggests that each of the Hadwiger measures can be defined in terms of curvatures and whatnot, but the formulas he gives only make sense for compact manifolds (with boundaries, corners...).<br><br>Chen (MR1215324) describes the combinatorial Euler characteristic with the following fun integral: let <em>f</em>: <strong>R</strong> &rarr; <strong>R</strong> be continuous except for finitely many jump and/or removable discontinuities, and define &int;<sub>Euler</sub>f = &Sigma;<sub><i>x</i>&isin;<strong>R</strong></sub> [ f(x) - (1/2) (f(x<sup>+</sup>) + f(x<sup>-</sup>)) ]; then try to compute Euler integrals of characteristic functions.  The problem is that he then defines the multi-dimensional version via the Fubini theorem, but suggests that his integrals depend on a choice of basis.</p></li>
<li><p>The definition of combinatorial Euler characteristic is great for ""finite polyhedral complexes"", I think.  By a ""finite polyhedral complexes"" I mean glue together finitely many polyhedra, but you're allowed to leave some faces open, so that unlike a CW complex not every cell must have complex closure.  Then you can calculate Euler characteristic with the usual formula: (number of cells of even dimension) - (number of cells of odd dimension).  I think this is a topological (but not homotopy!) invariant.</p></li>
</ul>

<p>Anyway, so first, are there references I've missed?</p>

<p>Second and more importantly, all the references consider only subsets of Euclidean space (well, Schanuel briefly mentions the Burnside rig of varieties/<strong>C</strong>, but only computes a quotient).  Why?  Why isn't there an intrinsic topological description, or perhaps manifold-theoretic description?</p>

<p>In particular, a ""measure-theoretic"" version that does not rely on embeddings in Euclidean space would be great, as it would presumably give ""measures"" against which we could integrate smooth functions.  Any ideas?</p>
",combinatorics
"<p>I hope this doesn't fall under the ""not interesting to mathemeticians"" category.  </p>

<p>I'm attempting to solve one of the <a href=""http://www.facebook.com/careers/puzzles.php?puzzle_id=12"" rel=""nofollow"">facebook engineering puzzles</a>.  Essentially, the idea is that two dancers do a dance-off with a predefined number of moves.  For every turn, the dancer has to begin with the last move the other dancer used.  Every time a combination of moves is used, both that combination and its reverse are excluded.  For instance, if you do (1, 2), then neither dancer can do (1, 2) or (2, 1).  Dancers may repeat moves.  The dancers will dance optimally, and the battle is over when there are no more moves left.</p>

<p>My first thought when trying to solve this went like this:  the dancers are essentially building a B(n, 2) de Bruijn sequence.  The length of the sequence should be n^2.  I figured that if the number of turns is odd, then you win.  If the number of turns is even, then they win.  Thus since n^2 will be odd if n is odd, and n^2 will be even if n is even, all I did was check to see if it was odd or even to determine the winner.  This wasn't the correct answer.</p>

<p>So here's my current way of thinking:  the dancers are going through a de Bruijn graph.  For every turn, two vertices are considered visited <em>unless</em> it is a duplicate (like (1, 1) or (2,2)).  Therefore, the number of turns available would be 2^n - n.  But this just seems like a more complex way to do the same thing as I was doing above.  After all 2^n will always yield a positive, so this will yield an even if n is even and an odd if n is odd.</p>

<p>I don't really want to ask anyone to solve this for me (I want to solve it on my own).  But can someone at least tell me if I'm on the right path, or is there something fundamental I'm missing?</p>
",combinatorics
"<p>Suppose that $n+m$ balls of which $n$ are red and $m$ are blue, are arranged in a linear order, we know there are $(n+m)!$ possible orderings. If all red balls are alike and all blue ball are alike, we know there are $\frac{(n+m)!}{n!m!}$ possible orderings.</p>

<p>For example, 2 red and 3 blue balls:</p>

<p>R1 R2 B1 B2 B3</p>

<p>R2 R1 B2 B3 B1</p>

<p>The above two orderings are equivalent and can be denoted as:</p>

<p>R R B B B </p>

<p>Now here is the problem: what if we further concentrate on the color, and record consecutive balls of the same color with the just ONE color code?</p>

<p>For example the color code for the afore-mentioned example would be:</p>

<p>R B</p>

<p>How many possible color code orderings are there?</p>
",combinatorics
"<p>A cohort in a school consists of 75 students who study for 6 years. Each year, the students are randomly distributed into 3 classrooms of 25 students each. What is the probability that, after 6 years, each student has at some point been in a classroom with every other student?</p>

<p>More generally: Starting with an edgeless (undirected) graph on $cn$ vertices, let a <strong>round</strong> consist of first randomly partitioning the vertices into $c$ disjoint sets of $n$ vertices each, then adding an edge between every pair of nonadjacent vertices that lie in the same set. What is the probability that, after $y$ rounds, the result is a complete graph?</p>

<p>I asked this question on math.stackexchange but received no fully useful response (see <a href=""http://math.stackexchange.com/questions/7454/what-is-the-probability-that-every-pair-of-students-studies-together-at-some-poin"">here</a>, where I've also posted an answer with further discussion and generalization and partial ""solutions""). I'd especially like to know about tools for the exact answer, but approximations or bounds would also be interesting.</p>

<p>The particular case above was posed by a friend, who teaches in a school with those values of $c$, $n$, and $y$.  In that particular case the answer is easily seen to be ""Don't hold your breath, pal.""</p>
",combinatorics
"<p>Although I think I know the answers to these, I'd just like to collect them all in one place.</p>

<p>What is the quantum PCP theorem, what implications does its proof have for simulation of Hamiltonians and is following Irit Dinur's reproof of the classical version the best/only current mode of attack (and if so why?) What is the sort of math/physics/theoretical CS background needed to approach this problem?</p>
",combinatorics
"<p>Gessel-Viennot's simple but powerful lemma has many striking applications, such as counting noninsecting paths , proving the Jacob-Trudi's identities, and solving the aztec diamond problem. So I wonder wether it can also be used to prove the Dodgson's condensation and Newton's indentities. Also, if you know other theorems or identities that can be solved by this lemma, please let me konw...</p>
",combinatorics
"<p>Fix an alphabet $A$ and consider words of length $n$ over $A$. Fix a set $B$ of $k$ forbidden subwords (subword is not necessarily connected, i.e. $abb$ is a subword of $abcb$). Can anything be said about the asymptotics of number of permissible words (i.e. words that don't containt any word from $B$ as a subword)? (a particular case - what if $n=k^{1+\epsilon}$ and we let $k \rightarrow \infty$?)</p>
",combinatorics
"<p>I was wondering if anyone could point me in the direction of a text or paper which would help deal with the following problem </p>

<p>Suppose i am given a $K_{\mathrm{log}(n)} \times K_{\mathrm{log}(n)}$ bipartite graph in which edges occur randomly with probability $p(n)$, i want to find the size of the largest matching w.h.p for certain values of $p$.</p>
",combinatorics
"<p>Let $\mathcal{M}$ be a rank-$d$ matroid on $[n]$. Say a matroid $\mathcal{N}$ is a <em>relaxation</em> of $\mathcal{M}$ if $\mathrm{rank}(\mathcal{N})=d$, $\mathrm{groundset}(\mathcal{N})=[n]$, and every independent set of $\mathcal{M}$ is an independent set of $\mathcal{N}$ (observe that this notion of relaxation is in the labeled sense).</p>

<blockquote>
  <p>Has anyone seen the set of all relaxations of $\mathcal{M}$ naturally show up in some context? </p>
</blockquote>

<p>I'm particularly interested in the algorithmic task of listing all relaxations of a given matroid $\mathcal{M}$, and in any heuristic to make an implementation more efficient than performing the enumeration by brute force; it would be even better if such an implementation already exists.</p>

<p>Actually, I only care about those relaxations of $\mathcal{M}$ that are realizable over a fixed field, say $\mathbb{C}$, which brings me to the next question:</p>

<blockquote>
  <p>Does anyone know of an implementation of a (finite) algorithm that decides whether a matroid is representable and provides a representation in case it is? (that such a finite algorithm exists can be proved using Groebner bases) </p>
</blockquote>

<p>Here I'm explicitly disregarding any complexity issues; I just want to be able to do compute a realization for some small matroids.</p>

<p><strong>Note:</strong> the first question is different from the ""opposite"" one of listing all matroids that <em>specialize</em> a fixed matroid, which has been asked <a href=""http://mathoverflow.net/questions/107138/finding-the-matroids-with-a-specified-set-of-non-bases"">here</a>. I wonder how different the task of listing all relaxations is.</p>

<hr>

<p><strong>Update:</strong> I implemented the following brute-force algorithm in sage to enumerate the relaxations of a rank-$d$ matroid on $[n]$:</p>

<p><code>For every subset</code> $\mathcal{F}$ <code>of the nonbases of</code> $\mathcal{M}$, <code>check whether</code> $bases(\mathcal{M})\cup \mathcal{F}$<code>is the collection of bases of a matroid.</code></p>

<p>According to sage's method <code>.is_valid()</code> for matroids, the outcome for all the matroids I tested was that all $2^{\#\{nonbases(\mathcal{M})\}}$ subsets of $\binom{[n]}{d}$ obtained form the bases of a matroid, which wasn't what I expected.</p>

<blockquote>
  <p>Can it be that there's a bug in sage's <code>.is_valid()</code> method, or is it actually to be expected that most naive relaxations of a matroid (as enumerated above) are actually matroids?</p>
</blockquote>

<p>(the reward is independent from the update in the question)</p>
",combinatorics
"<p>I'm looking at a random bipartite graph $K_{\omega(n)}*K_{\omega(n)}$ where $\mathrm{log}(n)\leq \omega(n) \leq n^{1/2}$, in which each of the $\omega(n)^{2}$ edges is placed randomly with probability $p=\frac{\mathrm{log}(n)}{\omega(n)^{2}}$. Now i know the threshold for an isolated vertex is an $n \times n$ random bipartite graph is $p(n)=\frac{\mathrm{log}(n)}{n}$ i thought since $\omega(n)^{2} \leq n$ perhaps in my case as the probability for an edge was larger i might find a similar thing, but i think not. Here is my arguement</p>

<p>For any vertex $v$ in $K_{\omega(n)} \times K_{\omega(n)}$ let $X(v)$ be the indicator random variable with $X(v)=1$ if $v$ is isolated and $X(v)=0$ otherwise. It follows that $P(X(v)=1)=\left(1-\frac{\mathrm{log}(n)}{\omega(n)^{2}}\right)^{\omega(n)} \approx e^{-\frac{\mathrm{log}(n)}{\omega(n)}}=\frac{1}{n^{1/\omega(n)}}=O(1)$ </p>

<p>Thus the probability that a vertex $v$ is isolated is constant as $n\rightarrow \infty$ and so it is very likely that there will be an isolated vertex. Is this arguement valid in proving we have an isolated vertex in the regime i have described. </p>
",combinatorics
"<p>This is a question I have been asking myself some 5 years ago. I later got bored by lack of progress, but maybe some additive combinatorialists here know further. I'm not claiming it is conceptual or objectively interesting, but I wouldn't be surprised to see it studied by the likes of Erdös either.</p>

<p><strong>Question:</strong> Let $G$ be a finite abelian group such that the sum of all elements of $G$ is zero. Let $n\neq 1$ be an integer such that $n\mid \left|G\right|-1$. Can we partition the set $G\setminus \left\lbrace 0\right\rbrace$ into disjoint $n$-element zero-sum subsets? (A subset of $G$ is said to be <em>zero-sum</em> if the sum of its elements is zero.)</p>

<p><em>[Question corrected due to a remark by quid.]</em></p>

<p><strong>Remarks:</strong></p>

<p><strong>1.</strong> This has a definitely positive answer for $G = \left(\mathbb Z / \left(p\right)\right)^k$ with $p$ a prime and $k$ a positive integer. (In fact, the abelian group $\left(\mathbb Z / \left(p\right)\right)^k$ is isomorphic to the additive group of the finite field with $p^k$ elements; now you can take a primitive root $\zeta$ in this field, set $m=\dfrac{p^k-1}{n}$, and partition $G\setminus \left\lbrace 0\right\rbrace$ into the zero-sum subsets</p>

<p>$\left\lbrace \zeta^0, \zeta^{0+m}, ..., \zeta^{0+\left(n-1\right)m}\right\rbrace$,</p>

<p>$\left\lbrace \zeta^1, \zeta^{1+m}, ..., \zeta^{1+\left(n-1\right)m}\right\rbrace$,</p>

<p>...,</p>

<p>$\left\lbrace \zeta^{m-1}, \zeta^{m-1+m}, ..., \zeta^{m-1+\left(n-1\right)m}\right\rbrace$.)</p>

<p><strong>2.</strong> In the general case, we can WLOG assume that $n$ is prime, but this doesn't seem to help (me).</p>
",combinatorics
"<p>Math people:</p>

<p>I am looking for a proof of a conjecture I made.  I need to give two definitions. For distinct real numbers $x_1, x_2, \ldots, x_k$, define $\sigma(x_1, x_2, \ldots, x_k) =1$ if $(x_1, x_2, \ldots, x_k)$ is an even permutation of an increasing sequence, and $\sigma(x_1, x_2, \ldots, x_k) =-1$ if $(x_1, x_2, \ldots, x_k)$ is an odd permutation of an increasing sequence. For example, $\sigma(2, 1, 10, 8) = 1$ because $(2,1,10,8)$ is an even permutation of $(1,2,8,10)$, and $\sigma(2, 1, 8, 10) = -1$ because $(2,1,8,10)$ is an odd permutation of $(1,2,8,10)$.  For real $B$, $n\geq 1$ and distinct real numbers $\mu_1, \mu_2, \ldots, \mu_n, \gamma_1, \gamma_2, \ldots, \gamma_n$, let $M(B;\mu_1,\mu_2,\ldots,\mu_n;\gamma_1,\gamma_2,\ldots,\gamma_n)$ be the $n$-by-$n$ matrix defined by </p>

<p>$$ M(B;\mu_1,\mu_2,\ldots,\mu_n;\gamma_1,\gamma_2,\ldots,\gamma_n)_{i,j}=\frac{\exp(-B\gamma_j)}{\mu_i+\gamma_j}+\frac{\exp(B\gamma_j)}{\mu_i-\gamma_j}.        $$</p>

<p>My conjecture is the following: if $n \geq 1$, $B \geq 0$, and $\mu_1, \mu_2, \ldots, \mu_n, \gamma_1, \gamma_2, \ldots, \gamma_n$ are distinct <em>positive</em> numbers with 
$0&lt;\mu_1 &lt; \mu_2 &lt; \cdots &lt; \mu_n$ and $0&lt;\gamma_1 &lt; \gamma_2 &lt; \cdots &lt; \gamma_n$ , then</p>

<p>$$\operatorname{sgn}(\operatorname{det}(M(B;\mu_1,\mu_2,\ldots,\mu_n;\gamma_1,\gamma_2,\ldots,\gamma_n))) = (-1)^{\frac{n(n+1)}{2}}
           \sigma(\mu_1, \mu_2, \ldots, \mu_n, \gamma_1, \gamma_2, \ldots, \gamma_n). $$</p>

<p>Of course $\operatorname{sgn}(x)$ is the sign of $x$, which is $1$, $-1$, or $0$. I have proven this is true for $n=1$ and $n=2$.  For $n$ between $3$ and $20$, I have run thousands of experiments in Matlab using randomly generated $\mu$'s and $\gamma$'s.  In a set of one thousand experiments, the conjectured equation will typically hold every single time, or might fail once or twice, with the determinant (with the wrong sign) being extremely small, so perhaps roundoff error is the culprit.</p>

<p>UPDATE: let $d(B)$ be the determinant of the matrix, where the other parameters should be clear from context.  $d(B)$ is an analytic function of $B$.  It suffices to show that $\frac{\partial^m d}{\partial B^m}$ has the desired sign at $B=0$ for all $m \geq 0$.  Unfortunately, the determinant of $\frac{\partial M}{\partial B}$ is not the same thing as $\frac{\partial^m d}{\partial B^m}$ (if it were, properties of Cauchy matrices would yield the desired conclusion).  Since the conjecture is true for  $n=1$, that means that the displayed formula for $M_{i,j}$ above, and all its derivatives with respect to $B$, have the same sign as $\mu_i - \gamma_j$ at $B=0$, and $M_{i,j}$ has that sign for all positive $B$.  I proved the conjecture for $n=2$, by computing the determinant of $M$ and its derivatives with respect to $B$ at $B=0$, and looking at the six possible orderings of $\mu_1, \mu_2, \gamma_1$, and $\gamma_2$ given the restrictions $\mu_1 &lt; \mu_2$ and $\gamma_1 &lt; \gamma_2$.  I had some help from Maple multiplying out, simplifying and factoring algebraic expressions.  I am trying to prove the general case by induction on $n$, expanding the determinant along the last row or column, but the determinants of the $n-1$-by-$n-1$ minors don't seem to necessarily have the ``right'' signs.</p>

<p>Thanks to some comments provided below, unless I am confused, the conjecture can be proven for $B=0$ and large positive $B$, for any $n$, using properties of Cauchy matrices.</p>
",combinatorics
"<p>Can anyone help me with this problem? It just popped to my mind!!!</p>

<p>we have a $2n\times 2n$ grid sheet and a connected shape $L$ consisting of $2n-1$ grid squares. we've cut two copies of $L$ out of the sheet. Is it always possible to cut a third copy of $L$?</p>

<p>I think the answer is yes, but I couldn't solve it. any Ideas?</p>
",combinatorics
"<p>Suppose we color  a   $X \times X$ finite plane by red and blue arbitrarily. How large does X need to be to guarantee a  monochromatic combinatorial square $k \times k$ </p>

<p>1 0 1 0 1 1</p>

<p>1 1 1 1 1 1 </p>

<p>1 0 1 0 1 1</p>

<p>1 1 1 1 1 1</p>

<p>The above figure shows a combinatorial $2 \times 2$ filled  square filled by zeros.</p>
",combinatorics
"<p>You can map whole numbers to combinations when taking them in order. For example, 13 choose 3 would look like:</p>

<pre><code>0 --&gt; (0, 1, 2)
1 --&gt; (0, 1, 3)
2 --&gt; (0, 1, 4)
etc...
</code></pre>

<p>Given a particular combination, such as <code>(0, 3, 9)</code>, is there a way to determine which whole number maps to it (26, in this case), short of writing out all the combinations in order until I hit upon the proper one? Furthermore, is there a way of doing this when counting combinations with repetitions?</p>

<p>If anyone is wondering, this isn't homework, but for a personal programming project.</p>
",combinatorics
"<p>Kendell-Mann numbers $M(n)$ ( see the sequence A000140 <a href=""http://oeis.org/A000140"" rel=""nofollow"">http://oeis.org/A000140</a> ) have the simple property: $M(n+1) \approx (n-1/2)M(n)$.</p>

<p>The property can be proved by different methods.
For eg. <a href=""http://mathoverflow.net/questions/46368/the-property-of-kendall-mann-numbers"">The property of Kendall-Mann numbers </a></p>

<p>What I am looking for is to find out if a combinatorial proof exists?</p>

<p>For eg. Let us start: Suppose we look at all the permutations of $n-1$ in the maximal grouping, then at all the permutation of $n$ in that maximal grouping; is there any simple way in which each permutation in the first set gives rise to $n$ permutations in the second? Better yet, a simple way in which about half the $n-1$-permutations give rise to $n$ $n$-permutations each, and the other half give rise to $n+1$ $n$-permutations each?</p>

<p>Any hints are higly welcomed.
I hope that the combinatorial proof will makes the reason for the simple property more transparent.</p>
",combinatorics
"<p>We are interested in a solution to the following scheduling problem, or any information about how to find it or its existence. This one comes from real life, so you will not only be helping a mathematician quench his thirst of knowledge!</p>

<blockquote>
  <p>We have 18 players playing a certain sport (let's say curling) on 3 different alleys (6 players per alley) at the same time. They play 17 games and we want that every combination of 2 players play exactly 5 times together.</p>
</blockquote>

<p>(As Douglas Zare points out in a comment below, this is known as a resolvable block design with t=2, v=18, k=6, lambda=5 (and b=51, and r=17)).</p>

<p>We asked around and someone came up with a near solution: almost every pair playing 5 times except for a few 6's and 4's. Brute force seemed too slow so we tried with a genetic algorithm, to no avail (being complete beginners in this, we could not even get close to the near-solution that we had, so we do not draw conclusions from our experiments).</p>

<p>I found the near-solution in my old files, in case anyone wants to tinker a bit.</p>

<pre>
{{1, 2, 3, 4, 5, 6}, {7, 8, 9, 10, 11, 12}, {13, 14, 15, 16, 17, 18}},
{{1, 6, 10, 12, 14, 16}, {2, 3, 8, 11, 15, 17}, {4, 5, 7, 9, 13, 18}},
{{1, 5, 7, 8, 15, 16}, {2, 4, 10, 11, 13, 14}, {3, 6, 9, 12, 17, 18}},
{{1, 4, 8, 9, 14, 17}, {2, 6, 7, 10, 15, 18}, {3, 5, 11, 12, 13, 16}},
{{1, 6, 8, 11, 13, 18}, {2, 4, 9, 12, 15, 16}, {3, 5, 7, 10, 14, 17}},
{{1, 2, 7, 12, 13, 17}, {3, 4, 8, 10, 16, 18}, {5, 6, 9, 11, 14, 15}},
{{1, 3, 9, 10, 13, 15}, {2, 5, 8, 12, 14, 18}, {4, 6, 7, 11, 16, 17}},
{{1, 5, 10, 11, 17, 18}, {2, 6, 8, 9, 13, 16}, {3, 4, 7, 12, 14, 15}},
{{1, 2, 9, 11, 16, 18}, {3, 6, 7, 8, 13, 14}, {4, 5, 10, 12, 15, 17}},
{{1, 4, 8, 12, 15, 18}, {2, 3, 7, 9, 11, 14}, {5, 6, 10, 13, 16, 17}},
{{1, 3, 7, 14, 16, 18}, {2, 5, 8, 9, 10, 17}, {4, 6, 11, 12, 13, 15}},
{{1, 5, 6, 9, 12, 14}, {2, 3, 10, 13, 15, 18}, {4, 7, 8, 11, 16, 17}},
{{1, 3, 10, 11, 12, 16}, {2, 4, 5, 8, 13, 14}, {6, 7, 9, 15, 17, 18}},
{{1, 2, 3, 4, 6, 17}, {5, 7, 11, 12, 13, 18}, {8, 9, 10, 14, 15, 16}},
{{1, 4, 7, 9, 10, 13}, {2, 12, 14, 16, 17, 18}, {3, 5, 6, 8, 11, 15}},
{{1, 2, 5, 7, 15, 16}, {3, 8, 9, 12, 13, 17}, {4, 6, 10, 11, 14, 18}},
{{1, 11, 13, 14, 15, 17}, {2, 6, 7, 8, 10, 12}, {3, 4, 5, 9, 16, 18}}
</pre>
",combinatorics
"<p>Following is the wonderful Euler's partition identity:
$$\prod_{i=1}^\infty (1 - x^i) = 1 + \sum_{k=1}^\infty (-1)^k \left (x^{(3k^2-k)/2} + x^{(3k^2+k)/2} \right )$$</p>

<p>I'm wondering if there is similar expansion for infinite product
$$\prod_{i=1}^\infty (1 - x^{2i-1})$$</p>

<p>We know that the inverse of that is the generating function for partitions with odd parts.</p>

<p>Edit: After a few computation, the non-zero coefficients seem very dense and quite arbitrary, so an explicit formula might not be plausible. My main question is whether this function is $D$-finite. The notion of $D$-finite function is defined in Stanley's book. From the Euler's formula, we see that the function 
$$\prod (1-x^i)$$
is not $D$-finite.</p>
",combinatorics
"<p>Is there an existing or elementary proof of the determinant identity
$
\det_{1\le i,j\le n}\left( \binom{i}{2j}+ \binom{-i}{2j}\right)=1
$?</p>
",combinatorics
"<p>For a lattice $\mathbb Z^d$, denote by <em>lattice line</em> any line that contains two (and thus infinitely many) lattice points.  </p>

<blockquote>
  <p>For $2\le k&lt;n$, define a <strong>$(n,k)$-coloring</strong>, or $C_d(n,k)$ for short, as a $n$-coloring $\mathbb Z^d\to \{0,1,\dots,n-1\}$ such that    </p>
  
  <ul>
  <li>in each lattice line, exactly $k$ colors occur,  </li>
  <li>each color is used for at least $2$ points of $\mathbb Z^d$.  </li>
  </ul>
</blockquote>

<p>It seems obvious that a $C_d(n,k)$, if it exists, must always be periodic in all directions (i.e. on each lattice line), although I cannot see a simple argument for that. Possibly there are some parallels with the <a href=""http://en.wikipedia.org/wiki/Hales%E2%80%93Jewett_theorem"" rel=""nofollow"">Hales-Jewett theorem</a>.  </p>

<blockquote>
  <ul>
  <li>Is there an easy proof for the periodicity?</li>
  </ul>
</blockquote>

<p>For a periodic coloring $C_d(n,k)$, let $D$ be a <em>fundamental domain</em>, i.e. a colored minimal cuboid such that its periodic continuation in all coordinate directions yields the given coloring. Some easy examples, all for $k=2$:</p>

<ul>
<li><strike>For a prime $p$, let $D$ be a $p\times p$ diagonal matrix with $r$ 1’s and $p-r$ 2’s on the diagonal, where $0&lt;r&lt;p$. This yields a $C_2(3,2)$.</strike></li>
<li>A $C_2(3,2)$ is also obtained by $D= \pmatrix{ 0 &amp; 0 &amp; 0 &amp; 1\\ 0 &amp; 2 &amp;   0 &amp; 2 \\ 0 &amp; 0 &amp; 0 &amp; 1\\ 1 &amp; 2 &amp;   1 &amp; 2  }$ or $D= \pmatrix{ 0 &amp; 0 &amp; 0 &amp; 1\\ 1 &amp; 2 &amp;   1 &amp; 2 }$. Note that the last $D$ is not square.</li>
<li><em>EDIT: this one doesn't work for $d&gt;2$.</em> For a prime $p$, take for $D$ the cube $\{0,1,\dots,p-1\}^d$ with a point $x\in D$ getting color $d-\#x$, where $\#x$ is the number of coordinates equal to zero. It is easy to check that this yields a $C_d(d+1,2)$ for each prime $p$; these colorings will be called <strong>""simplex constructions""</strong>. The special case $d=2$ yields $C_2(3,2)$'s which are 
again non-isomorphic to the above ones, with e.g. $D= \pmatrix{ 0 &amp; 1 &amp; 1\\ 1 &amp; 2   &amp; 2 \\ 1 &amp; 2   &amp; 2 }$ for $p=3$. </li>
<li>A $C_d(2^d,2)$ is defined by a $2^d$-hypercube $D$ in which each color is used once (and it is not hard to see that all $C_d(2^d,2)$ are of this form). We may call this one the <strong>""rainbow construction""</strong> and note that it generalizes immediately to a $C_d(k^d,k)$. For this one, $k$ does <em>not</em> need to be a prime! </li>
</ul>

<p><strong>Questions:</strong> </p>

<blockquote>
  <ul>
  <li>For which triples $(d,n,k)$ do such colorings $C_d(n,k)$ exist?  </li>
  <li>Which periods (i.e. side lengths of $D$) can occur for a given triple?  </li>
  <li>Are there other examples where $D$ is not a hypercube?  </li>
  </ul>
</blockquote>

<p>It seems like there are no $C_d(n,2)$ for $n&gt;d+1$ unless $n=2^d$. Is there an easy way to prove that?</p>

<p>Now for $k&gt;2$, apart from the rainbow construction, it is much harder to find general constructions. I wonder if it is possible to tweak certain combinatorical designs in order to obtain a suitable $D$ or, for dimension $d=2$, to build one from an appropriate set of latin squares. Or is there a construction for $k=3$ based on the above simplex constructions?<br>
 As $k$ grows, searching for small $D$'s by hand feels a bit like solving a sudoku. While a $C_2(6,3)$ is still quite easy to find (e.g. $D= \pmatrix{ 0 &amp; 1 &amp; 2 &amp; 0\\ 1 &amp; 2 &amp;  1 &amp;3 \\ 0 &amp; 1 &amp; 2 &amp; 0\\ 4&amp; 3&amp;4&amp;5  }$), I have the impression that no $C_2(n,3)$ exists for $n&gt;6$, except of course $n=9=3^2$. The following question seems well motivated:   </p>

<blockquote>
  <p>For given naturals $d,k\ge2$, denote by $m(d,k)$ the biggest $n&lt;k^d$ such that a $C_d(n,k)$ exists. What are good lower and upper bounds for $m(d,k)$ ?  </p>
</blockquote>

<p>By the above, we have supposedly $m(d,2)=d+1$ and $m(2,3)=6$.</p>
",combinatorics
"<p>Consider the set $L = \prod_{i=1}^n\{1,0\}$, i.e. L consists of the element of n-tuples whose entries are 0 or 1. Also we can regard $L$ as a subset of $R^n$. </p>

<p>Define linear functions $f(x)= a_1x_1+ \cdots + a_nx_n$ on $L$, of course also on $R^n$, such that $a_i &gt; 0, i =0,\cdots,n$.</p>

<p>Suppose we have $L_1,\cdots,L_k$ which are disjoint subsets of L. Say $\{L_i\}_{i=1}^k$ is well-separated by $f$ if there exists $0\leq\theta_0&lt;\theta_1&lt;\cdots&lt;\theta_{k-1}&lt;\theta_{k}\leq\infty$ such that   $L_i \subset \{\theta_{i-1}&lt;f&lt;\theta_{i}\}$ for $i=1,\cdots,k$.</p>

<p>I want to know what are the conditions for a fixed collection of disjoint subsets of $L$, denote as  $\{L_i\}_{i=1}^k$, to be well-separated by some linear function $f$ defined as above.</p>

<p>For example, when $k=2$, it is easy to see well-separateness by some linear function of above is equivalent to the convex hull of $L_1$ and $L_2$ in $R^n$ are disjoint.</p>

<p>Now the question is whether I can have the similar condition for $k&gt;2$.</p>

<p>Thanks a lot.</p>
",combinatorics
"<p>Let $X$ be a finite set and $T$ be a topology on $X$. Then $T$ is both union-closed and intersection-closed. <em>Can we deduce that  $T$ satisfies <a href=""http://mathoverflow.net/questions/47419/difficult-examples-for-frankls-union-closed-conjecture"">Frankl's union-closed set conjecture?</a></em> </p>

<p>(We know that a complement of a union-closed set is an intersection-closed set and the union-closed set conjecture is equivalent to the intersection-closed set conjecture.)</p>
",combinatorics
"<p>Let $A$ be a finite set of non-negative integers and write $I_k$ for the set ${0,1,\ldots,k-1}$. Form all possible l-wise intersections $(A+k_1)\cap \ldots \cap (A+k_l)$, where each $k_i$ runs through all values of the set $I_k$ (thus giving us $k^l$ of such intersections). Given an integer $0&lt;t&lt;|A|$, I want to maximize the number of intersections with cardinality at least $t$. Is it true that the optimal set $A$ is $\{0,1,\ldots,|A|-1\}$?</p>
",combinatorics
"<p>Let's say that I have a one-dimensional line of finite length 'L' that I populate with a set of 'N' random points. I was wondering if there was a simple/straightforward method (not involving long chains of conditional probabilities) of deriving the probability 'p' that the minimum distance between any pair of these points is larger than some value 'k' -i.e.  if the line was an array, there would be more than 'k' slots/positions between any two point. Well that, or an expression for the mean minimum distance (MMD) for a pair of points in the set - referring to the smallest distance between any two points that can be found, not the mean minimum/shortest distance between all possible pairs of points.  </p>

<p>I was unable to find an answer to this question after a literature search, so I was hoping someone here might have an answer or point me in the right direction with a reference.  This is for recreational purposes, but maybe someone will find it interesting.  If not, apologies for the spam.  </p>
",combinatorics
"<p>Actually, I suppose that the answer is technically ""yes,"" since computing the permanent is #P-complete, but that's not very satisfying. So here's what I mean:</p>

<p>Kirchhoff's theorem says that if you take the Laplacian matrix of a graph, and chop off a row and a column, then the determinant of the resulting matrix is equal to the number of spanning trees of the graph. It would be nice to have some analogue of this for other points of the Tutte polynomial, but this is in general too much to ask: the determinant can be computed in polynomial time, but problems such as counting 3-colorings are #P-hard.</p>

<p>However, if we use the permanent instead of the determinant, we don't run into these complexity-theoretic issues, at least. So, given a graph G on n vertices, can we construct a matrix of size around nxn whose permanent is the number of 3-colorings of G?</p>

<p>(The secret underlying motivation here is a vague personal hope that we can extend the analogy between the Laplacian matrix and the Laplacian operator [no, the naming isn't a total coincidence] to analogies between other matrices and general elliptic operators, and then prove some sort of ""index theorem,"" which could [even more speculatively, here] help us understand why graph isomorphism is hard, prove or construct a counterexample to the reconstruction conjecture, prove the Riemann hypothesis, and achieve world peace forever.)</p>
",combinatorics
"<p>When I teach elementary probability to my finite math students, a common error is to mix up the concepts of disjointness and independence.  At some point I thought that it might be helpful to some students to draw the analogy between the two concepts implied by the following pair of statements:</p>

<ul>
<li><p>To compute the probability of the union of disjoint events, you add the probabilities of the events.</p></li>
<li><p>To compute the probability of the intersection of independent events, you multiply the probabilities of the events.</p></li>
</ul>

<p>I also teach them is that when events are not disjoint, you can still compute the probability of their union by applying the principle of inclusion-exclusion.  Hence the question: Is there a useful analog of the principle of inclusion-exclusion for computing the probability of the intersection of non-independent events?</p>

<p><em>Edit:</em>
I am incorporating the following clarification that I made in a comment responding to the answer of Anna Varvak:</p>

<blockquote>
  <p>In inclusion-exclusion, one alternately adds and subtracts intersections. Intersections measure the degree to which disjointness fails. Can we write the right-hand side of Bayes Theorem as alternate multiplications and divisions of something, where ""something"" measures the degree to which independence fails?</p>
</blockquote>
",combinatorics
"<p>Instances of SAT induce a bipartite graph between clauses vertices and variable vertices, and for planar 3SAT, the resulting bipartite graph is planar. </p>

<p>It would be very convenient if there was a planar layout that had all the variable vertices in one line and all the clause vertices in a straight line. This can't be done because such a graph would be outerplanar, and $K_{2,3}$ isn't. </p>

<p>But maybe a weaker layout is possible. </p>

<blockquote>
  <p>Is it possible to lay out any planar
  bipartite graph $G = (A \cup B, E)$
  such that</p>
  
  <ul>
  <li>All vertices of $B$ are on a straight line</li>
  <li>A can be partitioned into $A_1 \cup A_2$ such that all vertices of $A_1$
  are on a parallel straight line to the
  left of $B$, and all vertices of $A_2$
  are on a parellel straight line to the
  right of $B$.</li>
  </ul>
</blockquote>

<p>This seems to relate to <a href=""http://mashfiquirabbi.110mb.com/files/thesis.pdf"">track drawings of planar graphs</a>. </p>
",combinatorics
"<p>What are the current best lower bounds for off-diagonal Ramsey numbers $R(k,l)$ with $l$ of order unity and asking for asymptotic behavior for large $k$, such as $R(k,4)$, $R(k,5)$, and so on?  (please include any log factors, too!)  Other than the more complicated arguments of Kim for $R(k,3)$, are all the other best lower bounds from the Lovasz local lemma?</p>
",combinatorics
"<p>Recall the following version of Szemerédi's Theorem: let $r_k(N)$ be the largest cardinality of a subset of $[N]:=\{1,\ldots, N\}$ which does not contain an arithmetic progression of length $k$. Then, for any $k\ge 3$, $r_k(N)/N\to 0$ as $N\to\infty$. </p>

<p>It follows that the same is true for any finite pattern. i.e. if $A\subset\mathbb{N}$ is a finite set, then, if $r_A(N)$ is the largest cardinality of a subset of $[N]$ which does not contain a set of the form $t+n.A$, we again have $r_A(N)/N\to 0$ as $N\to\infty$. This is obvious since $A\subset [\max A]$.</p>

<p>For $k=3$, <a href=""http://arxiv.org/abs/1011.0104"" rel=""nofollow"">Tom Sanders</a> has recently substantially improved the best known upper bound for $r_k(N)$, namely $O(N/\log^{1-o(1)}N)$. I believe for $k=4$ the current ""world-record"" is due to <a href=""http://arxiv.org/abs/math/0610604"" rel=""nofollow"">Green and Tao</a> and for $k&gt;4$ to <a href=""http://www.ams.org/mathscinet-getitem?mr=1844079"" rel=""nofollow"">Gowers</a> (corrections welcome).</p>

<p>My question is about quantitative bounds for $r_A(N)$. Obviously, $r_A(N)\le r_{\max A}(N)$, but if $A$ is sparse this is likely to be far from optimal. Can one do better? Are there any quantitative results for more general sets $A$?</p>

<p>In particular, is it true that $r_A(N)$ ``behaves like'' $r_{|A|}(N)$?</p>

<p>To be concrete, what type of bounds can one get for $r_A(N)$ when $A=\{1,2,m\}$? Will they be more like $r_3(N)$, or more like $r_m(N)$ (or something strictly in between)?</p>
",combinatorics
"<p>I think this is a natural question but am not sure where to find resources.</p>

<p>Consider the possible multisets arising from choosing $n$ times an item from one of $k$ categories. We can represent one such multiset by a vector $\vec{x} = (x_1,\dots,x_k)$ with $\sum_i x_i = n$.</p>

<p><strong>Question.</strong> I would like to upper-bound the quantity</p>

<p>$$ \sum_\vec{x} \frac{n!}{x_1! \cdots x_k!} x_1^{x_1} \cdots x_k^{x_k}  $$</p>

<p>This is equivalent to</p>

<p>$$ k^n \mathbb{E} \left[ x_1^{x_1} \cdots x_k^{x_k} \right] $$</p>

<p>where the expectation is over $\vec{x}$ as the outcome of a uniform multinomial distribution ($n$ draws and $k$ equally likely categories). I'd rather not assume that either $k$ or $n$ is large with respect to the other (or assume both; both cases are interesting).</p>

<p><strong>My approaches so far.</strong></p>

<p>If we are sloppy about how many $x_i$ are nonzero (for instance if $n \gg k$) then we expect most cases have all $x_i &gt; 1$, and we can use Stirling's approximation for all of the factorials. (If this is not the case, we have to be more careful and talk about only the nonzero $x_i$, so the below is not correct as stated, but hopefully can be modified.) We get that our sum is
\begin{align} 
 &amp;\approx \sum_{\vec{x}} \frac{\left(\frac{n}{e}\right)^n \sqrt{2\pi n}}{\left(\frac{x_1}{e}\right)^{x_1} \cdots \left(\frac{x_k}{e}\right)^{x_k} \sqrt{\left(2\pi x_1\right)\cdots\left(2\pi x_k\right)}} x_1^{x_1} \cdots x_k^{x_k}  \\
 &amp;= \frac{n^n}{(2\pi)^{(k-1)/2}} \sum_{\vec{x}} \frac{1}{\sqrt{x_1 \cdots x_k}}
\end{align}</p>

<p>Perhaps this sum can be approximated by an integral or volume of some sort? (Again, it is over all vectors $\vec{x}$ consisting of natural numbers and summing to $n$.) But I'm not sure how to do so, it got messy fast for me.</p>

<p>Another thought I had is to say that ""most"" vectors $\vec{x}$ have each $x_i \approx \Theta\left(\frac{n}{k}\right)$ (again being careful about regimes where many $x_i = 0$), and go from there. But I couldn't bound the contributions from the ""tail"" well.</p>
",combinatorics
"<p>Wythoff Nim is an impartial game where 2 players take turns in reducing the heights of two finite heaps of tokens. Two types of moves are allowed </p>

<p>(I) Remove any number of tokens from precisely one of the heaps, at least one and at most a whole heap. (These are the allowed moves in 2 heap Nim.)</p>

<p>(II) Remove the same number of tokens from both heaps, at least one from each heap and at most the number of tokens in the smallest heap.</p>

<p>The positions of an impartial game are partitioned into P and N. The second player to move wins if and only if the position is in P. The unique teminal position for both Nim and Wythoff Nim is empty heaps. </p>

<p>The P-positions of 2 heap Nim are all configurations with the same number of tokens in both heaps. The P-positions of Wythoff Nim are of the forms $(\lfloor \phi n\rfloor, \lfloor\phi^2 n\rfloor),(\lfloor\phi^2 n\rfloor,\lfloor\phi n\rfloor), n\in {\bf Z}_{\ge 0}$, where $\phi = \frac{1 + \sqrt{5}}{2}$. </p>

<p>It is clear that Wythoff Nim is an extension of Nim. By adjoining the type (II) moves to the game of Nim the unique ""accumulation point"" of P-positions of Nim has \emph{split} into two new accumulation points of P-positions of Wythoff Nim.</p>

<p>We wonder whether this splitting of P-positions continues if we adjoin the following new type of (symmetric) moves to the game of Wythoff Nim. </p>

<p>(III) Remove $t&gt;0$ tokens from one of the heaps and $2t$ tokens from the other, provided the remaining heap sizes are non-negative.</p>

<p>The initial (upper) P-positions of this new game (called (1,2)-GDWN) are $(0,0), (1,3), (2,6), (4,5),\ldots$.  </p>

<p>Experimental results gives four distinct ""accumulation points"" for the P-positions of this game (with upper convergents of ratios of heap sizes $1.478\ldots$ and $2.247\ldots$).
It is known that the upper P-positions of the new game do not converge.</p>

<p>It is not hard to prove that the non-terminal P-positions partition the positive integers. (Use that the type (I) and (II) moves are a subset of all moves.)</p>
",combinatorics
"<p>It is well known that</p>

<p>1) if there exists a non-trivial automorphism of a graph $G$ with corresponding permutation matrix $P$ then if $(v,\lambda)$ is an eigenvector-eigenvalue pair of the graph Laplacian $L(G)$ then $(Pv,\lambda)$ is also an eigenvector-eigenvalue pair (if $v$ and $Pv$ are linearly independent then this gives rise to eigenvalues with multiplicity greater than 1) and, </p>

<p>2) if all the eigenvalues of the $L(G)$ are simple than every automorphism of G has order 1 or 2. </p>

<p>If $G$ exhibits only a trivial automorphism ($G$ is asymmetric) can it be said that $L(G)$ has no repeated eigenvalues?</p>

<p>If not, a counterexample would be most helpful. I haven't found one on a brute force check of all graphs up to 9 nodes.</p>

<p>(I am assuming unweighted, undirected graphs)</p>
",combinatorics
"<p>Let $n\geq 2$ be a positive integer. For the purposes of this definition, let a <em>colored graph</em> be a finite undirected graph in which each edge is colored with one of $n$ colors so that no vertex is incident with two edges of the same color.  (Without loss of generality, we suppose that every vertex is incident with <em>exactly</em> one edge of each color; add loops wherever necessary.)  If $G_1$ and $G_2$ are two colored graphs, we define a product $H=G_1\times G_2$ as follows.</p>

<ul>
<li>The vertices of $H$ are the ordered pairs of vertices $(v_1,v_2)$, where $v_i$ is a vertex of $G_i$.</li>
<li>If $(v_1,w_1)$ and $(v_2,w_2)$ are edges of the same color in $G_1$ and $G_2$, respectively, then there is an edge (also of the same color) between $(v_1,v_2)$ and $(w_1,w_2)$ in $H$. </li>
</ul>

<p><strong>Examples.</strong> Consider $n=3$, the simplest interesting case (and the one that interests me most). Let $K'_3$ be the complete graph on three vertices with an extra loop at each vertex, and let $K_4$ be the complete graph on four vertices. (There is essentially only one way to to color each of these graphs.)</p>

<ul>
<li>$K'_3\times K'_3$ has two components: one is a copy of $K'_3$ and the other has six vertices.</li>
<li>$K'_3\times K_4$ is a connected graph with twelve vertices.</li>
<li>$K_4\times K_4$ has four components, each of which is a copy of $K_4$.</li>
</ul>

<p>Does this have a name? Has it been studied? It seems plausible enough to me that this may be a well-studied thing. At the moment, I'm especially interested in necessary/sufficient criteria for the product of connected colored graphs to be connected, or more generally an efficient way to count (or at least estimate) the number of components of the product, but any information that exists is reasonably likely to be useful to me.</p>

<p>My motivation here comes from some problems I'm working on in combinatorial number theory. I have various (colored) graphs that I associate to a positive integer $N$, and in many cases the graph corresponding to $MN$ is the product in this sense of the graphs corresponding to $M$ and $N$ whenever $\gcd(M,N)=1$. The graphs at prime powers are much simpler than the general case.</p>
",combinatorics
"<p>Let $n\geq 3$ be a natural number and  Consider the following game: </p>

<p>Correspond an integer to each vertices of an equiangular polygon 
(at least two of the numbers are unequal). </p>

<p><strong>(1) Replace the number of each vertices with the number obtained by the sum of 
its neighborhood numbers minus its own number. (Edit: Do this for all vertices at once, not one by one)</strong></p>

<p>This gives us a new equiangular polygon with an integer corresponded to each of its vertices. </p>

<p>Again do as in (1) and Continue the progress. </p>

<p>Let $A$ be the set containing the numbers corresponded to vertices of this polygon
in this (infinite) process. Now the question is: </p>

<p><strong>what are the possible values of $n$ if we want $A$  to be a bounded set of integers!?</strong></p>
",combinatorics
"<p>Are there deterministic algorithms that generate a sequence of Hamilton Tours that is superior to a sequence of randomly chosen tours, when applied to the TSP (by applying to the TSP, I understand summing up a tour's edge weights)? </p>

<p>Whether Low Discrepancy is better that Random Generation is decided via the index of the Optimal Tour in the Low Discrepancy sequence of all tours.<br>
If it is more likely to encounter the Optimal Tour in the Low Discrepancy sequence earlier than in the Random Generation sequence, then Low Discrepancy is conidered superior.<br>
<em>That measure of superiority is only one concrete example; other ways of defining it are also possible, while eventually yielding a different decision.</em></p>

<p>Background of my question is to learn whether similar improvements as in multidimensional integration are possible when switching from Monte Carlo to Low Discrepancy.<br>
<em>Note however, that multidimensional integration only serves as an example for the beneficial use of Low Discrepancy but is otherwise considered as being completely unrelated to TSP</em></p>

<p>I also appreciate any further information as well, like how to define a discrepancy measure for tours, estimates for performance gains, etc.</p>

<p>I know that there are methods for generating Low Discrepancy permutations, but I want information dedicated to tours and not to permutations in general.</p>

<p>What I have tried so far, is to combine the ability to calculate the n-th permutation via factoradic numbers with n taken from an appropriately chosen van der Corput sequence.
I'm not quite satisfied with that approach because:<br>
-the calculation of the n-th permutation is based on lexicographical ordering but, I would prefer the order generated by the Steinhaus-Trotter algorithm (because of the minimal change from one permutation to the next)<br>
-the van der Corput sequence corresponds to inverting the sequence of bits and is thus tailored for value ranges that are powers of two; numbers ranges that are factorials do not fit that pattern and one has to reject certain values of the van der Corput sequence because they are outside the valid range<br>
-cyclicity and symmetry are not taken into account</p>

<p>all that adds some bias, which worries me</p>
",combinatorics
"<p>Wikipedia's article on the <a href=""http://en.wikipedia.org/wiki/Reconstruction_conjecture"">Reconstruction Conjecture</a> mentions that the conjecture is false for digraphs, and refers to two papers by Stockmeyer. As far as I can see, none of the counter-examples in those papers are acyclic, so my question is</p>

<blockquote>
  <p>Can a directed acyclic graph be reconstructed from its deck of vertex-deleted subgraphs?</p>
</blockquote>

<p>One has to assume the graph has at least $5$ vertices to avoid certain small cases. (Edit: For $4$ vertices, see Julian's example below.) Acyclic tournaments are reconstructible according to the references.</p>

<p>The question has an equivalent reformulation in representation theory:</p>

<blockquote>
  <p>Let $Q$ be a directed acyclic graph as above, and let $k$ be an algebraically closed field. Can the path algebra $\Lambda=kQ$ be reconstructed from its deck of vertex-deleted quotients $\Lambda/\Lambda e \Lambda$?</p>
</blockquote>
",combinatorics
"<p>By a lattice, we mean a finitely generated, free $\mathbb{Z}$-module together with a symmetric bilinear form. Typical examples are the hyperbolic lattices $U$ and the root lattices $A_{n}, D_{n}, E_{n}$ associated to Dynkin matrices. In general we <strong>cannot</strong> say that for lattices $L,M$ and $N$
$$
L\oplus M \cong L\oplus N \Longrightarrow M\cong N. 
$$
In other words, cancellation does not hold over $\mathbb{Z}$. </p>

<p>I wonder when this cancellation holds. Are there any criteria? I am particularly interested in the case $L=U$. </p>
",combinatorics
"<p>Let $S$ be a set of binary vectors (in $\lbrace 0,1 \rbrace^m $) whose VC dimension is $d$. Let $H$ be the Hamming graph generated from this set where each node represents a binary vector and two nodes have an edge if they differ in ""at most"" $d$ positions.  Is there a way to bound the size of the vertex cover of $H$?</p>

<p>Any relevant reference would be of great help!</p>
",combinatorics
"<p>The Eulerian polynomials satisfy the recurrence relation
$$x A_n(x) = \sum_{k=0}^{n} \binom{n}{k}(x-1)^{n-k} A_k(x).$$</p>

<p>This reminds me very much of 
$$0 = \sum_{k=0}^{b} \binom{b}{k}(-1)^{b-k}T_k$$
where $T_k$ counts the number of SSYT of shape $k^c$ with entries $1,2,\dots,n$
and $b=\binom{n}{c}.$</p>

<p>Are there any other combinatorial objects that satisfy a recurrence of length $n,$
where the summand is a binomial $\binom{n}{k}$ and with an alternating sign, in some sense?
(The Eulerian polynomials yields and alternating sum for $x=0$, but the result is very unexiting.)</p>

<p>It feels like such recurrences arises quite naturally, 
and the ""sign"" part should make a counting argument with inclusion/exclusion easier.
(The SSYT recuurence is such an example).</p>
",combinatorics
"<p>Is there a function $p:\mathbb N\to \{ 1,-1 \} $ and a fixed $N\in \mathbb N$ such that for every $n \geq N$ we get:</p>

<p>$\sum _{i=0} ^{n} p(i)\binom {n}{i}=0$
?</p>

<p>Obviously $p(i)=(-1)^i$   works for $N=1$, and so does $p(i)=(-1)^{i+1}$, but are there any others?</p>

<p>(my personal guess is that there aren't)</p>
",combinatorics
"<p><strong>The model:</strong></p>

<p>Suppose that for each lattice point in $\mathbb Z^2$ we pick a random direction uniformly and independently. At time $t=0$ we start drawing rays starting from each lattice point in the chosen directions with unit velocity. The drawing of a ray will continue until it intersects another ray, at which point both rays stop.</p>

<p>In the end we are left with a graph $G$ (more like a union of segments, but let's pretend it's a graph), and I would like to understand it's properties.</p>

<p><strong>Question:</strong></p>

<p>This seems at first like it might share some properties with percolation in $\mathbb Z^2$, but I'm not so sure. I'd like to know how the connected components are distributed. For example, say we restrict to the lattice points inside the rectangle $[0,n]\times[0,m]$, and perform the process above (with the modification that if a ray hits the boundary rectangle it also stops).  What is the expected number of connected components in $G$? (the boundary rectangle is not a part of $G$).</p>

<p>(There used to be a question here about cycles formed, but I removed it since it is more appropriate for motorcycle graphs mentioned in the answer below. For now, I want to focus on connected components. jc's answer seems to indicate that connected components will usually be small.)</p>
",combinatorics
"<p>Embedding different graphs, especially binary trees, in the hypercube has a huge literature. However, I could not find anything if we restrict the embedding to be monotone. So I would like to injectively map the vertices of a complete binary tree, $T_d$, which I denote by the binary sequences of length at most $d$, into the hypercube, $C_n$, whose vertices I denote by the binary sequences of length $n$, such that if $x$ and $xb$ (where $b$ is a bit) are two adjacent vertices of $T_d$, then for their images, $f(x)$ and $f(xb)$, it holds that $f(xb)$ has more 1's than $f(x)$ and it has a $1$ everywhere where $f(x)$ has a one. So e.g., $01$ and $011$ might be mapped to $100$ and $101$ or even to $100$ and $111$. (So I do not need that they are adjacent in $C_n$.)</p>

<p>Our goal is to find the smallest $n$ for which such an embedding is possible.
It seems like a natural generalization of a very well studied problem (at least if we suppose that the images are adjacent in $C_n$, which should not make a difference in the asymptotics).
Has anyone every heard of this problem?
Do you think it's possible to apply some variant of the Lovasz Local Lemma?</p>

<p>I conjecture that $n\approx 1.29d$ but I could only prove $1.29d\le n \le 1.38d$.
The lower bound follows from the simple observation that we need $\sum_{i\ge d} {n\choose i}\ge 2^d$, while the upper bound comes from $n(d_1)+n(d_2)\ge n(d_1+d_2)$ and some computer programs.
I know that this is not always sufficient, e.g., for $d=14$ we need $n\ge 20$, but I conjecture that we need $n$ to be at most one bigger.</p>

<p>Probably I should also mention that this problem came up related to a search problem studied at our university search seminar and some of the above observations are joint works with others.</p>
",combinatorics
"<p>The numbers $2^{n(n+1)/2}$ come up in various enumerative contexts.  In addition to the trivial example (bit-strings of length $n(n+1)/2$) and the old example of domino tilings of Aztec diamonds (Elkies, Kuperberg, Larsen, and Propp: see <a href=""http://www.emis.de/journals/JACO/Volume1_2/x9m7n00g384067u3.fulltext.pdf"">http://www.emis.de/journals/JACO/Volume1_2/x9m7n00g384067u3.fulltext.pdf</a> and <a href=""http://www.emis.de/journals/JACO/Volume1_3/r261p9652890q1j7.fulltext.pdf"">http://www.emis.de/journals/JACO/Volume1_3/r261p9652890q1j7.fulltext.pdf</a> ) and another old example involving order ideals in a tetrahedral poset (whose details I forget; perhaps someone can remind me), there are various other examples discussed in <a href=""http://arxiv.org/abs/1103.5054"">http://arxiv.org/abs/1103.5054</a> (Nordenstam and Young) as well as the example discussed in <a href=""http://arxiv.org/abs/1312.5758"">http://arxiv.org/abs/1312.5758</a> (Liu and Stanley).</p>

<p>I'm sure some of these are in direct canonical bijection (without one having to break symmetries or make arbitrary choices), but I suspect that the whole assortment of combinatorial models splits up into two or three distinct classes, where the bijections between the classes are non-canonical (cf. the original bijection between bit-strings and domino tilings of Aztec diamonds, which is non-canonical).  And I'm sure the OEIS has a couple of avatars of the sequence 1,2,8,64,1024,... that I've missed.</p>

<p>Can we bring some order to this situation by showing which pairs of aforementioned classes of objects are in canonical bijection?</p>

<p>(Note to those with moderator powers: I'm on the fence as to whether or not this question should be a community wiki; I'll leave this to your judgment. Also note that I've attempted to use the tag ""bijective-combinatorics"", which doesn't seem to exist.  If there's a tag already in use that means the same thing, feel free to change my tag appropriately.)</p>
",combinatorics
"<p>Let $X=Gr(r,V), Y=Gr(r+1,W)$ where $V,W$ are complex vector spaces with $\dim V &gt; r$ and $\dim W &gt; \dim V$. Let $\phi:X\rightarrow Y$ be some embedding of varieties. This induces a morphism on cohomology $\phi^{*}:H^{*}(Y)\rightarrow H^{*}(X)$. It is well known that the classes in $H^{*}(X)$ (respectively $H^{*}(Y)$) given by Young diagrams form a $\mathbb{Z}$-basis for $H^{*}(X)$ (respectively $H^{*}(Y)$). </p>

<p>Moreover $\phi^{*}(\sigma_\lambda)=\displaystyle\sum_{\lambda'}c_\lambda^{\lambda'}\sigma_{\lambda'}$ (with the obvious notation) for some nonnegative integers $c_\lambda^{\lambda'}$. I was wondering if there is a criterion for the non-vanishing of these coefficients. I know that for full-flag varieties this is not known but I was hoping that at least for Grassmanians the situation gets better. </p>

<p>I am quite new to Schubert calculus so any reference is more than welcomed.  </p>
",combinatorics
"<p>We have all been there, when a formula works for the first 30 parameters,
but it is not sufficient for a proof. My question is where one can actually just check a finite number of cases, to conclude that a formula is correct.</p>

<p>That is, let $f,g : S \to \mathbb{N}$ be two functions from some (infinite) set $S$,
say the natural numbers, or permutations, graphs, etc. Assume that $f$ and $g$
are not too complicated (some measure of complexity here is needed, or they belong to some special family). </p>

<p><strong>What types of theorems are there of the form $f(S_k)=g(S_k)$ for $k=1,2,\dots,\max \{ C(f), C(g) \}$ implies $f \equiv g$?</strong> Here, the $S_k$ are members of $S$ in some natural order, and $C$ is some measure of complexity.</p>

<p><em>Example:</em> If $f,g$ are polynomials with integer coefficients, 
then we can take $C$ to be the degree of the polynomial. </p>

<p>Another example (which is a conjecture) is the following:
Let $p,q$ be permutation patterns of length $k$.
Then, is there some $N(k)$ such that if $|S_n(p)|=|S_n(q)|$ for all $n\leq N(k)$,
such that  $|S_n(p)|=|S_n(q)|$ for all $n$? It is conjectured that $N(k)=2k+1$ works.</p>

<p>Here, $S_n(p)$ is all permutations avoiding the pattern $p$.</p>

<p>A third example, I think, is Zeilbergers algorithm, which proves combinatorial identities by testing a finite number of cases. (Zeilberger is a big fan of this type of proofs, if I am to believe his opinions on his personal web page.)</p>
",combinatorics
"<p>I have an array of numbers lets call it $p$ , where $p[r]={k+r-1\choose k-1}$</p>

<p>I want to find the sum of all the elements of $p$ taken $n$ at a time .</p>

<p>$0\le r\le k$</p>

<p>For instance, for $k=3$ ,$n=2$ , i need</p>

<p>$$p[0]^2+p[1]^2+p[2]^2+p[3]^2+p[0]\cdot p[1]+p[0]\cdot p[2]+p[0]\cdot p[3]+p[1]\cdot p[2]+p[1]\cdot p[3]+\\+p[2]\cdot p[3]=\sum_{i\le j}p[i]\cdot p[j]=\sum_{i\le j}{k+i-1\choose k-1}{k+j-1\choose k-1}$$ which is $273$</p>

<p>Is there any way , i can solve this for any value of $k$ or $n$ without solving big equations like above</p>

<p>In other words , how to solve this summation?</p>

<p>$$\sum_{0\le x_1\le x_2...\le x_n \le n}^{}\binom{k+x_1-1}{x_1}\binom{k+x_2-1}{x_2}...\binom{k+x_n-1}{x_n}$$</p>
",combinatorics
"<p>Let $[n]$ denote the set of integers $\{1,2,\ldots,n\}$. A subset of $2^{[n]}$ is <strong>partition-free</strong> if it does not contain a partition of $[n]$.</p>

<blockquote>
  <p>What is the maximum size of a partition-free subset of $2^{[n]}$?</p>
</blockquote>

<p>Note that it is easy to get such a subset of size $2^{n-1}$: for some choice $x\in[n]$, we have a partition-free subset $\{S : S\in 2^{[n]},\ x\notin S\}$.</p>
",combinatorics
"<p>Let $\left[ n \right]=\{{1,2,\cdots,n\}}$ and call a family $\mathcal{F} \subset 2^{\left[n\right]}$ <strong>partition-free</strong> if it does not contain any partition of $\left[n\right]$. A <a href=""http://mathoverflow.net/questions/154308/partition-free-subsets-of-2n"">recent question</a> asked for the maximal size of such a set. The answer given is $2^{n-1}$ since having more than that allows a two member partition.</p>

<blockquote>
  <p>Q: can every partition-free family be enlarged to one of this size?</p>
</blockquote>

<p>There is an interesting comparison to <strong>Intersecting Families</strong> (ones which contain no two disjoint members.) Here again the maximal size is $2^{n-1}$ because we never can have both a set and its complement. Any intersecting family can be enlarged to one of this size (a nice exercise). Thus there are many examples built from the lines of projective planes, weighted voting schemes etc.  Also, any maximal intersecting family can be changed into any other by repeatedly switching a minimal member with its complement.</p>

<p>It is almost true that an intersecting family $\mathcal{F}$ is partition free. If $\left[n\right] \in \mathcal{F}$ (as will be the case for a maximal intersecting family) then we must replace $\left[n\right]$ with $\emptyset$ and then we will have a partition free-set. </p>

<p>There are certainly many other maximal partition-free families: From $\left[ 9 \right]$ start with all the sets with more than half the elements. Replace the whole set by $\emptyset$ and any set of size $6$ which does contain the element $1$ by its complement. </p>
",combinatorics
"<p>I have read that if 4 quasigroup operations, $\cdot,\circ,\star,\square$, on a set $S$ respect the following equation:
$$x\cdot (y\circ z) = (x \star y) \square z$$ 
for all $x,y,z\in S$, then all 4 quasigroups are isotopic to the same group.</p>

<p>I was wondering if a similar (or in some ways oposite) result could be hoped for:</p>

<blockquote>
  <p>Could there exist a system of quasigroup equations implying non-associativity?</p>
</blockquote>

<p>That is, could there exist a solvable system of quasigroup equations such that in every solution at least one of the quasigroups is isotopic to a non-associative loop (i.e., $\textbf{not}$ isotopic to a group)?</p>

<p>Note: In the system of equations, a quasigroup operation should not appear more than once in any single equation.</p>

<p><strong>Edit:</strong> The following types of equations are allowed</p>

<ol>
<li><p>An equation specifying two quasigroup operations are not isotopic such as $\cdot\not\equiv \circ$ (meaning for every 3 bijections $\varphi,\psi,\theta:S\to S$, there exist $x,y\in S$ such that $\theta(\varphi(x)\cdot \psi(y))\neq x\circ y$).</p></li>
<li><p>A regular quasigroup equation - such equations must contain at least 3 quasigroup operations.</p></li>
<li><p>An inexsitence equation of the following form: There does not exist a quasigroup operation $\square$ such that $(x\cdot y)\square (y \circ z)=x \star z$.</p></li>
</ol>

<p>Also, you can assume any lower bound (but not upper bound) you wish on the size of $S$ (this can be done by using the type 1 equations above).</p>
",combinatorics
"<p>Let $\pi_n$ be the poset of all set partitions of $\{1,...,n\}$ ordered by refinement, $\sigma = \{B_1,...,B_k\}$ be a set partition with blocks $B_i$, and $\max(B_i)$ be the maximum value in the block $B_i$. I'm trying to prove the following:</p>

<p>$$\Sigma_{\sigma\in\pi_{n-1}}\Pi_{B_i\in\sigma}(-1)^{|B_i|-1}(|B_i|-1)!(n+\max(B_i))=(2n-1)!!$$</p>

<p>I've already coded this in Mathematica to check that it's true until n=11 (after which the numbers become too large):</p>

<pre><code>&lt;&lt;Combinatorica`

f[x_]:=(-1)^(x-1)*(x-1) !

Total[Times @@@ Map[f, Map[Length, SetPartitions[n-1], {2}], {2}]*Times @@@ (Map[Max, SetPartitions[n-1], {2}] + n) ] == Factorial2[2*n-1]
</code></pre>

<p>Any thoughts would be greatly appreciated.</p>
",combinatorics
"<p>It is well known [it's on Wolfram Mathworld, for example] that the probability of no runs of $k$ consecutive $1$'s will occur in a $\{0,1\}$-valued sequence of length $n$ is exactly equal to $$\frac{F^{(k)}_{n+2}}{2^n}\quad\quad(1)$$ where $F^{(k)}_l$ is the $l^{th}$ $k-$step Fibonacci number. For example if $k=6,$ the sequence $F_l^{(6)}$ starts with $1,1,2,4,8,16,32,63,\ldots$. The probability in (1) is of course the probability that no set of $1$'s supported on an arithmetic progression of length $k$ and difference $d=1$ exist. The numerator is the cardinality of all sequences which have no $k$ consecutive $1$'s.</p>

<p>What if I allowed an arbitrary $d$ (of course $kd\leq n$ must hold) and asked the question as follows: </p>

<p><em>How many sequences of length $n$ support no all $1$-valued arithmetic progression of length $k$?</em></p>

<p>How does the probability change? It goes down, of course. Is there any hope of a closed form solution? Is it tangentially related to Szemeredi's Theorem? There, the question is about the length that guarantees the existence of such a subsequence (when interpreted in characteristic function terms), given a density for a subset of $\{1,2,\ldots,n\}$ (relative number of 1's). </p>

<p>I am willing to assume a density that is not too far below $1/2$ for my question.</p>
",combinatorics
"<p>Following combinatorics problem is claimed to be an open problem in ""<a href=""https://books.google.com/books/princeton?hl=en&amp;q=%22Will%20there%20always%20be%20a%20positive%20integer%22&amp;vid=ISBN9781400830398&amp;btnG.x=0&amp;btnG.y=0&amp;btnG=Search%20This%20Book#v=snippet&amp;q=%22Will%20there%20always%20be%20a%20positive%20integer%22&amp;f=false"">The Princeton Companion to Mathematics</a>"" (pp. 6)</p>

<blockquote>
  <p>Let $a_1,a_2,a_3,...$ be a sequence of positive integers, and suppose that each $a_n$ lies between $n^2$ and $(n+ 1)^2$. Will there always be a positive integer that can be written in a thousand different ways as a sum of two numbers from the sequence?</p>
</blockquote>

<p>I am curious to know current status and references for this problem.</p>
",combinatorics
"<p>We first introduce several functions motivated by Kolakoski's sequence. The conjecture itself can be stated independently of Kolakoski's sequence. You can skip straight to the formulation of the conjecture below the line. Kolakoski's sequence is the unique sequence of 1's and 2's which describes its own sequence of block lengths and whose first term is 1. The first few terms are 1, 2, 2, 1, 1, 2, 1.... </p>

<p>Notation: we'll write sequences as strings. We use a sequence of length 1 and a single term interchangeably. The concatenation of sequences $s$ and $t$ is $st.$</p>

<p>Let $m, n$ be different positive integers. $\{m, n\}^\omega$ is the set of finite nonempty sequences whose terms are all $m$ or $n.$ We define $E_{m, n}: \{m, n\}^\omega \times \{m, n\}^\omega \rightarrow \{m, n\}^\omega$ recursively as follows. </p>

<p>If $t$ has length $1$, then $E_{m, n}(s, t)$ is the unique finite sequence whose terms are all $m$ or $n$, whose first term is the term in $t$, and whose sequence of block lengths is $s.$ For example, $E_{2, 3}(233, 2)=22333222.$</p>

<p>If $t$ has length greater than $1,$ then suppose that $t=yu,$ where $y$ is a single term (the first term), $u$ is the rest of the sequence, and $yu$ is the concatenation. Then $E_{m, n}(s, yu) = E_{m, n}(E_{m, n}(s, y), u).$</p>

<p>One can show that for finite sequences $s_1, s_2, t_1,$ there exists a unique sequence $t_2$ of the same length as $t_1$ (all in $\{m, n\}^\omega$) such that $E_{m, n}(s_1s_2, t_1) = E_{m, n}(s_1, t_1)E_{m, n}(s_2, t_2).$ Furthermore, $t_2$ depends only on $s_1, t_1.$ We define the function $C_{m, n}$ such that $C_{m, n}(s_1, t_1) = t_2.$</p>

<hr>

<p>Another way to define $C_{m, n}: \{m, n\} \times \{m, n\}^\omega \rightarrow \{m, n\}^\omega$, where $m, n$ are positive integers.</p>

<p>We've restricted the first argument to $\{m, n\}$ because that's all that's necessary for the conjecture. Aside: in general, it makes sense for the first argument to be a finite sequence. See the above paragraph. One can show that $C_{m, n}(s_1 s_2, t_1) = C_{m, n}(s_2,C_{m, n}(s_1, t_1)).$</p>

<p>For $x, t$ in $\{m, n\},$ we define $C_{m, n}(x, t)$ to be $\bar{t},$ where $\bar{t}$ is the value in $\{m, n\}$ not equal to $t.$</p>

<p>For $x, y$ in $\{m, n\}$ and $u$ in $\{m, n\}^\omega,$ we define $f(s):=C_{m, n}(y, s)$ and $C_{m, n}(x, yu):=\bar{y}f^x(u),$ where the superscript denotes iteration. </p>

<p>For example, $C_{1, 2}(1, 222) = 1 C_{1, 2}(2, 22) = 11\left(C_{1, 2}(2, C_{1, 2}(2, 2)) \right) = 112.$</p>

<p>Some more examples: $C_{1, 2}(1, -)$ sends $111, 112, 121, 122, 211, 212, 221, 222$ to $222, 221, 212, 211, 121, 122, 111, 112$ respectively, and $C_{1, 2}(2, -)$ sends $111, 112, 121, 122, 211, 212, 221, 222$ to $211, 212, 221, 222, 111, 112, 121, 122$ respectively.</p>

<p>Observe that $C_{m, n}(x, -),$ where $x$ is fixed, is bijective on $\{m, n\}^\omega,$ and it fixes lengths. Here is the conjecture:</p>

<p><strong>Conjecture.</strong> Let $n, j$ be positive integers with $n$ even. Let $1^j$ be the sequence of $j$ terms which are all $1.$ Then the size of the orbit of $1^j$ under the function $C_{m, n}(1, -)$ equals $2^{\lfloor(j+1)/2\rfloor}.$</p>

<p>One can show that the following conjecture is equivalent: Let $n, j$ be positive integers with $n$ with $j$ even. Then the sequence $E_{1, n}(1^{2^j}, 1^{2j})$ has odd length. $(*)$</p>

<p>We can also define $C_{m, n}: \{m, n\} \times \{m, n\}^\omega \rightarrow \{m, n\}^\omega$ where $m, n$ are any integers. Well, we define it exactly as above. A negative power means involves taking the inverse of the function. To do this, we need the functions $C_{m, n}(x, -)$ to be bijective and length preserving. These properties are easy to show.</p>

<p>Here is another conjecture.</p>

<p><strong>Conjecture.</strong> Let $n, j$ be positive integers with $n$ even. Let $s_1, s_2$ be the two sequences of length $j$ which terms alternate between $-1$ and $n.$ Then the size of the orbits of $s_1$ and $s_2$ under the function $C_{-1, n}(-1,-)$ both equal $2^{\lfloor (j+1)/2 \rfloor}.$</p>

<hr>

<p><strong>Empirical evidence:</strong> Using C++ and a fast routine to exponentiate maps as well as some elementary observations, I proved both conjectures for all $j \le 26$ and all even integers $n.$ Using the equivalent form $(*),$ I proved the conjecture for the cases $n=2$ and $j \le 46.$</p>

<hr>

<p><strong>Remarks.</strong> One can easily show that the sizes of the orbit of an arbitrary string of length $j$ under the function $C_{m, n}(s, -)$ for an arbitrary string $s$ is at most $2^{\lfloor(j+1)/2\rfloor}.$ Thus the sizes of the orbits which we've stated are in some sense the maximum possible.</p>

<p>Note that this conjecture is not true when replacing the strings $1^j, s_1, s_2$ with arbitrary strings. For arbitrary strings, I've empirically found that the lengths of strings related to $E_{1, n}(1^{2^j}, 1^{2j})$ seem to be randomly even or odd, whereas they are always odd for the cases in the conjecture. Because I don't understand this conjecture well, it sort of looks like there are several hundred coin flips landing the same way. I also suspect that understanding these conjectures will involve fields outside combinatorics, but I have no idea which.</p>

<p>As far as I'm aware, this was first observed by Yongyi Chen. I would be interested if this conjecture is actually known.</p>
",combinatorics
"<p>The harmonic numbers are given by $$H_n=\sum_{k=1}^n\frac{1}{k}.$$
Numerical calculation suggests
$$
\sum_{k=1}^{n}(-1)^k{n\choose k}{n+k\choose k}\sum_{i=1}^{k}\frac{1}{n+i}=(-1)^nH_n.
$$
I can not give a proof of this identity. How to prove it? </p>

<p>Hints, references or proof are all welcome.</p>
",combinatorics
"<p>In certain dark corners of computer science and group theory, one often wants to prove that a language is not a regular language (ie a language accepted by a finite state automaton).  </p>

<p>The only general technique I know for doing this is the so-called ""pumping lemma"", which says that if L is a regular language, then there exists some n>0 with the following property.  If w is a word in L of length at least n, then we can write w=xyz (here x, y, and z are subwords) such that y is nontrivial and xy^{k}z is an element of L for all k>0.</p>

<p>This lemma basically reflects the trivial fact that in any directed graph, there is some n such that any path of length at least n contains a loop.</p>

<p>Question : are there any other general techniques for proving that a language is not regular?</p>
",combinatorics
"<p>Is there a good software package for doing computations in the cohomology ring of Grassmannians? Things like, I can write down a polynomial in, in fact, special Schubert classes, but it's one where doing the multiplication out is too tedious for me to have any chance at accuracy in the final answer, and want an efficient way to tell a computer to do it (things that will just multiply pairs, and then you input the next set of pairs don't count).</p>
",combinatorics
"<p>I feel a little embarrassed to be asking this question here, since I think it should be much easier than I'm making it, but here goes:</p>

<p>Given a finite poset P, does there necessarily exist some chain that intersects every maximal antichain? (Note: By maximal antichain, I mean that there's no antichain strictly containing our antichain.) The answer seems to be ""no"" for infinite posets, but I can't find either a reference or a proof when it comes to finite posets.</p>

<p>Sorry if this is an undergrad-homework-level problem...</p>
",combinatorics
"<p>We consider the class $C$ of directed simple (no multiple edges) graphs having the property that every vertex is reachable by a directed path from every other vertex.</p>

<p>Given an integer $k$, what is the maximal possible number of (directed) edges in a graph of $C$ with $n$ vertices
such that there are no directed cycles of length $\leq k$? </p>

<p>For $k=2$ this means simply 
that the existence of an edge from $v$ to $w$ forbids the existence of an edge from $w$ to $v$ and one can thus choose arbitrary orientions (giving rise to a graph in $C$) on the edges of the complete unoriented graph. </p>

<p>For $k=3$, one has also to forbid oriented triangles which is not possible by orienting all edges of a complete graph on $n\geq 3$ vertices such that the result is in $C$.</p>

<p>On the other hand, there are of course no triangles by choosing arbitrary orientations 
(giving rise to an element in $C$) of a complete bipartite graph.
There are thus such graphs having roughly $n^2/4$ directed  edges.</p>

<p>There should be better upper and lower bounds.</p>

<p>Motivation: G. Higman (A finitely generated infinite simple group. J. London Math. Soc. 26,
(1951). 61--64) constructed finitely generated infinite simple groups 
by considering quotients of the finitely presented group $$\langle g_1,\dots,g_n|g_{i-1}^{-1}g_ig_{i-1}=g_i^2\rangle$$
where indices are modulo $n$.</p>

<p>This group is trivial for $n=2,3$ and infinite for $n\geq 4$. Given a directed graph,
one can consider the corresponding group-presentation with generators corresponding to vertices and directed edges corresponding to relations $a^{-1}ba=b^2$. The triviality 
of the group constructed by Higman associated to $n=2,3$ implies that we want to avoid 
oriented cycles of length $\leq 3$ when searching for interesting examples.</p>
",combinatorics
"<p>It is easy to see that for a finite set of integers $A$ of cardinality $n$, the cardinality of the sumset $A+A$ satisfies
$$
2n-1\leq |A+A|\leq \frac{n(n+1)}{2}.
$$</p>

<p>The lower bound is essentially attained when the set $A$ is an arithmetic progression while the upper bound is attained for sets such that $a_{i}+a_{j}=a_{p}+a_{q}$ implies that $\{i,j\}=\{p,q\}$. An example of this set is </p>

<p>$$
A=\{2^{i}:i={0,1,\ldots,n-1}\}.
$$</p>

<p>I think is a fun problem (probably not very difficult) to study what is the rate of growth of $|A_{p}+A_{p}|$ as $n\to\infty$ where 
$$
A_p=\{1^p,2^p,\ldots,n^p\}.
$$</p>

<p>Define the ""asymptotic growth exponent"" as
$$
\mathrm{ge_{p}} = \lim_{n\to\infty} {\frac{\log(|A_{p}+A_{p}|)}{\log(n)}}.
$$</p>

<p>What is the limit $\mathrm{ge_{p}}$ for $p=2$? In general? </p>

<p>Enjoy! :-)</p>
",combinatorics
"<p>Let $A= (a_{ij})_{ij}, 1 \leq i, j \leq n$ be a symmetric $n \times n$ matrix. Suppose </p>

<p>(1) $a_{ij} \geq 0$ are real numbers;</p>

<p>(2) The sum of each row $\sum_{j=1}^{n} a_{ij} = 1$ for $1 \leq i \leq n$.</p>

<p>Then I want to show the following: there must exists a nonzero $\prod_{i=1}^n a_{i, \sigma(i)}$, where $\sigma \in S_n$ is an element of the symmetric group $S_n$. In other words, there must exists a nonzero summand in the expression of $\det A$.</p>
",combinatorics
"<p>Consider $(q_1,q_2,...) \in Q$ non-intersecting sets of distinct elements $(e_{(i,1)},e_{(i,2)},...)\in q_i$.</p>

<p>How many ways can one write down an ordering of all of the $\sum_j |q_j|$ elements s.t.:</p>

<p>(1) For any two elements $e_{(a,1)}$ &amp; $e_{(b,1)}$, where $a &lt; b$, it must be the case that $e_{(a,1)}$ comes before $e_{(b,1)}$ in the ordering;</p>

<p>(2) For any two elements $e_{(i,a)}$ &amp; $e_{(i,b)}$, where $a &lt; b$, and for any set $q_i$, it must be the case that $e_{(i,a)}$ comes before $e_{(i,b)}$ in the ordering;</p>

<p>Is there a closed-form expression for this count?</p>

<p>For example, if there are only two sets $q_1$ and $q_2$, each with three elements, one possible ordering could be:  $(e_{(1,1)},e_{(1,2)},e_{(2,1)},e_{(2,2)},e_{(1,3)},e_{(2,3)})$.</p>
",combinatorics
"<p>The <a href=""http://en.wikipedia.org/wiki/Four_color_theorem"">four color theorem</a> asserts that every planar graph can be properly colored by four colors.</p>

<p><strong>The purpose of this question is to collect generalizations, variations, and strengthenings of the four color theorem with a description of their status.</strong> </p>

<p>(Motivated by a comment of rupeixu to a <a href=""https://gilkalai.wordpress.com/2014/12/06/coloring-simple-polytopes-and-triangulations/"">recent blog post on my blog</a> presenting a question by Abby Thompson regarding a natural generalization of the 4CT.)
Related question:<a href=""http://mathoverflow.net/questions/7650/generalizations-of-planar-graphs"">Generalizations of Planar Graphs  </a> .</p>
",combinatorics
"<p>Let $L \subseteq A^\star$ be a formal language over $A$ generated by a context-free grammar, and $L' = A^\star - L$ be the relative complement in $A^\star$.</p>

<p>If $L$ and $L'$ are both context-free, are they necessarily deterministic context-free?</p>
",combinatorics
"<p>The following problem arises in a particular machine learning problem:</p>

<p>Assume that we have $n$ independent Bernoulli random variables with parameters $p_i$, e.g. $n=5$ and the $p$ vector is $(0.2, 0.3, 0.7, 0.6, 0.3)$. All possible realizations of the random variables form the corners of the $\lbrace 0,1\rbrace^n$-hypercube. There is one corner with highest probability (let's call it $c_\text{max}$), for $p=(0.2, 0.3, 0.7, 0.6, 0.3)$ we have  $c_\text{max} = (0, 0, 1, 1, 0)$. Every corner of the hypercube is thus associated with a probability, let's call it $P^*$.</p>

<p>I am interested in the random variable $Z: \lbrace0,1\rbrace^n\rightarrow\lbrace0,\dots,n\rbrace$ with $Z(c) = $ Hamming distance from $c$ to $c_\text{max}$. Thus, I want to know the probability mass of $P^*$ at distance $1, 2, \dots n$ from $c_\text{max}$. </p>

<p>Brute-force traversal of the hypercube corners is out of the question for the problem sizes I'm considering  ($n &gt; 100$). However, I was thinking that there might by a clever (recursive?) way of exploiting the fact that the probabilities of neighboring corners differ by only one multiplicative factor of $p_i$ or $(1-p_i)$. </p>

<p>Although I don't think that I'm the first to contemplate this problem, a standard literature search has not revealed anything usable. Any algorithm ideas or pointers to the literature are much appreciated.</p>

<p>Thanks,
Stephan</p>
",combinatorics
"<p>Let L be a 2-dimensional lattice and P- a lattice polygon. Suppose, it is triangulated into lattice tiangles. What are restrictions on their areas? For instance, can a lattice triangle of even area always be divided into lattice triangles of area 1? Is there any general approach to such questions? </p>
",combinatorics
"<p>I'm particularly interested in the case $\Lambda^3 \mathbb{F}_3^n$, and specifically, just stabilizers of vectors that satisfy the two conditions (i) there are no zero coordinates (in the basis induced from the standard basis of $\mathbb{F}_3^n$) and (ii) they are in the image of a map $(\mathbb{R}^n)^3 \to \Lambda^3 \mathbb{F}_3^n$ that I will now describe.</p>

<p>We start with the obvious map $(\mathbb{R}^n)^3 \to \Lambda^3 \mathbb{R}^n$. Then write our vector in the standard coordinates $\sum_{i &lt; j &lt; k} a_{ijk} e_i \wedge e_j \wedge e_k \in \Lambda^3 \mathbb{R}^n$ and then replace $a_{ijk}$ with $0 \in \mathbb{F}_3$ if it is 0, $1 \in \mathbb{F}_3$ if it is positive, and $-1 \in \mathbb{F}_3$ if it is negative.</p>

<p>I can calculate with GAP all stabilizers for n = 4, 5, and stabilizers for given vectors for n = 6, 7.</p>

<p>For n = 4 I get $\mathbb{Z} / 4, \mathbb{Z} / 3$, and $Alt(4)$, for n = 5 I get $1, \mathbb{Z} / 3$ and $\mathbb{Z} / 5$, and for n = 6 and 7 I can find cyclic groups of orders 1, 2, 3, 5, 6, and 1, 3 respectively.</p>

<p>It seems like the sort of problem that should have a solution....</p>
",combinatorics
"<p>Given a finite non-empty set $N$ of integers, call a subset $M$ of $N$ <em>good</em> if $gcd(M)=gcd(N)$. The other subsets are called <em>bad</em>.</p>

<blockquote>
  <p>Does there exist an algorithm which
  computes a good subset of minimal size
  in polynomial time (polynomial in $|N|$)?</p>
</blockquote>

<p>Using a greedy strategy, it is easy to find good subsets $M$ which are minimal with respect to inclusion (i.e. every proper subset of $M$ is bad). But it is not difficult to construct examples where such a greedy strategy may fail to find a set of globally minimal size.
Take for example N={6=2*3, 10=2*5, 15=3*5, 1}. Then $gcd(N)=1$, and both {6,10,15} and {1} are good subsets. Both are minimal good subset wrt to inclusion. This can be easily generalized.</p>

<p>So, something more advanced would needed. Obviously, one can test all subsets, but then one gets exponential runtime. Is there a better way? Or can one prove that there isn't? Maybe this is equivalent to efficiently factoring primes?
As it is, I am not even sure whether this problem is in NP...</p>

<p>(Note that this question is about an important special case of an <a href=""http://mathoverflow.net/questions/44888/finding-globally-minimal-row-subsets-of-an-integer-matrix-which-generate-the-full"">earlier question of mine</a>; I hope it'll attract a few more people by being less technical).</p>
",combinatorics
"<p>Consider two partially ordered sets $A = \{a&lt; b,a&lt; c\}$, $B=\{x&lt; z,y&lt; z\}$.</p>

<p>Their linear extensions (here we allow equality in linear extensions) for $A, B$ are 
$$A_L=\{A_1=\{a&lt; b&lt; c\}, A_2=\{a&lt; b= c\}, A_3=\{a&lt; c&lt; b\}\}$$
and
$$B_L = \{ B_1 = \{x&lt; y&lt; z\}, B_2=\{y&lt; x&lt; z\}, B_3 =\{x= y&lt; z\}\}$$</p>

<p>We may define two order isomorphisms</p>

<p>$f_1: A_1\to B_1$ by $f_1(a)=x, f_1(b)=y, f_1(c)=z$ and</p>

<p>$f_2:A_3\to B_2$ by $f_2(a)=y, f_2(b)=x, f_2(c)=z$,</p>

<p>but there is no order isomorphism $f_3$ from $A_2$ to $B_3$ s.t. $t&lt; s\Longleftrightarrow f_3(t)&lt; f_3(s)$ and $t=s \Longleftrightarrow f_3(t)=f_3(s)$.  (And it's easy to see that no other pairing of the $A_i$ with the $B_j$ will allow such maps to be chosen.)</p>

<p>There are no order isomorphisms from $A$ to $B$, either.</p>

<p>Is the following conjecture true?</p>

<p>For any partially ordered sets $A,B$, if there exist isomorphisms from $A$'s linear extensions to $B$'s, then there exists an isomorphism from $A$ to $B$.</p>

<p>If not, could you give me a counter example? </p>
",combinatorics
"<p>It is somewhat miraculous to me that even very complicated sequences $a_n$ which arise in various areas of mathematics have the property that there exists an elementary function $f(n)$ such that $a_n = \Theta(f(n))$ or, even better, $a_n \sim f(n)$.  Examples include </p>

<ul>
<li>Stirling's approximation $n! \sim \sqrt{2\pi n} \left( \frac{n}{e} \right)^n$ (and its various implications),</li>
<li>The asymptotics of the partition function $p_n \sim \frac{1}{4n \sqrt{3}} \exp \left( \pi \sqrt{ \frac{2n}{3} } \right)$,</li>
<li>The prime number theorem $\pi(n) \sim \frac{n}{\log n}$,</li>
<li>The asymptotics of the off-diagonal Ramsey numbers $R(3, n) = \Theta \left( \frac{n^2}{\log n} \right)$.</li>
</ul>

<p>What are examples of sequences $a_n$ which occur ""in nature"" and which provably don't have this property (either the weak or strong version)?  Simpler examples preferred.</p>

<p>(I guess I should mention that I am not interested in sequences which don't have this property for computability reasons, e.g. the busy beaver function.  I am more interested in, for example, natural examples of sequences with ""half-exponential"" asymptotic growth.)</p>
",combinatorics
"<p>An orthogonal representation [1] of a graph $G=(V,E)$ on $n$ vertices $\{1,2,...,n\}$ is an assignment of (complex)
unit vectors $v_{1},v_{2},...,v_{n}$ to the vertices of $G$ such that $\langle v_{i},v_{j}\rangle =0$ if and only if $\{i,j\}\in E(G)$. </p>

<p>An orthogonal matrix representation (see, e.g., [2]) of $G$ is an
assignment of unitary matrices $U_{1},U_{2},...,U_{n}$ to the vertices of $G$
such that $[U_{i}^{\dagger }U_{j}]_{k,k}=0$, for every $k$, if and only if $%
\{i,j\}\in E\left( G\right) $. </p>

<p>Is it true that if there is an orthogonal representation of a certain dimension then there is always an orthogonal matrix representation of the same dimension?</p>

<p>[1] L. Lovász,  On the Shannon Capacity of a Graph, IEEE Trans. Inf. Theory, 25 (1):1-7 (1979).</p>

<p>[2] P. J. Cameron, A. Montanaro, M. Newmann, S. Severini, A. Winter, On the quantum chromatic number of a graph, <a href=""http://arxiv.org/abs/quant-ph/0608016"">http://arxiv.org/abs/quant-ph/0608016</a></p>
",combinatorics
"<p>For an $n$-element metric space $X=\{x_1,\dots,x_n\}$ with metric
$d$ we introduce an array containing $\frac{n(n-1)}2$ numbers
$d(x_i,x_j)$, $i&lt;j$. We assume that all distances are at least
$1$. The number of <em>relevant scales</em> for the metric space $X$
is defined as the number of intervals $[2^{i-1},2^{i})$
$i=1,2,\dots$ containing some elements of the array $d(x_i,x_j)$,
$i&lt;j$. Let $RS(n)$ be the maximal number of relevant scales which
an $n$-element metric space may have.</p>

<p>Problems: (1) What is the rate of growth of $RS(n)$? (2) What
about exact evaluation of $RS(n)$ for all $n\in \mathbb{N}$?</p>

<p>Comments: (1) In Exercise 3.37 of my book ""Metric Embeddings"" I
suggest readers to prove the following two statements as exercises
(hints are given):</p>

<p>(i) $RS(n)\ge 2n-3$.</p>

<p>(ii) $RS(n)\le \frac{n(n-1)}2-(n-4)$.</p>

<p>So for nontrivially large $n$ the number $RS(n)$ is strictly
between $n$ and $\frac{n(n-1)}2$.</p>

<p>(2) One can replace $2$ by another number in the definition of
$RS(n)$, and it may change the answer.</p>
",combinatorics
"<p>From the observation, that a bipartite graph doesn't contain odd cycles, it would seem natural to attempt to destroy all odd cycles in the most efficient way, by either removing edges or vertices of odd cycles, in order to find a maximal subset of the vertices that spans a bipartite sub graph.</p>

<p><strong>I would appreciate references to articles in which such <em>direct methods of destroying odd cycles by removing edges or vertices from a graph</em> and their related problems are discussed.</strong></p>

<p>An example of a problem that is related to most effectively destroying odd cycles, would be how to determine the number of odd cycles that removing an edge or vertex will destroy. </p>
",combinatorics
"<p>I'd like to compute explicitly symmetric Macdonald functions associated to arbitrary (possibly non-reduced) root systems, using Computer Algebra System. </p>

<p>Unfortunately Sage seems to only implement the A-type Macdonald polynomials <a href=""http://www.sagemath.org/doc/reference/sage/combinat/sf/macdonald.html"">http://www.sagemath.org/doc/reference/sage/combinat/sf/macdonald.html</a></p>

<ul>
<li>Is there a nice paper where a combinatorial formula is provided? </li>
<li>Has somebody happened to implement it in some programming language?</li>
</ul>

<p>Of course I can perform the Gram-Schmidt orthogonalization w.r.t. the known measure, but I'll keep it as a last resort.</p>
",combinatorics
"<p>Let $G(k,n)$ be the Grassmannian of complex $k$-planes in $\mathbb{C}^n$. Then for $k_1+k_2=k$ and $n_1+n_2=n$, $G(k_1,n_1)\times G(k_2,n_2)$ is a submanifold of $G(k,n)$. So the cohomology class of it should be written as a linear combination of Schubert classes. Is there a method to compute the coefficients?</p>

<p>All I know about it is that each Schubert class corresponds to a partiton(or Young diagram). If this question is trivial or well-known, please let me know what I should read.</p>
",combinatorics
"<p>I have $n$ vectors $e_1 \in  (\mathbb Z/2 \mathbb Z)^m,\dots,e_n \in  (\mathbb Z/2 \mathbb Z)^m $</p>

<p>and a vector $ v \in  (\mathbb Z/2 \mathbb Z)^m $</p>

<p>I need to find the better algorithm which answers the question:</p>

<p>Does $v$ is in the vector space spanned by $e_1,\dots,e_n $ ?</p>
",combinatorics
"<p>I just had to make use of an elementary rational function identity (below).  The proof is a straightforward exercise, but that isn't the point.  First, ""my"" identity is almost surely
not original, but I don't have a reference for it.  Perhaps someone knows it (like a lost cat without a collar) or, more likely, could spot this as a special case of a more general identity.  Second, the obvious proof is not much of an explanation: a combinatorial identity often arises for a conceptual reason, and I'd be happy to hear if anyone sees mathematics behind this one.  </p>

<p>Let $f(x_1,\ldots,x_n)=\prod_{p=1}^n\big(\sum_{i=p}^n x_i\big)^{-1}$.  Then
$$
f(x_1,\ldots,x_n)+f(x_2,x_1,x_3,\ldots,x_n)+\cdots+f(x_2,\ldots,x_n,x_1)=\big(\sum_{i=1}^n x_i\big)/x_1\cdot f(x_1,\ldots,x_n),
$$
where $x_1$ appears as the $i$th argument to $f$ in the $i$th summand on the left side, for $1\leq i\leq n$.  But why?</p>
",combinatorics
"<p>(previous title "" Zero sum of binomials coefficients - a stronger version "")
This is a stronger version of <a href=""http://mathoverflow.net/questions/74045/zero-sum-of-binomial-coefficients"">another question</a>.</p>

<p>Is there an $N\in \mathbb N$ and a sequence of non-constant functions $ \left\{ p_n:[n] \to \{ 1,-1 \} \right\}_{n=N} ^{\infty}$ such that for all $n&gt;N$ we have:</p>

<p>$$ \sum _{i=0} ^{n} (-1)^{i}  p_n(i) \cdot \binom {n} {i} = 0$$</p>

<p>For instance, for all odd values of n, we may choose 
$p_{n}(i)=\begin{cases}
(-1)^{i} &amp; i\leq\frac{n-1}{2}\\\
(-1)^{i+1} &amp; i\geq\frac{n+1}{2}\end{cases}$. This simply means we sum the first half of the binomial coefficients and subtract the second half. The fact that for odd values we can partition the set of binomial coefficients evenly allows us to do that, so I don't see how the same trick may be applied for even values.</p>

<p>To my understanding, the methods that solved <a href=""http://mathoverflow.net/questions/74045/zero-sum-of-binomial-coefficients"">the previous question</a> (for which I thank <a href=""http://mathoverflow.net/users/2530/darij-grinberg"">darij grinberg</a> and <a href=""http://mathoverflow.net/users/10265/mikael-de-la-salle"">Mikael de la Salle</a>) are not applicable here.</p>

<p>My guess, as before, is that there is no such sequence (in which all functions are non-constant), any ideas on how to prove it?</p>

<p>(a counter example would surprise me, but is of interest as well)</p>
",combinatorics
"<p>This question is <a href=""http://math.stackexchange.com/questions/300026/number-of-permutations-with-k-inversions-and-with-a-single-clamped-value"">cross-posted</a> from math.stackexchange because it might be too technical.</p>

<p>Let $S_n$ be the symmetric group. Recall that the number of inversions of a permutation $\sigma\in S_n$ is the number of ordered pairs $i&lt; j$ with $\sigma(i) &gt; \sigma(j)$. Now, call the number of permutations with $k$-inversions $I_n(k)$. It's easy to see that going from $n-1$ to $n$ we can insert $n$ into spot $j$ to add $n-j$ inversions:</p>

<p>$$I_n(k)=I_{n-1}(k)+I_{n-1}(k-1)+\ldots +I_{n-1}(0).$$</p>

<p>If we let $G_n(t)=\sum_{k=0}^{\binom{n}{2}}I_n(k)t^k$, then the above gives 
$$G_n(t)=(1+t+t^2\ldots+t^{n-1})G_{n-1}(t),$$ </p>

<p>and it quickly follows that $G_n(t)=\prod_{j=1}^n\frac{1-x^j}{1-x}$. </p>

<p>I am interested in something more complicated. Let $I^{\sigma(y)=x}_n(k)$ count the number of permutations $\sigma$ of length $n$ such that for a given (fixed) $x,y$ we have $\sigma(y)=x$. In other words I am forcing $y$ to be in bin $x$. Proceeding by similar lines to the above, I get:</p>

<p>$$I_{n}^{\sigma(y)=x}(k)=\sum_{i=0}^{n-1-y}I_{n-1}^{\sigma(y)=x}(k-i)+\sum_{i=n-y+1}^nI^{\sigma(y-1)=x}_{n-1}(k-i)$$</p>

<p>where similar logic was used as before, except now we have to be careful whether we are inserting $n$ to the right/left respectively (inserting to the left shifts $x$ up one bin).</p>

<blockquote>
  <p>Assuming the above is right, is it at all tractable to derive
  an <em>asymptotic formula</em> for $I_n^{\sigma(y)=x}(k)$, as $n\rightarrow\infty$?</p>
</blockquote>

<p>As far as I understand, the way to derive asymptotics for $I_n(k)$, one needs something akin to the Knuth-Netto Formula:</p>

<p>$$I_{n}(k)=\binom{n+k-1}{k}+\sum_{j=1}^\infty (-1)^j\binom{n+k-u_j-j-1}{k-u_j-j}+\sum_{j=1}^\infty(-1)^j\binom{n+k-u_j-1}{k-u_j},$$</p>

<p>where the $u_j=3(3j-1)/2$ are pentagonal numbers. The above can be ""simplified"" using Stirling's approximation and a bunch of careful arithmetic to give asymptotics. <a href=""http://academic.csuohio.edu/bmargolius/homepage/inversions/invers.htm#s5"" rel=""nofollow"">Here is a reference for such a calculation.</a></p>

<p>Naively, the above formula comes from the <a href=""http://en.wikipedia.org/wiki/Pentagonal_number_theorem"" rel=""nofollow"">Euler pentagonal number theorem</a>. I would think one needs a specialized form of this theorem for what I am interested in.</p>

<blockquote>
  <p>Can such a similar asymptotic feat be accomplished for $I_n^{\sigma(y)=x}(k)$?</p>
</blockquote>
",combinatorics
"<p>Let $V = \mathbb C^n$. Consider the plethysm $\bigwedge^k Sym^d V$ as a representation of $GL(V)$. In what special cases (e.g., for what $k$, $d$, and $n$) is this representation's decomposition into irreps known?</p>

<p>The only known nontrivial special case that I am aware of is when $k = 2$: in this case the decomposition is $S_{2d-1,1} \oplus S_{2d-3,3} \oplus S_{2d-5,5} \oplus \cdots$. When $n = 2$, I also know that it is equivalent to find decompositions of plethysms of the form $Sym^k Sym^i V$.</p>

<p>Using the Macaulay2 package SchurRings, I computed all examples with $d \leq 8$ with no obvious patterns jumping out at me.</p>

<p>I would be interested in any other special cases people know about (including ones which only apply to $n = 2$), conjectures along these lines, tables of computed data, or ideas about references that might be fruitful.</p>
",combinatorics
"<p>Say, we have a semimagic square $X$, that is, an $n\times n$ square matrix with entries from natural numbers, such that each row and column of it sums up to the same natural number $s$.
Let $M$ be a set with $s$ elements.
To each $X_{ij}$, we assign a subset $M_{ij}$ of $M$ with $X_{ij}$ elements.</p>

<p><strong> Question: </strong> Is it possible to make the assignment in such a way, that 
    for every $i$ we have $\bigcup_j M_{ij} = M$ and
    for every $j$ we have $\bigcup_i M_{ij} = M$,
or equivalently, whenever the cells $X_{ij}$ and $X_{kl}$ lie in the same row or in the same column, then the subsets $M_{ij}$ and $M_{kl}$ are disjoint?</p>

<p><strong> PS1: </strong> You may think of $s^2$ different balls, each labeled by a number from ${\left\lbrace 1,\dots,s  \right\rbrace}$, such that for each label $l$, there are exactly $s$ balls having label $l$. You have to distribute the balls in the cells of $X$ in such a way, that in each cell $X_{ij}$ there are $X_{ij}$ balls and in each row and column of $X$ we have a whole set of balls labeled from $1$ to $s$.</p>

<p><strong> PS2: </strong> To me, the answer to the question seems to be positive. However, the greedy construction idea does not work.</p>
",combinatorics
"<p>I consider all $k$ element subsets of the set $\{1,\ldots,n\}$ and define a partial order relation $\prec$ as follows: $\{a_1,\ldots,a_k\}\prec\{b_1,\ldots,b_k\}$, if and only if $a_1&lt;\cdots&lt;a_k$, $b_1&lt;\cdots&lt;b_k$ and $a_i\leq b_i$ for all $i=1,\ldots,k$.</p>

<p>What is this partial order commonly called in the literature? Can someone point out references?</p>

<p>Thanks a lot,
Torsten</p>

<p>[edit] Here is a Hasse diagram of this partial order for $n=6$ and $k=3$:
<a href=""http://www.freeimagehosting.net/7pmk7"" rel=""nofollow"">http://www.freeimagehosting.net/7pmk7</a></p>
",combinatorics
"<p>Ordinary operad with one ouput can be obviously regarded as free module on itself. Is there are analogous construction for operad with many outputs (PROP)? This must be difficult question, but what is conceptual reason for that in the context of operads? Also, please point me ways of producing of representations of such structures. Some references and results beyond ordinary operads are welcome too.</p>
",combinatorics
"<p>Let m>1 be an odd natural number, x a m-cycle in Am, the alternating group in m letters, C the conjugacy class of x in Am.</p>

<p>Questiom: How can I describe the elements in the set { j | x^j in C} in terms of m?</p>

<p>For instance, if C' is the conjugacy class of x in Sm, the symmetric group in m letters, then { j | x^j in C} = { j | (j,m)=1 }, where (j,m) = Greatest common divisor of j and m. But in Am, C' splits in two conjugacy classes of Am of the same size: C and the conjugacy class of (1 2)x(1 2) in Am.</p>

<p>Thank you in advance. Fernando.</p>
",combinatorics
"<p>Given a prime power $q$, I would like to enumerate (preferably up to isomorphism*) all the permutation polynomials $f(x)$ on $K = GF(q^3)$ satisfying the following conditions:</p>

<ol>
<li>$f(ax) = af(x)$ for all $a \in GF(q)$,</li>
<li>$Tr_{K/F}(x f(x)) = 0$. ($F := GF(q)$)</li>
</ol>

<p>Such polynomials correspond to perfect matchings in the incidence graph of the projective plane $PG(2,q)$ as follows:
Look at $GF(q^3)$ as a $3$-dimensional vector space over $GF(q)$ equipped with the symmetric bilinear form $(x,y) \mapsto Tr_{K/F}(xy)$. Let the points of the projective plane be $1$-dimensional subspaces. 
And let the lines be given by the $2$-dimensional null spaces of the maps $x \mapsto Tr(ax)$, i.e. $a^\perp$, for a given $a \in GF(q^3)$. 
Therefore, a point $p$ is incident with a line $L$ if $Tr(x_p x_L) = 0$ where $x_p$ and $x_L$ are corresponding members of $GF(q^3)$. 
Now, every permutation polynomial on $GF(q^3)$ defined by the two conditions above maps $1$-dimensional subspaces to $1$-dimensional subspaces giving rise to a bijection between points and lines of $PG(2,q)$, i.e., a perfect matching in the incidence graph of $PG(2,q)$. 
We can see that this is an onto map where fiber of each perfect matching is a set of $(q-1)^{1+q+q^2}$ permutation polynomials. </p>

<p>By [1] a $k$-regular bipartite graph of size $2n$ has at least $$\left( \frac{(k-1)^{(k-1)}}{k^{(k-2)}} \right)^n$$ perfect matchings. 
Therefore there is a lower bound on the number of perfect matchings given by 
$\frac{q^{qn}}{(q+1)^{n(q-1)}}$ where $n = 1 + q + q^2$. </p>

<p>I also know that for for $q = 3$ there are exactly $3852$ perfect matchings giving rise to $31555584 = 3852 \times 2^{13}$ such permutations. This is from computer computations of the perfect matchings. For $q = 4$ there are $18534400$ of them. </p>

<p>To the finite field experts: Is there a way of theoretically classifying such polynomials? Can we give some bounds on the total number? Any suggestions on what approach might work?</p>

<p>*Look at the action of $\Gamma L(3,q)$ on $GF(q^3)$ viewed as a vector space over $GF(q)$. For a permutation polynomial $f$ and a group element $\sigma$ define $f^\sigma (x) = \hat{\sigma} (f(\sigma(x))$ where $\hat{\sigma}$ is the adjoint of $\sigma$ w.r.t. the symmetric bilinear form $(x, y) \mapsto Tr_{K/F}(xy)$.</p>

<p>[1] <a href=""http://homepages.cwi.nl/~lex/files/countpms2.pdf"" rel=""nofollow"">http://homepages.cwi.nl/~lex/files/countpms2.pdf</a> </p>
",combinatorics
"<h3>CONJECTURE</h3>

<p>Let $A= (c_0,c_1,\ldots,c_n)$ be a circulant matrix, i.e if $(c_0,c_1,\ldots,c_n)$ is the first column of $A$ then the $i$<sup>th</sup> column of $A$ is obtained by applying the permutation $(1,2,..,n)^{i-1}$. </p>

<p>Assume $A \in GL_n(Z)$, i.e $A$ with integer entries and determinant $\pm 1$ and moreover $c_0+c_1+\ldots+c_n=\pm 1$.</p>

<p>Then there exists one $j$ such that $c_j=\pm 1$ and $c_i=0$ for all $i$ different from $j$.</p>

<hr>

<p>Is this conjecture true?</p>

<p>What if we add the assumption that $n=p$ a prime?</p>

<p>Thanks for any idea!
Fabienne</p>
",combinatorics
"<p>Let the maximum and minimum degress of a graph be denoted (as usual) by $\Delta$ and $\delta$ respectively.</p>

<blockquote>
  <p>A graph is <strong><em>almost regular</em></strong> if $\Delta-\delta=1$.</p>
</blockquote>

<p>Now, here is a simple way to generate such graphs: start with a regular graph and delete a matching. Either that or add a matching. </p>

<blockquote>
  <p>An almost regular graph which is produced from a regular graph by the
  addition or removal of a matching is <strong><em>obvious</em></strong>.</p>
</blockquote>

<p>Can you find examples of non-obvious almost regular graphs? So far, I am unable to produce any but I have a feeling there ought to be some.</p>

<p>A follow-up question, in case non-obvious ones do exist, would of course be to estimate which case is more prevalent.</p>
",combinatorics
"<p>I want to compute this integral and I would appreciate any help: $N\geq 1$ is fixed.</p>

<p>$$I_N=\int_{0\le r_n\le r_{n-1}\le\cdots\le r_1} e^{-(r_1^2+\cdots+r_n^2)} \prod_{i&lt;j} \sinh(r_i-r_j) dr_1\cdots dr_n.$$
Any interpretation of this integral using matrix theory or any other field is welcome.</p>
",combinatorics
"<p>Say we have a labeled, binary unrooted tree $T$, i.e. each node has either 1 or 3 neighbors.<br>
Denote by $L(T)$ the set of leaves (degree-one nodes) of $T$.</p>

<p>For some $L \subseteq L(T)$, denote by $t(L)$ the smallest subtree of $T$ containing $L$.
That is, $t(L)$ is the minimal (in terms of nodes) connected induced subgraph of $T$ that contains $L$.</p>

<p>A $k$-partition $P = \{L_1, \ldots, L_k\}$ of $L(T)$ is called <strong>valid</strong> if for any distinct $L_i, L_j \in P$, 
$t(L_i)$ and $t(L_j)$ are vertex-disjoint.</p>

<p>The question is : how many valid $k$-partitions of $L(T)$ does $T$ have ?
Denote by $p(T)$ the number of such partitions.</p>

<p>I'd like to know if this problem is known/has been addressed previously.</p>

<p>I'd be happy with lower and upper bounds on $p(T)$.  I'd also like to know if the 
structure of $T$ is relevant, or is $p(T)$ only dependent on $|L(T)|$ ?</p>

<p>NOTE : this originates from this thing called the <a href=""http://en.wikipedia.org/wiki/Perfect_phylogeny"" rel=""nofollow"" title=""Perfect phylogeny problem"">Perfect Phylogeny Problem</a>, 
which has been studied for some time - but no one seems to have bothered with counting $p(T)$.</p>
",combinatorics
"<p>Consider the set of simplicial complexes on $n$ vertices, with partial ordering by containment. What is the Mobius function for this poset?</p>

<p>Are other combinatorial facts known about it (e.g. the number of chains of a given length from one simplicial complex to another)?</p>
",combinatorics
"<p>I am interested in the sequence</p>

<p>$$a(n)=\sum_{k=0}^n {p(n-k) \choose k}$$</p>

<p>where $p(n)$ is a polynomial equation.</p>

<p>When $p(n)=n$ this reduces to the Fibonacci sequence, but what about when $p(n)$ is quadratic?</p>

<p>For example when $p(n)=n^2$, it can be seen that $a(n)$ has superexponential growth by considering only one of the terms of the sum $$a(n) \ge {p(n-(n/2)) \choose n/2}={p(n/2) \choose n/2}\ge\left(\frac{p(n/2)}{n/2}\right)^{n/2}=\left(\sqrt{\frac{n}{2}}\right)^n$$
But I would like to know more information than just this lower bound -  an asymptotic formula would be great. Any ideas?</p>

<p>I found a related sequence <a href=""http://oeis.org/A121689"" rel=""nofollow"">here</a> (which is equivalent to the case when $p(n)=n^2$) along with its generating function if that is any help to anyone.</p>
",combinatorics
"<p>I was planning on figuring this problem out for myself, but I also wanted to try out mathoverflow.  Here goes:</p>

<p>I wanted to know the asymptotics of the sum of the absolute values of the Fourier-Walsh coefficients of the ""Majority"" function on 2n+1 binary inputs.  Long story short, that boiled down to finding the asymptotics of the following quantity:</p>

<p>L[n] := sum{k=0..n} F[n,k],</p>

<p>where</p>

<p>F[n,k] := (2n+1)!! / [(2k+1) k! (n-k)!].</p>

<p>Here is the set of steps that a naive person such as me always follows in such a scenario:</p>

<p>Step 1. Type it into Maple.  In this case, Maple reports back</p>

<p>L[n] = ( (2n+1) (2n choose n) / 2^n ) hypergeom([1/2, -n], [3/2], -1).</p>

<p>I don't know exactly what this hypergeom is, nor how to evaluate its asymptotics.  I can't seem to get Maple to tell me (with asympt()) either.</p>

<p>Step 2. Evaluate the first few terms (1, 4, 14, 48, 166, 584, 2092, etc.) and type it into OEIS.  It's clearly sequence A082590.  There are many definitions given for this sequence; One definition is (basically) the above hypergeometric formula.  Another is that it is</p>

<p>2^n sum{k=0..n} 2^(-k) (2k choose k).</p>

<p>Given this, it's pretty easy to deduce from Stirling that the rough asymptotics is Theta(2^(2n) / sqrt(n)).  Actually, I originally didn't notice this simple definition on the OEIS page.  Instead, the simplest thing I noticed was the title definition, </p>

<p>the [x^n] coefficient of 1/((1-2x) sqrt(1-4x)). </p>

<p>Since that was the simplest thing I initially noticed, I wondered how to find the asymptotics of that.  I was sure many people would know that, but mathoverflow didn't exist at the time.  So...</p>

<p>Step 3. Email Doron Zeilberger out of the blue, asking for help.  He very kindly responded: ""You could use the contour integral... or my favorite way would be to use my Maple packages: </p>

<p>read AsyRec:
read EKHAD:
Asy(AZd( 1/(1-2*x)/(1-4*x)^(1/2)/(x^(n+1)),x,n,N)[1],n,N,2);</p>

<p>which produces </p>

<p>2^(2*n)<em>(1/n)^(1/2)</em>(1+3/8/n+121/128/n^2).""</p>

<p>Great!  There's the precise answer!  But I don't know much about how Zeilberger's packages work, don't know what the contour integral is, and anyway, it's all roundabout story.  </p>

<p>If you were writing this in a paper, what would be the shortest way to go from the definition of L_n to the fact</p>

<p>L[n] = (2^(2n) / sqrt(n)) (1+o(1))?</p>
",combinatorics
"<p>The Murnaghan-Nakayama rule for S_n is a combinatorial rule to compute the irreducible characters of the symmetric group. Is there a q-analogue of this rule for GL(n,q) to compute the irreducible characters? For example, exhibiting that the value of the unipotent characters of GL(n,q) on a unipotent class is given by the cocharge Kostka-Foulkes polynomials, and showing other special cases. </p>
",combinatorics
"<p>While the general problem of detecting a Hamiltonian path or cycle on an undirected grid graph is known to be NP-complete, are there interesting special cases where efficient polynomial time algorithms exist for enumerating all such paths/cycles?  Perhaps for certain kinds of k-ary n-cube graphs?  I hope this question isn't too open-ended...</p>

<p>Update - Is the problem of iterating Hamiltonian path/circuits known to be NP-complete for the N-cube?    </p>
",combinatorics
"<p>Consider triangulation $T.$ </p>

<p>Is it always possible to choose such a subgraph $H$ of $T$ that has a common edge with every face of $T$ and can be directed in such way that indegrees of all vertices of $H$ are equal to one?</p>
",combinatorics
"<p>The Balog-Szemerédi-Gowers theorem can be stated in the following form: let $A,B$ be subsets of $\mathbb{Z}/n\mathbb{Z}$ (say) with equal cardinality, such that
$$
\|1_A*1_B\|_2 \ge K^{-1} \|1_A\|_1 \|1_B\|_2. 
$$
Then there exist $A'\subset A$, $B'\subset B$ with $|A'|\ge K^{-C}|A|$, $|B'|\ge K^{-C}|B|$ such that $|A'+B'|\le K^C |B'|$.</p>

<p>Here $C$ is an absolute constant.</p>

<p>My questions is: what happens if the $2$-norm is replaced by a $q$-norm? If $q\in (1,2)$, then it follows from Hölder that
$$
\|1_A*1_B\|_q \ge K^{-1} \|1_A\|_1 \|1_B\|_q 
$$
implies
$$
\|1_A*1_B\|_2 \ge K^{-\frac{q}{2(q-1)}} \|1_A\|_1 \|1_B\|_2,
$$
so the conclusion still holds, with a constant $C$ that depends on $q$ (blowing up as $q\downarrow 1$).</p>

<p>What about $q&gt;2$? More precisely:</p>

<blockquote>
  <p>Is there any $q&gt;2$ such that the conclusion of the B-S-G Theorem continues to hold if one assumes that $\|1_A*1_B\|_q \ge K^{-1} \|1_A\|_1 \|1_B\|_q $ (possibly with a constant $C$ that depends on $q$)?</p>
</blockquote>
",combinatorics
"<h2>Terminology and context</h2>

<p>(This should all be standard, but is recalled because terminology sometimes varies, and also to put the question into perspective.)</p>

<p>A partially ordered set is called <strong>well-founded</strong> iff it has no infinite decreasing sequence.  It is called <strong>well-partially-ordered</strong> (=wpo) iff it is well-founded and also has no infinite antichain; equivalently, every linearization (=total order extending the given order) is a well-order; equivalently, the lattice its downsets (=downwards-closed subset, =initial segments), partially ordered by inclusion, is well-founded.</p>

<p>The (well-founded) <strong>rank</strong> of a well-founded partially ordered set $P$ is the ordinal defined inductively by $\mathop{\mathrm{rk}}P = \sup\{\mathop{\mathrm{rk}}(x)+1 : x\in P\}$ where $\mathop{\mathrm{rk}}x = \sup\{\mathop{\mathrm{rk}}(y)+1 : y&lt;x\}$.  This is sometimes also called its “height”.  (Obviously, for a well-order, this is just the order type.)</p>

<p>If $P$ is well-partially-ordered, then the sup of the order types of linearizations is attained (de Jongh and Parikh, “<a href=""http://www.sciencedirect.com/science/article/pii/1385725877900671"">Well-Partial Orderings and Hierarchies</a>”, <em>Nederl. Akad. Wetensch. Proc. Ser. A</em> <strong>80</strong> = <em>Indag. Math.</em> <strong>39</strong> (1977), 195–207, thm. 2.13).  Furthermore, the sup in question is also the well-founded rank of the set of proper downsets, partially ordered by inclusion (a fact surprisingly difficult to find in the literature: see Blass &amp; Gurevich, “<a href=""http://dl.acm.org/citation.cfm?id=1352586"">Program Termination and Well Partial Orderings</a>”, <em>ACM Trans. Comput. Log.</em> <strong>9</strong> (2008), art. 18, §4.1 and §7).  Let this ordinal $o(P)$ be called the <strong>type</strong> or “length” or “stature” (comments about which term is best are welcome, incidentally).</p>

<p>Clearly, $\mathop{\mathrm{rk}} P \leq o(P)$ (with equality when $P$ is, in fact, totally ordered, i.e., well-ordered).  Also note for example that if $P = \Sigma^*$ is the set of words on a finite alphabet $\Sigma$, partially ordered by the “subword” relation, then $o(\Sigma^*) = \omega^{\omega^{n-1}}$ where $n = \#\Sigma$ (see <a href=""http://mathoverflow.net/questions/237188/computing-the-ordinal-of-a-rational-language-well-partially-ordered-by-the-subwo"">this other question</a>), whereas $\mathop{\mathrm{rk}}(\Sigma^*) = \omega$.</p>

<h2>Question</h2>

<blockquote>
  <p>Is it possible to give a an upper bound on the type $o(P)$ of a wpo $P$ based solely on its rank $\mathop{\mathrm{rk}} P$?</p>
</blockquote>

<p>And, of course, if the answer is “no”, I'd also like to know what is the smallest rank for which one can construct wpo's of arbitrarily large type, and how.</p>

<p>(Many papers related to the subject seem to tiptoe around this question without actually asking it, let alone answering it.  I find this perplexing because it seems like an obvious thing to ask, and no matter if the answer is easy, well-known or an open problem, whether it is positive or negative, I think it would behoove to point it out.  I seem to understand that the question might perhaps have been discussed in Diana Schmidt's Habilitationsschrift, but I don't have access to it.)</p>
",combinatorics
"<p>In ''<a href=""http://books.google.com/books?id=V8YgNioxF6AC&amp;printsec=frontcover&amp;dq=probabilistic+method&amp;hl=en&amp;src=bmrr&amp;ei=55eLTZ6YNM-WhQeE94yyDg&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=1&amp;ved=0CDAQ6AEwAA#v=onepage&amp;q&amp;f=false"" rel=""nofollow"">The Probabilistic Method</a>'' by Alon and Spencer, the following <b>unbalancing lights</b> problem is discussed. Given an $n \times n$ matrix $A = (a_{ij})$, where $a_{ij} = \pm 1$, we want to maximise the quantity</p>

<p>$x^T A y = \sum_{i=1}^n \sum_{j=1}^n a_{ij} x_i y_j$</p>

<p>over all $n$-dimensional vectors $x$, $y$ such that $x_i,y_j = \pm 1$. The name of the problem comes from interpreting $A$ as a grid of lights that are on or off, and $x$ and $y$ as sets of light switches, each associated with a row or column (respectively); flipping a switch flips all lights in that row or column, and the goal is to maximise the number of lights switched on.</p>

<p>Let $m(A)$ be the maximum of $x^T A y$ over $x$ and $y$ such that $x_i,y_j = \pm 1$. As Alon and Spencer discuss, for any $A$ it is possible to show that $m(A) \ge C n^{3/2}$ for some constant $0&lt;C&lt;1$. On the other hand, there is an explicit family of matrices $A$ such that $m(A) = n^{3/2}$.</p>

<p>It is natural to generalise this problem to $n \times n \times \dots \times n$ arrays $A$ containing $\pm 1$ entries, writing</p>

<p>$A(x^1,\dots,x^d) := \sum_{i_1,\dots,i_d=1}^n a_{i_1\dots i_d} x^1_{i_1} x^2_{i_2} \dots x^d_{i_d}$</p>

<p>and defining $m(A)$ as the maximum of $A(x^1,\dots,x^d)$ over $x^1,\dots,x^d$, each of which is again an $n$-dimensional vector of $\pm 1$'s. Now it is known (and fun to prove!) that for this ""$d$-dimensional"" variant, one can always achieve $m(A) \ge C^d n^{(d+1)/2}$ for some universal constant $C$ between 0 and 1, and on the other hand there exists a family of $A$'s with $m(A) = n^{(d+1)/2}$.</p>

<p><b>My question is:</b> can the lower bound be improved to $m(A) \ge C n^{(d+1)/2}$ for some universal constant $C&gt;0$? Or even just improved so that the dependence on $d$ is subexponential? Conversely, can the upper bound be reduced?</p>

<p><b>Background</b></p>

<p>Finding a lower bound on $m(A)$ in the more general case where $A$ is an arbitrary bilinear form was considered by <a href=""http://qjmath.oxfordjournals.org/content/os-1/1/164.extract"" rel=""nofollow"">Littlewood</a> back in 1930. The bound above for the $d$-dimensional case is a special case of a bound for general $d$-linear forms which was proven later by <a href=""http://www.jstor.org/pss/1968255"" rel=""nofollow"">Bohnenblust and Hille</a>. In the functional analysis literature, the quantity $m(A)$ is known as the injective tensor norm of $A$; this norm, and the above results, are discussed extensively in the book <a href=""http://books.google.com/books?id=QC_KALDZw5wC&amp;printsec=frontcover&amp;dq=analysis+blei&amp;hl=en&amp;ei=vJOLTZzXJMLAhAeyqZ2nDg&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=1&amp;ved=0CCgQ6AEwAA#v=onepage&amp;q&amp;f=false"" rel=""nofollow"">Analysis in Integer and Fractional Dimensions</a> by Ron C. Blei. However, I could not find any information about whether the bounds can be improved.</p>
",combinatorics
"<h2>The Problem:</h2>

<p>The following question of Horst Knörrer is a sort of toy problem coming from mathematical physics. </p>

<p>Let $x_1, x_2, \dots, x_n$ and $y_1,y_2,\dots, y_n$ be two sets of real numbers.</p>

<p>We give now a weight $\epsilon_\pi$ to every permutation $\pi$ on {1,2,...,n} as follows:</p>

<p>1) $\epsilon_\pi =0$ if for some $k \ge 1$, $x_k \ge y_{\pi(1)}+y_{\pi(2)}+\cdots +y_{\pi(k)}$.</p>

<p>2) Otherwise, $\epsilon_\pi=sg(\pi )$. ($sg (\pi )$ is the sign of the prrmutation $\pi$.)</p>

<p><strong>Problem:</strong> Show that there is a constant $C&gt;1$ such that (for every $n$ and every two sequences of reals $x_1,\dots,x_n$ and $y_1, \dots, y_n$), </p>

<p>$$\sum_\pi \epsilon_\pi \le C^n \sqrt{n!}.$$ </p>

<h2>Origin and Motivation from Mathematical Physics</h2>

<p>1) The problem was proposed by Horst in a recent Oberwolfach's meeting as a combinatorial problem that arises (as a toy problem) from mathematical physics. </p>

<p>The context of this question is explained in Section 4 of 
J.Feldman, H.Kn\""orrer, E.Trubowitz:
""<a href=""http://www.math.ethz.ch/~knoerrer/feldknoerrer.pdf"">Construction of a 2-d Fermi Liquid</a>"", Proc. XIV. International Congress on Mathematical Physics. Editor: Jean Claude Zambrini. World Scientific 2005</p>

<p>""In this section, we formulate an elementary question about permutations that may be connected with implementing the Pauli exclusion principle in momentum space."" </p>

<p>The problem and some variations are directly related to ""cancellations between
Fermionic diagrams"".</p>

<p>The wider picture (See the <a href=""http://www.math.ubc.ca/~feldman/fl.html"">Eleven Papers by J.Feldman, H.Knörrer, E.Trubowitz</a>) is toward mathematical understanding and formalism for highly successful physics quantum theories. (In a very very wide sense this is related to Clay's problem on <a href=""http://www.claymath.org/millennium/Yang-Mills_Theory/"">Yang-Mills and Mass gap</a>.) </p>

<h2>Remarks and more Motivation</h2>

<p>2) This remarkable cancellation property seems similar to cancellations that we often encounter in probability theory, combinatorics and number theory. </p>

<p>3) It look similar to me even to issues that came in my <a href=""http://mathoverflow.net/questions/57543/walsh-fourier-transform-of-the-mobius-function"">recent question</a> on Walsh functions.
So this question about permutations is analogous to questions asserting that for certain +1,-1,0 functions on ${-1,1}^n$ there is a remarkable cancellation when you sum over all $\pm 1$ vectors. This is true (to much extent) for very ""low complexity class functions"" (functions in $AC^0$) by a theorem of Linial-Mansour-Nisan, So maybe we can expect remarkable cancellation for ""not too complex"" functions defined on the set of permutations.</p>

<p>4) We can simplify in the question and replace condition 1) by </p>

<p>1') $\epsilon_\pi =0$ if for some $k \ge 1$, $x_k \ge y_{\pi(k)}$. </p>

<p>I don't know if this makes much difference.</p>

<p>5) An affarmative answer seems a very bold statement, so, of course, perhaps the more promising direction is to find a counter example. But I think this may be useful too.</p>
",combinatorics
"<p>I have the following problem </p>

<p>consider a random bipartite with vertex classes $A$ and $B$ of size $|A|=|B|=\mathrm{log}^{2}(n)$ graph in which every possible edge is chosen independently with probability $p(n)=\frac{1}{{\mathrm{log} (n)}}$. Now i don't know if this graph will contain w.h.p a perfect matching but if it does i'd like to prove it. So i guess my first question is does it? If the answer to my first question is yes, id' like to be able to prove it. As i'm fairly new to perfect matchings i had the following idea, although i'm not sure if this is a conventional way to prove a random bipartite graph has a perfect matching w.h.p </p>

<p>I'm aware that Halls condition is a necessary and sufficient condition to prove the existence of a perfect matching i.e. for any subset $S \subseteq A$ that $|N(S)| \geq |S|$. So would it suffice to show that for any $S \subseteq A$ that $|N(S)| \geq |S|$ in the following way. If a set $S'$ violates Halls condition then there must exist at least $\mathrm{log}^{2}(n)-|S'|$ vertices in $B$ which are not adjacent to any vertex in $S'$. Given any collection of these vertices the probability they are not independent to any vertex in $S'$ is $(1-p)^{|S'|(\mathrm{log}^{2}(n)-|S'|)}$. In addition there are $\binom{\mathrm{log}^{2}(n)}{\mathrm{log}^{2}(n)-|S'|}$ possible choices for $|S'|$  and $|S'|$ can range from $1$ to $\mathrm{log}^{2}(n)$. Henceit would suffice to require $\sum_{|S'|=1}^{\mathrm{log}^{2}(n)} \binom{\mathrm{log}^{2}(n)}{\mathrm{log}^{2}(n)-|S'|}(1-p)^{|S'|(\mathrm{log}^{2}(n)-|S'|)}=o(1).$ where $p=\frac{1}{\mathrm{log}(n)}$.</p>

<p>So firstly i'd like to know whether a perfect matching exists w.h.p and secondly whether my proof would be sufficient for it. I appreciate any help. </p>
",combinatorics
"<p>Given a formal grammar of a language or an Turing machine of the language, can we count the path that generating sentences of the language?</p>

<p>For example, we know that if the grammar is context-free and unambiguious , we have Schutzenberger-Chomsky theorem, by which we know the number of path is equivalent to the number of the sentence. Since grammars of languages may neither be context-free nor umabiguious, is there any formula or method that can counts the path generating sentences of a formal language? Obviously, the number of sentences may not equal to number of path generating sentences in such cases.</p>
",combinatorics
"<p>An colleague recently came to me with a problem concerning the scheduling of tasks in the presence of constraints (of the kind: task $x$ can't begin until task $y$ has been completed). It turned out that the problem was equivalent to that of computing the width (cardinality of maximum antichain) of a poset. </p>

<p>I know that the problem of computing the width of a poset can be translated into that of finding the size of a maximum matching in a certain bipartite graph, which in turn can be found using the Hopcroft–Karp algorithm, in time $O(n^{5/2})$ (where $n$ is the number of elements in the poset).</p>

<p>To me, that's ``polynomial time; end of story''; but to my colleague, who is working with actual data sets, the degree of the polynomial is very important.</p>

<p>My question: what is the current state-of-that art in terms of algorithms for computing the width of a general poset?</p>
",combinatorics
"<p>Is there a ""Cauchy-Schwarz proof"" of the following inequality?</p>

<p><strong>Theorem.</strong> Given $f \colon [0,1]^2 \to [0,1]$, one has
$$
\int_{[0,1]^4} f(x,y)f(z,y)f(z,w) \, dxdydzdw \geq \left(\int_{[0,1]^2} f(x,y) \, dxdy\right)^3.
$$</p>

<p><em>Background.</em>
This inequality is due to <a href=""http://www.ams.org/mathscinet-getitem?mr=184950"">Blakley and Roy (1965)</a>. In fact, they proved even more, namely when the LHS corresponds to a path of length $k$ (above $k=3$) and the RHS is $(\int f)^k$. </p>

<p>This is a special case of a more general Sidorenko's conjecture, which claims that $t(H,W) \geq (\int W)^{e(H)}$ for any bipartite graph $H$. The general case of Sidorenko's conjecture is still open. See, e.g., this <a href=""http://math.mit.edu/~fox/paper-sidorenko-short.pdf"">note by Conlon, Fox, and Sudakov</a> (although there has been some other progress since then).</p>

<p><a href=""http://arxiv.org/abs/1107.1153v1"">Szegedy and Li</a> gives a different proof of the above inequality, using convexity of the logarithm function. </p>

<p>Also see the paper of <a href=""http://arxiv.org/abs/1310.4383"">Kim, Lee, and Lee</a> for another approach.</p>

<p>On page 28 of <a href=""http://rads.stackoverflow.com/amzn/click/0821890859"">Lovasz' book on graph limits</a>, it states this inequality without proof, and then says</p>

<blockquote>
  <p>... and this is already quite hard, although short proofs with a tricky application of the Cauchy–Schwarz inequality are known.</p>
</blockquote>

<p>So my question is: how does one prove the inequality above using Cauchy-Schwarz?</p>
",combinatorics
"<p>This is a follow up to <a href=""http://mathoverflow.net/questions/177852/is-the-reduced-plethysm-restricted-to-2-columns-in-young-tableaux-of-this-schu"">this question</a> about finding the multiplicities of irreducible representations restricted to Young diagrams of 2-columns or less, inside the <em>plethysm</em> $Sym^m(\bigwedge^p \mathbf(V))$ for both cases when 1) p is odd 2) p-is even, here $\mathbf(V)$ is of sufficiently high dimension. This can be achieved by applying the duality and using the Cayley-Hamilton theorem (as you can see from the nice answers I got).</p>

<p>Now, I would like to find explicit construction of these irreducible spaces. That is given an irreducible representation $\mathbb{S}_\lambda \mathbf(V) \subset Sym^m(\bigwedge^p \mathbf(V))$ characterised by a Young-diagram $\lambda$ with 2 or less columns with multiplicity $m_\lambda$, I would like to find what weight vectors generate them for each of the copies of equivalent irreducibles.</p>

<p>I guess this will be given by the action of the <strong>young symmetriser</strong> for a subset of(equal to multiplicty) tableaux generated by the Littlewood richardson for the tensor product $(\bigwedge^p \mathbf(V))^{\otimes m}$ since </p>

<p>$Sym^m(\bigwedge^p \mathbf(V)) \subset (\bigwedge^p \mathbf(V))^{\otimes m} $</p>

<p>I realise that this might be a difficult problem in general, but in this case this it is very specialised, and only 2 or less number of columns are considered.</p>

<p>I will appreciate if anyone can provide an algorithm or positive rule or point me to a reference. </p>

<p>(p.s A brute force approach is to write down all tableaux for given young diagram, given by littlewood and symmetrise the collection of factors and see which one survives.) </p>

<p>I am a physicist and I apologise if this is a silly question.</p>
",combinatorics
"<p>Given two coprime integers $a &lt; b$ of different parities, only a finite number of 
points in $\mathbb N^2$ cannot be reached by a walk in $\mathbb N^2$, starting at the origin
and using only steps of the form $(b,\pm a),(\pm a,b)$ (and thus making an acute angle
with the north-eastern vector $(1,1)$).</p>

<p>Is there a good upper bound on the number of such exceptional points? Is there a good
upper bound on the coordinate sum $x+y$ of such an exceptional point $(x,y)$?</p>

<p>(Remark: A naive proof that almost all points can be reached gives an upper bound which is probably very far from the true value.)</p>
",combinatorics
"<p>Question arises from considering cache oblivious algorithms.</p>

<p>What is the optimal way arrange the numbers $1$ to $k^2$ in a grid, to minimize to average difference between any two neighbouring squares?  What about minimizing the expected maximum difference between two squares, chosen uniformly?  [Joining the edges of the grid to form a torus]</p>

<p>We can do better than just filling in row by row, for instance the Morton layout (for $k = 2^n$), as illustrated below for $k = 16$</p>

<p>$\begin{array}{cccccccc} 1&amp;  2&amp;  5&amp;  6&amp; 17&amp; 18&amp; 21&amp; 22\\\\
 3&amp;  4&amp;  7&amp;  8&amp; 19&amp; 20&amp; 23&amp; 24\\\\
 9&amp; 10&amp; 13&amp; 14&amp; 25&amp; 26&amp; 29&amp; 30\\\\
11&amp; 12&amp; 15&amp; 16&amp; 27&amp; 28&amp; 31&amp; 32\\\\
33&amp; 34&amp; 37&amp; 38&amp; 49&amp; 50&amp; 53&amp; 54\\\\
35&amp; 36&amp; 39&amp; 40&amp; 51&amp; 52&amp; 55&amp; 56\\\\
41&amp; 42&amp; 45&amp; 46&amp; 57&amp; 58&amp; 61&amp; 62\\\\
43&amp; 44&amp; 47&amp; 48&amp; 59&amp; 60&amp; 63&amp; 64\end{array}$</p>

<p>Is there a better layout?  I'm sure someone must have thought about this before, but can't seem to find anything relevant.</p>
",combinatorics
"<p>(In this discussion I'm assuming all matrices are binary (0/1-valued).) We say that a matrix $M$ can be <i>covered</i> by another matrix $N$ if every entry in $M$ is either (1) NOT contained in $N$, or (2) contained in a submatrix of $M$ that equals to $N$, up to reordering the columns and rows. Note that if $N$ contains both 0- and 1-entries then condition (1) never holds. Lacking of a better name, let's call a matrix $M$ a <i>self-covering</i> matrix if $M$ can be covered by <i>any</i> submatrix $M'$ of itself, provided that the columns (and likewise the rows) of $M'$ are pairwise distinct.</p>

<p>For example, a zero matrix is vacuously self-covering, and so uninteresting. Thus let's focus only on the case where the columns (and likewise the rows) of $M$ are pairwise distinct.</p>

<p>My questions are: have self-covering matrices been studied before? If yes, what are they called in literature? I came across these matrices during my research but I have little understanding about them. I can construct a nontrivial family of self-covering matrices, but I am wondering if there exists any other. In particular, I am interested to know more about their characteristics, and the sufficient and necessary conditions for a matrix to be self-covering. Any reference or answer is appreciated.</p>
",combinatorics
"<p>The Newton's series, i.e. the discrete analogue of the continuum Taylor expansion, involves classical iterated difference operators $\Delta$ defined by $\Delta f(k) = f(k+1) - f(k)$. Indeed, Newton's series writes $$f(x) = \sum_{k=0}^{\infty}\frac{\Delta^{k}f(a)}{k!}(x-a)_{k},$$ </p>

<p>where $(x)_{k} = x(x-1)(x-2)...(x-k+1)$. </p>

<p>There also exist a generalized difference operator defined by</p>

<p>$$\Delta^{\mu}f(x) = \sum_{k=0}^{\infty}\mu_{k}f(x+k),$$</p>

<p>where $\mu = (\mu_{1}, \mu_{2}, ...)$ is a sequence of real numbers such that $\sum_{k=0}^{\infty}\mu_{k} &lt; \infty$.</p>

<p>My question: is there a ""discrete Taylor expansion"" like the one presented above involving $\Delta^{\mu}$ instead of the classical $\Delta$ ?</p>

<p>Thank you for your answers !</p>
",combinatorics
"<h2>Background</h2>

<p>I came up with this while trying to find a sort of high-level exposition of the exterior algebra of a vector space.  Let $V$ be a vector space of dimension $n$ over $\mathbb{C}$, and let $k \in \mathbb{N}$.  One picture of $\Lambda^k(V)$, the $k^{th}$ exterior power of $V$, is as the space of totally antisymmetric tensors in $V^{\otimes k}$.</p>

<p>This can be constructed as follows.  Let
$$ \rho : S_k \to \mathrm{End}(V^{\otimes k})$$
be the representation given by
$$ \rho_\pi (v_1 \otimes \dots \otimes v_k) = v_{\pi(1)} \otimes \dots \otimes v_{\pi(k)},$$
and then let $\sigma$ be the alternating form of this representation, i.e. $\sigma_\pi = sgn(\pi) \rho_\pi$.  The total antisymmetrizer is the map
$$A_k = \frac{1}{k!} \sum_{\pi \in S_k} \sigma_\pi.$$
This is the projection onto the space of totally antisymmetric tensors, and so we can calculate the dimension of $\Lambda^k(V)$ simply by taking the trace of the map $A_k$.  It turns out that 
$$\mathrm{tr}(\rho_\pi) = n^{cyc(\pi)},$$
where by $cyc(\pi)$ I mean the number of cycles in the factorization of $\pi$ into disjoint cycles (including cycles of length 1).  This can be shown as follows.  Take a basis $\{ e_1, \dots, e_n \}$ of $V$ and then form the basis for $V^{\otimes k}$ consisting of all vectors $ e_{i_1} \otimes \dots \otimes e_{i_k}$ such that $1 \le i_1, \dots, i_k \le n $.  Then 
$$ \rho_\pi(e_{i_1} \otimes \dots \otimes e_{i_k}) = e_{i_{\pi(1)}} \otimes \dots \otimes e_{i_{\pi(k)}},$$
so this basis vector contributes 1 to the trace of $\rho_\pi$ if and only if $i_j = i_{\pi(j)}$ for all $1 \le j \le k$, i.e. if and only if all labels are constant over cycles of $\pi$.  Since there are $n$ choices for each label, this gives
$$\mathrm{tr}(\rho_\pi) = n^{cyc (\pi)},$$
and thus
$$ \mathrm{tr}(A_k) = \frac{1}{k!} \sum_{\pi \in S_k} sgn(\pi) n^{cyc (\pi)}.$$</p>

<hr>

<blockquote>
  <p>Question: does anybody know a simple combinatorial proof that 
  $$ \frac{1}{k!} \sum_{\pi \in S_k} sgn(\pi) n^{cyc (\pi)} = \binom{n}{k},$$
  where (in case you didn't read the long-winded background that I wrote), $cyc(\pi)$ is the number of cycles in the disjoint cycle factorization of $\pi$.</p>
</blockquote>
",combinatorics
"<p><strong>EDIT:</strong> Context for this investigation can be found in one of my other MO posts, <a href=""http://mathoverflow.net/questions/32377/pythagorean-theorem-for-right-corner-hyperbolic-simplices"">""Pythagorean Theorem for Right-Corner Hyperbolic Simplices?""</a></p>

<p>--</p>

<p>I'm investigating a function that has led me to this series:</p>

<p>$$T(r) = \sum_{k=0}^{\infty}{2k \choose k}\frac{1}{(k+r)^2 16^k}={}_3F_2(\;\;\frac{1}{2},\;r,\;r\;;\;1+r,\;1+r\;;\;\frac{1}{4}\;\;)\frac{1}{r^2}$$</p>

<p><a href=""http://www.cs.cmu.edu/~adamchik/articles/sums/Csum.pdf"" rel=""nofollow"">This paper (""A certain series associated with Catalan's constant"") by Victor Adamchik</a> spotlights a tantalizingly similar series ...</p>

<p>$$S(r)=\sum_{k=0}^{\infty}{2k\choose k}^2 \frac{1}{(k+r) \;\; 16^k}={}_3F_2(\;\;\frac{1}{2},\;\frac{1}{2},\;r\;;\;1,\;1+r\;;\;1\;\;)\frac{1}{r}$$</p>

<p>... where the square is on the ""wrong"" factor.</p>

<p>I'm not very familiar with hypergeometric series (yet). Is there an identity that relates $S$ and $T$?</p>

<p><strong>Edit:</strong> I've added the ""${}_3F_2$"" representations of $S$ and $T$.</p>

<p><strong>Edit2:</strong> I have a particular interest in the case $r=1/2$:</p>

<p>$$T(1/2) = 4 \cdot {}_3F_2(\;\;\frac{1}{2},\;\frac{1}{2},\;\frac{1}{2}\;;\;\frac{3}{2},\;\frac{3}{2}\;;\;\frac{1}{4}\;\;) = 4 \cdot \Im( Li_2( \exp( \frac{i \pi}{3} ))) = 4 \;\; \sum_{k=1}^{\infty}\frac{\sin(\frac{\pi}{3}k)}{k^2}$$</p>

<p>$$S(1/2)= 2\cdot {}_3F_2(\;\;\frac{1}{2},\;\frac{1}{2},\;\frac{1}{2}\;;\;1,\;\frac{3}{2}\;;\;1\;\;) = \frac{8G}{\pi}$$</p>

<p>where $G$ is the Catalan constant</p>

<p>$$G = \sum_{k=0}^{\infty}\frac{(-1)^k}{(2k+1)^2} = {}_3 F_2(\;\; \frac{1}{2},\;\frac{1}{2},\;1 \;;\;\frac{3}{2},\;\frac{3}{2}\;;\;-1\;\;)$$</p>

<p>and $Li_2$ is the <a href=""http://mathworld.wolfram.com/Dilogarithm.html"" rel=""nofollow"">dilogarithm</a>.</p>

<p>$G$ arises in my analysis of $T$, but the connection isn't clear (to me).</p>

<p><strong>Edit3:</strong> Thanks to guidance from the comments, I've expressed $T(1/2)$ in terms of the dilogarithm function. I've also given the ""${}_3F_2$"" representation of $G$. The connection between $S(1/2)$ (or $G$) and $T(1/2)$ still eludes me, but I've only begun searching through the various caches of identities that have been recommended.</p>
",combinatorics
"<p>I have the following sum
\begin{equation}
\sum_{r_1=q+1}^{\tau}\dots\sum_{r_\lambda=q+1}^{\tau}{\tau\choose r_1,\dots,r_\lambda,\tau-r_1-\dots -r_\lambda} (\Lambda-\lambda)^{\tau-r_1-\dots-r_\lambda}
\end{equation}
and would like to estimate its value. Any ideas or techniques to do this? By the way, it is not always the case that $\tau&gt;&gt;q$, so the entire range of possibilities is necessary.</p>
",combinatorics
"<p>While working on a problem in p-adic Hodge theory, and needing to write down a solution to a certain equation involving p-adic power series, I stumbled across a certain sequence of polynomials. Define $h_j(X)$ for $j \ge 0$ by $h_0(X) = 1$ and
$$ h_{j}(X) = \frac{X + 1}{j}\left(- X \frac{\mathrm{d}}{\mathrm{d}\ X} + j\right)h_{j-1}(X)$$
for $j \ge 1$.</p>

<p>I was interested in these because $h_j(X)$ is the unique polynomial of degree $j$ such that 
$$\left(\frac{t}{e^t - 1}\right)^{j+1} \cdot h_j(e^t - 1) = 1 + O(t^{j+1}),$$
and in fact it follows from the recurrence that
$$\left(\frac{t}{e^t - 1}\right)^{j+1} \cdot h_j(e^t - 1) = 1 + (-1)^j \sum_{n \ge j+1} \binom{n-1}{j} \frac{B_n t^n}{n!}$$
where $B_n$ are the usual Bernoulli numbers.</p>

<p>Now, I can't believe that these polynomials $h_j$ aren't some terribly classical well-studied thing, but they don't match any of the standard sequences of polynomials I could find on the web. Does anyone recognise these?</p>
",combinatorics
"<p>For $S_n,$ one can construct all the irreducible representations through the young diagrams. Is there any natural construction for the irreducible representation of $G\wr S_n$ (G is a finite group)?</p>
",combinatorics
"<p>Is the following conjecture true or false? (Hopefully it is true — I need it as a lemma.)</p>

<p>For every undirected graph $G=(V,E)$ there exist three <em>pairwise disjoint</em> sets of vertices $V_1,V_2,V_3$ (whose union is not necessarily $V$) such that for every $i\in\{1,2,3\}$ and for every cycle $C\in G$, $C\cap V_i\neq \emptyset$.</p>

<p>That is, each $V_i$ hits all cycles in $G$, and the $V_i$ are pairwise disjoint. </p>
",combinatorics
"<p>Many chess positions that one may easily set up on a chess board
are impossible to achieve in a game of legal moves. For example,
among the impossible situations would be:</p>

<ul>
<li>A position in which both kings are in check.</li>
<li>A position in which there are pawns on the first or on the
last rank.</li>
<li>A position with two white pawns on the same file, but black
still has all his pieces.</li>
<li>A position with a white bishop on the first rank, trapped by two
white pawns on the second rank, but the bishop is not on c1 or f1.</li>
<li>A position with two black-square white bishops and eight white pawns.</li>
</ul>

<p>The logician Raymond Smullyan wrote a delightful book <a href=""http://rads.stackoverflow.com/amzn/click/0486482014"">The Chess Mysteries of Sherlock Holmes: Fifty Tantalizing Problems of Chess Detection</a>,
containing many interesting chess detective stories, some
involving positions that were impossible for sometimes very subtle
reasons.</p>

<p>My question is:</p>

<p><strong>Question.</strong> What proportion of the chess positions that one can
set up on the board, using a legal collection of chess pieces, can
actually arise in a legal chess game?</p>

<p>What I mean is that collection of pieces is <em>legal</em>, if it occurs
in a position of a legal chess game, a game played according to
the rules. This collection is somewhat broader than one might
naively expect, since it is legally possible, for example, to have
a king of each color with nine white queens, as white may have
promoted all the pawns while all other pieces were captured. And
other similarly strange collections of pieces are possible. So the
collection of positions I am considering are those that can be
obtained by messing up the pieces on the board from an actual
legal game.</p>

<p>Of course it will be too difficult to get an exact answer, and I
shall be satisfied merely with good bounds. The <a href=""http://en.wikipedia.org/wiki/Chess#Mathematics_and_computers"">Wikipedia page on
chess and mathematics</a> mentions some numbers, including estimates on the
number of legal positions, but the information there doesn't seem
to answer this question. Perhaps those who are more familiar with
that work can point to where this question is answered there.</p>

<p>I guess the answer must be a rather small proportion, because it
seems that many legal chess positions can be easily transformed
into many illegal ones, by placing both kings in check, by adding
a pawn to the first rank (unless all pawns are already used), etc.
Is this right, and can such an argument be used to make tight
bounds?</p>

<p>I am here at the <a href=""http://www.chesscamp.net/camps/overnight_camp.htm"">Mountain Lake Chess Camp</a>, where we've been
discussing the question, when one of the instructors mentioned the
numerical bounds on the total number of chess positions, and the
question arose whether this included impossible-to-achieve
positions or not.</p>
",combinatorics
"<p>For every commutative ring $A$, let $\mathbf{Symm}_A$ be the ring of symmetric functions over $A$. Let $\mathbf{Symm}$ without a subscript denote $\mathbf{Symm}_{\mathbb{Z}}$.</p>

<p>We can define a bilinear map $\boxdot : \mathbf{Symm}_{\mathbb{Q}} \times \mathbf{Symm}_{\mathbb{Q}} \to \mathbf{Symm}_{\mathbb{Q}}$ by setting</p>

<p>$p_{\lambda} \boxdot p_{\mu} = \prod\limits_{i\geq 1,\ j\geq 1} p_{\operatorname*{lcm}\left(\lambda_i,\mu_j\right)}^{\gcd\left(\lambda_i,\mu_j\right)}$</p>

<p>for any two partitions $\lambda = \left(\lambda_1,\lambda_2,\lambda_3,...\right)$ and $\mu = \left(\mu_1,\mu_2,\mu_3,...\right)$. Here, we are writing $\boxdot$ as an infix operator (that is, $a\boxdot b$ means $\boxdot\left(a,b\right)$), and $p_\nu$ means the $\nu$-power sum symmetric function.</p>

<p>This bilinear map $\boxdot$ is associative. I call it the ""arithmetic product"", as it boils down to the <a href=""http://trac.sagemath.org/ticket/14542"">arithmetic product of species viewed through the cycle index series</a>.</p>

<p>Now, species theory can be used to show that $\boxdot$ restricts to a well-defined map $ \mathbf{Symm} \times \mathbf{Symm} \to \mathbf{Symm}$ (that is, the restriction of $\boxdot$ to $\mathbf{Symm} \times \mathbf{Symm}$ has its image in $\mathbf{Symm}$). My question is: Can this be proven more elementarily? Is there a good way to describe this map on an actual basis of $ \mathbf{Symm}$ rather than on the power-sum symmetric functions? Is there a more direct combinatorial or even representation-theoretical significance of this map?</p>

<p>(This is somewhat similar to <a href=""http://mathoverflow.net/questions/120924"">MO question #120924</a>, where another operation on $\mathbf{Symm}$ is constructed on the power sums first and then happens to be integral for weird reasons.)</p>
",combinatorics
"<p>[Metastuff: I asked this question in a slightly different way on mathSE last week, and it didn't go anywhere, which is why I am asking here. I added the DST tag because it's basically a problem about Borel equivalence relations stripped of all the Borelness constraints. I do need help, so helpful redirection is appreciated.]</p>

<p>I am trying to give a somewhat constructive definition of a function. It's somewhat constructive because I'll freely assume that I can well-order any set. Aside from that, I want to say what the function looks like.</p>

<p>I have two equivalence relations $E$ and $F$ on spaces $X$ and $Y$, respectively. There are no restrictions on the sizes of anything. I want to define a function $f : X \to Y$ such that
$$ x E y \Leftrightarrow f(x) F f(y)\;\;\;\text{ and }\;\;\;f(x) = f(y) \Rightarrow x = y $$
for all $x,y \in X$. This makes $f$ send all points in an $E$-class to the same $F$-class and also be injective on equivalence classes (i.e., injective as $X/E \to Y/F$) and on the underlying space.</p>

<p>Let $I$ be the class of nonzero cardinals. For every $i \in I$, the number of $F$-classes of size at least $i$ is greater than or equal to the number of $E$-classes of size at least $i$. I want to give a mostly-constructive proof that this is sufficient for there to be a function as described above (from $E$ to $F$), i.e., I want to describe the function.</p>

<p>I have been struggling with this on and off for several weeks. Below are some possible time-savers for you guys. If you already have a solution, you can skip it.</p>

<hr>

<p>The problem is extremely easy in the slightly nicer situation where, for every $i \in I$, the number of $F$-classes of size <strong>exactly</strong> $i$ is greater than or equal to the number of $E$-classes of size <strong>exactly</strong> $i$. Just partition the set of $E$-classes by size and put a well-order on each set in the partition. Do the same for $F$-classes. Then send the $n$th $E$-class of size $i$ to the $n$th $F$-class of size $i$.</p>

<p>The complication for the original case is that you might have to send an $E$-class of size $i$ to an $F$-class of size $j$ with $i &lt; j$. Two problems arise this way.</p>

<p>First, you can't use the larger classes wastefully by sending relatively small classes to them. E.g., if $E$ has solely two classes, one of size $2$ and one of size $5$, and $F$ has solely two classes, one of size $4$ and one of size $6$, you cannot send the class of size $2$ to the class of size $6$. The only way that I can think to avoid this problem is inductively: (i) well-order the classes in some way, (ii) send the least $E$-class to the least $F$-class that is big enough, (iii) remove these, and (iv) repeat from step (ii).</p>

<p>This creates the second problem: how to choose the well-order for step (i). If you try, e.g., to order the classes by increasing size with an arbitrary order among classes of the same size, you run into the following problem (as Brian Scott pointed out to me on mathSE a week ago). Suppose $E$ has $\omega$ many classes of size $1$ and one class of size $2$. Suppose $F$ has one class each of every finite size. Then the above won't work because $F$ has order-type $\omega$, but $E$ has order-type $\omega+1$.</p>

<p>You can fix this case with the same trick that you use to well-order the rationals. Put the $E$-classes of size $i$ into a column and well-order each column. <a href=""http://mathlesstraveled.files.wordpress.com/2007/12/rational-grid-diag-enum.png"" rel=""nofollow"">Then move along the diagonals like so.</a> But it's not clear to me what this looks like when you have any number of columns and rows rather than just countably many. </p>

<hr>

<p><strong>Edit to explain potential solution:</strong> It sounds plausible to me that sending an $E$-class to an $F$-class of the smallest available size that is large enough will avoid fatally wasteful assignments regardless of the order in which you make assignments. E.g., given an $E$-class of size $5$, if $F$-classes of sizes $4,7,$ and $9$ are available, choose one of size $7$.</p>

<p>The problem then is just how to iterate through the $E$-classes. This sounds problematic generally, but my knowledge of ordinals is weak. E.g., is there always some sense in which you can iterate through all the members of an initial ordinal?</p>

<p>Put the $E$-classes into <a href=""http://mathlesstraveled.files.wordpress.com/2007/12/rational-grid-diag-enum.png"" rel=""nofollow"">an array like this one</a> so that an $E$-class has an index <strong>(column,row)</strong>. Let the index $(s,p)$ mean that $s$ is the size of the $E$-class and $p$ is its arbitrarily-assigned position in the column. </p>

<p>Consider the case where you have at most countably many $E$-classes of each size and only countably many possible infinite sizes. That is, $p \in \omega$ and $s \in \omega \times \lbrace 0,1\rbrace$. That is, you have countably many finite sizes (tagged with $0$) and countably many infinite sizes (tagged with $1$). Then you just have two copies of the above array; one for finite sizes and one for infinite sizes. </p>

<p>Separately snake through each of them in the way depicted in the linked picture. For the array of finite sizes, this hits indices in this order: $((1,0),1), ((1,0),2), ((2,0),1), ((1,0),3), \ldots$, where the $0$ indicates that you're in the ""finite"" array. For the array of infinite sizes, this hits the indices in this (analogous) order: $((1,1),1), ((1,1),2), ((2,1),1), ((1,1),3), \ldots$. Here, $(1,1)$ denotes some infinite size such as $\omega$; $(2,1)$ might be $2^\omega$, and so on.</p>

<p>Finally, interleave the two orders that you got from snaking through each array. Most simply, you can take one member from each order at a time. This gives:
$$((1,0),1), ((1,1),1), ((1,0),2), ((1,1),2), ((2,0),1), ((2,1),1), ((1,0),3), \ldots$$</p>

<p>I apologize for the somewhat cumbersome notation, but I hope that the pattern becomes clear.</p>

<p>Incidentally, you won't necessarily have an $E$-class for all of the points in the above arrays. E.g., you might not have any $E$-classes of size $2$. I am assuming the fullest possible case for simplicity, as it still defines a well-order when you remove some of the points.</p>
",combinatorics
"<p>The following problem came from some joint research with Kevin Ford and Regis de la Breteche.  We believe a confirmation of the question presented at the end of this post will allow us to sharpen our results.</p>

<hr>

<p>We are considering families $F$ of sets which satisfy three properties.  First, each family $F$ is intersecting; that is, for all $A_1, A_2\in F$, we have that $A_1\cap A_2$ is non-empty.  Second, each family is finite, and each set in $F$ is finite as well, with the maximum cardinality of sets $A\in F$ called the size of $F$.  And third, each $F$ satisfies the following minimality condition: if $A\in F$ and $A'$ is a proper, non-empty subset of $A$, then the family of sets $F \cup {A'} \setminus {A}$ is not intersecting.</p>

<p>It can be shown quite quickly that if $F$ has size  $n$, then $|F|\le n^n$.</p>

<p>It is easy to construct a great many such families.  If one has a family $F$ of size $n$ and a set $B=\{ b_1, b_2 , \dots, b_{n+1} \}$ that does not intersect any set of $F$, then one can create a new family $F'$ that contains the set $B$ and new sets of the form $A\cup \{b_i \}$, $1\le i \le n+1$, where each $b_i$ and each set $A$ is part of at least one set of this type.  One can start from the trivial family $F=\{ \{a\}\}$ and build up many ($n$-uniform) families in this way.</p>

<p>By appending each $b_i$ to as few sets as possible, one can obtain families of size $n$ with very few total sets (as few as $n+1$).  By appending each $b_i$ to every set $A\in F$, one can obtain families of size $n$ with cardinality almost that of the maximal order $n^n$</p>

<p>Our question is, in bare form, this: suppose a family of size $n$ is very large, close to the maximal order $n^n$, then must there exist an element or subset that is extremely popular, in the sense that it is contained in many more sets than the average?</p>

<p>Put more concretely:</p>

<blockquote>
  <p>Is it true that given a family $F$ of size $n$, there exists a set $C$, with $|C|=k$ such that $$\left|\{ A \in  F:  C \subset A  \} \right| \ge \frac{|F|}{n^{o(k)}} $$ as $n \to \infty$?  If so, how good a bound can one obtain?  Would $$\frac{|F|}{100^k}$$ work?</p>
</blockquote>

<p>Our reason for believing this may be true comes from the appending construction mentioned above.  If the appending procedure is applied several times, those elements/subsets belonging to the original $F$ will be very popular in the final family obtained.</p>
",combinatorics
"<h2>BACKGROUND</h2>

<p>Assume a poset $\langle P, \le \rangle$. For two points $a,b \in P$
with $a \le b$, then $I = [a,b] = \{ x : a \le x \le b \}$ is the
interval between $a$ and $b$.</p>

<p>When $P$ is a chain (e.g. ${\mathbb Z}, {\mathbb R}$), then the $I$
are just standard intervals. Two real intervals $I=[a,b],J=[c,d]
\subseteq {\mathbb R}$ are ordered usually to mean that $I \le J$ iff
$b \le c$. Call this the ""strong order"", which isn't actually a proper
order (it needs to be ""reflexivized"" to require that $I \le I$). Two
other true orders are also available, namely that $a \le c$ and $b \le
d$ (the product order of the endpoints), or that $a \le c$ and $b \ge
d$ (subset order). These last two are conjugate orders. All of these
are defined in the context of Allen's alegbra, enumerating all the
possible relations between $I,J$ given combinations of both equal and
unequal endpoints.</p>

<p>Additionally, the intersection graphs of sets of real intervals are
interval graphs, which are well studied.</p>

<h2>MOTIVATION</h2>

<p>We work with data objects represented as finite, bounded posets.
Analyzing the intervals therein, and their orderings and
intersections, is very useful in a range of applications in layout and
display. </p>

<h2>QUESTION</h2>

<p>We are thus seeking extensions from real intervals to poset intervals
for the concepts of interval order, Allen's algebra, and inteveral
graphs. Our preliminary literature reviews haven't turned up anything,
and we're preparing to start the development from first
principles. Pointers appreciated, thanks!</p>
",combinatorics
"<p>The question is close to the <a href=""http://en.wikipedia.org/wiki/Sokoban"" rel=""nofollow"">Sokoban</a> game (thanks to Dima Pasechnik !), but a little different in details.</p>

<p>Consider a directed graph (multi-graph). Consider some set of marked chips (chip1, chipe2,..., chipM). Put chips on some set of vertices 'Init1','Init2','Init3'...
And consider some other set of  vertices 'Final1','Final2',..., 'FinalM'.</p>

<p><strong>Question</strong> Propose an ""efficient"" algorithm which will determine is it possible to ""MOVE"" chips from positions ""InitNN"" to positions 'FinalNN'.</p>

<p>Where we are allowed to ""MOVE"" chip from a vertex to an outgoing edge and from incoming edge to corresponding vertex.
With the CONSTRAINT that two chips are NOT allowed to be at the same place.
One move - moves  only ONE chip.
ChipK should go to position FinalK - same ""K"".</p>

<p><strong>Question</strong> There can be many approaches to solve the problem, I am interested
in analysis their complexity. Any ideas are welcome. For example if graph is ""random"" in certain sense what can be the algorithm the least average complexity ? </p>

<p>Where complexity is counted in number of operations (write a C-code (I actually wrote a Matlab code), compile to and calculate the number of cycles - this is well-defined complexity measure, different compilers and CPU will give approximately same result). </p>

<p><strong>Example of algorithm</strong> It seems the simplest way to solve a problem is the following.
Essentially it can be reduced to determining where two vertices are connected in some bigger graph, which in turn can be solved by ""breadth-first search"" (""wave algorithm"" in Russian) (I mean let us enumerate all
possible chip configurations - it will give vertices of the ""new graph"". Let us connect two vertices (configurations) if there is a ""MOVE"" which goes form one to another.)
By ""breadth-first search""  (""wave algorithm"" in Russian) I mean the following - take an initial vertex and find all connected to it; next step find all vertices connected to vertices found on the previous step; and so on....</p>

<p><strong>Question</strong> What about efficiency of this algorithm ? Can one propose better ?</p>
",combinatorics
"<p>Let $F_{i}$ be the fibonacci or a multinacci sequence. The number of representations of $N$ in the form
$ N=\sum_{i=0}^{k}s_{i}F_{i}, s_{i}\in ${0,1} 
is known. </p>

<p>My question is what is known about sequence-based numeration systems given by other linear recurrences. </p>

<p>To make the question precise,
i am interested in the recurrence 
$ G_{i+4}=G_{i+3}+G_{i+2}+G_{i+1}-G_{i}$
with $G_{0}=1$, $G_{1}=2$, $G_{2}=4$, $G(3)=8$. </p>

<p>What is known about
$ \sharp_{G} N:=${$(s_{0},\dots,s_{k})\in${0,1}$^{k+1}|N=\sum_{i=0}^{k}s_{i}G_{i}$}?</p>
",combinatorics
"<p>This question comes out of REU research from this past summer. Unfortunately weeks of thought led to only trivial observations and the conclusion that the problem is quite hard.</p>

<p>Fix $k,t$. Let $F$ be a set of $k$-subsets of $[n] := \{1,\ldots,n\}$ of minimal cardinality such that $F$ covers all $t$-subsets of $[n]$ (covers in the sense that any $t$-subset of $[n]$ is a subset of an element of $F$.) Let $\kappa_n := |F|$. The Erdős-Hanani conjecture states that </p>

<blockquote>
  <p>$\kappa_n = \binom{n}{t} / \binom{k}{t}(1 + o(1))$. </p>
</blockquote>

<p>Of course $\binom{n}{t} / \binom{k}{t}$ is a lower bound on $\kappa_n$, so the EH conjecture is saying that the obvious necessary condition is asymptotically sufficient. Rödl proved the EH conjecture in 1985.</p>

<p>This question is about what happens when $k$ and $t$ are not fixed. Specifically, take $k = \lfloor n/2 \rfloor$ and $t = \lfloor n/2\rfloor - 1$. Define $F$ and $\kappa_n$ as above. Is it true that</p>

<blockquote>
  <p>$\kappa_n = \frac{1}{\lfloor n / 2 \rfloor} \binom{n}{\lfloor n/2 \rfloor}(1 + o(1))$?</p>
</blockquote>

<h1>Background</h1>

<p>The EH conjecture lead to the study of what is called ""packing in a hypergraph."" See <a href=""http://en.wikipedia.org/wiki/Packing_in_a_hypergraph"">http://en.wikipedia.org/wiki/Packing_in_a_hypergraph</a>. Rödl's proof introduced what is now called the ""Rödl nibble"" and is pseudo-random in nature. Spencer gave a lovely proof using branching processes. There are a lot of results from the late 80s to 90s that say, as Kahn puts it in ""Asymptotics of Hypergraph Matching, Covering and Coloring Problems"", that hypergraphs are asymptotically well-behaved <i>as long as their edge sizes are bounded</i>! Unfortunately the $n/2$ version of EH involves hypergraphs of unbounded edge size and the existing methods appear useless.</p>

<h1>Some ideas</h1>

<p>A straightforward application of the method of alterations (or equivalently, some easy analysis of the greedy algorithm) gives that $\kappa_n \leq \log n \frac{1}{\lfloor n / 2 \rfloor} \binom{n}{\lfloor n/2 \rfloor} (1 + o(1))$, so the whole question is whether we can eliminate this log factor.</p>

<p>A set of $\lfloor n/2 \rfloor$-subsets has maximum coverage of $(\lfloor n/2 \rfloor - 1)$-subsets when all its elements have pairwise symmetric difference of at least 4. So really this is a coding theory problem. The paper ""Lower bounds for constant weight codes"" by Graham and Sloane shows that we can find a set $H$ of $\lfloor n /2\rfloor$-subsets of $[n]$ such that $|H| \geq \frac{1}{2}\binom{n}{\lfloor n/2 \rfloor}$ and the hamming distance between elements is at least 4. Let $G$ be the set of $(\lfloor n/2 \rfloor - 1)$-subsets covered by $H$. $G$ is half the size we want it to be, but we only used half as many elements are we are allowed. So we might be optimistic that by allowing some small overlap we can cover everything we want. If we take a permutation $\sigma \in S_n$ and look at $\sigma(H)$ (i.e. apply the permutation to the elements of the elements of $H$) it covers $\sigma(G)$. Of course $|\sigma(G)| = |G|$. We could hope that a good choice of $\sigma$ gives $|G \cup \sigma(G)| \approx 2|G|$ and we have found an appropriate set $F := H \cup \sigma(H)$. I asked the question of whether such a $\sigma$ must exist before: <a href=""http://mathoverflow.net/questions/101886/size-of-union-of-a-set-of-subsets-and-its-permutations"">Size of union of a set of subsets and its permutations</a>. That question is interesting in its own right, but this EH conjecture is really why I wanted an answer.</p>
",combinatorics
"<p>Is there any result about the time complexity of finding a cycle of fixed length $k$ in a general graph?
All I know is that <a href=""http://www.tau.ac.il/~nogaa/PDFS/col5.pdf"" rel=""nofollow"">Alon, Yuster and Zwick</a> use a technique called ""color-coding"",
which has a running time of $O(M(n))$, where $n$ is the number of vertices of the input graph and $M(n)$ is the time required to multiply two $n \times n$
matrices.</p>

<p>Is there any better result?</p>
",combinatorics
"<p>How many ways is there to build an arithmetic expression with fixed number of terms and fixed order? Let’s assume we have only one distinct operation that is neither commutative nor associative. The problem can be reduced to the question of how many different, full, binary trees could be constructed with a fixed number of leaves.</p>

<p>Suppose we have a list of n elements  which have to become leaves in a full, binary tree. The root could be chosen between each two sequential numbers. Thus, there is (n-1)  different ways to choose the root. If the root is located after the i-th number,  we can still construct the left child as a binary tree with i leaves and the right one with (n – i) leaves.</p>

<p>The formula for the number of different ways to construct a full, binary tree is</p>

<p>$ \Phi(n) = \sum^{n-1}_{i=1}\Phi(i).\Phi(n-i)$</p>

<p>The first value for n=1 ist set to:</p>

<p>$ \Phi(1) = 1 $</p>

<p>Is there a closed formula for this function? Is it - maybe - a popular problem in the Graph Theory with known solutions?</p>
",combinatorics
"<p>For finite trees $T_{1}$ and $T_{2}$ labelled by elements of some infinite set $S$, (we may assume that $S=\mathbb{N}$ without loss of generality), we define an equality-preserving embedding $f$ to be an embedding of $T_{1}$ into $T_{2}$ in the usual graph-theoretical sense (i.e. a homeomorphism) with the extra condition that
$l_{1}(x)=l_{1}(y)$ implies $l_{2}(f(x))=l_{2}(f(y))$ for all vertices $x,y$ of $T_{1}$ (where $l_{1}$, $l_{2}$ are the labelling function for $T_{1}$ and $T_{2}$, respectively). We say that $T_{1}$ is an equalitiy-preserving minor of $T_{2}$, written $T_{1}\prec_{ep}T_{2}$ iff there is an equality-preserving embedding $f:T_{1}\rightarrow T_{2}$. 
(Note that we do not demand that differently labelled vertices are mapped to differently labelled vertices.)</p>

<p>Is $\prec_{ep}$ a well-quasi-ordering or even a better-quasi-ordering on the set of finite trees labelled by natural numbers? (This holds, of course, by Kruskal's theorem if we replace $S$ with a finite set.)</p>

<p>Edit: Considering only well-quasi-orderings for the moment, one can also model this as follows: Given a tree $T$, we introduce for each label $c$ a new vertex $v_{c}$, join it to all vertices of $T$ that have this label and forget about the labels. That makes the question almost an instance of the graph minor theorem (stating that the finite graphs are wqo under the minor relation) but for the fact that the embeddings must map extra vertices to extra vertices and tree vertices to tree vertices. This would follow if the graph minor theorem would continue to hold for graphs coloured with finitely many (in fact merely $2$) colours.</p>
",combinatorics
"<p>When I was reading the paper:
Wang, Hao. ""Notes on a class of tiling problems."" Fundamenta Mathematicae 82.4 (1975): 295-305.
from <a href=""http://matwbn.icm.edu.pl/ksiazki/fm/fm82/fm82119.pdf"" rel=""nofollow"">http://matwbn.icm.edu.pl/ksiazki/fm/fm82/fm82119.pdf</a></p>

<p>I could not reproduce theorem 5.7:</p>

<p>Every solvable set (tilable) has a solution S such that every finite block occurring in S also occurs infinitely often in S:</p>

<p>Proof in the text: 
Given a solution T and the set K of all finite blocks occurring in T, consider the set L of all subsets of K such that a subset A of K belongs to the L if there is a solution covered by A, i.e., in that solution  all occurring finite blocks belong A. The set L is not empty because K belongs to it and it has minimal members. ...</p>

<p>Here's my problem: I could not see why the minimal member exists. There might be a sequence of A1>=A2>=A3>= ... belonging to L but their intersection does not belong to it ... I lacked a proof here... Any idea?</p>
",combinatorics
"<p>In what follows, all graphs $G$ are $K_3$-divisible (all degrees even, number of edges a multiple of three) on $n$ vertices, where $n$ is not too small.</p>

<p>The famous Nash-Williams conjecture claims that $\delta(G) \ge \frac{3}{4}n$ would be sufficient for $G$ to have a $K_3$-decomposition of its edges.  (The constant is asymptotically sharp and Gustavsson's theorem answers in the affirmative with $\frac{3}{4}$ replaced by $1-10^{-24}$.)</p>

<p>To my untrained eye, this hypothesis on minimum degree has always seemed stronger than necessary.  I am interested in weakening the hypotheses in the following direction.</p>

<blockquote>
  <p>If $\delta(G) &gt; c n$ and $|E(G)|&gt; \frac{3}{4}\binom{n}{2}$ then $G$
  has a triangle decomposition.</p>
</blockquote>

<p>(That is, if the minimum degree of $G$ is <em>not too small</em> while the <em>average</em> degree is at least what Nash-Williams demands, then we still have a $K_3$-decomposition.)</p>

<p>I can make silly counterexamples for $c \lesssim 3/28$.  Just take a $K_3$-divisible but non-$K_3$-decomposable graph on $m$ vertices which is $\lesssim 3/4$-dense and disjoint union with a clique of order $6 m+1$.  The resulting graph has $n=7m+1$ vertices, minimum degree about $3n/28$, and average density $\gtrsim (3/4+6^2)/7^2 = 3/4$.</p>

<p>Why would one want to make a hard conjecture even harder?  I suppose it is just an attempt to understand what really <em>makes</em> it hard!</p>

<p>So here comes my MO question.  <strong>Are there any obvious counterexamples to the above for</strong> $\frac{3}{28} &lt; c &lt; \frac{3}{4}$?</p>
",combinatorics
"<p>I'm trying to find out what is known about time-inhomogeneous ergodic Markov Chains where the transition matrix can vary over time. All textbooks and lecture notes I could find initially introduce Markov chains this way but then quickly restrict themselves to the time-homogeneous case where you have one transition matrix.</p>

<p>Obviously, in general such Markov chains might not converge to a unique stationary distribution, but I would be surprised if there isn't a large (sub)class of these chains where convergence is guaranteed. I'm particularly interested in theorems on the mixing time and convergence theorems that state when there exists a stationary distribution.</p>
",combinatorics
"<blockquote>
  <p>(I've asked this in <a href=""http://math.stackexchange.com/questions/1085704/is-there-a-systematic-relation-between-the-generating-functions-for-the-rows-vs"">MSE</a> but nobody had an idea since dec 14...)<br>
  <hr>
  <em>(Roughly related, but generalizing, of this <a href=""http://math.stackexchange.com/questions/569751/what-is-the-family-of-generating-functions-for-the-rows-of-this-stirling-numbe"">earlier MSE question</a>)</em>               </p>
</blockquote>

<hr>                             

<p>Background: <em>The first part of the following(the column-wise-focus) is also described in Eri Jabotinski's 1953-treatize <a href=""http://www.jstor.org/stable/2032522"" rel=""nofollow"">Representation of functions by matrices (at jstor)</a></em>             </p>

<p>Consider the matrix of Stirling numbers 2nd kind, factorially rescaled in columns and rows; let's call it $S$. I show here only the top left edge; but it is actually meant as of infinite size:     </p>

<p>$\qquad $ <img src=""http://i.stack.imgur.com/2DIy4.png"" alt=""(picture)""></p>

<p>It is well known (see for instance Abramowitz&amp;Stegun) that the generating function for the $c$'th column is $f_c(x)=(\exp(x)-1)^c $ , and for instance the leftmost column (index $c=0$) is related to $f_0(x)=(\exp(x)-1)^0 = 1 $ and the second column (index $c=1$ is related to the well known function $f_1(x)=\exp(x)-1$. So this matrix is also an example for (and in the form of) the (transposed) ""Carleman""-matrices, and in this question I'm interested in a general property of such Carleman-matrices.     </p>

<p>If I extend now that matrix by columns, for which the generating functions are accordingly $f_{-1}(x)=(\exp(x)-1)^{-1} $,$f_{-2}(x)=(\exp(x)-1)^{-2} $ and so on then I have not only to left-prepend new columns but also I must extend the matrix with prepended rows as well. The central segement of this now two-way infinite-indexed matrix, let's call it $S^*$ looks like this          </p>

<p>$ \qquad $ <img src=""http://i.stack.imgur.com/DXhwO.png"" alt=""picture"">              </p>

<p>Well, I'm having that the gf columnwise are $f_c(x)=(\exp(x)-1)^c$ with the column-index now from $-\infty$ to $ \infty$ . Matrices in this two-way-infinite form have been discussed by Eri Jabotinsky but I've not seen a discussion by him of my question so far.       </p>

<p><hr>
Now let's change our view to focus the <strong><em>rows</em></strong> instead.                    </p>

<p>I have found by pattern analyzing, that the rowwise generating functions (in this practical example) are $$g_r(t) = t/(1+t)/\log(1+t)^{r+1} $$ where I have now to replace $t =1/x$ to match the column-index for the exponents at $x$, so actually it is
$$ h_r(x)= 1/(1+x)/\log(1+1/x)^{r+1} $$
The index $r=c=0$ is at the single $1$ in the center of the image, and $r=1$ indicates the row below, which reads, form right to left, $g_1(t)=1 -1/2t+5/12t^2-3/8t^3 ...$   and is also $h_1(x)=1 -1/2/x+5/12/x^2-3/8/x^3 ...$       </p>

<p>I've also checked the similarly extended starred version of the matrix of Stirling numbers 1st kind, whose entries column-wise are generated by the functions $f_c(x)=\log(1+x)^c $.<br>
Here for the row-wise generating functions I've guessed $$g_r(t)= t \exp(t) / (\exp(t)-1)^{r+1} $$ and
$$h_r(x) = g_r(1/x) $$
(Correct me if my guess is wrong here)<br>
The relation of the guessed generating functions of the rows and of the columns is somehow striking, and even might come out simple and possibly trivial.
So my question:              </p>

<blockquote>
  <p><strong><em>Q</em></strong>: Is there any simple/memorizable rule for the relations of generating functions of the transposed Carleman matrices in comparable / general cases?<br>
  <em>(Possibly this applies only to triangular Carlemanmatrices, but I don't know that)</em></p>
</blockquote>

<hr>

<p><em>[update] A reference to a discussion of this might be sufficient; I think I've seen something like this several years ago but could not remember, where...</em> </p>
",combinatorics
"<p>What is the best lower bound in terms of $k$ on the number of edges in a $3$-uniform hypergraph that is not $k$-colorable?</p>

<p>Thanks in advance. </p>
",combinatorics
"<p>This is a follow up to an earlier <a href=""http://mathoverflow.net/questions/103364/growth-rate-of-the-infinity-norm-of-discrete-fourier-transform-of-1-1-vectors"">resolved question</a>. Define the $n$-dimensional discrete Fourier transform via the matrix
$$
D_{s,t} := \omega^{st},
$$
where $\omega=\exp(-2\pi i/n)$. Notice that $D$ is $\sqrt{n}$ times a unitary.</p>

<p>Observe that for any $x$, it holds that $\|Dx\|_\infty\geq \|x\|_2$, and in particular if $x\in\{\pm 1\}^n$, $\|Dx\|_\infty\geq \sqrt{n}$.</p>

<p>The earlier question was whether this bound is tight. The answer is a yes: there are explicit $x\in\{\pm1\}^n$ such that $\|Dx\|_\infty =\sqrt{n+1}$ when $n$ is a prime or power of two minus one.</p>

<p>Here is the follow up question. Suppose $x$ is chosen uniformly at random from $\{\pm 1\}^n$. How is $\|Dx\|_\infty$ distributed? An easy martingale Chernoff bound + union bound argument shows that</p>

<p>$$
\Pr_{x}\left[\|Dx\|_\infty \geq (\lambda +1)\sqrt{n}\right]\leq ne^{-2\lambda^2},
$$</p>

<p>which is useful when $\lambda \gg \sqrt{\log n}$ (and seems almost tight in this regime). Is it known, for instance, the probability that $\|Dx\|_\infty\leq 5\sqrt{n}$? We know that this probability is at least $2^{-n}$, but is this the correct estimate? Should it be closer to $n^c /2^n$, higher, or lower?</p>

<p>Many thanks!</p>
",combinatorics
"<p>Let's call a nice matrix a square matrix of size $n$ with elements from $\{1,...,n\}$ such that every row and every column contains all the number $1,...,n$, 
What is the number of nice matrices ? </p>

<p>a possible generalization is the following: the elements of the matrix are exactly $\{1,...,n^2\}$ and we ask that the sum of the element of the rows are equal. </p>

<p>always the question what is their number? </p>

<p>All comments are welcomed!
Thanks in advance</p>
",combinatorics
"<p>Two infinite words $\xi, \eta \in X^{\omega}$ are separated by an (Büchi-)automaton if it accepts one but not the other.</p>

<p>Denote by $F_n(\xi)$ the factors of length $n$ of an infinite word $\xi$ and also by $F_n^{\infty}(\xi)$ the factors of length $n$ that occur infinitely often. Define two equivalence relations on words:
$$
 \xi \sim_k \eta \mbox{ iff } \xi[1\ldots k] = \eta[1\ldots k] \land F_k(\xi) = F_k(\eta)
$$
and
$$
 \xi \sim_k^{\infty} \eta \mbox{ iff } \xi[1\ldots k] = \eta[1\ldots k] \land F_k^{\infty}(\xi) = F_k^{\infty}(\eta).
$$</p>

<p>Now I am interested in two questions: 1) If for two infinite words $\xi \sim_k \eta$, i.e.
their prefix and factors of length $k$ coincide, what is the size of the minimal automata separating them, and 2) if for two infinite words $\xi \sim_k^{\infty} \eta$, what is the minimum size of an automata separating them?</p>

<p>For i) I believe there is no interesting relationship, cause consider $\xi_i = 0^i 1 0^{\omega}$ and $\eta_i = (0^i1)^{\omega}$ then $\xi_i \sim_i \eta_i$ for all $i$ and they could always be separated by a two-state automata which stays in the first state as long as it read $0$'s, switches to the second state on the first $1$, and then stays there as long as just $0$'s are read, so accepting $\xi_i$ but not $\eta_i$. This lead me to consider the second equivalence relation. Here for example $\eta_i = (0^i1)^{\omega}$ and $\xi_i = 0^i100^i1000^i1\ldots$, then $\xi_i \sim^{\infty}_i \eta$ and I guess the minimal automata needed to separate them has $i+2$ states, reading $0$'s in the first state, switch to second state on first $1$, and then a loop which counts the $0$'s (need $i$ states for the loop) and goes back to the second state if $i$ $0$'s are followed by a $1$, so passing the second state an infinite number of times. This automata accepts $\eta_i$ but not $\xi_i$. </p>

<p>Are there any lower bounds on the size of an automata separating two words with $\xi \sim_k^{\infty} \eta$?</p>

<p><em>Added:</em> A finite automata accepts an infinite word according to the Büchi-condition if there is a prescribes set of states such that the infinite words enters some state of this set an infinite number of times, see <a href=""http://en.wikipedia.org/wiki/%CE%A9-automaton#Acceptance_conditions"" rel=""nofollow"">Wikipedia</a>.</p>
",combinatorics
"<p>I asked the following on MSE, but it received little attention...</p>

<p>The oriented Oberwolfach problem (with only one table) and its solution are the following.</p>

<p>In a meeting of $n$ people during $n-1$ days (combinatorists at Oberwolfach for concreteness), they all have diner around one table.
As these people only speak to their right neighbour, they want to be seated each day with a different right neighbour. For which $n$ is this possible?</p>

<p>The answer is : this is always possible unless $n=4$ or $n=6$, as stated in this other question <a href=""http://math.stackexchange.com/questions/1552096/round-robin-party-presents-or-graeco-latin-square-with-additional-cycle-proper"">http://math.stackexchange.com/questions/1552096/round-robin-party-presents-or-graeco-latin-square-with-additional-cycle-proper</a> .</p>

<p>This can be rephrased abstractly in terms of graph theory (see the answer to the question above) as follows: find  a decomposition of the directed complete graph $K_n^*$ into directed cycles all having length $n$.</p>

<p>My question is : if $n=p$ is a prime, then one can use multiplication by the $p-1$ units in $\mathbf F_p$ to build a solution.</p>

<p>However, for other values of $n$, I don't know (and I didn't find it in the papers solving the problem, although it must be in there somewhere) how to build solutions.</p>

<p>For example, can anyone explain to me how to build a solution for $n=8$ (if possible with a strategy no too <em>ad hoc</em>)?\</p>

<p><strong>Edit:</strong> I found (in the reference indicated in the comments above) a solution for $n=8$: it is :</p>

<p>$$(1, 2, 3, 4, 5, 6, 7, 8, 1) \\  (1, 3, 2, 4, 6, 5, 8, 7, 1)\\ (1, 4, 2,
5, 7, 3, 8, 6, 1)\\ (1, 5, 2, 6, 8, 3, 7, 4, 1)\\ (1, 6, 4, 7, 2, 8, 5, 3, 1)\\ (1, 7, 6,3, 5, 4, 8, 2, 1) \\ (1, 8, 4, 3, 6, 2, 7, 5, 1)$$
I don't really understand the pattern...</p>
",combinatorics
"<p>In dimension 2, the euler poincare formula restricts the incidence properties of  edges in a triangulation of a surface. 
Are there analogous generalizations for higher dimensions, like elaborations on the Schenzel formula for the specific case pf spheres?</p>
",combinatorics
"<p>Suppose we have $n$ points on a plane. Let $D$ be the sum of the squares of all the pairwise distances between the points. Let $A$ be the area of the convex hull. What is the minimum possible value of $\frac{D}{A}$ and what arrangement achieves it for specific values of $n$?</p>
",combinatorics
"<p>It is known that the binomial coefficient $2n \choose n$ is equal to number of shortest lattice paths from $(0,0)$ to $(n,n)$. The Catalan number $\frac{1}{n+1} {2n\choose n}$is equal to the number of shortest lattice paths that never go above the diagonal. Here, the diagonal may be viewed as a path from $(0,0)$ to $(n,n)$.</p>

<p>Is there a formula for the number of pairs $(P_{1},P_{2})$ where each $P_{i}$ is a shortest lattice path from $(0,0)$ to $(n,n)$ such that $P_{1}$ never goes above $P_{2}\ ?$ Here, ""$P_{1}$ never goes above $P_{2}$"" means that $P_{1}$ lies inside or on the boundary of the region determined by $P_{2}$, the $x$-axis, and the line $x=n$.</p>
",combinatorics
"<p>Can you prove that 8 is the largest cube in fibonacci sequence?</p>
",combinatorics
"<p>Given $X = \{x_1, ..., x_n\}$, how many collections $C$ of subsets of $X$ are there such that $C$ is the listing of all open balls of some metric space?</p>

<p>The first nontrivial example is $n=3$; let's call the points $x, y$ and $z$. Also, let $a = d(x, y), b = d(y, z), and c = d(z, x)$. For any collection $C$ to be a listing of all the open balls, it must contain all the singleton sets  and the whole set $X$. Let $C_0 = \{\{x\},\{y\},\{z\},X\}$. If $x, y$ and $z$ are equidistant, these are the only open balls. If, say, $a &lt; b &lt; c$, then we get $C = C_0 \cup \{\{x,y\},\{y,z\}\}$. Through careful case enumeration, we can answer this for small $n$, but the process quickly becomes unwieldy. Has anyone ever looked at this before, and is there a recursive formula or a generating function for this? What about if the points are unlabeled? For $n=3$, I count $7$ possibilities for $C$ if the points are labeled, and $3$ if the points are unlabeled. It's already somewhat time-consuming to count when $n=4$.</p>
",combinatorics
"<p>Let n be a natural number.  Let dc(n) be the number of <a href=""http://en.wikipedia.org/wiki/Composition_%28number_theory%29"" rel=""nofollow"">compositions</a> of n where the summands are required to be in the set of divisors of n.  Standard lore in analytic combinatorics yields the following formula for dc(n):</p>

<pre><code>dc(n) = nth Taylor coefficient of 1/(1- \sum_{m ∈ divisors of n} z^m)
</code></pre>

<p>But what are the asymptotics of dc(n)?  Here's a plot that I made (the y-axis is dc(n) on a log scale and the x-axis is n):</p>

<p><img src=""http://i583.photobucket.com/albums/ss275/jaspercrowne/compositiondivisors.png"" alt=""Compositions from divisors""></p>

<p>I would like to understand the ""fanning"", which presumably has something to do with whether numbers have lots of small divisors or not, and I would also like to understand why these fans seem to be so close to exponentials.  The solid fit line at the top is 2^n, which is the number of unrestricted compositions.</p>

<p>If that's too much to ask for, I guess I'd like to know how one might use known facts about the number of divisors, etc. to say something about this, as this rather artificial construction ought to be governed by some more fundamental number theoretic functions.</p>
",combinatorics
"<p>A conjecture by Chen and Chvátal asks for the minimum number of induced ""lines"" in a metric space, in the same spirit as the <a href=""https://en.wikipedia.org/wiki/De_Bruijn%E2%80%93Erd%C5%91s_theorem_(incidence_geometry)"" rel=""nofollow"">De Bruijn–Erdős theorem</a>.</p>

<p>Though the statement of this problem on Douglas West's page on <a href=""http://www.math.illinois.edu/~dwest/regs/linemetric.html"" rel=""nofollow"">the conjecture</a> asked about lines, I was wondering if any work had been done on the problem with maximal lines (which are not a proper subset of another line) but lack the resources to check. It would be easier to disprove than the original conjecture, but I was wondering if there was an easy counterexample before hitting it over the head with a computer?</p>
",combinatorics
"<p>Let $f(G)$ give number of perfect matchings of a graph $G$.</p>

<p>Denote $\mathcal N_{2n}=\{0,1,2,\dots,n!-1,n!\}$.</p>

<p>Denote collection of all $2n$ vertex balanced bipartite graph to be $\mathcal G_{2n}$.</p>

<p>There are many $m\in\mathcal N_{2n}$ that do not have a $G\in \mathcal G_{2n}$ such that $f(G)=m$ (refer <a href=""http://mathoverflow.net/questions/236713/number-of-perfect-matchings-of-bipartite-graphs"">Are all numbers from $1$ to $n!$ the number of perfect matchings of some bipartite graph?</a>).</p>

<p>How many numbers do we hit or miss in $\mathcal N_{2n}$?</p>

<blockquote>
  <p>Can $\bigg|{\big\{m\in\mathcal N_{2n}:f^{-1}(m)\cap\mathcal G_{2n}\neq\emptyset\big\}}\bigg|=O(2^{n^c})$ hold for some fixed $c\in(0,1)$?</p>
</blockquote>
",combinatorics
"<p>I'm brainstorming an idea for storing a compressed list of main class representatives of Latin squares of order $9$.  One way to compress the list would be to store one Latin square $L_1$, and for $i \geq 2$, store the Latin trade between $L_i$ and $L_{i-1}$.  We can reduce the size of the Latin trade by replacing $L_i$ by another main class representative that agrees with $L_{i-1}$ in more positions.  However, main classes of Latin squares of order $9$ usually contain $6 \times 9!^3&gt;10^{17}$ Latin squares, which is too many to look at exhaustively.</p>

<p><strong><em>Question</em></strong>: Given two Latin squares, $L$ and $M$, of order $9$, which Latin square $M'$ in the same main class as $M$ agrees with $L$ in the most cells?  How can we generate it?</p>

<p>I'm seeking an algorithmic answer (something implementable), and practical approximations would suffice.</p>
",combinatorics
"<p>If I'm not wrong, it is easy to prove the following statement :</p>

<p>If $n$ is a natural number $\leq 4$, if $\mathcal{F}$ is a union-closed family of nonempty sets, if the universe of $\mathcal{F}$ (i.e. the union of all members of $\mathcal{F}$) has exactly $n$ elements, if $\mathcal{F}$ is separating (i.e. for any two distinct elements $x, y$ in the universe of $\mathcal{F}$, there is a member of $\mathcal{F}$ that contains exactly one of $x, y$), then $\mathcal{F}$ has at least $n$ members and if it has only $n$ members, these members have a common element.</p>

<p>Is there a more general statement (for $n \geq 5$) in the literature ? Thanks in advance for the answers.</p>
",combinatorics
"<p>I just started reading about graph theory and have a question (which might be trivial). How many $(2n-1)$ edge colorings of $K_{2n}$ are there? </p>

<p>A vaguer question: can I write $K_{4n}= K_4 + K_4 +.....+K_4$ where each $K_4$ has a 3-edge coloring considered as a subgraph of $K_n$? More generally, what's a good reference for edge-colorings of complete graphs.</p>

<p>thanks</p>
",combinatorics
"<p>Given finite field $\mathbb{F}_q$, positive integers $n$ and $k&lt;n$. Given $k$-dimensional subspace $X$ of $\mathbb{F}_q^n$, for which $m=m(q,k,n)$ may we find for sure a vector in $X$ with at least $m$ non-zero coordinates?</p>
",combinatorics
"<p>I'm trying to compute an (s-t) maximum flow through a network which includes a number of arc pairs ((u,v), (v,u)) that have equal, negative capacities (weights). I'm not aware of any efficient algorithms that solve this problem directly, so I am trying to think of a way to transform the problem so that it can be passed to standard max-flow algorithms that assume all arc capacities are non-negative.</p>

<p>The only hint I could find online was a question in a 1999 homework assignment which asks students to ""Show how to reduce the problem of maximum flow with possibly negative capacities to two maximum flow problems both with nonnegative capacities.""  (The original can be seen here: <a href=""http://www.cs.cmu.edu/afs/cs/academic/class/15750-s99/www/homeworks/hw4.ps"" rel=""nofollow"">http://www.cs.cmu.edu/afs/cs/academic/class/15750-s99/www/homeworks/hw4.ps</a> )</p>

<p>How can this be done?</p>

<p>Edit #1:  I should explain the origin of these ((u,v),(v,u)) pairs. What I am really trying to do is solve an s-t maximum flow in a graph that is essentially undirected. By ""essentially undirected"" I mean a graph that is undirected except for arcs with source s and target in the undirected graph, and arcs with source in the undirected graph and target t. Of course, this kind of ""partially directed"" graph must be translated into a normal directed graph for any s-t max flow algorithm. To do this, I am applying the standard transformation of replacing every undirected edge (u&lt;->v) (with weight c) with a pair of directed arcs (u->v) and (v->u) with weight c. Since the original graph sometimes has negative edge weights, these ((u,v),(v,u)) pairs with equal negative weights arise.</p>
",combinatorics
"<p>Given a partition $\rho\in\mathcal{P}(n)$ with $k$ blocks
$$
\rho=\{B_1,B_2,\ldots,B_{k}\}
$$
we can define the set of equations
$$
E_{i}:\sum_{j \in B_{i}}{x_{j-1}}=\sum_{j \in B_{i}}{x_j}\quad\text{with}\quad i\in\{1,2,\ldots,k\}
$$
where $0\leq x_j\leq 1$ for $j=1,2,\ldots,n$.</p>

<p>The solution to these equations has $n+1-k$ free variables. We define $K_{\rho}$ as
$$
K_{\rho}=\text{volume of the solution set in $[0,1]^{n+1-k}$}.
$$</p>

<p>For instance, for the partition $\rho=\{\{1,3\},\{2,4\}\}$ the equations are $E_1=E_2: x_{1}+x_{3}=x_{2}+x_{4}$.</p>

<p>Hence,
$$
K_{\rho}=\mathrm{vol} \{(x_1,x_2,x_3)\in [0,1]^3: 0\leq x_1+x_3-x_2\leq 1\}=\frac{2}{3}.
$$</p>

<p>It can be proved that these convex polytopes have volume in $(0,1]$ and that the volume is 1 iff the partition is non-crossing. These polytopes are important for random matrix theory (moments of random Toeplitz matrices [Dembo et all], random Vandermonde matrices, etc) and combinatorics (related with the Eulerian numbers).</p>

<blockquote>
  <p>My question: is it possible to get a
  lower bound for $K_{\rho}$ in terms of
  $n$ and the number of blocks $k$?</p>
</blockquote>

<p><strong>Update:</strong>
I have the conjecture that for every $\rho\in\mathcal{P}(n)$ with $k$ blocks
$$
K_{\rho}\geq \Bigg[\frac{6(k-1)}{\pi n}\Bigg]^{\frac{k-1}{2}}
$$
and I proved it for $k=2$ and $k=3$ and arbitrary $n$.</p>
",combinatorics
"<p>So I'm trying to compute the Galois group of family of polynomials (indexed by their degree) using the technique of the Newton polygon. In order to apply this technique I need to find some good prime number $p$. </p>

<p>So this is the motivation behind my question that might seem a little bit unmotivated:</p>

<p>Let $N$ be a large integer. Then it is not too difficult to show the following statement:</p>

<p><strong>Theorem</strong>: For every prime $p$ such that $N/2&lt; p&lt; 2N/3$ one has that $p$ divides the following sum
$$
S_N:=\sum_{k=0}^N \binom{N+k}{k}2^{N-k}(-1)^k
$$</p>

<p>After many numerical examples, it always happens that most of the primes in the interval
$N/2 &lt; p &lt; 2N/3$ divide $S_N$ with multiplicity one. So here is my question:</p>

<p>Q: How would you show that there exists at least one prime $p$ in the interval $N/2 &lt; p &lt; 2N/3$ that divides exactly $S_N$, i.e., $p|S_N$ but $p^2\nmid S_N$ ,?</p>

<p>Note that the square of the product of all primes in the interval $(\frac{N}{2},\frac{2N}{3})$ is less that $\binom{2N}{N}$, so a naive counting argument does not seem to work here. </p>

<p>If you think that this problem is intractable then let me know, I'll try a different strategy. </p>
",combinatorics
"<p>Say I have polynomials $p_1,p_2,\dots,p_m$ in $\mathbb{R}^n$ (ie. over $n$ variables), each of degree $d$. Is there an upper bound on the number of ""regions"" created by the surfaces $p_i = 0$? Let's say $n$-dimensional regions, though I am ultimately interested in a bound on the number of $k$-dimensional regions for all $k$.</p>

<p>I'm hoping for something polynomial in $m$, and at most exponential in $n$ and $d$. For instance, when $d=1$, this is just an arrangement of hyperplanes, and the number of regions is bounded by $m^n$.<br>
Pointers to literature, proof ideas, etc would all be of help.</p>
",combinatorics
"<p>Let $M$ be a closed, triangulated manifold of dimension $m$ and $K(M)$ be its triangulation. Let $f_i$ denote the number of $i$-simplices of $K(M)$. As proved by Klee the face numbers satisfy the following <em>Dehn-Sommerville</em> relations
$$ f_k = \sum_{i=k}^m (-1)^{i+m} \binom{i+1}{k+1} f_i,$$
for $k = 0, 1, \dots, m$. </p>

<p>The above formula holds true for more general spaces called the <em>semi-Eulerian complexes</em> (i.e., these are simplicial complexes such that the Euler characteristic of the link of every non-empty face is equal to that of an appropriate-dimensional sphere). </p>

<p>Recall that the $h$-vector of a simplicial complex is defined as $h_i = \sum_{j=0}^i (-1)^{i-j} \binom{m-j}{m-i} f_{j-1}$ for $0\leq i\leq m+1$. 
The Dehn-Sommerville relations have a particularly beautiful expression in terms of these $h$-vectors:
$$h_{m+1-i} - h_i = (-1)^i\binom{m}{i}(\chi(M) - \chi(S^m)) $$
for $0\leq i\leq m+1$. </p>

<p>My question: Do these relations hold if one were to have a $\Delta$-complex (i.e., semi-simplicial complex) instead of simplicial triangulation of the manifold (one might have to assume the structure to be regular, i.e., attaching maps for homeomorphisms) ?</p>

<p>Is there an analogue of semi-Eulerian complex for $\Delta$-complexes ?</p>
",combinatorics
"<p>Let $u,v\in\{0,1\}^n$ be $0-1$ vectors with $n$ components.</p>

<p>Let $I=\langle u,v \rangle$. Clearly $I$ can take values in $\{0,1,\dots,n-1,n\}$.</p>

<p>How many different values can $$I'=\frac{\langle u,v \rangle}{\sqrt{\langle u,u \rangle\langle v,v \rangle}}$$ take?</p>

<p>The question is essentially, how many different angles can one make?</p>

<p>A calculation is shown here <a href=""http://math.stackexchange.com/questions/1058925/number-of-different-normalized-inner-products"">http://math.stackexchange.com/questions/1058925/number-of-different-normalized-inner-products</a> stating the number is around $cn^{2.75}$. Is there a proof for this?</p>
",combinatorics
"<p>Let $P=\{P_1,P_2\cdots P_n\}$ be a set of $n\geq 4$ points in the plane and $P_iP_j$ be the line segment connecting $P_i$ and $P_j$ that satisfy: </p>

<p>$(1)$Any three points of $P$ are not on a line;</p>

<p>$(2)$In the set $\{P_1P_2,P_2P_3,\cdots,P_{n-1}P_n,P_nP_1\}\setminus \{P_iP_{i+1}\}$,$P_iP_{i+1}$ only intersect with $P_{i-1}P_i$ and $P_{i+1}P_{i+2}$ ,$i=1,2,\cdots,n$(where $P_0=P_n,P_{n+1}=P_1$).</p>

<p>I conjecture that there must exist $1\leq i\leq n$ such that there is no point of $P$ in the interior of $\bigtriangleup P_{i-1}P_iP_{i+1}$,where $P_0=P_n,P_{n+1}=P_1$.</p>

<p>Is that right?</p>
",combinatorics
"<p>Somewhere, I  don't remember where, I saw a beautiful 3D figure of part a CAT(0) simplicial complex.  I am thinking and hoping that this was some finite piece of an affine building of type A2, presumably in characteristic 2.  But I'm very frustrated now that I just can't remember exactly what I saw or where I saw it.  It was something like part of the neighborhood of radius 1 or radius 2 of a vertex, with enough simplices removed so that the rest fits in $\mathbb{R}^3$.  It looked like Mathematica graphics, since (in my recollection) it had good colors to help show the 3-dimensional structure.  I'm thinking that I saw it in the AMS Notices, but it could also have been in an AMS calendar or elsewhere.  Does anyone remember seeing an image like this, and if so, where?</p>

<p>I'm asking because I'd like to have such an image in a paper that I'm working on, not necessarily the one that I saw but something similar.</p>

<hr>

<p>I got some good answers to my question, both here and in private e-mail to Bill Casselman.  But in the end I decided to make my own diagram (with the aid of TikZ and <s>Python</s> SAGE).  Here it is.</p>

<p><img src=""http://www.freeimagehosting.net/uploads/e38638d43e.png"" alt=""alt text""></p>

<hr>

<p>For those who are interested in the TikZ and SAGE code, I combined them into one TeX document.  I posted both <a href=""http://www.math.ucdavis.edu/~greg/a2building.tex"" rel=""nofollow"">the TeX source</a> and <a href=""http://www.math.ucdavis.edu/~greg/a2building.pdf"" rel=""nofollow"">its PDF output</a> (from pdflatex) on my web page.</p>
",combinatorics
"<p>Given a connected graph $G$, two players, Blue and Green, play the following game: initially, all vertices are unclaimed.  Players alternate turns.  On her turn, Blue adds a token to either an unclaimed vertex (turning it blue) or a blue vertex, and similarly on his turn, Green adds a token to either an unclaimed vertex (turning it green) or a green vertex.</p>

<p>If a vertex of degree $d$ ever receives $d$ tokens, it <em>topples</em>, donating one token to each of its neighbors.  This may in turn cause some of its neighbors to topple, and so on, as in the <a href=""http://en.wikipedia.org/wiki/Bak%E2%80%93Tang%E2%80%93Wiesenfeld_sandpile"">sandpile model</a>.  If Blue sets off a sequence of one or more topplings, she colors blue every vertex on which a token landed as a consequence of her move, and likewise for Green.  (Note that because the sandpile model is abelian, we don't need to specify an order of topplings.)  A player wins when she has managed to color the entire graph in her color.</p>

<p><b>Question</b>: For which graphs $G$ is this game a first-player win?</p>

<p>I would be interested in any nontrivial statements for interesting classes of graphs, e.g., for paths, trees, cycles, complete bipartite graphs, grid graphs, whatever.  The game is trivially a first-player win on a complete graph $K_n$: the first player simply plays $n - 1$ times on the same vertex, and there is nothing the second player can do.  It's also not hard to see that it's a second-player win on the graph with two edges and three vertices: the first player cannot win on her move, and following her move there is always one token on the degree-2 vertex.  The second player places a token on the unclaimed leaf vertex, which topples; there are now two tokens on the degree-2 vertex, which topples, making player 2 the winner.</p>

<p><em>Motivation</em>: This came up not in my research but rather in my relaxation -- there's a game installed on my math department Linux distribution called <a href=""http://www.kde.org/applications/games/kjumpingcube"">KJumpingCube</a>, which is precisely this game on square grid graphs.</p>

<p>One could also ask the same question for directed graphs, of course.</p>
",combinatorics
"<p>How to prove that the maximum number of mutually equidistant points in an n-dimensional Euclidean space is (n+1)?</p>
",combinatorics
"<p><b>What are the odds two uniformly chosen elements of S_n span the whole group (or just the alternating group)?</b>  Mathematica experements suggest those odds approach 1 - this might have been proven a long time ago.  How likely is it to get the alternating group or something much smaller?</p>

<p>Also, <b>how can you <em>efficiently</em> find the size of the subgroup $\langle a,b\rangle$ in S_n ?</b>  My crude tests consists of randomly multiplying the two permutations and seeing how many different elements you get.  Maybe there's a more efficient way to generate all the elements spanned by two permutation. 
<hr>
You <em>can</em> generate the whole permutation group using a swap (12) and a shift (12...n).  I wonder if all two element generating sets are conjugate to this.</p>
",combinatorics
"<p>It is well known via the RSK-correspondence that the length of the longest decreasing subsequence in a permutation $\pi \in S_n$ is the length of the longest column of the insertion tableau of $\pi$. ( The insertion tableau and the recording tableau produced by this algorithm have the same shape)</p>

<p><a href=""http://en.wikipedia.org/wiki/Robinson%25E2%2580%2593Schensted_algorithm"" rel=""nofollow"">link text</a></p>

<p>My question is what else can be gleaned from the RSK correspondence in terms of ,say,</p>

<p>a) the length of the next longest decreasing subsequence in $\pi$ ?</p>

<p>b) the number of longest decreasing subsequences in $\pi$, given the fact that there is exactly one column of maximum length ?</p>

<p>c) can we say more about the above two questions if we knew that $\pi$ was an involution? (If $\pi$ happens to be an involution, then insertion tableau and recording tableau produced are equal)</p>
",combinatorics
"<p>I have a question about an equality involving products of central binomial coefficients. If $x_1,...,x_n$ and $y_1,...,y_n$ are positive integers, with $\sum_i x_i = \sum_i y_i$ and 
$$ \binom{2x_1}{x_1} \cdots \binom{2x_n}{x_n} = \binom{2y_1}{y_1}\cdots \binom{2y_n}{y_n}\,, $$
what are the restrictions on the $x_i$ and $y_i$, and is there any solution other than the trivial one $\{x_1,...,x_n\}=\{y_1,...,y_n\}$?</p>
",combinatorics
"<p>Let $V$ be a set and $E$ a set of subsets of $V$.  I'd like to know the proper terminology for the following concept.</p>

<p>Let me call it ""generator"".  A generator is a set $F$ of subsets of $V$ such that every $e \in E$ is the union of elements of $F$.  (No intersections allowed.)</p>

<p>(One is then interested in finding properties of ""generators"" of $(V,E)$, e.g., for finite $V$, the minimum cardinality of a ""generator"" $F$.)</p>
",combinatorics
"<p>Let $M$ be a meet-semilattice with a least element $0$.  Suppose there is an order-reversing involution $a \mapsto -a$ on $M$ such that for all $a, b \in M$, $a \wedge b = 0$ if and only if $b \le -a$.  Then $M$ is a Boolean algebra.</p>

<p>Is there a paper/book I can cite for this claim?  The proof I have is just ploughing through with symbolic manipulation to show it is a distributive complemented lattice, but it's probably not something people want to read in a group theory paper.  Alternatively, does anyone know a more conceptual or slick proof?</p>
",combinatorics
"<h2>Context</h2>

<p>I'm working on a problem involving Lovasz Local Lemma, for proving that there exists a graph with a certain property.</p>

<h2>What I need to prove:</h2>

<p>There exists some constant $c$, and functions $p,a$ (which can depend on $n$) s.t.</p>

<p>$$ \frac{p^3}{a} \leq \left(1- \left[\frac{1-p}{(1-a)^n}\right]^{c^2k^2} \right)^{n^{ck}}$$</p>

<p>where $k = \sqrt{n}\log n$</p>

<h2>Why I believe it is true:</h2>

<p>Now, the RHS can be approximated as:</p>

<p>$$\exp \left( -n^{ck} \exp\left( (-p + an)c^2k^2\right) \right)$$</p>

<p>$$\exp
    \exp\left( ck( \log n + (an - p) ck)
     \right)
  $$</p>

<p>this then works if we take $p=O(n^{-1/2})$, and $a = O(n^{-3/2})$, and force the RHS to be close to 1, while the LHS to be &lt; 1.</p>

<h2>What I'm stuck on:</h2>

<p>Now, I'm stuck on the following. I'm not sure how to make this rigorous. In particular, I'm making three approximations of the form 1-x \approx e^{-x}, but on the outer $X^{n^{ck}}$ ""amplifies"" the inner errors.</p>

<h2>Question:</h2>

<p>How do I rigorize this?</p>

<p>Thanks!</p>
",combinatorics
"<p>I am trying to derive the <a href=""http://alexandria.tue.nl/repository/freearticles/597601.pdf"" rel=""nofollow"">classic paper</a> in the title only by elementary means (no generating functions, no complex analysis, no Fourier analysis) although with much less precision. In short, I ""only"" want to prove that the average height $h_n$ of a tree with $n$ nodes (that is, the maximum number of nodes from the root to a leaf) satisfies $h_n \sim \sqrt{\pi n}$.</p>

<p>The outline is as follows. Let $A_{nh}$ be the number of trees with height less than or equal to $h$ (with the convention $A_{nh} = A_{nn}$ for all $h \geqslant n$) and $B_{nh}$ the number of trees of $n$ nodes with height greater than or equal to $h+1$ (that is, $B_{nh} = A_{nn} - A_{nh}$). Then $h_n = S_n/A_{nn}$, where $S_n$ is the finite sum
$$
S_n = \sum_{h \geqslant 1} h(A_{nh} - A_{n,h-1}) = \sum_{h \geqslant 1} h(B_{n,h-1} - B_{nh}) = \sum_{h \geqslant 0} B_{nh}.
$$
It is well known that $A_{nn} = \frac{1}{n}\binom{2n-2}{n-1}$, for the set of general trees with $n$ nodes is in bijection with the set of binary trees with $n-1$ nodes, counted by the Catalan numbers.</p>

<p>Therefore, the first step is to find $B_{nh}$ and then the main term in the asymptotic expansion of $S_n$.</p>

<p>At this point the authors use analytical combinatorics (three pages) to derive
$$
B_{n+1,h-1} = \sum_{k \geqslant 1} \left[\binom{2n}{n+1-kh} - 2\binom{2n}{n-kh} + \binom{2n}{n-1-kh}\right].
$$</p>

<blockquote>
  <p>My own attempt is as follows. I consider the bijection between trees with $n$ nodes
  and monotonic paths on a square grid $(n-1) \times (n-1)$ from $(0,0)$ to $(n-1,n-1)$ which do not cross the diagonal (and are made of two kinds of steps: $\uparrow$ and $\rightarrow$). These paths are sometimes called <em>Dyck paths</em> or <em>excursions</em>. I can express now $B_{nh}$ in terms of lattice paths: it is the number of Dyck paths of length 2(n-1) and height greater than or equal to $h$. (Note: a tree of height $h$ is in bijection with a Dyck path of height $h-1$.)</p>
  
  <p>Without loss of generality, I assume that they start with $\uparrow$ (hence stay above the diagonal). For each path, I consider the first step crossing the line $y = x + h - 1$, if any. From the point above, all the way back to the origin, I change $\uparrow$ into $\rightarrow$ and vice versa (this is a <em>reflection</em> wrt the line $y=x+h$). It becomes apparent that the paths I want to count ($B_{nh}$) are in bijection with the monotonic paths from $(-h,h)$ to $(n-1,n-1)$ which avoid the boundaries $y=x+2h+1$ and $y=x-1$. (See <a href=""http://www.filedropper.com/lattice"" rel=""nofollow"">figure</a>.)</p>
</blockquote>

<p>In the classic book <em>Lattice Path Counting and Applications</em> by Mohanty (1979, page 6) the formula
$$
\sum_{k \in \mathbb{Z}} \left[\binom{m+n}{m-k(t+s)} - \binom{m+n}{n+k(t+s)+t}\right],
$$
counts the number of monotonic paths in a lattice from $(0,0)$ to $(m,n)$, which avoid the boundaries $y = x - t$ and $y = x + s$, with $t &gt; 0$ and $s &gt; 0$. (This result was first established by Russian statisticians in the 50s.) Therefore, by considering a new origin at $(-h,h)$, we satisfy the conditions of the formula: $s=1$, $t=2h+1$ and the destination point (the upper right corner) is now $(n+h-1,n-h-1)$. Then
$$
B_{nh} = \sum_{k \in \mathbb{Z}} \left[\binom{2n-2}{n+h-1-k(2h+2)} - \binom{2n-2}{n-h-1+k(2h+2) + 2h+1}\right].
$$
This can be simplified in
$$
B_{n+1,h-1} = \sum_{k \in \mathbb{Z}} \left[\binom{2n}{n+1-(2k+1)h} - \binom{2n}{n-(2k+1)h}\right],
$$
which, in turn, is equivalent to
$$
B_{n+1,h-1} = \sum_{k \geqslant 0} \left[\binom{2n}{n+1-(2k+1)h} - 2\binom{2n}{n-(2k+1)h} + \binom{2n}{n-1-(2k+1)h}\right].
$$
The difference with the expected formula is that I sum over the odd numbers ($2k+1$), instead of all positive integers ($k$). First, I hoped that the even terms would cancel out, but that does not seem to be the case.</p>

<p>Any idea where is the problem?</p>

<p>[<strong>Edit:</strong>
Starting from the expected result, by the same elementary binomial manipulations, we have
$$
B_{n,h} = A_{nn} + \sum_{k \in \mathbb{Z}}\left[\binom{2n-2}{n-k(h+1)} - \binom{2n-2}{n-1+k(h+1)}\right].
$$
But if we try to find a combinatorial interpretation to this sum in terms of bounded lattice paths, we fail: the destination point has coordinates $(n,n-2)$, which is below the inferior boundary $y = x - 1$, so the number of paths is $0$, but Mohanty's formula gives negative numbers in this kind of situation (although he does not mention this). Therefore, if we find a combinatorial interpretation for the absolute value of these numbers, we can understand the result in the same terms.]</p>

<p>[<strong>Edit:</strong> In response to a comment below, here are all the details in slow motion.
\begin{align}
B_{n,h} &amp;= \sum_{k \in \mathbb{Z}}\left[\binom{2n-2}{n-(2k+1)(h+1)} - \binom{2n-2}{n-1+(2k+1)(h+1)}\right]\cr 
B_{n+1,h-1} &amp;= \sum_{k \in \mathbb{Z}}\left[\binom{2n}{n+1-(2k+1)h} - \binom{2n}{n+(2k+1)h}\right]\cr
&amp;= \sum_{k \in \mathbb{Z}}\left[\binom{2n}{n+1-(2k+1)h} - \binom{2n}{n-(2k+1)h}\right]\cr
&amp;= \sum_{k \geqslant 0}\left[\binom{2n}{n+1-(2k+1)h} - \binom{2n}{n-(2k+1)h}\right]\cr
&amp;+ \sum_{k &gt; 0}\left[\binom{2n}{n+1+(2k-1)h} - \binom{2n}{n+(2k-1)h)}\right]\cr
&amp;= \sum_{k \geqslant 0}\left[\binom{2n}{n+1-(2k+1)h} - \binom{2n}{n-(2k+1)h}\right]\cr
&amp;+ \sum_{k \geqslant 0}\left[\binom{2n}{n+1+(2k+1)h} -\binom{2n}{n+(2k+1)h}\right]\cr
&amp;= \sum_{k \geqslant 0}\left[\binom{2n}{n+1-(2k+1)h} - \binom{2n}{n-(2k+1)h}\right]\cr
&amp;+ \sum_{k \geqslant 0}\left[\binom{2n}{n-1-(2k+1)h} -\binom{2n}{n-(2k+1)h}\right]\cr
&amp;= \sum_{k \geqslant 0}\left[\binom{2n}{n+1-(2k+1)h} - 2\binom{2n}{n-(2k+1)h} + \binom{2n}{n-1-(2k+1)h}\right].
\end{align}
]</p>
",combinatorics
"<p>Hi. Associated with a finite poset $P$, one can consider the poset $S(P)$, whose elements are the intervals of $P$, ordered by inclusion. (See <a href=""http://mathoverflow.net/questions/73640"">Discrete version of Nullstellensatz?</a> for some motivation why to look at this).</p>

<p>Does anyone know if there is an algorithm around which, given $P$, computes $S(P)$? I think it is not very difficult to come up with one, but I just want to know if it has already been implemented, say, in some computer algebra system, or studied in the literature.</p>
",combinatorics
"<p>I am trying to calculate the probability that i'll have L length sequence in a random subset of [n] when the subset size is k. for example, if n=5, k=4 and L=2 I'll have the below subsets: {2,3,4,5}, {1,3,4,5}, {1,2,4,5}, {1,2,3,5}, {1,2,3,4} and the answer will be 1/5 because there is only one subset that have L=2 suqence or for L=3 the anser will be 2/5 etc.</p>
",combinatorics
"<p>If you are given a $0$-$1$  circulant matrix with $n$ rows and $n$ columns, is there an efficient way of determining if there exists a non-zero $\{-1,0,1\}$-vector in its kernel?</p>

<hr>

<p>Could this problem in fact be NP-complete?</p>

<hr>

<p><strong>July 10 2015</strong></p>

<p>Emil Jeřábek argues in the comments that the problem is (very) unlikely to be NP-complete.  Its complexity still remains open however.</p>
",combinatorics
"<p>We call a set system $\mathcal{A}$ of subsets of the $n$ element universe $U$ a separating system if for any pair of elements $x,y \in U$ there is at least one set $A \in \mathcal{A}$ such that either ($x\in A$ and $y \notin A$) or ($x \notin A$ and $y \in A$). We call a set system completely separating if for any $x,y\in U$ both conditions hold. </p>

<p>For the sake of generalization first let us reformulate this definition. Instead of the sets consider their characteristic vectors instead. Their length is $|U|$ and they consists of zeros and ones. Now the separating system property is translated as follows: For any pair of coordinates there is at least one vector such that one coordinate is zero and the other is one. The complete separating system requires for any pair of coordinates at least one vector such that the first coordinate is zero and the second one, and at least one other vector the other way.</p>

<p>A classical question is the minimal size of a separating system on an $n$ element universe. I am interested in the literature of the following generalization of the classical question:</p>

<p>Consider vectors with coordinates $\{1,\ldots,k\}$ and a graph $G$ with vertex set $\{1,\ldots,k\}$. We would like the vectors to be a separating system with respect to coordinates $(i,j)$ if this is an edge of $G$. By being a separating system with respect to $(i,j)$ I mean that for any pair of coordinates there is at least one vector such that the first coordinate is $i$ and the second $j$ or vice versa. How many vectors do we need to satisfy all these requirements?</p>

<p>I am particularly interested in a small special case where $k=3$, and where one of the edges mean a completely separating system. But i doesn't seem to be fortunate enough to find any results of this type. </p>

<p><strong>My question is</strong>: Are there any results of this type?</p>
",combinatorics
"<h2>Problem statement</h2>

<p>Let $G=(V,E)$ be an undirected graph whose vertices are either black or white. A <em>local complementation</em> of $G$ with respect to a black vertex $v$ consists in:</p>

<ol>
<li>complementing the subgraph induced by $v$ and its neighbours,</li>
<li>flipping the colour of each neighbour of $v$ (i.e. black vertices become white and conversely), and finally</li>
<li>removing $v$ from $V$.</li>
</ol>

<p>The goal is to delete the whole graph using only local complementations.</p>

<h2>Questions</h2>

<p>Given an ordering $\mathcal O$ of the vertices of $V$, can we characterise cases in which  $\mathcal O$ allows us (or not) to delete $G$?</p>

<h2>Comments</h2>

<p>A lot of work on local complementations (or ""vertex eliminations"" in some papers) concerns itself with algorithmic issues, especially with finding orderings that will work. Note that this differs from my question, since here you don't get to choose an ordering. </p>

<p>Of course, verifying whether an ordering works is easy: keep complementing until you're done or stuck. Finding necessary or sufficient nontrivial structural conditions on $G$ or $\mathcal O$ seems harder. Does this problem ring any bell?</p>

<h2>Example</h2>

<p>Two different orderings for the same graph; the first one does not work:</p>

<p><img src=""http://homepages.ulb.ac.be/~alabarre/local-complementation-1.png""></p>

<p>The second one does:</p>

<p><img src=""http://homepages.ulb.ac.be/~alabarre/local-complementation-2.png""></p>

<h2>References</h2>

<p><a href=""http://dx.doi.org/10.1145/300515.300516"" rel=""nofollow"">Hannenhalli and Pevzner</a>, starting from page 14, and <a href=""http://dx.doi.org/10.1007/11880561_23"" rel=""nofollow"">Hartman and Verbin</a>. All other authors (e.g. <a href=""http://dx.doi.org/10.1016/0012-365X%2887%2990240-8"" rel=""nofollow"">Sabidussi</a>) consider variants like using directed graphs, or non-coloured vertices, or complementations which do not modify edges adjacent to $v$. Other authors whose papers I'm currently looking into are Donald J. Rose, Robert Endre Tarjan and François Genest.</p>
",combinatorics
"<p><em>I'm not sure if this is a soft question, or should be community wiki.</em> </p>

<p>I was explaining to a student how to prove that two sets were equal using what I called the 'oldest trick in the book': to show that $A = B$, prove $A \subseteq B$ and $B \subseteq A$. This got me thinking: what <strong>are</strong> the other ways of showing that two sets are equal. There's of course the bijection method (establish a 1-1 onto correspondence), but I couldn't think of others off the top of my head. </p>

<p>Are there many more general-ish techniques for proving two sets equal ? </p>
",combinatorics
"<p>On a simple representation of a simple Lie algebra, there is a unique bilinear form called <strong>the Shapovalov form</strong> for which the actions of $E_i$ and $F_i$ are biadjoint, and some fixed highest weight vector has $\langle v_h,v_h\rangle=1$.  </p>

<p>The representation has a distinguished collection of vectors $F_{i_1}\cdots F_{i_n}v_h$ for all sequences $\mathbf{i}$.  One can calculate any inner product $\langle F_{i_1}\cdots F_{i_n}v_h, F_{j_1}\cdots F_{j_n}v_h\rangle$, by simply moving the $F_j$'s to become $E_j$'s on the other side, and commuting them past the $F_i$'s.  This is not hard to do computationally, but the formulas one gets are not positive, which is annoying for my purposes.  </p>

<blockquote>
  <p>Does anyone know of positive formulae for these inner products?  What about their $q$-analogues for quantum groups?</p>
</blockquote>

<p><strong>EDIT:</strong>  I should note, following Allen's comment: I'm pretty sure that I know a vector space that has the dimension which is this inner product.  There's also a positivity proof using the canonical basis (all the elements I'm interested in are <em>positive</em> linear combinations of canonical basis elements).</p>

<p>I'm trying to show that a surjective map to this vector space is an isomorphism, and do so by finding a spanning set of the domain that has the right cardinality. </p>
",combinatorics
"<p>I've been playing around with numerical semigroups lately. I'm pretty new to this stuff, so I apologize in advance if my notation is non-standard. Fix positive integers $x_1,\dots,x_r$ with $\gcd(x_1,\dots,x_r) = 1$, and let  $S = \lbrace a_1x_1 + \cdots a_rx_r\mid a_1,\dots,a_r\in\mathbb{N}_0\rbrace$ be the numerical semigroup generated by the $x_i$. The <em>representation number</em> of $n\in\mathbb{N}_0$ over $S$ is given by $R_S(n) = \vert\lbrace (a_1,\dots,a_r)\in\mathbb{N}_0^r\mid n = \sum a_ix_i\rbrace\vert$. Now define $m(k) = \min\lbrace n\in\mathbb{N}\mid R_S(n)\geq k\rbrace$.</p>

<p>I am trying to show that there exists some $B \geq r-1$ so that $k^{1/B}\leq m(k)$ for all $k\in\mathbb{N}$.</p>

<p>I suspect that what I am trying to prove is elementary, and that someone else has already produced a proof, but I have not been able to find it or something similar yet. Any suggestions as to where I should look or ideas that will help me along with this proof would be greatly appreciated. </p>

<p>Thanks in advance. </p>
",combinatorics
"<p>Construct $A_k = (a_1, …, a_k)$ and $D_k = (d_1, …, d_k)$ inductively from $a_1 = d_1 = 0$, starting with $k = 1$, as follows:  let $h$ be the least integer $&gt;-a_k$ such that $h \not\in D_k$ and $a_k + h \not\in A_k$, and let $a_{k+1} = a_k + h$ and $d_{k+1} = h$.  Is every integer in $D_\infty$ and every positive integer in $A_\infty$?  If so, does this happen if $a_1$ is an arbitrary nonnegative integer and $d_1$ an arbitrary integer? </p>

<p>Example using $a_1 = d_1 = 0$:  $D_8 = (0,1,2,-1,3,4,-5,6)$ and $A_8 = (0,1,3,2,5,9,4,10)$. </p>
",combinatorics
"<p>For any natural number $N$ and $0\le n\le N$ define<br>
$$ 
f(n) = f(n,N) = \frac{1}{(N+1)!} \sum_{\substack{{S\subset \{1,\ldots,N\}} \\ {|S|=n}}} \prod_{s\in S} s. 
$$
(The empty product is interpreted as $1$.)  It is easy to see that 
$$
\sum_{n=0}^{N} f(n) = 1, 
$$ 
so that $f$ may be thought of as a probability distribution. </p>

<p>As $N$ gets large, what is the maximum value of $f(n)$?  What is the value $n_{max}$ where this peak value is attained, and 
what is the distribution of $f$, especially around $n_{max}$?   </p>
",combinatorics
"<p>It has been proved by Moon and Moser in 1965 that any finite simple graph has at most $3^{|V|/3}$ maximal cliques. Still, some hereditary classes of graphs have very few maximal cliques in comparison to the general case: for example 4-hole free odd-signable graphs have at most $|V|+2|E|$ maximal cliques.</p>

<p>Is it known a similar (not to say as tight as) upper-bound on the number of maximal cliques for other hereditary classes of graphs ? In particular, is it already known an improved (w.r.t. $3^{|V|/3}$) upper bound for perfect graphs, claw-free graphs or odd-hole free graphs ?</p>
",combinatorics
"<p>Beck-Fiala theorem states that if X is a finite set and H is any family of subsets of X, in which every vertex occurs in at most d sets of H, then there is a a function f:X->{&plusmn;1} such for every set S in H we have |sum<sub>x in S</sub> f(x)|&lt;=2d-2. In combinatorics parlance one formulates this as 'every hypergraph of maximal degree d has discrepancy at most 2d-2'. The theorem is striking since the bound on discrepancy depends only on d, but not on the sizes of X and H.</p>

<p>There were two papers that improve the bound of 2d-2. The first is due to <a href=""http://www.ams.org/mathscinet-getitem?mr=1466582"" rel=""nofollow"">Bednarchak and Helm</a>, which replaces 2d-2 by 2d-3 for d&ge;3. Their argument is short and sweet. The later improvement is due to <a href=""http://www.ams.org/mathscinet-getitem?mr=1710484"" rel=""nofollow"">Helm</a> to 2d-4. However, I have been unable to follow the paper. I also tried to contact the author, but I could not locate him. Has anyone been able to follow the paper, or at least understood the algorithm to find f well enough to explain it in pseudo-code?</p>
",combinatorics
"<p>Given real symmetric matrices $A,B\in\{0,1\}^{n\times n}$ is it true that $$AX=XB$$  has a solution of form $X$ a permutation matrix iff a solution with $XX'=I$ exists? We are over reals.</p>

<p>It is clear if there is a solution $X$ of permutation matrix form then $XX'=I$ solution exists. Is there any truth in converse statement?</p>
",combinatorics
"<p>Our human brains combine two $2$-D images we get from each of our two eyes to get one $3$-D image. Suppose there is a creature in another $4$-D world that can see in $4$-D. How many $3$-D images should the brain of such a creature receive? Generally, how many ($n-1$)-D images should a creature living in an $n$-D world receive to get at least one $n$-D image, for $n\geq 2$?</p>
",geometry
"<p>Let $C$ be a projective curve in $\mathbb{P}_2$ defined by a homogeneous polynomial $P(x, y, z)$ and let $\alpha$ be a linear transformation of $\mathbb{C}^3$. Let $Q$ be the homogeneous polynomial $Q = P \circ \alpha^{-1}$ which defines the image of $C$ under the projective transformation given by $\alpha$. Show that the matrix of second derivatives of $Q$ at a point of $\mathbb{P}_2$ represented by $v \in \mathbb{C}^3 - \{0\}$ is given by pre- and post-multiplying the matrix of second derivatives of $P$ at the point represented by $\alpha^{-1}(v)$ by the matrix of the linear transformation $\alpha^{-1}$ and its transpose, and hence that$$\mathcal{H}_P \circ \alpha^{-1} = (\text{det}\,\alpha)^2 \mathcal{H}_Q.$$Deduce that the definition of an inflection point is invariant under projective transformations.</p>

<hr>

<p>The Hessian $\mathcal{H}_P$ of $P$ is the polynomial defined by$$\mathcal{H}_P(x, y, z) = \det\begin{pmatrix} P_{xx} &amp; P_{xy} &amp; P_{xz} \\ P_{yx} &amp; P_{yy} &amp; P_{yz} \\ P_{zx} &amp; P_{zy} &amp; P_{zz} \end{pmatrix}.$$</p>
",geometry
"<p>A die with normal 4-sided polygon faces has 6 faces. 
A die with normal 5-sided polygon faces has 12 faces.</p>

<p>If a die has normal $n$-sided polygon faces, how many faces does it have?
Is there a general formula for this, and is there a rigorous proof?</p>

<p>Intuitively, if $n$ is odd, then the number of faces is $2n+2$, but I can't think of a rigorous proof for this. The hard cases seem to be when $n$ is even.</p>
",geometry
"<p>I understand what the problem with Gimbal Lock is, such that at the North Pole, all directions are south, there's no concept of east and west. But what I don't understand is why this is such an issue for navigation systems? Surely if you find you're in Gimbal Lock, you can simply move a small amount in any direction, and then all directions are right again?</p>

<p>Why does this cause such a problem for navigation?</p>
",geometry
"<p>On a two dimensional plane, line $X$ is at an angle of $x$ radians and an incoming light travels at an angle of $y$ radians. How can I calculate the angle of the outgoing light reflected off of the line $X$? How can I cover all possible cases?</p>

<p>Edit: I was trying to figure out <a href=""https://projecteuler.net/problem=144"" rel=""nofollow"">Project Euler problem 144</a>.</p>
",geometry
"<p>Let the dimension n=200 be fixed. The problem I am interested in is sampling points in n-dimensional Euclidean space uniformly from the region 
$$
\sum_{i=1}^{n} x_{i}\leq 1,
$$
     where $0\leq x_{i}\leq 1$ for all $1\leq i\leq n$.</p>

<p>One naive approach is to sample n points uniformly from the unit cube and then reject the sample if the sum is greater than 1. But this is a very inefficient approach. By simple MonteCarlo simulations I am observing that the Probability of the event $\sum_{i=1}^{n} x_{i}\leq 1$ is less than $10^{-6}$. </p>

<p>So is there any efficient way to do this sampling?</p>
",geometry
"<p><a href=""https://upload.wikimedia.org/wikipedia/commons/6/67/3D_shapes_in_isometric_projection.svg"" rel=""nofollow"">This</a> image shows a couple of different isometric projections. In the black shows the figure's ""true"" dimensions in an orthographic projection while the red shows the dimensions in an isometric projection.</p>

<p>Is there a relation between the two numbers?</p>
",geometry
"<p>$ABCD$ is a tetrahedron with position vectors of its angular points as $A(-5,22,5);B(1,2,3);C(4,3,2);D(-1,2,-3)$.Prove that the area of the triangle $AEF$ where the quadrilaterals $ABDE$ and $ABCF$ are parallelograms is $\sqrt{110}$<br></p>

<hr>

<p>For finding the area of triangle $AEF$,we need to find the coordinates of $E$ and $F$,as the coordinates of $A$ are given.As $A,B,C,D$ is a tetraheron,So $A,B,C,D$ are the points in the space ,not in the plane.
<br>I am not able to find the coordinates.<br>
Please help me.Thanks.</p>
",geometry
"<p>A tutorial sheet has the following problem.</p>

<blockquote>
  <p>Find a unit normal vector and a basis for the tangent space of the
  following smooth manifold $M \subseteq \mathbb{R}^2$ at a point $(a,b) \in M$. $$M=\{(x,y) \in \mathbb{R}^2 : x^2+y^2=1\}$$</p>
</blockquote>

<p>The idea is to do it without finding an explicit parametrization for $M$ (although of course, that is quite easy.)</p>

<p>The solution sheet says this:</p>

<blockquote>
  <p>Have $f(x,y) = x^2+y^2 = 1$ so a normal is $\nabla f = (2x,2y) = (2a,2b)$ at $(x,y) = (a,b)$.</p>
  
  <p>Tangent space = $\mathrm{ker}(Df) = (\nabla f)^\perp = \{v \in \mathbb{R}^2 : v \cdot (2a,2b) = 0\}$ has basis $\{(-b,a)\}$.</p>
</blockquote>

<p>The stuff about normals makes sense, but I don't get the line about tangent spaces. In particular:</p>

<ol>
<li>What is the difference between $Df$ and $\nabla f$? Aren't they the same?</li>
<li>How do we get from $\mathrm{ker}(Df)$ to $(\nabla f)^\perp$? What is the general principle here?</li>
</ol>
",geometry
"<p>Imagine I draw a triangle on a cartesian plane so that it has vertices at $P=(0,0), Q=(b,c), R=(a,0)$ where $b&lt;a$ and $b,a&gt;0$. As far as basic logic goes we should be able to arrange all triangles in this way. The equation of the the three lines that outline the triangle are:</p>

<p>line PR is $y=0$</p>

<p>line PQ is $y=\frac{c}{b}x$</p>

<p>Point slope form of RQ is $y-0=\frac{c-0}{b-a}(x-a)$ --> $y=\frac{c}{b-a}x+a*(\frac{c}{b-a})$</p>

<p>The altitude is a perpendicular line extending from one side to the opposite vertex.
Let PR(Q) denote the altitude extending from line PR to vertex Q.</p>

<p>PR(Q) is $x=b$</p>

<p>PQ(R) is $y-0=-\frac{b}{c}(x-a)$  --> $y=-\frac{b}{c}x+\frac{ba}{c}$</p>

<p>QR(P) is $y-0=-\frac{b-a}{c}(x-0)$ --> $y=-\frac{b-a}{c}x$</p>

<p>By definition they all must intersect at $x=b$ and yield the same y value.
Thus for every value of a,b,c </p>

<p>$\frac{b^2}{c}+\frac{ba}{c}=\frac{b-a}{c}$ must be true.</p>

<p>$b(b+a)=(b-a)$ --> $(b-1)(b+a)=0$ --> either b=1 or a=-b which does not apply to every triangle.</p>

<p>I have seen many proofs validating the concurrency of the altitudes and the existence of the orthocenter and I have no doubt that it is true. However, that would imply that I have made a mistake in my work and I have been unable to spot it. So, what did I miss? </p>
",geometry
"<p>Let's say I have n rectangles: each with their own height and width, and each with their own coordinate on a plane. </p>

<p>I can scale the width and height of the rectangles by let's say...S. How do I adjust the distances between them to make a proper zoom-in effect (so they don't overlap)? I want the distances between the objects all scaled by S ideally. </p>
",geometry
"<p>several hours ago, I saw the problem involving geometry. The problem is tell about truncated cylinder.</p>

<p>I want to know how to derive the formula of volume and its surface area without calculus, but still don't get it.</p>

<p>I've just can found the definition and the volume without proof from: </p>

<p><a href=""http://encyclopedia2.thefreedictionary.com/Truncated+Cylinder"" rel=""nofollow"">http://encyclopedia2.thefreedictionary.com/Truncated+Cylinder</a></p>

<p>Truncated cylinder is the geometric solid produced when a cylinder is cut by a plane that is not parallel to the base. </p>

<p>The volume of a truncated circular cylinder is $V = \frac{\pi r^2(h1 + h2)}{2}$, where $h1$ and $h2$ are the lengths of the longest and shortest elements of the cylinder and $r$ is the radius of the base.</p>

<p>But, there are no proof here, how can I prove this formula? And also is it possible to find the surface area for this kind of the cylinder?</p>

<p>Edit: I've just found the formula of its surface area(without proof too). Here is the link: </p>

<p><a href=""http://www.math24.net/cylinder.html"" rel=""nofollow"">http://www.math24.net/cylinder.html</a></p>

<p>But, how can I got the Area of the bases of a truncated cylinder? In this formula, the root form is appears. How can I got the root form?   </p>

<p>Thanks </p>
",geometry
"<p><em>PQRS</em> is a square. The bisector of angle SQR meets <em>PR</em> and <em>SR</em> at <em>T</em> and <em>V</em> respectively. <strong>Prove that:</strong> <code>QV*TR = QT*SV</code></p>

<p><img src=""http://i.stack.imgur.com/hBuIg.png"" alt=""enter image description here""></p>
",geometry
"<p>Take in the real plane a finitely long horizontal line segment and connect the two endpoints by a convex path, above the segment, with the property that the only extreme points of the convex hull of the resulting arch-like circuit formed by the line segment and the path are the points along the line segment part, the `baseline' so to speak.  That is, there are no linear parts of the path and it is continuous.  </p>

<p><strong>Question</strong>: Consider two such figures A and B.  I am curious about whether there is a general method for detecting an intersection between A and B, assuming I only know the coordinates of the points of A and the points of B.</p>

<hr>

<p>Motivation: My friend is working on some kind of applied physics problem about colliding `trajectories.'  He asked me essentially the same question as the one posed above.  I thought about it for about an hour and a half before convincing myself that, if there is in fact a general method, the key should maybe be to look at what happens in the vicinity of corners and maximums and then try to exhaustively outline conditions for intersection.  The cases I came up with were: </p>

<ol>
<li>A and B just touch in a single point, so that they do not trespass into each other's interior--i.e., a corner of A pricks the outside of B or the maximum of A just touches the baseline of B from below.</li>
<li>A and B just touch in a single point, with all of A except this isolated point (the point of contact) lying strictly inside B.</li>
<li>A and B coincide in two points, so that either a corner or the maximum of A lies inside B.</li>
<li>A and B coincide in three points, whereby a `tail' of A lies in the interior of B, but the rest of A passes out of B.</li>
<li>A and B coincide in four points--A essentially squeezes through B.</li>
<li>A and B coincide in five points; similar to case 5 but the maximum of A also coincides with the maximum of B.</li>
<li>A and B coincide in a point and a common subset of each other's baselines by lying on the same horizontal and having their tails overlap.</li>
<li>A and B coincide in all points. </li>
</ol>

<p>But actually if one looks closely, I am pretty sure that all of the cases except the fifth one can be covered entirely by checking if either a corner or the maximum of A occurs on or inside the boundary of B.  So actually the problem should be reduced to checking two cases:</p>

<ol>
<li>Either a corner or the maximum of A occurs on or inside the boundary of B.</li>
<li>Neither the corner nor the maximum of A occurs on or inside the boundary of B.</li>
</ol>

<p>My idea is to run the following algorithm.  First for both A and B set aside the following special points: their left corners, their right corners, and their maximums.  Start with A and pick some $z$ out of its special points.  Retrieve, if they exist, the unique points $p_1$ and $p_2$ of B that have the same vertical coordinates as $z$ does and similarly retrieve the points $q_1$ and $q_2$ of B that have the same horizontal coordinates as $z$ does.  Compare them: If either $p_1$ or $p_2$ is identical to $q_1$ or $q_2$, then you know that the figures coincide in a special point of A, which handles cases 1, 3, 6, and 8; If the horizontal coordinate of $z$ is between those of $p_1$ and $p_2$ and if the vertical coordinate of $z$ is between those of $q_1$ and $q_2$, then you know that $z$ lies in the interior of B or somewhere on its baseline, handling cases 2, 4, and 7 (technically, these pairs of points are not well-defined in the seventh case because $p_1 = p_2 = z$ for instance, but you can just directly inspect for overlapping baselines by checking to see if the corners of A and B have the same vertical coordinates and if one of the corners of A (B) lies in between B's (A's) corners).  However, I don't quite know how to test case 5--I thought there should be some checkable necessary and sufficient condition having to do with maximums, but it seems hard to do.  Presumably, you'd cycle through the five remaining special points if none of the above checks out.  </p>

<p><strong>Some follow-up questions are</strong>: Are my cases exhaustive?  If so, how do I check for case 5 and is there a way to do it in terms of my special points?  If my intuition is correct here, how do you formally argue for it?</p>

<p>All that I am doing in the above algorithm is just taking orthogonal projections onto horizontals and verticals, which is sensible from an intuitive geometric standpoint, since I am looking for instances of A and B crossing into each other.  I did some research later on and discovered that my thinking makes a great deal of contact with the idea of the separation theorem for convex polygons and that my algorithm seems in fact to be almost a direct application of that theorem.  (After all, you could just treat the figures under consideration as the limiting case, right?) </p>

<p><strong>Added</strong>: Actually, I think I was seeing ghosts and it should be pretty simple to handle the fifth case--all you have to do is check to see if the baseline of A lies between the baseline of B and the maximum of B.</p>
",geometry
"<p>Let the three sides of a triangle be $a,b$ and $c$. If the equation </p>

<blockquote>
  <p>$$a^2+b^2+c^2=ab +bc+ac$$</p>
</blockquote>

<p>holds true, then the triangle is an equilateral triangle.</p>

<p>How do we prove this? An answer or even the slightest hint will be appreciated.</p>
",geometry
"<p>I'm storing hyper-regions as vectors in an SQL table like so:</p>

<pre><code>region1: D1, D1', D2, D2', D3, D3'...DN, DN'
region2: D1, D1', D2, D2', D3, D3'...DN, DN'
</code></pre>

<p>It's relatively easy to find regions that are non-intersecting, or entirely overlap. (<code>select from regions where D1 &gt; foo, D2 &lt; bar</code>, etc). How can I determine the volume of intersection, in SQL, between two regions?</p>

<p>In three dimensions the calculation would look something like the following:</p>

<pre><code>r1: X:0, X':2, Y:0, Y':2, Z:0, Z':2
r2: X:1, X':3, Y:1, Y':3, Z:0, Z':2

SELECT (mathmagic)
</code></pre>

<p>result: 2 (I have defined 2 cubes, <code>2x2x2</code>, but the second cube is shifted 1 unit on both x and y axes, so the overlap is a 2x1 area)</p>

<p>Edit: A general formula would be fine too, doesn't have to be in SQL.</p>
",geometry
"<p>I have searched but could not find the exact question.</p>

<p>Two circles with radii 5 intersect such that the center of one circle lies on the circumference of another. What is the area of the overlapping region in terms of pi?</p>
",geometry
"<p>Let $E$ be a Euclidean space, and let $X, Y\subseteq E$ be two disjoint subsets.</p>

<p>Suppose that there exist isometries $i$ and $j$ such that $i(X)\cap j(Y)=\emptyset$ and $i(X)\cup j(Y)=X\cup Y$. Does it follow that there's an isometry fixing $X\cup Y$, mapping $X$ to $i(X)$ and mapping $Y$ to $j(Y)$? (Hints and pointers welcome too.)</p>
",geometry
"<blockquote>
  <p>In parallelogram $ABCD$, angle $A$ is acute, point $E$ is on the $AD$ such that $BE$ is perpendicular to $AD$ and point $F$ is on line $CD$ such that $BF$ is perpendicular to $CD$. If $AB=BF=13$ and $AE=5$, compute the length of $EF$.</p>
</blockquote>

<p>I drew the diagram, all I can do is to get the length of $BE$ by Pythagorean theorem, I'm learning geometry (sophomore), does this question require knowledge about calculus or trig?  Can anyone help me with it?</p>

<p>This question is from senior A division contest.</p>
",geometry
"<p>Two circles of equal radius intersect at points C and D.The centres of the two circles are points A and B respectively.If their radius is 10 units,the area of triangle ABC is 40,then how do we find the distance between A and B?</p>
",geometry
"<p>Let $A\subset\mathbb{R}^N\setminus\{0\}$ be a closed symmetric set ($x\in A$ then $-x\in A$). Suppose that $A$ is homeomorphic to some sphere $S^n$, $n\leq N$ ($n$ is the dimension of the sphere). Is it possible to construct a homeomorphism $F:A\to S^n$ such that $F$ is odd?</p>

<p>Update: this problem was solved <a href=""http://mathoverflow.net/questions/152099/constructing-a-odd-homeomorphism-between-a-and-sn"">here</a>.</p>
",geometry
"<p>If each side of a regular polygon of $n$ sides subtend an angle $\alpha$ at the center of the polygon and each exterior angle of the polygon is $\beta$,then prove that $\cos \alpha+\cos(\alpha+\beta)+\cos(\alpha+2\beta)+.....+\cos(\alpha+(n-1)\beta)=0 $<br></p>

<p>Since this is a regular polygon.Therefore,each $\alpha=\frac{2\pi}{n}$ and since each external angle is $\beta$.So by geometry,$\alpha=\beta.$<br></p>

<p>$\cos \alpha+\cos(\alpha+\beta)+\cos(\alpha+2\beta)+.....+\cos(\alpha+(n-1)\beta)=\frac{\cos\frac{n\beta}{2}}{\cos\frac{\beta}{2}}\cos\frac{2\alpha+(n-1)\beta}{2}$<br></p>

<p>Now putting $\alpha=\beta=\frac{2\pi}{n}$ does not give me answer.What mistake did i make?</p>
",geometry
"<p>I have a piece of steel, cylindrical (hollow), <code>200mm</code> outside diameter with <code>160mm</code> inside diameter (<code>20mm</code> wall thickness), and I need to screw a bolt through the outside of the cylinder towards the center.</p>

<p>I chose a <code>6mm</code> thick bolt, which requires a <code>12mm</code> washer (outside diameter).</p>

<p>This means I need to use a flat sander (or similar, maybe a dremmel) to shave off some of the outside of the cylinder, to make a flat plane for the washer to sit on, aiming for <code>12mm</code> wide.</p>

<p>This will reduce the wall thickness slightly, and I need to calculate how much the wall thickness will shrink by, in order to make sure the bolt isn't slightly too long for the part I'm connecting it to on the inside of the cylinder.<br>
(I might try sanding the bolt down by this amount, or find another mechanical solution - I haven't decided yet.)</p>

<p>I started drawing out a rough diagram to help me visualize and see if any of my past algebra/trig knowledge would help (I'm usually pretty good with basic trig), but since there's also a circle involved I got lost pretty quick.<br>
Is calculus needed to approximate the change in wall thickness?<br>
How should I go about finding this value?</p>
",geometry
"<p>I had some troubles with this problem :</p>

<blockquote>
  <p>Let $ABCD$ be a convex quadrilateral. $M$ and $N$ are the midpoints of
  the diagonals $AC$ and $BD$. The sides $AB$ and $CD$ are extended
  until they intersect. The intersection point is $E$. The sides $AD$
  and $BC$ are extended until they intersect. The intersection point is
  $F$. Let $P$ be the midpoint of the segment $[EF]$. Prove that $M$, $N$, $P$ are 
  collinear.</p>
</blockquote>

<p>First, I found that a quadrilateral in which the opposite sides interesect is also known as a <em>complete quadrilateral</em>.
Then, the line $M-N-P$ is known as <em>Newton-Gauss line</em> and the problem above as <em>Newton's Problem</em>.</p>

<p>I've taught about solving it using areas. I've used the property that <em>median divides the triangle in two echivalent triangles (with the same area)</em>. Many properties can be derived from it.</p>

<p>I haven't figure out, but I'm interested in a proof using areas. I would appreciate some suggestions.</p>

<p>Thanks!</p>
",geometry
"<p>Given the semimajor axis and a flattening factor, is it possible to calculate the semiminor axis?</p>
",geometry
"<p>What length of rope should be used to tie a cow to an <strong>exterior fence post</strong> of a <em>circular</em> field so that the cow can only graze half of the grass within that field?</p>

<p><em><strong>updated:</em></strong> To be clear: the cow should be tied to a post on the exterior of the field, not a post at the center of the field. </p>
",geometry
"<p>Given two points around an origin $(0,0)$ in $2D$ space, how would you calculate an angle from $p_1$ to $p_2$?</p>

<p>How would this change in $3D$ space?</p>
",geometry
"<p>This year I will be teaching 8 hard-working home-educated teens a Geometry course.   Back in 1994-1999 I worked full time as a High School educator, taking a turn teaching everything from Pre Algebra through Basic Calculus, and Geometry was (and still is) my favorite.   I am wanting to buy (at abebooks or some such place) a stack of student books and a teacher's edition.  Recommendations?    In some ways the recent editions may be better.   In other ways . . .  not so much.  I recall being aghast as a teacher at how ""dumbed down"" the texts had become just in the few years between my being a high school student and a high school teacher.  And that was 20 years ago.  If you have a specific publisher and year (Prentice Hall 1989, as a random example) that you enjoyed using as a teacher, I'd love to hear your comments.</p>
",geometry
"<p>$ABC$ is a triangle, $D$ is a point on the side $BC$ of  $\triangle ABC$, $R_b$ is circumradius of $\triangle ABD$ , and $R_c$ is the  circumradius of $\triangle ACD$. 
Prove that 
$$ {Rb\over Rc} ={AB\over AC}$$
Thanks for your help</p>
",geometry
"<p>Find the equation of the plane tangent to the surface:
$$x^{\frac{1}{3}}+y^{\frac{1}{3}}+z^{\frac{1}{3}}=1$$ at the point:
$$P=\left(1,-1,1\right)$$
How to find it? I know i have to calculate a gradient which is:
$$\left(\frac{1}{3}x^{-\frac{2}{3}}, \frac{1}{3}y^{-\frac{2}{3}}, \frac{1}{3}z^{-\frac{2}{3}} \right)$$ but what should i do next? I think i need to substitute point into the gradient but how to substitute this point if i have $-1$ under the root?</p>
",geometry
"<p>I have a square that's $10\mathrm{m} \times 10\mathrm{m}$. I want to cut it in half so that I have a square with half the area. But if I cut it from top to bottom or left to right, I don't get a square, I get a rectangle!  </p>

<p>I know the area of the small square is supposed to be $50$, so I can use my calculator to find out how long a side should be: it's $7.07106781$. But my teacher said I should be able to do this without a calculator. How am I supposed to get that number by hand?</p>
",geometry
"<p>I learned that the volume of a sphere is $\frac{4}{3}\pi r^3$, but why? The $\pi$ kind of makes sense because its round like a circle, and the $r^3$ because it's 3-D, but $\frac{4}{3}$ is so random! How could somebody guess something like this for the formula?</p>
",geometry
"<p>Let both ends of a string of length $L$ be tied to a stick of length $S$. Among all plane regions enclosed by this contraption, it achieves maximum when the string forms a circular arc.</p>

<p>It is noted that if $S=0$, this theorem is reduced to the isoperimetric theorem, which states, for the length $L$ of a closed curve and the area $A$ of the planar region that it encloses, </p>

<p>$4\pi A \le L^2$,</p>

<p>and that equality holds if and only if the curve is a circle.</p>

<p>Your comments and ideas are greatly appreciated!</p>
",geometry
"<p>What mathematical ideas can be used to define the highest point on a planet (for example, the top of Mt Everest for Earth)?  If we think of the planet as a solid, one idea is that the highest point is the point farthest from the centroid. However, this method would give strange answers for Earth because of the fact that the Earth looks more like an ellipsoid that is bigger in the east-west direction than in the north-south direction than it does like a sphere.  Is the idea of a ""sea level"" important?</p>
",geometry
"<p>Does a surface such that any two different triangles on it are not congruent exist?</p>

<p><strong>Added</strong>:Suppose that surfaces are defined by some continuous function:$R^2\rightarrow R$ and a triangle is a set of three non collinear points connected by three geodesics.</p>
",geometry
"<p>what is minimum number of points in affine plane,</p>

<p>By the way: Here are the $\textbf{Three Axioms}$ for affine plane.</p>

<ol>
<li><p>Given two distinct points $\textbf{P}$ and $\textbf{Q}$, there is only one line  passing through them</p></li>
<li><p>Given a point $\textbf{P}$ and a line $\textit{l}$, if $\textbf{P}\not\in\textit{l}$,
there is only one line passing through point $\textbf{P}$ and parallel to line $\textit{l}$</p></li>
<li><p>There exist three points $\textbf{P}$, $\textbf{Q}$, $\textbf{R}$ non-collinear</p></li>
</ol>
",geometry
"<p>Let $A = (x_A, y_A)$ and $B = (x_B, y_B)$. Let $\gamma$ be a circumference of radius $r$, centered in $(0, 0)$; $A$ and $B$ lie outside of $\gamma$, and on the same side of some line $L$ through the center of $\gamma$.</p>

<blockquote>
  <p>Make tangents from $A$ and $B$ to $\gamma$. These tangents intersect in a point $C$, on the same side. What are the coordinates of $C$?</p>
</blockquote>

<p><img src=""http://i.stack.imgur.com/kCgRf.png"" alt=""enter image description here""><br>
<em>In green, you can see the tangents from $A$ and from $B$, which intersect in $C$.</em></p>

<p>I could find a solution by finding the equation of each tangent, and then finding their intersections. However, such a solution involves manipulating quite a few parametric polynomials, which takes a long time and is rather inelegant. Is there a simpler solution relying upon geometrical theorems?</p>
",geometry
"<p>Let's presume I have two vectors $V_1$ and $V_2$. As far as I understand normal to a vector is all vectors lying on a plane perpendicular to it. What I need is a normal to $V_1$ that lies on a plane formed by $V_1$ and $V_2$.</p>

<p><a href=""http://i.stack.imgur.com/Q7j3a.png"" rel=""nofollow"">Example</a></p>
",geometry
"<p>Below is a visual proof (!) that $32.5 = 31.5$. How could that be?</p>

<p><img src=""http://farm1.static.flickr.com/48/152036443_ca28c8d2a1_o.png"" alt=""alt text""></p>
",geometry
"<p><strong>Background:</strong> Many (if not all) of the transformation matrices used in $3D$ computer graphics are $4\times 4$, including the three values for $x$, $y$ and $z$, plus an additional term which usually has a value of $1$.</p>

<p>Given the extra computing effort required to multiply $4\times 4$ matrices instead of $3\times 3$ matrices, there must be a substantial benefit to including that extra fourth term, even though $3\times 3$ matrices <em>should</em> (?) be sufficient to describe points and transformations in 3D space.</p>

<p><strong>Question:</strong> Why is the inclusion of a fourth term beneficial? I can guess that it makes the computations easier in some manner, but I would really like to know <em>why</em> that is the case.</p>
",geometry
"<p>I would like to find an equation that I can put into excel to calculate the coordinates for the center of the circle. </p>

<p>Given</p>

<p>$P_1\equiv (a=33855.05, b=21129.55)$</p>

<p>$P_2\equiv (c=33745.04, d=21221.69)$</p>

<p>$\text{Radius}= 590$</p>

<p>I know that the center lies on the perpendicular bisector between the two points, but don't know how to calculate it.  What I have so far:</p>

<p>I calculated the Midpoint ($M$) of the chord<br>
$M \equiv(e, f) \equiv\left(\frac{a+c}{2}, \frac{b+d}{2}\right) \equiv (e=338855.05, f= 21175.62)$</p>

<p>I also know the slope
$m = \frac{b-d}{c-a} = 0.838$</p>

<p>So how do I find the coordinates of center? I am aware that there will be two possible answers. </p>
",geometry
"<p>The $\mathbf{A}$ be an $n\times n$ full rank matrix. Then, the (signed) volume enclosed by the rows (or columns) of $\mathbf{A}$ is equal to $\det(\mathbf{A})$. My question is, what is a geometric interpretation of $\det(\mathbf{A}^{-1})$? What would be the parallelotope defined by $\mathbf{A}^{-1}$ and in which way is it related to the parallelotope defined by $\mathbf{A}$?</p>
",geometry
"<blockquote>
  <p>Find point $E$ on $CD$ of parallelogram $ABCD$ such that $\angle AEB  = \angle BEC$</p>
</blockquote>

<p>Shape is supposed to look something like this. 
<a href=""http://i.stack.imgur.com/SQ0f6.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/SQ0f6.png"" alt=""enter image description here""></a></p>
",geometry
"<p>I was thinking about Jordan curve with infinite length and Koch snowflake seems to be a valid answer intutively. Can anyone give mathematical proof for this?</p>
",geometry
"<p>The convex hull is defined as the smallest convex set containing a set of points. Now we want to generalize it to a set of balls. If these balls have the same radius, then it can be shown that a ball lies on the boundary of the convex hull of balls if and only if its center lies on the boundary of the convex hull of center.</p>

<p>My question is: what about the case when the balls have different radii? Can we solve it in $O(n\log n)$ time, when there are $n$ balls? The correspondence between the convex hull of centers and the convex hull of balls seem to disappear, thus giving me the difficulty.</p>

<p>Remark: This is taken from an exercise in Chapter 1 of ""<em>Computational Geometry: Algorithms and Applications</em>"" by <em>Mark de Berg</em> et al.</p>
",geometry
"<p>Let $ABC$ be an acute-angled triangle in which $\hat{ABC}$ is the largest angle. Let $O$ be its circumcenter. The perpendicular bisectors of $BC$ and $AB$ meet $AC$ at $X$ and $Y$ respectively. The internal bisectors of $\hat{AXB}$ and $\hat{BYC}$ meet $AB$ and $BC$ at $D$ and $E$ respectively. How do I prove that $BO$ is perpendicular to $AC$ if $DE$ is parallel to $AC$.</p>
",geometry
"<blockquote>
  <p>A  tetrahedron $A-BCD$,and let $$S_{ABC}=a,S_{ACD}=b,S_{ABD}=c,S_{BCD}=d$$
  and such
  $$d^2=a^2+b^2+c^2$$</p>
</blockquote>

<p><strong>show that:
then tetrahedron $A-BCD$ is Trirectangular Tetrahedron.</strong></p>

<p><img src=""http://i.stack.imgur.com/Fa034.jpg"" alt=""enter image description here""></p>

<p><strong>I know this reslut,if $A-BCD$ is Trirectangular Tetrahedron.then we have
$$d^2=a^2+b^2+c^2$$
and I can prove this. But the inverse problem,I can't see it,and can't prove it.I hope someone can know? Thank you</strong></p>
",geometry
"<p>I think that's intuitively evident but I can't prove that the set $\mathbb{S}^n\setminus\{(0,\cdots, 1),(0,\cdots, -1)\}\; (n&gt;1)$ is path connected. Does anyone have a formal argument to prove it?</p>

<p>Thanks</p>
",geometry
"<p>I'm trying to rotate a point around a single axis of a 3D system.</p>

<p>Given $P=\begin{pmatrix}
101 \\
102 \\
103
\end{pmatrix}
$,</p>

<p>And the rotation matrix <a href=""http://en.wikipedia.org/wiki/Rotation_matrix#In_three_dimensions"">formula</a> for rotation around the X axis only, I get:</p>

<p>$Rx(\psi=90^\circ)=
\begin{pmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; -1 \\
0 &amp; 1 &amp; 0
\end{pmatrix}$</p>

<p>The rotation yields 
$Rx*P =\begin{pmatrix}101 \\ -103 \\ 102\end{pmatrix}$</p>

<p>...but I expected a 90 degree rotation around $x$ would mirror the $y$ coordinate, yielding $\begin{pmatrix}101 \\ -102 \\ 103\end{pmatrix}$. By now I'm utterly confused by the various rotation conventions, and I'd be grateful for any help in clearing up where I went wrong with this simple operation.</p>

<p>Thanks!</p>
",geometry
"<p>I need to do some calculations in order to do this drawing (sorry for the quick sketch):</p>

<p><a href=""http://i.stack.imgur.com/ByJ3E.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/ByJ3E.jpg"" alt=""enter image description here""></a></p>

<p>I need to define a set of variables and do simple calculations as much as possible in order to come up with the above sketch given that:</p>

<p>N: is the number of smaller circles, previously defined and always known</p>

<p>Separation angle SA: is the angle that should be between two circles must be calculated so the circles never intersect </p>

<p>Group Angle GA : the angle each little circle (group) should have when distributed around the bigger circle</p>

<p>R: is the radius  of bigger circle which can be defined to make the calculation easier </p>

<p>r: is the radius of smaller Circle  </p>

<p>How can I define or calculate the angles and the smaller radius so the N number of circles will never intersect  </p>

<p>Thank you</p>

<p><strong>An Update</strong> 
Here is what Ive don so far, again that I posting the equations in a programing form Iam a bit in a hurry</p>

<pre><code>//assume  sepration angle  = 1/3 group angle for simplness , I have no idea why I did this 
    var groupAngle = 360 / (noGroups * 1.333);
    var sepAngle = (1 / 3) * groupAngle;
    //mathmatical relation  
    var groupRadius = Math.sin((groupAngle * Math.PI / 180) / 2) *R;
</code></pre>

<p>after I assumed the above I used the angles to find the center for each circle then draw it - I used sin and cos to find the center relative to the canvas I have which wasn't a problem - however the problem is which I know from the start that I should define R in away the circles will never get out of the rectangle you notice the cut out circles but for not to make things more complicated than they already r I decide R should be some how little bit less than the height of the rectangle <a href=""http://i.stack.imgur.com/22tDP.png"" rel=""nofollow"">result image</a>
Now to solve this problem I decided after the calculation and before centering my circles I will reduce the R to R-r this way all circles are shifted inside since eventually I will delete the bigger circles and have the other circles aligned correctly - I cant post another picture -</p>

<p>what remains here that If you keep reducing N, r gets larger to some how it miss up the whole drawing I need to restrict r to another value  </p>
",geometry
"<p>I am having trouble understanding the concept. Usually when I calculate the center of mass of an object when given area and dimensions I'd multiply corresponding distances with areas etc then divide-by the total are (Given that we're using a 2D shape).</p>

<p>However when I come to this question for example:
<img src=""http://i.stack.imgur.com/vp4hh.png"" alt=""enter image description here""></p>

<p>I worked out the following: $(3*6^{2})-({\pi*3^{2}\over 2})(6-{4\over \pi})$ which is meant to give the center of mass, but I was under the assumption you must divide by the total area as per usual?</p>

<p>May someone explain to me why this isn't the case?</p>
",geometry
"<p>I came across the following geometry problem. </p>

<blockquote>
  <p>In the exterior of a triangle $ABC$ three equilateral triangles $ABC' , BCA'$ and $CAB'$ are constructed. Prove that the centroids of these triangles are the vertices of an equilateral triangle.</p>
</blockquote>

<p>The book presents a proof using complex numbers which is fairly elementary.</p>

<p>What intrigues me is that the author leaves a note: ""The reader who wants a 'proof without words' should examine the diagram""</p>

<p>Diagram attatched below, can someone show me <em>how</em> this proves anything at all?</p>

<p><img src=""http://i.stack.imgur.com/3nDsT.png"" alt=""enter image description here""></p>
",geometry
"<p><a href=""http://i.stack.imgur.com/9Q6Cy.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/9Q6Cy.jpg"" alt=""enter image description here""></a></p>

<p>I see this post and I am stunned. I think this is fallacious but I can't figure where is the fallacy?</p>

<p>If you know the fallacy. Please post a answer.</p>
",geometry
"<p>The sphere is </p>

<p>$x^2 + y^2 + z^2 = 81$</p>

<p>and the point is $(5,6,9)$</p>

<p>I am using Langrane multipliers , but the answers I am getting are so far off. I will post my system of equations soon. </p>

<p>I found the gradient of $F: (2(x-5), 2 (y-6), 2(z-9))$<br>
Gradient of $G: (2x, 2y, 2z)$</p>

<p>$2x-10 = 2 \lambda x$<br>
$2y-12 = 2 \lambda y$<br>
$2z-18 = 2 \lambda z$<br>
$x^2+y^2+z^2 = 81$</p>

<p>This system seems very challenging to solve.</p>
",geometry
"<p>$A$ and $B$ are two points on the circumference of a circle center $O$. $C$ is a point on the major arc $AB$. Draw the lines $AC$, $BC$, $AO$, $BO$, and $CO$, extending the last line to a point $D$ inside the sector $AOB$. Prove that $\angle AOD$ is twice $\angle ACO$ and that $\angle BOD$ is twice angle $\angle BCO$. Hence show that the angle subtended by the minor arc $AB$ at the centre of the circle is twice the angle that it subtends at the circumference of the circle.</p>
",geometry
"<p>My purpose is to find the surface area of a torus defined by the equation : $$(\sqrt{x^2+y^2}-a)^2+z^2=r^2$$
where $a,r$ are parameters such that the torus is non degenerated. </p>

<p>First I know a mean of calculating its surface : with the parametrization :$$\phi : (u,v) \mapsto ((a+r \cos u) \cos v ,(a+r \cos u) \sin v,r \sin u)$$ :</p>

<p>Then : $$Area= \int _{torus} dp = \int _{u,v \in ]0,2 \pi[} \|\phi _u (u,v) \times \phi _v (u,v)\| dudv = 4 \pi ^2 ar$$</p>

<p>My question is :</p>

<blockquote>
  <p>How can I calculate this area without the parametrisation of the surface, just with the equation (and without using the rotating symetry) ? </p>
</blockquote>

<p>Thanks in advance.</p>
",geometry
"<p>My friend gave me this 3D math problem to solve, and I have absolutely no idea on how to solve it! I don't even know where to start. I don't think I have the mental capacity to solve, nor the experience! =P</p>

<p>Secretly, I don't think it's possible, but you never know with fancy math problems like these.</p>

<p>Imagine an arbitrary function $f(x,y)$ in 3D space. Now, go along the surface and place markers in a grid-like fashion.</p>

<ul>
<li>If the markers were infinitely close, write a general formula for the ratio of the density of these markers given $2$ points (think like how derivatives generalized slope to a single point)</li>
<li>Then find the formula for a unit sphere centered at the origin with the first point at the origin. Write it as a function $g(x, y)$</li>
</ul>

<p>Anything helps! I haven't learned 3D geometry yet, so I am really lost.</p>
",geometry
"<p>So the problem is that there is one circle with radius of five and one circle with radius of 1. There centers are 8 units apart and there is a pulley belt that goes around the outside as shown in the image. It is given that the belt touches 2/3 of the edge of the larger circle and 1/3 of the edge of the smaller circle. The goal is to find the total length of the belt. I know that the belt is $(2/3)10\pi + (1/3)2\pi + 2$ (distance between the points of tangency on the circles). However, I am unable to come up with that last component. I thought of using triangles, but I can't assume that there are $90^\circ$ angles when I draw the triangles. Help would be appreciated
<img src=""http://i.stack.imgur.com/O7ME9.png"" alt=""enter image description here""></p>
",geometry
"<p>Suppose we have a n-cube and we subdivide it into smaller n-cubes (by adding vertices and faces) in such a manner that the intersection of two cubes is either a face of both cubes or empty. First, is there a way to triangulate each one of the smaller cubes using only that cube's vertices (we are not allowed to add any vertices) in such a manner that the intersection of two n-simplices is either a face of both simplices or empty? Second, if this is possible would we consider such triangulations of all of the smaller cubes to be a triangulation of the larger cube (again, the intersection of two n-simplices is either a face of both simplices or empty?) </p>

<p>I assume the answer to my first question is yes and the answer to my second question is no, meaning that not every kind of triangulation of all the smaller cubes would lead to a triangulation of the large cube. However, I also assume that if we can find a triangulation for the smaller cubes that works and we use that same triangulation for every small cube (all of the smaller cubes are exactly the same) then we will achieve a triangulation of the larger cube (this might not be true if the faces of a small cube don't end up looking the same (similar) after the triangulation), meaning that orientation matters.    </p>

<p>Thanks for your help.              </p>
",geometry
"<p>I am doing an ottoman in wood. The shape is a truncated cylinder. What I need is to be able to cut the wall in thin wood to wrap it around the truncated cylinder.
I know it can be made from a semi circumference but I haven't been able to find a formula to do so. I am attaching an sketch of what I want to do. <a href=""http://i.stack.imgur.com/m4n9B.jpg"" rel=""nofollow"">Current Truncated Cylinder</a> . I found this <a href=""http://i.stack.imgur.com/nD8ew.png"" rel=""nofollow"">diagram</a> but the formula does not work.
Any help will be really appreciated.</p>

<p>Thanks,</p>
",geometry
"<p>I am currently trying to implement a 3D convex hull algorithm that is based on the paper <a href=""http://dl.acm.org/citation.cfm?id=359430"" rel=""nofollow"">Convex Hulls of Finite Sets of Points in Two and Three Dimensions</a> by F.P. Preparata and S.J. Hong, but I’ve run into some trouble understanding the “gift wrapping principle”. </p>

<p>So on page 91 of the paper (pg 5 of the pdf, last paragraph of 1st column) there is this passage: </p>

<blockquote>
  <p>The gift wrapping principle works as follows: Let <em>C</em> be a polyhedron with <em>n</em> vertices. Assuming a face <em>f</em> of <em>C</em> is given, select an edge of <em>f</em>. This edge and every vertex of <em>C</em> determine a plane; a new face of <em>C</em> belongs to the plane forming with <em>f</em> the largest convex angle. </p>
</blockquote>

<p>Now this passage doesn’t make much sense to me and I was hoping someone out there could help me understand it. First, I always thought that in order to determine a plane you need two points in the plane and a normal vector with that plane. I’m assuming the two points in the plane come from the edge but how can any vertex be normal to a plane containing the points. Maybe I’m just not visualizing this correctly, but it doesn’t seem like that would work. Also the last sentence about a convex angle doesn’t really make sense either as of right now. </p>

<p>Any help with this would be appreciated</p>
",geometry
"<p>I've tried to proof <em>Menelaus' theorem</em> using areas, but I've didn't figure out how. Some suggestions would be appreciated. </p>

<p>Menelaus' Theorem states :</p>

<blockquote>
  <p><a href=""http://i.stack.imgur.com/WwsS5.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/WwsS5.png"" alt=""enter image description here""></a></p>
  
  <p>Given a triangle ABC and a  transversal line that crosses BC, AC and
  AB at points D, E and F respectively, with D, E and F distinct from A,
  B and C, then :</p>
  
  <p>$$\frac{AF}{FB} * \frac{BD}{DC} * \frac{CE}{EA} = 1 $$</p>
</blockquote>

<p>So far, I've proved Van Aubel's and Ceva's Theorem using areas, but I got stuck at Menelaus.</p>

<p>First, I taught $\frac{[ACB]}{[BCF]} = \frac {AB}{BF}$. And I've applied this for few more triangles, but it didn't work.</p>

<p>(I've noted with $[ABC]$ the area of triangle ABC).</p>

<p>Thanks! </p>
",geometry
"<p>Puzzle: Divide a regular hexagon into 12 identical non-convex hexagons.  </p>

<p>I found this at <a href=""http://www.jaapsch.net/tilings/"" rel=""nofollow"">Jaap Scherphuis' Tiling Applet</a>, and it looks new to me.  Are there any solutions other than the one answer there?</p>
",geometry
"<p>We know that equal chords are equidistant from the center.
However, I was curious if the lengths involved are proportional as well since the circle is a pretty symmetrical shape. Here's what I mean: </p>

<p>Let there be two chords,C1 and C2, in a circle at distances D1 and D2 from the center. Will  L1 and L2 be proportional to the distances D1 and D2?  </p>

<p>Is   $  \frac{L1}{L2} = \frac{D1}{D2} $ true?     </p>
",geometry
"<p>In $\Delta ABC, $ $O$ is the circumcentre and $H$ is the orthocentre. Then prove that $AH^2 +BC^2 =4AO^2.$</p>

<p>I am unable to solve this problem. Any help will be appreciated. </p>
",geometry
"<p>How do I prove that 5 points lie on the same circle?
I know about the theorem that opposite angles in a quadrilateral are supplementary, but how does that help me prove that 5 points lie on the same circle?
Can I break apart the irregular pentagon into two quadrilaterals to show it?</p>
",geometry
"<p>I know the definitions of sides and angles in standard geometry (i.e. perpendicular, parallel, adjacent, etc), but I need help defining them in terms of points. Given the following two examples, what different terms define points B in relation to point A?</p>

<h1>1</h1>

<pre><code>  B
B A B
  B
</code></pre>

<h1>2</h1>

<pre><code>B   B
  A
B   B
</code></pre>
",geometry
"<p>From a geometrically intuitive point of view, it is obvious that if two <strong>injective</strong> $C^1$ curves $\gamma,\delta$ with values in $\mathbb R^n$ have the same images, then their lengths $\ell(\gamma)$ and $\ell(\delta)$ (as defined by the standard definition from differential geometry) are equal. This is a well-known resulut if $\gamma$ and $\delta$ are reparametrizations of one another; however, they need not necessarily be. Can it still be proved without this assumption?</p>
",geometry
"<p>In the given figure, $PQRS$ is a parallelogram. $PQ$ is produced to $L$ so that $QL=PQ$. The line $SL$ cuts $QR$ at $O$. Prove that: $\triangle PQS=2\triangle ROL$.
<a href=""http://i.stack.imgur.com/Ph1pr.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/Ph1pr.jpg"" alt=""enter image description here""></a></p>

<p>Attempt </p>

<p>$$PL=LQ$$
$$ Q \ \text{is the mid point of} \ PC$$
$$\triangle POQ=\triangle QOL$$</p>

<p>Now what should I do next?</p>
",geometry
"<p>This is something that bothered me in my lectures on analytics geometry (because it was given without proof). I can see that $\langle (x,0),(0,y) \rangle=0$ easily, but what about when these two vectors are rotated? I believe I've been able to prove it for $2$-dimensions:</p>

<p>$$\langle A,B \rangle=\langle (|A|\cos\theta ,|A| \sin \theta ),(|B|\cos\psi ,|B| \sin \psi)\rangle\\ = |A||B|cos \theta \cos \psi+|A||B|\cos \theta \cos \psi\\=|A||B|(\cos\theta \cos\psi+ \sin \theta \sin \psi)\\=|A||B|\cos (\theta - \psi)$$</p>

<p>Now $\cos( \theta - \psi) =0$ exactly when $ \theta - \psi=n\pi  +\cfrac{\pi}{2}, n\in \Bbb{Z}$. That is <em>basically</em>, when the difference of the two angles is $\cfrac{\pi}{2},\cfrac{3\pi}{2}$.</p>
",geometry
"<blockquote>
  <p>How many triangles with positive area can be drawn on the coordinate
  plane such that the vertices have integer coordinates $(x,y)$ satisfying
  $1≤x≤3$ and $1≤y≤3$?</p>
</blockquote>

<p>It is easy that we have  nine possible ways to connect the coordinated to make  triangles. But  is there any easy way to get the number of co-nonlinear points? </p>

<p>If you draw for me, it be be really a big help </p>
",geometry
"<p>I'm writing a routine to judge if an angle $\varphi$ in a plane lies in the smaller of the two angles formed by two other rays at angles $\varphi_1$ and $\varphi_2$. The angles <em>aren't</em> bounded in $\left[0,2\pi\right)$.</p>

<p>The usual convention is followed: the $0$ angle lies on the positive half of $x$ axis, and increasing angle goes counter-clockwise. In the diagram $\varphi$ lies in the convex angle while $\varphi'$ doesn't.</p>

<p><a href=""http://i.stack.imgur.com/IeChZ.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/IeChZ.png"" alt=""An illustration""></a></p>

<p>I'm thinking that since $\varphi$ is ""<em>between</em>"" $\varphi_1$ and $\varphi_2$, this relation has to hold
$$\sin(\varphi-\varphi_1)\sin(\varphi_2-\varphi)&gt;0, \tag{1}$$</p>

<p>because the two sine values have the same sign. However, some angles in the concave side (the bigger angle) can also satisfy this by forming two obtuse angles, so (1) isn't good.</p>

<p>I would appreciate your ideas on a sound and simple mathematical method.</p>
",geometry
"<p>I am struggling to understand an equation given in an academic paper (in atmospheric sciences/geography) that I am reading. The paper defines a line, called the Clear Line, which is derived through linear regression of a number of points. They state that</p>

<blockquote>
  <p>the transformation that quantifies the perpendicular displacement of a point from this line with be given by: $d = x \sin \theta - y \cos \theta$, where $\theta$ is the slope angle of the line.</p>
</blockquote>

<p>I understand this to mean that the given equation should tell me the perpendicular distance from the point to the line. I have two problems: I can't see how this works, and it gives me different answers to other formulae that I do understand.</p>

<p>The diagram below shows a point (A) and two lines, $y = x$ and $y = x + 6$. Obviously the distance from the point (the dotted line) should be longer for $y = x + 6$ than it should be for $y = x$, but the formula given in the paper gives the same result for both. Of course this is the case, as the formula takes into account three of the four variables involved (gradient of the line and x and y locations of the point, but not the y-intercept of the line).</p>

<p><img src=""http://i.stack.imgur.com/Ophgm.png"" alt=""enter image description here""></p>

<p>So, I have two questions:</p>

<ol>
<li><p>Am I correct in stating that the formula given in the paper does <strong>not</strong> calculate the distance from the point to the line.</p></li>
<li><p>Given that it doesn't do that - what does it do? I assume it does something relevant (either that or the paper is completely wrong!) - but I can't seem to work out what it does by using trigonometry, constructing various triangles, and trying to understand where the equation came from - but I can't work it out!. It does seem to produce an answer that is vageuly related to the direction (if we just look at lines of different gradients - ignoring the intercepts - it seems to give a result which is related to the distance from the line).</p></li>
</ol>

<p>Any ideas would be much appreciated!</p>
",geometry
"<p>A circle passes through the point 3,$\sqrt{\frac{7}{2}}$ and touches the line pair $x^2-y^2-2x+1=0$. The co-ordinates of the centre of the circle are:-</p>

<hr>

<p><strong>My attempt:-</strong>
Using quadratic formula to separate the line pair into two lines.
$$x^2-y^2-2x+1=0$$
$$x=\frac{-(-2) \pm \sqrt{2^2-4(1-y^2)(1)}}{(2)(1)}$$
$$x=1\pm y$$
So we have two lines x-y-1=0 and x+y-1=0.I don't know that to do next?</p>
",geometry
"<p>The following is just a rough version of the question, which is made more clear below:</p>

<blockquote>
  <p>How can it be proven/disproven that the fastest route for a racecar making a quarter-circle turn is the route given by a section of a bigger circle that intersects the outer part of the track at the start and end of the turn and intersects the inner part of the track halfway through the turn?</p>
</blockquote>

<p>In the figure below, I have drawn a circle of radius $R$ so that it intersects 1) a circle with radius $r_2$ at points that are $\frac{\pi}{2}$ radians apart in the circle defined by $r_2$, and 2) a smaller circle of radius $r_1$ inscribed in the one with radius $r_2$. The figure should make it clear. </p>

<p>I have calculated $R$ to be 
$$R=\frac{r_1^2+r_2^2-\sqrt{2}r_1r_2}{2r_1-\sqrt{2}r_2}$$
which makes sense since $R\rightarrow \infty$ as $r_1 \rightarrow \frac{\sqrt{2}}{2}r_2$, in which case you can draw a straight line.</p>

<p>Now, the length of the arc drawn out by the bigger circle from one point of intersection to the other is given as $\theta R$, where
$$\theta = 2\arctan\left(\left(2\left(\frac{R}{r_2}\right)^2-1\right)^{-1/2}\right)$$</p>

<p>Now returning to the question: We assume that the speed at which the racecar is going at any point in the turn is proportional to $\sqrt{r}$, where $r$ is the radius of turning at that point (i.e. the curvature at that point is $1/r$). </p>

<blockquote>
  <p>For a track with constant width $r_2-r_1$ (with $\frac{\sqrt{2}}{2}r_2&lt;r_1&lt;r_2$), is the route through a quarter-circle turn that minimizes the time spent in said turn given by a section of a circle with length $\theta R$ (as seen in the figure)?</p>
</blockquote>

<p>The reason I think it is given by $\theta R$ is based purely on intuition.</p>

<p>I guess the problem will most easily be solved using calculus of variations, as it is somewhat similar to the Brachistochrone problem (with the added constraint of the width of the track), but I don't know how to attack it. </p>

<p>Thanks!</p>

<p><a href=""http://i.stack.imgur.com/aw6TH.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/aw6TH.png"" alt=""enter image description here""></a></p>

<p><strong>EDIT 1:</strong> <a href=""http://math.stackexchange.com/questions/444289/shortest-path-and-minimum-curvature-path-implementation"">This question</a> addresses the more general question of finding the optimal route around a track, but has an algorithmic approach instead. If someone coincidentally has a script with such an $A*$ algorithm at hand, they could test it on a quarter-circle turn and see whether or not the route of least curvature follows the arc of a bigger circle?</p>

<p><strong>EDIT 2:</strong> As <em>Jens</em> has suggested in the comments, some kind of speed limit should be introduced. I think it is sufficient to demand that the function given by the speed of the car should be differentiable (after all, infinite acceleration isn't very realistic).</p>
",geometry
"<p>I keep looking at this picture and its driving me crazy. How can the smaller circle travel the same distance when its circumference is less than the entire wheel? </p>

<p><img src=""http://mathworld.wolfram.com/images/gifs/AristotlesWheel.gif"" alt=""demonstration image""></p>
",geometry
"<p>I have tried a lot to prove this well-known result. The basic idea behind the proof is clear to me. But I'm stuck at showing either of the following conditions:</p>

<ol>
<li>The map $\ G \rightarrow TG \ $ given by  $ \ g \mapsto (L_{g})_{*}(e)(v_{e})  \ $ is smooth.</li>
<li><p>$\ D\star(g,e)(0_{g},-):T_{e}(G) \rightarrow T_{g}(G)\ $ is vector space isomorphism.</p>

<p>Where G is the Lie group, e is the identity element  and star is the multiplication operation. There is already an available solution in stackexchage but the solution is not correct completely. So it'll be very helpful if someone provides details. I'm completely stuck at showing smoothness of the map using charts. Please help.  </p></li>
</ol>
",geometry
"<p><strong>Question:</strong></p>

<blockquote>
  <p>three circles $K_{1},K_{2},K_{3}$ are tangent to each other,(Circles $K_{1}$ and $K_{2}$ are externally tangent at a point $T$),Denote by $L_{1}$ is the exterior common tangent of the circles $K_{1},K_{2}$,meets $K_{3}$ in $P,Q$,and Denote by $L_{2}$ is the common tangent at $T$ meet $K_{3}$ in $B$.</p>
</blockquote>

<p>show that:</p>

<blockquote>
  <p>$$\angle PK_{3}B=\angle BK_{3}Q$$</p>
</blockquote>

<p><img src=""http://i.stack.imgur.com/Yl1b0.jpg"" alt=""enter image description here""></p>

<p>maybe this is famous thereom?  if someone have see it?can you link .Thank you</p>
",geometry
"<p>I've been reading about tropical geometry and many papers reference polyhedral fans. I feel like I have a decent intuitive picture of what they are from reading articles but I still haven't been able to guess the general definition. All the ones I've encountered have been systems of linear inequalities, so that is my best guess at a general definition.</p>

<p>Any comments on where they appeared first historically or links/books to general resources on learning about them would be appreciated. Also, I'm curious to know what other areas of math these show up in?</p>
",geometry
"<p>Knowing that the acute angles of the trapezoid are $60^\circ$ and $45^\circ$ and the difference of the squares of base lenghts is equal to 100, calculate the area of this trapezoid.</p>

<p>Here's my solution: Let a be the shorter and b the longer base. By drawing two lines from the ends of a perpendicular to b, we form two right triangles. One of them has angles $45^\circ-45^\circ-90^\circ$ and the second is $60^\circ-30^\circ-90^\circ$. Using the properties of these triangles, we can see that the side of the first triangle lying on b is equal to h=height (both lie between 45 and 90) and the side of the latter which is lying on b is equal to $\frac{h\sqrt{3}}3$. Then, $b-a=h+\frac{h\sqrt{3}}3$ so $h=\frac{3(b-a)}{3+\sqrt{3}}=(b-a)(1-\frac{\sqrt{3}}{3})$. We just plug it into the initial equation and we get that the total area is $50(1-\frac{\sqrt{3}}{3})$.</p>

<p>And that's the problem. From what I read on the page I got this problem from, the result should be $25(3-\sqrt{3})$. Why is that so? What's wrong in my solution?</p>
",geometry
"<p><a href=""http://i.stack.imgur.com/cUKIq.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/cUKIq.png"" alt=""enter image description here""></a></p>

<p>What is the area of the square versus a,b and c ?
Thanks</p>

<p><strong>Edit to clarify the question, based on the OP's response to comments.</strong></p>

<p>The segments with lengths $a$ and $c$ are parallel, joined by $b$ perpendicular to both. What is the side of the square as a function of $a$, $b$ and $c$?
they are just some known arbitrary length of 3 segments drawn inside a square as a and c are parallel and b normal to them.</p>
",geometry
"<p>Given in figure 4, there are 5 parallel lines intersected by 4 other parallel lines. How many unique parallelograms are there in figure 4?<img src=""http://i.stack.imgur.com/jLAAU.jpg"" alt=""enter image description here""></p>

<p>Answer: 60. When two pairs of parallel lines intersect, one parallelogram forms -> number of parallelograms are </p>

<p>vector(4, 2) * vector(5, 2) = 6 * 10 = 60</p>

<p>I'm confused on how the 6 and 10 appeared. I thought dot notation would dictate that the answer be 24? Unless, I am completely mistaken and the two were not written as vectors. Any help would be greatly appreciated!</p>
",geometry
"<p>Just today, I was making tortilla chips, and I began to wonder, what is the most efficient way to pack circular quarters onto the plane?</p>

<p><a href=""http://i.stack.imgur.com/mXnzy.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/mXnzy.png"" alt=""enter image description here""></a></p>

<p>This sort of circle packing is most efficient for circles, but what if quarter circles are used instead of whole circles, is it still this method?</p>

<p>Does anyone have an answer for this? What is the most efficient way to pack quarter circles onto the plane?</p>
",geometry
"<p>Normally I would just divide both sides by the number $4$ because it's not good in there, but I can't do it for </p>

<p>$$4x^2+y^2=1$$</p>

<p>I must have $$\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$$</p>

<p>So what's the easiest way?</p>
",geometry
"<p>I found in a book of <a href=""http://en.wikipedia.org/wiki/Sangaku"">Sangakus</a> the following problem.</p>

<p><img src=""http://i.stack.imgur.com/bSYaL.png"" alt=""Three Circles""></p>

<p>Let $R_b$, $R_g$ and $R_r$ the radiuses of the blue, green and red circles $C_b$, $C_g$ and $C_r$.</p>

<p>Prove that
$$\frac{1}{\sqrt{R_r}}=\frac{1}{\sqrt{R_b}}+\frac{1}{\sqrt{R_g}}\,.\quad (1)$$
And this I can do. But then</p>

<p><strong>I would like to draw the figure myself with only a ruler and a compass.</strong></p>

<p>I know it is possible as I can construct inverses, sums and square roots with only a ruler and a compass, but when I tried to draw the figure with a ""simple"" or ""natural"" construction, I failed.</p>

<p>Does someone have an idea of how to draw it ""naturally""?</p>

<hr>

<p><em>EDIT</em></p>

<p>Answer to a comment of Amzoti:
To prove Relation (1) I first prove the relation:
$$AB^2=4R_gR_b\quad (2)$$
<img src=""http://i.stack.imgur.com/NlmgG.png"" alt=""Two Circles"">
Relation (2) is a consequence of Pythagoras' theorem in the triangle $O_bO_gH$:
$$AB^2+(R_g-R_b)^2=(R_b+R_g)^2\,.$$
(It was the previous Sengaku in the book.)</p>

<p>We thus get the relations
$$
\begin{align}
AB^2 &amp; =4R_gR_b\quad (2) \\
AC^2 &amp; =4R_gR_r\quad (3) \\
BC^2 &amp; =4R_bR_r\quad (4) \\
\end{align}
$$
where $A$, $B$, $C$ are the orthogonal projections of the centers of the circles $C_b$, $C_g$ and $C_r$ on the line $d$. The relation $AB^2=AC^2+BC^2+2AC.BC$ then yields, using Relations (2) to (4),
$$4R_gR_b=4R_gR_r+4R_bR_r+8\sqrt{R_bR_g}R_r$$
Divided by $4R_rR_gR_b$ this equation is
$$\frac{1}{R_r}=\Big(\frac{\sqrt{R_g}+\sqrt{R_b}}{\sqrt{R_bR_g}}\Big)^2$$
which is in fact Relation (1) squared.</p>
",geometry
"<p>Given the coordinates of a point $(x, y)$, what is a procedure for determining if it lies within a polygon whose vertices are $(x_1, y_1), (x_2, y_2), \ldots , (x_n,y_n)$?</p>
",geometry
"<p>Inside an equilateral triangle $ABC$,an arbitrary point $P$ is taken from which the perpendiculars $PD,PE$ and $PF$ are dropped onto the sides $BC,CA$ and $AB$,respectively.Show that the ratio $\dfrac{PD+PE+PF}{BD+CE+AF}$ does not depend upon the choice of the point $P$ and find its value.  </p>

<p>I have no idea how to proceed. I could not do anything beyond calculating the area of $PDB,PCE,PFA$ but here I get nothing. Please help!</p>
",geometry
"<p>Please Help</p>

<p>A circle is drawn such that it intersects all three sides of $\triangle PQR$ as shown below. Prove that if $AB = CD = EF$, then the center of the circle is the incenter of $\triangle PQR$.</p>

<p><img src=""http://i.stack.imgur.com/4FyCR.png"" alt=""Diagram""></p>
",geometry
"<p>Let the point $I$ in tetrahedron $ABCD$. Find $\min\{IA + IB + IC + ID\}$.</p>

<p>I can't solve this problem, even in the case ABCD regular. Please help</p>
",geometry
"<p>Can anyone tell me a way to calculate area of a triangle given the equations of its 3 sides without sketching or finding the points of intersection?  </p>
",geometry
"<p>I have a cube made using CSS transforms that I'm trying to animate rotating about an axis going through 2 opposite vertices.</p>

<p><strong>What I have:</strong></p>

<p>Initial cube:</p>

<pre><code>   /* Animation start */
   rotateX(0deg) rotateY(0deg) rotateZ(0deg);
   /* Animation end */
   rotateX(0deg) rotateY(0deg) rotateZ(0deg);
</code></pre>

<p><img src=""http://i.imgur.com/G31bduO.gif"" alt=""http://i.imgur.com/G31bduO.gif""></p>

<p>Rotated cube:</p>

<pre><code>   /* Animation start */
   rotateX(-45deg) rotateY(45deg) rotateZ(0deg);
   /* Animation end */
   rotateX(-45deg) rotateY(45deg) rotateZ(0deg);
</code></pre>

<p><img src=""http://i.imgur.com/nzOtrJu.gif"" alt=""http://i.imgur.com/nzOtrJu.gif""></p>

<p>Rotating X:</p>

<pre><code>   /* Animation start */
   rotateX(-45deg) rotateY(45deg) rotateZ(0deg);
   /* Animation end */
   rotateX(315deg) rotateY(45deg) rotateZ(0deg);
</code></pre>

<p><img src=""http://i.imgur.com/VSoYx5w.gif"" alt=""http://i.imgur.com/VSoYx5w.gif""></p>

<p>Rotating Y:</p>

<pre><code>   /* Animation start */
   rotateX(-45deg) rotateY(45deg) rotateZ(0deg);
   /* Animation end */
   rotateX(-45deg) rotateY(405deg) rotateZ(0deg);
</code></pre>

<p><img src=""http://i.imgur.com/lpVTHai.gif"" alt=""http://i.imgur.com/lpVTHai.gif""></p>

<p>Rotating Z:</p>

<pre><code>   /* Animation start */
   rotateX(-45deg) rotateY(45deg) rotateZ(0deg);
   /* Animation end */
   rotateX(-45deg) rotateY(45deg) rotateZ(360deg);
</code></pre>

<p><img src=""http://i.imgur.com/G85yQfK.gif"" alt=""http://i.imgur.com/G85yQfK.gif""></p>

<p><strong>What I want:</strong></p>

<p><img src=""http://i.stack.imgur.com/jQN3Y.gif"" alt=""http://i.stack.imgur.com/jQN3Y.gif""></p>

<p>I'm not a programmer or a mathematician, and I've tried looking this up on <a href=""http://en.wikipedia.org/wiki/Rotation_matrix#Rotation_matrix_from_axis_and_angle"" rel=""nofollow"">Wikipedia</a> and through past answers, but both get into some heavy matrix-transformation stuff and technical jargon  that goes over my head. I'm just trying to figure out the right numbers to plug in for the X, Y, and Z axes to achieve a ""sideways"" rotation.</p>

<p>Thanks for any help!</p>

<p><strong>Edit</strong>: I just noticed this, but I think CSS3's <code>rotateX</code> isn't behaving the way it should. Both <code>rotateY</code> and <code>rotateZ</code> act relative to the object - using its axes for rotations even when those axes have been rotated - but <code>rotateX</code> seems to always rotate relative to the viewport, no matter how much I try to stop it from doing that! This is evident even in the above pictures - <code>rotateY</code> and <code>rotateZ</code> both rotate the cube along one of its own axes, but <code>rotateX</code> instead rotates the whole cube along the viewport's X axis.  I <em>think</em> this might be an implementation bug; feel free to correct me if I'm wrong.</p>
",geometry
"<p>It is clear that a reordering of the elements in a chosen basis for an n-dimensional vector space induces a permutation on n elements, and conversely such a permutation corresponds to a re-ordering of the basis.</p>

<p>I am wondering why the signature of a permutation is associated to the orientation induced by a basis. I understand that one can do this technically - but is there an intuitive way to understand why this is so? </p>

<p>That is, is there a way to understand  why the concept of orientation, as experienced in 1,2 and 3 dimensional Euclidean space, is formalized (and thereby generalized to abstract vector spaces of arbitrary finite dimension) using the signature? </p>
",geometry
"<p>If the bisectors of the angles of a triangle $ABC$ meet the opposite sides in $A',B',C'$,prove that the ratio of the areas of the triangles $A'B'C'$ and $ABC$ is $2\sin \frac{A}{2}\sin \frac{B}{2}\sin \frac{C}{2}:\cos \frac{A-B}{2}\cos \frac{B-C}{2}\cos \frac{C-A}{2}$<br></p>

<p>Area of $ABC=$Area of $ABA'+$Area of $ACA'$
<br>$=\frac{1}{2}(c+b)AA'\sin \frac{A}{2}=R(\sin C+\sin B)AA'\sin \frac{A}{2}$<br>
$=R\times 2\sin \frac{B+C}{2} \cos \frac{B-C}{2}AA'\sin \frac{A}{2}$<br></p>

<p>How to find the area of $A'B'C'$ and get the desired result,help me please.Thanks in advance.</p>
",geometry
"<p>Let $n$ be a positive integer. I want to prove one of these:</p>

<p>1.$\mathbb{R}^n$ cannot be expressed as $A\cup B$ where $A,B$ are algebraic varieties $V(I),V(J)$ and $A,B\neq\mathbb{R}^n$.</p>

<p>2.$\mathbb{R}^n$ is not Haussdorff under Zariski's topology.</p>

<p>3.If $V(J)=\mathbb{R}^n$ then $J=0$. </p>

<p>where $I,J$ are ideals of the ring of polynomials in $n$ indeterminates.</p>

<p>I started trying to prove 2, then arrived to 1, which seemed very intuitive under the real numbers. But I still don't see how to prove it (I think there may be different ways to prove it outside of the algebraic geometry). Then I got to 3, but I don't think it's true in general (I'd have to use characteristic 0 I think).</p>

<p>Any idea or hint?</p>
",geometry
"<p>Back in grade school, I had a solution involving <a href=""http://joezeng.com/images/triangle_proof.png"">""folding the triangle""</a> into a rectangle half the area, and seeing that all the angles met at a point.</p>

<p>However, now that I'm in university, I'm not convinced that this proof is the best one (although it's still my favourite non-rigorous demonstration). Is there a proof in, say, linear algebra, that the sum of the angles of a triangle is 180 degrees? Or any other Euclidean proofs that I'm not aware of?</p>
",geometry
"<p>The diagonals of a rectangle are both 10 and intersect at (0,0). Calculate the area of this rectangle, knowing that all of its vertices belong to the curve $y=\frac{12}{x}$.</p>

<p>At first I thought it would be easy - a rectanlge with vertices of (-a, b), (a, b), (-a, -b) and (a, -b). However, as I spotted no mention about the rectangle sides being perpendicular to the axises, it's obviously wrong which caused me to get stuck. I thought that maybe we could move in a similar way - we know that if a rectangle is somehow rotated (and we need to take that into account), the distances from the Y axis from the points being symmetric to (0,0) are still just two variables. So we would have: (-b, -12/b), (a, 12/a), (-a, -12/a), (b, 12/b). I then tried to calculate the distance between the first two and the second and the third which I could then use along with the Pythagorean theorem and a diagonal. However, the distance between the first two is $\sqrt{(a+b)^2+(\frac{12}{a}+\frac{12}{b})^2}$ which is unfriendly enough to make me thing it's a wrong way. Could you please help me?</p>
",geometry
"<p>We all know that $x^2+y^2=r^2$ is a circle. What does $(x^2+y^2)^2$ signify? In general, what is $(x^2+y^2)^n$?</p>
",geometry
"<p>I have two circles with radii $r$ and $R$. I need to know how far apart to draw them
so that their intersection has area $A$. Basically, I'm solving for $d$ in the diagram seen in the MathWorld link.</p>

<p>It's not hard to solve for $A$ (see <a href=""http://mathworld.wolfram.com/Circle-CircleIntersection.html"" rel=""nofollow"">MathWorld</a>), </p>

<p>$A = r^2\cos^{-1}\left(\frac{d^2+r^2-R^2}{2dr}\right) + R^2\cos^{-1}\left(\frac{d^2+R^2-r^2}{2dR}\right)-\frac{1}{2}\sqrt{(-d+r+R)(d+r-R)(d-r+R)(d+r+R)}$</p>

<p>but I've been struggling to find a solution for $d$. </p>
",geometry
"<p>In the trapezium $ABCD$ , $AB$ is parallel to $CD$ and $O$ is the intersection of $AD$ and $BC$. The line $PS$ is drawn through $O$ in such a way that $PS$ is parallel to $DC$. If $AB = 20$ AND $CD = 30$,what is the length of $PS$ ?</p>

<p>First I searched for similar triangles.According to that I saw that triangle DPO and triangle ADB are similar.In the other side triangle APO and triangle ADC are similar. By equalizing the lengths OP according to the two ratios, finally i got PS = 24. Is it correct?</p>
",geometry
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://math.stackexchange.com/questions/139340/representing-the-multiplication-of-two-numbers-on-the-real-line"">Representing the multiplication of two numbers on the real line</a>  </p>
</blockquote>



<p>Consider the real line in the plane. Suppose you are given the location of the point associated to $0$ and two oter points $a$ and $b$ on the line, it's strightforward to provide a geometric construction(*) that allows you to identify the point associated to $a+b$. My question is: suppose we are given the locations of $0$ and $1$, given two points $a$ and $b$ can we provide a geometric construction which allows to identify the point $a \cdot b$?</p>

<p>(*) <a href=""http://en.wikipedia.org/wiki/Compass_and_straightedge_constructions"" rel=""nofollow"">Compass and straightedge construction</a></p>
",geometry
"<p>This is equivalent to  the positive integer solutions to $$\frac{a-2}{a} + \frac{b-2}{b} + \frac{c-2}{c} = 2$$ with $3 \le a \le b \le c$.</p>

<p>Small solutions like $(6, 6, 6)$ and $(4, 8, 8)$ can be guessed, but other solutions such as $(4, 5, 20)$ exist.</p>

<p><a href=""http://i.stack.imgur.com/fjhIH.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/fjhIH.png"" alt=""enter image description here""></a></p>
",geometry
"<p>Prove that having 6 points in the interior of a square of side length 3, we can choose 2 of them so that the distance between them is less than 2.</p>

<p>Looks obvious, but I can't get a rigorous demonstration. </p>

<p>I tried to cover the square with 6 circles of radius 1, having the centers inside the square, to prove they must intersect at least once.</p>

<p><strong>Note:</strong></p>

<p>This partition leads to solution.</p>

<p>The rectangles on the first row: $3/2 * (3 - \sqrt3) $ </p>

<p>The rectangles on the second row: $1 * \sqrt3 $ </p>

<p>The 5 zones are so that the distance between any 2 points inside the same zone is less than 2.</p>

<p><a href=""http://i.stack.imgur.com/YQolX.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/YQolX.png"" alt=""enter image description here""></a></p>
",geometry
"<p>Two circles ,of radii $a$ and $b$,cut each other at an angle $\theta.$Prove that the length of the common chord is $\frac{2ab\sin \theta}{\sqrt{a^2+b^2+2ab\cos \theta}}$<br></p>

<p>Let the center of two circles be $O$ and $O'$ and the points where they intersect be $P$ and $Q$.Then angle $OPO'=\theta$<br></p>

<p>$\cos \theta=\frac{a^2+b^2-OO'^2}{2ab}$<br></p>

<p>$OO'^2=a^2+b^2-2ab\cos\theta$<br></p>

<p>In triangle $PO'Q$,angle $PO'Q=\pi-\theta$<br></p>

<p>$\cos(\pi-\theta)=\frac{b^2+b^2-l^2}{2b^2}$ Then i am stuck.Please help me to reach upto proof.</p>
",geometry
"<p>I've to solve this simple exercise but i can't see how.<br>
Problem: let $AB$ and $CD$ two equivalent ropes of one circle of centre $O$. Let $P$ and $Q$ two points that belong on the extentions of the previous ropes such that $BP$ and $DQ$ are equivalent. So show that the centre $O$ belong on the axis of the segment $PQ$ .
<a href=""http://i.stack.imgur.com/7TDAi.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/7TDAi.png"" alt=""rope of a circle""></a></p>
",geometry
"<p>In the sides $BC,CA,AB$ are taken three points $A',B',C'$ such that $BA':A'C=CB':B'A=AC':C'B=m:n$.Prove that if $AA',BB',CC'$ are joined they will form by their intersections a triangle whose area is to that of the triangle ABC as $\frac{(m-n)^2}{m^2+mn+n^2}$<br></p>

<p>I dont know how to find the area of inner $A'B'C'$ and how to relate with area of outer triangle.Please help.</p>
",geometry
"<p>Given a line segment of say length $L$ is it possible </p>

<ol>
<li>Is it possible to create a line segment of length $\sqrt{L}$ ?</li>
<li>Is it possible to create a line segment of length $\frac{a}{b}L$, where $a,b$ are positive integers  ?</li>
</ol>

<p>The constructions only permit to use a ruler and a compass. My question arises due to a statement in the book Hardy and Wright, which is as follows :</p>

<blockquote>
  <p>Euclidean constructions by ruler and compass are equivalent analytically to solutions of a series of linear or quadratic equations.</p>
</blockquote>
",geometry
"<p>i interested in  the following definition but i don't understand it because i don't understand what mean by ""flat space generated by C"" .<br>
 <img src=""http://i.stack.imgur.com/Pot7u.png"" alt=""enter image description here""></p>

<p>the same definition is given by <img src=""http://i.stack.imgur.com/JwFzG.png"" alt=""enter image description here""></p>

<p>i have also the same problem with this definition, i don't know what he mean by subspace spanned by C .
i want to be intuitive with it.
Thanks in advance.</p>
",geometry
"<p>Given two convex polygons $P$ and $Q$ what is the minimum intersection polygon $A=P\cap Q'$ where $Q'$ is the polygon $Q$ offset by a vector $\overline r$ of fixed length?</p>

<p>Put another way, what is the vector $\overline r_{min}$ that minimizes $P\cap (Q+\overline r)$? Is there an algoritm that finds this ""direction of minimum overlap""? Does this problem has a name?</p>

<p><img src=""http://i.stack.imgur.com/D2BXC.png"" alt=""Figure""></p>
",geometry
"<h2><strong>Derivation/equation for solid angle factor correction</strong></h2>

<p><strong><em>Summary</em></strong>: I want to determine a correction for the Solid Angle Factor (SAF) due to partially overlapping 'outer' spheres (of different sizes), as perceived/viewed from the center of a 'central' sphere. The distances of these spheres from the 'central sphere' are not equal, i.e. they are not equidistant. The coordinates, distances and relatives angles of all the spheres can be determined via software, i.e. they are known.</p>

<hr>

<p>“The Solid Angle Factor (SAF) is defined as the solid angle of the ligand cone comprising the metal at the apex and the primary coordinating atom or group (the first-order SAF) or the whole ligand (the second-order SAF) divided by 4π. <strong>Geometrically, it refers to the ratio of the projected area to 4π, i.e. the area of the sphere surface.</strong> It actually represents the size of the ligand as viewed from the metal centre towards the ligand. The sum of the values of SAF of all the ligands coordinated to the metal centre represents the total occupancy of the ligands in the coordination sphere. It is apparent that this occupancy should not reach unity because there are gaps and holes among the ligands.” (Polyhedron Vol. 6, No. 5, pp. 104-1048, 1987) (See <a href=""https://www.dropbox.com/s/g2f97bn97yq56vu/xi-zhang1987.pdf?dl=0"" rel=""nofollow"">https://www.dropbox.com/s/g2f97bn97yq56vu/xi-zhang1987.pdf?dl=0</a>)</p>

<p>In other words the solid angle is related to the projection of an 'outer' 'ligand' (sphere of known radius) onto the surface of a central ('metal' atom) sphere, as viewed from the center of the central sphere.
<strong>Solid angle factor (SAF) equation</strong>:</p>

<p>$$SAF=\frac{2\pi (1-\cos \Theta )}{4\pi } = \frac{1}{2}(1-\cos \Theta)$$</p>

<p>$$\theta =\sin^{-1}(\frac{\nu }{\iota })$$</p>

<p>, where ν = radius of the sphere of ligand/coordinating atom (This is known),
l = distance between the center of the 'ligand' spheres to the center of the metal atom/ 'sphere'.</p>

<p>A correction (approximation) has been supplied for the case where 2 identical  'ligand' spheres (i.e. the spheres have identical radii) are partially overlapping and are equidistant from the metal center:</p>

<p>$$\Delta SAF = \frac{2(\frac{2\varphi (\pi \nu ^{2})}{360}-d\nu \sin \varphi )}{4\pi (\iota \cos \eta )^{^{2}}}$$</p>

<p>(See link above and the following link:
<a href=""https://www.dropbox.com/s/7w3kyvf1xq9e320/Solid%20angle%20factor_details_1_2%20%281%29.pdf?dl=0"" rel=""nofollow"">https://www.dropbox.com/s/7w3kyvf1xq9e320/Solid%20angle%20factor_details_1_2%20%281%29.pdf?dl=0</a> . These diagrams/equations illustrate what I understand of the the given correction equation, as well as the definition of the above symbols)</p>

<hr>

<p><strong>Derivation/equation for solid angle factor correction</strong>:
However, since there are multiple 'ligand' spheres around the metal several may partially overlap (or be perceived to overlap as viewed from the central 'metal' sphere) due to their close proximity to the metal, thereby resulting in the ‘observed’ solid angle factor being different from the calculated solid angle factor (without correction) from the metal.
The correction must consider:</p>

<ol>
<li>The distance from the central 'metal' sphere to the center of each 'ligand' sphere. (They are not necessarily equidistant)</li>
<li>The radius of each 'ligand' sphere (since they may have different (known) radii).</li>
</ol>

<p><strong>How would such an equation be derived and what would the equation be?</strong> Perhaps by considering 2 'ligand' spheres at a time? I am interested in the corrected (i.e. accurate) sum of all the SAF (known as the <strong>Solid Angle Sum (SAS)</strong>) of all the surrounding 'ligand' spheres, which should be &lt; or = 1.0.</p>

<p>I look forward to any helpful responses.
$$Thank you$$</p>
",geometry
"<p>I was looking at this <a href=""http://what-if.xkcd.com/11/"" rel=""nofollow"">XKCD what-if</a> question (the gas mileage part), and started to wonder about the concept of unit cancellation. If we have a shape and try to figure out the ratio between the volume and the surface area, the result is a length. For example, a sphere of radius 10cm has the volume of $\approx 4118 cm^3$ and an area of $\approx 1256 cm^2$. Therefore, the volume : surface area is $\approx 3.3 cm$.</p>

<p>My question is: what is the physical representation of length in this ratio?</p>
",geometry
"<p>I have general equation for ellipsoid not in center:
$$ \frac{(x-x_0)^2}{a^2}+\frac{(y-y_0)^2}{b^2}+\frac{(z-z_0)^2}{c^2}=1.$$
What is the equation when it's rotated  based on $\alpha$(over $x$ axis), $\beta $(over $y$ axis) and $\gamma$(over $z$ axis)?</p>
",geometry
"<p>Tonight I stumbled across the concept of translational invariance while studying metric spaces, but I still do not have a clear conception of what it exactly means in abstract terms. Could anyone clarify it to me?</p>

<p>Thank you for your time!</p>
",geometry
"<p>It appears to me that only Triangles, Squares, and Pentagons are able to ""tessellate"" (is that the proper word in this context?) to become regular 3D convex polytopes.</p>

<p>What property of those regular polygons themselves allow them to faces of regular convex polyhedron?  Is it something in their angles?  Their number of sides?</p>

<p>Also, why are there more Triangle-based Platonic Solids (three) than Square- and Pentagon- based ones? (one each)</p>

<p>Similarly, is this the same property that allows certain Platonic Solids to be used as ""faces"" of regular polychoron (4D polytopes)?</p>
",geometry
"<p>Polygons are, in this question, defined as non-unique if they similar to another (by rotation, reflection, translation, or scaling).</p>

<p>Would this answer be any different if similar but non-identical polygons were allowed?  And if only if rotated/translated by rational coefficients?</p>

<p>Would this answer be any different if we constrained the length and internal angles of all polygons to rational numbers?</p>

<p>Assume the number of sides is finite but unbounded, and greater than two.</p>
",geometry
"<p>I must construct this triangle:</p>

<p>Consider the triangle $ABC$. Take $D$ in the line of $BC$ such that $C$ is the mid point of $BD$ and take $Y$ in the line $AC$ such that the lines $AB$ and $BY$ are parallel. </p>

<p>I constructed the point $D$, but I don't see how I can construct the point $Y$ without this point being $A$. Does another possibility exists? I don't see how.</p>
",geometry
"<blockquote>
  <p>A certain rectangular crate measures 8 feet by 10 feet by 12 feet. A
  cylindrical gas tank is to be made for shipment in the crate and will
  stand upright when the crate is placed on one of its six faces. What
  should the radius of the tank be if it is to be of the largest
  possible volume?</p>
</blockquote>

<ol>
<li>4</li>
<li>5</li>
<li>6</li>
<li>8</li>
<li>10</li>
</ol>

<p>The answer is given = 5. </p>

<p>But what is the problem with radius 6. If we guess 6 is the radius then, the rectangle of the edge 8 or 10 could fit. I think, i have misunderstand the question. </p>
",geometry
"<p>In triangle ABC $\angle BAC=90$, $\angle ABC$:$\angle ACB $=1:2 and AC = 4cm.  Calculate the length of BC. 
I tried this by constructing an equilateral triangle as in the figure. 
I am interested in the solution using Pythagoras theorem</p>
",geometry
"<p>Lets say i have an injective continuous curve $\sigma$ in $\mathbb{C}$, indexed on $[0,\infty)$ and converging to $\infty$. If $\vert \sigma(0)\vert&gt;0$ , is it possible that it can trap itself outside the unit circle? By that i mean, that there doesn't exist an extension of the curve, so that the beginning point is on the unit circle? My intuitive guess if of course no, but i wonder if there is a simple proof that doesn't require more than the first course in topology . I would also appreciate if someone could confirm that my guess is correct.</p>

<p>thanks for reading.</p>
",geometry
"<p>My book writes that</p>

<blockquote>
  <p>Every conic section has four foci. Two are real and two are complex.</p>
</blockquote>

<p>But during the discussion of parabola, it told only about one real focus. It only wrote that </p>

<blockquote>
  <p>...the other focus and directrix lie at infinity.</p>
</blockquote>

<p>So, what would the figure look like? I know it is difficult to visualize. But still I ask what will be the figure? Will it be an ellipse-like??? And what about the complex foci??? Please help.</p>
",geometry
"<p>Can someone help me to evaluate this integral? 
$$\int \limits _0 ^\beta \frac{\sin\theta}r\,d\theta$$</p>

<p>I need it in a physics exercise.
<img src=""http://i.stack.imgur.com/AKlOb.png"" alt=""See the image here"">
Given a circle (as shown in diagram), a point $P$ and angle $\theta$ made with the axis.</p>
",geometry
"<p>Congruence transformations (isometries) and similarity transformations (isometries + dilations) should be constructable.  What about other affine transformations?  Other conformal mappings?</p>

<p><em><strong>edit</em></strong>: by constructable, I mean given the defining information for the transformation in a geometric way (e.g. a dilation requires a center and a ratio, so the given could be a point and two segments), can you construct the image of a point under the transformation from its preimage?</p>
",geometry
"<p>I'm trying to graph the function $y = \frac{x^2-4}{x-2}$.  I factored the numerator into $(x+2)(x-2)$, and then canceled the common factor (x-2), leaving the function as $y = x + 2$.  </p>

<p>Is it acceptable to graph the original function as $y = x + 2$, a straight line with domain and range all real numbers?  Or do you have to restrict the domain as in the original function?</p>

<p>Thanks,
Sean</p>
",geometry
"<p>Prove that $\sin \alpha+\sin \beta+\sin \gamma \geq\sin 2\alpha+\sin 2\beta+\sin 2\gamma $ where $\alpha$ $,\beta$ $,\gamma$ are the angles of a triangle</p>
",geometry
"<p>I am trying to understand this formula from Wikipedia <a href=""http://en.wikipedia.org/wiki/Solid_angle"" rel=""nofollow"">here</a>. It is a generalization of radian. I am trying to do unit check but I cannot see how the units match. Steradion must be dimensioless unit (derived SI unit). </p>

<p>This $\int\int_S \frac{\bar r \cdot \hat n dS}{r^3}$ has area times a small area in the numerator and volume in denomirator so integral of one divided by meter. I am doing somewhere an idea-mistake. Where?</p>

<p><strong>Formula from Wikipedia about solid angle</strong></p>

<blockquote>
  <p><img src=""http://i.stack.imgur.com/xj2ty.png"" alt=""enter image description here""></p>
</blockquote>
",geometry
"<p>The volume of a cone with height $h$ and radius $r$ is $\frac{1}{3} \pi r^2 h$, which is exactly one third the volume of the smallest cylinder that it fits inside.</p>

<p>This can be proved easily by considering a cone as a <a href=""http://en.wikipedia.org/wiki/Solid_of_revolution"">solid of revolution</a>, but I would like to know if it can be proved or at least visual demonstrated without using calculus.</p>
",geometry
"<p>A friend and I were reading some of the more catastrophic predictions for climate change, and were wondering if it would be possible to recover from complete permanent loss of polar ice (which cools the planet by reflection).</p>

<p>One idea we kicked around was building a giant occulter in space. Technological considerations aside, how big a shadow could we cast?</p>

<p>I can't figure out how to handle the umbra and penumbra. If you have</p>

<ul>
<li>Earth of radius $r_e$</li>
<li>orbiting the Sun of radius $r_s$</li>
<li>at a distance $d_{se}$</li>
<li>and an occulter of radius $r_o$ in between the two</li>
<li>at a distance $d_{so}=d_{se}-d_{oe}$</li>
</ul>

<p>how much light would be blocked?</p>
",geometry
"<p>This is an A level question. For better understanding, I will attach a screenshot of the question and the mark scheme. </p>

<p>Question: </p>

<p><a href=""http://imgur.com/EP3rP5Y"" rel=""nofollow""><img src=""http://i.imgur.com/EP3rP5Y.png"" title=""source: imgur.com"" /></a></p>

<p>Here's what I have done:</p>

<p>$$A(OBA) = \frac 12r^2α$$ [basic formula for area of sector]</p>

<p>$$A(ONB) = \frac 12r \sin(\frac {BN}{r})$$ [basic formula for area of triangle]</p>

<p>$$2\frac 12r \sin(\frac {BN}{r}) = \frac 12r^2α$$ [because A(ONB) is half A(OBA)]</p>

<p>$$2 \sin(\frac {BN}{r}) = rα$$
[simplifying the equation]</p>

<p>And that's where I'm stuck. </p>

<p>Answer: </p>

<p><a href=""http://imgur.com/XfNvrpj"" rel=""nofollow""><img src=""http://i.imgur.com/XfNvrpj.png"" title=""source: imgur.com"" /></a></p>

<p>Thanks in advance!</p>
",geometry
"<p>When differentiated with respect to $r$, the derivative of $\pi r^2$ is $2 \pi r$, which is the circumference of a circle.</p>

<p>Similarly, when the formula for a sphere's volume $\frac{4}{3} \pi r^3$ is differentiated with respect to $r$, we get $4 \pi r^2$.</p>

<p>Is this just a coincidence, or is there some deep explanation for why we should expect this?</p>
",geometry
"<p>Let $f$ the isoperipetric quotient and $P$ an equilateral $n$-gon. (See <a href=""http://www.math.chalmers.se/~rowlett/monthly.pdf"" rel=""nofollow"">Sound of Symmetry</a> for more detail)</p>

<p>Since $f$ is scale invariant, then we shall assume that the sides of $P$ all have length equal to one. Consider the edge between two vertices $\nu_i$ and $\nu_{i+1}$, where the vertices are considered modulo $n$. Denote by $\{\gamma_i\}_{i=1}^n$ the set of interior angles of $P$, and the exterior angles $\alpha_i := \pi - \gamma_i$. Consider moving the edge between $\nu_i$ and $\nu_{i+1}$ in the direction of the outward normal to this edge. Let $t$ denote the distance the edge is translated. Then the perimeter $$L(t) = L + t(\csc \alpha_i - \cot \alpha_i) + t(\csc \alpha_{i+1} - \cot \alpha_{i+1})\color{red}{+ O(t^2)},$$ where $L$ is the perimeter of $P$ at $t=0$.</p>

<p><a href=""http://i.stack.imgur.com/UdfLc.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/UdfLc.jpg"" alt=""enter image description here""></a></p>

<p>I thought that $$L(t) = L(0) + t((\csc \alpha_i - \cot \alpha_i) + (\csc \alpha_{i+1} - \cot \alpha_{i+1})) , $$ but I have difficulty seeing why they added $O(t^2).$</p>

<p><strong>Question :</strong> Why do we have to add the part $O(t^2)$ at the equation of perimeter?</p>

<p><strong>P.S.</strong> I know that there exists a similar question, but knowing that it is not the same : <a href=""http://math.stackexchange.com/questions/1880116/why-the-ot2-part-in-lt-l-t-csc-alpha-i-cot-alpha-i-csc-alph"">Why the $O(t^2)$ part in $L(t) = L + t(\csc \alpha_i - \cot \alpha_i +\csc \alpha_{i+1} - \cot \alpha_{i+1}) + O(t^2)$?</a>.</p>
",geometry
"<p>It is impossible to find $n+1$ mutually orthogonal unit vectors in $\mathbb{R}^n$. </p>

<p>However, a <a href=""http://maze5.net/?page_id=367"" rel=""nofollow"">simple geometric argument</a> shows that the central angle between any two legs of a simplex goes as $\theta = \mathrm{arccos}(-1/n)$. This approaches $90$ degrees as $n \rightarrow \infty$, so since there are $n+1$ vertices of a simplex in $n$-dimensional space, we can conclude</p>

<blockquote>
  <p>Given $\epsilon &gt; 0$, there exists a $n$ such that we can find $n+1~$ <em>approximately mutually orthogonal</em> vectors in $\mathbb{R}^n$, up to tolerance $\epsilon$. (Unit vectors $u$ and $v$ are said to be approximately orthogonal to tolerance $\epsilon$ if their inner product satisfies $\langle u,v \rangle &lt; \epsilon$)</p>
</blockquote>

<p>My question is a natural generalization of this - if we can squeeze $n+1$ approximately mutually orthogonal vectors into $\mathbb{R}^n$ for $n$ sufficiently large, how many more vectors can we squeeze in? $n+2$? $n+m$ for any $m$? $2n$? $e^n$? </p>

<hr>

<p><strong>Edit:</strong> I think one can squeeze at least $n+m$ for any $m$, via the following construction. Given $\epsilon$, one finds the $k$ such that you can have $k+1$ $\epsilon$-approximate mutually orthogonal unit vectors in $\mathbb{R}^k$. Call these vectors $v_1, v_2, ..., v_k$. Then you could squeeze $mk+m$ vectors in $\mathbb{R}^{mk}$, by using the vectors
$$\begin{bmatrix}
v_1 \\
0 \\
\vdots \\
0
\end{bmatrix},
\begin{bmatrix}
v_2 \\
0 \\
\vdots \\
0
\end{bmatrix},
\begin{bmatrix}
v_{k+1} \\
0 \\
\vdots \\
0
\end{bmatrix},
\begin{bmatrix}
0 \\
v_1 \\
\vdots \\
0
\end{bmatrix},
\begin{bmatrix}
0 \\
v_2 \\
\vdots \\
0
\end{bmatrix},
\begin{bmatrix}
0 \\
v_{k+1} \\
\vdots \\
0
\end{bmatrix}, \dots
\begin{bmatrix}
0 \\
0 \\
\vdots \\
v_1 \\
\end{bmatrix},
\begin{bmatrix}
0 \\
0 \\
\vdots \\
v_2 \\
\end{bmatrix},
\begin{bmatrix}
0 \\
0 \\
\vdots \\
v_{k+1} \\
\end{bmatrix}.
$$</p>

<p>So, setting $n = mk$, we have found an $n$ such that we can fit $n + m$ $\epsilon$-orthogonal unit vectors in $\mathbb{R}^n$.</p>
",geometry
"<p>I am working on computing phase diagrams for alloys.  These are
blueprints for a material that show what phase, or combination of
phases, a material will exist in for a range of concentrations and
temperatures (see <a
href=""http://web.cos.gmu.edu/~tstephe3/talks/SIAMMaterialsScience2010.pdf"" rel=""nofollow"">this
pdf presentation</a>).  </p>

<p>The crucial step in drawing the boundaries that separate one phase
from another on these diagrams involves minimizing a free energy
function subject to basic physical conservation constraints.  I am
going to leave out the chemistry/physics and hope that we can move forward
with the minimization using Lagrange multipliers. </p>

<p>The free energy that is to be minimized is this:</p>

<p>$\widetilde{G}(x_1, x_2) = f^{(1)}G_{1}(x_1) + f^{(2)}G_{2}(x_2),$</p>

<p>subject to:</p>

<p>$f^{(1)}x_1 + f^{(2)}x_2 = c_1,$</p>

<p>$f^{(1)} + f^{(2)} = 1. $</p>

<p>(and also that the $x_{i} > 0$ and $f^{(i)} > 0$, for $i=1,2$.)</p>

<p>The Lagrange formulation is:</p>

<p>$L(x_1,x_2,f^{(1)},f^{(2)},\lambda_1, \lambda_2, \lambda_3) =
f^{(1)}G_{1}(x_1) + f^{(2)}G_{2}(x_2)$  </p>

<p>$- \lambda_{1}(f^{(1)}x_1 + f^{(2)}x_2 - c_1)$</p>

<p>$- \lambda_{2}(f^{(1)} + f^{(2)} - 1) $</p>

<p>The minimization of $\widetilde{G}$ follows from finding the $x_{i}$'s  that satisfy $\nabla L = 0:$</p>

<p>$\frac{\partial L}{\partial x_{1}}   = f^{(1)}G_{1}'(x_1) - \lambda_{1}f^{(1)} = 0$</p>

<p>$\frac{\partial L}{\partial x_2}     = f^{(2)}G_{2}'(x_2) - \lambda_{1}f^{(2)} = 0$</p>

<p>$\frac{\partial L}{\partial f^{(1)}} = G_{1}(x_1) - \lambda_{1}x_{1} - \lambda_2 = 0$</p>

<p>$\frac{\partial L}{\partial f^{(2)}} = G_{2}(x_2) - \lambda_{1}x_{2} - \lambda_2 = 0$</p>

<p>which yields:</p>

<p>$(*) f^{(1)}\left[G_{1}'(x_1) - \lambda_1 \right] = 0$       </p>

<p>$(**) f^{(2)}\left[G_{2}'(x_2) - \lambda_1 \right]= 0 $       </p>

<p>$(***) G_{1}(x_1) - G_{2}(x_2) = \lambda_1 \left[ x_1 - x_2\right]$ </p>

<p>Because $f^{(1)}$ and $f^{(2)}$ are not to be zero, from (*) and (**) we have that </p>

<p>$G_{1}'(x_1) = G_{2}'(x_2) = \lambda_{1}.$</p>

<p>And, a manipulation of equation (***) looks like </p>

<p>$\frac{G_{1}(x_1) -G_{2}(x_2)}{x_1 - x_2} = \lambda_{1}.$</p>

<p>Now, think of $G_{i}$ as an even degree polynomial (which it isn't, but
it's graph sometimes resembles one) in the plane.  Let the points $x_1$
and $x_2$ be locations along the x-axis that lie roughly below the
minima of this curve.  The constraints (*),(*<em>), and (*</em>*) describe the
condition that the line drawn between $(x_1,G_{1}(x_1))$ and $(x_2,G_{2}(x_2))$ form a common tangent
to the ""wells"" of the curve.  It is these points $x_1$ and $x_2$,
which represent concentrations of pure components in our alloy, that
become mapped onto a phase diagram.  It is essentially by repeating this procedure for many
temperatures that we can trace out the boundaries in the desired phase diagram.</p>

<p><strong>The question is:</strong>  Looking at this from a purely analytic geometry
perspective, <strong>how would one derive the ""variational"" approach to find a common tangent line that we seem to have found using the above Lagrangian?</strong>  (warning: I don't really know how to
model things using variational methods.)  </p>

<p><strong>And, secondly:</strong> I have presented a model of a binary alloy, meaning
two variables to keep track of representing concentrations.  I have
been working on ternary alloys, where this free energy $\widetilde{G}$
is a function of three variables (two independent: $x_1,x_2,x_3$,
where $x_3 = 1- x_1 - x_2$) and is therefore a surface over a Gibbs
triangle.  Then $\nabla L = 0$ produces partial derivatives that no
longer ""speak geometry"" to me, although the solution is a common tangent
plane.  (I have attempted to characterize a common tangent plane
based purely in analytic geometry - completely disregarding the
Lagrangian - and have come up with several relations between
directional derivatives... <strong>How might directional derivatives relate
to the optimality conditions set forth by the Lagrangian?</strong>)</p>

<p><strong>EDIT:</strong>  Thank you Greg Graviton for wading through this sub-optimal notation and pointing out several mistakes in the statement of the problem.  (Also, thank you for the <a href=""http://math.stackexchange.com/questions/632/validating-a-mathematical-model-lagrange-formulation-and-geometry/1245#1245"">excellent discussion below</a>.)</p>
",geometry
"<p>Let $f$ be a function from the set of all points on the plane to the nonzero real numbers. Suppose that for any triangle $ABC$ with incenter $I$, we have that $f(I)=f(A)f(B)f(C)$. What are the possibilities for $f$?</p>

<p>Clearly, $f=1$ and $f=-1$ work. Are there other ones?</p>
",geometry
"<p>I was wondering if there is a formula that could generate the values of the sides of a triangle where his area equals to his perimeter. I only found that if the triangle is equilateral then 
$$l=\frac{12}{√3}$$
where $l$ is the side of the triangle.</p>

<p>Thanks for support</p>

<p>Peterix</p>

<p>P.S. There is a similar problem <a href=""http://math.stackexchange.com/questions/90236/right-triangle-where-the-perimeter-areak"">here</a></p>
",geometry
"<p>I'm trying to calculate the distance of a certain point of an ellipse to the centre of that ellipse:</p>

<p><img src=""http://i.stack.imgur.com/hwOqM.png"" alt=""""></p>

<p>The blue things are known: The lengths of the horizontal major radius and vertical minor radius and the angle of the red line and the x-axis. The red distance is the desired result. It is not given where on the ellipse the point is. It can be anywhere on the ellipse. Is this problem possible? If so, in which can this be solved? Thanks in advance!</p>

<hr>

<p>After reading Kaj Hansen's comment and trying a bit this is what I did, it still won't work though.</p>

<p>In a triangle, $tan(\theta)=\frac{\text{opposite side}}{\text{adjecent side}}$. The slope of a line is $\frac{\Delta y}{\Delta x}$. Therefor the slope of the red line is $\tan(\theta)$; the formula of the line is $y=\tan(\theta)\cdot x$. </p>

<p>The formula of the ellipse is $\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}=1$. When I put the two formulas together I get 
$$\frac{x^{2}}{a^{2}}+\frac{(\tan(\theta)\cdot x)^{2}}{b^{2}}=1$$</p>

<p>After a bit of rearranging:</p>

<p>$$x=\pm \sqrt{\frac{a^{2}\cdot b^{2}}{a^{2}\cdot (\tan(\theta))^{2}+b^{2}}}$$</p>

<p>$$$$</p>

<p>$$y=\tan(\theta)\cdot x$$</p>

<p>$$y=\pm \tan(\theta) \cdot \sqrt{\frac{a^{2}\cdot b^{2}}{a^{2}\cdot (\tan(\theta))^{2}+b^{2}}} $$</p>

<p>Now with the help of Pythagoras' theorem $c=\sqrt{a^{2}+b^{2}}$ the red line should be </p>

<p>$$\sqrt{\left ( \sqrt{\frac{a^{2}\cdot b^{2}}{a^{2}\cdot (\tan(\theta))^{2}+b^{2}}}\right ) ^{2}+\left ( \tan(\theta) \cdot \sqrt{\frac{a^{2}\cdot b^{2}}{a^{2}\cdot (\tan(\theta))^{2}+b^{2}}} \right )^{2}}$$</p>

<p>which can be simplified:</p>

<p>$$\sqrt{\frac{a^{2}\cdot b^{2} \cdot (\tan(\theta))^{2}+a^{2}\cdot b^{2}}{a^{2}\cdot (\tan(\theta))^{2}+b^{2}}}$$</p>

<p>This, however, does not give the right answer. Let's try something:</p>

<p>$a=2$; $b=1$; $\theta=\frac{1}{2}\cdot \pi$ (The point is the point where the ellipse intersects with the minor radius)</p>

<p>$$\sqrt{\frac{2^{2}\cdot 1^{2} \cdot (\tan(\frac{1}{2}\cdot \pi))^{2}+2^{2}\cdot 1^{2}}{2^{2}\cdot (\tan(\frac{1}{2}\cdot \pi))^{2}+1^{2}}}$$</p>

<p>$$\sqrt{\frac{4 \cdot (\tan(\frac{1}{2}\cdot \pi))^{2}+4}{4\cdot (\tan(\frac{1}{2} \pi))^{2}+1}}$$</p>

<p>But wait, $\tan(\frac{1}{2}\cdot \pi)$ is undefined. The formula cannot be filled in completely, which is a requirement. I need a formula that can be filled in for every value of $\theta$ on the domain $[0,\frac{1}{2}\cdot \pi]$</p>
",geometry
"<p>$ABCD$ is a square and $AB$ = 1. Equilateral triangles $AYB$ and $CXD$ are drawn such that $X$ and $Y$ are inside the square.How can I find the length of $XY$ ?</p>
",geometry
"<p>Consider two circles of radii $4\;cm$ and $8\;cm$, respectively, both circles have the same center $C$ and is two bodies $A$ and $B$, so that $A$ is smaller circumference of the trajectory at a constant speed of $5\; km/h$, while $B$ is also the greatest circumference at a constant speed of $10\;km/h$.</p>

<p>Knowing that the bodies initially form an angle of $90^o$ with respect to the center $C$, where the time needed and how to calculate so that the points $A$, $B$ and $C$ are aligned? </p>

<p>And how to calculate the next time they met aligned?</p>
",geometry
"<p>Is there a quick way to estimate the distance between a point and a triangle in 3d space?  Preferably one which never returns higher than the actual distance.</p>

<p>I know I could form a pyramid then use the height equation to get the exact value but I'm just looking for a decent estimate.</p>
",geometry
"<p>been stuck on solving/proving the following puzzle:</p>

<p>You need to make a hole in the wall, so that a 1 meter line can pass it through the hole at all angels, find a shape with minimum surface area that would satisfy the above conditions ?</p>
",geometry
"<p>Suppose $\alpha_1, \alpha_2, \alpha_3 $ are complex numbers which are not collinear. Is it possible to use some geometry to find the center of the circle that contains $\alpha_1, \alpha_2, \alpha_3 $ ? </p>
",geometry
"<p>If perpendicular distance from given point(lying on that line) to other point is given then How do I find Co ordinates of other point?</p>
",geometry
"<p>I'm trying to prove that, as Wikipedia <a href=""http://en.wikipedia.org/wiki/Watt%27s_linkage#Shape_traced_by_the_linkage"" rel=""nofollow"">says</a>, ""when the lengths of its bars and its base are chosen to form a crossed square, it traces the lemniscate of Bernoulli"" I'm using the setup described <a href=""http://books.google.co.uk/books?id=iIN_2WjBH1cC&amp;pg=PA58&amp;redir_esc=y#v=twopage&amp;q&amp;f=false"" rel=""nofollow"">here</a> (Although, they have a mistake the fixed point in the text should be D, as in the diagram), but all multiplied by a factor of 2.</p>

<p>So I decided to use vectors to prove it.</p>

<p>Let the point B and C have position vectors $\vec{x}$ and $\vec{x}'$ respectivelly. And the point (1, 0) be $\vec{a}$ . Then the constraints are:
$$\begin{gather}
(\vec{x}'-\vec{a}) \cdot (\vec{x}'-\vec{a}) =2 \\
(\vec{x}+\vec{a}) \cdot (\vec{x}+\vec{a}) =2.\end{gather}$$</p>

<p>Also, if we let $\vec{X}$ be the position vector to trace the lemniscate, then:
$$\vec{X}=\vec{x}+1/2(\vec{x}'-\vec{x})=1/2(\vec{x}'+\vec{x})=1/2(\vec{x}'-\vec{a}+\vec{x}+\vec{a}).$$</p>

<p>Now,
$$\begin{align}
(\vec{X} \cdot \vec{X})^2
&amp;=(1/4((\vec{x}'-\vec{a}) \cdot (\vec{x}'-\vec{a})+(\vec{x}+\vec{a}) \cdot (\vec{x}+\vec{a})+2(\vec{x}'-\vec{a}) \cdot (\vec{x}+\vec{a})))^2 \\ 
&amp;=(1/4(4+2(\vec{x} \cdot \vec{x}'-\vec{a} \cdot \vec{x} +\vec{a} \cdot \vec{x}' -\vec{a} \cdot \vec{a}))^2 \\
&amp;=(1/2(1+xx'+yy'-x+x'))^2\end{align}.$$</p>

<p>From which I just can't get the required $2(X^2-Y^2)=1/2((x+x')^2-(y+y')^2)$ on the RHS to make the algebraic equation for the lemniscate. In particular, I can't get any $y^2$ or $y'^2$. So what am I doing wrong?</p>
",geometry
"<p>I've just came back from my Mathematics of Packing and Shipping lecture, and I've run into a problem I've been trying to figure out.</p>

<p>Let's say I have a rectangle of length $l$ and width $w$.</p>

<p>Is there a simple equation that can be used to show me how many circles of radius $r$ can be packed into the rectangle, in <strong>the optimal way</strong>?  So that no circles overlap. ($r$ is less than both $l$ and $w$)</p>

<p>I'm rather in the dark as to what the optimum method of packing circles together in the least amount of space is, for a given shape.</p>

<p>An equation with a non-integer output is useful to me as long as the truncated (rounded down) value is the true answer.</p>

<p>(I'm not that interested in <strong>how</strong> the circles would be packed, as I am going to go into business and only want to know how much I can demand from the packers I hire to pack my product)</p>
",geometry
"<p>PS is a line segment of length 4 and O is the midpoint of PS. A semicircular arc is drawn with PS as diameter. Let X be the midpoint of this arc. Q and R are points on the arc PXS such that QR is parallel to PS and the semicircular arc drawn with QR as diameter is tangent to PS. How can I get the area of the region QXROQ bounded by the two semicircular arcs?</p>
",geometry
"<p>Given</p>

<ol>
<li>A straight line of arbitrary length</li>
<li>The ability to construct a straight line in any direction from any starting point with the ""unit length"", or the length whose square root of its magnitude yields its own magnitude.</li>
</ol>

<p>Is there a way to geometrically construct (using only a compass and straightedge) the a line with the length of the square root of the arbitrary-lengthed line?  What is the mathematical basis?</p>

<p>Also, why can't this be done without the unit line length?</p>
",geometry
"<p>I'm working through ""An Introduction to Inequalities"" by Bellman and Beckenbach. They're discussing the path of a reflected ray of light, and they make a statement that seems kind of un-intuitive to me.</p>

<p>Consider the three points in the plane P, Q, and R such that:</p>

<p>$P:(0, a)\\Q:(q, b)
\\R:(r, 0)$</p>

<p>R lies between P and Q. </p>

<p>The authors state that vis-a-vis the triangle inequality, </p>

<p>$\sqrt{a^2+r^2}+\sqrt{b^2+(q-r)^2}\ge\sqrt{(a+b)^2+q^2}$</p>

<p>To me though, if we use the plain english version of the triangle inequality, that is, the sum of the lengths of any two sides of a triangle is greater than or equal to the length of the third, we should get this:</p>

<p>$\sqrt{a^2+r^2}+\sqrt{b^2+(q-r)^2}\ge\sqrt{(b-a)^2+q^2}$</p>

<p>I'm aware that the triangle inequality states that:</p>

<p>$\sqrt{x_1^2+y_1^2}+\sqrt{x_2^2+y_2^2}\ge\sqrt{(x_1+x_2)^2+(y_1+y_2)^2}$</p>

<p>And by this definition, the authors' statement makes perfect sense. However, from a geometric standpoint, I just can't seem to make heads or tails of this. Can someone sort this out for me?</p>
",geometry
"<p>Consider a regular n-gon with side length $A$.</p>

<p>Let $p$ be a point in the polygon.
Let the distances from $p$ to the corners of the n-gon be $x_1,x_2,...,x_n$</p>

<p>Are there solutions with $A,x_1,x_2,...x_n$ all positive integers and $gcd(A,x_1,x_2,...,x_n) = 1$.</p>

<p>For the triangle ( $n=3$) this question has been answered already here</p>

<p><a href=""http://math.stackexchange.com/questions/485755/do-there-exist-an-infinite-number-of-rational-points-in-the-equilateral-triang"">Do there exist an infinite number of &#39;rational&#39; points in the equilateral triangle $ABC$?</a></p>

<p><a href=""http://mathoverflow.net/questions/180191/rational-distance-from-vertices-of-an-equilateral-triangle"">http://mathoverflow.net/questions/180191/rational-distance-from-vertices-of-an-equilateral-triangle</a></p>

<p>--</p>

<p>I assume for sufficiently large $n$ there are no solutions ?</p>

<p>In particular im intrested in $n=4,5,6$.</p>
",geometry
"<p>Struggling to begin answering the following question:</p>

<blockquote>
  <p>Let $L$ be the line given by $x = 3-t, y= 2+t, z = -4+2t$. $L$ intersects the plane $3x-2y+z=1$ at the point $P = (3,2,-4)$. Find parametric equations for the line through $P$ which lies on plane and is perpendicular to $L$.</p>
</blockquote>

<p>So far, I know that I need to find some line represented by a vector $n$ which is orthogonal to $L$. So, with the vector of $L$ represented by $v$, I have:</p>

<p>$$n\cdot v = 0 \Rightarrow [a, b, c] \cdot [-1, 1, 2] = 0 \Rightarrow -a + b + 2c = 0$$</p>

<p>I am not sure how to proceed from here, or if I am even on the right track.</p>
",geometry
"<p>Input parameters:
space dividor (number), vector (vec2)</p>

<p>Desired result:
Divide space in $X$ sectors, then move all vectors to one sector. (Angle of any vector wont be larger then $360/X$.)</p>

<p>Example of behavior that I made but seems to long:</p>

<ul>
<li>First, calculate $360$/space dividor which results in angle that we use as modulo. </li>
<li>Lets say we have space divider $6$, so $360/6 = 60$</li>
<li>Then calculate angle of the given vector. </li>
<li>Lets say the result is $173$°</li>
<li>Do modulo$(173, 60) = 53$</li>
<li>Now create new unit vector with $53$°</li>
<li>Calculate length of given vector</li>
<li>Result is unit vector multiplied by length. </li>
</ul>

<p>My question is, is there any shorter way to achieve same result? </p>
",geometry
"<p>What does $\rho$ mean as to be measured along geodesics and more importantly how would i be able to parametrize this accordingly as being on the sphere's surface? </p>

<p>I know that I have to use the First fundamental Form, but struggle to use it as well............the path is in 3-D space (ie, great circle). </p>

<p>So how can I get around this? As a result of not being able to figure out the usage of $\rho$ I am unable to do part c). Finding the area.  </p>

<p><a href=""http://i.stack.imgur.com/k4XZb.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/k4XZb.png"" alt=""enter image description here""></a></p>
",geometry
"<p>A triangle $\bigtriangleup ABC$ is given, and let the external angle bisector of the angle $\angle A$ intersect the lines perpendicular to $BC$ and passing through $B$ and $C$ at the points $D$ and $E$, respectively. Prove that the line segments $BE$, $CD$, $AO$ are concurrent, where $O$ is the circumcenter of $\bigtriangleup ABC$.</p>

<p>I've seen this problem on AOPS site,and I've read that the condition for $BE,CD,AO$ to be concurrent is the following :</p>

<p>$$\frac{\sin BAO}{\sin OAC}.\frac{\sin ACD}{\sin DCB}.\frac{\sin EBC}{\sin EBA}=1$$</p>

<p>But I can't see the reason behind it... I know both Ceva and Menelaus's Theorem but I don't see how one of them is applied to give the condition above. </p>

<p>So I am asking if there's some theorem I am missing out or if that condition is just a rearranged form of Ceva\Menelaus's Theorem applied to some triangle I can't see.</p>

<p><a href=""http://i.stack.imgur.com/tTzgz.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/tTzgz.png"" alt=""enter image description here""></a></p>
",geometry
"<p>The original problem can be found here:
<a href=""http://www.qbyte.org/puzzles/puzzle07.html"" rel=""nofollow"">Nick's Mathematical Puzzle 62: Four squares on a quadrilateral</a> : <em>Squares are constructed externally on the sides of an arbitrary quadrilateral. Show that the line segments joining the centers of opposite squares lie on perpendicular lines and are of equal length.</em></p>

<p>$ABCD$ is an arbitrary quadrilateral; $E,F,G$ and $H$ are centers of squares outside the quadrilateral. Prove $EF\bot GH$ and $\overline{EF}= \overline{GH}$.
<img src=""http://i.stack.imgur.com/2XbYZ.png"" alt=""enter image description here""></p>

<p><a href=""http://www.qbyte.org/puzzles/p062s.html"" rel=""nofollow"">The solution</a> presented is using the geometric meaning of complex numbers.</p>

<p>Is there any pure geometric approach to prove it?</p>
",geometry
"<p>When I look at the Taylor series for $e^x$ and the volume formula for oriented simplexes, it makes $e^x$ look like it is, at least almost, the sum of simplexes volumes from $n$ to $\infty$. Does anyone know of a stronger relationship beyond, ""they sort of look similar""?  </p>

<p>Here are some links:<br>
Volume formula<br>
<a href=""http://en.wikipedia.org/wiki/Simplex#Geometric_properties"" rel=""nofollow"">http://en.wikipedia.org/wiki/Simplex#Geometric_properties</a></p>

<p>Taylor Series<br>
<a href=""http://en.wikipedia.org/wiki/E_%28mathematical_constant%29#Complex_numbers"" rel=""nofollow"">http://en.wikipedia.org/wiki/E_%28mathematical_constant%29#Complex_numbers</a></p>
",geometry
"<p>I read <a href=""http://math.stackexchange.com/questions/625/why-is-the-derivative-of-a-circles-area-its-perimeter-and-similarly-for-spheres"" rel=""nofollow"">this question</a> the other day and it got me thinking: the area of a circle is $\pi r^2$, which differentiates to $2 \pi r$, which is just the perimeter of the circle. </p>

<blockquote>
  <p>Why doesn't the same thing happen for squares? </p>
</blockquote>

<p>If we start with the area formula for squares, $l^2$, this differentiates to $2l$ which is sort of right but only <em>half</em> the perimeter. I asked my calculus teacher and he couldn't tell me why. Can anyone explain???</p>
",geometry
"<p>It is well known that the Earth spins on its axis. It is also well known that the Earth's axis also precesses, i.e. spins around a secondary axis, much more slowly. Less well known is that we have seen asteroids that seem to tumble through space, with precession rates on roughly the same order of magnitude as rotation rates. My question is, why haven't we seen many instances of higher orders of rotation (where the secondary axis spins around a tertiary axis, the tertiary axis spins around a quaternary axis, etc.)? Can rotations of a high enough order always be expressed in terms of lower-order rotations at higher rates of rotation, or do higher-order rotations eventually decay into lower-order ones (as, for example, rotating around the $x$, $y$, $z$, and $x$ axes, all at the same rate*, produces an about-face, a seemingly impossible behavior)? (The latter seems to be stated by a comment on <a href=""http://math.stackexchange.com/questions/44696/arent-asteroids-contradicting-eulers-rotation-theorem"">this question</a>, but it doesn't go into much explanation.)</p>

<p>*This generates the matrix $$\begin{pmatrix}
  \cos^2t &amp; \sin t\cos t(\sin t-1) &amp; \sin t(\sin t+\cos^2t) \\
  \sin t(\sin t+\cos^2 t) &amp; \cos t(\sin^3t-\sin^2t+\cos^2t) &amp; \sin t\cos^2t(\sin t-2) \\
  \sin t\cos t(\sin t-1) &amp; \sin t(\sin^3t+2\cos^2t) &amp; \cos t(\sin^3t-\sin^2t+\cos^2t) \\
 \end{pmatrix}$$
with the about-face occurring at $t=\pi/2$.</p>
",geometry
"<p><img src=""http://i.stack.imgur.com/bVgHa.png"" alt=""enter image description here""></p>

<p>How to find  angle x without using calculator? 
By using the trigonometric ratio formula, we can evaluate x but  in this case calculator is necessary. </p>
",geometry
"<p>Given 4 points (lP1, lP2, lP3, lP4) ordered from highest y value to lowest, and when y values equal each other, it is sorted from lowest x to highest x, based in a regular mathematical Quadrant I (not inverted as it typically would be for Computer Science). Based off of this, what is the best way to determine from which points lines should be drawn to create a non self-intersecting Quadrilateral?</p>
",geometry
"<p>In the coordinate plane, the vertices of a quadrilateral are (-4,-2), (8,5), (6,8), and (-1,6). What are the coordinates of the point in the plane for which the sum of the distances from this point to the vertices of the quadrilateral are minimum?</p>

<p>What would be the best way to tackle this problem and would it involve am-gm?</p>
",geometry
"<p>Seeing as proving the existence and/or uniqueness of the Levi-Civita connection seems to crop up in every single exam in Geometry and General Relativity, what is the most succinct proof of this, to memorize.</p>
",geometry
"<p>Given a square $ABCD$ such that the vertex $A$ is on the $x$-axis and the vertex $B$ is on the $y$-axis. The coordinates of vertex $C$ are $(u,v)$. Find the area of square in terms of $u$ and $v$ only.</p>

<p><strong>What I have done</strong></p>

<p>Let the coordinate of $A$ be $(x,0)$ and $B$ be $(0,y)$. Also let the side of the square be a units.</p>

<p>$2a^2=AC^2=(x-u)^2+v^2$</p>

<p>$a^2$ is the required area so if we write $x$ in terms of $u$ and $v$ then the job will be done. </p>

<p>Now from here I thought of two ways either using trigonometry or using rotation of axes but here none of them will work because some angles will be involved and we require just $u$ and $v$ and nothing else in the expression of the area of square.</p>

<p>So how to do it? Please help.</p>
",geometry
"<p>There is a well known theorem often stated as the angle in a semi-circle being 90 degrees. To be more accurate, any triangle with one of its sides being a diameter and all vertices on the circle has its angle opposite the diameter being 90 degrees. The standard proof uses isosceles triangles and is worth having as an answer, but there is also a much more intuitive proof as well (this proof is more complicated though).</p>
",geometry
"<p>In the given figure, $AD||BC||EF$, $AB||DE$ &amp; $BE||AF$. Prove that :$||gm ABCD=||gm BEFG$<a href=""http://i.stack.imgur.com/KGn4Q.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/KGn4Q.jpg"" alt=""enter image description here""></a></p>

<p>Attempt </p>

<p>Joining $BD$, I got:</p>

<p>$$\triangle ABD=\triangle BCG$$
If $AG$ intersects $BD$ at $O$
$$\triangle AOB +\triangle AOD=\triangle BOG+quad. OGCD$$</p>

<p>Now what should I do next? </p>
",geometry
"<p>The <a href=""http://en.wikipedia.org/wiki/Pythagorean_theorem"">Pythagorean Theorem</a> is one of the most popular to prove by mathematicians, and there are <a href=""http://www.cut-the-knot.org/pythagoras/"">many proofs available</a> (including one from <a href=""http://en.wikipedia.org/wiki/James_A._Garfield"">James Garfield</a>).  </p>

<p>What's the most elegant proof?</p>

<p>My favorite is this graphical one:</p>

<p><img src=""http://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Pythagorean_Proof_%283%29.PNG/220px-Pythagorean_Proof_%283%29.PNG"" alt=""alt text""></p>

<p>According to cut-the-knot:</p>

<blockquote>
  <p>Loomis (pp. 49-50) mentions that the
  proof ""was devised by Maurice Laisnez,
  a high school boy, in the
  Junior-Senior High School of South
  Bend, Ind., and sent to me, May 16,
  1939, by his class teacher, Wilson
  Thornton.""</p>
  
  <p>The proof has been published by Rufus
  Isaac in Mathematics Magazine, Vol. 48
  (1975), p. 198.</p>
</blockquote>
",geometry
"<p><img src=""http://i.imgur.com/cy7f8Zt.png"" alt=""Triangle""></p>

<p>Please view the picture above. </p>

<ul>
<li>It is an isosceles triangle</li>
<li>It is mirror symmetric, all circles are EQUAL in radius.</li>
<li>Let the green and purple angles be P and G. Let's assume that Green = 75 deg, Purple = 30 deg (could be different, is it possible to have these as variable?)</li>
<li>I am looking to find the BLUE and RED angles, given the values of P and G.</li>
<li>The value of P and G are determined by how the circles are placed, basically it depends on radius of the circles as well as arc sector length. <strong>(check below)</strong></li>
<li>Note that, the angles are formed by the tangent of the circles, at the intersection point (Not necessarily equal to P or G for example)</li>
</ul>

<p>The following picture is a better example of my last point</p>

<p><img src=""http://i.imgur.com/QMm01Ds.png"" alt=""Triangle 2""></p>

<p>The only difference in those picture, is that the circles are closer together, same size, different arc length</p>

<p>(different view, to show the interior angles)</p>

<p><img src=""http://i.imgur.com/ey0JzY9.png"" alt=""Triangle""></p>

<p>If you look at this picture, I consider arc length is more like ""arc sector"", from point G to point C.</p>

<p><img src=""http://i.imgur.com/TfJSyFY.png"" alt=""Arc Length""></p>

<p>Since it's an isosceles triangle and symmetrical, two of the circles will have the same arc length (let's call it L1), and other one, the bottom circle, will be L2.</p>

<p>Radius is R</p>

<p><em>Is there a way to determine a relationship between the angles, L1, L2 and R? If a simple ""plug and chug"" formula is not possible, then could there be a non-linear relationship that I could use?</em></p>

<p>Or one for each angle.</p>

<p>Thank you all!</p>

<p>Note: I may have asked a similar question before, but I had the wrong picture in my mind when I drew it, therefore I doubt it could have been solved.</p>

<p>Some clarification:</p>

<blockquote>
  <p>There are 3 circles of equal radius (known as fact). The ""triangle"" is for visual purpose to simplify the problem, its vertices are the intersection of the circles. My problem has 3 circles, intersecting like that, with one being a bit lower which forms an isosceles triangle when joining points. I want to find the angle formed by the tangent lines at the intersection point, as a function of arc length (sector) and radius. Again, the triangle came to be AFTER I laid down the circles, circles are defined arbitrarily on a plane (keeping symmetry of course)</p>
</blockquote>
",geometry
"<p>It is known that calculating the volume of the <a href=""https://en.wikipedia.org/wiki/Birkhoff_polytope"" rel=""nofollow"">Birkhoff polytope</a> in higher dimension is still open.</p>

<p>I am not very good at it. I am trying to understand  why it is complicated. It would be really great if someone could explain it easily. Any link or reference will be appreciated. Thank you.</p>
",geometry
"<p>Given N points on a 2D grid of the form (X,Y) we need to find to find all the points (R,S) such that the sum of the distances between the point (R,S) and each of the N points given is as small as possible.</p>

<p>Distance measurement b/w 2 points is done as follows</p>

<p>distance between the points (A,B) and (C,D) = |A-C| + |B-D|.</p>

<p>Also :</p>

<p>1) In the N given points some points can be repeated
2) (R,S) can also be any of the N given points
3) All points must have integer co-ordinates.</p>

<p>Constraints:
$N \le 1000$,
$-10^8 \le X \le10^8$,
$-10^8 \le Y \le10^8$</p>

<p>One Such Input is as follows</p>

<p>N = 5</p>

<p>The 5 points are as follows
$(0, 0),
(-1, 0),
(1, 0),
(0, 1),
(0, -1)$</p>

<p>The number of points (R,S) is 1.</p>

<p>I have written a code for this but for large inputs it times out. I can paste the code here for reference. What i did was to form a polygon that surrounds all of these N points given and within this polygon calculate all the other points for smallest possible distance. But this technique won't work as values of X and Y are huge. Can You suggest me any formula of some sort or any observation so that it becomes easier for me to evaluate this function.</p>

<p>Thanks in advance</p>
",geometry
"<p>How could I prove that the three Euclidean inequalities (given the three sides) are the necessary and sufficient conditions for the existence of a triangle? I have tried to solve it and look it up in many books but I did not find this proof.</p>

<p>Thank you, </p>

<p>Antonio Squadri</p>
",geometry
"<p>I'm having some trouble proving a theorem of Neutral Geometry. First, allow me to clearly state what we are allowed to assume in Neutral Geometry:</p>

<ol>
<li><p><a href=""http://en.wikipedia.org/wiki/Hilbert%27s_axioms#I._Incidence"" rel=""nofollow"">Hilbert's incidence axioms</a></p></li>
<li><p><a href=""http://en.wikipedia.org/wiki/Hilbert%27s_axioms#II._Order"" rel=""nofollow"">Hilbert's order axioms</a></p></li>
<li><p><a href=""http://en.wikipedia.org/wiki/Hilbert%27s_axioms#III._Congruence"" rel=""nofollow"">Hilbert's congruence axioms</a></p></li>
<li><p>We are $\textbf{NOT}$ allowed to assume Hilbert's Euclidean parallel postulate (which means we cannot use the converse of the AIA theorem) and we are $\textbf{NOT}$ allowed to assume Dedekind's Axiom (which means we cannot draw a bijection between angle sizes and real number degree measures). Every proof I have found from searching online involves implicitly assuming one of those two axioms, but they don't necessarily hold in Neutral Geometry.</p></li>
</ol>

<p>Having said that, here's the theorem I'm trying to prove:</p>

<p>If $\square ABCD$ is a rectangle, then $\overline{AB}\cong\overline{DC}$ and $\overline{AD}\cong\overline{BC}$. Here's my attempted proof:</p>

<p>$\textit{proof}$:</p>

<ol>
<li><p>Suppose $\square ABCD$ is a rectangle.</p></li>
<li><p>$\overline{AD}\cong\overline{AD}$ because $\cong$ is reflexive.</p></li>
<li><p>$\sphericalangle A\cong\sphericalangle D$ because $\sphericalangle A$ and $\sphericalangle D$ are right angles and all right angles are congruent.</p></li>
<li><p>$\textbf{Suddenly, a miracle occurs, and we find that}$ $\sphericalangle CAD\cong\sphericalangle BDA$.</p></li>
<li><p>By 2, 3, 4, and the ASA criterion for triangle congruence, we find that $\triangle CDA\cong\triangle BAD$.</p></li>
<li><p>By 5, $\overline{AB}\cong\overline{DC}$.</p></li>
<li><p>Use a similar argument to show that $\overline{AD}\cong\overline{BC}$ $\blacksquare$</p></li>
</ol>

<p>Can someone help me fill in the justification for step 4? Is it even possible to justify step 4 in Neutral geometry?</p>

<p>Thanks for your help,</p>

<p>Jay</p>
",geometry
"<p>I am super new to olympiad-style math which focuses on a lot of inequalities, and tough problems which highschool students do not go over. I'm in 9th grade, and am trying to get into all of this stuff just so that I can win a few math competitions, and just become a better math student overall.</p>

<p>I'm starting off with inequalities, which seem very prevalent in olympiad math. They seem quite daunting to me, but I guess if I start step by step, I'll improve with a lot of practice.</p>

<p>To start off learning inequalities, I've begun with the AM-GM Inequality, learning it, practising &amp; perfecting it. In addition to this, I check out some external sources like the Cauchy-Schwarz Master Class, which was a book suggested to me by another user on this website. I skimmed through it very quickly, and it turned out to be something I was looking for. It has a section on AM-GM Inequality, which is what I'm starting with, which is nice. I'll be proceeding to Cauchy-Schwarz straight after, I guess.</p>

<p>I have trouble kind of understanding what it is some people do with AM-GM though. I also see many authors and people use AM-GM to solve a particularly daunting inequality which I could NEVER solve. When they explain their logic, and how they may use the AM-GM inequality to solve the problem, hey, it makes sense, it actually is logical and I can kind of appreciate how they did it all. But I don't understand where they get all these ideas and solutions from, I feel like I'm supposed to memorize whatever number of cases there are for AM-GM, and to somehow apply them when I'm faced with another question involving it. I don't know how to become necessarily proficient at it.</p>

<p>Since I'm super new to this, the only thing I'm really doing is reading the Cauchy-Schwarz Master Class, practicing a few of these AM-GM problems on AoPS forums, and looking up YouTube tutorials regarding AM-GM whenever I can.</p>

<p>If someone could help me out with learning AM-GM further, that would be very helpful. </p>

<p>Also, if you guys don't mind-- as a separate super noob question, I must ask,</p>

<p>The author of the Cauchy-Schwarz Master Class takes the inequality,</p>

<p>$xy &lt; (x^2 / 2) + (y^2 / 2)$</p>

<p>Which makes perfect sense to me, and then he says:</p>

<p>Let's replace x and y with their square roots, and then go on from there, which I don't really get.</p>

<p>Would we then get,</p>

<p>$\sqrt{xy} &lt; (x / 2) + (y / 2)$?</p>

<p>They then end up with,</p>

<p>$4\sqrt{xy}&lt; 2x + 2y$,</p>

<p>I see the author relates that inequality to the areas &amp; perimeters of squares and rectangles, which I kind of understand. Could we use that fact to then apply the AM-GM inequality to optimization problems for rectangles/squares? </p>

<p>I don't completely understand how the author got $4sqrt(xy) &lt; 2x + 2y$, I also don't understand how that inequality relates to anything. If I were to guess, I guess I'd say 4 times the square root of the area of the rectangle, will always be less than the perimeter of the square?</p>

<p>I'm in 9th grade and a COMPLETE beginner when it comes to this, so help would be really greatly appreciated. I just need someone to clear up things for me.</p>

<p>Thanks.</p>
",geometry
"<p>Of triangle ABC, I am given the coordinates of two points (A and B) and the angles between the side AB and each of the two other sides. </p>

<p>How can I get the coordinates of point C?</p>
",geometry
"<p>I don't understand this really good and couldnt find anything helpful on internet. I only found in book the following: A is the matrix with reflection over line through the origin with direction vector $\left(\cos(\frac{\alpha }{2} ) , \sin(\frac{\alpha }{2} ) \right) ^{T}$
$A=\begin{pmatrix} \cos(\alpha ) &amp; \sin(\alpha ) \\ \sin(\alpha )  &amp; -\cos(\alpha )    \end{pmatrix}$
I'm not sure how to connect this from book to solve it, because there is another direction vector.</p>
",geometry
"<p>It is given that in a triangle ABC, a line from A to BC intersects BC at point D. If the ratio in which AD divides BC is given can we say anything about the ratio of areas of triangle ABD and triangle ADC ?  </p>

<p><img src=""http://i.stack.imgur.com/zC5iw.jpg"" alt=""enter image description here""></p>
",geometry
"<p>I've been struggling trying to understand how to find the center of a circle given 4 points in the circumference $(x_1,y_1),(x_2,y_2),(x_3,y_3),(x_4,y_4)$</p>

<p>Please help me. I don't understand when the polygon created is not a rectangle p.ex..</p>
",geometry
"<p>Let $Z_2$ be the group with $2$ elements. Let $a\in Z_2$ be the nontrivial element. </p>

<p>Let $S^n$ be the $n$-sphere. Let $C(S^n,2)=\{(x,y)\in S^n\times S^n\mid x\neq y\}$.</p>

<p>Let $a$ act on $C(S^n,2)$ by
$
a(x,y)=(y,x).
$
And $a$ act on $S^1$ by antipodal map $a(e^{i\theta})=e^{i(\theta+\pi)}$.</p>

<p>Consider a fibre bundle with fibre $S^1$ and base space $ C(S^n,2)/Z_2$</p>

<p>$$
\xi: S^1\to C(S^n,2)\times_{Z_2}S^1\to C(S^n,2)/Z_2. 
$$
How to detect whether the bundle is  trivial or not?</p>
",geometry
"<p>The square of the side opposite a MUNDANGLE in a triangle is equal to the sum of the squares of the other two sides added to the product of these two sides multiplied by $\sqrt{3}$. What is MUNDANGLE?</p>

<p>This was an extra credit problem on my test, but my teacher said we had to do it for homework.</p>

<p>If anyone could support me and lead me to through the problem that would be great</p>
",geometry
"<p>Computational geometry?
(Computational geometry) Given a set of n randomly scattered points for even
n = 2,4,6,...,50 . Find the maximum number of lines between the pairs of nodes in
such a way the lines do not cross each other.</p>
",geometry
"<p>I want to show the following:</p>

<p>Let $A,B \subseteq \mathbb{R}^n$ disjoint, nonempty, closed and convex sets. Then there exists a $h \in \mathbb{R}^n$, such that $A$ and $B$ gets separated in the following way:
$$
 \langle b, h \rangle \le \langle a, h \rangle \quad \forall a \in A, b \in B.
$$
I have the following proof: Consider $C := B - A$, which is convex too. Because $A$ and $B$ are disjoint, it must be that $0 \notin C$. (*) Then there exists a $h$ such that $\langle c, h \rangle \le 0$ for all $c \in C$ or $\langle c, h \rangle \ge 0$ for all $c \in C$. WLOG let $\langle c, h \rangle \le 0$, then
$\langle b - a, h \rangle \le 0$, which means $\langle b, h \rangle - \langle a, h \rangle \le 0$, i.e. $$\langle b, h \rangle \le \langle a, h \rangle.$$</p>

<p>But (*) uses the fact that: For every convex set $X$ and a point $u \notin X$, there exists a $h$ such that $\langle u, h \rangle = 0$ and $\langle x, h \rangle \le 0$  for all $x \in X$ or $\langle x, h \rangle \ge 0$  for all $x \in X$.</p>

<p>Which I feel is geometrically true because the Elements $h$ could be identified with hyperplanes, but I am not sure how to proof this?</p>
",geometry
"<p>Below is a puzzle of counting triangles.How to solve such puzzle ?</p>

<p><img src=""http://i.stack.imgur.com/xrLlr.jpg"" alt=""enter image description here""></p>

<p>source:
<a href=""http://gpuzzles.com/mind-teasers/how-many-triangles-challenge/?source=stackmath"" rel=""nofollow"">http://gpuzzles.com/mind-teasers/how-many-triangles-challenge/?source=stackmath</a></p>
",geometry
"<p>Pick's theorem asserts that, given a simple lattice polygon $p$ in $\mathbb{R}^{2}$, if $I$ is the number of lattices inside $p$ and $B$ is the number of lattices on the boundary of $p$, then the area of $p$ equals $I + B/2 - 1.$ For example, if $p$ is the right triangle determined by the lattices $(0, 0)$, $(0, 1)$, and $(1, 0)$ then we have $I = 0$ and $B = 3$ so that the area $1/2$ of $p$ equals $I + B/2 - 1.$</p>

<p>Since it seems in principle that we can apply this theorem to a plane triangle $q$ in $\mathbb{R}^{3}$, I am wondering then how we can obtain $I$ and $B$ for $q$?    </p>
",geometry
"<blockquote>
  <p>Is the square of 2013×2013 can be divided into rectangles 1×3 in such
  a way that the number of rectangles arranged vertically differ by 1
  from the number rectangles arranged horizontally? Prove your answer</p>
</blockquote>

<p>I totally have no idea how to solve that. I need accurate solutions or good hints. </p>
",geometry
"<p>Is there a geometric interpretation of second order linear partial differential equations which explains why they are classified as either elliptic, hyperbolic or parabolic, or is this just a naming convention? That is, do they have any relation with actual ellipses, hyperbolas and parabolas?</p>
",geometry
"<p>Related to the proposition $6$ (page $820$) of the article <a href=""http://www.math.chalmers.se/~rowlett/monthly.pdf"" rel=""nofollow"">Sound of Symmetry</a>, could anyone be able to tell me why the $3$-gon $P$ is equilateral (they use the Steiner's fundamental theorem (page $819$).) I think this is a trivial question, but I am stuck to answer it.</p>

<blockquote>
  <p><strong>Steiner's fundamental theorem :</strong> Among all triangles with the same base and height, the isosceles has the smallest perimeter.</p>
</blockquote>

<p>Thanks!</p>
",geometry
"<p>I have been working on <a href=""http://math.stackexchange.com/questions/756253/triangles-packed-into-a-unit-circle"">this problem</a> for quite a while and it seems necessary to prove or disprove this particular problem.</p>

<p>Suppose $T$ is the set of all possible triangles made from the vertices of a given convex polygon $A$. </p>

<p>If $A$ has 3 to 4 vertices, the smallest triangle in $T$ will always be made from <em>three adjacent vertices</em>. </p>

<p>Is true for all convex polygons?
If not, what can we state about the minimum triangle?</p>
",geometry
"<p>The notion (rank-2) ""tensor"" appears in many different parts of physics, e.g. stress tensor, moment of inertia tensor, etc.</p>

<p>I know mathematically a tensor can be represented by a 3x3 matrix. But I can't grasp its geometrical picture — unlike scalar (a number) and vector (an arrow with direction and magnitude) which I can easily see what's going on.</p>

<p>How to visualize a tensor?</p>
",geometry
"<p>My function is $ x = \cosh(y)$ from $0 &lt; y &lt; a$ and to be rotated around the $y$-axis, where $a$ describes how big the object will be. (The object is said to be a vase.) The vase is to have a flat bottom.</p>

<p>We are given that the arc length is $\sinh(1.85)$ for the constant $a$. How big is the surface area of the vase?</p>

<hr>

<p>My problem lies with the constant $a$.</p>

<p>The standard formula for surface area is:</p>

<p>$$2\pi\int_a^b x ds $$</p>

<p>and this should result to:</p>

<p>$$2\pi\int_0^a \cosh(y) \sinh(1.85) $$</p>

<p>but I can't calculate this integral without knowing the constant $a$ and I have no idea how to do that.</p>

<p>Thanks in advance for any help :)</p>
",geometry
"<p>It's easy to find good recommendation for books here for any subject other than analytic geometry ,therefore I'd like to ask for any suggestion of analytic geometry books ,the only  charactrestic I'm looking for is a somewhat visual expostion.</p>
",geometry
"<p>I got stuck on this problem:</p>

<blockquote>
  <p>Given a convex quadrilateral of
  area $S$ and sides $a$, $b$, $c$ and $d$, 
  prove that: 
  $$S \leq \frac{(a+b)(c+d)}4$$</p>
</blockquote>

<p>What I've done so far was to proof that $$S \leq \frac{(a+c)(b+d)}4$$ using the realtion that for a given triangle $ABC$,   $A_{ABC} \leq \frac12 {AB}\cdot{AC}$ or $A_{ABC} \leq \frac12 {AB}\cdot{BC}$ etc.
This is derived from $A_{ABC} = \frac12 AB \cdot AC \cdot \sin (BAC)$ and $0&lt;\sin (BAC)\leq1$. </p>

<p>Anyway, this isn't enough to solve the problem. Some suggestions would be appreciate.</p>

<p>Thanks!</p>
",geometry
"<p>Given an initial position and a subsequent position, each given by latitude and longitude in the WGS-84 system.  How do you determine the heading in degrees clockwise from true north of movement?</p>
",geometry
"<p>Given a line <em>L</em> in three-dimensional space and a point <em>P</em>, how can we find the normal vector of <em>L</em> under the constraint that the normal passes through <em>P</em>?</p>
",geometry
"<p>From a point 5 meter above the water surface the angle of elevation of the top of a certain tree is 40 degree 10 minutes while the angle of depression of its image is 63 degree 20 minutes. Find the height of the tree and its distance from the point of observation</p>
",geometry
"<p>The absolute value of a $2 \times 2$ matrix determinant is the area of a corresponding parallelogram with the $2$ row vectors as sides.</p>

<p>The absolute value of a $3 \times 3$ matrix determinant is the volume of a corresponding parallelepiped with the $3$ row vectors as sides.</p>

<p>Can it be generalized to $n-D$? The absolute value of an $n \times n$ matrix determinant is the volume of a corresponding $n-$parallelotope?</p>
",geometry
"<p>The ellipse with equation $\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$ has one of its foci at the point $F$. The perpendicular from the origin to the tangent at a point $P(a\cos\theta, b\sin\theta)$ on the ellipse intersects the line $FP$ at a point $G$. Find the locus of $G$ as $\theta$ varies. </p>
",geometry
"<blockquote>
  <p>What does it mean for two triangles to be equally oriented?</p>
</blockquote>

<p>I have heard this term a lot but I haven't seen a definition of it. I know that in $3$-space two triangles are considered to be equally oriented if we can slide one on top of the other with the vertices aligning if they are similar or congruent. In $2$-space, though, it is more confusing to me. Below is a picture of equally oriented similar triangles $AMN$, $NBM$ and $MNC$ constructed on segment $MN$. I don't get why they are equally oriented though.</p>

<p>Also, does equally oriented only make sense if the triangles are similar or congruent?</p>

<p><a href=""http://i.stack.imgur.com/hjrNG.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/hjrNG.png"" alt=""enter image description here""></a></p>
",geometry
"<p>Given a line $AB$ such that $A(0,0,0)$ and $B(4,7,9)$. How can I obtain a point $C(x,y,z)$ of $\Delta ABC$ with $AB$, $AC$, and $BC$ known?</p>

<p>Any help will be appreciated!</p>
",geometry
"<p><strong>Question:</strong></p>

<blockquote>
  <p>If in a triangle with $A,B,C$ as the angles and $a,b,c$ as the sides opposite to the respective angles: $$\sin(A-B) = \frac{a}{a+b}\sin A\cos B - \frac{b}{a+b}\sin B\cos A$$ then prove that the triangle is isosceles.</p>
</blockquote>

<p>I started by using the identity of $\sin(A-B) = \sin A\cos B - \sin B\cos A$. However, I'm not sure how to proceed on from here. Comparing the coefficients doesn't lead me anywhere. A small hint would be appreciated.  </p>
",geometry
"<p>Given two vectors <strong>a</strong> and <strong>b</strong>, let <strong>c</strong> = <strong>a</strong> cos $\theta$ + <strong>b</strong> sin $\theta$. As we vary $\theta$ from $0$ to $2 \pi$,  <strong>c</strong> traces out an ellipse.</p>

<p>Can anyone tell me why this is true? </p>
",geometry
"<p>Task: In parallelogram OABC sides AB and BC have the centers D and E. Prove with vectors that vectors OD and OE divide the Diagonal vector AC into three equal parts.</p>

<p>I got this task from my teacher and i couldn't do it and i'd just like to see how it is supposed to be done just for my interest.</p>
",geometry
"<blockquote>
  <ol>
  <li><p>If each edge of a cube is increased by 25%, then what is the percentage increase in its surface area?</p></li>
  <li><p>If the length of a rectangle is increased by 20% and breadth of the rectangle is increased by 30%, what is the new area percentage compared to original area percentage of this particular rectangle?</p></li>
  </ol>
</blockquote>

<p>Please, can anyone explain the answer with logic and explanation? what is effective percentage, how can we calculate?</p>

<p>I have Tried this:</p>

<p>x+y+xy/100 using Formula, How this Formula Derived why we want to use this Formula Here</p>
",geometry
"<p>I'm trying to put the following equation in determinant form:
$12h^3 - 6ah^2 + ha^2 - V = 0$, where $h, a, V$ are variables (this is a volume for a pyramid frustum with $1:3$ slope, $h$ is the height and $a$ is the side of the base, $V$ is the volume). </p>

<p>The purpose of identifying the determinant is to construct a nomogram. I'm not sure if it actually can be placed in determinant form, and I'm curious if there is a Mathematica function that can do this?
I've been trying a pen and pencil approach as listed <a href=""http://www.projectrho.com/nomogram/determinant06.html"" rel=""nofollow"">here</a>. But this approach has hopefully been automated. </p>

<p>Any tips are appreciated!</p>
",geometry
"<p>If $k=\nabla\cdot n$, what is the geometric relationship between $k$ and $n$? 
In terms of size and direction?</p>

<p>Is it true that $n$ is an outward-pointing normal iff $k&gt;0$ and $n$ is inward-pointing iff $k&lt;0$?</p>
",geometry
"<blockquote>
  <p>How can I show that $\arctan (x) + \arctan(1/x) =\frac{\pi}{2}$?</p>
</blockquote>

<p>I tried to let $x = \tan(u)$. Then </p>

<p>$$ \arctan(\tan(u)) + \arctan(\tan(\frac{\pi}{2} - x)) = \frac{\pi}{2}$$</p>

<p>but it does not seem useful. </p>

<blockquote>
  <p>I'd appreciate most a proof that gives intuition and / or uses geometric
  insight.</p>
</blockquote>
",geometry
"<p>Take $n$ equally spaced points on a circle. Connect them by a cycle(circuit) with $n$ line segments. Two cycles are considered equivalent if same when rotated or reflected. How many cycles are there?</p>

<p><a href=""http://i.stack.imgur.com/KoJYq.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/KoJYq.png"" alt=""for n = 2, 3, 4, 5""></a></p>

<p>It can also be viewed as integer sequence.</p>

<p>Take an integer sequence $a_i(1 \leq i \leq n, \: 1 \leq a_i \leq n, \: a_i \neq a_j)$. Two sequences $a_n, \: b_n$ are considered equivalent if there exists some integers $k, \: l$ such that $a_i \equiv b_{i+l \bmod n}+k(\bmod n)$ or $a_{i+l} \equiv -b_{i+l \bmod n}+k(\bmod n)$</p>
",geometry
"<p>I'm working on a project involving thermoacoustics, and one of the important parameters is known as the hydraulic radius. If you have a pipe with some odd geometry, the hydraulic radius is its cross-sectional area of flow (i.e.: of the area not occupied by the shape) divided by its wetted perimeter.</p>

<p>The project I'm working on uses a ""stack"" for a certain component of the piping system. This comprises a series of plates with some thickness <code>t</code> and spacing <code>x</code> that fit within a tube. One of the plates is bisected widthwise by a diameter of the tube. If the thickness, number of plates, and tube diameter are known, what is the hydraulic radius of this shape?
<img src=""http://i.stack.imgur.com/ERMEW.png"" alt=""enter image description here""></p>

<p>The white area inside the red circle is the cross-sectional flow area
The perimeter of that white area is the wetted perimeter
The ratio of these two values is the value in question</p>
",geometry
"<p>From Wiki <a href=""https://en.wikipedia.org/wiki/Dual_polyhedron"" rel=""nofollow"">Dual polyhedron</a> </p>

<p>For example the smplices:</p>

<p>3-simplex (tetrahedron) is self-dual</p>

<p>2-simplex (triangle) is self-dual</p>

<p>1-simplex (line segment)  ??</p>

<p>hypercubes:</p>

<p>3-cube (cube) dual is octahedron</p>

<p>2-cube (square) dual is square, self-dual</p>

<p>1-cube (line segment) ??</p>

<p>In the above link you can see it says all regular simplices are self-dual, but I can't see how a line segment is self-dual. Shouldn't its dual have 1 vertex and 2 edges? How would you draw that? Is there a rigorous definition of duality in this geometric sense?</p>
",geometry
"<p>The question is as follows:</p>

<p>Let $E$ be an ellipse with major axis length $4$ and minor axis length $2$. Inscribed an equilateral triangle $ABC$ in $E$ such that $A$ lies on the minor axis and $BC$ is parallel to the major axis. Compute the area of $\triangle ABC$.</p>

<p><strong>My Work</strong>:</p>

<p><img src=""http://i.stack.imgur.com/7vzfj.png"" alt=""ellipse""></p>

<p>Pardon my lack of talent with paint, but you get the idea. Points $a$ and $b$ have coordinates $(-x,y)$ and $(x,y)$ respectively. The equation for the ellipse in question is $x^2/4 + y^2 = 1$, which yields $y = \frac{\pm\sqrt{4-x^2}}{2}$ when rearranged, but the triangle is in the upper half so we can say that $y = \frac{\sqrt{4-x^2}}{2}$ for simplicity. Both $a$ and $b$ are at a distance of $\sqrt{x^2+y^2}$ from the origin, and a distance of $2x$ from each other. Since this is an equilateral triangle, we can say that $$2x = \sqrt{x^2+y^2} \hspace{5 mm} \text{and}$$</p>

<p>$\hspace{67 mm} \displaystyle{y = \frac{\sqrt{4-x^2}}{2}},$</p>

<p>a system of equations that yield readily to substitution. From these equations, we get that $x = \frac{2\sqrt{13}}{13}$ and $y = \frac{4\sqrt{3}}{26}$. From the dotted lines in the diagram, I hope it's clear that the square's area is $4xy$, and the triangle is half the square, so its area is $2xy$. Multiplying everything together yields the result $\frac{8\sqrt{39}}{169}$. This is a tiny number, and it seems the actual answer is $\frac{192\sqrt{39}}{169}$. I've double checked my work, and have no idea where I went wrong. Any ideas on where I went wrong, or on how to get the correct answer?</p>
",geometry
"<p>The question is asking to show $S^1 \times S^1$ is homeomorphic to a torus. I have read some other posts in here but most of them are proving it with ""lattice"" which I haven't learn. Here is what I did, write down a function $f: T/\sim \text{}\rightarrow S^1 \times S^1$ </p>

<p>where $T= [0,1] \times [0,1]/\sim$ whit relation $(0,a)\sim(1,a)$, $(b,0)\sim(b,1)$ for $a,b \in [0,1]$</p>

<p>and</p>

<p>$$f(x,y)=(\cos(2\pi x),\sin(2\pi x),\cos(2\pi y),\sin(2\pi y))$$</p>

<p>And I wish to show that $f$ is a homeomorphism. (Recall from lecture, I need to show $f$ is a continuous bijection with continuous inverse $f^{-1}$.)</p>

<p>How do I show $f$ is a bijection and what is $f^{-1}$? Is that $f^{-1}(x,u,y,v)=(\mid \frac{1}{2\pi}\arccos(x)\mid,\mid \frac{1}{2\pi}\arccos(y)\mid)$</p>
",geometry
"<p>If $v_0, v_1,\ldots, v_n$ are such vectors, that:   </p>

<ol>
<li>$(v_j-v_0) $ is perpendicular to $(v_i-v_0) $ for any different $i,j=1,\ldots,n$   </li>
<li>$||v_i-v_0||=a, $ for any $ i=1,\ldots,n$   </li>
</ol>

<p>Then $n$-hypercube in $\Bbb R^n$ is defined this way:<br>
$K:= \{v \in \Bbb R^n \mid (v-v_0) = \alpha_1 (v_1-v_0) + \alpha_2 (v_2-v_0) + \ldots. +\alpha_n (v_n-v_0) ;\ \alpha_i \in [0,1] \}$<br>
and the set of dots in $K$:<br>
$W:= \{v \in \Bbb R^n \mid (v-v_0) = \alpha_1 (v_1-v_0) + \alpha_2 (v_2-v_0) + \ldots +\alpha_n (v_n-v_0) ;\ \alpha_i \in \{0,1\} \}$   </p>

<p>How can I find the number of diagonals in $n$-hypercube, which are perpendicular to one diaginal?</p>
",geometry
"<p>I have a $3$-D sphere of radius $R$, centered at the origin. </p>

<p>$(x_1,y_1,z_1)$ and<br>
$(x_2,y_2,z_2)$ are two points on the sphere. </p>

<p>The Euclidean distance is easy to calculate, but what if I were to restrict myself to traveling on the surface of the sphere?  </p>

<p>Two approaches come to mind: use <a href=""http://en.wikipedia.org/wiki/Arc_length"" rel=""nofollow"">arc-length</a> in some way, or simply use trigonometry: calculate the angle between the two points and get a distance from that.  </p>

<p>Will both/either of these methods work? Which would be easier?</p>

<p>Somewhat related to <a href=""http://math.stackexchange.com/questions/720/how-to-calculate-a-heading-vector-on-the-earths-surface"">this question</a>. Maybe it will inspire someone to go answer it!</p>
",geometry
"<p>RHS is a well known test for determining the <a href=""http://en.wikipedia.org/wiki/Congruence_%28geometry%29#Determining_congruence"" rel=""nofollow"">congruency of triangles</a>. It is easy enough to prove it works, simply use Pythagorus' theorem to reduce to SSS. I thought that it seems strange that this only works for an angle being 90 degrees - or does it? What if I tried changed the given angle to 89 degrees or 91 degrees, would it still be uniquely identified up to congruence?</p>
",geometry
"<p>I have a Point P in unit circle (on or in it) with a radius of r. How can I calculate a Point Q with a fixed radius of x, which has the same angle like P</p>
",geometry
"<p>Given $AB,AC$ tangents to two circles at points $B,C$ in the picture.</p>

<p><img src=""http://i.stack.imgur.com/8pidu.jpg"" alt=""enter image description here""></p>

<p>$AB=2AE$, $DE=10+AB$.</p>

<p>$O_1$ is the middle point of chord $DE$.</p>

<p>Need to prove that the point $O_1$ is the center of the left circle.</p>

<p>I can't see how it can be done.</p>

<p>I'd appreciate any help.</p>

<p>Thanks.</p>
",geometry
"<p>Show that the affirmation </p>

<blockquote>
  <p>""For every three points (not on the same line) on the plane, one can find a circle that contains these three points""</p>
</blockquote>

<p>is equivalent to </p>

<blockquote>
  <p>""Given a line and a point out of this line, there is only one line passing through this point and parallel to the first one"".</p>
</blockquote>

<p>I was able to show that the second affirmation implies the first one:</p>

<p>Consider a triangle ABC. Let M be the midpoint of AB. Mark P such that the angle PMA = 90° = PBM. Now, let N be the midpoint of BC. Using the second statement, there is only one line passing through N parallel to MP. This line can't be orthogonal to BC, otherwise we would have  a triangle with two rect angles. So, the line passing through N perpendicular to BC meets PM in a point O. Now, it's easy to construct such a circle.</p>

<p>But I couldn't prove the reciprocal...</p>
",geometry
"<blockquote>
  <p>A circular conductor, with cross section given by $(x-d)^2+y^2=b^2$, i.e. radius $b$ and centered on $x=d$, has a circular core, made up of the interior of the circle $x^2+y^2=a^2$, with $b-d&gt;a$, removed. A total current $I$ flows in the region between these two circles, with a uniform density, $J$ per unit area. By considering the magnetic field generated by a current density $J$ inside the circle $(x-d)^2+y^2=b^2$ and that generated by an equal and opposite current density in the circle $x^2+y^2=a^2$, show that the magnetic field inside the circle $x^2+y^2=a^2$ is constant with magnitude $\mu_0Id/(2\pi(b^2-a^2))$. In which direction does it point?</p>
</blockquote>

<p>I am having trouble understanding the setup of the above described situation. This is how I am interpreting it but I doubt it is right since the situation isn't very symmetrical. I also don't know what it means when it says the region $x^2+y^2=a^2$ with $a &lt; b - d$ is removed.  </p>

<p><a href=""http://i.stack.imgur.com/1aulC.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/1aulC.png"" alt=""enter image description here""></a> </p>
",geometry
"<p>Pick's theorem says that given a square grid consisting of all points in the plane with integer coordinates, and a polygon without holes and non selt-intersecting whose vertices are grid points, its area is given by: </p>

<p>$$i + \frac{b}{2} - 1$$</p>

<p>where $i$ is the number of interior lattice points and $b$ is the number of points on its boundary. Theorem and proof may be found on <a href=""http://en.wikipedia.org/wiki/Pick%27s_theorem"" rel=""nofollow"">Wikipedia</a>.</p>

<p>Let us suppose that the grid is not square but triangular (or hexagonal). Does a similar theorem hold?</p>
",geometry
"<p>I know there is a double covering map between SU(2) and SO(3) but I have no idea how I would go about proving this or showing this. </p>

<p>can someone point me in the right direction please?</p>
",geometry
"<p>Using only precalculus mathematics (including that the area of the triangle with vertices at the origin, $(x_1,y_1)$, and $(x_2,y_2)$ is half of the absolute value of the determinant of the $2\times 2$ matrix of the vertices $(x_1,y_1)$ and $(x_2,y_2)$, $\frac{1}{2}\cdot\left|x_1\cdot y_2 - x_2\cdot y_1\right|$) how can one prove that <a href=""http://en.wikipedia.org/wiki/Shoelace_Method"" rel=""nofollow"">the shoelace method</a> works for all non-self-intersecting polygons?</p>
",geometry
"<p>I haven't been able to find the parametric equations and specifications to form a triskelion, a triple spiral (this is made of three interlocked couples of spirals).</p>

<p>Using the parametric equation of an Archimedean spiral, I have tried this (in Matlab):</p>

<pre><code>% Centers of spirals
theta = [0:360*3] * pi / 180; r = theta;
x = r .* cos(theta); y = r .* sin(theta);
theta = [90:120:360] * pi / 180;
xy(:, 1) = cos(theta) * 2 * x(end) / sqrt(3);
xy(:, 2) = sin(theta) * 2 * x(end) / sqrt(3);

% First spiral of first couple
theta = [0:(360*3-60)] * pi / 180; r = theta;
x11 = r .* cos(theta); y11 = r .* sin(theta);
plot(x11 + xy(1, 1), y11 + xy(1, 2))
hold on

% Second spiral of first couple
theta = [0:(360*3+60)] * pi / 180; r = theta;
x21 = r .* cos(theta); y21 = r .* sin(theta);
plot(-x21 + xy(1, 1), -y21 + xy(1, 2))

% First spiral of second couple
theta = [0:(360*3)] * pi / 180; r = theta;
x12 = r .* cos(theta); y12 = r .* sin(theta);
plot(x12 + xy(2, 1), y12 + xy(2, 2))

% Second spiral of second couple
theta = [0:(360*3-120)] * pi / 180; r = theta;
x22 = r .* cos(theta); y22 = r .* sin(theta);
plot(-x22 + xy(2, 1), -y22 + xy(2, 2))

% First spiral of third couple
theta = [0:(360*3+120)] * pi / 180; r = theta;
x13 = r .* cos(theta); y13 = r .* sin(theta);
plot(x13 + xy(3, 1), y13 + xy(3, 2))

% Second spiral of third couple
theta = [0:(360*3)] * pi / 180; r = theta;
x23 = r .* cos(theta); y23 = r .* sin(theta);
plot(-x23 + xy(3, 1), -y23 + xy(3, 2))

axis equal, axis off
</code></pre>

<p>As you see it cannot work, only two spirals are interlocked (by construction).</p>

<p>How should the spirals be in order to obtain a nice triskelion?</p>
",geometry
"<p>There is rectangle pool with an area of 36 square-yards, then there is another pool of the same area, but with a smaller perimeter. How is this achieved? </p>
",geometry
"<p>I drew this picture to interpret my question.</p>

<p><img src=""http://i.stack.imgur.com/e0c6d.png"" alt=""enter image description here""></p>

<p>I have the x and y axis for all the vertices before rotating the object. And I have the angle of rotation, how can I find the x and y axis for the vertices after rotating the object.</p>

<p>Thanks</p>
",geometry
"<p>Is there any mathematical significance to the fact that the law of cosines...</p>

<p>$$
\cos(\textrm{angle between }a\textrm{ and }b) = \frac{a^2 + b^2 - c^2}{2ab}
$$</p>

<p>... for an impossible triangle yields a cosine $&lt; -1$ (when $c &gt; a+b$), or $&gt; 1$ (when $c &lt; \left|a-b\right|$)</p>

<p>For example, $a = 3$, $b = 4$, $c = 8$ yields $\cos(\textrm{angle }ab) = -39/24$.</p>

<p>Or $a = 3$, $b = 5$, $c = 1$ yields $\cos(\textrm{angle }ab) = 33/30$.</p>

<p>Something to do with hyperbolic geometry/cosines?</p>
",geometry
"<p>In triangle $DCB$, $BC = 10$ and is also the diameter. If the area of triangle $DCB = 11$, then determine the perimeter of the triangle.</p>

<p><img src=""http://i.stack.imgur.com/1pIsB.png"" alt=""enter image description here""></p>

<p>I am a little stuck on this problem. I tried using the sine rule with angle $D$ seeing that it equals 90. Can someone assist me or give me a hint please?</p>
",geometry
"<p>Is there an algorithm to determine the largest equilateral triangle in a convex polygon?</p>
",geometry
"<p>I have some polygons I would like to map onto the face of a cone.</p>

<p>I can see from <a href=""http://www.math.montana.edu/frankw/ccp/multiworld/multipleIVP/cylindrical/body.htm#skip3"" rel=""nofollow"">this page</a> that I can convert  the points of the polygon to cylindrical coordinates, which is almost what I want.</p>

<p>How do I go about modifying the formulas to work for conical coordinates?</p>
",geometry
"<p>There are irregular pentagons that tessellate. Is there some observable property?</p>

<p><img src=""https://i.stack.imgur.com/MVLmt.jpg"" alt=""Known irregular pentagons that tessellate, by year""></p>

<p>Please provide anything else you want to relative to the question, thank you!</p>
",geometry
"<p>This may be a poorly phrased question - please let me know of it - but what is the correct way to think of the cotangent bundle? It seems odd to think of it as the dual of the tangent bundle (I am finding it odd to reconcile the notions of ""maps to the ground field"" with this object).</p>
",geometry
"<p>In school, we learn that sin is ""opposite over hypotenuse"" and cos is ""adjacent over hypotenuse"".</p>

<p>Later on, we learn the power series definitions of sin and cos.</p>

<p>How can one prove that these two definitions are equivalent?</p>
",geometry
"<p>This was posed as a homework problem to me and I have made progress, but I don't think I have a solution.</p>

<p>So there are a lot of random points on the plane and we need to find a circle that contains exactly eight of them. The way I would attack this is to list the distances of each point pairs. Now take a pair (among perhaps several) that has a minimal distance. </p>

<p>I think that even if the minimal distances are equal, the most you can do with equal minimal distances without having a circle covering them is seven points (suspiciously one short of that eight!) by picking the centre of a circle and then six equidistant points on the circle (belonging to a 60 degree central degree). </p>
",geometry
"<p>When drawing an angle line (45 degrees) in a rectangle from a general point $p = (x,y)$ that located on the right or the top line of the rectangle. How can I find the intersection point $p2$ of this line with the rectangle?</p>

<p>In other words, I want to write the target point, $p2$, with my current information: $x, y, w, h$. (This variables are described in the picture below).</p>

<p>The point $(0,0)$ is in the top-right corner.</p>

<p><img src=""http://i.stack.imgur.com/vpcRR.jpg"" alt=""rect""> </p>
",geometry
"<p>So the projective plane $\mathbb{RP}^2$ is not a vector space.  Is it still isomorphic to its dual?  If not, is there at least an invertible map that takes $\mathbb{RP}^2$ to its dual?</p>
",geometry
"<p>If there is an unit circle and inscribed in it there is a regular n-sided polygon, what is the minimum number of circles with radius $1/2$ to cover the polygon completely?</p>
",geometry
"<p>in this picture a length of square edge is 8 cm. I want to calculate the radius of circle. i try to calculate it, but i don't know how.</p>

<p><a href=""http://i.stack.imgur.com/j32nQ.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/j32nQ.png"" alt=""enter image description here""></a></p>

<p>I calculate this:</p>

<p><a href=""http://i.stack.imgur.com/dubLO.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/dubLO.png"" alt=""enter image description here""></a></p>
",geometry
"<p>I'm reading the book ""Rational Points on Elliptic Curves"" and on page 23 the author takes an arbitrary (non-singular) elliptic curve in the projective plane and finds a rational point $O$, referring to it by $[1,0,0]$, and calling the line tangent to this point the line $Z=0$, a notation for a line I have never seen before but am assuming means that this line is supposed to be one of the new axes.  Then the third point of intersection of this line with the elliptic curve is referred to as $[0,1,0]$ and the line tangent to this point is called $X=0$ and finally a third line is drawn through $O$ and is called $Y=0$.</p>

<p>Here is a picture I made which mimics the one given in the book:</p>

<p><img src=""http://i.stack.imgur.com/nxYCs.png"" alt=""enter image description here""></p>

<p>Edit: I just realized my picture isn't exactly correct, the line $Y=0$ goes through $O$ but doesn't have to go through the third red point with no label.</p>

<p>I have some basic experience with the projective plane, but I have no idea what the author is doing here and how I should envisage these three lines as my new axes in the projective plane under some rational transformation or something.  Supposedly this is at least the first step in putting an elliptic curve into Weierstrass Normal Form, can someone explain this process to me?</p>
",geometry
"<p>In the figure $D$ and $E$ are the mid points of $AB$ and $AC$ respectively. $F$ and $G$ are two points on $BC$ such that $DG||EF$ then prove that $$2||gm DEFG=\triangle ABC$$</p>

<p><a href=""http://i.stack.imgur.com/D3Pis.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/D3Pis.jpg"" alt=""enter image description here""></a></p>

<p>My Attempt </p>

<p>$$DE||BC$$
$$DE=\frac {1}{2} BC$$
$$DEFG$$ is a parallelogram </p>

<p>$$DE=GF$$</p>

<p>Then what should I do next? </p>
",geometry
"<p>How can I calculate the maximum number of points that can be placed on the surface of a unit sphere, if any two points wont be closer than 1 unit? </p>
",geometry
"<p>I would like to show that $\arctan\left(\frac{1}{2}\right)$ is not a <a href=""http://mathworld.wolfram.com/ConstructibleNumber.html"" rel=""nofollow"">constructible number</a>.</p>

<p>I would like to use the following lemma:</p>

<blockquote>
  <p>Let $P(x)=x^3+ax^2+bx+c$ a polynomial with $a,b,c\in\mathbb{Q}$, if $P$ has no roots in $\mathbb{Q}$ then $P$ has no roots in $K$ (the set of constructible numbers).</p>
</blockquote>

<p>How can I judiciously choose $a,b,c$ to achieve this?</p>
",geometry
"<p>let $ABCD$ be an orthogonal tetrahedron.and the altitudes intersect $H$,and 
$$HA=a,HB=b,HC=c,HD=d$$</p>

<p>Find the $V_{A-BCD}$</p>

<p><img src=""http://i.stack.imgur.com/OuUhM.jpg"" alt=""enter image description here""></p>

<p>before to  solve this an orthogonal tetrahedron，I think we must first solve this problem</p>

<p>$\Delta ABC$,and  the altitudes intersect $H$,
$$HA=a,HB=b,HC=c$$</p>

<p>then Find this $S_{ABC}=$</p>

<p><img src=""http://i.stack.imgur.com/xUBCk.jpg"" alt=""enter image description here""></p>

<p><img src=""http://i.stack.imgur.com/xUBCk.jpg"" alt=""enter image description here""></p>

<p>let $R$ is circumradius of $ABC$,and we use this know
$$AH^2+BC^2=4R^2$$
$$BH^2+AC^2=4R^2$$
$$CH^2+AB^2=4R^2$$</p>
",geometry
"<blockquote>
  <p>Moderator Note: this is a question from the <a href=""http://www.mathe-wettbewerbe.de/bwm/bwm-wettbewerb-naechster-lauf"" rel=""nofollow"">Federal Mathematics Competition 2013</a>.</p>
</blockquote>

<p>So here's another quite complex problem: $P$ is a point in the interior of a square $ABCD$, such that $\angle DCP = \angle CAP = 25^\circ$. What is $\angle ***PBA***$?</p>

<p>Does anybody have any ideas on this problem? I tried to find as much angles as I could, but I just got stuck... </p>

<p>Hope for some good answers :)</p>

<p>Markus</p>
",geometry
"<p>A triangle has vertices (2,-2),(-2,2) and (0,6)need help finding incenter and Euler's line</p>

<p>This is a problem with many multiple parts like finding centroid, orthocenter, circumcenter. I have completed these parts, but do not know how to find the incenter or Euler's line. If someone could assist that would be great.</p>
",geometry
"<p><img src=""http://i.stack.imgur.com/eOywW.png"" alt=""slices of a triangle""></p>

<p><em>Figure description:</em> The point $(0, 0)$ is in the upper left corner. The coordinate system grows to the lower right corner. The short sides of the big triangle have the same length.</p>

<p>I want to slice up the blue area in the drawing into $n$ parts of equal area $A$. I know the values of $x_0$ and $x_n$ and I want to know the values of $x_i$ where $0 &lt; i &lt; n$.</p>

<p>I solved it for $n = 2$:</p>

<p>$$A = \frac{x_1^2}{2} - \frac{x_0^2}{2} = \frac{x_2^2}{2} - \frac{x_1^2}{2}$$</p>

<p>$$\cdots$$</p>

<p>$$x_1 = \sqrt\frac{x_0^2 + x_2^2}{2}$$</p>

<p>But how do I solve this for any $n$?</p>

<p><em>Context:</em> (Probably irrelevant for the mathematical problem.) The slices represent workload that I want to distribute to separate threads. Currently <a href=""https://github.com/panzi/numbers-rust/blob/master/numbers_unsafe_mt.rs"" rel=""nofollow"">my program</a> has 2 threads hard coded, but I want to make it configurable (because now I have an 8 core machine).</p>

<p>My program produces objects and then combines all the produces objects with each other to produce more objects. I distribute the combination operations across multiple threads. The blue area represents all combinations of the objects that where produces before (in the white area). The program stops if no new valid object can be created through combinations.</p>
",geometry
"<p>I'm looking for exercises similar to those seen on putnam exams or olympiad exams, such as finding the area of polygons inscribed other polygons, finding certain angles, etc.</p>
",geometry
"<p>How do I parametrize a triangle with vertices $A(1,1)$, $B(2,2)$ and $C(1,3)$?</p>

<p>I have tried working with the equations of the lines that form it but am not completely sure how to link them together to come up with a parametrization of the form $r(t)$.</p>
",geometry
"<p>show that out of all triangles inscribed in a circle the one with maximum area is equilateral</p>

<p>How do i start. I have to use function of two variables</p>

<p>Thanks</p>
",geometry
"<p>The problem is this:</p>

<p>Given two different points, $A$ and $B$, take the midpoint between them ($O$) draw the circumference $\Gamma (O,OA)$</p>

<p>Take any point $C$ on $AB$ and draw a line $t$ perpendicular to $AB$ through $C$</p>

<p>Take any point $P$ on $t$ as long as it lies in the interior of $\Gamma$ and draw $AP$ and $BP$ let these lines touch $\Gamma$ on $D$ and $E$ respectively. Take the midpoint $F$ of $D$ and $E$ and let $G$ be the intersection between $t$ and $OF$.</p>

<p>Show that $GE$ is tangent to $\Gamma$</p>

<p>The draw looks like this:
<img src=""http://i.stack.imgur.com/F7840.png"" alt=""draw""></p>
",geometry
"<p>I am speculating that the length is $2\pi$ because the circumference of a unit circle in $\mathbb{R}^2$ is $2\pi$. From my understanding, a great circle in  $\mathbb{S}^2$ would be a circle centered at the origin with a radius of 1.</p>

<p>Would anyone be able to confirm this?</p>

<p>Thank you.</p>
",geometry
"<p>The solution to Putnam 2000 A5 uses this formula, for which the following proof is given:
(source: <a href=""https://mks.mff.cuni.cz/kalva/putnam/psoln/psol005.html"" rel=""nofollow"">https://mks.mff.cuni.cz/kalva/putnam/psoln/psol005.html</a>)</p>

<hr>

<p>Let the sides (of triangle $ABC$) have lengths $a, b, c$ as usual. The question suggests that we use some relationship of the form $abc = constant \times R$. ...</p>

<p>To prove the relation, let $O$ be the centre of the circumcircle. Project $AO$ to meet the circle again at $K$. Let $AH$ be the altitude. <strong>Then angle $ABC = \angle AKC$</strong>, so triangles $ABH$ and $AKC$ are similar. Hence $\frac{AB}{AH} = \frac{AK}{AC}$ or $\frac{c}{AH} = \frac{2R}b$. Hence $abc = 2R·a·AH = 4\Delta R$.</p>

<hr>

<p>The bold part confuses me. How does $ABC = AKC$? $K$ is dependent wholly on $O$ and $A$ whereas $B$ is independent of both. And if $ABC = AKC$, how does that lead to $ABH \sim AKC$?</p>
",geometry
"<p>I would like to express the fact that a generic <a href=""https://en.wikipedia.org/wiki/Polytope"" rel=""nofollow"">Polytope</a> can be generated from other basic geometric shapes, for example this shape</p>

<p><img src=""http://i.stack.imgur.com/Zok3W.png"" alt=""enter image description here""></p>

<p>$C$ in this case is formed by a triangle + a quadrilateral, the catch that I want to communicate is that in this case my basic shape is a</p>

<ul>
<li>Polytope, <em>generally</em> of the same order of the space which contains it, in this case it's a 2D space and my shapes are 2D, but it's not mandatory, I can still get basic 2D shapes in 3D for example; Of course the space which I'm in works as a limit, I can't have 4D shapes in a 3D world for example .</li>
<li>two different shapes, can be considered the same basic shape, as long as all the bottom level Polytopes ( up until the last level with 0 dimensions, a vertex ) that compose my top level Polytope are available with the same cardinality</li>
</ul>

<p>Which means that a triangle and a quadrilateral are different because they are 2D Polytope with a different number of 1D and 0D Polytopes, the triangle has 3 vertices and 3 edges where a quadrilateral has 4 vertices and 4 edges.</p>

<p>Now take this rationale that I use to identify my basic shapes in a given dimension and try to find out a generic name that can describe the fact that $C$ is composable from $A+B$ in any dimension .</p>

<p>I'm unable to communicate this concept of ""composable Polytopes from basic but different ( according to my rationale ) Polytopes"" .</p>
",geometry
"<p>Open problem in Geometry/Number Theory.  The real question here is:</p>

<p><em>Is there an infinite family of points on $y=x^2$, for $x \geq 0$, such that the distance between each pair is rational?</em></p>

<p>The question of ""if not infinite, then how many?"" follows if there exists no infinite family of points that satisfies the hypothesis.</p>

<p>We have that there exists a (in fact, infinitely many) three point families that satisfy the hypothesis by the following lemma and proof.</p>

<p><strong>Lemma 1:</strong>  <em>There are infinitely many rational distance sets of three points on $y=x^2$.</em></p>

<p>The following proof is by Nate Dean.</p>

<p><em>Proof.</em>  Let $S$ be the set of points on the parabola $y = x^2$ and let $d_1$ and $d_2$ be two fixed rational values.  For any point, $P_0(r)=(r, r^2) \in S$, let $C_1(r)$ be the circle of radius $d_1$ centered at $P_0(r)$ and let $C_2(r)$ be the circle of radius $d_2$ centered at $P_0(r)$.  Each of these circles must intersect $S$ in at least one point. Let $P_1(r)$ be any point in $C_1(r) \cap S$ and likewise, let $P_2(r)$ be any point in $C_2(r) \cap S$.  Now let $dist(r)$ equal the distance between $P_1(r)$ and $P_2(r)$. The function $dist(r)$ is a continuous function of $r$ and hence there are infinitely many values of $r$ such that $P_0(r)$, $P_1(r)$,
and $P_2(r)$ are at rational distance. $ \blacksquare $</p>

<p>This basically shows that the collection of families of three points that have pairwise rational distance on the parabola is dense in $S$.</p>

<p>Garikai Campbell has shown that there are infinitely many nonconcyclic rational distance sets of four points on $y = x^2$ in the following paper: <a href=""http://www.ams.org/journals/mcom/2004-73-248/S0025-5718-03-01606-5/S0025-5718-03-01606-5.pdf"">http://www.ams.org/journals/mcom/2004-73-248/S0025-5718-03-01606-5/S0025-5718-03-01606-5.pdf</a></p>

<p>However, to my knowledge, no one has come forward with 5 point solutions, nor has it been proven that 5 point solutions even exist.</p>

<p>But I know that many people have not seen this problem!  Does anyone have any ideas on how to approach a proof of either the infinite case or even just a 5 point solution case?</p>

<p><strong>Edit:</strong>  The above Lemma as well as the paper by Garikai Campbell do <strong>not</strong> include the half-parabola ($x \geq 0$) restriction.  However, I thought that the techniques that he employed could be analogous to techniques that we could use to make progress on the half-parabola version of the problem.</p>
",geometry
"<p>We have an affine coordinate system and $3$ points given: $A=(1,0,0)$, $B=(0,1,0)$, $C=(0,0,1)$, $D=(1,1,1)$. I have to find a linear transformation, which depicts the points $A$, $B$, $C$ and $D$ accordingly into $B$, $C$, $A$ and $D$.</p>
",geometry
"<p>I encountered a question about areas of a circles and sectors on KhanAcademy, I was given the sector area and the central angle of the radian. I know that the ratio of:</p>

<p>$${Area\,\,of\,\, Sector \over Total\,\,area\,\,of\,\,circle} = {Central\,\,angle \over 360deg}$$</p>

<p>But that is the formula to find the sector area. What if I have the sector area and central angle and I have to find the area of the circle?</p>

<p>I Googled and I found that $θ \over 2$ is used to find the area of the circle with given sector area and central angle.</p>

<p>Why is it $θ \over 2$?</p>
",geometry
"<p>Source: Oxford Exam $A2 \ 1999$</p>

<p>We want to construct a conformal map $F$ from the unit disc $\mathbb{D}=\{z:|z|&lt;1\}$ to $\mathbb{C} \setminus S$ where $S$ is the half-line $\{x+i:x \in (-\infty,0] \}$ with the additional property that $F(0)=0$.</p>

<p>Here are my thoughts, can someone see if they are correct please:</p>

<ol>
<li>Use the Möbius transformation $f_1:z \mapsto \frac{1-z}{z+1}$ to send $\mathbb{D}$ to the right half plane.</li>
<li>Use the map $f_2:z \mapsto z+ \alpha$ where $\alpha \in \mathbb{C}$ we will determine later. This simply takes the right half plane to the right half plane.</li>
<li>Use the map $f_3:z \mapsto z^2$ to map the right half plane to $\mathbb{C}$ with a cut along the negative reals.</li>
<li>Use the map $f_4:z \mapsto z+i$ to move the cut up and map to $\mathbb{C} \setminus S$.</li>
</ol>

<p>Now the composition of these four maps is conformal so we certainly have a conformal map between the sets.</p>

<p>We now need $F(0)=f_4 \circ f_3 \circ f_2 \circ f_1(0)=0$.</p>

<p>$f_1(0)=1$, $f_2(1)=1+\alpha$, $f_3(1+\alpha)=\alpha^2+2\alpha+1$, $f_4(\alpha^2+2\alpha+1)=\alpha^2+2\alpha+1+i$</p>

<p>So we need to solve $\alpha^2+2\alpha+1+i=0$ and this is the $\alpha$ required to ensure $F(0)=0$. </p>

<p>We can find that $\alpha=\sqrt{-i}-1$.</p>

<p>Thus we are done.</p>

<p>Is this correct?</p>
",geometry
"<p>I'm about to grow lettuces on a hydroponic system and I was wondering what would be the ideal pattern to provide each lettuce with the max space.
Would it be better to plant them according to a grid like on the picture below or to a ""brick"" pattern such as ""one row of 5, then one row of 4 and so on"" or any other even better pattern?
The number of pots is currently 16, but I don't mind slightly altering this if this is required by an ideal pattern.
Obviously, this must also include the space from the last pots/rows to the edges of the total rectangle.
The size of the total area is 120cm x 80cm (47.24 in x 31.5 in)</p>

<p>Thanks a lot in advance for your help
<a href=""http://i.stack.imgur.com/TkFg3.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/TkFg3.jpg"" alt=""Pots distribution""></a></p>
",geometry
"<p>Consider the 'lens' described by $\{z:|z-i|&lt;\sqrt{2}\ \text{and}\ |z+i|&lt;\sqrt{2} \}$ . We want to map this to the upper right quadrant using a Möbius transformation.</p>

<p>The two circles meet at $z=1,-1$ and so if we use the map $f:z \mapsto  \frac{z-1}{z+1}$ we should send the lens to a sector centered on the origin.</p>

<p>I have two questions:</p>

<ol>
<li>How do we find the angle sweeped out by the sector? As $f$ is conformal, it will be equal to the angle at which the two circles meet; but how is this calculated? And is there some general method for working this out?</li>
<li>After finding this angle, how do we work out how the sector is rotated relative to say the real axis after applying $f$? Again, is there some general way of doing this also?</li>
</ol>

<p>After establishing this, the question becomes simple as we can use a power map to adjust to the correct angle and then a rotation to position the sector.</p>

<p>After responses to 1. and 2. I think my approach is sound, though I'd be interested in hearing if it isn't also.</p>
",geometry
"<p>I know that distance of a plane $π_1$ (whose equation is $\vec{r}\cdot \hat{n}= d$) from a point $P$ (with position vector $\vec{a}$) in plane $π_2$ is given by $PQ = |d - \vec{a}\cdot\hat{n}|$ where $\hat{n}$ is unit vector perpendicular to plane $π_1$.
But I am not able to solve the following question:</p>

<blockquote>
  <p>If the equation of the plane $π_2$ is in the form $\vec{r}\cdot\vec{N} = d$, where $\vec{N}$  is normal to the plane, then the perpendicular distance is                           $$\frac{|\vec{a}\cdot \vec{N}-d|}{|\vec{N}|}.$$</p>
</blockquote>
",geometry
"<p>Can someone offer a worked example of how Omar Khayyam would have a solved a cubic equation with geometric solutions by means of intersecting conics? </p>
",geometry
"<p>I want to be able to check if a list of points will hit a screwed rectangle (rhombus I think).</p>

<p>I start out with 2 point P and T, I want to create a rectangle between the 2 points. I have used <a href=""http://stackoverflow.com/questions/7854043/drawing-rectangle-between-two-points-with-arbitrary-width"">http://stackoverflow.com/questions/7854043/drawing-rectangle-between-two-points-with-arbitrary-width</a> to do this. This gives me 4 points A, B, C and D of the new rectangle.</p>

<p>I then want to check if the point M is withing this rectangle.</p>

<p><a href=""http://i.stack.imgur.com/8UjTo.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/8UjTo.png"" alt=""enter image description here""></a>
The two black dots are my points P and T, the black box is the rectangle I want to generate between the two dots, being X wide.
I then want to test if the red dots are withing the black box.</p>
",geometry
"<p>Why is $\dfrac{\sqrt{1-t^2}}{\sqrt{1+t}} = \sqrt{1-t}?$ </p>

<p>And conversely $\dfrac{\sqrt{1-t^2}}{\sqrt{1-t}}= \sqrt{1+t}$?</p>

<p>I used it in an assignment because maple said it's true but I want to know why and can't seem to figure it out. Is it because there are som rules with adding squareroots like there are rules with multiplying them? Ie. $ \sqrt{a}\sqrt{b}=\sqrt{ab}$ due to rules for powers? </p>
",geometry
"<p>In my geometry class last year I remember putting down the statement in a column proof ""That all isosceles are always and only similar to other isosceles"". I do not remember what I was trying to prove. But, I do remember that I was stressed and that was the only thing I could think of and made a  guess thinking I would probably get the proof wrong on my test.</p>

<p>Funny enough though, I didn't get the proof wrong and I was wondering if anyone could show a proof as to why this would be true. I mean I makes sense but, I do not see any way to prove it. Could you please explain how this is true?</p>
",geometry
"<p>I'm looking for the name of a shape that is like a capsule, but where each circle can have different radii. The shape could be described using two circles (two centers and two radii). Something like this (this is a 2D shape, not a lame attempt at 3D):</p>

<p><img src=""http://i.stack.imgur.com/GoBEt.png"" alt=""figure""></p>
",geometry
"<p>I have two lines $(5,5,4) (10,10,6)$ and $(5,5,5) (10,10,3)$ with same $x$, $y$ and difference in $z$ values.</p>

<p>Please some body tell me how can I find the intersection of these lines.</p>

<p><strong>EDIT:</strong> By using the answer given by coffemath I would able to find the intersection point for the above given points. But I'm getting a problem for $(6,8,4) (12,15,4)$ and $(6,8,2) (12,15,6)$. I'm unable to calculate the common point for these points as it is resulting in Zero.
Any ideas to resolve this?</p>

<p>Thanks, 
Kumar.</p>
",geometry
"<p>Given an arbitrary amount of ordered segments, with arbitrary lengths is there a way to determine if they can be formed into a simple polygon?</p>

<p>And if so, is it possible to work out the angles needed to do so?</p>

<p>Thanks</p>
",geometry
"<p>Given an $n$-gon, $P$, for which numbers $k$ must there exist a point $x$ so that there are $k$ equally spaced rays emanating from $x$ which divide $P$ into $k$ equal area parts?</p>

<p>For $k=2$ we can find a point $x$ by sweeping a line at fixed angle across the figure.</p>

<p>For $k=4$ the problem was asked here:
<a href=""http://math.stackexchange.com/questions/838257/dividing-n-gon-into-4-equal-parts?rq=1"">Dividing $n$ gon into 4 equal parts</a>
. The idea of the solution being find a line dividing the figure in half,  sweep in another line, perpendicular to the first until it divides the figure in half another way.  Then continuously shift about the intersection point and apply the intermediate value theorem to get two consecutive quadrants equal from which you can deduce all $4$ quadrants are equal.</p>

<p>For $k=3$ a similar argument works I think. For $k \ge 5$ I don't know.</p>
",geometry
"<p><img src=""http://i.stack.imgur.com/PCJMe.jpg"" alt=""enter image description here""></p>

<p><em>A little background(if you don't care for my story, skip straight to the question):</em> I've missed a few lectures from my teacher because I fell ill. Since I have no information to work with other than the bad notes a friend of mine has taken, I don't have much to work with. Now I'd love help with this problem because I've been at it for almost $3$ hours and nothing I try works. I don't need the answer at all, I have the answer, what I need is the process. I need to know how to get that answer. </p>

<p>*<em>Now the question is-</em>*An airplane travels due west for $1.5$ hours at $320$ mph. then it changes course to $S31°W$. Fine the airplane's distance from its point of departure and its bearing, after a  total flight time of $3.5$ hours.</p>

<p><strong>What I know so far</strong>, sorry I wasn't as detailed as I should be. I have drawn it out, i know distance between from the starting point and when it changes direction being $480$. And the distance of the direction change to the end point which is $640$. I know the angle where the plane changes direction totals out to $121°$. I could be wrong with this information, but the point is I've taken many different approaches at this problem but have gotten no correct answers. I've taken it ""outside of the box"" and expanded the 480 line until i can drop it down to the end point and make the spot where those two lines meet a right angle, if that makes sense. I've used ""sohcahtoa"" and found out the lengths of that small right triangle, added it with the lengths of the large obtuse triangle to put it all together. The missing side is the hypotenuse and I used the Pythagorean theorem to find it, but the answer comes out wrong. I tried so many different values and processes, and nothing. For the missing angle I use the inverse of the tan function and got an answer for that, but it's also wrong. I'd appreciate any input, anything at all.</p>
",geometry
"<p>I can get up to showing that it is an abstract geometry, but I cannot figure out how to show that for every two points, there is a unique line. The definition of a line in vector form is given 
$L (AB) = \{X \in R \times R~ | ~X=A+t(B-A) ~\text{for some}~~ t \in \mathbb R\}$</p>

<p>$A,B,X$ are points.</p>

<p>I am trying to go about this by supposing A,B are in $L (CD)$ and $L (XY)$. From there I try to get $C=X$ and $D=Y$, but I can't do this. Any help or hint is appreciated.</p>

<p>The Cartesian Plane is the set of Points in $R \times R$ and the set of all lines $L (AB)$.</p>

<p>This is a problem in a textbook but I am not doing this for homework. I just find this subject really interesting so any help is appreciated.</p>
",geometry
"<p>We are trying to find intersection of hyperbolas and we ended up in five equations
$$\begin{align}
A_1X^2+B_1Y^2+C_1XY+D_1X+E_1Y+F1&amp;=0\\
A_2X^2+B_2Y^2+C_2XY+D_2X+E_2Y+F2&amp;=0\\
A_3X^2+B_3Y^2+C_3XY+D_3X+E_3Y+F3&amp;=0\\
A_4X^2+B_4Y^2+C_4XY+D_4X+E_4Y+F4&amp;=0\\
A_5X^2+B_5Y^2+C_5XY+D_5X+E_5Y+F5&amp;=0
\end{align}$$
We want to find numerical solutions to these equations for $(X,Y)$
so that we can write C++ code.</p>

<p>Appreciate your suggestions and help!</p>
",geometry
"<p>So the exercise is this:</p>

<p>We have and infinite chessboard and we have a coin. Every grid is of length and width $a$, whereas the coin has diameter $2 \cdot r&lt;a$. We throw a coin into a chessboard and we want to know with what probability the coin will falll into the grid.</p>

<p><img src=""http://i.stack.imgur.com/y9SI1.jpg"" alt=""enter image description here""> </p>

<p>So let $S_{1}$=area of green rectangle, $S_{2}=S_{1}+$ area of the red border.
So the probability in my opinion is 
$ P(a)= \frac{S_{1}}{S_{2}} $.</p>

<p>Is this in any shape or form correct?</p>
",geometry
"<p>Suppose one has a convex $n$-gon. What would be an example of an $n$-gon s.t. $3$ of its sides could not be the sides of a $\Delta$? If one has an $n$-gon that is around a circle, would it work in this case? How would one prove my second question? The help would be appreciated!</p>
",geometry
"<p>I know volume preserving diffeomorphisms of a sphere^2 make a group sdiff(S2). I would to know if it is a Lie group, which I assume if it is that makes interpolation easier (like with rotations). </p>

<p>So that is one question, is it a Lie group?</p>

<p>Also is the group path connected? If so, how can I interpolate between two elements in the group?</p>

<p>These are not subjects I know very little about. I apologize if Im phrasing it in some way that sounds ridiculous.  </p>
",geometry
"<p>How to calculate volume of tetrahedron given lengths of all it's edges?</p>
",geometry
"<p>I was studying solar geometry and I read the next equation</p>

<p>$$r=r_{0}\left(1+0,017\sin\left[\frac{2\pi(d_{n}-93)}{365}\right]\right) $$</p>

<p>where $r_{0}$ is the average distance between the Earth and the Sun and 0.017 is the eccentricity of the earth orbit, $d_{n}$ is the days.</p>

<p>My question is how to proof the equation and why the argument of the sine.
I suppose that is for properties of the ellipse (the orbit of the Earth is a ellipse) but doesn't work.</p>
",geometry
"<p>I need to find a direction vector for a line parallel to a plane $x+y+z = 0$ and that have $45$ degrees with the plane $x-y = 0$</p>

<p>So, i've assumed the vector $\vec V_r = (a,b,c)$ and since it is parallel to the first plane, the product:</p>

<p>$$(a,b,c)\cdot(1,1,1) = 0$$ 
(where $(1,1,1)$ is the vector normal to the first plane).</p>

<p>And also, using the formula for the angle between a line and a plane, where $n$ is the normal vector for the second plane:</p>

<p>$$\sin(\alpha) = \frac{|\vec V_r\cdot\vec n|}{\|\vec V_r\| \|\vec n\|}$$
so:
$$\sin\Bigl(\frac{\pi}{4}\Bigr) = \frac{\bigl|(a,b,c)\cdot(1,-1,0)\bigr|}{\sqrt{a^2+b^2+c^2}\sqrt{2}}$$</p>

<p>Then I end up with two equations:
$$a + b + c = 0$$
$$\frac{1}{\sqrt{2}} = \frac {|a-b|}{\sqrt{a^2+b^2+c^2}\sqrt{2}}$$</p>

<p>But i'm not able to solve for $(a,b,c)$. Could somebody help me? Thanks :)</p>
",geometry
"<p>If you have a set of points on a hemisphere, how do you find a point on that hemisphere that has the minimum total great circle distance to the points in the set.</p>
",geometry
"<p>Let f be a function of the form: $x=f_x(t); y=f_y(t);\text{ and }z=f_z(t)$. Does the derivative set of the 3 functions mean the tangent at a point on the curve of f?</p>

<p>Thank you in advance.</p>
",geometry
"<blockquote>
  <p>If $z$ is constructible, then its minimal irreducible polynomial has a degree a power of $2$. Does the polynomial have to be defined over the rationals?</p>
</blockquote>

<p>I am asking this because we can equivalently define a constructible number if the field extension $\mathbf{Q}(z)/\mathbf{Q}$ has dimension a power of $2$. Why do we define it over the rationals like that? Can we define it over the reals?</p>
",geometry
"<p>In any $\Delta ABC$, and the incenters of the triangle $ABC$ is $I$, and let $D$, $E$, and $ F$ be the points on $BC$, $AC$, $AB$, respectively, and the point $M$ is on $AD$, such that $AD$, $BM$, $CM$ and $\bigodot I$ meet $H$, $G$, $J$, respectively.</p>

<blockquote>
  <p>show that:
  $$GH\cdot DJ=GD\cdot JH$$</p>
</blockquote>

<p><img src=""http://i.stack.imgur.com/c6mEL.jpg"" alt=""enter image description here""></p>

<p>My try: let $AB=c,BC=a,AC=b$, then
$$\dfrac{AB}{AC}=\dfrac{BD}{DC}\Longrightarrow BD=\dfrac{ac}{b+c},DC=\dfrac{ab}{b+c} $$</p>

<p>and $$AD^2=AB\cdot AC-BD\cdot DC=bc-\dfrac{a^2bc}{(b+c)^2}\Longrightarrow AD=\dfrac{\sqrt{bc(b^2+c^2-a^2+2bc)}}{b+c}$$</p>

<p>let $AM=kAD$,
so use <a href=""http://zh-cn.enc.tfode.com/%E6%96%AF%E5%8F%B0%E6%B2%83%E7%89%B9%E5%AE%9A%E7%90%86"" rel=""nofollow"">http://zh-cn.enc.tfode.com/%E6%96%AF%E5%8F%B0%E6%B2%83%E7%89%B9%E5%AE%9A%E7%90%86</a></p>

<p>we  have
$$BM\cdot AD^2+DM\cdot AB^2=(BM+DM)\cdot AM^2+BM\cdot DM(BM+DM)$$
 then I can't work, so I think this problem have other nice methods. Thank you. </p>
",geometry
"<p>I'm trying to compute the minimal bounding box of an arc segment so when it's time to render it, I only have to examine pixel coordinates within a minimal rectangular region.  The code below covers the case when $0 \leq \theta_0 \lt \pi/2$.  Was wondering if there is some sort of rotational symmetry so that I don't need 4x the amount of code statements that the box() function already is (1 for each quadrant where $\theta_0$ could be.  The prog language is D.</p>

<pre><code>struct Arc {
protected:
Vec2 c;
float r0, r1;
float t0, t1;

invariant() {
    assert(r0 &lt; r1 &amp;&amp; t0 &lt; t1);
}

public:
this(in Vec2 center, float radius0, float radius1,
     float theta0, float theta1) 
{
    c = center;
    r0 = radius0;
    r1 = radius1;
    t0 = theta0;
    t1 = theta1;
}

@property Box2 box() {
    double minX, minY, maxX, maxY;

    if (theta0 &gt;= 0) {
        if (theta0 &lt; PI/2) {
            if (theta1 &lt; 2*PI - theta0)
                maxX = r1 * cos(theta0);
            else
                maxX = r1 * cos(theta1);

            if (theta1 &lt;= PI/2) {
                maxY = r1 * sin(theta1);
                minY = r0 * sin(theta0);
                minX = r0 * cos(theta1);
            }
            else {
                maxY = r1;
                if (theta1 &lt;= PI) {
                    if (theta1 - PI/2 &gt; PI/2 - theta0)
                        minY = r0 * sin(PI - theta1);
                    else
                        minY = r0 * sin(theta0);
                    minX = r1 * cos(PI - theta1);
                }
                else {
                    minX = -r1;
                    if (theta1 &lt;= 3*PI/4) 
                        minY = r1 * sin(theta1);
                    else    // 2PI &gt;= theta1 &gt; 3*PI/4 
                        minY = -r1;
                }
            }
        }
    }
}
}
</code></pre>

<p>My guess is is that you compute which quadrant $\theta_0$ is in, then rotate the whole thing into quadrant 1 which I already have code for (rotate by either $\pi/2, \pi,$ or $3\pi/2$), compute the bounding box in that quadrant, then rotate the bounding box by the same angle, negated.  Would this work?  I think I will need to open up Geogebra and draw some test images to find out.</p>
",geometry
"<p>It approximately looks like the following picture
<img src=""http://i.stack.imgur.com/G5SY6.png"" alt=""enter image description here""></p>

<p>The figure may be rotated at any angle.</p>

<p>I know the coordinates of points $A$, $B$, $C$, $D$ and the length of $BF$.</p>

<p>$\angle ABD$ and $\angle CBD$ are equal ($AD = CD$ and $AB = CB$).</p>

<p>$\angle EAB = \angle EFB = \frac{\pi}{2}$ (right angles).</p>

<p>I need to find the coordinates of $E$ and $G$.</p>
",geometry
"<p><strong>Question</strong>: See the figure below. If AB=BC and DE=EF, is the line DF parallel to the line AC?</p>

<p><img src=""http://i.stack.imgur.com/wNIfK.png"" alt=""enter image description here""></p>

<p>This should be an elementary problem. But I can't construct a counterexample to disprove the above question. If the answer is negative, please give a counterexample. Thanks.</p>
",geometry
"<p>ABCD is a parallelogram. A, B and C equal (1,1), (4, 3) and (-1, 4) respectively.  </p>

<p>I have worked out the length of AB and AC to be the root of 13, and ABC is a right-angled triangle as I was asked to prove that (by showing AB and AC are equal).  The gradient of AB = 2/3.</p>

<p>I'm simply stuck on finding co-ordinate D.  The topic we are doing in class is co-ordinate geometry, so I know about finding the length and straight line equations.</p>

<p>I'd appreciate help or direction in what to do.</p>
",geometry
"<p>In a triangle $ABC$, it is known that $ AC = m$, $AB = 3m$, $BC = Rm$. </p>

<p>Find for which values of $R $ the triangle is: </p>

<p>(i) An acute angle triangle. </p>

<p>(ii) A right angle triangle. </p>

<p>(iii) An obtuse angle triangle. </p>

<p>I have tried several approaches including the law of cosine and the Pythagorean theorem, but it didn't help. </p>
",geometry
"<p>I have two parameterized planes, for example, {u, 0, v} and {u-1, v-1, 1}. And I have to find the parametric equation of the line that intersects both planes. By setting both planes equal to each other I get {u=u-1, 0=v-1, v=1} = {0=-1, v=1, v=1}. Then by substituting v into the first equation {u, 0, v} I get the answer {u, 0, 1} which is correct but this approach doesn't seem correct. Is there another way to solve this?</p>
",geometry
"<p>Let $ABCD$ be a cyclic quadrilateral with side lengths $AB=p,BC=q,CD=r,DA=s$.Show that $\dfrac{AC}{BD}=\dfrac{ps+qr}{pq+rs}$.  </p>

<p>My work:<br>
I have found out that this follows from Ptolemy's Second Theorem but cannot prove it.Please help! With or without Ptolemy is fine, I do not have any restriction.</p>
",geometry
"<p>Suppose I have a rectangle and I want to fill it with hexagons without having any white space. The hexagon doesn't need to be in the regular hexagon shape so the only thing that matters is that it needs to have 6 sides. Each hexagon can have maximum one common side with another hexagon.</p>

<p>I have been trying to solve it and I think it is impossible but I cannot prove it:S.</p>

<p>Can somebody help me filling it out or proving that it is impossible?</p>
",geometry
"<p>This is quite simple question for this forum ;)</p>

<p>How to find distance in octahedron between centers of two adjacent faces, if its edge equals <code>a</code>?</p>
",geometry
"<p>I should find a set of $n$ points $Q$ in a plane, so that $t(Q)$ (the number of possible triangulations) the following equation holds: </p>

<p>$$t(Q) \ge 2^{n-2\sqrt{n}}$$</p>

<hr>

<p>I solved the problem using the vertex points of a convex polygon. Wikipedia says, that $t(Q) = C_{n-2}$ and by induction I can show, that $C_{n-2} \ge  2^{n-2\sqrt{n}}$. </p>

<p>I think, that this approach is way to complex. There must be a better solution, because $C_{n-2} \gg  2^{n-2\sqrt{n}}$ for big $n$. </p>

<p>Any ideas?</p>
",geometry
"<p>I'm looking to calculate the outer radius of a spherical shell of a desired volume and thickness.  I don't know if the years have knocked some obvious obstacle out of my perception, but here's what i'm struggling with.<br>
Given: Thickness T, Radii R and r, and Volume V and the following relationships:
$$
T=R-r
$$
$$
V=\frac{4}{3}\pi R^3 - \frac{4}{3}\pi r^3
$$
How do I solve for R in terms of V and T?</p>

<p>I get as far as:</p>

<p>$$
\frac{3V}{4\pi}=R^3-(R-T)^3
$$
Which comes down to...
$$
\frac{3V}{4\pi} = 3R^2-3RT+T^2
$$</p>

<p>Which i'm lost on breaking apart.  For more clarification, this is supposed to be just a fun exercise for a D&amp;D game.  The rules i'm working with are limited by volume, and the integrity of created objects would be limited by thickness.  Thus, these are the terms i wanted to control, and then calculate the resulting outer radius of what the character can create.</p>

<p>Thanks for any help that can be provided!</p>
",geometry
"<p>I have the following problem: bisectors $AA',BB'$ and $CC'$ of the triangle $ABC$ intersect the circumcircle in the points $A"",B"",C"".$ Holds the following equivalence: $\frac{AA'}{AA""}+\frac{BB'}{BB""}+\frac{CC'}{CC""}=\frac{9}{4}$equivalent triangle $ABC $ equilateral?</p>
",geometry
"<p>For univariate polynomials degree is number of roots with multiplicity?</p>

<p>For multivariate polynomials what is geometric meaning?</p>
",geometry
"<p>It seems like a simple enough question. For the involute of a circle, what is the separation distance between successive turns?</p>

<p>Is this derivation correct?</p>

<p>Parametric formula for the y-coordinate:</p>

<p>$ y = r(Sin(\theta) - \theta Cos(\theta)) $</p>

<p>Differentiating:</p>

<p>$ \frac{dy}{d\theta} = r \theta Sin(\theta) $</p>

<p>Which has roots at $ \theta = \pi n, n\in \mathbb{Z} $</p>

<p>Taking every other $n$, since those are successive turns:</p>

<p>$ y = r(Sin(\theta) - \theta Cos(\theta)) $</p>

<p>simplifies to</p>

<p>$ y = -r \pi n $</p>

<p>where $n$ is even and $n \ge 0$.</p>

<p>Therefore the spacing between successive turns, $D$ is:</p>

<p>$ D = 2 \pi r $</p>

<p>Is that even close to right? Is it that simple? I guess it makes intuitive sense based on the circumference of the circle. And some plots I've made bear it out. But I'd like to know for sure. </p>
",geometry
"<p>What is the nature of  Triangle if $\frac{AB}{AC}=\frac12$ and $\angle BAC=60^{\circ}$?. Can we use ratio between side lengths?</p>
",geometry
"<p>The question is:
The lines L and M have equations y = 2x + 3 and 2x + y = 11 respectively.  Point A has co - ordinates (1, 5).</p>

<p>As part of the question, I found a) the intersection of L and M is P(2, 7) and b) that the equation of a line passing through A that is perpendicular to M is y = 1/2x + 9/2.</p>

<p>The last part is ""B is a point on M such that ABP = 90 degrees.  Find the co-ordinates of point B.""  I could do this if it didn't have to be on M, but I am not sure how to bring M into it.  </p>

<p>All help appreciated.</p>
",geometry
"<p>Let's imagine a ring sector (from a random planar face revolved 360deg). Is there a way to differentiate between the non-circumferential faces and the circumferential faces ? The available information are the centers of gravity, surfaces areas, volume centroid of the ring, a point on each surface and normals.</p>

<p><a href=""http://i.stack.imgur.com/n5Qw1.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/n5Qw1.png"" alt=""Example""></a></p>

<p>For instance, in the image above I would like to differentiate between the blue faces and the white ones. Please note that this ring has been made from a square face revolved but the geometry could come from any type of cross section. 
Any ideas?</p>
",geometry
"<p>Given three points being vertices of some regular polygon is it possible to find minimal number of sides of such polygon? Vertices can be chosen arbitary and it is not required for them to be adjacent. The only requirement is that they are vertices of some regular polygon.</p>

<p>Thanks!</p>
",geometry
"<p>I found this question a while ago on a SAT practice exam or something, can't quite remember. So given an acute triangle $ABC$ with $P$ a point inside it and $AP$, $BP$, and $CP$ meeting the opposite sides at $D$, $E$, and $F$ respectively:</p>

<p><img src=""http://imgur.com/tnZew.png"" alt=""alt text""></p>

<p>How can you find the area of triangle $ABC$ given the areas of triangles $x$, $y$, and $z$?</p>
",geometry
"<p>Following my <a href=""http://math.stackexchange.com/questions/1279/what-is-the-name-for-a-shape-that-is-like-a-capsule-but-with-two-different-radii"">previous question</a>, I'm wondering how I can determine if a point is within the convex hull of two circles (a boolean value). There's no problem testing if the point is in either of the two circles, but it can also be ""between"" them and I don't know how to test for that.</p>

<p>Seeing Wolfram MathWorld's article on <a href=""http://mathworld.wolfram.com/Circle-CircleTangents.html"">Circle-Circle Tangeants</a>, it seems that an inequation that tests if the point is on the internal side the two external circle tangeants would do the trick, but I'm afraid my solving skills are too far away to be able to turn the tangeant equations into a fitting inequality.</p>

<p>I'm defining the convex hull of two circles using both centers and radii.</p>
",geometry
"<p>A book I am using has a problem which includes two points on the graph of $y=\ln x$, $M_1(x_1, y_1)$ and $M_2(x_2, y_2)$ and identifies the middle of the chord $M_1 M_2$ between them as $I(x_e, y_0)$. What do you suppose is meant by $x_e$ in this case? Is it $x=e$ or $x$ such that $y=e$ or ?  I could put the whole problem here, but I hope to solve it myself once I understand the notation.</p>

<p>Update: the whole problem (please don't solve it yet or I won't get to. I would like to understand the problem better. I've done some thinking and computing and have some good ideas, but I don't understand the problem fully. Thus, hints would be more appreciated than an answer.):</p>

<p>Klein &amp; Reeb, Problem I.1.10 </p>

<p>Soient $M_1(x_1,x_y)\,M_2(x_2,y_2)$ deux points du graphe de $y=\ln x$. Soit $I(x_e,y_0)$ le milieu de la corde $M_1 M_2$. D'aprés la
concavité du graphe $y_0 &lt; \ln x_0$; en déduire: $2 \sqrt{x_1 x_2} &lt; x_1 + x_2$.</p>

<p>My translation:</p>

<p>$M_1(x_1,x_y)\,M_2(x_2,y_2)$ are two points on the graph of $y=\ln x$.
$I(x_e,y_0)$ is the middle of the chord $M_1 M_2$. According to the
concavity of the graph  $y_0 &lt; \ln x_0$; deduce $2 \sqrt{x_1 x_2} &lt; x_1 + x_2$.</p>

<p>Update: given GPerez's comment below which agrees with a thought I had too about $x_e$, I'd say it's possible (but not yet conclusive in my mind) the book has a typo and $x_0$ was meant instead. </p>

<p>Update: my thought process on solving the problem was approximately thus: since $y=\ln x$ is concave, if $M_1$ is negative, then $0&lt;x_1&lt;1$ since $\ln x &lt; 0$ for $0 &lt; x &lt; 1$. If $x_e$ wasn't a typo, I had supposed that, since it was the x-coordinate of the midpoint of $M_1 M_2$ it might mean that $M_2$ had to be located to the right of either where $y$ attains the value $e$ or where $x=e$, and knowing this would indicate that $M_2$ is to the right of that point since it is the right endpoint. From these facts, we would then deduce that $0&lt;x_1&lt;1$ and (for the case where we suppose $x_e$ means $x=e$:) $e&lt;x_2&lt;\cdot$ where $\cdot$ here is some value to the right of $x_2$ or (for the case where we suppose that $x_e$ means $y=e$:) $1&lt;x_2&lt;\cdot$ where $\cdot$ here is some value to the right of $x_2$. Then using the rules of logarithmic manipulation we could expand the LHS and RHS of the inequality given and compare term by term to prove it based on our knowledge of the range of possible values for $x_1$ and $x_2$ supposed above. That was my plan, but given the uncertainty of the notation and the incompletion, as of yet, of my computations, I've not concluded the solution. </p>
",geometry
"<p>The title really say's it all, but once again is a curve's curvature invariant under rotation and uniform scaling?</p>
",geometry
"<p>This is a followup to <a href=""http://math.stackexchange.com/questions/1326/is-a-curves-curvature-invariant-under-rotation-and-uniform-scaling"">this question</a>, where I learned that curvature is invariant to rotations. </p>

<p>I have learned of a version of curvature that is <a href=""http://en.wikipedia.org/wiki/Affine_curvature#Affine_curvature"" rel=""nofollow"">invariant under affine transformations</a>.</p>

<p>I am wondering if there a is a form of curvature between the two. Invariant under uniform scaling and rotation but not all affine transformations?</p>
",geometry
"<p>Dot product of two vectors on plane could be defined as product of lengths
of those vectors and cosine of angle between them.</p>

<p>In cartesian coordinates dot product of vectors with coordinates $(x_1, y_1)$ and
$(x_2, y_2)$ is equal to $x_1x_2 + y_1y_2$.</p>

<p>How to prove it?</p>
",geometry
"<p>Given a list of coordinates of a coplanar plane (<code>pt1</code>, <code>pt2</code>, <code>pt3</code> and so on), how to compute the centroid of the coplanar plane?</p>

<p>One way to do it is to project the plane onto XY and YZ plane, but I don't really favor this approach as you have to check the orientation of the coplanar plane first before doing the projection and computing the centroid.</p>

<p>More specifically, I'm looking for a natural extension of the <a href=""http://en.wikipedia.org/wiki/Centroid#Centroid_of_polygon"" rel=""nofollow"">2D centroid plane algorithm</a> in 3D:</p>

<p><img src=""http://upload.wikimedia.org/math/e/e/1/ee14cbb2b170c4bb435f1d84e78f6d66.png"" alt=""alt text"">
<img src=""http://upload.wikimedia.org/math/a/4/c/a4cee81a1d18e4d067f66d4d40a8a1fe.png"" alt=""alt text""></p>

<p><img src=""http://upload.wikimedia.org/math/0/2/a/02aecb75f67f8c7b2fc11fdcbcb6ea80.png"" alt=""alt text""></p>

<p>Any idea?</p>
",geometry
"<p>You've spent your whole life in the hyperbolic plane. It's second nature to you that the area of a triangle depends only on its angles, and it seems absurd to suggest that it could ever be otherwise.</p>

<p>But recently a good friend named Euclid has raised doubts about the fifth postulate of Poincaré's <em>Elements</em>. This postulate is the obvious statement that given a line $L$ and a point $p$ not on $L$ there are at least two lines through $p$ that do not meet $L$. Your friend wonders what it would be like if this assertion were replaced with the following: given a line $L$ and a point $p$ not on $L$, there is exactly one line through $p$ that does not meet $L$.</p>

<p>You begin investigating this Euclidean geometry, but you find it utterly impossible to visualize intrinsically. You decide your only hope is to find a model of this geometry within your familiar hyperbolic plane. </p>

<p>What model do you build?</p>

<p>I do not know if there's a satisfying answer to this question, but maybe it's entertaining to try to imagine. For clarity, we Euclidean creatures have built models like the upper-half plane model or the unit-disc model to visualize hyperbolic geometry within a Euclidean domain. I'm wondering what the reverse would be.</p>
",geometry
"<p>Prove that G is a center of the circle circumscribed on BED.</p>

<p><img src=""http://i.stack.imgur.com/8ig7V.jpg"" alt=""Picture""></p>

<p>So we know that we should prove that G lies on the perpendicular bisectors of every side of the BED triangle. For |ED| we can note that $\triangle EDG$ is equilateral so G, as the opposite vertex of |ED|, has to be on the perpendicular bisector.</p>

<p>And... I'm stuck. How can I show it for the other two? There is a ton of angles here but I don't know how to put them to use. Could you tell me what I should take into account while dealing with geometry problems like this? I don't know what to look at and the amount of information on the picture kind of makes me dizzy and everything looks useful and useless at the same time.</p>
",geometry
"<p>Is there some well established way on how to <strong>quantify</strong> rotations in $\mathbb{R}^n$? To say which rotation is greater and which is smaller?</p>

<p>In $\mathbb{R}^2$ the rotation is characterized by a single angle. This angle can be interpreted as the <strong>magnitude</strong> of the rotation.</p>

<p>In $\mathbb{R}^3$ however we have three possible axes around which to rotate. Furthermore we can get a zero rotation by rotating around each axis by $\pi$ radians. Therefore devices such as the sum of the three angles do not make sense.</p>

<p>In $\mathbb{R}^n$ the situation is even more complicated.</p>

<p>Let's say that the rotation is characterized by matrix $R$. Is the distance of $R$ from the identity matrix $I$ of the appropriate dimension a reasonable choice? For example 
$$
m_{R} = || R - I|| 
$$ 
where $||.||$ is some matrix norm. If so, which norm would be appropriate?</p>
",geometry
"<p>In mathematics, geometry is the topic I like. Just out of curiosity I would like to know what computational geometry is about. Who studies this subject and why. What are its applications, or is it confined to a theoretical side of things? How does it relate to computer science?</p>
",geometry
"<p>i have a rhombus ( i.e. diamond) grid determined by these equations</p>

<pre><code>    x = (rhombusWidth / 2) * gridX
    y = rhombusHeight * gridY;

   if (x % 2 != 0) 
        y +=  rhombusHeight/2;

return [x,y]
</code></pre>

<p>where rhombusWidth is the width of the rhombus, rhombusHeight is the height of the rhombus, gridX is the x grid rhombus value and gridY is the y value for the grid rhombus. This translates from grid to real world coordinates. </p>

<p>I would like to be able to translate from world to grid in such a manor that all the points from the interior of a certain rhombus returns the same gridX and gridY. Can someone please help?</p>
",geometry
"<p>Given $n$ points on $\mathbb{R}^{2}$, s.t no three are on the same straight line, and not all the points are on the same circle, prove that there exists a circle which contains only three of those points. We are considering only the circles that are defined by the above points, of course. </p>

<p>I am trying to find a direct geometrical proof. I was thinking of looking at the circle and point which have minimal positive distance between them (since I have seen a similar question considering straight lines and points which uses this strategy), or looking at all the circles containing a specific point, but I still can't seem to find the trick. </p>

<p>Thanks alot!</p>
",geometry
"<p>If we have three points like $A(x_1,y_1,z_1)$, $B(x_2,y_2,z_2)$ and $C(a,b,c)$. Then, $A$ and $B$ determines a line like $l$. After that, we rotate $C$ around $l$ by $\omega$ degree (anti-clockwise). How can be calculated new position of $C$  ""$C'(a',b',c')$""?</p>
",geometry
"<p>What is the probability that the convex hull of n+2 random points on n-dimensional sphere contains sphere's center?</p>
",geometry
"<p>P is the middle of a median line from vertex A, of ABC triangle. If Q is the point of intersection of lines AC and BP. Find relations of $|\vec{AQ}|$/$|\vec{QC}|$ and $|\vec{BP}|$/$|\vec{PQ}|$</p>

<p><a href=""http://i.stack.imgur.com/ka8E8.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/ka8E8.png"" alt=""enter image description here""></a></p>

<p>Any suggestions for the title, welcomed.</p>
",geometry
"<p>I am a recently graduated student and doing Post Graduation now. I often come across uniform convergence, uniform continuity etc. As we all know that we check continuity and convergence easily by just seeing the graph of function and it is very helpful in solving problems. But I just can't <strong>analyse uniform convergence and uniform continuity geometrically</strong>.
An explanation would be really helpful.</p>

<p>If there is some book from which we can analyse concepts of analysis geometrically, I'd be very interested in reading it; please let me know if you know of such a text.</p>

<p>Thanks in advance.</p>
",geometry
"<p>I have a very simple question: suppose I have two 2D linear equations in general form</p>

<p>$$ a_1x + b_1y + c_1 = 0$$
$$ a_2x + b_2y + c_2 = 0$$</p>

<p>I'd like to know what's the (intuitive) geometric interpretation of their addition and subtraction</p>

<p>$$ (a_1 + a_2)x + (b_1 + b_2)y + (c_1 + c_2) = 0$$
$$ (a_1 - a_2)x + (b_1 - b_2)y + (c_1 - c_2) = 0$$</p>
",geometry
"<blockquote>
  <p>Consider a unit cube in $\Bbb R^3$. What is a position (up to translation, etc.) of the cube such that its projection on the $Oxy$-plane has a maximal area?</p>
</blockquote>

<p>Here is a picture: if the sides of the cube are parallel to the three axis, then the projection is the unit square, with has area $1$. But it is possible to project it so that we get a regular hexagon (like the orange one, below).</p>

<p>$\qquad\qquad\qquad\quad$<a href=""http://i.stack.imgur.com/hSXIN.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/hSXIN.png"" alt=""cube_projection""></a></p>

<p>I believe that the regular hexagon could be a local maximum for the area of the projection, but I'm not sure. I don't even know how to compute the corresponding area of the orange hexagon (what should be the length of the orange side of one of the six equilateral triangles in the hexagon?).</p>

<hr>

<p>I solved the problem for a unit disk in the space: the area of the projection is $\pi \sin(\theta)$, maximal when the angle $\theta$ is $\pi/2$ ($\theta$ is indicated on the right of the picture).</p>

<p>$\qquad\qquad\qquad\quad$<a href=""http://i.stack.imgur.com/ad4SZ.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/ad4SZ.png"" alt=""enter image description here""></a></p>

<p>I also tried for a unit square in $2D$, the maximal area being achieved at $\theta=\pi/4$.</p>

<p>$\qquad\qquad\qquad\quad$<a href=""http://i.stack.imgur.com/XIzdh.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/XIzdh.png"" alt=""enter image description here""></a> </p>

<p>A similar question could be asked for a cylinder or a cone instead of a cube (the answer is trivial for a sphere, by the way).</p>

<p>Thank you for your comments!</p>
",geometry
"<p>This is an exercise in Ch. 4 of Beardon's <em>Algebra and Geometry</em>, on vectors in $\mathbb{R}^3$. Note that they are considered as points throughout this text.</p>

<p>Let $\mathbf{a}$ and $\mathbf{b}$ be vectors, and $l_1, l_2 \in \mathbb{R}$ such that $l_1+l_2=\|\mathbf{b}-\mathbf{a}\|$. Let $\mathbf{c}$ be a unique point on line segment $[\mathbf{a},\mathbf{b}]$ such that $l_1=\|\mathbf{c}-\mathbf{a}\|$ and $l_2=\|\mathbf{c}-\mathbf{b}\|$. By writing $\mathbf{c}-\mathbf{a}=t(\mathbf{b}-\mathbf{a})$, prove that $$\mathbf{c}=\frac{l_1}{l_1+l_2}\mathbf{a}+\frac{l_2}{l_1+l_2}\mathbf{b}.$$ What is the midpoint of $[\mathbf{a},\mathbf{b}]$?</p>

<p>So far, I have $t=\frac{l_1}{l_1+l_2}$, and hence that $\mathbf{c}-\mathbf{a}=\frac{l_1}{l_1+l_2}(\mathbf{b}-\mathbf{a})$. Similarly, $\mathbf{c}-\mathbf{b}=\frac{l_2}{l_1+l_2}(\mathbf{b}-\mathbf{a})$. What now?</p>
",geometry
"<p>An infinite $r$-regular graph is a graph with $\infty$ vertices where each vertex touches precisely $r$ edges.</p>

<p>We say an $r$-regular graph can be embedded in the $R^2$ Euclidean plane if its set of edges and vertices can be represented as a set of points on the plane where each point is connected via an edge to precisely the $r$ closest points to it. For example, some $4$-regular graphs can be embedded in the plane by placing each vertex of the graph on a unique point $(m,n)$ on the plane where $m$ and $n$ are integers. Some $8$-regular graphs can be embedded using the same placement.</p>

<p>The question is: for what values of $r$ do there exist connected $r$-regular graphs that can be embedded in the plane? </p>

<p>The graphs need not be planar, but an answer dealing with the planar case is welcome.</p>
",geometry
"<p>I have unit balls defined by the $1$, $2$ and $\infty$ norm in $\mathbb{R}^2$. I want to find the orthogonal projection of a vector $(x,y)$ onto the balls.</p>

<p>How could it be done? I only know how to project vectors orthogonally but have no idea how to do it over the balls.</p>

<p>Thanks a lot.</p>
",geometry
"<p>I have values for x,y,z coordinates of two points A and B as in attached figure, my objective is to determine a third point C hence making a triangle. Since I could determine distance values between the points, I tried to obtain the angles BAC and ABC.
However when I used cosine formula, the value I obtained for cosA is not within the range of [-1, 1]. Hence the inverse cosine resulted in Complex number.
How can I avoid or deal with such situation?
Please I will appreciate any guide
<a href=""http://i.stack.imgur.com/awMEj.png"" rel=""nofollow"">Triangle from the two points A,B and Point C to be determined </a></p>
",geometry
"<p>Suppose $S$ is a hyperbolic surface with geodesic boundary and $P$ is a hyperbolic pair of pants with $a$, $b$, $c$ geodesic boundary. Let $\gamma$ be the unique geodesic realizing the distance between the boundary components $b$ and $c$ of the pair of pants $P$, i.e. $\operatorname{length}(\gamma) = \operatorname{dist}(b, c)$. Now suppose $d$ is a boundary of $S$ such that the length of $d$ is equal to the length of $a$. We attach $P$ with $S$ along the boundary components $a$ and $d$ so that the resulting surface $S'$ is a hyperbolic surface. Now my questionis the following:</p>

<p>Does the geodesic $\gamma$ realise the distance between $a$ and $b$ in the surface $S'$?</p>
",geometry
"<p>I stumbled apon this questions in a proofs worksheet and I was quite baffled by it because it seems like you can prove the sides to be congruent by cpctc however after I checked my work, the answers simply just said not necessarily.</p>

<p>So I was just hoping someone knew a way to figure out why the two sides were not congruent and is there another way besides AAA and ASS or SSA is there another way to prove that these two shapes are just not congruent.</p>

<p>Thanks (An answer with some work would be greatly appreciated)</p>

<p>QUESTION (Only 19 and 20):</p>

<p><a href=""http://i.imgur.com/UzGXBSw.jpg"" rel=""nofollow"">http://i.imgur.com/UzGXBSw.jpg</a></p>

<p>ANSWERS FOR 19 AND 20:</p>

<p><a href=""http://i.imgur.com/e5KhQdR.png"" rel=""nofollow"">http://i.imgur.com/e5KhQdR.png</a></p>
",geometry
"<p>In $\mathbb{R}^2$ was disposed on each point coordinates in $\mathbb{Z}$, except $(0,0)$, a small open square of side  $2r$ where $r\in]0,\frac{1}{2}[$. </p>

<p>Prove that there is a real $R&gt;0$ such that for any real $\theta$, an observer located at $(0,0)$ and looking in the direction $(\cos\theta,\sin\theta)$ manages to see a square located in a circle with centre coordinates $(0,0)$ and radius $R$ (Euclidean)</p>

<p>Thanks in advance</p>
",geometry
"<p>Does anyone know if it has been proved what the maximum number of simplexes occurring in the plane is for a given value of $n$ points? I am interested in this question in relation to packing problems (eventually generalizing to tetrahedron packing in 3-space).</p>

<p>In 1974, Harborth proved the following theorem by applying Euler's polyhedral formula and using induction.</p>

<blockquote>
  <p>Let $f_{2}^{\text{min}}(n)$ denote the maximum number of times the minimum distance can occur among n points in the plane. Then, $$f_{2}^{\text{min}}(n) = \lfloor 3n - \sqrt{12n -3} \rfloor$$</p>
</blockquote>

<p>For any dimension $d$, we have a general definition for the maximum number of times the minimum distance can occur among $n$ points in $\mathbb{R}^d$ as, $$f_{d}^{\text{min}}(n) = \max_{|P|=n} | \{\overline{pq} | p,q \in P \text{ and } |p-q|=1\}|$$
where $P \subseteq \mathbb{R}^d$ is any $n$-element point set. We now wish to extend this result to not only consider the maximum number of times the minimum distance can occur among $n$ points in $\mathbb{R}^d$, but to the maximum number of times a regular $k$-simplex of minimum side length can occur among $n$ points in $\mathbb{R}^d$.</p>

<p>Toward the end, I define the $\Delta$-function as follows:</p>

<blockquote>
  <p>Let $\widehat{v_{1}...v_{k}}$ denote a $k$-simplex with vertices $v_{1},...,v_{k} \in \mathbb{R}^d$. Then,
  $$\Delta_{d}^{k}(n) = \max_{|P|=n} | \{\widehat{v_{1}...v_{k}} | v_{1},...,v_{k} \in P, |v_{i}-v_{j}|=1, i\neq j\}|$$
  defines the maximum number of occurrences of a regular $k$-simplex of minimum edge length determined by an $n$-element point set in $P \subseteq \mathbb{R}^d$.</p>
</blockquote>

<p>So, in terms of this $\Delta$-function, we have $f_{2}^{\text{min}}(n) = \Delta_{2}^{1}(n) = \lfloor 3n - \sqrt{12n -3} \rfloor$. I am now interested in extending Harborth's result to $\Delta_{2}^{2}(n)$ and in doing so I have proved the following corollary of two lemmas I proved (I will not mention the proofs).</p>

<blockquote>
  <p>Any simplicial $k$-complex $\mathcal{K}$ for which $\Delta_{d}^{k}(n)=|\mathcal{K}|$ is connected and homogeneous, where $k \leq d$ for $P \subseteq \mathbb{R}^d$ with $|P|=n$.</p>
</blockquote>

<p>I now want to extend Harborth's result to determining $\Delta_{2}^{2}(n)$, that is, determining the maximum number of regular triangles of side length equal to the minimum distance that can occur among an $n$-element point set in the plane.</p>

<p>The start of my proof looks something like this, I am stuck though and am looking for guidance.</p>

<blockquote>
  <p>By Corollary 1, we have that $\Delta_{2}^{2}(n)=|\mathcal{K}|$ where $\mathcal{K}$ is a connected homogeneous simplicial $2$-complex. By the necessity of homogeneity, $\partial \mathcal{K}$ is a closed polygon (is it necessarily convex?) with at most $n$-vertices. Let the degree of a vertex in $\mathcal{K}$ denote the number of adjacent vertices in $\mathcal{K}$. Then, let $b$ and $b_{d}$ denote the total number of vertices of $\partial \mathcal{K}$, and the number of those vertices that have degree $d$ in $\mathcal{K}$, respectively. Then, $b = b_{2} + b_{3} + b_{4} + b_{5}$. [From here, I don't know where to go, I want to employ Euler's polyhedron formula somehow. If $\partial \mathcal{K}$ is convex, could I say $\Delta_{2}^{2} = 2 - n + E(n)$, where $E(n)$ is a function which determines the number of edges of $\mathcal{K}$? Any ideas for how to determine E(n)?]</p>
</blockquote>

<p>I appreciate any suggestions!</p>
",geometry
"<p>In an exercise I was asked to find a formula of the form $F(x,y,z)=C$ for a cylinder though the axis $(t,t,t)$ and radius $R$. The formula I got seemed a bit suspicious so I wanted to ask if I have it right.</p>

<p>Basically I used the vector formula for the distance between a line and a point found here: <a href=""http://mathworld.wolfram.com/Point-LineDistance2-Dimensional.html"" rel=""nofollow"">http://mathworld.wolfram.com/Point-LineDistance2-Dimensional.html</a>. I chose $x_1=(0,0,0), x_2=(1,1,1)$ to determine the line. Marking $r=(x,y,z)$ for a point on the cylinder, after some simplification and moving things around in the equation, I got that each point on the cylinder needs to fulfill the formula:</p>

<p>$$(y-z)^2+(z-x)^2+(x-y)^2=3R^2$$</p>

<p>Have I correctly derived the formula?</p>

<p>Thanks a bunch!</p>
",geometry
"<p>I wish to generalize the notion of two points determining a unique line to four dimensions, but with the additional condition that all points on the line are a unit distance from the origin and the ""line"" is not straight, but forms a least-distance curve between the two points. This is easy to do in the case of three dimensions: the line is a great circle and is defined by p.x=0, where p is found by the cross product of the two points. But I can't seem to generalize this to four dimensions. Is there not a unique geodesic curve that passes through two points? If there is, how would I express it in terms of the two points?</p>
",geometry
"<p>If we define the 2-form $\omega=\frac{1}{r^3}(x_1dx_2\wedge dx_3+x_2dx_3\wedge dx_1+x_3dx_1\wedge dx_2)$ with $r=\sqrt{x_1^2+x_2^2+x_3^2}$</p>

<p>If we now define $x(\theta,\phi)=(\sin\theta\cos\phi,\sin\theta\sin\phi,\cos\theta)$ for $\theta\in(0,\pi)$ and $\phi\in (0,2\pi)$</p>

<p>I now want to show that the pullback of this map is:</p>

<p>$x^*\omega=\sin\theta d\theta\wedge d\phi$ </p>

<p>Now my definition of the pullback of a map $c:[a,b]\rightarrow D$ is $\alpha(c'(t))dt$ but am unsure as to how to proceed? I can see that this curve $x$ is a parametrization of the sphere in $\mathbb{R}^3$ but after that I am a bit lost?</p>

<p>Thanks for any help</p>
",geometry
"<p>I know that the involute of circle of radius $r$ centered at $(0,0)$ is given by the following parametric form:
$$\begin{cases}
x(\theta) = r \big(\cos(\theta) + \theta\ \sin(\theta) \big),\\
y(\theta) = r\big(\sin(\theta) - \theta\ \cos(\theta) \big),
\end{cases}$$
with $\theta\in\mathbb{R}$. Given a point $(a,b)\in\mathbb{R}^2$, I would like to compute its distance to the involute (or the closest point on the involute).</p>

<p>Given the parametric form I can compute the normal direction to the involute at a point and, thus, I need to compute a $t\in\mathbb{R}$ such that 
$$(a,b) = \big(x(\theta),y(\theta)\big) \ + \ t\ \big(-y'(\theta),x'(\theta)\big).$$
I guess that now the <em>easiest</em> way consists on computing $\theta$ first, which gives the closest point:
$$\frac{x(\theta)-a}{y'(\theta)}-\frac{b-y(\theta)}{x'(\theta)}=0.$$
It is obvious that one needs iterative solvers to approximate the solution (I have already tried Newton-Raphson).</p>

<p>The main problem is that the function to be minimized is highly oscillating and it can be difficult to give a good approximation for the initialization of the algorithm. In fact, it seems that this should also depend on the radius $r$.</p>

<p>Any help or suggestion is really welcome: from a geometrical point of view (a way to simplify the computations, an already computed formula...), from a numerical point of view (other algorithms) or from the implementation point of view.</p>
",geometry
"<p>I know about the inversion of a point inside a circle. But I was reading Peter Sarnak's paper on the Apollonian gasket, and got to the part where he was trying to prove descartes circle theorem. He described this circle inversion. Could someone please derive it?
<a href=""http://i.stack.imgur.com/jmQDw.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/jmQDw.png"" alt=""inversion of a circle""></a></p>
",geometry
"<p>There are $5$ points on the surface of a sphere. Is it always possible to divide the surface into $5$ connected congruent regions such that each region contains one of the $5$ points?</p>
",geometry
"<p>In $\mathbb C^2$ I have the following three lines:</p>

<p>$r_1:3x-y+3=0, r_2:y=0, r_3:x-i=0$</p>

<p>I want to find all the affine transformations such that</p>

<p>$f(r_1)=r_2, f(r_2)=r_3, f(r_3)=r_1$</p>

<p>I was thinking the following:</p>

<p>since I want that the line of equation $3x-y+3=0$ is transformed in the line of equation $y'=0$ I ask for</p>

<p>$y'=k(3x-y+3)\qquad k\in\mathbb{C}$</p>

<p>I do the same for the other lines:</p>

<p>$x'-i=hy\qquad h\in\mathbb{C}$</p>

<p>$3x'-y'+3=t(x-i)\qquad t\in\mathbb{C}$</p>

<p>Solving the previous system I find that the affinity should be the following</p>

<p>$x'=-\frac{1}{3}y+i$</p>

<p>$y'=3x-y+3$</p>

<p>This is the only solution of the previous system... I was wondering if it is the only affinity I'm looking for or if there are other affinities that I could find with another argument.</p>

<p>Thank a lot</p>
",geometry
"<p>I was wondering what would the quoteint group $\mathbb R/\mathbb Z$ look like geometrically ? Any two elements in this group will be related only if their difference is an integer. </p>

<p>I was reading about the geometry of a torus, wherein it was stated that $\mathbb R^n/\mathbb Z^n$ was equivalent to a torus in n-dimension, so i was thinking that $\mathbb R/\mathbb Z$ should probably be a circle,but if that is correct how would i get that kind of a construction?</p>
",geometry
"<p><a href=""http://math.gmu.edu/~eobrien/Venn4.html"">This page</a> gives a few examples of Venn diagrams for 4 sets. Some examples:<br>
<img src=""http://math.gmu.edu/~eobrien/image/Vennflower.gif"" alt=""alt text""> 
<img src=""http://math.gmu.edu/~eobrien/image/Venn4r.gif"" alt=""alt text""><br>
Thinking about it for a little, it is impossible to partition the plane into the $16$ segments required for a complete $4$-set Venn diagram using only circles as we could do for $&lt;4$ sets. Yet it is doable with ellipses or rectangles, so we don't require non-convex shapes as <a href=""http://en.wikipedia.org/wiki/Venn_diagram#Edwards.27_Venn_diagrams"">Edwards</a> uses.   </p>

<p>So what properties of a shape determine its suitability for $n$-set Venn diagrams? Specifically, why are circles not good enough for the case $n=4$?</p>
",geometry
"<p>Is there a collective term for the $XY, YZ$ and $ZX$ planes in $3D$ co-ordinate geometry? I was thinking ""principal planes"" but I'm not sure where I heard that.</p>
",geometry
"<p>I am using a laser range finder to calculate the height of a second story wall. I have a fixed point and three separate lengths hitting the top, the bottom, and an indeterminate point on the wall. With the exact lengths of all three line segments, how do I find the length of the wall? Note: I am unable to create a right triangle due to the height and the uneven wall underneath. </p>

<p><img src=""http://i.stack.imgur.com/dH4ZI.png"" alt=""illustration""></p>
",geometry
"<p>If I have a grid made of equilateral triangles, I can easily form larger convex polygons as a set of tiles in that grid. I believe this holds for some (but not all) tilings of non-equilateral triangles.</p>

<p>The same for quadrilaterals - it's obvious for squares, rectangles and parallelograms, but I believe it also holds for some other (but not all) tilings of quadrilaterals.</p>

<p>I'm pretty sure tiling a flat area purely with convex pentagons is impossible, so skip that case.</p>

<p>With hexagons, a tiled grid is possible, but the only way to make a convex polygon from those convex hexagonal tiles seems to be to use only one tile - no multi-tile convex polygons seem possible.</p>

<p>My speculation is that it's only possible to form a multi-tile convex polygon from convex polygon tiles if all those tiles have interior angles at all vertices of 90 degrees or less, at least for those vertices that are at a vertex or edge of that larger convex polygon.</p>

<p>Is that speculation correct? Is there a proof or disproof?</p>
",geometry
"<p>For example, in space three-dimensional affine space generated by two skew lines is all the space three-dimensional, since they are not coplanar.
  For this reason it is not worth the Grassmann formula, which in this case would say that the space generated by the two straight lines has dimension 1 +1-0.</p>

<p>The affine geometry is intermediate between the geometry of vector spaces and the projective subspaces in a vector space are forced to pass through the origin. The affine space is then built in order to remedy this lack unnatural, but in doing so you lose the Grassmann formula, and many problems will lengthen the list of cases to consider: two straight lines can be accidents, coplanar, skew ... The projective space eliminates re-adding phenomena of parallelism of ""new points at infinity"", without restoring a ""vantage point"", and so here is Grassmann.</p>

<p>Could you help me understand this concept? In a strict and intuitive way.</p>
",geometry
"<p>I am in high school and I have a question that I haven't been able to solve for a very long time. Please help?</p>

<blockquote>
  <p>A sand timer consists of two cones joined at the apex. Each cone has height h, radius r and an angle at the apex of 60°.</p>
  
  <p>Express the radius of the top cone in terms of its height. Give your answer in exact form.</p>
</blockquote>

<p>I am stuck and don't know how to complete this question. Could you please help?</p>

<p>Thank you! ^^</p>
",geometry
"<p>Trying to calculate heat transfer which is a function of distance of each molecule to the closest wall for various container shapes.  For example, a rectangular prism versus a cylinder.</p>

<p>So I think that  a 'thin' rectangular prism of volume V average distance to wall can be much less than average distance of a cylinder.  Reducing only to the cross section, assuming a rectangle of dimension $x$, $.5x$, versus a cylinder of of radius $\sqrt{\frac{x^2}{2 \pi}}$ (which is same volume I think) what is the average distance from a point in the circle to the perimeter versus the average distance of a point in the rectangle to its closest perimeter?</p>

<p>For a circle I have this idea that if inscribe a smaller circle inside the big circle with the same center point, such that the smaller circle contains 1/2 the volume of the outer circle, then the average distance is radius of outer circle minus radius of inner circle.  Is that correct?</p>

<p>For the rectangle I don't quite know  -- whether the same approach could be used to inscribe a rectangle of the same aspect ratio which contains 1/2 the area of the outer rectangle and the average distance is the length of the perpendicular connecting the inner and outer rectangle?</p>

<p>Is this a correct approach?</p>
",geometry
"<p>A base of a pyramid is a square of side 10. The lengths of three consecutive side edges are 8, 6, 10. Calculate the lenght of the fourth side edge.</p>

<p>I have not the slightest idea how to touch this. The triangle sides aren't isosceles so the line $|OO'|$ where $O$ is the apex and $O'$ is the point of the base diagonals crossing is not perpendicular to the base. Therefore, I simply don't know how to move on with this.. I see no angles to use some trigonometry on, nor any friendly right triangles which I could use to calculate something. Could you please help?</p>
",geometry
"<p>The equation for the line is
\begin{equation}
\frac{x-5}{2} = 1 - y = \frac{z - 15}{4}
\end{equation}</p>

<p>The equation for the plane is
\begin{equation}
\left(\begin{array}{c} x \\ 
                       y \\ 
                       z \end{array}\right) = 
\left(\begin{array}{r} -2 \\ 
                       -7 \\ 
                       5 \end{array}\right) + s
\left(\begin{array}{c} 2 \\ 
                       6 \\ 
                       3 \end{array}\right) + t
\left(\begin{array}{r} 1 \\ 
                       4 \\ 
                       -1 \end{array}\right)                   
\end{equation}</p>

<p>What I'm not really sure about is how to convert the vector equation into the general equation of the form
\begin{equation}
ax + by + cz + d = 0.
\end{equation}</p>
",geometry
"<p>anyone can help me? :&lt;</p>

<p>Are there any equations that I could use in this question? I am so confused. I only know how to do the question if it changes ""parallel"" to ""perpendicular"" because I only know the equations for that...</p>

<p>thx </p>
",geometry
"<p>I've got exercise to do as en exercise to my school leaving exam and I have no idea how to prove it:</p>

<blockquote>
  <p>Diagonals of trapezium intersect in point $S$. Through point $S$ the
  segment was given that is parallel to the bases and intersect the legs
  in points $E$ and $F$. Prove that $|ES| = |SF|$.</p>
</blockquote>

<hr>

<p><sub>I'm sorry for my poor translation but I'm not good at math english yet.</sub></p>
",geometry
"<p>The center of gravity coordinates of a triangle can be calculated </p>

<p>$O(\frac{x_1+x_2+x_3}{3},\frac{y_1+y_2+y_3}{3},\frac{z_1+z_2+z_3}{3})$ where $P_1,P_2, P_3$ are the corner points of a homogeneous triangle and we know that the areas of triangles $(P_1,P_2,O),(P_1,P_3,O),(P_2,P_3,O)$ in the big triangle equal to each other?</p>

<p>I have not found the formulas about the gravity center of a homogeneous tetrahedron. </p>

<ol>
<li><p>Is the gravity center coordinates of tetrahedron
$O(\frac{x_1+x_2+x_3+x_4}{4},\frac{y_1+y_2+y_3+y_4}{4},\frac{z_1+z_2+z_3+z_4}{4})$ where $P_1,P_2 P_3,P_4 $ are the corner points of the tetrahedron?</p></li>
<li><p>Are the volumes of tetrahedrons $(P_1,P_2,P_3,O),(P_1,P_2,P_4,O),(P_2,P_3,P_4,O),(P_1,P_3,P_4,O)$ in the big tetrahedron equal to each other?</p>

<p>How can be proved the Lemma 1 above?</p></li>
</ol>

<p>Many thanks for answer and advice</p>

<p>Note: I confirmed that if Lemma (1) is true ,Lemma (2) is true too.</p>

<p>The volume of the big tetrahedron can be computed by 4x4 matrix</p>

<p>$$V=\frac{1}{6} |det(\begin{bmatrix}x_1 &amp; y_1 &amp; z_1&amp; 1\\x_2 &amp; y_2 &amp; z_2&amp; 1\\x_3 &amp; y_3 &amp; z_3&amp; 1\\x_4 &amp; y_4 &amp; z_4&amp; 1\end{bmatrix})|$$</p>

<p>If the center is $O(x_0,y_0,z_0)=O(\frac{x_1+x_2+x_3+x_4}{4},\frac{y_1+y_2+y_3+y_4}{4},\frac{z_1+z_2+z_3+z_4}{4})$  then</p>

<p>$$V_{123}=\frac{1}{6} |det(\begin{bmatrix}x_0 &amp; y_0 &amp; z_0&amp; 1\\x_1 &amp; y_1 &amp; z_1&amp; 1\\x_2 &amp; y_2 &amp; z_2&amp; 1\\x_3 &amp; y_3 &amp; z_3&amp; 1\end{bmatrix})|=\frac{V}{4}$$</p>

<p>$$V_{124}=\frac{1}{6} |det(\begin{bmatrix}x_0 &amp; y_0 &amp; z_0&amp; 1\\x_1 &amp; y_1 &amp; z_1&amp; 1\\x_2 &amp; y_2 &amp; z_2&amp; 1\\x_4 &amp; y_4 &amp; z_4&amp; 1\end{bmatrix})|=\frac{V}{4}$$</p>

<p>$$V_{234}=\frac{1}{6} |det(\begin{bmatrix}x_0 &amp; y_0 &amp; z_0&amp; 1\\x_2 &amp; y_2 &amp; z_2&amp; 1\\x_3 &amp; y_3 &amp; z_3&amp; 1\\x_4 &amp; y_4 &amp; z_4&amp; 1\end{bmatrix})|=\frac{V}{4}$$</p>

<p>$$V_{134}=\frac{1}{6} |det(\begin{bmatrix}x_0 &amp; y_0 &amp; z_0&amp; 1\\x_1 &amp; y_1 &amp; z_1&amp; 1\\x_3 &amp; y_3 &amp; z_3&amp; 1\\x_4 &amp; y_4 &amp; z_4&amp; 1\end{bmatrix})|=\frac{V}{4}$$</p>
",geometry
"<p>I'm a visual learner and I'm having trouble intuitively understanding subspaces. Our professor defined a subspace as a non-empty set closed under linear combinations. However, I'm having trouble picturing this.</p>

<p>Are subspaces just lines, planes, and n-dimensional spaces?</p>

<p>Can subspaces be finite? I.e. can a subspace in $R^3$ be a cube with dimensions 10x10x10?</p>
",geometry
"<p>I've got stuck on this problem :</p>

<blockquote>
  <p>Proof that for every triangle of
  sides $a$, $b$ and $c$ and area
  $S$, the  following
  inequalities are true :</p>
  
  <p>$4S \le a^2 + b^2$</p>
  
  <p>$4S \le b^2 + c^2$</p>
  
  <p>$4S \le a^2 + c^2$</p>
  
  <p>$6S \le a^2 + b^2 + c^2$</p>
</blockquote>

<p>The first thing that comed in my mind was the inequality $S \le \frac 12 ab$. That is derived from the fact that $S = \frac 12ab \cdot \sin(\angle ACB)$ and $0 &lt; \sin(\angle ACB) \le 1$.</p>

<p>Anyway, this wasn't enough to solve the problem. Some help would be well received.</p>

<p>Thanks!</p>
",geometry
"<p>Let’s say we have a triple of integers $(a,b,c)$ which is assumed to be a Pythagorean triple, so that $$a^2+b^2=c^2.\tag{$\star$}$$
Without using ($\star$) directly or indirectly — but using other properties and theorems related to rational right triangles — what are ways of proving that $(a,b,c)$ is or is not a Pythagorean triple? I’m thinking of theorems on areas, medians, incircles and outcircles, triangle points, infinite ternary tree constructions, <em>etc.</em></p>

<p>As a concrete example, consider the triple $(3,4,7)$. Without using the fact that $3^2+4^2 \ne 7^2$, how would one prove that $(3,4,7)$ is not a Pythagorean triple?</p>

<p>More to the point, consider the <em>indeterminate</em> triple $$(14x^3,(x^3-7)y^2, x^3y^2+7y^2-14x^3),\tag{$\dagger$}$$
which is derived from the Mordell equation $y^2=x^3+7$. That equation has no integer solutions (as proved using other algebraic methods) — I'm trying to find out if triangle properties can be used to prove the same result.</p>
",geometry
"<blockquote>
  <p>We are given a fixed point on a circle of radius $1$, and going from this point along the circumference in the positive direction on curved distances $0,1,2,\ldots$ from it we obtain points with abscissas $n = 0,1,2,\ldots$ respectively. How many points among them should we take to ensure that some two of them are less than the distance $1/5$ apart?</p>
</blockquote>

<p>I have a few questions about this. Firstly, what does the question mean by abscissa? Are they talking about the <a href=""https://en.wikipedia.org/wiki/General_Dirichlet_series"" rel=""nofollow"">abscissa of convergence</a>? Secondly I don't really get the distance thing going $0,1,2,\ldots.$ Below is the official solution:</p>

<p><a href=""http://i.stack.imgur.com/U7ELA.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/U7ELA.png"" alt=""enter image description here""></a></p>

<p>Why don't they ever go more than $+1$ distance (except for going across the fixed point)? Finally, since we are worried about actual distance not curved, how can they be sure this is in fact the first such pair of points?</p>
",geometry
"<p>What is the best way to show that $S = \{(x,y) | x^2 + 3y^2 = 1\}$ is contained in the unit ball without graphing the set?</p>
",geometry
"<blockquote>
  <p>Find the projection of the line $x+y+z-3=0=2x+3y+4z-6$ on the plane $z=0$</p>
</blockquote>

<p>The equation represents the line of intersection of two planes. Using augmented matrix
$$
\begin{bmatrix} 
1 &amp; 1 &amp; 1 &amp; 3 \\
2 &amp; 3 &amp; 4 &amp; 6
\end{bmatrix}$$</p>

<p>$R_2\rightarrow R_2-2R_1$
$$
\begin{bmatrix} 
1 &amp; 1 &amp; 1 &amp; 3 \\
0 &amp; 1 &amp; 2 &amp; 0
\end{bmatrix}$$</p>

<p>$$y+2z=0$$
$$x+y+z=3$$
Equation of line is
$$\frac{x-0}{1}=\frac{y-0}{-2}=\frac{z-0}{1}$$</p>

<p>Angle made by line and normal is $$\cos(90-\theta)=\frac{1}{\sqrt{6}}$$
where $\theta$ is the angle made by line and plane.</p>

<p>How should I proceed?</p>
",geometry
"<p>Is there any geometrical interpretation as to why matrix product is not commutative?</p>

<p>Similarly, is there any geometrical interpretation of matrix product when you have  matrices $A$, $B$ such that $AB=BA$?</p>
",geometry
"<p>I am seeking a listing of the distinct <a href=""http://mathworld.wolfram.com/HamiltonianCycle.html"" rel=""nofollow"">Hamiltonian cycles</a> following the edges of the icosahedron and the dodecahedron.  By <em>distinct</em> I mean they are not congruent by some symmetry
of the icosahedron or dodecahedron (respectively). So they do not make the same sequence of angular turns. For example (as Gerhard corrected me in the comments), there is just one distinct Hamiltonian cycle on the cube.</p>

<p>Hamiltonian cycles of the Platonic solids are all over the web, but I am not finding a definitive list of the number and a description of each.  Thanks to anyone who can point me in the right direction!</p>
",geometry
"<p>This question is not from a math course. It's a real world problem and I'm in over my head math-wise; I don't know where to start.</p>

<p>I'm going to use Google Maps to draw a race course for rowers and then track the rowers in real time on that map. I hope that many of you are thinking this is not a difficult task. I probably knew it once but that was in another life: decades ago!</p>

<p>The input for the map is going to be the four corners of the course in Latitude and Longitude. This <em>should</em> form a rectangle. Then the number of lanes would be entered. </p>

<p>I'd need to take the start and finish lines, divide their length by the number of lanes and get a series of points along the start and finish lines and then draw the lanes. </p>

<p>Google Maps will draw the lines if I give it the start and end points. The course is a maximum of 2 km long so I don't really have to account for curvature of the earth.</p>

<p>Above is the primary question. As part of that I also want to draw a non-existing course for development and demonstration purposes. I'm going to use a pond near my home.</p>

<p>For that I'll use Google to find a lake and get a Latitude and Longitude for a point in that lake. Then I'll want to make the four points that make up the ""original"" course as input into the formula created above. </p>

<p>Thanks in advance for the assistance.</p>
",geometry
"<p>Say $P \sim Q$ ($P$ and $Q$ are «projectively equivalent») iff there is a projective transformation $f$ such that $f(P) = Q$.  Then $\sim$ is an equivalence relation.  I read that the space of inscribed $n$-gons modulo projective equivalence has dimension $n-3$.  Why is this?  Also, are there any related results?</p>
",geometry
"<p>Suppose I have a point $x \in \mathbb{R}^n$ on an <a href=""http://en.wikipedia.org/wiki/N-sphere"" rel=""nofollow"">n-sphere</a>. Suppose I divide the n-sphere into 4 sections (I think this makes sense in $n$ dimensions), how do I know which section $x$ lies on? </p>
",geometry
"<p>Is there a way to go from a vector equation for example :
$$
[x, y, z] = [1, 6, 2] + s[3, -2, 5] + t[5, 1, -6] 
$$
to general equation which is the form:
$$
ax+by+cz+d=0\ ?
$$</p>
",geometry
"<p>I'm working on computer program and I need to know how to find all of the coordinates (x, y) of a triangle given on a graph using the three vertices. The Triangle may be any type including right, equilateral, obtuse, acute, etc.. Is there any way to find all of these coordinates? Please help.</p>
",geometry
"<p><img src=""http://i.stack.imgur.com/2YdYu.png"" alt=""Motor axis M, gyro axis G""></p>

<p>Suppose I have a motor with axis M on my diagram rotating at rate $r$ [rad/sec]. Connected to the motor is a gyroscope, the axis G of which is at an angle a to to that of the motor (the gyroscope will measure rotation components around this axis, and ignore all other).
Which rotation rate will the gyroscope measure?
Okay, when $a=0$, then the gyro rate is $r$. 
When $a=\frac{\pi}{2}$, the gyro rate is zero.
Whe $a=\pi$, the gyro rate is $-r$ 
, and when $a= \frac{3\pi}{2}$ the gyro rate is zero again. 
The gyro rate could be $\cos(a)r$ but is it?</p>
",geometry
"<p>What is the volume when $f(x) = x^2$ is rotated around the line $y = x$?</p>

<p>For each individual $x$, I was considering the difference between $\begin{pmatrix} x\\x \end{pmatrix}$ and the projection of $\begin{pmatrix} x^2\\x \end{pmatrix}$ onto $\begin{pmatrix} x\\x \end{pmatrix}$ (which would give vectors perpendicular to the line $y = x$ and of the correct length, going from a point on $y=x$ to the corresponding point on $y=x^2$).</p>

<p>I would get $\begin{pmatrix} x\\x \end{pmatrix} \cdot \left(1 - \frac{x^3+x^2}{2x^2}\right)$, and I could integrate the length of that squared times $\pi$, going from $0$ to $1$ to find the volume.</p>

<p>I would get $\pi \cdot \int_0^1 2*\left(x - \frac{x^3+x^2}{2x}\right)^2 = \frac{\pi}{60}$, but the correct answer is $\frac{\sqrt{2}\pi}{60}$.</p>

<p>Incidentally, $\frac{d\begin{vmatrix} x\\x \end{vmatrix}}{dx} = \sqrt{2}$.</p>

<p>I'm missing something, and can't figure out exactly how this (rigorously) fits together.</p>
",geometry
"<p>(I would be appreciative if somebody could give a more formal formulation of this problem.)</p>

<p>The <a href=""http://mathworld.wolfram.com/SpiderandFlyProblem.html"" rel=""nofollow"">Spider and the Fly Problem</a> is a problem in which the objective is to minimize the distance the spider must travel to reach the fly on the other side of the room.</p>

<p><img src=""http://i.stack.imgur.com/kgmAe.png"" alt=""Mesh of a cube with a Spider and a Fly.""></p>

<p>The spider can only move on the surface of the room. Let S be the point where the spider is, and F be the point where the fly is. One is given the length of YG, GF, PH, and HS, as well as the length, width and height of the rectangular prism. Assume that the fly and spider stay on their respective sides, but aside from that, their points are not necessarily where they are placed on the diagram. <strong>Is there a general formula for calculating the shortest distance between the spider and the fly?</strong> (Is there a general formula for the geodesic of the cuboid?)</p>

<p>I solved the original spider and the fly problem (by just creating meshes of the cube and getting lucky), but I don't see how I could generalize the result, especially as the spider and fly do not have to be at the same position they are in the original problem. In the original problem, the spider is centered and one unit from the top, and the fly is centered and one unit from the bottom. I've tried considering the simpler case where the fly and spider remain in the same spot, but I still couldn't generalize it, especially for more extreme cases (if we make the height <em>very</em> large compared to the others, our line will go off the mesh, I'm not sure how to deal with this.)</p>

<p>I looked online for any hints about the problem, and the <a href=""http://mathworld.wolfram.com/SpiderandFlyProblem.html"" rel=""nofollow"">the Mathworld Page</a>
 used the word ""geodesic"" to describe the solution. I did some more research, but could only find solutions for the sphere and some other 3d shapes. I also couldn't find any page describing a general solution to the problem, only pages using the meshes of the rectangular prism as a solution.</p>
",geometry
"<p>A hypothetical (and maybe practical) question has been nagging at me.</p>

<p>If you had a piece of paper with dimensions 4 and 3 (4:3), folding it in half along the long side (<strong><em>once</em></strong>) would result in 2 inches and 3 inches (2:3), which wouldn't retain its ratio. For example, here is a piece of paper that doesn't retain its ratio when folded:
<img src=""http://i.stack.imgur.com/l14ls.jpg"" alt=""enter image description here""></p>

<p>Is retaining the ratio technically possible? If so, what is the side length and ratio that fulfills this requirement? Any help would be appreciated.</p>

<p><strong><em>Update:</em></strong></p>

<p>I added ""<strong><em>once</em></strong>"" because I got an answer saying that any recectangle would work, as any rectangle folded twice has the original ratio. Nice answer, but not quite what I was looking for. As for the other answers, I got 3x as much information as I needed! Thanks!</p>
",geometry
"<p>This is the problem:</p>

<p>In $\mathbb{E}^3$ we consider the conic $\gamma$ of equations $x=yz-2=0$ , the line $a$ of equations $x=y+z=0$ and the surface $Q$, that is generated by the rotation of $\gamma$ around $a$.</p>

<p>(a) After having explained the equation, show that $Q$ is a hyperbolic hyperboloid.</p>

<p>(b) Describe the cartesian equations of the straight lines contained in Q, and the minimum circle of Q.</p>

<p>(c) Let $Q'$ projective closure of $Q$ in $\mathbb{P} ^ 3$, determine a plane $\pi$ in  $\mathbb{P} ^ 3$, through P = (2:0:0:1), such that the trace of Q' in the space affine $\mathbb{A}: = \mathbb{P} ^ 3/\pi$ is a paraboloid</p>

<p>I try to complete (a): I found the plane perpendicular to $ a $, but I do not know how to impose conditions to generate Q</p>
",geometry
"<p>I'm doing 3rd year undergraduate geometry (an introductory subject), and we've been given formal definitions of terms like ""$n$-manifold"" and ""smooth $n$-manifold."" However, I tend to think about these concepts in simplified terms. My simplified definitions are:</p>

<ul>
<li><p>An $n$-manifold is a subspace of $\mathbb{R}^k$ for some $k \in \mathbb{R}$ that is locally homeomorphic to $\mathbb{R}^n,$ regarded up to homeomorphism.</p></li>
<li><p>A smooth $n$-manifold is a subspace of $\mathbb{R}^k$ for some $k \in \mathbb{R}$ that is locally diffeomorphic to $\mathbb{R}^n,$ regarded up to diffeomorphism.</p></li>
</ul>

<p><strong>Question 0.</strong> Are these definitions basically correct? If not, why not?</p>

<p><strong>Question 1.</strong> Can the concept of a Riemannian $n$-manifold be given a ""simplistic"" definition like those above that is basically correct?</p>
",geometry
"<p>How can I calculate the length of the <a href=""http://en.wikipedia.org/wiki/Cathetus"" rel=""nofollow"">cathetus</a> in a triangle if I know the length of the hypotenuse and the ratio between the two catheti?</p>

<p>For example:</p>

<p>The hypotenuse is 5cm long, and the ratio between the catheti is 4:3 - how long are the catheti or either cathetus?</p>
",geometry
"<p><strong>Stromquist's Theorem</strong>:  If the simple closed curve J is ""nice enough"" then it has an inscribed square.<br>
""Nice enough"" includes polygons.<br>
Read more about it here:  www.webpages.uidaho.edu/~markn/squares<br>
An ""inscribed square"" means that the <em>corners</em> of a square overlap with the curve.</p>

<p>I would like to suggest a counter-example:</p>

<p>The curve connected by the points:
(.2,0)
    (1,0)
    (1,1)
    (0,1)
    (0, .2)
    (-.2, -.2)
    (.2,0)<br>
Link to plot: <a href=""http://www.freeimagehosting.net/uploads/5b289e6824.png"" rel=""nofollow"">http://www.freeimagehosting.net/uploads/5b289e6824.png</a><br>
Can this curve be incribed by a square?</p>

<p>(An older version of this question had another example: a triangle on top of a square (without their mutual side.) )</p>
",geometry
"<p>Let $\varepsilon &gt; 0$. Let $k_d(\varepsilon)$ be the minimum number of balls $B(x, \varepsilon) \subset \mathbb{R}^d$, $x \in \mathbb{S}^{d-1}$, w.r.t. the usual metric in $\mathbb{R}^d$, needed in order for the balls to cover $\mathbb{S}^{d-1}$.</p>

<p>Is there a neat way to calculate $k_d(\varepsilon)$? I'm interested in the rate at which it increases as $d$ grows. For example, the ratios $k_{d+1}(\varepsilon) / k_d(\varepsilon)$, would suffice.</p>

<p>So far, I have tried to look at regular polygons with vertexes on $\mathbb{S}^{d-1}$ and areas of spherical caps around $x$ in comparison to the area of $\mathbb{S}^{d-1}$, but things tend to get quite messy: For example with the spherical caps you end up looking at regularized incomplete Beta functions.</p>

<p>If somebody has a slick way to approach this, I would appreciate it if they shared. Of course literary references to something related to this would be great as well.</p>

<p>Thanks!</p>

<p>EDIT: It turns out that people <a href=""http://iitp.ru/upload/content/839/Dumer.pdf"" rel=""nofollow"">have</a> been seriously working on optimal spherical coverings. However, they study something called ""covering density"" which I'm not instantly sure how to turn into a number of spheres.</p>
",geometry
"<p>Prove that a) the medians b) the altitudes and c) the angle bisectors drawn from the base angle of an isosceles triangle are congruent. </p>

<p>Looking at this problem, I feel that this statement is just false. If you have an isosceles triangle given in the following link <a href=""http://mathforum.org/dr.math/faq/formulas/images/isostri2.gif"" rel=""nofollow"">http://mathforum.org/dr.math/faq/formulas/images/isostri2.gif</a>. Then clearly these are not congruent. Is there something in the problem that I am missing? Thanks</p>
",geometry
"<p><a href=""http://ericsartor.ca/movementdesign/circleratio.png"" rel=""nofollow"">Ratio example image</a></p>

<p>I am doing some web design, and I need a way to dynamically figure out what to set a circle's diameter to so that it exactly covers a rectangle, as shown in the above image.  In the first scenario (in the image), I calculated that the diameter of the circle was 12% greater than the width of the rectangle, and thought this would work for all rectangles, but it does not.  The problem is that the width of the rectangle is dynamic, so I never know what it's value will be ahead of time, I have to size the circle based off of whatever dimensions the rectangle is at the time.</p>

<p>This is probably a fairly simple formula, but I am far from being a mathematician, clearly.  If I can do anything to clarify my question, please ask!  Thanks!</p>
",geometry
"<p>Wikipedia says (<a href=""http://en.wikipedia.org/wiki/Icosahedron"" rel=""nofollow"">link</a>)that cartesian coordinates of icosahedron are:</p>

<pre><code>(0, ±1, ± φ)
(±1, ± φ, 0) 
(± φ, 0, ±1)
</code></pre>

<p>Where <code>φ</code> = (1 + √5) / 2 is golden ratio ≈ 1.618.</p>

<p>I found on the internet <a href=""http://rbwhitaker.wikidot.com/index-and-vertex-buffers"" rel=""nofollow"">this code</a>:</p>

<pre><code>// vertex position and color information for icosahedron
            vertices[0] = new VertexPositionColor(new Vector3(-0.26286500f, 0.0000000f, 0.42532500f), Color.Red);
            vertices[1] = new VertexPositionColor(new Vector3(0.26286500f, 0.0000000f, 0.42532500f), Color.Orange);
            vertices[2] = new VertexPositionColor(new Vector3(-0.26286500f, 0.0000000f, -0.42532500f), Color.Yellow);
            vertices[3] = new VertexPositionColor(new Vector3(0.26286500f, 0.0000000f, -0.42532500f), Color.Green);
            vertices[4] = new VertexPositionColor(new Vector3(0.0000000f, 0.42532500f, 0.26286500f), Color.Blue);
            vertices[5] = new VertexPositionColor(new Vector3(0.0000000f, 0.42532500f, -0.26286500f), Color.Indigo);
            vertices[6] = new VertexPositionColor(new Vector3(0.0000000f, -0.42532500f, 0.26286500f), Color.Purple);
            vertices[7] = new VertexPositionColor(new Vector3(0.0000000f, -0.42532500f, -0.26286500f), Color.White);
            vertices[8] = new VertexPositionColor(new Vector3(0.42532500f, 0.26286500f, 0.0000000f), Color.Cyan);
            vertices[9] = new VertexPositionColor(new Vector3(-0.42532500f, 0.26286500f, 0.0000000f), Color.Black);
            vertices[10] = new VertexPositionColor(new Vector3(0.42532500f, -0.26286500f, 0.0000000f), Color.DodgerBlue);
            vertices[11] = new VertexPositionColor(new Vector3(-0.42532500f, -0.26286500f, 0.0000000f), Color.Crimson);
</code></pre>

<p><strong>Let's forget the code and focus only on coordinates of vertices.</strong> <br/></p>

<p>When I look on coordinates from wiki and divide <code>φ/1</code> its ≈ 1.618. <br/>
When I do same with coordinates from the code above 0.42/0.26 ≈ 1.615 <br/> 
So when I compare this two sets of coordinates I can say that 1 corresponds with 0.26 and 0.42 with <code>φ</code>. <br/>
If lets say that k = 1/0.26 = 50/13 ≈ 3.84, so if I multiply all coordinates from second set by k, I can write them as: <br/></p>

<pre><code>(±1, 0 ,±φ) 
(0, ±φ, ±1)
(±φ, ±1, 0) 
</code></pre>

<p>So for conclusion:<br/>
Wiki coordinates:</p>

<pre><code>(0, ±1, ± φ)
(±1, ± φ, 0) 
(± φ, 0, ±1)
</code></pre>

<p>Second set coordinates: <br/></p>

<pre><code>(±1, 0 ,±φ) 
(0, ±φ, ±1)
(±φ, ±1, 0)
</code></pre>

<p><strong>Why does this happens? Why does not corresponds the placement of <code>φ</code> and <code>0</code> and 1 in x,y,z position in coordinates?</strong></p>
",geometry
"<p>I have a set of rigid transforms $\in \mathbb{R}^{4x4}$, where each transform is an approximation to some unknown, ""correct"" transform. I'm looking for an algorithm to estimate the correct transform given the approximations. My first thought would be to take the element-wise average over the entries in the matrices, and then re-normalize the resulting matrix to get a rigid transform, but I bet there's a better way to do it. Does anyone have any advice?</p>

<p>Thanks!</p>
",geometry
"<p>This is a variant of the result discussed in this link: <a href=""http://math.stackexchange.com/questions/1873521/on-a-constant-associated-to-equilateral-triangle-and-its-generalization"">On a constant associated to equilateral triangle and its generalization.</a></p>

<p>Consider any regular polygon and an arbitrary point, $P$, on an arbitrary circle with center at the centroid of the polygon. The sum of the square distances from $P$ to the sides of the polygon is a constant. </p>

<p>This can be extended to a tetrahedron. Consider a tetrahedron $ABCD$ and an arbitrary point, $P$, on any sphere with center at the centroid of the tetrahedron. The sum of the square distances from $P$ to the planes containing the faces of the tetrahedron is a constant. I suspect this can be generalized to any regular polyhedra.</p>

<p>These two similar results are probably particular cases of a more general theorem, so my question is: which whould be this general theorem for which these two results are just particular cases?</p>
",geometry
"<p>Is it possible to rotate the axes along a point that is NOT lying on the axes? For example, consider the point C(u,v) where $u,v \neq 0$. Can I rotate the axes about this point? 
In my mind, this seems very possible. Also, the way I visualize it, I would say that the coordinates of point C with respect to the new axes will remain (u,v). Am I correct in saying so?</p>
",geometry
"<p>Suppose I have a particle traveling through a medium. Suppose also I have some concentric circles drawn. As the particle passes through each circle, its trajectory (T$_n$) changes $\alpha$ degrees to the left from the tangent of each circle (p$_n$). </p>

<p>If I draw $N$ circles, what would be the radius (R$_n$) of the circle that the trajectory T$_n$ produced will be perpendicular to T$_1$ (T$_1$ $\perp$ T$_n$)? Would I be able to draw an equation to relate the angle that T$_n$ makes with T$_1$? If $\alpha$ is not constant, would the same apply?</p>

<p>N.B.: I attached a figure to illustrate my question, if i am not being clear enough. But hopefully it is not too confusing.</p>

<p>N.B.: I suspect what i have to do is have a relation such as $\partial\theta/\partial r$, with $\theta$ as the angle between $T_n$ and $T_1$. And the work, i think, will be easier to do in cylindrical coordinates.</p>

<p>Thanks in advance.
<a href=""http://i.stack.imgur.com/pcNXm.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/pcNXm.png"" alt=""Diagram of a trajectory deviation as it passes through the circles.""></a></p>
",geometry
"<p>I tried to help one of my friends with her exercise, who is actually younger than me, but I can't figure it out myself. The problem is the following:</p>

<p>We have a cyclic quadrilateral, whose diagonals are perpendicular. Is the ABCO quadrilateral's area half the whole? This can also be proved by showing that the areo of the ABCO and AOCD is the same.</p>

<p><a href=""http://i.stack.imgur.com/W8raF.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/W8raF.png"" alt=""enter image description here""></a></p>

<p>After some heavy thinking I am currently at the following state:
<a href=""http://i.stack.imgur.com/GK8KT.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/GK8KT.png"" alt=""enter image description here""></a></p>

<p>I now that the whole's area is $\frac{x*y}{2}$, which must be equal to the following, kind of ugly expression:
$$2*(\frac{x*\sqrt{r^2-\frac{x^2}{4}}}{2}+\frac{x*cos(45°+\frac12arccos(\frac{y}{2r})*cos(45°-\frac12arccos(\frac{y}{2r}))*r}{2})$$</p>

<p>Now I'm sure it can be solved (and by replacing the variables I get a near-correct result to the area according to geogebra), but I don't think that it would be the most elegant solution, there might be some shorter ways to do it.</p>
",geometry
"<p>I have two intersecting quadrilaterals (the area of intersection is the grey polygon with thick boundary):</p>

<p><img src=""http://i.stack.imgur.com/pSciO.png"" alt=""enter image description here""></p>

<p>These properties holds:</p>

<ul>
<li>One quadrilateral is always a rectangle</li>
<li>There is always some intersection</li>
<li>Both quadrilaterals are convex (hence the intersection is a convex polygon as well)</li>
</ul>

<p>The goal is to measure area of intersection (the actual shape is not needed, only a scalar showing how much space is covered by the intersection).</p>

<p>The problem arises in computer graphics (image mosaicing using projective geometry), where one image is stationary and the other is rotated in space and then projected in the same plane as the first one. I need to sort the images according the area of intersection they form.</p>
",geometry
"<p>I came across a sum but could not solve it as i dont know the 3d equations of a circle :<br>
The sum is   If $A(3,-2,2)$ and $B(2,9,5)$ are the end points of a diameter of a circle,then the third pt that lies on the circle is  </p>

<ol>
<li>$5,6,1$</li>
<li>$5,6,-1$</li>
<li>$5,-6,1$</li>
<li>$-5,-6,-1$    </li>
</ol>

<p>Ans:  </p>

<blockquote class=""spoiler"">
  <p> 2</p>
</blockquote>

<p>Would appreciate if someone can explain the equation of a circle (whether parametric or a normal equation) before helping solve the sum.  </p>

<p>P.S- The time limit for solving the sum was one minute  </p>
",geometry
"<p>Are there books or article that develop (or sketch the main points) of Euclidean geometry without fudging the hard parts such as angle measure, but might at times use coordinates, calculus or other means so as to maintain rigor or avoid the detail involved in Hilbert-type axiomatizations?</p>

<p>I am aware of Hilbert's foundations and the book by Moise.   I was wondering if there is anything more modern that tries to stay (mostly) in the tradition of synthetic geometry.   </p>
",geometry
"<p>I want to try to emulate what this application can do:</p>

<p><img src=""http://img530.imageshack.us/img530/5756/bezier.png"" alt=""alt text""></p>

<p>Given the red round dots (from the mouse) it is able to solve for the bezier handles given that the tension of the curve is set to $0.6$. How could I solve for the bezier handles? Is there some way I could do this with the slope or perpendicular of the previous and next curve?</p>

<p>Thanks</p>

<p>*I should also add that each point is equidistant meaning point $i + 1$ is the distance to point $i$ or point $i + 2$.</p>
",geometry
"<p>Let $A\subset\mathbb{R}^2$ and $b=(b_1,b_2)$ is in the convex hull of $A$. Prove that for any $x=(x_1,x_2)\in\mathbb{R}^2$, there exists $a=(a_1,a_2)\in A$ such that $a_1x_1+a_2x_2\le b_1x_1+b_2x_2$.</p>

<p>I tried to use dot product to reformulate the problem and here is the beginning of my proof: </p>

<p>Assume the statement is false. Then there is an $x$ such that $(a-b)\cdot x&gt;0$ for all $a\in A$. </p>

<p>But I can't find a contradiction from here. Can you finish my proof or provide another proof? I also hope that there is a geometric proof. </p>
",geometry
"<p>Related to <a href=""http://math.stackexchange.com/questions/1659/locating-the-quadrant-containing-a-point-on-an-n-sphere"">this question</a>.</p>

<p>Note that I'm using the <a href=""http://mathworld.wolfram.com/Hypersphere.html"" rel=""nofollow"">geometer definition</a> of an $n$-sphere of radius $r$, i.e.$ \{ x \in \mathbb{R}^n : \|x\|_2 = r  \} $</p>

<p>Suppose I have an $n$-sphere centered at $\bf 0$ in $\mathbb{R}^n$ with radius $r$ which has been divided into $2^k$ orthants by $k$ axis-aligned hyperplanes (note, $k \le n$) in $\mathbb{R}^{n-1}$ passing through $\bf 0$. For e.g., if $k=1$, we have $2$ $n$-hemispheres.</p>

<p>Here's the <strong>question</strong>: how do I find the center of mass of such an orthant? Or (since I'm still working on it), how would you find the center of mass of an $n$-hemisphere?</p>
",geometry
"<p>I'm trying to understand as to why, with a given volume, the diameter and height of a cylinder need to be the same for the minimum surface area. <a href=""http://math.stackexchange.com/questions/127569/optimization-with-cylinder"">This thread</a>, shows how to derive the minimum surface area of a cylinder with a given volume, but doesn't explain why this is.</p>
",geometry
"<p>Why does every direction at the north pole point south?</p>

<p>Why doesn't this happen at any other point on (face of the) earth? Is this due to convention used by humans or is there a geometrical explanation to it?</p>

<p>The way I see it, at north pole the surface is flat like anywhere else, albeit somewhere in the arctic ocean and not land. If this is right, then why can't there be other directions like anywhere else?</p>

<p>I am not able to figure this out. Please explain the geometry behind it if it is applicable.</p>
",geometry
"<p>If two chords of a circle intersect and are $\perp$ to each other, is it possible to find the distance from the intersection point of the chords to the center?</p>

<p>I was trying to use the power of a point argument.</p>
",geometry
"<p>Let $S\subset \mathbb{R}^3$ be a connected smooth surface. Suppose that every point of $S$ is an umbilic point. Prove that $S$ is a subset of either a plane or a sphere in $\mathbb{R}^3$.
Here's a HW problem. I wonder how to prove it.</p>
",geometry
"<p>I have developed the formula to determine the radius of a cylinder with a fixed volume:</p>

<p>$$ f(x) = \sqrt[3]{\dfrac{V}{\pi}}\ $$</p>

<p>Substituted into the formula for the surface area of a cylinder, I get the following function. This would give me the minimum surface area of a cylinder for a given volume.</p>

<p>$$
S(V) = 2\pi(\sqrt[3]{\dfrac{V}{\pi}})^2+2\pi(2 * \sqrt[3]{\dfrac{V}{\pi}})
$$</p>

<p>However, my assignment for class asks for a <em>rational</em> function for this problem. How could I take my existing function and make it rational?</p>
",geometry
"<blockquote>
  <p>What is orthogonal projection of zero to triangle generated by three points (0,1) (5,0) and (2,4)</p>
</blockquote>

<p>Well, in my opinion, there is none. However, my teacher think that it has but he don't know how to find it. </p>
",geometry
"<p>Trying again, with a somewhat simpler sounding question, since my previous one (<a href=""http://math.stackexchange.com/q/147311"">Generalizations of equi-oscillation criterion</a>) got zero response:</p>

<p>Let $F:[0,1] \to R^2$ be a parametric polynomial curve of degree $m$. I want to adjust the coefficients of $F$ to make it lie as closely as possible to the unit circle, $C$. More specifically, I want to have $F(0) = (1,0)$, and $F(1) = (0,1)$, and I want the maximum distance 
$$E_1 = \max \{dist(F(t),C): t \in [0,1]\}$$
to be minimized. </p>

<p>It would be OK to minimize the following error $E_2$ instead, if it's easier:</p>

<p>$$ E_2 = \max \{ \big| F_x^2(t) + F_y^2(t) - 1 \big|: t \in [0,1]\}$$</p>

<p>What if I replace the unit circle by an ellipse (for example).</p>

<p>Two specific questions:</p>

<p>(1) Can we prove that the best approximation is equi-oscillatory, in some sense ?</p>

<p>(2) How can the best approximation be computed ?</p>

<p>This site <a href=""http://spencermortensen.com/articles/bezier-circle/"">http://spencermortensen.com/articles/bezier-circle/</a> has a good result for the case of a circle with ($m=3$).</p>

<p>You could also think of this as a question about Bezier curves of degree $m$. Clearly, it would be a good idea to set the first control point equal to $(1,0)$, and the last one equal to $(0,1)$. Then, we just need to adjust the other control points until we get an optimal fit.</p>

<p><strong>A simple algebraic version of the problem:</strong> Find two polynomials $x(t)$ and $y(t)$ such that $x(0)=1$, $x(1)=0$, $y(0)=0$, $y(1)=1$, and $x(t)^2 + y(t)^2 - 1$ is small for all $t \in [0,1]$.</p>
",geometry
"<p>I need to draw a great circle arc between two latitude and longitude points. </p>

<p>For sake of example we will use the coordinates for LAX and JFK.</p>

<ul>
<li>JFK is 40.64°N / 73.78°W</li>
<li>LAX is 33.94°N / 118.41°W</li>
</ul>

<p>My function for drawing an arc requires me to get:</p>

<ul>
<li>The center point of the circle.  </li>
<li>The radius of the circle.  </li>
<li>The start angle of the circle.  </li>
<li>The end angle of the circle. </li>
</ul>

<p>By definitions <a href=""http://williams.best.vwh.net/avform.htm"" rel=""nofollow"">here</a>, I can figure out every point on the arc. I'm just having a hard time figuring out how to find those 4 particular variables.</p>
",geometry
"<p>Given $4$ points $P_1,P_2,P_3,P_4$ on the coordinate plane with origin $O$ which satisfy the condition $\vec{OP_1}+\vec{OP_3}=\frac{3}{2}\vec{OP_2}$ and $\vec{OP_2}+\vec{OP_4}=\frac{3}{2}\vec{OP_3}$<br>
If $P_1,P_2,P_3$ lie on the circle $x^2+y^2=1$,then prove that $P_4$ lies on the circle.<br></p>

<hr>

<p>My Attempt:<br>
Let the coordinates of $P_1,P_2,P_3,P_4$ be $(x_1,y_1),(x_2,y_2),(x_3,y_3),(x_4,y_4)$.According to the given condition,<br>
$x_1+x_3=\frac{3}{2}x_2$<br>$y_1+y_3=\frac{3}{2}y_2$<br>$x_2+x_4=\frac{3}{2}x_3$<br>$y_2+y_4=\frac{3}{2}y_3$<br>
Since $P_1,P_2,P_3$ lie on the circle $x^2+y^2=1$.<br>
So,$x_1^2+y_1^2=1.......................(1)$<br>
$x_2^2+y_2^2=1...........................(2)$<br>
$x_3^2+y_3^2=1...........................(3)$<br>
Now we need to prove that $x_4^2+y_4^2=1$<br>
Subtracting $(3)$ from $(1)$ we get<br>
$x_1^2-x_3^2+y_1^2-y_3^2=0$<br>
$(x_1+x_3)(x_1-x_3)+(y_1+y_3)(y_1-y_3)=0$<br>
$\frac{3}{2}x_2(x_1-x_3)+\frac{3}{2}y_2(y_1-y_3)=0$<br>
$x_2(x_1-x_3)+y_2(y_1-y_3)=0$<br><br>
But  i am stuck here and cannot move ahead.Please help me.Thanks.</p>
",geometry
"<p>This was from a recent math competition that I was in. So, a triangle has sides $2$ , $5$, and $\sqrt{33}$. How can I derive the area? I can't use a calculator, and (the form of) Heron's formula (that I had memorized) is impossible with the$\sqrt{33}$ in it. How could I have done this? The answer was $2\sqrt{6}$ if it helps.</p>

<hr>

<p>Edited to add that it was a multiple choice question, with possible answers:</p>

<p>a. $2\sqrt{6}$<br>
b. $5$<br>
c. $3\sqrt{6}$<br>
d. $5\sqrt{6}$ </p>
",geometry
"<p>The Minkowski lower bound for packing hyperspheres of unit radii in $\mathbb{R}^n$ states that the density of hyperspheres satisfies, for all $n\geq 2$
\begin{equation}
\Delta_n \geq \frac{\zeta(n)}{2^{n-1}},
\end{equation} 
where $\zeta(n) \rightarrow 1$ as $n$ tends to infinity.</p>

<p>My question is whether boundary conditions in the definition of density affect the asymptotic behavior of this bound. Any reasonable definition of density would be something like:
\begin{equation}
\Delta_n = \lim_{\rho \rightarrow \infty} \frac{N(\rho \mathscr{B}_n)}{\mu(\rho \mathscr{B}_n)},
\end{equation} 
where $\mathscr{B}_n$ is a subset of $\mathbb{R}^n$,  $\rho$ is a uniform scaling factor for $\mathscr{B}_n$, $\mu(\cdot)$ indicates measure, and $N(\cdot)$ indicates the number of balls.</p>

<p>The Minkowski bound  implies that, as $n \rightarrow \infty$
\begin{equation}
\Delta_n \geq \frac{1}{2^{n-1}} + o(1).
\end{equation} 
Does this asymptotic behavior hold independent of boundary conditions on $\mathscr{B}_n$, or should $\mathscr{B}_n$ be some ""regular"" shape, like a ball or a box, or some other convex shape? </p>

<p>What if $\rho = \rho(n)$, for example the dimension grows at a faster rate than the scaling factor used to define the density, does the same asymptotic behavior hold?</p>
",geometry
"<p>What is the minimum and maximum of sum of angles of a <a href=""http://mathworld.wolfram.com/SphericalTriangle.html"" rel=""nofollow"">spherical triangle</a>? Let us remove a constraint from spherical triangles: sides are not necessarily circular arcs. Then what will be the minimum and maximum of sum of angles of such triangles?</p>
",geometry
"<p>A puzzle:  Three equilateral triangles of size 3, 4, and 7 touch at a corner. The other corners of the size 4 triangle are 3 away from a 3 corner, and 7 away from a 7 corner. How far apart are the other 3 and 7 corners?</p>

<p>The answer is 6.  I have an unreasonably complicated proof.  Can anyone find an elegant proof?</p>

<p><img src=""http://i.stack.imgur.com/0wA7Q.jpg"" alt=""enter image description here""></p>

<p><a href=""http://www.maa.org/sites/default/files/images/upload_library/22/Polya/07468342.di020785.02p0455x.pdf"" rel=""nofollow"" title=""The Propeller Theorem"">The Propeller Theorem</a> doesn't seem to help.</p>
",geometry
"<p>Find a vector equation and parametric equation of the line in $\mathbb{R}^3$ that passes through the point $(1,2,-3)$ and is parallel to the vector $u=(4,-5,1)$. Find two points on the line that are different from the point $(1,2,-3)$</p>

<p>Here is what I've done so far:</p>

<p>$(x,y,z)=(x_0,y_0,z_0)+(a,b,c)t 
       =(1,2,-3) + (4,-5,1)t$</p>

<p>$x=1+4t$, $y=2-5t$, $z=-3+t$ (then I don't know how to solve it...should I find ""t"" first? if yes, how can I solve it) </p>

<p>thanks for helping... :)</p>
",geometry
"<p>I'm interested in finding the maximum area ellipse that does not cover some points $\mathbf{p}_i$ and that is centered at the origin. Hence, ideally I'd like to solve this optimization problem:
$$
\begin{array}{rl}
\operatorname{maximize} &amp; \det \boldsymbol \Sigma \\
\operatorname{subject to} &amp; \boldsymbol \Sigma \succeq \mathbf{0} \\
&amp; \mathbf{p}_i^T \boldsymbol \Sigma^{-1} \mathbf{p}_i \ge 1 \quad \forall i
\end{array}
$$
The ellipse would be thus defined by the equation $\mathbf{p}_i^T \boldsymbol \Sigma^{-1} \mathbf{p}_i = 1$. Is there a known/reliable method to solve such a problem (with many $\mathbf{p}_i$)?</p>

<p>What I've tried:
Substituting $\boldsymbol \Omega=\boldsymbol \Sigma^{-1}$ doesn't help:
 $$
\begin{array}{rl}
\operatorname{minimize} &amp; \det \boldsymbol \Omega \\
\operatorname{subject to} &amp; \boldsymbol \Omega \succeq \mathbf{0} \\
&amp; \mathbf{p}_i^T \boldsymbol \Omega\,\mathbf{p}_i \ge 1 \quad \forall i
\end{array}
$$
The constraints are nice and convex (linear matrix inequality and a set of scalar linear inequalities), the problem is the objective function which is concave, hence no go.</p>

<p>You can give a sort of estimate to the solution by replacing the objective with $\operatorname{tr}\boldsymbol\Omega$; this would make the objective linear and would also be equivalent (at least in the 2D case) to maximizing $\displaystyle\frac{\det\boldsymbol\Sigma}{\operatorname{tr}\boldsymbol\Sigma}$, which is kind of similar, but not really the same.</p>

<p>Also, my gut tells me that the optimal ellipse should cross three of the $\mathbf{p}_i$ points. This implies that you could find the optimum by enumerating all sets of three points, fitting an ellipse through them (if possible), checking if all other points fall outside, and keeping the ellipse with the largest area. For pathological cases you could then also check all combinations of two points by fitting the maximum area ellipse passing through them...</p>

<p>The problem with this approach is that: (a) I don't know if it is in fact optimal, it's merely a gut feeling (b) I don't like it, it's sort of brute force and it has $\Theta(n^4)$ time complexity.</p>

<p>Any suggestions?</p>

<p><strong>EDIT:</strong>
As MvG pointed out, the solution to the problem is unbounded. So let us consider the additional constraint $\boldsymbol\Sigma\preceq\sigma\mathbf{I}$ (equivalently $\boldsymbol\Omega\succeq\frac{\mathbf{I}}{\sigma}$)</p>
",geometry
"<p>I would like to find the angle between two vectors (theta) -> v1 From i to i+1 v1=(xi1-xi , yi1-y1) and v2 from i+1 to i+2 v2=(xi2-xi1, yi2-yi1), which are shown as in the figure (but v1 and v2 can be arbitrarily placed so theta may arbitrarily change as well). Coordinates of the vector start and end points are given in Cartesian coordinates. </p>

<p>Then this angle theta will be divided into 2 to find the bisector angle between two vectors. I would like to avoid calculation of the angles of vectors as much as possible and try to do this as vector operations. </p>

<p>I tried to subtract second vector from first one and find the angle by arctangent operation, however that did not help for all possible cases (i.e. when vector 1 and vector2 angles are not close to each other, etc.)</p>

<p>Other idea is to find the angle by arctan2(dot(v1,v2), det(v1,v2)) which is basically correspond to arctan2(sin, cos).</p>

<p>What would be a reasonable approach to find this directed angle from first vector to the second one? </p>

<p><img src=""http://i.stack.imgur.com/nKun9.png"" alt=""calculation of theta""></p>
",geometry
"<p>I'm getting different answers using different methods in this question -</p>

<p>Q.There are 2 spherical balls touching each other at a point P. They both are kept on the ground and the point P is 10 cm above the ground. The radius of one circle is 8 cm. Find the radius of the other circle.</p>

<p>My approach -</p>

<p>Let the radius of the other circle be r cm.
Drawing perpendiculars from the centers of both triangles, as well as from the center of triangle with radius 8 cm (to other radius), we get a right triangle. Now perpendicular = r - 8 cm. Hypotenuse = r + 8 cm, and base = 20 cm (Using Tangent Property from same point).
Solving, we get r = 12.5</p>

<p>If instead, we use similarity, we get 2 other answers - 8, 40/3. Indeed, 8 is wrong.</p>

<p>Please help.</p>

<p><img src=""http://i.stack.imgur.com/tq5Ps.png"" alt=""enter image description here""></p>
",geometry
"<p>It's the first exercise in this <a href=""http://archive.org/stream/courseinmathemat01gouruoft#page/31/mode/2up"" rel=""nofollow"">book</a> (It has a drawing).</p>

<blockquote>
  <p>Let $ \rho = f(\theta) $ be the equation of a plane curve in polar coordinates.  Through the pole $O$ draw a line perpendicular to the radius vector $OM$, and let $T$ and $N$ be the points where this line cuts the tangent and the normal.  Find expressions for the distances $OT$, $ON$, $MN$, and $MT$ in terms of $f(\theta)$ and $f'(\theta)$.</p>
  
  <p>Find the curves for which each of these distances, in turn, is constant.</p>
</blockquote>

<p>I tried to find the curve with $OT$ being constant.</p>

<p>$$\begin{aligned}
M (\rho\cos \theta, \rho\sin\theta)\\
T (k\sin\theta, k\cos\theta)\\
\frac{y_T-y_M}{x_T-x_M} = \frac{dy_M}{dx_M} \\
(k\cos\theta-\rho\sin\theta)(\rho'\cos\theta-\rho\sin\theta)=\\(k\sin\theta-\rho\cos\theta)(\rho'\sin\theta+\rho\cos\theta)
\end{aligned}$$</p>

<p>What should I do next?</p>
",geometry
"<p>I am reading some texts on projective geometry but I am still confused about some easy exercises. I found the following one:</p>

<p>$P_1=[0:1:2:3], P_2=[0:1:2:4], P_3=[1:1:1:1]$ are three points in $\mathbb RP^3$</p>

<p>Now there two things I would like to show that $E=&lt;P_1,P_2,P_3&gt;_{proj}$ is a projective plane and I would like to determine $a_i$ such that $E=\{[x_0:x_1:x_2:x_3]\in\mathbb RP^3:a_0x_0+a_1x_1+a_2x_2+a_3x_3=0\}$</p>

<p>I think the first thing to is to write $&lt;P_1,P_2,P_3&gt;_{proj}$ explicitly as a plane, but I have no idea how to do it, may you could help me with that problem. </p>
",geometry
"<p>On a Cartesian graph I have a point at $x = 0$ and $y = 0$. This point needs to move forward at a $30^\circ$ angle. It should travel forward at this angle for $1.75$ on the graph. What equation can I use to do this?</p>

<p>Summary:</p>

<ul>
<li>Cartesian graph point $(0, 0)$</li>
<li>Moves forward at a $30^\circ$ angle</li>
<li>Needs to travel forward at the angle $1.75$ on the graph</li>
<li>Is there an equation for this?</li>
</ul>
",geometry
"<p>A perfect mirror covered the inside surface of a sphere  (assumption: there is no any loss during reflection and reflections continue endless) and there is a very small laser on point $A$ in the surface of the sphere and the direction of the laser light goes to inside and  reflects from other point $B$ in the surface of the sphere.<br>
What are the whole possible mathematical conditions to get periodical reflections. (Passing again from $A$ to $B$) </p>

<p><img src=""http://i.stack.imgur.com/FcTDk.png"" alt=""enter image description here""></p>

<p>Thanks a lot for answers</p>
",geometry
"<p>What is the geometrical action of a skew-symmetric matrix on an arbitrary vector?</p>

<p>The rotation matrix is a skew-symmetric matrix when $\theta$ is some multiple of $\frac{\pi}{2}$. But it cannot be true that every skew-symmetric matrix represents a rotation?</p>

<p>Also, since the leading diagonal is zero, it cannot represent a scaling nor a shear. In fact, none of the standard transformation matrices <a href=""http://en.wikipedia.org/wiki/Transformation_matrix"" rel=""nofollow"">on Wikipedia</a> seem to fit the pattern of an arbitrary skew-symmetric matrix.</p>

<p>So can anything be said about the geometrical action of a skew-symmetric matrix on an arbitrary vector?</p>
",geometry
"<p>I am confused by a step made in a proof of the following result.</p>

<blockquote>
  <p>Let $f_{2}^{\text{min}}(n)$ denote the maximum number of times the minimum distance can occur among n points in the plane. Then $f_{2}^{\text{min}}(n) = \lfloor 3n - \sqrt{12n-3} \rfloor$.</p>
</blockquote>

<p>Proof: Assume $n \geq 3$ and consider a set $P$ of $n$ points with minimum distance 1, and connect two elements of $P$ by a segment if and only if their distance is exactly 1. Thus, we obtain a graph $G$ embedded in the plane. Assume that $G$ has the largest possible number of edges; that is, $|E(G)|=f_{2}^{\text{min}}(n)$. It is easy to see that every vertex of $G$ is adjacent to at least two other vertices. Moreover, $G$ is two-connected; that is, $G$ remains connected after the removal of any of its vertices.
The outer face of $G$ is bounded by a simple closed polygon $C$. Let $b$ and $b_{d}$ denote the total number of vertices of this polygon and the number of those vertices that have degree $d$ in $G$, respsectively. Clearly, $b = b_{2} + b_{3} + b_{4} + b_{5}$. The internal angle of $C$ at a vertex of degree $d$ is at least $(d-1)\frac{\pi}{3}$, and the sum of these angles is $(b-2)\pi$. Hence, $b_{2} + 2b_{3} + 3b_{4} + 4b_{5} \leq 3b-6$.
[Important Part]:</p>

<p>On the other hand, denoting by $f_{i} (i \geq 3)$ the number of internal faces of $G$ with $i$ sides, we obtain from Euler's polyhedral formula that,
$$n - f_{2}^{\text{min}}(n) + f_{3} + f_{4} + ... = 1$$</p>

<hr>

<p>The proof then continues and I understand everything before and after where it is mentioned that $n - f_{2}^{\text{min}}(n) + f_{3} + f_{4} + ... = 1$, but how is this arrived at? It is likely a very very simple answer, but if you could explain with details how this is arrived at by Euler's polyhedral formula I would be able to understand the proof. Thank you.</p>

<p>EDIT: I'm concerned with either my understanding that $V - E + F = 2$ for any graph embedding or convex polyhedra, or Gerry Myerson's answer that the Euler characteristic should be 1? Can anyone else comment on this?</p>
",geometry
"<p>What software do you use to <strong>accurately draw geometry diagrams</strong>?</p>
",geometry
"<p>I have this problem: consider the two sets $A$ and $B$</p>

<p>$$A=[0,1]\times [a,5]$$ and $$B=\{(x,y):x^2+y^2&lt;1\}$$</p>

<p>What are the values of $a$ that guarantee the existence of a hyperplane that separates $A$ from $B$.</p>

<p>Given a chosen value of $a$, find one of those hyperplanes.</p>

<p>My main problem is axiomatics: how do I read: $A=[0,1]\times[a,5]$, what's with the $\times$?</p>

<p>Thank you</p>
",geometry
"<p>I did all the algebra and for some reason I'm getting 0 > $y_2^2$ which is clearly wrong.</p>

<p>Where did I mess up at?</p>

<p><img src=""http://i.stack.imgur.com/PRlcJ.jpg"" alt=""enter image description here""></p>

<p><img src=""http://i.stack.imgur.com/KhTU4.jpg"" alt=""enter image description here""></p>
",geometry
"<p>How do I find the volume of the frustum of a cone which has base area $A_o$, top area $A_t$ and height $h$?</p>

<p>I am able to do this for circular and square bases, but unable to figure it out for arbitrary surfaces.</p>

<p>Can someone give me an idea of how to do this rigorously?</p>
",geometry
"<p>Since any two Euclidean shapes have an infinite number of points inside of them, shapes with different area have the same infinite number of points in them (and any object has the same number of points in it as are inside the plane it is inside). So area isn't a measure of the amount of points in an object, right? And if this is true, what does the area of a shape actually represent? In other words beyond the abstract idea of the amount of space in an object, what does an area of, for example, $4$, mean?</p>
",geometry
"<p><img src=""http://i.stack.imgur.com/idp4h.png"" alt=""enter image description here""></p>

<p>I've been doing these questions for hours and I've just got stumped on this one.  I know that if I multiply the 3.5 and 2 I can find the area of that part of the figure, but not the outer triangles. I'm not sure were to go on from there. </p>
",geometry
"<p>As a teenager I was given this problem which took me a few years to solve.  I'd like to know if this hae ever been published.  When I presented my solution I was told that it was similar to one of several he had seen.</p>

<p>The problem:</p>

<p>For an <code>n</code> dimensional space, develop a formula that evaluates the maximum number of <code>n</code> dimensional regions when divided by <code>k</code> <code>n-1</code> dimensional (hyper)planes.</p>

<p>Example:  A line is partitioned by points: 1 point, 2 line segments. 10 points, 11 line segments, and so one.  </p>
",geometry
"<p>Circle $c_2$ - with center $N$ - is inside circle $c_1$ and is tangent to circle $c_1$ - with center $M$ -  in $P$. The line $l$ intersects $c_1$ at points $A$ and $D$ and $c_2$ at points $B$ and $C$.</p>

<p>How do I proof that $\angle  APB = \angle  CPD$ and that $\angle  MPD = 90^{\circ} - \angle PAD$?</p>

<p><img src=""http://i.stack.imgur.com/GTzW0.png"" alt=""enter image description here""></p>
",geometry
"<p>There are $N$ bugs in a plane. All bugs are moving at the same constant (nonzero) speed, but no two bugs are moving in the same direction (velocity vectors are of the same speed, but no two are parallel). </p>

<p>Prove that at some point in time $N$ bugs will form <strong>convex</strong> polygon.</p>

<p>Edit: Can you loosen up any of the conditions so that the statement still holds?</p>
",geometry
"<p>Suppose that there are two square pyramids on the $xyz$-plane.</p>

<p>Both have base coordinates of $(0,0,0)$, $(30,0,0)$, $(0,30,0)$, and $(30,30,0)$.</p>

<p>One pyramid has its apex at $(10,10,30)$, while the other has its apex at $(20,20,30)$. </p>

<p>What is the volume of their intersection?after change in coordinates</p>
",geometry
"<p>I am working on some simulation software, and I want to get the bearing of one point in the simulation from the position of another. I have a point A at position (lat, lon), I also have an entity B which is moving around point A (point A is static- not moving at all). Given that B is constantly moving, its lat/ lon values are constantly changing.</p>

<p>How can I get the angle at which point B lies from point A at any given time? i.e. where between 0- 360 does B lie from A? Is there a way of doing this using just the two points' lat/ lon values?</p>
",geometry
"<p>A rectangular solid consisting of 18 smaller cubes that are identical is positioned in the standard (x, y, z) coordinate system. Vertex M has coordinates of (-1, 3, 0) and point O on the y axis has points of (0, 3, 0). What are the coordinates of Vertex N?<img src=""http://i.stack.imgur.com/RKMZZ.jpg"" alt=""enter image description here""> </p>
",geometry
"<p>Given a triangle ABC, $\angle BAC = 20^{\circ}, \angle ACB=30^{\circ}$. M is a point inside the triangle such that $\angle MAC=\angle MCA=10^{\circ}$. L is a point on AC (L is between A and C) such that $AL=AB$. If $AM \cap BC =K$, prove that $K$ is the center of the excircle of $\triangle ABL$. Find $\angle AMB$. </p>

<p>Proving that $K$ is the excenter of $\triangle ABL$ is easy. However, I cannot find $\angle AMB$.</p>
",geometry
"<p>A velocity encompasses both speed and direction in a single vector. I'm a little bit confused about how to separate the two.</p>

<p>I have 2 creatures. The first is located at position (x1, y1). The second is located at (x2, y2).</p>

<p>I would like the first creature to move towards the second creature, so I get the vector from creature1 to creature2 as so:</p>

<pre><code>velocity = (x2 - x1, y2 - y1)
</code></pre>

<p>Then I normalize the vector using the distance between the 2 points like so:</p>

<pre><code>velocity.x = velocity.x / distance;
velocity.y = velocity.y / distance;
</code></pre>

<p>If I use this as my velocity, the creature will move in the correct direction but it will be moving too fast. How can I control the speed of the creature without changing the direction? I would like for creature1 to move in the direction of creature2 at a constant speed which I choose.</p>
",geometry
"<p><em><strong>The problem:</em></strong></p>

<p>Suppose two convex pentagons $A$ and $B$ have equal interior angles (that is, $A=A_1A_2A_3A_4A_5$ and $B=B_1B_2B_3B_4B_5$) with $\angle A_j =\angle B_j$ for each $j\in\{1,\ldots,5\}$). </p>

<p>Suppose that $\mbox{int}(A) \approx \mbox{int}(B)$ are conformally equivalent with a biholomorphism $f:\mbox{int}(A) \rightarrow \mbox{int}(B)$ whose continuous extension to the boundary maps $A_i\overset{f}{\mapsto}B_i$. </p>

<p>Show that under these conditions, $A$ and $B$ are similar. </p>

<p><em><strong>Ideas:</em></strong></p>

<p>I would suspect the reflection principle would be applicable, but I'm not certain how to work out the proof. </p>
",geometry
"<p>I am trying to show that if a sequence of number $x_{n}$ is defined by $x_1 = h$, $x_{n+1}=x_n^2 + k$, where $0&lt;k&lt;\frac{1}{4}$ and $h$ lies between the roots $a$ and $b$ of the equation $$x^2 -x +k = 0$$ Then show that $$a &lt; x_{n+1}&lt;x_n&lt;b$$ and i am also interested in evaluating the limit of $x_n$.</p>

<p><strong>Analysis towards a solution</strong></p>

<p>I suspect that geometrically this sequence may have tendencies to converge or intersect  this quadratic equation's parabola although i am unsure how to exploit this hunch. What else do I know $$x^2 -x +k = 0 = (x-a)(x-b)$$ hence $a + b =1$ and $0 &lt; k = ab &lt; \frac{1}{4}$</p>

<p>Although i am unsure how to proceed from here any help would be much appreciated.</p>
",geometry
"<p>I have a general line $r: ax + by + c = 0$ and two parallel lines  $s,t$  distant $d$ from $r$. And a square of side $l = 1$ centered at $(x_c,y_c)$. The square sides are perpendicular to the $x$ and $y$ axis.</p>

<p>I want a find a function $f(x_c,y_c,a,b,c,d)$ that finds the area of the square within the two lines $s,t$.</p>
",geometry
"<p>Let $A$ and $B$ be two geometric shapes in the plane (two measureable subsets of $\mathbb{R}^2$) such that $A\subseteq B$.</p>

<p>Define a $path$ from $A$ to $B$ as a function $f$ from $[0,1]$ to subsets of $\mathbb{R}^2$ such that:</p>

<ul>
<li>$f(0)=A$.</li>
<li>$f(1)=B$.</li>
<li>$f$ is monotonically increasing, i.e. for every $t'&gt;t$, $f('t)\supseteq f(t)$.</li>
<li>$Area(f(t))$ is a continuous function of $t$.</li>
</ul>

<p>Intuitively, a path describes how the shape $A$ grows continuously until it becomes $B$. It makes sense that such a function exists. But how can I prove it?</p>

<p>Alternatively, if a path does not always exist, what are the conditions on $A$ and $B$ that guarantee that it does?</p>
",geometry
"<p>Let $ABC$ be a triangle and $\Gamma$ its circumcircle. On sides $AC$, $BC$ lies respectively points $E$, $F$ such that $CE=BE$ and $CF=AF$. $CM$ is a median of triangle $EFC$. Show that line $CM$ pass throught point $K$ which is point where meets tangents to circle $\Gamma$ at points $A, B$. </p>

<p>Here is my sketch, I know that $E, F, A, B$ lies on a common circle because triangle $EFC$ and $ABC$ are similar, but don't know what to do now.</p>

<p><img src=""http://i.imgur.com/VrdZ1ZB.jpg"" alt=""""></p>
",geometry
"<p>I encountered this problem in Griffiths' <em>Introduction to Electrodynamics</em>. The first problem under volume integrals (Example 1.8). It reads:</p>

<blockquote>
  <p>Calculate the volume integral of $T = xyz^2$ over the prism in Fig. 1.24.
  <img src=""http://i.stack.imgur.com/CYpHk.png"" alt=""enter image description here""></p>
</blockquote>

<p>I understand how to perform integrals, but in this particular one I get lost while going through the solution provided. It's as if a step is jumped. The integral performed along $x$ confuses me since it has limits of $0$ and $(1 -y)$. How does $y$ not appear in the answer? It's as if some nicety is performed. I hope someone has come across the question in Griffiths before (and maybe even has the book at hand)</p>
",geometry
"<p>Take a square, ABCD. Add two points, E and F on AB such that AE=EF=FB. Now, add G, H on BC, I and J on CD, K and L on AD.</p>

<p>Now pick four pairs of the eight points, E,F,G,H,I,J,K,L. Draw the line segments between your picks, for example EG,FH, IL, JK. If we consider two such drawings equal if they can be rotated into each other, how many different drawings are there? What if we mandate that the drawing must have a line of symmetry?</p>
",geometry
"<p>Can we take any decision about the quadrants, through which a line-segment passes, from the value and sign of the slope of a line-segment?</p>

<p>For instance, can we tell that since the slope is between 0 and 1, the line-segment must be passing through 2nd and 4th quadrant and so on?</p>

<p>What other information can we extract from the magnitude and sign of a slope?</p>

<p>I have generated this data.</p>

<p><a href=""https://drive.google.com/file/d/0B-B-1BTjmHpwY0diUS1ZLUF4MFU/preview"" rel=""nofollow"">https://drive.google.com/file/d/0B-B-1BTjmHpwY0diUS1ZLUF4MFU/preview</a></p>

<p>From this I found that:</p>

<ul>
<li><p>There is no difference between slopes of lines and line-segments.</p></li>
<li><p>If the sign is negative, it passes through 2nd and 4th quadrant.</p></li>
<li><p>If the sign is positive, it passes through 1st and 3rd quadrant.</p></li>
<li><p>If $0&lt;m&lt;1$, the line passes through $0 ^{\circ}$ to $45^{\circ}$ or $181^{\circ}$ to $225^{\circ}$.</p></li>
<li><p>If $m&gt;1$, the line passes through $46 ^{\circ}$ to $90^{\circ}$ or $226^{\circ}$ to $270^{\circ}$.</p></li>
<li><p>If $m&lt;0$, the line passes through $91 ^{\circ}$ to $180^{\circ}$ or $271^{\circ}$ to $360^{\circ}$.</p></li>
<li><p>If $m&gt;0$, the y value is increasing.</p></li>
<li><p>If $m&lt;0$, the y value is decreasing.</p></li>
</ul>
",geometry
"<p>See the image. Area of green and red regions are equal. Can you represent $x=|O_2D|$ in terms of $r_1$ and $r_2$ for $r_1&gt; r_2$ ?<br>
<img src=""http://i.stack.imgur.com/FtKm6.png"" alt=""enter image description here""></p>

<p>Edit: The point $O_1$ does not enter in the region of small circle.</p>
",geometry
"<p>If in a triangle ABC,BE and CF are the two medians perpendicular to each other and, if AB = 19 cm and AC = 22 cm then the length of </p>
",geometry
"<p>Today I've computed $$\zeta(3)=\frac{9}{8}+\frac{1}{27}\int_0^1\int_0^1\int_0^1\frac{dxdydz}{1-(xyz)^{1/3}}$$
using a well know method to get this kind of integrals, I say with geometric series. After, only from a scholar/academic viewpoint I am asking myself if are feasibles more calculations in the way that was in the literature. Since I believe that the answer is no, because is very difficult or impossible to get in a closed-form  $\zeta(3)$ with this method, only is required answer my <strong>Question</strong>. Then I can refresh this kind of calculations, that is an exercise to state the right identity of the formula for change of varibles in multivariate calculus: what is the (shape of the following) set $T\subset \mathbb{R}^3$ that is prescribed in such formula?</p>

<blockquote>
  <p><strong>Question.</strong> Can you explain (if you can draw a draft of such subset it is well) <strong>how do you calculate the set</strong> $T\subset \mathbb{R}^3$ <strong>prescribed from</strong> definition of $(u,v,w)$, see my calculations below, as a linear bijection (thus continuously differentiable) when my purpose was to use the <strong>theorem of change of variables for multivariable calculus</strong>? </p>
</blockquote>

<p><strong>My definition will be</strong> (I haven't a mathematical reasoning to claim this choice) 
$$\begin{cases}
u=(x+y+z)/3 \\
v=(x-y+z)/3  \\
 w=(x+y-z)/3 \\
\end{cases} $$
thus inverting with elementary operations on the associated matrix of the corresponding liner transformation, one gets $$\begin{cases}
x=\frac{3}{2}(v+w)  \\
y=\frac{3}{2}(u-v)  \\
z=\frac{3}{2}(u-w).  \\
\end{cases} $$ </p>

<p>Thus using the cited theorem for the change of variable, that is calculate the absolute value of the <strong>Jacobi determinant</strong> and do the substitution in such formula one gets $$\int_0^1\int_0^1\int_0^1\frac{dxdydz}{1-(xyz)^{1/3}}=\int_{T}\frac{2(\frac{3}{2})^3dudvdw}{1-\frac{3}{2} \left( (v+w)(u-v)(u-w) \right)^{1/3} },$$
since as I've said the calculation for the absolute value of the Jacobi determinant was  $$  \left| \left( \frac{3}{2} \right)^3 \det \begin{pmatrix}
0 &amp; 1 &amp; 1 \\
1 &amp; -1 &amp; 0 \\
1 &amp; 0 &amp; -1
\end{pmatrix}  \right| =$$ $$=  \left( \frac{3}{2} \right)^3 \left| 0\cdot\det \begin{pmatrix}
-1 &amp; 0 \\
0 &amp; -1
\end{pmatrix} -\det \begin{pmatrix}
1 &amp; 0 \\
1 &amp; -1
\end{pmatrix} + \det \begin{pmatrix}
1 &amp; -1 \\
1 &amp; 0
\end{pmatrix} \right|= 2\left( \frac{3}{2} \right)^3.$$</p>

<p>I hope that there are no typos. I revised the <strong>definition</strong> for $(u,v,w)$ and there are no typos. <strong>Many thanks.</strong></p>
",geometry
"<p>I'm trying to implement a image processing feature descriptor based on this <strong><a href=""http://vision.eecs.ucf.edu/papers/mmsp42-scovanner.pdf"" rel=""nofollow"">paper</a></strong>. After computing all relevant normals for specific keypoints and their neighbors in an image I want to perform orientation quantization by storing all normals in a weighted histogram.</p>

<p>For that purpose I try to span equally sized bins over a sphere (described by $\theta$ and $\phi$) by creating meridians and parallels. (see Figure 2 in paper)</p>

<p>The histogram should be of size 8×4 and therefore contain 32 bins. <strong>I understand that this leads to problems due to singularities at the poles since bins get progressively smaller</strong>: </p>

<p><img src=""http://i.stack.imgur.com/VfRmL.png"" width=""250"">
<img src=""http://i.stack.imgur.com/aHBqL.jpg"" width=""220""></p>

<p>To overcome this it is mentioned that we must normalize the values added to each bin by the area of the bin (also called 'solid angle'). The formula for calculating the solid angle is given as:</p>

<p>$$ \omega = \Delta \phi(cos \theta - cos( \theta + \Delta \theta))$$</p>

<p>I understand that  $\phi$ is measured from the <em>north pole</em> = 0&deg; to <em>south pole</em> = 180&deg; while $\theta$ is measured around the equator in the range of [0, 2&pi;]. What I don't understand is how exactly the normalization works.</p>

<p><img src=""http://i.stack.imgur.com/RY2v6.png"" width=""550""></p>

<p>Lets say I have a normal $N$ and I have computed the values $\phi \substack{N}$ and $\theta \substack{N}$ for it according to the second page of the paper. Next I compute the size in degrees that each Bin in the $8x4$ histogram has:</p>

<p>$$\frac{360^\circ}{8} = 45^\circ (theta) ; \frac{360^\circ}{4} = 90^\circ (phi)$$</p>

<p>Now I can divide $\phi \substack{N}$ and $\theta \substack{N}$ by the corresponding bin size to get the actual number of the Bin in which the current normal should be stored:</p>

<p>$$ \frac{\Delta \phi}{90^\circ} = numberOfBinPhi$$
$$ \frac{\Delta \theta}{45^\circ} = numberOfBinTheta$$</p>

<p>Lets assume that this results in the following values:</p>

<p>$$ numberOfBinPhi = 1$$
$$ numberOfBinTheta = 3$$</p>

<p>Now the question is, how to compute the solid angle $\omega\substack{N}$ for such case? Is:</p>

<ul>
<li>$\Delta \phi = 90^\circ$  </li>
<li>$\Delta \theta = 45^\circ$</li>
<li>$\phi\substack{N} = 90^\circ * numberOfBinPhi = 90^\circ$</li>
<li>$\theta\substack{N} = 90^\circ * numberOfBinTheta = 135^\circ$</li>
</ul>

<p>and therefore:</p>

<p>$$ \omega = \Delta \phi(cos \theta - cos( \theta + \Delta \theta))$$</p>

<p>$$ = $$</p>

<p>$$ \omega = 90^\circ(cos135^\circ - cos( 135^\circ + 45^\circ))$$</p>

<p>I'm not sure, if my understandings are true so far, please point out any mistake or obstacle. Thank you!</p>
",geometry
"<p>All of its vertices satisfy $x^2+y^2+z^2=1$
Find the remaining two vertices with respect to $a$ and $b$.</p>
",geometry
"<p>Refer to the figure below. The distances are $|AR| = 9, |RB| = 21, |BC| = 40, |CQ| = 18$, and $|QA| = 12$. Use Ceva’s Theorem for this configuration to calculate $|PC|$.</p>

<p><a href=""http://i.stack.imgur.com/h94i6.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/h94i6.png"" alt=""enter image description here""></a></p>

<p>Curve's Theorem seems pretty straight forward, except I am not given $|BP|$. Here is what I have:</p>

<p><strong>Attempt</strong></p>

<p>\begin{align}
\dfrac{AR}{RB}\cdot\dfrac{BP}{PC}\cdot\dfrac{CQ}{QA}=1&amp;\Rightarrow \dfrac{BP}{PC}=\dfrac{252}{162}\\
&amp;\Rightarrow\dfrac{BP}{PC}=\dfrac{14}{9}\\
&amp;\Rightarrow PC=\dfrac{9BP}{14}\qquad(\star).
\end{align}
However, I cannot figure out how to find $BP$. My initial thought is to use the angle bisector theorem as follows:</p>

<p>\begin{align}
\dfrac{BP}{PC}=\dfrac{BA}{CA}&amp;\Rightarrow\dfrac{BP}{PC}=\dfrac{RA+RB}{AQ+QC}\\
&amp;\Rightarrow\dfrac{BP}{PC}=\dfrac{30}{30}\\
&amp;\Rightarrow\dfrac{BP}{PC}=1\\
&amp;\Rightarrow BP=PC.
\end{align}
This now tells us that
\begin{align}
BP&amp;=\dfrac{1}{2}BC\\
&amp;=\dfrac{1}{2}40\\
&amp;=20
\end{align}
Substituting this result into $(\star)$ gives
\begin{align}
PC&amp;=\dfrac{(9)(20)}{14}\\
&amp;=12.86
\end{align}
However, I am not sure this is correct. I am hoping someone can confirm correctness or point out where I have made errors.</p>

<p>Cheers</p>
",geometry
"<p>Bernhard Elsner, alias MathOMan, posted this exercise in plane Geometry, <a href=""http://www.mathoman.com/en/index.php/1529-theorem-about-a-circle-three-chords-and-a-midpoint"" rel=""nofollow""><em>Theorem about a circle, three chords and a midpoint</em></a> on January 29th, 2010.</p>

<p>""Let $\mathcal{C}$ be a circle, $A,B$ two distinct points on $\mathcal{C}$ and $M$ be the midpoint of the chord $[AB]$. Take two other chords,$[PQ]$ and $[SR]$, that pass through $M$. Let $C$ (resp. $D$) be the intersection of $[AB]$ with $[PS]$ (resp. $[RQ]$).
Prove that $M$ is the midpoint of the chord $[CD]$.""</p>

<p><img src=""http://www.latroika.com/mathoman/pix/exercice-cercle-cordes-milieu.png"" alt=""alt text""></p>

<p>To prove it I've written the following (failed) argument, in the <a href=""http://www.mathoman.com/de/index.php/1529-verschiedene-sehnen-in-einem-kreis"" rel=""nofollow"">German version</a> of this post (translation of mine):</p>

<p><img src=""http://calcauxprobteor.files.wordpress.com/2010/04/cordas.jpg"" alt=""alt text""></p>

<p>The figure is symmetric with respect to $M$: $\overline{AM}=\overline{MB}$, $\overline{PM}=\overline{MU}$, $\overline{RM}=\overline{MW}$, $\overline{QM}=\overline{MV}$, $\overline{QR}=\overline{VW}$, $\overline{SM}=\overline{MT}$. From $\dfrac{\overline{SC}}{\overline{DT}}=\dfrac{\overline{CM}}{\overline{MD}}=1$ follows that $\overline{CM}=\overline{MD}$.</p>

<p>Here is an extract of the author's reply (translation of mine): </p>

<p>""It is not clear that  $\overline{QM}=\overline{MV}$. Is the point $V$ on the line $(QM)$ defined by this equality or is $V$ defined as the intersection point of the lines $(QM)$ and $(WC)$? Why are both definitions to give the same point?</p>

<p>(...)</p>

<p>Let $C^{\prime }$ be the intersection of $(SP)$ and $(VW)$, and $D^{\prime }$
the intersection of $(TU)$ and $(QR)$. (...)</p>

<p>One still has to show that $C^{\prime }=C$ and $D^{\prime }=D$."" </p>

<p>I have agreed with these objections.</p>

<p>Until now no proof has been posted. The author considers that the ""proof is not quite simple"".</p>

<p>Q. What is the theorem this exercise refers to? Or how does one prove it?</p>
",geometry
"<p>Having a circle of radius $R$ with the center in $O(0, 0)$, a starting point on the circle (e.g. $(0, R)$) and an angle $\alpha$, how can I move the point on the circle with $\alpha$ degrees? I need to get the second point where it was moved.</p>

<h2>Example</h2>

<blockquote>
  <p>The red point is on $(0, R)$ and $\alpha$ is $90$ degrees. The violet circle is where the first point is supposed to be moved, and its coordinates are $(R, 0)$. Then we consider the violet point as starting point and move it with $45$ degrees. The new position will be where the blue circle is.</p>
  
  <p><img src=""http://i.stack.imgur.com/Tko9F.png"" alt=""""></p>
</blockquote>
",geometry
"<p>I am trying to find the vertices of a regular polygon using just the number of sides and 2 vertices. After the second vertex, I will make left turns to find each subsequent vertex that follows.</p>

<p>For example, If I have 4 sides, and 2 points, (0,0) &amp; (0,10), how would I go about find the next to point of the square? I know the points would be (10,10) and then (10,0), but I can't think of a formula to accomplish this.</p>

<p>Thank you for any help, and I hope I provided enough information.</p>
",geometry
"<p>I know this question exists but the answer is very vague, and I'm hoping someone could provide a more complete example (rather than just providing a formula that is difficult to use)</p>

<p>I have two lines:</p>

<p>1: $\begin{bmatrix} 1 \\ 0 \\ -1 \end{bmatrix} + t\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}$</p>

<p>2: $\begin{bmatrix} -1 \\ 1 \\ 0 \end{bmatrix} + s\begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix}$</p>

<p>How can I determine the shortest distance between them (without calculus, which I haven't learned yet)?</p>
",geometry
"<p>i'm looking for a fast method to get the intersecting points between a ray and a parallelgram defined by the 4 vertices!</p>

<p>till now i've thought to test the intersection point between ray and the 4 edge, but mayebe there are computationally faster OR mathematically more elegant way to do it.</p>

<p>mayebe check ray-triangles intersection with the 4 triangles that forms the parallelogram?</p>

<p>some advice?</p>

<p>EDIT: as copper.hat point me out the intersection points could be 0, 1 or 2. or the entire edge if the ray is coincident with an edge</p>
",geometry
"<p>This problem has puzzled me for years.  I've asked students, teachers and engineers and none of them have solved it.  It looks simple, but as of yet, no solution.  I can come up with several equations, but I can't reduce them down to a solution.</p>

<p>Imagine a doorway of height ""A"" and width ""B"".  You have a board of width ""w"".  You want to place the board in the door frame and run it corner to corner.  The board must just fit (too long and it won't fit inside the door way, too short and it doesn't run corner to corner).  I'm looking for the general solution so that it could be used for any door size and a board of any width.  You can introduce any number of angles to solve this, but your final solution must be purely in terms of ""A"", ""B"", and ""w"".</p>

<p>I would love to see a worked solution (or a layman's explanation as to why there isn't one).</p>

<p>Have fun!</p>

<p>I had a diagram drawn, but I'm too new to this site so it couldn't be posted</p>
",geometry
"<p>I would like to obtain/generate points on a circle in Cartesian coordinates such that the distance between two consecutive points will be always equal. For example, plotting a circle with radius 100 with each point 1 unit away from the previous and the next point. </p>

<p>I have tried to use polar coordinates as well as the R=x^2+y^2, but could not achieve what I wanted. What would be a reasonable approach for determining those points on a circle?</p>
",geometry
"<p>I'm working on a program where I need to draw an arc in a rectangle fulfills these requirements:</p>

<p>1) The arc must be part of a perfect circle (not the band!), must not be oval<br>
2) The arc intersects the rectangle at the bottom left and bottom right corners<br>
3) The height of the arc does not exceed the height of the rectangle<br>
4) If the arc were assumed to be part of a circle, what the circle's center point would be</p>

<p>The requirements are such as many drawing libraries use a center point to calculate how to draw the arc accurately. The only information that we can use as input is the width and height of the rectangle, and the required output would be the center point of the circle and the radius.  </p>

<p>The image below shows an example - the input box, and the output circle.</p>

<p><img src=""http://i.imgbox.com/2vsUZuwn.jpg"" alt=""image""/></p>

<p>I could write a brute force method to solve this, but I'd like something more elegant. I have found many sites which have answers like this that use a parabolic formula with width and height, but in this case the height (of the arc) is not definite- if, for example, the rectangle were very tall, the arc would only use space at the bottom of the rect.<p></p>

<p>If the rectangle were perfectly square, or the height of the rect was larger than the width, the formula would be easy-<p></p>

<p>(using a coordinate system where 0,0 is the bottom left corner)<br>
circle.centerPoint = (rect.width / 2, 0);<br>
circle.radius = (rect.width / 2);<p></p>

<p>But as the rect gets longer, the center point needs to drop and the radius needs to get larger.
I feel that this could be really easily figure out, but I just don't have the mathematical background to handle it.  Is there a formula out there to solve this?</p>

<p>Disclaimer: I am bad at math, and never took a calculus class. Please keep answers simple.</p>
",geometry
"<p>Let $A(\vec{a}), B(\vec{b})$ and $C(\vec{c})$ be three non-collinear points. Prove that the vector $\vec{v}$ perpendicular to the plane of the triangle $ABC$ drawn from the origin $O$ is given by $\vec{v}=\pm\vec{a}\cdot(\vec{b}\times\vec{c})\cdot\dfrac{(\vec{a}\times\vec{b}+\vec{b}\times\vec{c}+\vec{c}\times\vec{a})}{4\Delta^2}$ where $\vec{\Delta}$ is the vector area of the triangle $ABC.$<br></p>

<hr>

<p>$\vec{\Delta}=\frac{1}{2}\vec{AB}\times\vec{AC}=\frac{1}{2}(\vec{b}-\vec{a})\times(\vec{c}-\vec{a})=\frac{1}{2}(\vec{a}\times\vec{b}+\vec{b}\times\vec{c}+\vec{c}\times\vec{a})$<br>
$\Delta^2=\frac{1}{4}(\vec{a}\times\vec{b}).(\vec{a}\times\vec{b})+(\vec{a}\times\vec{b}).(\vec{b}\times\vec{c})+(\vec{a}\times\vec{b}).(\vec{c}\times\vec{a})+(\vec{b}\times\vec{c}).(\vec{a}\times\vec{b})+(\vec{b}\times\vec{c}).(\vec{b}\times\vec{c})+(\vec{b}\times\vec{c}).(\vec{c}\times\vec{a})+(\vec{c}\times\vec{a}).(\vec{a}\times\vec{b})+(\vec{c}\times\vec{a}).(\vec{b}\times\vec{c})+(\vec{c}\times\vec{a}).(\vec{c}\times\vec{a})$<br><br></p>

<p>But I don't know how to derive the required relation. Please help me. Thanks.</p>
",geometry
"<p><a href=""http://i.stack.imgur.com/UK66w.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/UK66w.png"" alt=""illustration""></a></p>

<p>There is a river in the shape of an annulus. Outside the annulus there is town ""A"" and inside there is town ""B"". One must build a bridge towards the center of the annulus such that the path from A to B crossing the bridge is the shortest possible. Where to build the bridge?</p>
",geometry
"<p>Given a matrix <strong>A</strong>, $3 \times 3$, that is symmetric with zero diagonal, I calculate a matrix <strong>V</strong>, $3 \times 3$, whose columns are the corresponding right eigenvectors and a diagonal matrix <strong>D</strong>, $3 \times 3$. of eigenvalues so that <strong>A<em>V = V</em>D</strong>.</p>

<p>I have the following question:</p>

<p>Given a vector <strong>X</strong> $1 \times 3$ how can I calculate its projection into eigenvectors-eigenvalues space <strong>VD</strong>?</p>
",geometry
"<p>I have two disks of radii $R_1, R_2$ with distance between centers, $d &lt; R_1 + R_2$.</p>

<p>How can I find the surface area common to the two disks?</p>

<p>Rationale:</p>

<p>Solar irradiation / energy input in penumbra during solar eclipse, a problem for sun-synchronous satellites. Knowing apparent size of the Sun and the Moon, and position within penumbra it's possible to calculate how much of the solar disk remains unobscured, as a simple difference between its surface and the intersection area. </p>
",geometry
"<p>In $\triangle ABC, AB=AC $ and $\angle BAC=20^\circ$ If $CD$ is the median from $C$ to side $AB$, find $\angle ADC$.</p>
",geometry
"<p>Inspired by Wikipedia's article on pentagonal tiling, I made my own attempt. </p>

<p><a href=""http://i.stack.imgur.com/XcH02.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/XcH02.jpg"" alt=""enter image description here""></a></p>

<p>I believe this belongs to the 4-tile lattice category, because it's composed of pentagons pointing towards 4 different directions. According to Wikipedia, 3 out of the 15 currently discovered types of pentagonal tiling belongs to the 4-tile lattice category (type 2, 4 &amp; 6).</p>

<p><a href=""https://en.wikipedia.org/wiki/Pentagonal_tiling"" rel=""nofollow"">https://en.wikipedia.org/wiki/Pentagonal_tiling</a></p>

<p>I don't think my attempt is an instance of type 4 or 6, since in both type 4 &amp; 6, any side of all pentagons overlaps with only one side of another pentagon, while in my attempt, half of the long sides overlap with two shorter sides.</p>

<p>At the same time, I can't figure out how my attempt is an instance of type 2... Please kindly offer your insight.</p>

<p><a href=""http://i.stack.imgur.com/SOBhB.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/SOBhB.jpg"" alt=""enter image description here""></a></p>

<p><a href=""http://i.stack.imgur.com/fPuAB.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/fPuAB.jpg"" alt=""enter image description here""></a></p>
",geometry
"<blockquote>
  <p>In hexagon $ABCDEF$, which is nonconvex but not self-intersecting, no pair of opposite sides are parallel. The internal angles satisfy $\angle A = 3\angle D$, $\angle C = 3 \angle F$, and $\angle E = 3\angle B$. Furthermore $AB = DE$, $BC = EF$, and $CD = FA$. Prove that diagonals $\overline{AD}$, $\overline{BE}$, and $\overline{CF}$ are concurrent.</p>
</blockquote>

<p>There are solutions <a href=""http://www.artofproblemsolving.com/wiki/index.php/2011_USAMO_Problems/Problem_3"">here</a> at AoPS, but I was wondering if anyone had any alternate takes on this problem/has a copy of the official solutions.</p>
",geometry
"<p>There is a plane P.100 lines are on P.Is it possible to arrange them in a way such that they intersect in exactly 2002 points given that no three of them are concurrent?</p>

<p>Any help is highly appreciated.</p>
",geometry
"<p>Two points $A$ and $B$ are in the same semi-plan(take into consideration the line $d$), and their position is arbitrary. Point $A_1$ is the reflection of $A$. Prove that the sum of distances $MA+MB$ is minimum if point $M$(M is an arbitrary point on line $d$) belongs to $BA_1$ .</p>

<p>By intuition I suppose that I somehow have to prove that the measure of angle between the segments $AM$ and $MB$ is $90$ degree, but I don't have any idea. I hope you'll help me find the solution. Thank you!!!</p>

<p><img src=""http://i.stack.imgur.com/2hecv.jpg"" alt=""enter image description here""></p>
",geometry
"<p>Given the points $M(3,4)$ and $N(1,2)$, find $x$ in the point $P(x,0)$ so that $PM + PN$ is a minimum.</p>
",geometry
"<blockquote>
  <p>I have N points in D-dimensional space. I need to calculate the farthest Manhattan distance between two points of them. </p>
  
  <p>(2 ≤ N ≤ 100000, 1 ≤ D ≤ 6), the absolute value of the given coordinates is 1000000. <a href=""http://www.spoj.com/problems/DISTANCE/"" rel=""nofollow"">Source</a></p>
</blockquote>

<p>I tried to sum the coordinates for every point, then calculate the difference between the MIN and MAX value, but this will not work with case like this</p>

<blockquote>
  <p>N = 2, D = 2</p>
  
  <p>4 -4</p>
  
  <p>-7 7</p>
  
  <p>my wrong answer  = 0 - 0 = 0</p>
  
  <p>correct answer = abs(4 - (-7)) + abs(-4 - 7) = 22</p>
</blockquote>

<p>I also tried to find the MIN and MAX coordinate for all the D coordinates and maximize the result. But it didn't work too.</p>

<p>I can't find a correct and fast solution, of course brute force will get [ Time limit exceeded ]</p>

<p>Edit: You can find a more detailed description of Joseph's answer <a href=""http://math.stackexchange.com/a/477767/275204"">here</a>. </p>
",geometry
"<p><img src=""http://i.stack.imgur.com/H0vW9.png"" alt=""enter image description here""></p>

<p>We have to find the area of the pink region. As we all know this can be evaluated using limiting its Riemann sum, of which its a standard example. However I want to know if this can be done without using calculus, with directly using geometry. I think it would be very interesting challenge, but I am not able to think of a way out.  </p>
",geometry
"<p>Given a convex quadrilateral $ABCD$. In $\Delta ABC$, $I$ is the incentre and $J$ is the excentre opposite to vertex $A$. Similarly, $K$ is the incentre and $L$ is the excentre opposite to vertex $A$ of $\Delta ACD$. Prove that the three lines $IL,JK$ and the angle bisector of angle $BCD$ are concurrent.</p>

<p>I tried assuming some angles in one if the triangle. Used some trigonometry, but the problem just got nasty. I don't think pure geometry would do it. The problem looks good. If possible, please solve using trigonometry and/or algebraic geometry. Thanks.</p>
",geometry
"<p>Find the length of the diagonal of the largest possible cube inscribed in a hemisphere of radius $ 4√2 cm$.</p>

<p>A) $12 cm$
B) $6 cm$
C) $8 cm$
D)$ 4 cm$</p>

<p>Solution</p>

<p>Diagonal of cube $= √3 edge $</p>

<p>Edge $ = 8√2$</p>

<p>So diagonal $ = 8√6 $</p>

<p>My answer is different from the given options. Where am I wrong ?</p>
",geometry
"<p>In a right angled triangle, a semicircle is drawn such that its diameter lies on the hypotenuse and its center divides the hypotenuse into two segments of lengths 15 and 20.Find the length of the arc of the semicircle between the points at which the legs touch the semicircle.</p>
",geometry
"<p><img src=""http://i.stack.imgur.com/WU0V8.png"" alt=""enter image description here"">
If point A(x1,y1) and C(x3,y3) are given i have to find points B(x2,y2) and D(x4,y4),if points B and D are given i need to find point A and C.Edges of rectangle may not be parallel to axes </p>
",geometry
"<p>For a general conic  $Q(x,y)=ax^2+2hxy+by^2+2gx+2fy+c$ we define a matrix $A$ as follows:</p>

<p>$A=\left( \begin{matrix} a&amp; h&amp; g\\ h&amp; b&amp; f\\ g&amp; f&amp; c\end{matrix} \right)$.</p>

<p>Then we define
$\tau=a+b$,  $\delta=\left| \begin{matrix} a&amp; h\\ h&amp; b\end{matrix} \right| $ ve $\Delta=\left| \begin{matrix} a&amp; h&amp; g\\ h&amp; b&amp; f\\ g&amp; f&amp; c\end{matrix} \right|$
With these arguments, we say that $Q(x,y)$ gives us</p>

<p>an ellipse if $\Delta \neq 0$ and $\delta &gt;0$ ,</p>

<p>a parabola if $\Delta \neq 0$ and  $\delta  =0$ ,</p>

<p>a hyperbola  if $\Delta \neq 0$ and $\delta &lt;0$ .</p>

<p>Now, my questions: 
Where does this $A$ matrix and all $\tau, \delta, \Delta$ definitions come from?Why do we need $\Delta \neq 0$?</p>
",geometry
"<p><a href=""http://i.stack.imgur.com/uIigP.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/uIigP.png"" alt=""enter image description here""></a></p>

<p>Given that: </p>

<p>$\vec{OA}=a$</p>

<p>$\vec{OB}=b$</p>

<p>$\vec{OC}=c$</p>

<p>And that point R and F are the mid-points of $\vec{AC}$ and $\vec{BC}$ respectively, show that $\vec{OG}=\frac{1}{3}(a+b+c)$. I am really stuck with this question. What I tried is to show that $\kappa\vec{AF}=\lambda\vec{RB}$ where $\lambda$ and $\kappa$ are constants, but It gets more complicated. Any ideas?  </p>
",geometry
"<p>Is it possible to draw an equilateral triangle which does not pass through the center of the circle(I mean the center of the circle does not lie within the boundaries of the triangle)?The given conditions are that the vertices of the triangle will touch the circumference of the circle. I assume it is not but cannot prove it. Please help.</p>
",geometry
"<p>I have 2 eqns<br>
$$ x_1+4x_3\leq4$$</p>

<p>$$ x_2+4x_3\leq4 $$
$$x_1\geq0$$
$$x_2\geq x_3\geq0$$ 
By drawing geometrical figure I have vertices whose co-ordinates is $(0,0,0) , (4,0,0) (0,0,1) ,(0,4,0) ,(4,4,0)$
I want to include an in-equality named $$x_1+x_2+x_4+x_5\geq \epsilon$$
 I cant visualize the result of adding this .
Is (0,0,1) point is out of the geometrical figure for adding the constraint ? Can you please help me to visualize the affect of adding another constraint ?</p>
",geometry
"<blockquote>
  <p>In the adjacent figure, $\frac{AG}{GD} = \frac{3}{4}$ and $\frac{BD}{DC}=\frac{4}{7}$ and $AE=12 $ cm. Find the length of $EC$.<br>
  1) 33<br>
  2) 36<br>
  3) 44<br>
  4) 48  </p>
</blockquote>

<p>Figure:<br>
 <img src=""http://i.imgur.com/FZA1ELh.jpg"" alt=""image""><br>
I think similarity of triangles is to be used but can't really find the target triangles.  </p>
",geometry
"<p>Two circles intersect at $P$ and $Q$.Through $P$ two lines $APB$ and $CPD$ are drawn to intersect circles at $A,B,C,D$. $AC$ and $DB$ when produced meet at $O$. How do I prove that $OAQB$ is cyclic quadrilateral. Please if possible first give me image so that I can also try it, I can't draw its figure properly.</p>
",geometry
"<p>A rectangle is drawn so that it fits inside the region bound by the curve $y=4Sin(x)$ where $0 \le x \le \pi$ and the x-axis. Find the maximum perimeter of the rectangle using optimization.</p>

<p>So far i've tried to say since it's a rectangle $P=2x+2y$ and thus, $P=2x+8Sin(x)$. But finding the maximum value of $x$ by letting the derivative be $0$ ended up with the value of $x$ being $104.47$. Which is outside the domain given. </p>

<p>Any help would be greatly appreciated. Thankyou</p>
",geometry
"<blockquote>
  <p>Inside a very large field there is a shed in the shape of a regular pentagon of side $12$ m. A goat is tied at one vertex of the pentagon by a rope of length $16$ m. The goat cannot access the area inside the shed. Find the area that can be accessed by the goat inside the field.  </p>
</blockquote>

<p>No figure was provided in the original question. Hence note that the  figure attached is <em>my own interpretation</em>. Please correct the figure if it seems wrong.<br>
Figure:<br>
 <img src=""http://i.imgur.com/bDKUElR.png"" alt=""1"">   </p>

<p>As I have interpreted we need to find the area of the shaded region of the circle with radius $16$ m.<br>
The problem I am facing is that I am not allowed to use the values of any trigonometric ratios besides the standard $45^{\circ},30^{\circ},60^{\circ},90^{\circ},0^{\circ}$. I could have solved it had a calulator been allowed but no value except these has to be used.  </p>
",geometry
"<p>I am having difficulty in solving below question. Please help. Find x angle in below diagram<img src=""http://i.stack.imgur.com/D82X6.jpg"" alt=""""></p>

<p>I have drawn two parallel lines from D and E intersecting sides CB and CE respectively on F and G. look below
I got x+y=70 and x+a+b=130. a=y, b=60. now how to proceed? Am I moving in right direction?</p>

<p><a href=""http://i.stack.imgur.com/HmnI9.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/HmnI9.jpg"" alt=""enter image description here""></a></p>
",geometry
"<p>Consider a triangle $ABCD$ where $A$ is the bottom left corner, $D$ is the top left corner, $C$ is the top right corner and $B$ is the bottom right corner. $DC$ and $AB$ are both $11$ units long and $DA$ and $CB$ are both 7 units long. Now consider 2 more points, $F$ and $E$. $E$ lies on $BC$, $x$ units above $B$ and $F$ lies on $DC$, $2x$ units to the left of $C$. All these points are on the perimeter of the rectangle.</p>

<p>A triangle $AFE$ is then formed.</p>

<p>Find the value of $x$ which the area of the triangle will be the least.</p>

<p>I have tried different ways in terms of area of triangles etc. However I have made no progress. Any help will be appreciated.</p>
",geometry
"<p>I need to rotate 3D coordinate system so Z axis points in new direction.</p>

<p>So, I have a direction defined by spherical coordinates ($\theta$, $\phi$), where $\theta$ (in $[0, \pi]$ range) is polar and $\phi$ (in $[0, 2\pi]$ range) is azimuthal angles. I want to transform my 3D Cartesian coordinates so that Z is now pointing in that direction.</p>

<p>Now, I understand that this is not a unique transformation -- I do not care how X and Y axis are going to rotate. I am interested only in having Z axis in the right place. </p>

<p>Is it possible to get a transformation matrix for this?</p>
",geometry
"<p>This seemingly trivial question inspired this one: Somewhere within a circle of unit radius is placed a circle of radius $r, 0 &lt; r &lt; 1$, such that this inner circle's center is uniformly distributed within $1-r$ of the outer circle's center.  An equilateral triangle with uniformly distributed orientation is inscribed within the inner circle.  (That is, all three vertices are on the inner circle's circumference.)</p>

<p>What is the probability (in terms of $r$) that the outer circle's center is inside the triangle?</p>
",geometry
"<p>Given ellipse(${x^2 \over a^2}+{y^2 \over b^2}=1$) and a point $(x_0,y_0)$<br>
We draw two tangent lines to the ellipse that are going through $(x_0,y_0)$
Find the equation of the straight line connecting two points where tangent lines are touching ellipse.<br>
I can do it through solving system of 4 equations.
But I think there is an easier, maybe geometric way of solving the problem.
Share some new ideas. Thanks.</p>
",geometry
"<p>A particle moves west at a speed of $25km/hr$ from the origin when $t=0$. Another particle moves north at a speed $20km/hr$ and stops at the origin when $t=1$, where $t$ is in hours. What will the minimum distance be between the $2$ particles and at what time $t$ does such minimum occur.</p>

<p>I have studied these questions for a while but i need help deriving an equation relating the two particle's movements to minimize them. Thanks for any help.</p>

<p>Note: The particles are co-planar.</p>
",geometry
"<p>So there is this rectangular area, $3km$ wide by $8km$ long. $A$ is at the top left hand corner of the area. $B$ is the bottom right hand corner. $C$ is the top right hand corner and $D$ is some point that lies on $BC$.</p>

<p>I have to find the quickest way to get from $A$ to $B$ when traveling across the area can be done at $6 km/hr$ while travelling along the perimeter can be achieved at $8 km/hr$</p>

<p>So essentially I have to derive an equation to get to $B$ from $A$ and minimise the time it will take to travel across the area to get to such point. </p>

<p>So far i have figure that $AD = \sqrt{3^2 +x^2}$ where $x$ is the distance of $CD$ and $DB=8-x$. However how am i supposed to make an equation to minimise the time when all i have are distance values? </p>

<p>Thanks for any help.</p>
",geometry
"<p>A spherical triangle A is called equiangular if its 3 angles are equal. A is called Platonic if copies of A tile the unit sphere. I need to find all such triangles. Don't we have an infinite amount of them? Any input would be appreciated. </p>
",geometry
"<p>I have found the formula for calculating the R of a circle, based on a circular segment, which is:</p>

<p>$$ R=\frac{h}2+\frac{c^2} {8h}$$</p>

<p>where $R$ is radius, $c$ is the length of the segment, and $h$ is the height of the segment.</p>

<p>What I want to do is solve this equation for $h$. e.g. <code>h=[...]</code>.</p>

<p>I have been trying, but for me it boils down to the fact that I don't know how to solve an equation with the form $a+b=a*d$ for $a$.</p>
",geometry
"<blockquote>
  <p>Equilateral triangles $ABX$ and $CAY$ are described on sides $AB$ and $AC$ of a $\triangle ABC$ externally to $\triangle ABC$. Prove that $CX = BY$.</p>
</blockquote>

<p>I constructed the following figure for it.</p>

<p><a href=""http://i.stack.imgur.com/X7tHG.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/X7tHG.png"" alt=""enter image description here""></a></p>

<p>I am not able to proceed any further. How could I do this?</p>
",geometry
"<p>There are two clocks.  One is a regular clock measuring regular time $\tau$.  The other is a clock measuring time $t$ which also advances clockwise, but does not advance uniformly--it accelerates w.r.t. $\tau$ from 12 to 6 o'clock, and decelerates from 6 to 12, such that the two clocks always tell the same time at 12 and 6.  It is given that the alternating acceleration and deceleration of $t$ w.r.t. $\tau$ is uniform--$\frac{d^2t}{d\tau^2}=K$ where $K$ is a constant.  Is this enough info to determine the ""dilation"" $\frac{dt}{d\tau}$?  If not, what other info is needed?</p>
",geometry
"<p>Let $O=(0,0)$, $A= (0,a)$ and $B= (b,0)$, where $0&lt;a&lt;b$ are reals. Let $\Gamma$ be a circle with diameter $\overline{AB}$ and let $P$ be any other point on $\Gamma$. Line $PA$ meets the $x$-axis again at $Q$. Prove that $\angle BQP = \angle BOP$.</p>

<p>Here is my interpretation of the diagram</p>

<p><img src=""http://i.stack.imgur.com/qdqGJ.png"" alt=""diag""></p>

<p>Is it incorrect to assume that $\Gamma$ is the circumcircle of $\triangle AOB$? Can anyone tell me what's the error?</p>
",geometry
"<p>I've been surprised at how challenging this problem is. Given an isosceles trapezoid, with the larger base b, the four angles, and the two equal sides c know, find the length of the shorter base a. Is the calculation even possible without knowing the height?</p>
",geometry
"<p>We have a square whose length is $1$ unit. Every time we rotate by $\theta$ and scale the square such as you see in the image. Does the total area of squares converge if $\theta $ goes to $0$?
<img src=""http://i.stack.imgur.com/EPECs.jpg"" alt=""enter image description here""></p>
",geometry
"<p>I have the coordinates of the endpoints of the line as $(x_1,y_1)$ and $(x_3,y_3)$.
The difference in coordinate 'delta' refers to either $\Delta x$ or $\Delta y$ (We do not know which one it is) with respect to the first point $(x_1,y_1)$. However it is known that it is the larger difference i.e., Given $a&gt;b$, if $x_2 = x_1+a$ and $y_2 = y_1+b$, then the 'delta' is $\Delta x$. Conversely, if $a&lt;b$ and the other conditions remain the same, then the 'delta' is $\Delta y$. Please note that this is not the same as distance. Only the larger difference in coordinate is available.</p>

<p>For example, Given the straight line with coordinates $(0,0)$ and $(9,4)$ with the larger 'delta' as '3', we need to find the point $(x_2,y_2)$ with this delta.</p>
",geometry
"<p>AAS says ""Any two angles and a non-included side"" while</p>

<p>ASA says ""Any two angles and the included side"".</p>

<p>That's just ""any two angles and <em>a</em> side""?  Why do we have both the AAS and ASA rules for triangle congruency?</p>
",geometry
"<p>The cissoid of Diocles is the curve whose equation in terms of polar coordinates $(r,\theta)$ is
$$r = \sin\theta \tan\theta, −\frac{\pi}{2}&lt;\theta &lt;\frac{\pi}{2}$$</p>

<p>Write down a parametrization of the cissoid using $\theta$ as a parameter and show that</p>

<p>$$\gamma(t)=\left(t^2, \frac{t^3}{\sqrt{1-t^2}}\right)$$ for $-1\lt t\lt 1$ </p>

<p>is a parametrization of it. </p>

<hr>

<p>I researched what is the cissoid of Diocles. And I reached the following graph result; </p>

<p><img src=""http://i.stack.imgur.com/OgIKg.jpg"" alt=""enter image description here""></p>

<hr>

<p>I found the question a differential geometry textbook while I am studying by myself . 
Please help me solving the question. Thank you:) </p>
",geometry
"<p>Suppose there is an arbitrary vector in 3D space :   $\vec v = (a,b,c)$  , starting from point $(x_0,y_0,z_0)$ which is the center or 'spine' of the cone.<br>
There is also the vector $\vec u = (h,i,j)$ , starting from point $(x_1,y_1,z_1)$, which goes along the outer surface of the cone.</p>

<p>It is guaranteed that there is one point of intersection between them, which means that there exists an $t$ which satisfies:<br>
$x_0+a*t = x_1+h*t$<br>
$y_0+b*t = y_1+i*t$<br>
$z_0+c*t = z_1+j*t$</p>

<p>Taking each vector as representing an infinite line in 3D space, one should be able to get a double cone by ""rotating"" the second vector around the first.</p>

<p>My question is, what would the formula for this cone be?</p>
",geometry
"<p>Below I drew a golden rectangle in a pentagon in Adobe Illustrator.  </p>

<p>What would be the best way to inscribe a golden rectangle into a pentagon as shown in the figure below in a mathematical manner?  If the length of the sides of the pentagon are 1, what is the length and width of the golden rectangle?  How do the sides of the rectangle relate to the pentagram?  What would be the best way to inscribe the golden rectangle in a perfect manner, such as in geogebra? I'm trying to figure it out!  Thanks so much!</p>

<p><a href=""http://i.stack.imgur.com/t9tu2.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/t9tu2.jpg"" alt=""golden rectangle in a pentagon""></a></p>

<p>What is the ratio of A/B and C/D?  (These do not seem to be golden ratios.)</p>

<p>Do more golden ratios emerge elsewhere?  Is there anything golden about the triangles produced around the edges?</p>

<p>Thanks so much!!</p>
",geometry
"<p>How do I calculate the length of the major axis of an <a href=""http://en.wikipedia.org/wiki/Ellipse"" rel=""nofollow"">ellipse</a>? I have the eccentricity and the length of the semi-major axis.</p>
",geometry
"<p>I've been searching for a formula, but couldn't find any. Here is the question: </p>

<p>What is the highest number of equal nonoverlapping spheres that touch a unit sphere? The distance between the points that the outer spheres touch to the inner sphere wont be any smaller than 1 unit, and this distance measuring will be along the surface of the inner sphere.</p>
",geometry
"<p>I am battling with a programming problem.</p>

<p>Given two or more overlapping and interacting Bézier polygons, how can I perform merge (union) operations on a list of input Bézier polygons so as to produce merged Bézier polygons (polygons specified in Bézier format)?</p>

<p>Any resources in the Internet or algorithms about such implementations is very much appreciated.</p>

<p>Thanks!</p>
",geometry
"<p>I recently realized the area formula of all polygons, and most basic figures can be proven from the areas of square and rectangle. For example if we know the area of rectangle, we can the area formula of parallelogram, then triangle and so on. That brings us to the question how to prove that the area of the square with side $a$ is $a^2$. </p>

<p>I just came upon ProofWiki article (<a href=""http://www.proofwiki.org/wiki/Area_of_Parallelogram/Rectangle"">http://www.proofwiki.org/wiki/Area_of_Parallelogram/Rectangle</a>), which showed me to get the area of rectangle from that of the square, which completes the rest of the link. But the square?</p>

<p>I see that for such a basic figure we need some axioms to get our foot down. One that I think is absolutely essential that that of a square of $1$ units has an area of $1$ unit square, from which we can generalize to bigger squares. Another I think which we used in the rectangle proof that, if a figure $A$ is divided into different pieces then the area of $A$ is the sum of the area of the different pieces.     </p>

<p>So my first question: what set of axioms are needed that best and unambiguously describe the area of figures?</p>

<p>Anyway, the one informal proof we are show in primary schools, that divided for example a $5 \cdot5
$ square into $25$ pieces of $1$ cm$^2$ (intuitively very plausible) fails to convince me. Somehow, we may generalize it to rational numbers, but what if the side is $\pi$? We cannot keep dividing it infinitely many times.</p>

<p>So the second question: How do we using the axioms find the area of the square? And is there any gap, when we move forward, for example with the rectangle? Thanks.</p>
",geometry
"<p>Given a random set of points in 2D space such as:</p>

<p><img src=""http://i.stack.imgur.com/oiI0J.png"" alt=""Random points""></p>

<p>How would one go about finding the smallest perimeter polygon that encompasses all points and has a point as each one of its vertices? For the above diagram the polygon would be:</p>

<p><img src=""http://i.stack.imgur.com/qafjE.png"" alt=""Corrected points with polygon""></p>
",geometry
"<p>Let the circles<br>
$$x^2+y^2-2cy-a^2=0~~~~and~~~~x^2+y^2-2bx+a^2=0$$<br>
with centres at $A$ and $B$ intersect at $P$ and $Q$. Show that the points $A,B,P,Q$ and $O=(0,0)$ lie on a circle.  </p>

<p>My work:<br>
I found out the centre of the 2 circles to be $A(0,c),B(b,0)$ and also found out that the points at the which circle cut, $P,Q$ are the common chord of both the circles. So,I found out the equation of the chord of the circle to be $bx-cy=a^2$. Now, I am stuck. I tried to figure out that these points are concylic by considering two quadrilaterals formed by these points but nothing to progress. Please help!</p>
",geometry
"<p>I have to prove the following:</p>

<p>The line segment xz is an edge of the convex hull CH(A) iff all other points of A lie in one of the closed half-planes induced by the supporting line <em>l</em>(x, z) of xz, i.e., on (x, z) or to one side of the previous.</p>

<p>So far the only idea is to start somehow with the basics that a convex combination is a linear combination of points but no idea of the next step</p>
",geometry
"<p>It is a postulate that it is possible to draw a straight line from any point to any point. Firstly, if the points are the same does this postulate still hold? Secondly, if this is a fact that can't be proven, how can we know it to be true even if it seems obvious?</p>
",geometry
"<p>There is a set of points on the Cartesian coordinate system. How do I group points into several circles with a given radius and meeting the following requirements:</p>

<ul>
<li>each point belongs to a group <strong>at least</strong>， specifically,

<ul>
<li>circles can intersect </li>
<li>a point can belong to several circles</li>
<li>points can be placed on the boundray</li>
</ul></li>
<li>the number of groups is minimum</li>
</ul>

<p>For instance, group the following points into 3 circles. </p>

<p><a href=""http://i.stack.imgur.com/Qk6zr.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/Qk6zr.png"" alt=""enter image description here""></a></p>
",geometry
"<p>Let $\vec{a},\vec{b},\vec{c}$ be non coplanar unit vectors,equally inclined to one another at an angle $\theta$.If $\vec{a}\times\vec{b}+\vec{b}\times\vec{c}=p\vec{a}+q\vec{b}+r\vec{c}$.Find scalars $p,q$ and $r$ in terms of $\theta.$<br></p>

<hr>

<p>My attempt:<br>
$\vec{a}\times\vec{b}+\vec{b}\times\vec{c}=p\vec{a}+q\vec{b}+r\vec{c}$<br><br>
$(\vec{a}\times\vec{b}).\vec{c}=p(\vec{a}.\vec{c})+q(\vec{b}.\vec{c})+r$<br>
Since the angle between $\vec{a},\vec{b}$ and $\vec{b},\vec{c}$ and $\vec{c},\vec{a}$ is $\theta$<br><br>
$(\vec{a}\times\vec{b}).\vec{c}=p\cos\theta+q\cos\theta+r.............(1)$<br>
$\hspace{1.5cm}0=p\cos\theta+q+r\cos\theta.............(2)$<br>
$(\vec{b}\times\vec{c}).\vec{a}=p+q\cos\theta+r\cos\theta.............(3)$<br>
We know that $(\vec{a}\times\vec{b}).\vec{c}=(\vec{b}\times\vec{c}).\vec{a}$<br>
From equation $(2),q=-p\cos\theta-r\cos\theta$<br>
Put this in equation $(1)$ and $(3)$<br>
$(\vec{a}\times\vec{b}).\vec{c}=p\cos\theta+(-p\cos\theta-r\cos\theta)\cos\theta+r$<br>
$(\vec{a}\times\vec{b}).\vec{c}=p(\cos\theta-\cos^2\theta)+r(1-\cos^2\theta)$<br>
$(\vec{a}\times\vec{b}).\vec{c}=p(\cos\theta-\cos^2\theta)+r\sin^2\theta...........(4)$<br>
$(\vec{b}\times\vec{c}).\vec{a}=p+(-p\cos\theta-r\cos\theta)\cos\theta+r\cos\theta$<br>
$(\vec{b}\times\vec{c}).\vec{a}=p(\sin^2\theta)+r(\cos\theta-\cos^2\theta)...........(5)$<br>
Dividing equation $(4)$ by equation $(5)$,and solving we get $p=r$<br><br>
But after that i am stuck.And could not solve further.In the answers,$p=\dfrac{-1}{\sqrt{1+2\cos\theta}},q=\dfrac{2\cos\theta}{\sqrt{1+2\cos\theta}},r=\dfrac{-1}{\sqrt{1+2\cos\theta}}$ is given.<br><br>
But i do not know how it came.Please help me.Thanks. </p>
",geometry
"<p>I'm trying to write a function that will determine whether a circular arc travels clockwise or counter-clockwise. </p>

<p>Given the X,Y coordinates for the start point, center point, and end point I first calculate the angle in radians from the center point to the start and end points.</p>

<p>I thought if I subtracted the ending line angle from starting line angle I could determine if the direction of the arc like this:</p>

<pre><code>if (angle1 - angle2 &lt;= 0): # Clockwise
else: # Counter-Clockwise
</code></pre>

<p>This does work for any cases where the arc doesn't cross the zero-radians line. But if the arc crosses that line the logic doesn't work.</p>

<p><a href=""http://i.stack.imgur.com/TNoWd.png"" rel=""nofollow"">This Illustration</a> shows that the arc S1-C-E1 works but S2-C-E2 doesn't.
I'm pretty sure I've got the right idea, I'm just stuck on the logical bit. </p>

<p>I found another question here that seemed to be similar to what I'm trying to do, but its answer involved a matrix which, I'm sad to admit, I've never learned how to work with. I need an answer that I can easily translate into code or enter into a spreadsheet.</p>

<p>Thanks for any and all assistance!</p>
",geometry
"<p>On the sides $BC, CA$ and $AB$ of the triangle $ABC$ we construct externally the squares $BCDE, ACFG $ and $ABHI$. Denote $A', B'$ and $C'$ the intersectiond points of the lines $BF$ and $CH$, $AD$ and $CI$, respectively $AE$ and $BG$. Prove, that $AA', BB'$ and $CC'$ are concurrent.</p>

<p><img src=""http://i.stack.imgur.com/SC2iv.png"" alt=""Illustration""></p>

<p>Any nice idea? Thank you!</p>
",geometry
"<p>What would be the equation for the curve highlighted on the picture? I would google it, however I don't even know what should I search for, since I don't know the technical name of this kind of curves, any idea? or advise what should I look for?</p>

<p><img src=""http://i.stack.imgur.com/CcHEe.png"" alt=""enter image description here""></p>
",geometry
"<p>Can you help me find the following to plot this curve, </p>

<p>$$y^2 = \frac{x^2 +12x +36}{x^4 -4x^3 - 12x^2 - 32x 64}$$</p>

<ol>
<li>In Explicit Form</li>
<li>Find the Symmetry</li>
<li>X &amp; Y intercepts</li>
<li>Vertical and Horizontal Assymptotes </li>
<li>Plot</li>
</ol>

<p>I've been trying to figure this out but the professor only gave an example in the $y^2 =P(x)$ form but this is $y^2 = P(x) /Q(x)$ so I'm a little confused how to go about plotting this, thanks in advance to those that can help.</p>
",geometry
"<p>$\triangle ABC$ is right angled at $A$. $AB=20, CA= 80/3, BC=100/3$ units. $D$ is a point between $B$ and $C$ such that the $\triangle ADB$ and $\triangle ADC$ have equal perimeters. Determine the length of $AD$.</p>
",geometry
"<p>When rendering object onto a screen, one must often cut up their objects into quads and triangles to allow the computer to process them and finally draw them onto a screen.</p>

<p>I am trying to slice up a given piece of geometry and end up with solely triangles. Since I am trying to incorporate something like this into a program, I am trying to find a general algorithm. I couldn't find any existing algorithms for this, so I had a go at it myself:</p>

<p><img src=""http://i.stack.imgur.com/gXyHm.png"" alt=""enter image description here""></p>

<p>The problem I'm having with this is that I sometimes end up with a gap in my shape, and at the third step I don't know how to find the correct vertex to start at.</p>

<p>Some ""rules"":</p>

<ul>
<li><p>The object can have any number of vertices (although realistically speaking a limit of ~20 would suffice)</p></li>
<li><p>The order of the vertices is known. This means the perimeter of the object is also known.</p></li>
<li><p>The collection of triangles after applying the algorithm should have the same area and perimeter as the piece of geometry at the beginning. (So the collection of triangles should be the same shape)</p></li>
</ul>

<p><strong>The question is: is there a known algorithm for cutting up a single, closed shape into triangles (or quads)?</strong></p>

<p>I don't know if this question is truly appropriate for the math exchange, but I hope someone here has done this before, or knows how to as I'm stuck.</p>
",geometry
"<p>The two endpoints of a 1-metre long rod have an initial position at $(0,0),(0,1).$ The rod slides continuously to the position $(1,0),(0,0)$ sweeping out a region in the positive quadrant. Determine the equation for the boundary of this region.</p>

<hr>

<p>My attempt:</p>

<p>At any position, let $a$ denote the distance from the lower endpoint to the origin, $b$ the distance from the upper endpoint to the origin. Then we have
$$a^2+b^2=1,$$
$$\frac{x}{a}+\frac{y}{b}=1.$$
I tried to fix $x$ and use the method of Lagrange multiplier to determine the maximal $y.$ But I couldn't solve the equations. Any ideas?</p>
",geometry
"<p>A code snippet I need to optimize is performing something peculiar. It seems that it's somehow related to transforming from a frame of reference to another. This is what it does, in mathematical terms:</p>

<p>$ \mathfrak{q}_{prevToCurrExpMap} = \exp ( \mathfrak{q}_{PrevToCurr} ) $</p>

<p>then</p>

<p>$ \mathfrak{q}_{prevToCurrExpMap} = \mathfrak{q}_{prevToCurrExpMap} + \mathfrak{q}_{rotationInduction}$</p>

<p>and finally </p>

<p>$ \mathfrak{q}_{prevToCurr} = \ln (\mathfrak{q}_{prevToCurrExpMap} ) $</p>

<p>Essentially, the orientation quaternion's exponential map is altered by a quaternion addition, and then the result is extracted by taking the logarithm. I am trying to understand the logic behind this piece of ""code"", but nothing comes to mind.</p>

<p>Is there any obvious reason for replacing a quat $\mathfrak{q}$ with $\ln(\exp(\mathfrak{q}) + \mathfrak{p})$? (at a first glance, it does not seem to encode any kind of interpolation, but it might be trickier than it appears.)</p>
",geometry
"<p>I can't seem to find a textbook solution to this. It is always assumed that the length of the sides is know.</p>

<p><img src=""http://i.stack.imgur.com/zdIzF.gif"" alt=""Isosceles triangle""></p>

<p><a href=""http://i.stack.imgur.com/zdIzF.gif"" rel=""nofollow"">Isolceles triangle</a></p>

<p>So the base $a$ is known. The bottom angles where $\alpha$ and the two sides $b$ touch, are known. </p>

<p>What is $h$?</p>
",geometry
"<p>this is a bit more complicated than the post title suggests because I was running out of words. I suppose the full title would be: ""Finding the distance between the centre of an arbitrarily rotated cylinder and a point on that cylinder which is the intersection of a ray projected from the centre of the cylinder at angles a and b, which are relative to the absolute axes.""</p>

<p>To break it down a little:</p>

<p>I have a circular cylinder, which is rotated to an arbitrary orientation in 3D. I have the radius of the cylinder and I have a vector which is the vector along the cylinder's length (essentially the cylinder's orientation). The cylinder's height is infinite.</p>

<p>I also know the coordinates of the centre of the cylinder, let's call that point p. From p I draw a line in 3D in a direction specified by two angles, alpha and beta, which are angles of rotation in the cardinal axes of x and y (i.e. the absolute axes, and not relative to the cylinder). I would like to work out the point at which this line intersects the cylinder and also the distance between the two points.</p>

<p>So to break it down further:</p>

<p>1) I need to rotate the cylinder back to the origin, and then rotate the line by the exact same same angles to get them relative to the cylinder while the cylinder is at the origin.</p>

<p>2) Using this new point of reference, I need to calculate the point of intersection between the now transformed cylinder and the line made from the two transformed angles I have.</p>

<p>I can get x and y of this point by using rCosAlpha,rSinAlpha and I can get z by using rtanBeta (I have the adjacent - r (the radius) - and need the opposite)</p>

<p>And then I simply use Pythagoras' theorem to get the distance.</p>

<p>The problem is working this all out using these two frames of reference: absolute orientations and relative orientations. Or solving problem (1) so I don't have </p>

<p>Does anybody have any ideas?</p>
",geometry
"<p>Could someone explain to me, using perhaps a very simple example in @d, what we mean by orthogonal projection from space D to space D'? Thanks</p>
",geometry
"<p>I am a woodworker and want to build boxes that are not at right angles, a pyramid for example.  I am looking for the formulas that will allow me to relate the two miter cuts necessary (one that will create a trapezoid shape, for example, and the other that will allow the edges of the trapezoids to be glued [for a normal box it is 45, for a frame it is either 0 or 90] to the exterior angle of the box. </p>
",geometry
"<p>I want to apply the <a href=""http://en.wikipedia.org/wiki/Shoelace_formula"" rel=""nofollow"">Shoelace formula</a> to a list of polygon vertices, whose order is known, but they are stored in memory in the wrong order:</p>

<pre><code>Point Nr.    x    y
1            1    0
4            1    1
2            0    0
3            0    1
</code></pre>

<p>Since the Shoelace formula contains products of coordinates (<code>x1*y2</code> etc.) of successive vertices, I would have to sort them first. Is there a way to avoid this?</p>
",geometry
"<p>I'm looking for an algorithm to find the shortest(s) path that have no intersection with the interior of a set of polygons in a bi-dimensional space:</p>

<p><img src=""http://i.stack.imgur.com/uNwm4.png"" alt=""enter image description here""></p>

<p>Is this a classical problem with a well-known solution or an equivalent or a special case of a wider range of classical problem ?</p>
",geometry
"<p>You are in a directed weighted graph with $N$ $(63 \le N \le 10^6)$ vertices and $M$ $(1 \le N \le 10^6)$ edges and you want to get from $63^{rd}$ to $4^{th}$ vertex. Going through $i^{th}$ edge takes you $t_i$ hours $(1 \le t_i \le 24)$. A big monster wants to kill you. He appears in the $i^{th}$ edge $f_i$ times per 24 hours randomly. What is the lowest expected value of you meeting with monster?</p>

<p>Input: In the first line we've got $N$ and $M$. In the $M$ following lines there are descriptions of the edges. In each line there is 4 numbers - $a_i, b_i, t_i, f_i$. It means that $i^{th}$ edge is directed from $a_i$ to $b_i$.</p>

<p>Output: You should give one number. The lowest possible expected value of you meeting with monster.</p>

<p>Example:</p>

<p>Input:</p>

<pre><code>64 3
63 4 24 24
63 2 5 1
2 4 5 1
</code></pre>

<p>Output: </p>

<pre><code>0.416667
</code></pre>
",graph_theory
"<p>What are anonymous graphs, what is graph embeddedness, and how do they relate to each other? Very confused - I could not find short answer. Thanks.</p>
",graph_theory
"<p>I need to a way to express a change in the structure of a given graph <code>G</code>, such that the original graph is <code>G</code> and the changed graph is <code>G'</code>. A change in the graph can be the addition or removal of any number of vertices and/or edges.</p>

<p>Currently, my thought is to express the change as two percentages: the number of vertices in <code>G'</code> as a percentage of the number of vertices in <code>G</code>, and the same for edges. However, it occurs to me that removing a vertex also means removing all edges connected to it.</p>

<p>Are there any standard ways of quantifying the change in a graphs structure?</p>
",graph_theory
"<p>Define the Revision Tracking Graph (RTG), which is an oriented graph (without circles) where each node x has a set C(x) associated with it, which contains all edges leading into it on all paths from a node 0 (node with empty set). Each edge can be in a set exactly once!</p>

<p>You can also describe this data structure by the rules for its growth:</p>

<ol>
<li>Start with node 0 with associated empty set <code>C(0) = {}</code></li>
<li>For any node x create a new node y where (x,y) is oriented edge from x to y and 
<code>C(y) = C(x) union { (x,y) }</code></li>
<li>For any nodes f and t, create node r, where (f,r) and (t,r) are oriented edges and 
<code>C(r) = C(f) union C(t) union { (f,r), (t,r) }</code></li>
</ol>

<p>Those rules can be described by words as 1) creating new object 2) branching and versioning 3) merging. You can see that the only difference between branching and versioning is whether there already is an edge leading from a node or not. </p>

<p>You can further differentiate the graph by naming branches (paths in the graph).</p>

<p>Base node is defined as a node b, such as <code>C(b) = C(f) intersect C(t)</code>. For short: <code>Result=(From-Base)+To</code>. In other words, if you remove all edges in C(b) from C(f) and add edges from C(t), the resulting set would have every edge exactly once and all edges from C(f) and C(t) would be present in C(r).</p>

<p>I have actually several questions pertaining to this data structure:</p>

<blockquote>
  <ol>
  <li>Prove there are no circles in the graph</li>
  <li>Prove that for certain graphs there are such nodes F,T for which base cannot be found as specified in simple equation.</li>
  <li>Prove that for each graph and each pair of nodes F and T, there is a set of n pairs of nodes Fi,Bi where Fn = F and <code>R = T + Sum(i=1..n) of (Fi-Bi)</code>.</li>
  <li>Create algorithm to find B in simple case where n = 1.</li>
  <li>Create algorithm to find Fi,Bi for i=1..n where n > 1.</li>
  </ol>
</blockquote>

<p>I know the answers to 1,2 and 4, but I put them here to get you in the mood of working with this data structure. Have fun with it, pose additional problems and find answers. Any new answers could significantly advance the theory behind revision control systems.</p>
",graph_theory
"<p>Let $A_1, A_2, \ldots, A_{20}$ be twenty sets each of size $20$ such that $|A_i \cap A_j | \le 2$. Prove that they have a system of distinct representatives.</p>
",graph_theory
"<p>Prove that if $G$ is connected, not the complete graph and $\Delta(G) &gt; 2$ then the chromatic number of G is at most $\Delta(G)$.</p>
",graph_theory
"<p>An excercise says ""deduce Konig's Theorem on bipartite graphs from Dilworth's theorem on posets"". </p>

<p>Let G be a bipartite graph, G=(A,B). Order the edges left to right. A maximum antichain is a largest independent set in the graph. </p>

<p>I can see a maximum antichain must have every vertex in G incident with it. But it doesn't follow that every edge is incident with it. That may not be true. </p>

<p>So how does one proceed? </p>
",graph_theory
"<p>I am working on the following problem:</p>

<p>Suppose that $T$ is a spanning tree of a graph $G$, with an edge cost function $c$.  Let $T$ have the <em>cycle property</em> if for any edge $e' \not \in T, c(e') \geq c(e)$ for all $e$ in the cycle generated by adding $e'$ to $T$.  Let  $T$ have the <em>cut property</em> if for any edge $e \in T$, $c(e) \leq c(e')$ for all $e'$ in the cut defined by $e$</p>

<p>Show that (i), (ii), and (iii) are equivalent, where: (i) T has the cycle property, (ii) T has the cut property, and (iii) T is a minimum cost spanning tree.</p>

<p>I believe that to show that (iii) implies (i), we suppose otherwise, and then show that this would give a cycle with an edge that can replace another edge in T and that is cheaper, whence we have a contradiction.  Similarly, I believe to show that (iii) implies (ii), we similarly suppose otherwise, and then show that this would give a cut with an edge that can replace another edge in T and that is cheaper, whence a contradiction.</p>

<p>However, I am not sure how to prove the other implications needed for this problem.  My feeling is to somehow use a similar argument to what I listed, but ""in reverse"".</p>

<p>Any help with this problem would be greatly appreciated.  Thank you very much.</p>
",graph_theory
"<p>I'm looking for a simple (or better yet, minimal) example of a planar triangulation of which dual graph (that of the faces) would be ""obviously"" non-Hamiltonian.</p>

<p>(NB: I once asked the same question for planar triangulations, but I'm now interested in their dual graphs.)</p>

<p>Thanks in advance!</p>
",graph_theory
"<p>I know that the answer to this question is given using the following regression formula:
$$f(n)=(n-1)f(n-1)+\binom {n-1}{2}f(n-3)$$</p>

<p>The first part of the right-hand side is true when a node is added somewhere between two nodes, however I'm having trouble understanding why the second part is true.</p>
",graph_theory
"<p>If two graphs are isomorphic, and one has a simple circuit of a particular length, must the other graph also have a circuit of the same length?</p>

<p>Do they also have to have the same number of such circuits? </p>

<p>In the book that I use it is claimed that the following two graphs are isomorphic:</p>

<p><img src=""http://i.stack.imgur.com/MoFPc.png"" alt=""enter image description here""></p>

<p>Graph G has two circuits of length 5, but no circuits of length 4. Graph H has one circuit of length 5 and one circuit of length 4. Doesn't this mean that they are not isomorphic?</p>

<p>Edit: The book shows their isomorphism with the function f, where f(u1)=v6, f(u2)=v3, f(u3)=v4, f(u4)=v5, f(u5)=v1, f(u6)=v2. Doesn't this prove that they are isomorphic?</p>
",graph_theory
"<p>Is there a natural to other than 0 such that in the diagram of Hasse of natural with divisibility there is a natural between a and 0?</p>
",graph_theory
"<p>I'm looking for a way to generate random connected directed acyclic graphs, where I can specify the number of vertices that have no outgoing edges (leaf vertices).</p>

<p>Anyone ever seen such a thing, or know how to generate such graphs?</p>

<p>Thanks.</p>
",graph_theory
"<p>Let $d_1$, $d_2$, ..., $d_n$ be positive integers. Let $B$ be the $n \times n$ matrix
$$\begin{pmatrix}
d_1 &amp; 1 &amp; 1 &amp; \cdots &amp; 1 \\
1 &amp; d_2 &amp; 1 &amp; \cdots &amp; 1 \\
1 &amp; 1 &amp; d_3 &amp; \cdots &amp; 1 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; 1 &amp; 1 &amp; \cdots &amp; d_n \end{pmatrix}.$$
When does $B$ have a square root in $\mathrm{Mat}_n(\mathbb{Z})$?</p>

<p>Motivation: The <a href=""http://en.wikipedia.org/wiki/Friendship_graph"" rel=""nofollow"">Friendship Theorem</a> states that the only graph in which every pair of vertices is joined by a path of length $2$ is the ""Friendship Graph"", which you can see at the linked article. If $A$ is the adjacency matrix of such a graph, with degree sequence $(d_1, d_2, \ldots, d_n)$, then $A^2=B$. So this contributes the solution $(d_1, d_2, \ldots, d_n) = (2,2,2,\ldots,2,2m)$, with $n=2m+1$.</p>

<p>I was preparing notes on the friendship theorem and got distracted by trying to figure out when this matrix has an integer square root at all. It seemed like it might make a nice challenge for here.</p>
",graph_theory
"<p>I am having trouble understanding and producing integer linear programming formulations for combinatorial optimisation problems.</p>

<p>I can understand basic ones like the knapsack problem:</p>

<p>$min \quad \sum_{i \in I} v_i x_i$<br>
$s.t.$<br>
$\qquad \sum_{i \in I} w_i x_i \leq K$<br>
$\qquad x_i \in \{0, 1\} \qquad (i \in I)$</p>

<p>however when it comes to something like this formulation for the steiner minimal tree problem:</p>

<p>$min \quad \sum_{[i,j]\in E} d_{ij}$<br>
$s.t.$<br>
$\qquad d_{ij} \leq \| a^i-x^j\| - M(1-y_{ij}), \quad [i,j] \in E_1,$<br>
$\qquad d_{ij} \leq \| x^i-x^j\| - M(1-y_{ij}), \quad [i,j] \in E_2,$<br>
$\qquad d_{ij} \leq 0, \hspace{105pt}  [i,j] \in E_3,$<br>
$\qquad \sum_{j\in S} y_{ij} = 1, \hspace{82pt} i \in P,$<br>
$\qquad \sum_{i &lt; j,i \in S} y_{ij} = 1, \hspace{68pt} j \in S - \{p+1\},$<br>
$\qquad y_{ij} \in \{0,1\}, \hspace{87pt} [i,j] \in E,$<br>
$\qquad d_{ij} \in \mathbb{R}, \hspace{104pt} [i,j] \in E,$<br>
$\qquad x^i \in \mathbb{R}, \hspace{105pt} i \in S.$  </p>

<p>I have trouble working out what each of the constraints represent.</p>

<p>I am not asking for someone to explicitly explain that particular problem (although that would be a good help) I am more asking for advice on good ways to increase my understanding ILP formulations for combinatorial optimisation problems - especially for graph theory related problems.</p>

<p>Are there any good resources that people could recommend that explain the basics well with some good worked examples?</p>

<p>I'm sure I will get it eventually, it feels like the sort of thing that takes a while to understand and then it just ""clicks"" all of a sudden; I just need some help getting it to ""click""!</p>

<p>Any help would be greatly appreciated.</p>
",graph_theory
"<p>How many paths <em>starting from a given node</em> touch each node a given number of times?</p>

<p>We have a complete graph with vertices $1,2,3…j$. We want to know the number of paths of length $N$, starting from vertex $1$, such that vertex $i$ appears $k_i$ times for $1≤i≤j$. $N$ is equal to the sum of the $k_i$'s.</p>

<p>For the case with arbitrary initial vertex, the answer has been provided elsewhere on this forum (see <a href=""http://math.stackexchange.com/questions/129451/find-the-number-of-arrangements-of-k-mbox-1s-k-mbox-2s-cdots/129802#129802"">Find the number of arrangements of $k \mbox{  }1&#39;$s, $k \mbox{  }2&#39;$s, $\cdots, k \mbox{  }n&#39;$s - total $kn$ cards.</a>) </p>
",graph_theory
"<p><em><a href=""http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.4863"" rel=""nofollow"">Cai-Furer-Immerman </a> showed that the W-L(Weisfeiler-Lehman )
hierarchy cannot distinguish general graphs except at linear dimension.</em></p>

<p>Even besides CFI's result, there is good reason to believe that purely
combinatorial methods cannot work for general graphs. Even for the
""bounded parameter"" families for which we have polynomial-time
algorithms, the group-theory method is generally required. </p>

<p>Furthermore,
the ""algebraic structure"" of the GI problem seems essential to its
potential tractability, since every generalization of GI that destroys
the algebraic structure is NP-complete.</p>

<p><strong>But I can not find any error in <a href=""https://www.researchgate.net/publication/296704876_An_Ofracnlog_2n2log_2n2_Graph_Isomorphism_Algorithm_for_a_Restricted_Class_of_Graph"" rel=""nofollow"">this quasi-polynomial claim</a>, which proposition is wrong?</strong></p>

<p>The algorithm does not depend on W-L method entirely though .</p>

<p>This post is motivated by <a href=""http://cstheory.stackexchange.com/questions/32237/is-anyone-aware-of-a-counter-example-to-the-dharwadker-tevet-graph-isomorphism-a"">this query</a> .</p>

<p>Link of the claim :<a href=""https://www.researchgate.net/publication/296704876_An_Ofracnlog_2n2log_2n2_Graph_Isomorphism_Algorithm_for_a_Restricted_Class_of_Graph"" rel=""nofollow"">'Quasi polynomial claim for a restricted class Graph Isomorphism'</a></p>
",graph_theory
"<p>suppose that $G$,$H$,$K$ are connected graphs with at least two vertices,prove that the only solution of the equation $L(G)=H \square K$ is $K=K_n$ ,$H=K_m$ and $G=K_{m,n}$.</p>

<p>because the eigenvalue of any line graph $L(G)$ is not fewer than -2 (as a theorem),if we suppose that $K$ and $H$ will be some thing else,some how I must make a contradiction. but I can't make it.</p>

<p>I don't what to do,any hint or guidance me to be in right way will be great ,thanks.</p>
",graph_theory
"<p>So while going through the <a href=""https://www.dropbox.com/s/428pyq6lek1tfax/WeightedGraphMatchingApproach.pdf?dl=0"" rel=""nofollow"">paper</a> H. A. Almohamad and S. O. Duffuaa: <em><a href=""https://www.google.com/search?q=%22linear%20programming%20approach%22%20%22weighted%20graph%20matching%22"" rel=""nofollow"">A Linear Programming Approach for the Weighted Graph Matching Problem</a></em>, <a href=""http://dx.doi.org/10.1109/34.211474"" rel=""nofollow"">DOI:10.1109/34.211474</a>. I came across the equation
<a href=""http://i.stack.imgur.com/N7LZX.png"" rel=""nofollow"">Equation (7) being transformed to Equation (10).</a> I don't seem to know how they achieved that and what it means.</p>

<p>$$R=A_GP-PA_H \tag{7}$$</p>

<p>$$VEC(R)=A_{GH} VEC(P) \tag{10}$$</p>

<p></p>

<p>P- is an orthogonal matrix $n \times n$
<br/>A<sub>G</sub> and A<sub>H</sub> are Adjacency matrices</p>
",graph_theory
"<p>I've got this problem on my Graph algorithms exam and I still can't solve it!Here is the problem:
At first there are 100 people sitting at a round table and neither one is  enemies with their neighbor. Than first night comes and each person becomes an enemy with one of his neighbor.How many nights have to pass so that there is no more way that one can be sat down so one doesn't sit beside his neighbor?</p>
",graph_theory
"<p>If we use the standard definition of a path in a graph, is it possible that there exists an infinite path in a finite graph?</p>
",graph_theory
"<p>I've read an article about a comparison between human brain and artificial neural networks. It's said that human brain contains $\approx 10^{11}$ neurons and each neuron is connected to $\approx 10^4$ others! Is it possible? What kind of graph would it be?</p>
",graph_theory
"<p>I feel like it is, but couldn't find anything online to support it - suppose the set A={a,b,c} and the relation set R={(a,b),(b,c),(c,a)}, would the transitive closure be reflexive (ie contain (a,a), (b,b) and (c,c)) since you can go from a back to a going all the way around?</p>

<p>Thanks in advance.</p>
",graph_theory
"<p>If G is a simple graph containing exactly two components H and H', show that $$|E(G)| \le \frac{(|V(G)|-1)(|V(G)|-2)}{2}$$</p>

<p>Here is my (incomplete) proof that I need help with:<br>
 1. Since H and H' are components of G, $E(H) \cap E(H') = \emptyset$ and $V(H) \cap V(H') = \emptyset$.<br>
 2. Therefore $|E(G)| = |E(H)| + |E(H')|$ and $|V(G)| = |V(H)| + |V(H')|$.<br>
 3. Suppose H and H' are complete subgraphs. Then $|E(H)| = C(|V(H)|, 2) = \frac{(|V(H)|)(|V(H)|-1)}{2}$.<br>
4. Similarly, $|E(H')| = \frac{(|V(H')|)(|V(H')|-1)}{2}$.<br>
5. Let $|V(H)| = a$ and $|V(H')| = b$. Then, $|E(H)| = \frac{a(a-1)}{2}$ and $|E(H')| = \frac{b(b-1)}{2}$ and $|V(G)| = a + b$.<br>
6. $Max |E(G)| = |E(H)| + |E(H')| = \frac{a(a-1) + b(b-1)}{2}$.<br>
7. Therefore, $|E(G)| \le \frac{a(a-1) + b(b-1)}{2}$.<br>
8. ...</p>

<p>How do I show that $\frac{a(a-1) + b(b-1)}{2} \le \frac{(a+b-1)(a+b-2)}{2}$ for all $a, b \ge 1$? If I can do that, I can show that $|E(G)| \le \frac{(a+b-1)(a+b-2)}{2}$ and thus $|E(G)| \le \frac{(|V(G)|-1)(|V(G)|-2)}{2}$.</p>

<p>EDIT: Is my approach correct? I am also open to any alternative methods of proof for this question. </p>
",graph_theory
"<p>Find a connected graph whose automorphism group has size 3.</p>

<p>Note: I know such graph must be non-simple.</p>
",graph_theory
"<p>Let p1, p2, . . . , pn be n points in the plane such that the distance between any two points is
at least one. Let G = (V, E) be the graph such that V = {p1, p2, . . . , pn} and E = {pipj
|
distance between pi and pj
is exactly one}. Show that ∆(G) = 6.</p>
",graph_theory
"<p>What is the method of proof to show that a graph has a certain topological minor? I am in a rigorous second discrete math class where we were given this question:</p>

<p><strong>Prove or disprove: If G is bipartite and does not have K3,3 as
a topological minor, then G is planar.</strong></p>

<p>My idea was to show that G does not have K5 as a topological minor, then invoke Kuratowski's Theorem. The problem was I could not 100% think of a way to show that G has the K5 topological minor since we never went over a way of proof in lecture. Any help would be great!</p>
",graph_theory
"<p>How many induced graphs has a graph with $n$ vertices?</p>

<p>I think that there are $2^n=\sum_{k=0}^n \binom{n}{k}$.Is this correct?</p>
",graph_theory
"<p>Arrange $2^{n-1}-1$ zeroes and $2^{n-1}$ ones in a balanced full binary tree of depth $n$. If we want the number of edges that connect the same (and respectively different) digits are the same, then one claims that the root of this tree has to be a one. Why is that?</p>

<p>For example, if $n=2$, then we need to arrange 1 zero and 2 ones. One arrangement that makes the number of edges that connect the same digits (which in this case is only one: the edge with a ""+"" who connects 2 ones,) and the number of edges that connect two different digits (which in this case is also one: the edge with a ""-"") are the same. Note that the root of this tree is unexceptionally 1.</p>

<pre><code>      1
    /   \
 + /     \ -
  /       \
 1         0
</code></pre>

<p>And here is a case where $n=3$.</p>

<pre><code>          1
        /   \
     + /     \ -
      /       \
     1         0
  + / \ -   + / \ -
   /   \     /   \
  1     0   0     1
</code></pre>

<p>Again, we see that the root is a one. If we change the root to a zero, however, then we can never find an arrangement that makes the number of ""+"" edges equals to the number of ""-"" edges. Why is that?</p>
",graph_theory
"<p>I am trying to show that a graph is planar. Possibly the simplest method I have found is to show the graph can be drawn on a page (i.e. in the plane) without any edges crossing. So, can I assume that if I am given a graph that has edges crossing I can simple move the vertices around to obtain a version such that the edges are not crossing (if such an arrangement exists)?</p>

<p>It may be better to show an example of what I am thinking. Perhaps someone can confirm that what I have done is permutable. Refer to the figure below were I start with the left graph and end with the right graph.</p>

<p><a href=""http://i.stack.imgur.com/EnE2d.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/EnE2d.jpg"" alt=""enter image description here""></a></p>

<p>Alternatively, it seems as though one can show a graph is planar if it can be embedded in a disk. I believe the following figure shows such an embedding in a disk</p>

<p><a href=""http://i.stack.imgur.com/euukC.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/euukC.png"" alt=""enter image description here""></a></p>
",graph_theory
"<p>If I take a triangle-free graph, By <a href=""http://en.wikipedia.org/wiki/Gr%C3%B6tzsch%27s_theorem"" rel=""nofollow"">Grötzsch's theorem</a>, it should be 3-colorable, and I have already had a coloring. If I change the color of one vertex, and I want to check how many vertices (at least) do I need to change, and I cannot find an idea on writing an algorithm to find out. I know that by symmetry, I can exchange two colors, I will get a new coloring method, it gives an upper bound. But it cannot give me any idea about the algorithm. </p>

<p>Is there any hint or literature to help me? Thanks for your attention!</p>
",graph_theory
"<p>I have read proofs and descriptions stating that a planar connected graph have the Euler characteristic 2. I'm not sure if that statement is equivalent to ""a connected graph with the Euler characteristic 2 have a planar embedding""?</p>

<p>I'm studying a math course where I'm supposed to show that a certain graph have a planar embedding, and I'm wondering if I can show it by using the Euler characteristics.</p>
",graph_theory
"<p>Consider a graph that we know is completely connected and has a Hamiltonian cycle. Can we say that it is two colorable because we visit each vertex once and alternate colors as we walk the cycle? Or is this there something that I'm overlooking?</p>
",graph_theory
"<p>Suppose we have a finite simple graph $G$. Call $\mathcal O$ the set of graphs without isolated vertices up to isomorphism whose line graph is isomorphic to $G$. Can $\mathcal O$ contain more than one element?</p>
",graph_theory
"<p>How to prove inductively the total number of paths from the root to all leaves in a given tree? </p>

<p>From what I understand, one should show how to find the number of paths to a specific leaf, then use induction to find the total number of paths to all leaves. However, I am not quite sure how to show the this step mathematically. </p>
",graph_theory
"<p>From an array of u rows and v columns ,we can derive a directed graph G = (N,A), where each node i elementof(N) is a pair [h(i), k(i)] where h(i) indicates the row and k(i) indicates the column of the element represented by i. The number of nodes is n = uv. An arc (i,j) elementof(A) exists if k(j) = k(i)+1 and h(j) =h(i) + alpha, where alpha = −1; 0; 1 but the extreme cases in which h(i) = 1 or = u; the cost of arc (i, j) is set to the entry associated to the pair [h(i), k(i)], i.e. all the arcs leaving node i have the same cost, and it is the value at position [h(i), k(i)]. With this transformation the shortest path problem on the grid is mapped into a shortest path problem on a classical graph. By using this transformation, we can see that our problem has another special characteristic: the graph G is a stable acyclic sequential layered graph. </p>

<p>this is taken from Circular Shortest Path on Regular Grids by Changming Sun Stefano Pallottino</p>

<p>what is alpha here? how to represent the adjacency matrix of grid graph?</p>
",graph_theory
"<p>Would you do it by showing that elementary matrix operations can be used to get from one matrix to the other? If not, how would you show that 2 adjacency matrices are isomorphic?</p>
",graph_theory
"<p>I'm struggling with the following question:</p>

<blockquote>
  <p>Prove that every Eulerian graph of odd order has three vertices of the same degree.</p>
</blockquote>

<p>I'm not sure how to proceed with this. If someone could give me a boost it would be appreciated.</p>
",graph_theory
"<p>I have been recently reading about Cayley graphs and character theory. It is evident that Cayley graphs are very useful tool in theoretical computer science. In physics, Cayley graphs seem do appear in the study of quantum walks. I wonder however, if they have been used anywhere else in physics, specially in the study of the spectral properties of physical systems. Any references will be helpful.</p>

<p>Thanks in advance.</p>
",graph_theory
"<p>I have a research question that involves human subjects being sorted into groups before playing a social game. </p>

<p>Before sorting, each person decides on their preferred group size, from 1 to n; where n is the total number of players.</p>

<p>I want to be able to sort people into groups of their preferred size, allowing a given level of tolerance for being in a group size that differs from the preferred group size. </p>

<p>For example, in the simplest case we allow no tolerance.
Consider the set of group size preferences for a population of 25 players</p>

<blockquote>
  <p>G = [1 1 1 1 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 5 5 5 5].</p>
</blockquote>

<p>This will result in the following sorting:</p>

<blockquote>
  <p>Group a: [ 1 ]</p>
  
  <p>Group b: [ 1 ] </p>
  
  <p>Group c: [ 1 ]</p>
  
  <p>Group d: [ 1 ]</p>
  
  <p>Group e: [ 2 2 ]</p>
  
  <p>Group f: [ 3 3 3 ]</p>
  
  <p>Group g: [ 3 3 3 ]</p>
  
  <p>Group h: [ 4 4 4 4 ]</p>
  
  <p>and the group of remainders: [ 2 3 3 4 4 5 5 5 5 ].</p>
</blockquote>

<p>Note how group size equals group size preference and the remainders are all those individuals that could not be put into a group of preferred size.</p>

<p>I want to be able to extend this by allowing some level of tolerance in acceptable group size compared to the preference. For instance, an individual that prefers to be in a group of 3, with tolerance of 1, would be willing to be in any group of size 2-4, but would otherwise be a remainder. However, being in a group of preferred size should have more weight than being assigned to a different group.</p>

<p>Can this problem be solved to minimise:
a.) the number of individuals that are left as a remainder
b.) the number of people that are put into groups different to their preference
c.) the level of tolerance?</p>

<p>Even pointing to similar problems would be much appreciated. </p>

<p>Thank you for any assistance!</p>
",graph_theory
"<p>A non-closed path is chosen at random on the complete graph K9. All
paths are equally likely. What is the probability that the path contains
the edges {23} and {34} given that it is length 6? Given that it has
the edge {89}?</p>
",graph_theory
"<p>I need to prove that in a planar graph with more than two vertexes at least a vertex with a maximum grade of five exists.</p>

<p>I know that planar graphs fulfill the relation $\#E \le 3\#V-6$, and relation $\#E \le 2\#V-4$ if there is no subgraph that is isomorphic to $K_{3}$. $\#E$ being the number of edges and $\#V = n$ being the number of vertexes.</p>

<p>Based on the statement that says $\sum_{i=1}^{n}gr(v_{i}) = 2\#E$ I have come up that for complete graphs $K_{n}$ the next relation must be fulfilled: $$n^{2}-4n+6\le 0$$ But I can not figure how to prove what it is asked to prove </p>
",graph_theory
"<p>All the citizens of a country,of which the alphabet has $10$ letters have as a name a word of length exactly $6$.
The number of the citizens is $10^6$ and all of them have different names.If $G$ is the graph with vertices the citizens and $2$ citizens are connected with an edge if and only if their names differ exactly at one position,which is the diameter of $G$ ? </p>
",graph_theory
"<p>Hi I saw in an R forum the <a href=""https://stat.ethz.ch/pipermail/r-help/2011-February/268569.html"" rel=""nofollow"">answer</a>: </p>

<p>“If the graph has n nodes and is represented by an adjacency matrix, you can square the matrix (log_2 n)+1 times. Then you can multiply the matrix element-wise by its transpose. The positive entries in the 7th row will tell you all nodes sharing a cycle with node 7.  This assumes all edge weights are positive.""</p>

<p>I’m a PhD student working on my research and I need to check for cycles in a directed graph to make sure it is a DAG. The answer given is extremely useful but I need the theorem statement, or a reference. Does anyone has a book reference where this is stated or a paper?</p>

<p>Thanks!</p>

<p>Daniela.</p>

<p>PS Unfortunately the people from the R forum didn't let me to ask the question there</p>
",graph_theory
"<p>Let $S_1$ and $S_2$ be two minimal separators of a graph $G$ such that $S_1\cap S_2 \neq \phi$. Then is it true that $S_1 \cap S_2$ is also a minimal seperator. </p>
",graph_theory
"<p>So I was given this question that asks: Given a simple graph with $n = 4k + 2$ vertices. Can the vertices of
this graph have distinct degrees?</p>

<p>I was wondering how I would go about this. I am usually provided a graph as a visual but I am confused with this question</p>
",graph_theory
"<p>In advance I apologise for my lack of Mathematical knowledge and low quality question: I'm not trained as a mathematician, nor do I have a substantial knowledge of mathematical terminology. However, I'm eager to put my programming lines into a mathematical framework, so that's why I ended up here. </p>

<p>My problem is the following:
Consider a semi-random network of $N$ nodes $i$ and $M$ connections, the structure of the network does not really matter here. Now I have defined the degree $k$ of a node $i$ as
$$
    k_i=\sum\limits_j A_{ij}
$$
with $A_{ij}$ the adjacency matrix defining the connections between nodes in the network and summing over all nodes $N$.  </p>

<p>Now I want to define hubs in the network using a hub threshold $k_h$. I actually want to <em>count</em> the number of hubs in my network with respect to the total number of nodes $N$ (let's call this $H$), so far I've come up with this:
$$
H=\frac{1}{N}\sum\limits_i \sum\limits_{k_i&gt;k_h} i
$$
But I don't think this gives me the right answer, since say that node 10 and 11 are hub nodes, the answer would be $21/N$ instead of $2/N$. I feel like I'm very close, but I can't see it. How should I state it?</p>

<p>Many thanks!</p>
",graph_theory
"<p>Let $X_1, \ldots, X_n$ be a collection of random variables. Consider the directed graph with vertex set $\{ 1, 2, \ldots, n \}$ where there is a directed edge $i \to j$ if $\mathbb{P}(X_i &gt; X_j) &gt; \frac{1}{2}$. </p>

<p><strong>Question 1:</strong> What directed graphs can arise in this way? Certainly they must be simple and have no loops. Is that the only restriction? Alternatively, $\mathbb{P}(X_i &gt; X_j) &gt; \frac{1}{2}$ defines an irreflexive antisymmetric relation on $\{ 1, 2, ... n \}$. Which such relations arise in this way? </p>

<p><strong>Question 2:</strong> Does the answer change if we require the $X_i$ to all be defined on a finite sample space? </p>

<p><strong>Question 3:</strong> What if we require the $X_i$ to be independent? </p>

<p>It is known (see <a href=""http://en.wikipedia.org/wiki/Nontransitive_dice"">nontransitive dice</a>) that this graph can have directed cycles even if the $X_i$ are independent; in particular, the corresponding relation need not be transitive. </p>
",graph_theory
"<p>I have the following graph theory question that I am stuck on:</p>

<p>Prove or disprove:
For every graph G and every integer $r \geq \text{max} \{\text{deg}v: v \in V(G) \}$ , there is an r-regular graph H containing G as an induced subgraph. Thanks for any help.</p>
",graph_theory
"<p>Can somebody explain why there cannot be any triangles or squares in a Moore graph with diameter 2? This was stated without proof in my class. </p>
",graph_theory
"<p>Like everybody on this website it seems, I have a traveling salesman problem. But the traveler wants to visit tunnels, so his exit points are not the entry points, he has to visit all of them, and his travel distance between tunnels has to be minimized. The tunnels are one way, he doesn't get to choose the travel direction.</p>

<p>Is there an academical name for this variant? some google keywords? </p>
",graph_theory
"<p>I'm currently reading a proof of the following claim from the notes <a href=""http://www.cs.berkeley.edu/~sinclair/cs271/n5.pdf"" rel=""nofollow"">http://www.cs.berkeley.edu/~sinclair/cs271/n5.pdf</a> which can be found on the bottom of page 6. I'd like to point out i'm interested in the random algorithmic aspects of the notes and have never studied Boolean functions before.</p>

<p>Claim 5.4: Almost all $n$-input Boolean functions require circuits of size at least $2^{n}/n$</p>

<p>The proof goes as follows: </p>

<p>Proof: (sketch) Let $N(S)$ be the number of circuits of size $S$. To bound $N(S)$, note that each gate has two
possible inputs and $16$ functions, so there are $16\times S^{2}$
choices for a single gate, so the number of circuits is
$N(S) \leq (16 ∗ S^{2})^{S}$. There are $2^{2^{n}}$
different functions with $n$ inputs. A calculation shows that if $S &lt; 2
^{n}/n$,
then $N(S)/2^{2^{n}} \rightarrow 0$
as $n \rightarrow \infty$.</p>

<p>Questions:</p>

<p>1) (NOT REGARDING PROOF) Firstly they mention briefly what a gate is but can every boolean function be represented using a series of gates? On page 6 they seem to mention a boolean function has $n$ inputs ($x_{1},...,x_{n}$) and $1$ output, and then just jump to a notion of a gate without really linking them together.  </p>

<p>2) (REGARDING PROOF) I understand since each gate has two inputs for example $x_{2},x_{5}$ and $|\{0,1\}^{2}|=4$ each of these pairs can be assigned two values $0$ or $1$ and so there are 16 possible functions. How did they get $16 \times S^{2}$ possible choices for each gate and more importantly what do they mean here by choice?</p>

<p>3) (REGARDING PROOF) How does the deduction that if $S&lt;2^{n}/n$ then then $N(S)/2^{2^{n}} \rightarrow 0$
as $n \rightarrow \infty$ complete the proof?</p>

<p>I really appreciate any help. </p>
",graph_theory
"<p>Prove or disprove: There exists an integer k such that every k-connected graph is hamiltonian.</p>
",graph_theory
"<p>$G$ is a connected graph. Show that if $A,B$ are bonds, and $e \in A \cap B$, there is a bond $C \subseteq A \cup B \setminus \{e\}$</p>

<p>A bond is a set of edges $X$ so that $G \setminus X$ has two connectivity components.</p>

<p>Any hints and assistance would be much appreciated!  </p>
",graph_theory
"<blockquote>
  <p>If $G$ is a connected finite graph which has no triangles, and $G$ has the property that if two vertices have a common neighbour then they have exactly two common neighbours, does $G$ have to be strongly regular?</p>
</blockquote>

<p><strong>Note:</strong> I showed it is regular, but how to prove/disprove it's strongly regular?</p>
",graph_theory
"<p>There is a transitive tournament (T) with $n &gt; 1$  vertices and the  score sequence is defined as $s_1, s_2, \ldots,s_n$</p>

<p>Prove that T is transitive if and only if the score of the $k^{th}$ vertex ($s_k$) = '$k-1$' for $k =1,2,\ldots. n $ </p>

<p>i.e $s_k = k-1$ for all $k= 1,2,3,\ldots, n$</p>

<p>I have been researching and noticed that this is similar to the Landau's Theorem (1953), however i am completely lost with the proof. I know that thew score is the out degree, and i know that the out degree is the total number of edges coming out of the vertex (n-1) minus the in-degree , which is of course also (0,1,2,3...n-1). </p>

<p>I know that a tournament must have a unique ranking, and i also know that at transitive  tournament must have at least one in degree on 0 .</p>

<p>I also know that a transitive tournament must have an in degree sequence of $(0,1,2,3,...n-1)$, and obviously the out degree is the number of edges minus that. </p>

<p>I have tried going along the lines of proof by contradiction, but i am completely stuck </p>

<p>I would really like to find a proof for this, please help! </p>
",graph_theory
"<p>Is there an elementary (no consideration of root systems involved) proof of the fact that the graph of an finite coxeter system doesn't entail any cycle? I got as far as this: If there were any cycle $s_1,\dots,s_p$, consider the element $s_1\dots s_p$. It's probably going to be of infinite order (but I can't say why) and therefore the coxeter group isn't finite. Alternatively, $(s_1\dots s_p)^r$ could yield to elements of increasing length contradicting the fact that finite coxeter groups entail an element of maximal length.</p>
",graph_theory
"<p>Prove that in a group of 60 people one can always find two people with even number of common acquaintances. </p>

<p>I just want a small hint to this problem , not a full solution .</p>
",graph_theory
"<p>A coherent graph with at least $3$ vertices is called doubled coherent,if it remains coherent even if we delete any edge.How many,at least,edges do such a graph with $n$ vertices has to have?</p>

<p>I think that it should have at least $n$ edges,or am I wrong?</p>
",graph_theory
"<p>We say that a graph $G$ is distributed with $\mathcal{G}_{n,p}$ if it is a graph on $n$ vertices, and for which each of the ${n\choose 2}$ possible edges is chosen independently of the other edges and with probability $p$.</p>

<p>A <em>monotone property</em> $P$ of a graph is a set of graphs (on $n$ vertices) that is closed from above (that is, if $G\in P$ and $G\subseteq H$ then $H\in P$.</p>

<p>A function $f(n)$ is said to be a <em>threshold</em> for a property $P$ if for any $p(n)=\omega(f(n))$, $G\sim\mathcal{G}_{n,p}$ has $P$ asymptotically almost surely (a.a.s.), and for any $p(n)=o(f(n))$, $G\sim\mathcal{G}_{n,p}$ does not have $P$ a.a.s.</p>

<p>For example, if $P$ is ""has a triangle as a subgraph"", then $P$ is clearly monotone, and $f(n)=n^{-1}$ is a threshold for $P$. $f(n)=\frac{\ln{n}+\ln\ln{n}}{n}$ is a threshold for the Hamiltonicity property (in a stronger sense).</p>

<p><strong>My question is this:</strong> what are the thresholds for the properties of having ""quite short"" paths or cycles? By ""quite short"" I mean of length $\Theta(n^\varepsilon)$ for some $0&lt;\varepsilon&lt;1$, or of length $\Theta(\ln{n})$.</p>
",graph_theory
"<blockquote>
  <p>Thomassen ($1983$): Prove that there exists a function $f : N → N$ such
  that every graph of minimum degree at least $3$ and girth at least
  <em>f(r)</em> has a K$_{r}$ minor, for every $r ∈ N$.</p>
</blockquote>

<p>So my book says that the proof results from theses two Lemmas (<strong>BOLDED</strong>), but I am having a hard time seeing the connections. </p>

<p>I just need to know/understand how it results from the two lemmas (I want to say this problem might just be some simple algebraic manipulation of the equations to find the functions, but I am having a hard time figuring it out. Maybe solve for a $k$ in terms of $r$ then plug it in somewhere?)</p>

<p>This is from the book:</p>

<blockquote>
  <p>""There exists a function $f: N → N$ such that every graph of minimum
  degree at least $3$ and girth at least $f(r)$ has a $K_r$ minor, for all
  <em>r∈ N</em>. </p>
  
  <p>Proof. </p>
  
  <p>We prove the theorem with $f(r) := 8 log r + 4 log(log r)+ c $, for some constant $c∈R$. Let $k = k(r)∈N$ be minimal with $3·2k$
  $≥ c′r\sqrt{logr}$, where $c′∈R$ is the constant from Theorem $7.2.3.$ 
  Then for a suitable constant $c∈R$ we have $8k + 3 ≥ 8 log r +$
  $4log(log &gt; r)+ c$, 
  and the <strong>result follows by Lemma $1$ and $2$</strong> (below).""</p>
  
  <p>$1.$ <em>(Kostochka $1982$)</em> There exists a constant $c∈R$ such that for every $r ∈ N$, every graph $G$ of average degree $d(G) ≥ c ·r\sqrt{logr}$ contains a K$_r$ as a minor. Up to the value of $c$, this bound is best
  possible as a function of $r$.</p>
  
  <p>$2.$ Let $d, k ∈ N$ with $d≥3$ and let $G$ be a graph of minimum degree $\delta(G)≥d$ and girth $g(G)≥ 8k+3$. Then $G$ has a minor $H$ of minimum
  $\delta(H) ≥ \{d(d − 1)\}^k$.</p>
</blockquote>
",graph_theory
"<p>Given two points $X,Y$ on two sides of square $[0,1]\times [0,1]$ ($X:(0,1/2),Y:(1,1/2)$ (PS: My original question is $X,Y$ on opposite of a square, but I think that's not the real case) )and $n$ points distributed uniformly(i.i.d) in the square (where $n$ is large, and $A$ denotes the set of $n$ points), can I caluculate the asymptotic behavior of the value $M(n)$, where $M$ is defined as
$$M(n)=E\left[\min_{B\subset A} \sum_{k=1}^{|B|+1} d(B_k,B_{k-1})^2\right]$$
where $B_k$ is the $k$th element of $B$,$B_0=X,B_{m+1}=Y$(We let $m=|B|$), and the expected value is taken over all the possible $A$ . That is to say, I would like to compute the expected value of the minimal weight defined as sum of the square of distance.</p>

<p>I know that when $n\to\infty,M(n)\to 0$. And in the $1$-dim case, this is easy, since it is only a Poisson process, and the distance between two consecutive points are surely exponential distribution.(Calculation suggests it's about $(n+3)/((n+1)(n+2))$,where $n$ is number of points added) But in the two dimensional case, I got stuck and don't know how to tackle it. This is a problem arouse from the calculation of the cost of a network. Any hint or reference are welcomed, Thanks!</p>

<p>(Some computer experiment suggests that the weight is about $\approx 1.1/\sqrt{n}=O(1/\sqrt{n})$. I also wonder if there are some similar results?)</p>
",graph_theory
"<p>There is a proof in my textbook for the following claim, which doesn't make a whole lot of sense to me.  My annotations are in <strong>bold</strong>.  Could someone perhaps elaborate on what's going on?</p>

<p>Claim.  If there does not exist a cycle containing edges $e$ and $g$ then there exists a vertex $u \in V (G)$ such that every path in $G$ sharing one end with e and another with $g$ contains $u$.</p>

<p>Proof: The claim trivially holds if $e$ or $g$ is a loop <strong>OK</strong>, so we assume that neither is. Let $P$ with vertex set $v_1, v_2, . . . , v_k,$ in order, be a path with $e$ joining $v_1$ to $v_2$ and $g$ joining $v_{k−1}$ and $v_k$. Let $f_i \in E(P_i)$ be the edge with ends $v_i$ and $v_{i+1}$. Let $j$ be chosen minimum so that no cycle in $G$ contains $e$ and $f_j$ <strong>We can do this because we know that at least the edge $g$ will not create a cycle by assumption, right?</strong>. We will show that $u = v_j$ satisfies the claim.</p>

<p>Suppose not. Let $C$ be a cycle containing $e$ and $f_{j−1}$ <strong>What if $f_j = e$?  then what cycle? a single vertex?</strong> and let $P′$ be a
path from an end of $e$ to an end of $f$ <strong>Not sure what the book meant by $f$ here, any guesses?</strong> avoiding $u$. Choose a subpath $Q$ of $P′$ with one end in $V (C)$ and another in ${v_{j+1}, v_{j+2}, . . . , v_k}$ as short as possible. Then $C \cup Q \cup P$ contains a cycle containing both $e$ and $f_j$, a contradiction. (The last statement requires some case checking.) <strong>This ending seems a bit abrupt and non-obvious to me</strong></p>

<p>Thanks for the help</p>
",graph_theory
"<p>Let $G$ be a graph. </p>

<p><strong>Is the following implication true ?</strong></p>

<p>$G$ is graceful $\Rightarrow G$ is connected </p>

<p><strong>Definition</strong>: Let $G$ be a graph with $m$ edges. $G$ is <strong>graceful</strong> if there exists an injection $\Phi: V(G) \mapsto \{0,\ldots, m\}$ and $\{\mid \Phi(u) - \Phi(v) \mid : uv \in E(G) \} = \{1, \ldots, m\}$ </p>
",graph_theory
"<p>Naturally we can describe graphs via tables of ""yes there is an edge"" or ""no there is not"" between each pair of vertices, so the definition of an adjacency matrix is easily understood.  Thinking of these tables as <em>matrices</em>, however, adds structure - specifically, an interpretation as a linear operator.  Why do we look at them in this light?  Is it just for application - for example, efficiently obtaining a lot of data about a graph by computing its spectrum?  Or is there also an intuitive geometric (or algebraic) motivation behind the adjacency matrix?</p>

<p>For example, the $2$-path <img src=""http://i.stack.imgur.com/bSdoS.png"" alt=""2-path""> has adjacency matrix
 $$\mathcal{A}(P_2)=\left(\begin{array}{cc} 0 &amp; 1\\1 &amp; 0\end{array}\right)$$ which acts on a $2$-dimensional vector space by flipping the coordinates, $(x,y)\mapsto (y,x)$.  Can we somehow intuitively connect this action to the $2$-path?  What about for other simple graphs?</p>
",graph_theory
"<p>Can a graph <em>g</em> that satisfies the necessary condition for having an Eulerian trail have two or more distinct Eulerian trails given a fixed starting vertex? </p>

<p>Or, if a graph has an Eulerian trail, is that the only Eulerian trail in that graph?</p>
",graph_theory
"<p>I was reading a paper named <a href=""http://www.dli.gov.in/data_copy/upload/INSA/INSA_2/20005a23_585.pdf"" rel=""nofollow""><strong><em>Decompositions of the Kronecker product of a cycle and a path into long cycles and long paths</em></strong></a> by P. K. Jha (<em>Indian J. pure appl. Math.</em> <strong>23</strong>(8): 585-606, August 1992).</p>

<p>In one theorem I have a doubt. I am not getting how the proof of <strong><em>Lemma 1.3</em></strong> is done. I am not getting any idea what is the need of taking a graph like $G$ here. I will be very thankful if anybody can explain that. Here is that lemma :</p>

<p><img src=""http://i.stack.imgur.com/MTtyQ.jpg"" alt=""enter image description here""></p>
",graph_theory
"<p>Im starting to learn graph theory and i want to learn which approaches to take when it comes to finding the chromatic polynomial to different graphs. </p>

<p>Say we have these graphs,</p>

<p><a href=""http://i.stack.imgur.com/HvtWe.png"" rel=""nofollow"">Graphs</a></p>

<p>I can see that G1 is similar to k7 so using deletion-contraction to get subgraphes would be the best approach for that graph i think. But what about the G2 and G3? Does the deletion-contraction method work on those to? Or are there other approaches you can use and more importantly, how do you you know when you should use them?</p>
",graph_theory
"<p>The knight's tour is a sequence of 64 squares on a chess board, where each square is visted once, and each subsequent square can be reached from the previous by a knight's move.  Tours can be cyclic, if the last square is a knight's move away from the first, and acyclic otherwise.</p>

<p>There are several symmetries among knight's tours.  Both acyclic and cyclic tours have eight reflectional symmetries, and cyclic tours additionally have symmetries arising from starting at any square in the cycle, and from running the sequence backwards.</p>

<p>Is it known how many knight's tours there are, up to all the symmetries?</p>
",graph_theory
"<p>This is a practice question (not HW)</p>

<p>Prove that any circuit in a graph must contain a cycle AND that any circuit that is not a cycle contains at least two cycles.</p>

<p>Note : This is for a  first course in Graph theory</p>

<p>I have answer to this question but the answer raises more questions.
ANSWER: Suppose the vertices of the circuit are $v_0,v_1,...v_n,v_0$. Consider all subcircuits of the form $v_i,...v_n,v_i$. The subcircuit that uses the fewest number of vertices is a cycle (my Q: BUT WHY).</p>
",graph_theory
"<p>I am a novice when it comes to graph theory. Now i'm solving different questions where you get a graph and should determine the chromatic number and chromatic polynomial for that graph. I'm stuck at this particular graph:</p>

<p><a href=""http://i.stack.imgur.com/BSnrT.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/BSnrT.png"" alt=""enter image description here""></a></p>

<p>I started with isolating the ""trickiest"" sub graph ""g"" which happened to also be a wheel graph with an even amount of vertices n. And according to the internet, a wheel graph with this property has a chromatic number of 4, yes? </p>

<p>My big issue is when i check the correct answer of the question it says that the chromatic number of the entire graph G is 3. Did i incorrectly assume that the chromatic number of G couldn't be less than the chromatic number of g?</p>
",graph_theory
"<p>If $G$ is an outerplanar graph of order $n \geq 2$ and size $m$, show that $m \leq 2n -3$</p>

<p>[I can show the result for Hamiltonian outerplanar graphs, and I think its posible to extend the result, but my proof is very inelegant and tedious. Any ideas?]</p>
",graph_theory
"<blockquote>
  <p>Let $G = (V,E)$ be a connected graph. Suppose $e$ is an edge in a circuit of $G$. Show that the new graph $(V,E-\{e\})$ is still connected. </p>
</blockquote>

<p>Attempt: Let $v,w \in V$ be vertices. Then inside $G$, $v$ and $w$ are connected. Suppose the circuit starts and ends at vertex $a \in V$. Then the only problem that could occur is that the deleted edge is part of the connection between $v$ and $w$. So let's suppose this were the case. </p>

<p>I want to use the transitivity of the connected relation to say that $v$ is connected to $a$ which is connected to $v_i$, the vertex of the disconnect, which is connected to $w$. I can do the latter by symmetry of the relation $v$ connected to $w$. However, there is a concern whether $v$ is connected to $a$. Namely that the deleted edge occurring at $v_i$ might also appear in the connection between $v$ and $a$. Can this happen? If so, how can I change my walk to bypass it. </p>
",graph_theory
"<p>The proof of this is everywhere skipped and said to be collorary of Ford-Fulkerson theorem.
It's usually something like:</p>

<p>Let $A$ and $B$ be low cuts of a flow chart. Then $A \cup B$ and $A \cap B$ are also min cuts.</p>

<p>Can anyone tell me how exactly this is proved or link me a proof please?</p>

<p>Regards, Raxel.</p>
",graph_theory
"<p>Is there a relation between Clique size $\omega(G)$ and genus $g(G)$ of a graph? That is does $$\omega(G)^c\geq g(G)\geq \omega(G)^{\frac{1}d}$$ hold with constants $c,d\geq1$?</p>
",graph_theory
"<p>It is known that if a graph is connected, cubic, simple and $t$-transitive, then $t \le 5$. A proof is given in [Biggs, Algebraic Graph Theory, Chapter 18], and this result is due to [Tutte, ``A family of cubical graphs,'' Proc. Cambridge Philosophical Society, 45, 459-474].  </p>

<p>My question is: Is the proof given in Biggs' text the same as the one in Tutte's paper?  I was unable to obtain Tutte's paper.  I would appreciate if someone could electronically post or mail to me his paper.  </p>
",graph_theory
"<p>Is this true that graph consisting of $n$ edges and $n$ vertices has only one circuit. </p>

<p>I drew some graphs on paper and I believe that it is true. But how to prove that? I will be glad for any help.</p>
",graph_theory
"<p>Which of the following graphs have Euler circuits, Euler trails, or neither?</p>

<p><img src=""http://i.stack.imgur.com/WngtA.png"" alt=""enter image description here""></p>

<p>I tried :Euler Trails [A,B,C,A,D,B,C]</p>

<p><img src=""http://i.stack.imgur.com/1IB7h.png"" alt=""enter image description here""></p>

<p>I tried :Euler Trails [A,B,D,E,G,F,D,C,A,D,G]</p>

<p>but I am confused about Euler circuits.</p>
",graph_theory
"<p>The degree of every vertex of a graph $G$ of order $2n+1\geq5$ is either $n+1$ or $n+2$. Prove that $G$ contains at least $n+1$ vertices of degree $n+2$ or at least $n+2$ vertices of degree $n+1$. </p>
",graph_theory
"<p>I don't know what is the way to check this:  </p>

<p>Check whether the graph having degree sequence $\{3,3,1,1\}$ is a simple graph or not?  </p>

<p>Please help explaining the strategy I must follow to check this...</p>
",graph_theory
"<p>Suppose we model traffic flow between two points with a directed graph. Each route has either a constant travel time or one that linearly increases with traffic. We assume that each driver wishes to minimise their own travel time and we assume that the drivers form a Nash equilibria. Can removing a route ever decrease the average travelling time?</p>

<p>Note that the existence of multiple Nash equilibria makes this question a bit complicated. To clarify, I am looking for a route removal that will guarantee a decrease in the average traveling time regardless of the Nash equilibria that are chosen before and after.</p>
",graph_theory
"<p>Suppose that $G$ and $H$ are infinite graphs and that $G$ is isomorphic to a subgraph of $H$ and $H$ is isomorphic to a subgraph of $G$. Must $G$ and $H$ be isomorphic?</p>

<p>I've only just started on graph theory and this is one of the bonus questions on the assignment sheet. I don't see anything in my notes regarding infinite graphs and so I don't think this can quite classify as homework.</p>

<p>My intuition tells me that this might be a good definition for isomorphism for infinite graphs and hence Yes to the question but I don't quite seem to have any ideas on how to prove it.</p>

<p>Any insight or literature on this (because I can't seem to find much on this even on the internet!) will certainly be helpful.</p>
",graph_theory
"<p>Lovasz theta number: (It is said to be polynomial, but I do not know how to computer it)</p>

<p><a href=""https://en.wikipedia.org/wiki/Lov%C3%A1sz_number"" rel=""nofollow"">https://en.wikipedia.org/wiki/Lov%C3%A1sz_number</a></p>

<p>Grötzsch graph:<a href=""http://i.stack.imgur.com/jidJt.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/jidJt.png"" alt=""enter image description here""></a></p>

<p><a href=""https://en.wikipedia.org/wiki/Gr%C3%B6tzsch_graph"" rel=""nofollow"">https://en.wikipedia.org/wiki/Gr%C3%B6tzsch_graph</a></p>

<p>I would like to know the Lovasz number of the complement Groetzsch graph.</p>
",graph_theory
"<p>$S$ is the string of characters:<code>TACGCGGT$</code></p>

<p>For string S and each of the positions $i=1,2,\dots,9$ write down the suffix string starting at position $i$.</p>

<blockquote>
  <p>What is the above question asking? For the following question I need to create the suffix tree, which I have done. But the above question seems to be asking me to simply write:</p>
</blockquote>

<p><code>TACGCGGT$</code>,<code>ACGCGGT$</code>,<code>CGCGGT$</code>,<code>GCGGT$</code>,<code>CGGT$</code>,<code>GGT$</code>,<code>GT$</code>,<code>T$</code>,<code>$</code>.</p>

<p>Surely that isn't the answer to the problem. What does it mean?</p>

<hr>

<p>Alternatively: It could be asking me for </p>

<p>T: <code>ACGCGGT$</code>,<code>$</code>
A: <code>CGCGGT$</code>
C: <code>GCGGT$</code>,<code>GGT$</code>
G: <code>CGGT$</code>,<code>GT$</code>,<code>T$</code>
C: <code>GGT$</code>
$: ``</p>

<p>But that seems absurd, since it doesn't really feel like $i=1,2,\dots,9$ since we don't really do $i=6,7,8$, as they are already done.</p>

<hr>

<p>The first way seems wrong since it would be too easy for a second year math course, especially for $8\%$ of the test's value...</p>
",graph_theory
"<p>I am learning martingale and Hoeffding-Azuma inequality recently but do not how to apply the those inequality or theorem here.</p>

<p>Let $G=(V,E)$ be a graph with chromatic number 600,i.e. $\chi(G)=600$. Let $S$ be a random subset uniformly chosen from $V$. Denote $G|_S$ the induced subgraph of $G$ on $S$. Prove that 
$$P(\chi(G|_S)\leq 200 )\leq 2^{-10}.$$</p>

<p>I am not sure how to approach ones, especially for the condition $\chi(G)=600$. I am thinking that for a 600 vertices complete graph, the probability to be computed is just the ratio $$\frac{\sum_{i=0}^{200}C_i^{600} }{2^{600}},$$</p>

<p>meaning the ratio btween the number of all subgraph with vertices number less than 200 and the total number of subset of $V$. But is it enough?  Even this ratio is hard to compute.</p>
",graph_theory
"<p>I am looking for some <em>well-known</em> algorithms in which sparse matrix elements are accessed in a <em>non-structured</em> way, i.e. row/column depends on a value of another (sparse) matrix/vector element or some variable that is changing throughout the course of the algorithm.</p>

<p>So, if one was to execute an algorithm on a computer or even by hand on a paper, there should <em>not</em> be many visible patterns in which <em>adjacent non-zero elements</em> in a single row/column are accessed consecutively.</p>

<p>For example, consider a sparse matrix
$$
M = \begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 2 \\
0 &amp; 3 &amp; 4 &amp; 0 &amp; 5 \\
6 &amp; 0 &amp; 0 &amp; 7 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 8 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 9
 \end{bmatrix}
$$</p>

<p>I am not interested in algorithms which contain fairly regular element access patterns like:</p>

<ul>
<li><code>3 4 5</code> - accesses the non-zero elements in row 2, in order</li>
<li><code>9 8 0 5 2</code> - accesses last column in reverse order</li>
<li><code>1 4 7 8</code> - accesses the superdiagonal, still too structured/regular</li>
</ul>

<p>but those which involve a lot of ""random"" patterns like:</p>

<ul>
<li><code>6 8 1 9 4 3</code> - accesses only non-zeroes, very interesting</li>
<li><code>3 0 8 5 1 0 0 6</code> - accessing some zero elements is also interesting</li>
<li><code>8 0 2 5 9</code> - permutation of a row/column is still interesting enough</li>
</ul>

<p>(Of course, the exact access pattern depends on the implementation of an algorithm, but I am looking for those algorithms in which there is no obvious way to access, for instance, an entire row/column of a matrix in (reverse) order.)</p>

<p>I would prefer a deterministic algorithm, but randomized ones are also fine.</p>
",graph_theory
"<p>I have the following paragraph in my notes:</p>

<blockquote>
  <p>If $G=(V,E)$ is a general graph . Let $U\subseteq V$ and let $F$ be a subset of $E$ such that the vertices of each edge in $F$ are in $U$ ,<br>
  then $H=(U,F)$ is also a general graph and $H$ is a subgraph of $G$ .  </p>
  
  <p>If $F$ consists of all edges of $G$ which have endpoints in $U$ ,then $H$ is called induced subgraph of $G$ and is denoted by $G_U. $  </p>
</blockquote>

<p>From here both the definition of a subgraph and a induced subgraph seem same to me..<br>
I can't understand what is the difference between them...<br>
Please help with this..</p>
",graph_theory
"<p>For any digraph $G = (V,E)$, consider the digraph $H = (E,F)$ with $F = \{ee' \in E \times E\ |\ \exists u,v,w \in V: e = uv \wedge e' = vw\}$, that is, the digraph $H$ whose nodes are the edges of the digraph $G$ and whose edges connect any two edges of $G$ which, together, form a directed path.</p>

<p>Which term is used in the literature for the digraph $H$ wrt. the digraph $G$?</p>
",graph_theory
"<p>I was wondering if someone can help me understand how prove that this graph is connected.</p>

<p>Given a graph with n vertices, prove that if the degree of each vertex is at least $(n − 1)/2$ then the graph is connected.</p>

<p>So far I know that about connected graphs:</p>

<p>An undirected graph is called <strong>connected</strong> if there is a path between
every pair of distinct vertices of the graph</p>

<p>The <strong>distance</strong> between two vertices in a graph is the length of
the shortest path between them.</p>

<p>The <strong>diameter</strong> of a graph is the distance between the two vertices
that are farthest apart.</p>

<hr>
",graph_theory
"<p>Let $T$ be a tree in which the largest degree of a node equals to $t$. Let $n_1$ denote the number of nodes of degree $1$ in $G$. Prove that $n_1 ≥ t$</p>

<p>I understand why this works but I am not sure how to prove it mathematically. It makes sense, because vertices of degree one are those at the end of each leaf (let their number be n) and/or the vertex in the beginning of the tree that doesn't branch into more than one edge. And the vertex with highest degree is gonna have at max n edges connected to it. Am I making sense? any help in the formal proof?</p>
",graph_theory
"<p>If I have the following graph :  <img src=""http://i.stack.imgur.com/4eVLO.png"" alt=""enter image description here""></p>

<p>Should the degree of vertex $v_2$ be 1 or 2...I'm asking this because I'm not sure whether loop should be counted while considering degree...</p>

<p>(In my notes the definition of degree of a vertex $a$ is defined to be : the no. of edges it belongs to). </p>
",graph_theory
"<p>Suppose there is a square binary matrix (Adjacency matrix of a graph), $A$.</p>

<p>I got that, the matrices, $A^2$ and $A^3$ are distinct but the set of eigenvalues are same for $A^2$ and $A^3$. It is to be noted that the set of eigenvalues of $A$ is different from the same of $A^2$ and $A^3$. Other powers of $A$ are same as $A^3$. </p>

<p>What does the above result interpret?</p>

<p>Please let me know. </p>

<p>Thanks in advance!  </p>
",graph_theory
"<blockquote>
  <p><strong>Serf definition</strong>: A vertex $z$ in a nontrivial tournament is called a <strong>serf</strong> if for every vertex $x$ distinct from $z$, either $x$ adjacent to $z$ or $x$ is adjacent to a vertex that is adjacent to $z$. </p>
</blockquote>

<p>Prove that every nontrivial tournament has at least one serf.</p>

<p>I'm not sure if I understand this correctly, but a tournament is  an oriented complete graph, and in a complete graph of order $n$ every vertex un-oriented adjacent to $n-1$ other vertex, so the only way for a vertex to not be a serf is that vertex has to be a source.</p>

<p>Assume the contrary that there exists a tournament that doesn't have any serf, then that tournament has every vertex is a source, which is impossible, thus every tournament must have at least one serf.</p>

<p>is my argument acceptable?</p>
",graph_theory
"<p><img src=""http://i.stack.imgur.com/cbjy9.png"" alt=""maxflow-mincut theorem"">
The proof is taken from course <em>Algorithm II, Princeton, coursera</em>. In the proof of iii => i, Why/How iii implies the existence of cut (A, B)?</p>
",graph_theory
"<p>A standard proof of the existence of Eulerian circuits proves the following are equivalent for a connected graph $G$: </p>

<blockquote>
  <p>(i) Every vertex in $G$ has even degree</p>
  
  <p>(ii) The edges of $G$ can be partitioned into disjoint cycles</p>
  
  <p>(iii) $G$ is Eulerian</p>
</blockquote>

<p>I'm interested in $(i) \implies (ii)$. The proof I've seen is by induction. However, the claim is very much about the edge space of $G$. Is there a linear algebraic proof of that implication?</p>
",graph_theory
"<p>a)  Show that for $2$ vertices $u$ and $v$ have the same score in a tournament $T$ then $u$ and $v $ belong to the same strong component of order $k$</p>

<p>b)  Prove that every regular tournament is strong</p>

<blockquote>
  <p>Define the relation on $V(T)$ by $u$ is related to $v$ if there is both $u-v$ path and $v-u$ path in $T$. This is an equivalent relation so this relation partition $V(T)$ into equivalent classes $V_1, V_2,..., V_k$  $(k\geq 1)$. Let $S_i= T[V_i]$ for $1 \leq i \leq k$, then $S_i$ are called <strong>strong components</strong> of $T$</p>
</blockquote>

<p>a)</p>

<p>From $u$ and $v$ have the same score I can see that $od(u)=od(v)$. So there is a path from $u$ and $v$ to other $k$ vertices, but how do I know there is a path from $u$ to $v$ and from $v$ to $u$  from these info?</p>

<p>b)</p>

<p>Let $T$ be a regular tournament then for every $v$ in $T$ , $id(v)=od(v)$. A tournament is a directed graph, and a directed graph such that for every $v$ in $T$ , $id(v)=od(v)$ is Eulerian. So a regular tournament is strong because it contain an Eulerian cycle.</p>
",graph_theory
"<p>Are there any class of graphs where distance between every two vertices is $\geq$2. 
I was wondering about the existence of such graphs. Because for counter examples I have Paths $P_n$. </p>

<p>Thank you very much.</p>
",graph_theory
"<p>Consider directed graph which has $N + 2$ layers numbered from left to right by integers from $0$ up to $N + 1$.</p>

<p>The leftmost ($0$) and the rightmost ($N + 1$) layers both contain only one vertex while every other layer contains exactly $M$ vertices. Vertices are numbered independently in each layer by integers from 0 to M - 1. For each pair of vertices which are in the adjacent layers ($i$ and $i + 1$ for any $i$ ($0 &lt;= i &lt;= n$)), there exists an edge. The vertex which is in the layer with smaller number is the initial vertex for such edge and the other one is the terminal vertex.</p>

<p>So the graph initially is something like this :</p>

<p>Let us assume N = 4  And M=3 </p>

<p><img src=""http://i.stack.imgur.com/sGvod.png"" alt=""enter image description here""></p>

<p>Here A node is in layer 0 and N th node is in layer N+1 that is 5</p>

<pre><code>Layer 1 has nodes = {B,C,D}
Layer 2 has nodes = {E,F,G}
Layer 3 has nodes = {H,I,J}
Layer 4 has nodes = {K,L,M}
</code></pre>

<p>Now we know that number of paths to go from A(that is first layer) to N(that is last layer) is $M^N$</p>

<p>Now suppose we add K more edges. Each edge connects two vertices which are in the different layers, no matter the adjacent layers or not. Also, each edge is directed from left to right (as well as all previously existing edges).</p>

<p>Like say we add an edge between Layer 1 Node 3 that is D to Layer 3 Node 3 that is J then graph look like this :</p>

<p><img src=""http://i.stack.imgur.com/1RmFA.png"" alt=""enter image description here""></p>

<p><strong>How many ways are there to reach from leftmost layer(0) to the rightmost layer(N+1) after adding these K edges ?</strong> </p>

<p><strong>Note : Two paths are considered different if there is, at least, one edge which belongs to exactly one path. However, we are allowed to traverse the same set of vertices. In that case, there should be a multiple edge in the graph. It is also possible if some edge added connects two adjacent layers.</strong></p>

<p>For example : It can also be like this :</p>

<p><img src=""http://i.stack.imgur.com/FroCw.png"" alt=""enter image description here""></p>

<p>In this case both edges are considered as different . So we need to count these total ways.</p>

<p>My Attempt : I know that if suppose we add a single edge between layers at A from start and B from end then it introduces M^(A-1)*M^(N-B) new paths. But problem arise when their are other edges added after that edge.</p>

<p>Example : Let N=4 , M=2 and K=2</p>

<p>There are 16 ways to get from the layer #0 to the layer #5. Now we have added edges. </p>

<p>Let first edge added is between (Layer 2,Node 1) to (Layer 5,Node 0) then there are 2 ways to get from the layer #0 to the layer #5 using this edge (0, 0 -> 1, 0 -> 2, 1 -> 5, 0 and 0, 0 -> 1, 1 -> 2, 1 -> 5, 0) </p>

<p>Let second edge added is between (Layer 0,Node 0) to (Layer 4,Node 0) then there is 1 way to get from the layer #0 to the layer #5 using this edge (0, 0 -> 4, 0 -> 5, 0)</p>

<p>So total is 16+2+1=19 ways</p>

<p><strong>Edit :</strong> To make question precise we can assume that we are given N , M and K </p>

<p>Also then we are given K extra edges. Each edge is of form Layer1 , Node1 , Layer2 , Node 2 which shows that a edge between Node 1 of Layer 1 is directed toward Layer 2 Node 2.</p>

<p>How many paths are their now to reach last layer from starting layer ?</p>
",graph_theory
"<p>I am currently in the process of reading an article by D.Bundy <a href=""http://www.sciencedirect.com/science/article/pii/S0097316505001834"" rel=""nofollow"">The connectivity of commuting graphs</a>. In section 3 (in the Preliminary Results) Bundy gives the following result:</p>

<p>$\mathbf{(3.1)}$ Let $G=\operatorname{Sym}(n)$ and $H$ be the stabilizer in $G$ of a system of imprimitivity with blocks of size $s$, for $1&lt;s&lt;n$. Then $H$ is a maximal subgroup of $G$.</p>

<p><strong>Proof.</strong> Elementary. $\Box$ </p>

<p>I'm afraid I fail to see how to prove this. Indeed, suppose that $1&lt;s&lt;n$ and that $st=n$ for some $1&lt;t&lt;n$. Then we have that $H\cong \operatorname{Sym}(s)\wr\operatorname{Sym}(t)$, so the result is equivalent to proving that if $1&lt;t,s&lt;n$ with $ts=n$, then the copy of $\operatorname{Sym}(s)\wr\operatorname{Sym}(t)$ contained in $\operatorname{Sym}(n)$ is maximal in $\operatorname{Sym}(n)$. Any help on seeing why this is true would be greatly appreciated.</p>
",graph_theory
"<p>For any flow network N, add an edge $e_{ts}$ and color it black. Color all other edges in N with black, red or green, then at least one of the following two cases is true:</p>

<p>1) There exists a cycle C which includes $e_{ts}$ and is composed only with <strong>black and red</strong> edges, in which all <strong>black</strong> edges points to the same direction(all clockwise/anticlockwise in the cycle)</p>

<p>2) There exists a edge set A which includes $e_{ts}$ and is composed only with <strong>black and green</strong> edges, where the vertices in G-A can be divided into two sets $V_1$ and $V_2$ (suppose t is in $V_1$), such that all black edges point from $V_1$ to $V_2$ </p>

<p>I guess I may need to construct a feasible flow from s to t and $e_{ts}$ joins the sink and the source. But I'm not sure how to do that.</p>
",graph_theory
"<p>There would be 34 edges.</p>

<p>If we increase the vertices then we would decrease the Degree. </p>

<p>Hence 10 Vertices with degree of 3 and one with degree of 4. </p>

<p>So I think in total it would be 11 vertices am I right.</p>
",graph_theory
"<p>I'm trying to prove that given an undirected non-trivial graph $G, G$ is the periphery of some other graph $H$, if and only if:  </p>

<p>a)for each vertex $ v \in V(G)$ , $ecc(v)=1 $<br>
 or<br>
 b)for each vertex  $ v \in V(G)$ , $ecc(v)\neq1 $  </p>

<p>$V(G)$ being the set of vertices of $G$ , $ecc(v)$ being the eccentricity of vertex $v$<br>
The periphery of a graph is the set of vertices with eccentricity equal to the diameter of the graph (diameter being the maximum eccentricity).</p>

<p>The first case seems a bit easier, as from what i can tell, graphs with eccentricity 1 are the complete graphs $K_n$ , so maybe i can construct some graph for every $n$ number of vertices that has G as the perimeter.
For the other case i don't really know where to start.</p>
",graph_theory
"<p>I have a homework problem where I have a graph $G$ and I am tasked with proving that at least one of $G$ and $G$ complement is connected. However, I am unclear on the exact meaning of $G$ complement. </p>

<p>For example, let's imagine I have a disconnected graph with four vertices $(V_1, V_2, V_3, \text{and } V_4)$. 
If the edges form a sort of box where the bottom edge is left disconnected, would $G$ complement have that edge filled in along with the cross edges as well? Furthermore, does $G$ complement contain all of the edges in $G$ or just the edges not contained in $G$? Thanks for taking the time to read.</p>
",graph_theory
"<p>If $A$ is an adjacency matrix of a graph $G$ and it can be diagonalized to get it in the form $A=PDP^{-1}$, with $D$ diagonal, is there any graph-theoretic interpretation to the matrices $P$ and $D$?</p>
",graph_theory
"<p>I read the following statement :</p>

<blockquote>
  <p>If the graphs $G$ and $G'$  are isomorphic then following is true:  </p>
  
  <ul>
  <li>If $G$ is connected, so is $G'$. More generally, $G$ and $G' $ have same number of connected components.   </li>
  </ul>
</blockquote>

<p>I don't understand what connected components mean.  Can anyone explain this to me, please?</p>
",graph_theory
"<p>I am trying to do Mathematics for CS course( 6.042) from MIT opencourseware. Could anyone please help me with this problem( from problem set 6. Problem 6).</p>

<p>Let G be a graph. In this problem we show every vertex of odd
degree is connected to at least one other vertex of odd degree in G.
<br><br>
(a) [6 pts] Let v be an odd degree node. Consider the longest walk starting at v that does
not repeat any edges (though it may omit some). Let w be the final node of that walk. Show
that w is not equal to v.<br><br>
(b) [4 pts] Show that w must also have odd degree.</p>
",graph_theory
"<p>The set of the vertices of the graph $G$ is $V=\{ 0,1,2,3,4,5,6\}$. The vertices i and j are connected with an edge if and only if $|i-j| \mod 3 \in \{0,1 \}$. </p>

<p>Does $G$ have an Euler circuit?? </p>

<p>I drawed the graph:</p>

<p><img src=""http://i.stack.imgur.com/rhkuF.png"" alt=""enter image description here""></p>
",graph_theory
"<p>So, Gallai is mentioned in e.g. Wikipedia page about perfect graphs <em>and</em> Berge's article at some point. </p>

<p>My understanding is that Gallai was the first who properly talked about bipartite graphs and line graphs of bipartite graphs and comparability graphs being ``clique colourable"" (+complements). </p>

<p>He also was the first to talk about odd holes, but Berge was the first to realise about odd antiholes and hence the perfect graph theorem and the strong perfect graph theorem. </p>

<p>Is this correct? I want to say something about the history of perfect graphs without it being guff. </p>
",graph_theory
"<blockquote>
  <p>For a simple undirected graph $G$, suppose we have two vertices $v_1$ and $v_2$ such that $G-v_1 \simeq G-v_2$. Does this necessarily mean that there is an automorphism of $G$ that maps $v_1$ to $v_2$?</p>
</blockquote>

<p>This is just a condition that I've assumed to be true for awhile now without thinking too hard about whether or not it's actually true. Using the condition that $G-v_1 \simeq G-v_2$ has been a useful way to characterize two vertices as being ""the same,"" but I was wondering if this actually corresponds to automorphisms of the graph.</p>
",graph_theory
"<p>A standard result in graph minor theory is that a graph is series-parallel if and only if it is $K_4$-minor free.</p>

<p>I'm looking for a good source for a proof of this that is understandable to undergraduates.</p>
",graph_theory
"<p>We have a data set which is comprised of Connectors and Segments.  Each segment has exactly two connectors, but each connector can belong to zero or more segments (i.e. connector 'A' in the left image below has no segments, while connector 'M' has three, M-R, M-L and M-N.)</p>

<blockquote>
  <p>It is understood that wherever any lines meet or intersect, there will be a connector so we don't have to worry about even/odd rules, overlapping or partially-enclosed polygons, etc. as they don't apply.</p>
</blockquote>

<p>In short, we're trying to identify all of the created polygons (the colored shapes in the right image.)  I believe this can be completed in two steps.</p>

<p><a href=""http://i.stack.imgur.com/3AENJ.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/3AENJ.png"" alt=""Polygons""></a></p>

<p><strong>Part 1: Removing superfluous items</strong></p>

<p>Stand-alone connectors (connector 'A' here) can simply be removed since they can't be part of a shape's outline.</p>

<p>Floating end-points referencing a single segment (connectors 'B' and 'E') can also be removed as they too can't be part of a shape's outline.  This will also remove their referenced segments (B-C and E-D).</p>

<p>Performing the above recursively will next identify 'C' as an endpoint (since 'B' and B-C were already removed) so it and it's remaining segment C-D can also be removed.  On the next recursive pass, connector 'D' and segment D-F will also be removed, etc.</p>

<p>However, I haven't found a good way to identify segment G-H. That said, I think that can be achieved during polygon detection since such segments would only be the result of compound paths and would be traced in both directions during one shape's detection. (More on that below.)</p>

<p><strong>Step 2: Polygon Detection</strong></p>

<p>Each segment can be traced in two directions. For instance, the segment connecting 'O' and 'P' can be either O-P or P-O.  Picking a trace-direction of clockwise, O-P would belong to the polygon O-P-Q-N whereas P-O would belong to the polygon P-O-I.</p>

<p>The following logic assumes a trace-direction of clockwise.</p>

<p>Starting from any segment, when tracing around, if you get back to your starting point, you have identified a potential polygon.  By keeping a running delta of your heading's angle as you trace around (this is how much your heading turns and is not to be confused with simply adding the angles between segments), when done, if that angle is positive, you've detected a valid polygon.  If it's negative, you've detected a 'containing' polygon, meaning one that contains one or more 'valid' polygons.  The outer perimeter of the entire shape (or shapes) are all containing polygons.</p>

<p>Consider the case of a square, diagonally divided into two triangles.  Tracing each segment twice--once in each direction--you will end up with three potentially-valid polygons: a square and two triangles.  The triangles will have a positive angle delta telling you they're valid, but the square's angle delta will be negative telling you that's the containing polygon.</p>

<blockquote>
  <p>Note: A containing polygon can be equal to a valid polygon too. It will just be 'wound' in the opposite direction.</p>
</blockquote>

<p>Consider a simple triangle.  The clockwise trace will yield the valid polygon.  The second attempt to trace clockwise will actually yield a counter-clockwise trace which will give you a negative angle delta, telling you that's actually the outline of the shape.</p>

<blockquote>
  <p>Note: You also have to test for other polygons encountered along the way by also testing each point for any previously-encountered point during that shape detection.  If you find you've revisited the same point, save off the polygon created since the first encounter of that point, check it's angle. If it's positive, it's a valid polygon (and you're actually currently tracing a containing polygon.) If it's negative, you've detected a containing polygon (in which case you're currently tracing a valid polygon.) Finally, remove all segments on your accumulation stack back to the first instance that point was last encountered and continue on with your detection.</p>
</blockquote>

<p>For instance, if you started at 'J' and traced around counter-clockwise, you would go through 'I', 'H', then 'G', then 'F' then you'd be back at 'H'. You just found a polygon H-G-F which has a negative angle so you know it's a containing polygon. Remove those three segments from your stack and continue on.  Now you'll again hit 'I'.  In this case, you already visited that same segment during this pass, but in the other direction, so simply remove that segment completely from your stack and continue on, next to 'O' then 'N', etc. You'll eventually be back at 'J'.</p>

<p>When a segment has been traced in both directions, it can be considered 'used' and no further processing of that segment is needed. Continue processing all non-used segments.  Once all segments have been traced in both directions, you can be sure all polygons--valid and containing--have been found.</p>

<p>Finally, check each containing polygon to see if it falls within any valid polygon. If so, exclude it from that valid polygon creating a compound path.  In the example here, containing polygon H-G-F is contained by the valid cyan polygon so it should be excluded.  Note there is also a valid H-F-G polygon which is marked in red here.</p>

<p>Anyway, that's what I've come up with, but I'm wondering if there's a better/simpler way. Thoughts?</p>
",graph_theory
"<p>I'm having trouble making progress on this. I'm trying to use contradiction and I'm really not seeing anything.  Any help would be greatly appreciated!</p>
",graph_theory
"<p>Let G1, G2, G3 be three (possibly overlapping) graphs on the same vertex set, and suppose that G1 can be properly colored with 2 colors, G2 can be properly colored with 3 colors, and G3 can be properly colored with 4 colors. Let G be the graph on the same vertex set, formed by taking the union of the edges appearing in G1, G2, G3. Prove that G can be properly colored with 24 colors.</p>
",graph_theory
"<p>Is it possible to create a graph ( represented in the form of Adjacency Matrix), when the number of nodes and the count of neighbors for each node is given?</p>
",graph_theory
"<p>Say I have an image, with pixels that can be either $0$ or $1$. For simplicity, assume it's a $2D$ image (though I'd be interested in a $3D$ solution as well). </p>

<p>A pixel has $8$ neighbors (if that's too complicated, we can drop to $4$-connectedness). Two neighboring pixels with value $1$ are considered to be connected. </p>

<p>If I know the probability $p$ that an individual pixel is $1$, and if I can assume that all pixels are independent, how many groups of at least $k$ connected pixels should I expect to find in an image of size $n\times n$?</p>

<p>What I really need is a good way of calculating the probability of $k$ pixels being connected given the individual pixel probabilities. I have started to write down a tree to cover all the possibilities up to $k=3$, but even then, it becomes really ugly really fast. Is there a more clever way to go about this?</p>
",graph_theory
"<p>I'm looking for a reference rather than an answer. I think I'm just not Googling the right combination of terms. I imagine that there is a class of graphs which is equivalent to some class of languages via some transformation (acceptance?). I'd like to know more about this, but can't seem to find much.</p>
",graph_theory
"<p>What is the smallest $n$ such that every 2-coloring of edges of $K_n$ contains a red or blue 4-cycle (not $K_4$)? I am given that $R(4,4) \le 18$ and $R(3,5) \le 14$</p>

<p>Any help is greatly appreciated!</p>
",graph_theory
"<p>Proposition. If $G$ is a bipartite graph with at least one edge, then its spectrum is symmetrical with respect to $0$, i.e. if a number $\lambda$ is an eigenvalue of $G$ then $- \lambda$ is also an eigenvalue of $G$.</p>

<p>Proof. Let $G \in B(m,n)$. Then $A(G)$ is an $(m+n) \times (m+n)$ matrix. Suppose that $\lambda$ is an eigenvalue of $G$ and $x=(x_{1},x_{2},...,x_{m+n})$ is a corresponding eigenvector. Consider the vector $y=(y_{1},y_{2},...,y_{m+n})$ where $y_{j}=x_{j}$ if $1 \le j \le m$ and $y_{j}=-x_{j}$ if $m+1 \le j \le m+n$. 
Then </p>

<p>$ \sum_{j=1}^{m+n}a_{ij}y_{j}=\sum_{j=m+1}^{m+n}a_{ij}y_{j}=-\sum_{j=m+1}^{m+n}a_{ij}x_{j}=- \lambda x_{i} = -\lambda y_{i}$, if $1 \le i \le m$, 
and $ \sum_{j=1}^{m+n}a_{ij}y_{j}=\sum_{j=1}^{m}a_{ij}y_{j}=\sum_{j=1}^{m}a_{ij}x_{j}=\lambda x_{i} = - \lambda y_{i}$, if $m+1 \le i \le m+n$.</p>

<p>So $y$ satisfies $A(G)y=- \lambda y$, and $- \lambda$ is an eigenvalue of $G$</p>

<p><strong>My question</strong>: How to proof that laplacian spectrum is symmetric for bipartite graphs. Proof above is the proof in one way: if $G$ is bipartite then condition, but my task is to proof that: if condition then $G$ is bipartite. I would like to get a seed of an idea, how can I do that.</p>
",graph_theory
"<p>Let $\binom{n}{2}$ be the set of all subsets of $\{1,2,3, \ldots, n\}$ of size $2$ and let $C_n$ be the set of $E \subseteq C_n$ so that the graph $G$ with vertex set $\{1,2, 3, \ldots, n\}$ and edge set $E$ is connected.  Using generating function methods one can show that $$\sum_{E \in C_n} (-1)^{|E|} = (-1)^{n-1}(n-1)!.$$</p>

<p>For example, if $n=3$ then $$C_n = \{\{12,23\}, \{12, 13\}, \{13, 23\}, \{12, 13, 23\} \}$$ and then $$(-1)^2 + (-1)^2 + (-1)^2 + (-1)^3 = 2!.$$
Is there a more direct proof?  For example, a sign-reversing involution argument.</p>
",graph_theory
"<p>Consider a 'game' played on a subset $S$ of an $n^2$ square grid as follows. There are 3 types of pieces, each occupying a square, 1 green, some red and the rest are blue, a move consists of shuffling the green piece with any of its 4 adjacent pieces (if they are within $S$). $S$ consists of squares, squares not in $S$ are static, $S$ can be any subset of the $n^2$ square.</p>

<p>If two board configurations are reachable from eachother, is it possible to obtain an upper bound on the number of moves needed, given only the board size $n$, is it polynomial in $n$?</p>
",graph_theory
"<p>suppose $P_n$ and $P_m$ are paths with $n$ and $m$ edges respectively.consider $A_n$ and $A_m$ as adjacency matrix of them.now I want to calculate the number of perfect matching of $P_n \square P_m$ (it is cartesian product <a href=""http://en.wikipedia.org/wiki/Cartesian_product_of_graphs"" rel=""nofollow"">http://en.wikipedia.org/wiki/Cartesian_product_of_graphs</a> )</p>

<p>now I consider $A_{m,n}=A_m \otimes I_n + I_m \otimes A_n$ which is adjacency matrix for $P_n \square P_m$. ($\otimes$ is Kronecker product <a href=""http://en.wikipedia.org/wiki/Kronecker_product"" rel=""nofollow"">http://en.wikipedia.org/wiki/Kronecker_product</a>) </p>

<p>now because $P_n \square P_m$ is bipartite graph then the number of perfect matching is equal to $\sqrt{per(A_{m,n})}$.</p>

<p>now I know that if I define $A^{*}_{m,n}=A_m \otimes I_n + iI_m \otimes A_n$ which $i^2=-1$ it is enough to show that $ det(A^{*}_{m,n})=per(A_{m,n})$</p>

<p>my problem is to show this later equation which is so great relation.</p>

<p>please give me the way to prove that,any help will be great,thanks.</p>
",graph_theory
"<p>I am wondering if there is any existing algorithm for the following routing problem. </p>

<p>Let's suppose that you are given a directed graph where the edges are labeled with a weight indicating a cost. Each node belongs to a POI (point-of-interest) such as restaurants, grocery stores, etc. Given a set of POIs you have to visit, what is the shortest route from a node X to Y, visiting all the POIs given you?  (e.g., ""I have to go to my office from my house. On the way, I have to visit a grocery store, a department store, and a gas station. What is the shortest route?)</p>

<p>I tried to find if there was any literature on this problem but could not find any. Does anybody know this type of problem and any solution?</p>

<p>Thanks</p>
",graph_theory
"<p>The maximum number of points in a plane such that the distance of any of these points from  a given point in the plane is less than the distance of it from any other point is five.</p>
",graph_theory
"<p>I am trying to find a polynomial time reduction from the colored graph isomorphism to the regular graph isomorphism.
Doing a search on this problem, I found <a href=""http://pages.cs.wisc.edu/~dieter/Papers/3gi.pdf"" rel=""nofollow"">this article</a> and it seems like theorem 1 is the solution I am looking for, however I don't fully understand it.
Could someone please explain how the reduction works?</p>
",graph_theory
"<p>So i asked this question and was given a hint</p>

<p>The degrees would have to be the integers 0,1,…,4k+1: why?</p>

<p>This was my solution to it</p>

<p>Given a simple graph with n = 4k + 2 vertices. Can the vertices of
this graph have distinct degrees?</p>

<p>Since n is isomorphic to its complement, we know that graph have
the same number of edges. Also, if we look at the union of the edges of both
graphs we know we get all possible edges. If n has n vertices, there are $n(n-1)\over 2$ possible edges, so n must have exactly half of them. Therefore,</p>

<p>$|E(n)| = |E(n)| =$$n(n-1)\over4$</p>

<p>Now we can see that since |E(n)| must be an integer, 4 must divide evenly
into n or n − 1. So, we conclude that n = 4k + 1 for some nonnegative
integer k.</p>

<p>From this can i conclude that n is isomorphic to its complement and n = 4k + 1 for some nonnegative integer k, then it has distinct degrees.</p>
",graph_theory
"<p>Let G be a graph of order n. Prove that if deg u + deg v ≥ n - 2 for every pair u, v of nonadjacent vertices of G, then G has at most two components.</p>
",graph_theory
"<p>There is this know formula for determining the automorphism group of a graph $G$: let the connected components of $G$ consist of $n_1$ copies of $G_1$, $\dots$, $n_r$ copies of $G_r$, where $G_1, \dots, G_r$ are pairwise non-isomorphic. Then $${\rm Aut}(G) = ({\rm Aut}(G_1) \wr S_{n_1}) \times \dots \times ({\rm Aut}(G_r) \wr S_{n_r}).$$</p>

<p>I know intuitively what the formula does, but I am not able to prove the formula formally, probably because I don't understand the definition of the wreath product properly.</p>

<p>I would also appreciate if someone would describe the automorphism group of a graph which is a disjoint union of three paths of length one (or any other simple example).</p>

<p>If you are aware of a text or a website, where this is explained, it would be nice if you gave me a link, I wasn't able to find anything.</p>

<p>Thank you for your help!</p>
",graph_theory
"<p>So i was given this question</p>

<p>Draw the graph whose vertex set is the set of integers from 1 to 7,
and two vertices x and y are adjacent if $|x − y| ≡ 0(mod 2)$. Is the graph simple, count the degree of each vertex, By adding some edges is it possible to transform it into Eulerian one?</p>

<p>What is really throwing me off is the $|x − y| ≡ 0(mod 2)$ part. </p>

<p>In a simple graph the edges form a set and each edge is a unordered pair of distinct vertices. In a simple graph with n vertices, the degree of every vertex is at most n − 1. So since the graph would be adjacent to $|x − y| ≡ 0(mod 2)$ it would be simple because it can evenly divide.</p>
",graph_theory
"<p>In a university, the secretariat plans the examination period. There are $6$ subjects, $A,B,C,D,E,Z$ and $9$ students($1, \dots , 9$). At the subject $A$ the students $1,2,3$ are subscribed, at the subject $B$ the students $1,2,9$, at the subject $C$ the students $1,7,8$, at the subject $D$ the students $3,5,7,9$, at the subject $E$ the students $4,5,8$ and at the subject $Z$ the students $4,6,8$. Each examination lasts $2$ hours, and it can only be during the morning hours $10-12$. The only restriction at the planning is that it is not allowed that $2$ subjects, ,at which the same student is subscribed , get examinated simultaneously.</p>

<p>Which is the minimum number of days that are required,so that all the exams are taken?</p>

<p>I tried to solve the exerise,with the chromatic number,using the following graph:</p>

<p><img src=""http://i.stack.imgur.com/BCqgN.png"" alt=""enter image description here""></p>

<p>So,the minimum number of days is $4$..or am I wrong??</p>
",graph_theory
"<p>Consider a tournament with $n$ contestants - that is, a complete graph directed graph $K_n$ where each edge is pointed one way or the other. We call a subset $\{a,b,c\}$ a ""cyclic triplet"" if each of the three wins one of the two games against the other two. It is not hard to find a maximum number of cyclic triplets. </p>

<p>We can argue by considering the triplets involving a particular contestant that the maximum number of ""cyclic triplets"" among such triplets occurs when he beats  half of the remaining contestants. Hence the global maximum occurs when everyone beats half the remaining ones.</p>

<p>Now, define a subset $\{a,b,c,d\}$ to be a ""cyclic quadruplet"" if two contestants win two games against the other two, while the remaining two win one game. What is the maximum number of cyclic quadruplets?</p>
",graph_theory
"<p>if the graph G can be embedded on a torus can we say:</p>

<p>if</p>

<p>$\chi(G)\ge r\Rightarrow K_r\prec G$.</p>

<p>Kr is a minor of G?</p>
",graph_theory
"<p>I am reading the following paper on Rectangular Cartograms - <a href=""http://ac.els-cdn.com/S0925772106000770/1-s2.0-S0925772106000770-main.pdf?_tid=ce3aa43e-cef1-11e3-b342-00000aacb361&amp;acdnat=1398702556_1adee439a6b55c82efa20917178fb0aa"" rel=""nofollow"">http://ac.els-cdn.com/S0925772106000770/1-s2.0-S0925772106000770-main.pdf?_tid=ce3aa43e-cef1-11e3-b342-00000aacb361&amp;acdnat=1398702556_1adee439a6b55c82efa20917178fb0aa</a> and I am totally confused as to what this statement says on Page-177 in the Algorithmic Outline section of the paper</p>

<blockquote>
  <p>""Assume that we have an administrative subdivision into a set of
  regions. The regions and adjacencies can be represented by nodes and
  arcs of a graph F, which is the face graph of the subdivision.""</p>
</blockquote>

<p>Now there are a couple of questions I would like to ask :</p>

<p>1) What is meant by administrative subdivision into a set of regions?</p>

<p>2) What is meant by a Face Graph?</p>
",graph_theory
"<p>Let's say $G$ is the graph for the legal moves of the rook in a chess board where the nodes corresponds to squares in the board; thus, there are 64 nodes present. I am trying to figure out #edges in $G$.</p>

<p>I think, there should be $ \binom{8}{2} $ edges for each column and $ \binom{8}{2} $ for each row. Since there are 8 rows and 8 columns in the chess board the solution is: $$ 8 * \binom{8}{2} + 8 * \binom{8}{2} $$</p>

<p>Is it correct? If not, why not?</p>

<p>Note: You can see the movements of the rook at <a href=""http://en.wikipedia.org/wiki/Chess#Movement"" rel=""nofollow"">http://en.wikipedia.org/wiki/Chess#Movement</a>.</p>
",graph_theory
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://math.stackexchange.com/questions/227681/how-to-find-chromatic-number-of-the-hypercube-q-n"">How to find chromatic number of the hypercube $Q_n$?</a>  </p>
</blockquote>



<p>Let $G$ be the graph whose vertex set is the set of $k$-tuples with coordinates in $\{0,1\}$ with $X$ adjacent to $Y$ when $X$ and $Y$ differ in exactly one position. Determine whether $G$ is bipartite.</p>
",graph_theory
"<p>Consider the following graph orientation problem: we would like to orient the edges of a graph G in such a way that each vertex has at most k incoming edges. Prove that this is possible if and only if |E[W]| ≤ k|W| for each subset of vertices W, where E[W] is the set of edges with both endpoints in W.</p>
",graph_theory
"<p>I know I'm probably wrong, maybe someone can explain it to me. I'm doing practice problems in preparation for a test that is coming up.</p>

<blockquote>
  <ol start=""12"">
  <li>Let u and v be two vertices in a graph G. Show that if G has two simple  paths between vertices u and v, then G has a simple circuit.</li>
  </ol>
  
  <p>Sol: Assume that G has the following two simple paths: (u,..P1..,v)
  and (v,..P2..,u). Therefore, G has the circuit (u,..P1..,v,..P2..,u).
  If this circuit has no  repeated edges, then the proof is complete.</p>
  
  <p><strong>Otherwise, let (x,y) be the first  edge that occurs in P1 and is repeated in P2. In this case, the circuit can be  represented as
  follows: (u,..P1..,x,y,..P1..,v,..P2..,y,x,..P2..,u) This circuit can
  be reduced to become as follows: (u,..P1..,x,..P2..,u) where no edge
  in P1 is repeated in P2(because edge (x,y) was the first edge in  P1
  that is repeated in P2). Thus, the reduced circuit is simple.</strong></p>
</blockquote>

<p>I've marked the part I'm having trouble with in bold. I don't
understand how we can just strip out the y vertex and simplify the
graph. I suspect I'm not preparing the graph properly, but I've
uploaded an example image to show why the graph can't be simplified.
<img src=""http://i.stack.imgur.com/DKQ0p.png"" alt=""enter image description here""></p>
",graph_theory
"<p>A <em>module</em> in a graph $G$ is a subset $M$ of the vertices such that all the vertices in $M$ have the same neighbourhoods <em>outside</em> of $M$. That is, if $v_1, v_2 \in M$ and $x \not\in M$, then we have $v_1x\in E(G)$ iff $v_2x\in E(G)$. They generalise connected components. </p>

<p><a href=""http://en.wikipedia.org/wiki/Modular_decomposition"" rel=""nofollow"">It is known</a> that every graph who is both connected and whose complement is connected, can be expressed as a union of disjoint, maximal nontrivial modules. </p>

<p>My question is, does the modular decomposition of a graph have any relationship known to the related matrices of a graph, e.g. adjacency matrix, Laplacian etc? </p>
",graph_theory
"<blockquote>
  <p>Let $A$ be an alphabet, $K$ and $N$ be natural numbers and $X$ be a
  list of $N$ strings over $A$, each one consisting of $K$ letters. You
  have one operation ($@f$): convert a string from $X$ to
  another string from $X$. The cost of applying $@f$ over $(X_1, X_2)$ is
  the number of letters that one needs to change so that $X_1$ becomes
  $X_2$. (thank you @mvw for pointing out that this is called ""Hamming distance"")</p>
  
  <p>You want to know (in a polynomial time) the minimum cost of making all
  of the strings the same.</p>
</blockquote>

<p>My solution: Create a matrix (a graph) $N \times N$ showing the cost of every possible operation over $X$ and then find the minimum spanning tree (let's call it $@T$). Using $@T$ I can run a BFS like algorithm starting from the leafs down to the ""center"" and calculate the total cost of the operations.</p>

<p>My question: Is my solution correct (I can not prove it - it only feels correct) and if not - can you give me a correct one?</p>

<p>Thank you for your time</p>
",graph_theory
"<p>$G$ is factor-critical $\Leftrightarrow$ $c_o(G-U) \leq |U|$, $\forall U \subseteq V(G)$ except when $U = \emptyset$ (where $c_o$ is the number of odd components - basically, the RHS means that $U = \emptyset$ violates Tutte's condition)</p>

<p><em>My attempt:</em> ($\Rightarrow$) $G-v$ has a perfect matching $\forall v \in V(G)$. Consider $G' = G-v$ for some arbitrary $v$. Then $c_o(G'-W) = c_o(G - X - v) \leq |W| = |X+v|$, $\forall W \subseteq V(G')$. However, $|W| \geq 1$ since $W = X + v$ for some $v \in V(G)$, $X \subset V(G)$.</p>

<p>I feel like I'm just going in circles and not really getting anywhere, and I don't know how to begin proving the reverse direction.</p>
",graph_theory
"<p>Vizing's theorem states that a graph can be edge-colored in either $\Delta$ or $\Delta+1$ colors, where $\Delta$ is the maximum degree of the graph.</p>

<p>A graph with edge chromatic number equal to $\Delta$ is known as a class 1 graph.</p>

<p>A graph with edge chromatic number equal to $\Delta+1$ is known as a class 2 graph.</p>

<p>which one of them are bigger?(contains more graphs) and why?</p>
",graph_theory
"<p>Let $G=(V,E)$ be a bipartite graph, with partition $V=A \cup B$. Recall that an independent set $I$ of $G$ is a set of vertices sharing no edges. </p>

<p>The <em>independent domination number</em> $i(G)$ is deﬁned to be the minimum cardinality among all maximal independent sets of vertices of $G$. </p>

<p>Suppose $G$ is <em>balanced</em>, i.e. $|A|=|B|$. Is it true that there always exists a balanced independent set $I$ (i.e., $|I \cap A|=|I\cap B|$) of size $|I|=i(G)$?</p>

<p>If not, what additional hypotheses on $G$ would imply such statement?</p>
",graph_theory
"<p>Let $K_{a,b}$ be the complete bipartite graph. Show that
$K_{a,b}$ is a tree if and only if $a = 1$ or $b = 1$.</p>

<p>The way my professor showed us for a complete graph is as below. I just don't know how to start for a complete bipartite graph. </p>

<blockquote>
  <p>$K_a$ is a tree if and only if $a=2$ or $a=1$.</p>
</blockquote>

<p><em>Proof:</em> For all $u\in V(K_a)$, $\deg(u) = a-1$ implies that $$2|E(K_a)| = \sum \deg(u) = (a-1)|V(K_a)|=a(a-1),$$ so $|E(K_a)|=\frac{a(a-1)}{2}.$</p>

<p>Since $K_a$ is connected, it is a tree if and only if \begin{eqnarray*} 0 &amp;=&amp;|E(K_a)| -|V(K_a)| +1 \\
&amp;=&amp; a(a-1)/2 -a +1 \\ 
&amp;=&amp; \frac{1}{2}(a(a-1)-2a+2)\\
&amp;=&amp; 1/2[a(a-1)-2(a-2)] \\
&amp;=&amp; 1/2[(a-1)(a-2)] =0 \end{eqnarray*}</p>

<p>Thus $K_a$ is a tree if and only if $a-1=0$ or $a-2=0,$ i.e., $a=1$ or $a=2$.</p>

<blockquote>
  <p>$K_{a,b}$ is a tree if and only if $a=1$ or $b=1$.</p>
</blockquote>

<p><em>Proof:</em> For all $u,v \in V(K_{a,b})$, $\deg(u) = a$ and $\deg(v) = b $ implies that $$2|E(K_{a,b})| = \sum \deg(u) + \sum \deg(v)= ab+ab=2ab,$$ so $|E(K_{a,b})|=ab.$</p>

<p>Since $K_{a,b}$ is connected, it is a tree if and only if \begin{eqnarray*} 0 &amp;=&amp;|E(K_{a,b})| -|V(K_{a,b})| +1 \\
&amp;=&amp; ab-a-b +1 \\ 
&amp;=&amp; (a-1)(b-1)=0\end{eqnarray*}</p>

<p>Thus $K_{a,b}$ is a tree if and only if $a-1=0$ or $b-1=0,$ i.e., $a=1$ or $b=1$.</p>
",graph_theory
"<p>I was doing excercises about graphs theory and I came across a quite interesting excercise (which probably has something to do with Hamiltonian Cycle):
""Is it possible to step on every field of a 4x4 or 5x5 chessboard just once and return to the starting point using a knight?""
Does anyone have any idea how to tackle this problem? I am more interested in a outline of how to do it or just some hints.</p>
",graph_theory
"<p>Eulers Identity: n-m+r=2</p>

<p>a)If G is a planar graph which contains no cycles of length less than <em>g</em>, then give an improved version of Eulers identity by relating the number of regions to the number of edges.</p>

<p>b)use (a) to show Petersen graph is not planar</p>

<p>I'm thinking i need to relate n with g such that a new euler identity can be written with an inequality instead...not sure how they relate though.</p>
",graph_theory
"<p>In a group of 4 people, is it possible for each person to have exactly 3 friends? Why?</p>

<p>My solution</p>

<p>n Let G be a graph with 4 vertices, one vertex representing each person in the group.
Join two vertices u and v by an edge if and only if u and v are friends. Then the degree of
each vertex equals the number of friends that the corresponding person has. If each person
has exactly 3 friends, then each vertex has degree 3. Therefore, the total degree would be
3 · 4 = 12. This is an even number.</p>

<p>$n\equiv 0\pmod{2}$ and $n&gt;3$</p>

<p>So It is possible.</p>

<p>Is this correct?</p>
",graph_theory
"<p>I am trying to understand directed preorders, a.k.a. directed sets. Are they analogous to connected DAGs?</p>
",graph_theory
"<p>Let $G$ be a planar minimal 5-chromatic graph. That is, any of its proper subgraphs has chromatic number at most 4. I need to prove that its minimum degree is at least 5. I want to prove by contradiction, first by assuming that there is a vertex of degree 4. But I couldn't find any contradiction. Can anyone offer any ideas?</p>
",graph_theory
"<p>Let's say we have a graph, with a list of edges and vertexes $(E,V)$, all the vertexes are connected to at least one edge at one end. There are many ways a complete set of <a href=""http://www.mathreference.com/gph,basis.html"" rel=""nofollow"">cycle basis</a> can be found out from it.</p>

<p>Now the issue is, is it <strong>always</strong> possible to find a complete set of cycle basis that each edge is shared by at most $2$ cycles?</p>

<p><strong><em>Edit: There is a <a href=""http://math.stackexchange.com/questions/1340/in-a-graph-is-it-always-possible-to-construct-a-set-of-cycle-basis-with-each-an/1343#1343"">mathematical argument</a> proving why it is not possible. But admittedly such a highly abstract reasoning is a bit hard for me to grasp. I would appreciate if someone can provide a graphical example of such a graph.</em></strong> </p>
",graph_theory
"<p>Let $G$ be a graph of order $8$ with $V(G)=\{v_1, v_2,...,v_8\}$ such that deg $v_i=i$ for $1 \leq i \leq 7$. What is deg $v_8$.</p>

<p>Any help or hints would be greatly appreciated.</p>
",graph_theory
"<p>In any undirected tree $T$, what is the maximum distance from any vertex $v$ with $\text{deg}(v) \geq 3$ to the closest (in a shortest path sense) vertex $y$ with $\text{deg}(y) \leq 2$? That is, $y$ can be leaf.</p>

<p>It seems to me that this distance can be at most $\dfrac{\text{diam}(T)}{2}$, and furthermore that the maximum distance will be attained from a graph center. Is this true? There's probably simple argument for it somewhere.</p>
",graph_theory
"<p>So I'm working on proving (via contradiction) that the flow number $\phi(G)$ of a bridgeless graph $G$ is always defined. I'm using the flow polynomial, and I got to a point where I have $0=T(0,1-u)$.</p>

<p>So, my question:
If $T(x,y)=0$ where $T(x,y)$ is the Tutte polynomial, what does this mean about the graph? Does it mean it has no edges at all?</p>

<p>Thanks!</p>
",graph_theory
"<p>I recently found the following exercise:</p>

<blockquote>
  <p>Given a cubic, simple undirected graph $G$ without cut edges, then $G$ is matching covered. I.e. every edge is contained in a perfect matching.</p>
</blockquote>

<p>My idea was that, given an edge $e=(u,v)$, I could delete from $G$ the two edges with vertex $u$, say $(u,v_1)$ and $(u,v_2)$, in order to obtain a new graph with:</p>

<ul>
<li>$1$ vertex of degree $1$ ($u$ itself)</li>
<li>$2$ vertices of degree $2$ ($v_1$ and $v_2$)</li>
<li>any other vertex of degree $3$.</li>
</ul>

<p>Then, using the Tutte theorem, I am trying to prove the existence of a perfect matching in this new graph as this would be a perfect matching for $G$ containing $e$.</p>

<p>Does anyone have some sorts of advice about that? </p>
",graph_theory
"<p>I consider an edge-coloured graph with the colours red and blue. Gyarfas proofed in his paper <a href=""http://www.renyi.hu/~gyarfas/Cikkek/16_Gyarfas_VertexCoveringsByMonochromaticPathsAndCycles.pdf"" rel=""nofollow"">http://www.renyi.hu/~gyarfas/Cikkek/16_Gyarfas_VertexCoveringsByMonochromaticPathsAndCycles.pdf</a> the existence of two cycles covering the vertices and intersecting on at most one vertex. </p>

<p>He considered the longest path consisting of a red path followed by blue path (such a path $P$ is Hamiltonian). If a vertex $v$ is not covered it must be joined in blue to the origin of $P$ and in red to the end of $P$. Then you can cover the vertices of $P$ and $v$ using the edge from the starting point of $P$ to the end point (lets call them $a$ and $b$). Therefore there exists a monochromatic cycle $C$ and a monochromatic path $P$ with different colors partitioning the vertex set. </p>

<p>I am asking for help with the drawing. I think it looks like <img src=""http://i.stack.imgur.com/CpNlu.jpg"" alt=""enter image description here""> but where is the cycle $C$?</p>
",graph_theory
"<p>Is there a graph homomorphism between the 6-hypercube (<a href=""https://en.wikipedia.org/wiki/File:6-cube_graph.svg"" rel=""nofollow"">https://en.wikipedia.org/wiki/File:6-cube_graph.svg</a>) and the cube (<a href=""https://en.wikipedia.org/wiki/File:3-cube_graph.svg"" rel=""nofollow"">https://en.wikipedia.org/wiki/File:3-cube_graph.svg</a>)?</p>
",graph_theory
"<p>Here $G_{n,p}$ represents the Erdős-Rényi random graph model, where the graph has order $n$ and each edge is added independently with probability $p$. I am faced with proving the following claim:</p>

<blockquote>
  <p>Show that there is a constant $c&gt;0$ such that, for every $p$ we have: </p>
  
  <p>$\mathbb{P}(G_{n,p}$ is disconnected) $\leq c \mathbb{P}(G_{n,p}$ has an isolated vertex).   $\,\,\,(*)$</p>
</blockquote>

<p>From the appearance of the question I think it is meant to be interpreted as asking ''in the limit $n \to \infty$''. It is clear that $\mathbb{P}($a fixed vertex of $G_{n,p}$ is isolated$)=(1-p)^{n-1}$. It is easy to calculate the expected number of isolated vertices using this, but I'm not convinced that helps.</p>

<p>As a last thought, a followup to the question asks ""What value of $c$ would be acceptable""? It is therefore probably not the case that a valid choice of $c$ will actually be obtained in the proof, although it may be reasonably clear how to calculate one; perhaps that clarifies the nature of the solution a little. Many thanks for your help.</p>

<p><strong>Edit:</strong> Update - I have thought a little more about it, and I have the following theorem we can hopefully make use of (if anyone is willing to help me!): suppose $p = \frac{\log{n}+\gamma(n)}{n}$ and $\gamma(n)$ grows at most slowly (say $o(\log \log n)$); then </p>

<blockquote>
  <p>if $\gamma(n) \to +\infty$, $\mathbb{P}(G_{n,p}$ disconnected)$\to 0$, </p>
  
  <p>if $\gamma(n) \to -\infty$, $\mathbb{P}(G_{n,p}$ disconnected)$\to 1$, </p>
  
  <p>if $\gamma(n) \to k$, $\mathbb{P}(G_{n,p}$ disconnected)$\to 1-e^{-e^{-k}}$.</p>
</blockquote>

<p>Now in the first case, being connected implies no isolated vertex, so $(*)$ holds with any constant $c$ since both probabilities are 0. Likewise, in the second case, the graph is almost surely disconnected: while this doesn't immediately imply that an isolated vertex exists, we can hopefully say for $X:=\#$ of isolated vertices,</p>

<p>$\mathbb{E}(X)=n(1-p)^{n-1} = n(1-\frac{\log{n}+\gamma(n)}{n})^{n-1} \sim ne^{-(\log{n}+\gamma(n))} = e^{-\gamma(n)} \to \infty$.</p>

<p>I <strong>think</strong> this last step holds but it may depend on $\gamma$: in general I'm not sure for which functions $(1+\frac{f(n)}{n})^n \to e^{f(n)}$, I know this is true for the log term but maybe not if $\gamma$ grows very fast (though obviously it can't grow any faster than $1-\frac{\log{n}}{n}$ otherwise we would have $p&gt;1$).</p>

<p>We can also calculate the second moment and get $\mathbb{E}(X^2)-\mathbb{E}(X)^2 \sim e^{-\gamma(n)}$ and deduce that with high probability there is an isolated vertex. Thus again, both probabilities are equal and we can take (e.g.) $c=1$. </p>

<p>The <em>hard</em> case is where $\gamma(n) \to k$: in this case we can reapply the same method to get $\mathbb{E}(X) \sim e^{-k}$, a constant. We can calculate again $\mathbb{E}(X^2) -\mathbb{E}(X)^2 \sim e^{-k}$, and use Chebyshev's inequality to calculate $\mathbb{P}(X=0) \leq e^{-k}/e^{-2k} = e^k$. If $k&lt;0$, then this gives us an actual bound on the probability; otherwise we just get $\mathbb{P}(X=0) \leq 1$. </p>

<p>Supposing $k&lt;0$ then; we can rewrite as $s:=\mathbb{P}(X&gt;0)=\mathbb{P}$(isolated vertex)$\geq 1-e^k$, $d:=\mathbb{P}($disconnected) and using the fact $d =1- e^{-e^{-k}}$ and a little rearranging I think we get out the inequality $d \leq 1-\exp\left(\frac{1}{s-1}\right)$. We can then find a $c$ which works by applying the lower bound to $s$ in terms of $k$ then looking at the values of $c$ such that $cx \geq 1-\exp\left(\frac{1}{s-1}\right),\,x \in [1-e^k,1]$. However, this is only for fixed $k$! If we try and do this for <em>every</em> $k&lt;0$ (i.e. every probability of this type) simultaneously, then we find that $c$ must be arbitrarily large. What's worse, this method doesn't work at all for $k \geq 0$ where we don't have a lower bound for $s$: in this case $s$ can be arbitrarily small and we can't pick a $c$ big enough to always work. So close and yet so far. </p>

<p>I am aware this question's length has spiralled out of control, so apologies for that - I know there's a good chance Math.SE is not going to provide me with an answer to this one. Nevertheless, it says add your working and this is what I managed to do! A proof which works for all <em>slowly</em> decreasing $\gamma$ or $\gamma \to k \in (-\infty,-\epsilon],$ any $\epsilon &gt; 0$. </p>

<p>I have a strong suspicion this is not how I was meant to try and tackle the question, but tragically this is the best I could do so far. Thank you in advance to anyone who actually reads through all this!</p>
",graph_theory
"<p>This is an interesting question where we are trying to solve another recursion which has same tree structure as the given recursion  and also has term similarities</p>

<p><strong>Given Data in question</strong></p>

<ol>
<li>$F_n=F_{n-1}+F_{n-2}$, where $F_1=F_2=1$, we have $F_n= \frac{(1+\sqrt{5})^n-(1-\sqrt{5})^n}{2^n\sqrt{5}}$ and generating function $g(x)= \sum_{n=0}^{\infty}F_nx^n=\frac{x}{1-x-x^2}$</li>
<li>More details of Fibonacci recursion and properties can be found <a href=""http://mathworld.wolfram.com/FibonacciNumber.html"" rel=""nofollow"">here</a>! .</li>
</ol>

<p><strong>Question</strong></p>

<p>Can we find solution for a)$Q_n$(interms of n)  b) $ g(x)= \sum_{n=0}^{\infty}Q_nx^n $ for the given recursion below   <strong>$nQ_n=Q_{n-1}+Q_{n-2}\tag 3$</strong> 
 $Q_1=Q_2=1$,by using the above results, given the fact that both follows same recursion tree  (in structure) even though results are different? if so please answer
<img src=""http://i.stack.imgur.com/qoTYd.png"" alt=""enter image description here""></p>

<p>NB :: This is not a home work problem. Logic is simple,the varying n will make it tough. And no  prof will give it as home work. I am trying this for weeks/months.. It is not simple. Attempt on a similar problem by me  can be found   <a href=""http://math.stackexchange.com/questions/881732/recurrence-solution-of-simple-recurrence"">here</a> </p>

<p>NB :: <strong>I know a method of using ODE. But I am trying to solve it with out ODE so that I can extent this to higher dimension like matrices in similar structure questions. Please avoid ODE solution</strong>  </p>
",graph_theory
"<p>I am wondering if there is proper terminology for a ""long"" loop in a social network. The end-game is to remove loops of n-edge length. (I need to research how to do that, but first I need the right terminology). </p>

<p><a href=""http://i.stack.imgur.com/hKXa3.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/hKXa3.jpg"" alt=""enter image description here""></a></p>

<p>The code to recreate this graph in R igraph is here:</p>

<pre><code>g &lt;- data.frame( kin1 =c(1,15,15,5,4,17,5,18,19,20,21,22,23,24,25,26,27,28,29,30,30), 

       kin2 =c(4,5,16,4,16,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,5), stringsAsFactors = F)


    g1  &lt;- graph.data.frame(g, directed=FALSE)

    plot(g1, layout=layout.fruchterman.reingold)
</code></pre>
",graph_theory
"<p>Let $G=(V,E)$ be a graph.</p>

<p>Let $M1, M2$ be two matchings of $G$. Consider the new graph $G' = (V, M1 ∪ M2)$ (i.e. on the same vertex set, whose edges consist of all the edges that appear in either $M1$ or $M2$). Show that $G'$ is bipartite.</p>

<p>Helpful definition: A connected component is a subgraph of a graph consisting of some vertex and every node and edge that is connected to that vertex.</p>
",graph_theory
"<p>Given is a weighted complete graph where every weigth is a positive ineger. Let n be the amount of vertices.</p>

<p>I have to prove that the number of edges of a minimum spanning tree of that graph is equal to n-1.</p>
",graph_theory
"<p>Let $G$ be a graph with $\chi(G)=k+2$ for $k\ge3$. Prove that $G$ contains a cycle of a length $l$ such that $l \equiv 2 \;(\bmod\; k)$. </p>

<p>Not quite sure how to approach this at all. I know that there is a subgraph $H$ with $\delta(H)\ge k+1$ (critical subgraph/degeneracy condition), and therefore $H$ has a cycle with length at least $k+2$, but I don't know how to get the $l \equiv 2 \;(\bmod\; k)$.</p>

<p>Thanks in advance.</p>
",graph_theory
"<p>I am working through a proof of the following Theorem:
Let $G$ be a connected, $k$-regular graph, $G\neq K_n$, then $G$ is strongly regular if and only if $|Spec(G)|=3$.</p>

<p>Now I am having trouble with the given proof of the ""$\Leftarrow$"" direction:</p>

<p>Let $k,\beta_1,\beta_2$ be the eigenvalues of $A$. Consider the matrix
    \begin{align*}
		M:=\frac{1}{(k-\beta_1)(k-\beta_2)}(A-\beta_1 I)(A-\beta_2 I),
	\end{align*}
    then $M$ has all of its eigenvalues equal to $0$ or $1$. This is, since if $b_i$ is an eigenvector of $A$ to eigenvalue $\beta_i$, $i=1,2$, with $b_i\perp\mathbb{1}$, then
    \begin{align*}
		M\cdot b_1 =0,\\
		M\cdot b_2 =0,\\
		M\cdot\mathbb{1}=\mathbb{1}.
	\end{align*}
    Therefore $Spec(M)=\{1^{(1)},0^{(n-1)}\}$. Since $G$ is connected and because of the spectrum of $J$ (the $n\times n$ matrix with all 1's entries) as computed as $Spec(J)=\{1^{(1)},0^{(n-1)}\}$, we get $M=\frac{1}{n}\cdot J$. That is
    \begin{align*}
		\frac{1}{n}\cdot J=\frac{1}{(k-\beta_1)(k-\beta_2)}(A-\beta_1 I)(A-\beta_1 I)(A-\beta_2 I).
	\end{align*}
    Factorising this out gives
\begin{align*}
   A^2=k\cdot I+\lambda\cdot A+\mu\cdot(J-I-A),
\end{align*}
which is a characterization of $G$ being strongly regular.</p>

<p>Now I doubt the implication to $M=\frac{1}{n}J$. For all we know, $M$ might be a diagonal matrix with a single $1$ and otherwise only $0$'s. Does this implication hold?</p>
",graph_theory
"<p>Let $f(G)$ be the smallest $m$, such that one can find $2m$ vertices in $G$ with the following property: pair up the vertices in any way, and find $m$ paths that join each pair. Then every set of path constructed will have a intersection. (Is there a name for this graph property?)</p>

<p>I have a feeling this property might be connected to the connectedness of a graph. but for large grid graphs, I can chose many vertices and still find disjoint paths connecting the pairs, when it is only 4 connected.</p>

<p>For a $n\times n$ grid graph $G$, what is $f(G)$?</p>

<p><strong>Edit:</strong> I have found the name of the property. A graph is $k$-linked if there exist $2k$ elements, such that there are $k$ disjoint paths that pairs two of them.</p>
",graph_theory
"<p>If you could explain the answer simply It'd help me out as I'm new to this subject.</p>

<p><strong>For which values of n is the complete graph Kn bipartite? For which values of n is Cn (a cycle of length n) bipartite?</strong></p>

<p>Is it right to assume that the values of n in Kn will have to be even since no odd cycles can exist in a bipartite?
Also, for Cn is it correct that the length of the cycle will also need to be even since you need to take an even number of steps to travel from V1 to V2 and V2 back to V1?</p>
",graph_theory
"<p><a href=""http://i.stack.imgur.com/LB76M.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/LB76M.png"" alt=""enter image description here""></a></p>

<p><a href=""https://staff.fnwi.uva.nl/n.s.walton/Notes/Hall_Birkhoff.pdf"" rel=""nofollow"">https://staff.fnwi.uva.nl/n.s.walton/Notes/Hall_Birkhoff.pdf</a> </p>

<p>Could someone possible explain how the inequality arises in $(44)$</p>
",graph_theory
"<p>Let $u$ and $v$ be 2 vertices in a tournament $T$. Prove that if $u$ and $v$ do not lie on a common cycle then $od(u)≠od(v)$</p>

<p>I have no idea how to start this proof. Please help.</p>
",graph_theory
"<p>An infinite $r$-regular graph is a graph with $\infty$ vertices where each vertex touches precisely $r$ edges.</p>

<p>We say an $r$-regular graph can be embedded in the $R^2$ Euclidean plane if its set of edges and vertices can be represented as a set of points on the plane where each point is connected via an edge to precisely the $r$ closest points to it. For example, some $4$-regular graphs can be embedded in the plane by placing each vertex of the graph on a unique point $(m,n)$ on the plane where $m$ and $n$ are integers. Some $8$-regular graphs can be embedded using the same placement.</p>

<p>The question is: for what values of $r$ do there exist connected $r$-regular graphs that can be embedded in the plane? </p>

<p>The graphs need not be planar, but an answer dealing with the planar case is welcome.</p>
",graph_theory
"<p>A permutation matrix is a square matrix with exactly one $\textbf{1}$ in each row and column, and zeros in all other positions of the matrix. Let $M$ be an $n\times n$ $\{0,1\}$ matrix with exactly $m$ ones in each row and column. Prove that $M$ can be written as the sum of $m$ permutation matrices.</p>

<p>I saw my lecturer about this problem and the hint he gave me was to think about decompositions of bipartite graphs into perfect matchings. </p>

<p>For the life of me I don't really understand what he means by that nor do I even know how to get started on the question.</p>

<p>Any help would be greatly appreciated.</p>
",graph_theory
"<p>Give an example of 2 non isomorphic regular tournament of the same order</p>

<p>I tried so many tournaments of the same order but got no luck, if they are regular, meaning all vertices of them have the same in and out degree, so they have arc preserved, which end up to make them isomorphic. I'm not sure there are such tournaments exist.</p>
",graph_theory
"<p>In doing a problem from graph theory by west. In one question it asks you to find the maximum sized clique in the graph.  I think it's 5 (using the top or bottom vertex). However in the solution manual it mentions that because the graph contains two points of degree 3 this is not possible. Is that correct? Can anyone explain why if so? Here's  a link to the graph. <a href=""http://imgur.com/wGCcf89"" rel=""nofollow"">http://imgur.com/wGCcf89</a></p>
",graph_theory
"<p>Is there a good database of unsolved problems in graph theory?</p>
",graph_theory
"<p>I'm taking an introductory graph theory course and I am having trouble going about answering this question. I've been told to look at the graph compliment but I don't quite understand how that ties into this.</p>
",graph_theory
"<p>A graph $G$ has the property that every edge of $G$ joins an odd vertex with an even vertex. Show that $G$ is bipartite and has even size.</p>
",graph_theory
"<p>Let $G=(V,E)$ be a connected undirected graph such that $E$ is the union of $n$ forests $F_1\cup F_2 \cup \dots \cup F_n$. Each forest has $V$ as its nodes and containts $k$ disconnected components. Each component is simply an edge connecting 2 vertices. </p>

<p>is it possible to compute the chromatic polynomial of $G$ through $F_1,F_2,\dots,F_n$? since the chromatic polynomial for $F_i$ is easy to compute.  </p>
",graph_theory
"<p>I recently met with a professor to discuss this problem and she didn't have an answer for how to do the calculation. What I did learn is that the counting itself is considered NP-Hard and is in a class known as #P. I'm currently running an efficient 4-coloring on a map of the US (contiguous 48) and was hoping to be able to compare the brute force count with a known value.</p>

<p>Any help is appreciated.</p>
",graph_theory
"<p>Give an undirected simple graph $G$ with $n$ vertices and $m$ edges, its <strong>2-Lift</strong> is constructed as follows:</p>

<ul>
<li>Define $G_1$ to be the original graph $G$. Make a duplicate copy of $G$ and call it $G_2$.</li>
<li>Now each edge $(u,v)$ in $G$ corresponds to a pair of edges $(u_1,v_1)$ in $G_1$ and $(u_2,v_2)$ in $G_2$.</li>
<li>For each edge $(u,v)$ in $G$, there are two choices and randomly decides what to do:
<ol>
<li>Leave each pair of edges as they are: $(u_1, v_1)$ and $(u_2, v_2)$</li>
<li>Make them cross: $(u_1, v_2)$ and $(u_2,v_1)$</li>
</ol></li>
</ul>

<p>As $G$ has $m$ edges, there are $2^m$ possibilities of 2-lifts of $G$. Naturally, there are two extreme cases when the 2-lift is not connected:</p>

<ul>
<li>When all the pairs of edges stay as they are, then $G_1$ and $G_2$ are isolated.</li>
<li>When all the pairs of edges are switched, then we still have two isolated graphs.</li>
</ul>

<p>Other than these two trivial cases, all the 2-lifts are connected graphs.</p>

<p>The 2-lifts of a graph are recently used for <a href=""http://arxiv.org/abs/1304.4132"" rel=""nofollow"">the existential proof of bipartite Ramanujan graphs</a> by Marcus, Spielman, and Srivastava. You may take a look at the visual representation of 2-lifts at the following urls.</p>

<ul>
<li><a href=""http://www.tcs.tifr.res.in/~prahladh/mysore2013/slides/Srivastava-mp1.pdf"" rel=""nofollow"">http://www.tcs.tifr.res.in/~prahladh/mysore2013/slides/Srivastava-mp1.pdf</a></li>
<li><a href=""http://cs-www.cs.yale.edu/homes/marcus/talks/bipartite_ramanujan.pdf"" rel=""nofollow"">http://cs-www.cs.yale.edu/homes/marcus/talks/bipartite_ramanujan.pdf</a></li>
</ul>

<hr>

<p>Now assume that the original graph $G$ is <a href=""http://en.wikipedia.org/wiki/Complete_bipartite_graph"" rel=""nofollow"">a complete bipartite graph</a> $K_{n,n}$. Except the two trivial extreme cases, it seems that all the 2-lifts are connected and have <a href=""http://mathworld.wolfram.com/GraphDiameter.html"" rel=""nofollow"">diameter</a> 4. (Remember that $dist(u,v)$, the distance of two vertices $u$ and $v$ in a graph, is defined to be the number of edges in a shortest path between $u$ and $v$, and the diameter of a graph is $\max_{u,v}dist(u,v)$.)</p>

<p>Is my conjecture true? If it is, how can I prove it?</p>
",graph_theory
"<p>I know Dijkstra's algorithm to find the shortest way between 2 nodes, but is there a way to find the shortest path between 3 nodes among $n$ nodes? Here are the details:</p>

<p>I have $n$ nodes, some of which are connected directly and some of which are connected indirectly, and I need to find the shortest path between 3 of them.</p>

<p>For example, given $n = 6$ nodes labelled A through F, and the following graph:</p>

<pre><code>A--&gt;B--&gt;C
A--&gt;D--&gt;E
D--&gt;F
</code></pre>

<p>How can I find the shortest path between the three nodes (A,E,F)?</p>

<p>I am looking for a solution similar to Dijkstra's shortest path algorithm, but for 3 nodes instead of 2.
<br/>
Please Note : <br/>
1- The Starting Node is A  <br/>
2- The Sequential is not important just the path needs to cover all these Nodes   <br/>
3- Their is no return back to A   <br/>
Please find the diagram Image
<img src=""http://i.stack.imgur.com/M1wxF.png"" alt=""enter image description here"">
Regards &amp; Thanks<br />
Nahed</p>
",graph_theory
"<p>I am seeking a listing of the distinct <a href=""http://mathworld.wolfram.com/HamiltonianCycle.html"" rel=""nofollow"">Hamiltonian cycles</a> following the edges of the icosahedron and the dodecahedron.  By <em>distinct</em> I mean they are not congruent by some symmetry
of the icosahedron or dodecahedron (respectively). So they do not make the same sequence of angular turns. For example (as Gerhard corrected me in the comments), there is just one distinct Hamiltonian cycle on the cube.</p>

<p>Hamiltonian cycles of the Platonic solids are all over the web, but I am not finding a definitive list of the number and a description of each.  Thanks to anyone who can point me in the right direction!</p>
",graph_theory
"<p>Let us denote by $\def\Graph{{\sf Graph}}\Graph$ the category of directed graphs
$G$ with multiple edges: they are given by a set $G_v$ of vertices, a set $G_e$ of edges,
and two functions from $G_e$ to $G_v$ determining the target ($\tau$) and the source ($\sigma$)
of every edge. The morphisms are called graph homomorphisms: given graphs
$G$ and $G'$, a graph homomorphism is a pair of functions $h_v\colon G_v \to G'_v$ and
$h_e\colon G_e \to G'_e$ such that the source and the target of every edge are preserved.</p>

<p>NOW,An algebraic theory is a small category $T$ with finite products.
An algebra for the theory $T$ is a functor $A\colon T \to {\sf Set}$ preserving finite products.
We denote by $\def\Alg{\mathop{\rm Alg}}\Alg T$ the category of algebras of $T$. Morphisms, called homomorphisms,
are the natural transformations; that is, $\Alg T$ is a full subcategory
of the functor category ${\sf Set}^T$
.</p>

<p>Q.HOW algebraic theory of $\Graph$ ($T_\Graph$) arises as the free completion, of the category $C$ consisting of two parallel arrows from $e$ to $v$:
$\tau$, $\sigma$, under products--what graph determines the $A$-image of a word in $\{e,v\}^*$ and a pair $(a, \alpha)$;see below.</p>

<p>Here,free completion under products in a category $C$ can be described as the category of all words over $\mathop{\rm obj} C$ (the
set of objects of $C$); that is, objects have the form of $n$-tuples $c_0\ldots c_{n-1}$,
where each $c_i$ is an object of $C$ (and where $n$ is identified with the set
$\{0,\ldots, n − 1\}$), including the case $n = 0$ (empty word). Morphisms from
$c_0\ldots c_{n-1}$ to $c'_0\ldots c_{k-1}'$ are pairs ($a$, $\alpha$) consisting of a function $a\colon k \to n$
and a $k$-tuple of $C$-morphisms $\alpha = (\alpha_0, \ldots, \alpha_{k-1})$ with $\alpha_i\colon c_{a(i)} \to  c'_i$.</p>
",graph_theory
"<p>To prove that two graphs are isomorphic I was taught to first consider the bijection between the two graphs. I was never taught however the rules when coming up with the bijection. 
Is my only rule, when coming up with a bijection between two graphs, that the vertices that I match, that they must have the same degree? 
eg. if <code>a</code> in graph 1 has a degree of 3 then I can only match it up with other vertices in graph 2 that have degrees of 3?</p>

<p>I am really confused on how to do this. </p>
",graph_theory
"<p>I am trying to understand this problem and yes this is from my assignment and I should be doing it myself, but I have been staring at it for 2 hours and not getting anywhere, so decided to post it here.</p>

<p>Let G be a connected cubic simple graph that contains 2 edge-disjoint spanning trees show that |G| = 4.</p>
",graph_theory
"<p>Is there a planar point set such that no matter how you colour the points with two colours can you can always find a triangle with exactly one point inside so that all four points have the same colour?</p>

<p>I'm not really sure how to start working on this graph problem any advice? </p>
",graph_theory
"<p>I have a graph, not necessarily connected, that I know for a fact has vertices with degrees at most $3$. I need to find it's chromatic number in polynomial time.</p>

<p>Well then it's just a matter of checking whether the graph is edgeless (if so, then $\chi(G)=1$), or if it's 2-colorable (simple DFS), but I'm stuck at checking if it's $3$-colorable. Brooks theorem states that </p>

<blockquote>
  <p>For any connected undirected graph G with maximum degree Δ, the chromatic number of G is at most Δ unless G is a clique or an odd cycle, in which case the chromatic number is Δ + 1.</p>
</blockquote>

<p>So basically I just have to check if it's a clique or if it's a cycle of odd length (which can be done by DFS also), and If they are not then $\chi(G)=3$, otherwise is $4$, right?</p>

<p>What I'm specifically asking is this. Brooks theorem assumes that $G$ is connected. But what if it's not? Won't I basically get the same thing by treating all components of $G$ separately? Each of them is connected and for each $H \in G$ $Δ_h \leq Δ$, so by Brooks theorem I'm safe if all of the components are not odd cycles, right?</p>
",graph_theory
"<p>I'm creating a directed graph from an adjacency list. The $0$ present that there is no relation while the $1$ represent that there is.</p>

<p>So i have a quick question regarding this.</p>

<p>Lets assume that $AB = 1$ that is that it has a connection.
$BA = 0$ which means that is does not have a connection. This continues throughout the graph. So we assume that it is anti symmetric. However the graph has loops. So $BB = 1$  $CC= 1$ etc.</p>

<p>It still considered anti symmetric?</p>
",graph_theory
"<p>Fáry's theorem is a (fairly famous) statement which asserts that every finite simple planar graph can be drawn in a way such that every edge is represented by a straight line segment.</p>

<blockquote>
  <p>Does this theorem extend to countably infinite graphs?</p>
</blockquote>

<p>A standard proof of this theorem proceeds by induction on the number of vertices, and hence is unapplicable here. I suspect the answer is <strong>no</strong>, but I can't think of a counterexample.</p>

<p>Thanks in advance.</p>
",graph_theory
"<p>This question came from a question asked earlier today linked <a href=""http://math.stackexchange.com/questions/1403945/grouping-kids-in-groups-of-4"">here</a></p>

<p>The question implicitly asked how to make a schedule with his/her class of 24 students such that:
1)  Everyday will consist of the 24 students split into 6 groups of 4 students.
2)  Over the course of several days, every pair of students will have been in a group with one another.</p>

<p>This seems like it might be a Steiner system, but i'm not exactly sure. <a href=""https://en.wikipedia.org/wiki/Steiner_system"" rel=""nofollow"">Steiner system</a> $S(2,4,24)$.
I've found that a necessary condition for this system existing is the existence of $S(1,3,23)$.  Now here's where I'm not sure if I'm following the definition of Steiner system exactly.  This system, $S(1,3,23)$ would be a $K_3$ decomposition of $K_{23}$, would it not?  <strong>Perhaps this is not exactly a Steiner system, this is part of my question.  Help me to clear this up</strong></p>

<p>How many days would be required to schedule this?<br>
Well, we need to partition the edges of $K_{24}$ which has $\binom{24}{2}$ edges.  Each $K_4$ has 6 edges.  So on a single day we would have 36 edges while we need a total of 276 edges.  However, $\frac{276}{36}$ is not an integer, so this actually tells us that <strong>we can't do this if we require no edges to be repeated.</strong>  So, some pairs of students will be in the same group with each-other more than once.</p>

<p><strong>The Question</strong>:  What is the minimum number of days required to schedule this?  Will $\lceil\frac{276}{36}\rceil = 8$ days be sufficient?  What exactly am I dealing with here?  Some sort of design?  A Steiner system?  What?</p>
",graph_theory
"<p>Given a simple graph on $n$ vertices, how many graphs are atmost there that are isomorphic to the given graph? Is it $\Theta(n^2!)$ or $\Theta(n!)$ which is number of permutations of rows or columns?</p>
",graph_theory
"<p>For any 3-coloring of $K_{17}$ I have to show there exists either a red, blue or green triangle. To start, can I use proof by contradiction with color red, blue, green? So $(0,0,136)$ means all 136 edges are green. Clearly this has green triangle. If we color the ""outside"" of the graph all one color, say red, then we have 17 edges that are red and no edge of the interior can be colored red in order to avoid red triangles. Then I try to obtain a contradiction?</p>
",graph_theory
"<p>I've been a talk with a PhD student about some graph issue and told me about GRAIL graph and have drawn it for me as you see in the picture, however, I try to generalize so-called ""Grail graph"" to k-pair problem. But I am not able to find a definition, though.</p>

<p>In the picture is an example of 2-pair problem in the GRAIL graph.</p>

<p><a href=""http://postimg.org/image/4a3xvsik9/"" rel=""nofollow"">http://postimg.org/image/4a3xvsik9/</a></p>

<p>so my question is: have you seen this kind of graph? or have you heard about this graph, or do you know a name for this graph (may be I misunderstood with this kind of graph).</p>

<p>I have to point that I found a paper called ""GRAIL: Scalable Reachability Index for Large Graphs"". However, it doesn't give me an example of a graph, instead it just give me a ""a good scale for reachability graph between fixed two nodes""; </p>

<p>Thank you.</p>
",graph_theory
"<blockquote>
  <p>Show that any connected graph $G$ satisfies $\lvert E(G)\rvert \geq \lvert V(G)\rvert -1 $ by induction on the number of edges.</p>
</blockquote>

<p>My attempt: </p>

<ol>
<li>Base Case: For any connected graph $G$ let number of vertices $= 1$
so $0 \geq 1-1$ which is true.</li>
<li>Now i'm not really sure what to do here.</li>
</ol>
",graph_theory
"<p>Let $G$ be an undirected graph and define </p>

<p>$$P=\{x \in R^{V}: x(u)+x(v) \leq 1 \:\:\text{for all edges}\:\: e=uv,\:\: x \geq 0\}$$</p>

<p>Show that any vertex $v$ of $P$ is half integral.</p>
",graph_theory
"<p>In software engineering, there is a coverage metric for testing called <a href=""https://en.wikipedia.org/wiki/Modified_condition/decision_coverage"" rel=""nofollow"">modified condition/decision coverage</a>, or MC/DC for short. This metric is well-known in the avionics industry due to showing up in the <a href=""https://en.wikipedia.org/wiki/DO-178B"" rel=""nofollow"">DO-178B</a> and <a href=""https://en.wikipedia.org/wiki/DO-178C"" rel=""nofollow"">DO-178C</a> standards as part of the testing requirements for Level A airborne software.</p>

<p>One way of thinking about MC/DC is in terms of Boolean functions. For an $n$-input Boolean function $f : \{0, 1\}^n \rightarrow \{0, 1\}$, MC/DC coverage is achieved if we can show that each of the $n$ input variables of $f$ has an <em>independent effect</em> on the output of $f$. That is, we have to exhibit pairs of input strings $x$ and $y$ such that $f(x) \neq f(y)$ and $x$ and $y$ differ only at a single position $i$. MC/DC coverage is achieved if we can find such pairs of strings for each input position $0 \leq i &lt; n$.</p>

<p>Now, test rig time on avionics hardware is often expensive. Companies have a strong desire to minimize the number of test cases that have to be run on their devices to achieve certification.* Obviously, if it is possible to achieve MC/DC coverage at all on some $n$-input function, then it can be done with $2n$ inputs: simply list all $n$ pairs of inputs individually. However, it is often possible to reuse the same input string to show the effect of multiple input variables. For example, if $f$ is a 4-input AND gate, then we can show the effect of all 4 input variables by evaluating $f$ at just 5 input strings: $\{1111, 0111, 1011, 1101, 1110\}$. This works because the necessary 4 pairs are $[\{1111, 0111\}, \{1111, 1011\}, \{1111, 1101\}, \{1111, 1110\}]$.</p>

<p>This prompts the question in the title: <strong>Is it always possible to get MC/DC coverage on an $n$-input Boolean function with $n + 1$ test cases (assuming that it is possible to get MC/DC coverage at all)?</strong></p>

<p>To state this question more formally, I will use the following definitions:</p>

<ul>
<li>Call two $n$-bit strings <em>$i$-adjacent</em> if they have <a href=""https://en.wikipedia.org/wiki/Hamming_distance"" rel=""nofollow"">Hamming distance</a> $1$, differing only at position $i$ ($0 \leq i &lt; n$).</li>
<li>Call an $n$-input Boolean function $f$ <em>dependent on all of its inputs</em> if for all $0 \leq i &lt; n$ there exist $i$-adjacent strings $x$ and $y$ such that $f(x) \neq f(y)$.</li>
<li>Let $f$ be an $n$-input Boolean function, and let $T$ be a list of $n$ unordered pairs of $n$-bit strings. Then $T$ <em>gets MC/DC coverage</em> on $f$ if for all $0 \leq i &lt; n$, we have $T_i = \{v_1, v_2\}$, $v_1$ and $v_2$ are $i$-adjacent, and $f(v_1) \neq f(v_2)$.</li>
</ul>

<p>Then my question is as follows: <strong>For any $n$-input Boolean function $f$ that is dependent on all of its inputs, does there always exist a list $T$ that gets MC/DC coverage on $f$ such that $|\bigcup_{0 \leq i &lt; n} T_i| = n + 1$?</strong></p>

<p>I have tried for a while to construct a counterexample function, but in every case I have found that either I could contrive a set of $n + 1$ test cases that works, or else the function ends up not actually depending on one or more of its input variables. For an example of a simple function that has an $n + 1$ solution that is not immediately obvious, consider the function $f(a, b, c, d) = (a \vee b) \wedge (c \vee d)$. The 5-element set $\{1010, 0010, 0110, 1000, 1001\}$ gets MC/DC coverage on this function, because we have $[\{1010, 0010\}, \{0010, 0110\}, \{1010, 1000\}, \{1000, 1001\}]$.</p>

<p>I have also made some minor efforts to prove the statement using subtrees of <a href=""https://en.wikipedia.org/wiki/Hypercube_graph"" rel=""nofollow"">hypercube graphs</a>, but I feel like my combinatorics background is not strong enough (or I'm missing something obvious). It's easy enough to check all the cases by hand for $n \leq 2$, but for $n \geq 3$ I'm stuck.</p>

<p><sub>* Don't think about this too hard the next time you're on an airplane.</sub></p>

<hr>

<p><strong>UPDATE:</strong> I have run a computer search with an SMT solver and determined that there are no counterexamples with $n \leq 4$.</p>

<p><strong>UPDATE 2:</strong> Here is a restatement of the problem in terms of hypercube graphs. Let $G$ be the $n$-dimensional hypercube graph, and let $f$ be a vertex coloring of $G$ with two colors (not requiring that adjacent vertices have different colors). Let $G'$ be the subgraph of $G$ obtained by removing any edge whose vertices are both the same color, so that the vertex coloring is proper. Suppose $G'$ contains an edge along each dimension. Then, does there always exist a set of $n + 1$ vertices such that the induced subgraph of $G'$ on these vertices also contains an edge along each dimension?</p>

<p>Also, here is a proof that it is not possible to use <em>fewer</em> than $n + 1$ vertices for any $f$. Suppose that we have a subgraph $H$ of the $n$-dimensional hypercube graph with $n$ edges and $k \leq n$ vertices. Since there are not more vertices than edges, $H$ must contain a cycle. But if $H$ contains a cycle, then it has to contain two edges that are both along the same dimension. Since there are only $n$ edges and at least two of them are along the same dimension, $H$ can't have edges along all $n$ dimensions. Note that this is purely a pigeonhole principle argument; it does not in any way depend upon $f$.</p>
",graph_theory
"<p>I'm currently working on the exercises of Noga Alon's book ""The Probabilistic method"". One exercise said that we are given a graph $H$ with $p$ vertices and that there exists a graph $G$ with $n &gt; p$ vertices and $m$ edges containing no copy of $H$.</p>

<p>We have to prove that if we have $k &gt; \frac{n^2ln(n)}m$ and we can find a $k$-coloring of a complete graph $K_n$ with $k$ colors then there exists a graph with no monochromatic $H$. I know this should be proved with probabilistic method, I just don't know how. Could any one give me a hint?</p>
",graph_theory
"<p>We say that $G$ is $∆$-critical if $G$ is connected with $∆(G) = ∆$, $χ'(G) = ∆ + 1$, and $χ'(G − e) &lt; χ'(G)$ for any $e ∈ E(G)$. Prove that if $G$ is $∆$-critical, then $d(x) + d(y) ≥ ∆ + 2$ for any $xy ∈ E(G)$.</p>

<p>Any hints or proofs are greatly appreciated.</p>
",graph_theory
"<p>Let $G$ be an undirected simple graph and let $A$ be its adjacency matrix. It is easy to see that $A$ is neither positive semidefinite nor negative semidefinite. </p>

<p>I would like to know if there are interesting graphs $G$ for which smallest eigenvalue of $A$ is at least $-1$. Clearly, cliques and disjoint union of cliques have this property. Are there any other graphs with this property?</p>

<p>Slightly related: A quick google search reveals that graphs with smallest eigenvalue $-2$ have been studied. What is special about $-2$ (or not special about $-1$)?</p>
",graph_theory
"<p>Let $H$ be a simple graph that has no cycles of length more than $3$. Each vertex has degree of $n$. Is it possible to prove $H$ has at least $2n$ vertices?</p>
",graph_theory
"<blockquote>
  <p>Each pair of cities in a nation has exactly one direct one-way road between them. Show that there is a path which visits each city exactly once.</p>
</blockquote>

<p>Now, this problem seems ripe for induction, but I have hit a bit of a snag trying to solve it that way. If we assume that this is true for $n$ cities, then I think it would be possible to add a city which only goes to other cities. This city would then not be able to fit onto the path already established, correct? I feel like I'm close, but not quite able to understand how to find a solution yet.</p>
",graph_theory
"<p>I am trying to figure out how to formally describe a probabilistic directed graph. In plain English the properties of the graph are as follows :</p>

<p>A graph is comprised of a set of nodes each with 2 edges. These edges can connect at random with any other two nodes. While each node can set only two outgoing edges, it can recieve any number of incoming edges. Each node re-assigns its edges at an individual rate.</p>

<p>If I have described it right, those nodes which reassign edges more frequently will cluster in terms of network connectivity over time, since the chance of their finding one another is higher. </p>

<p>If anyone could suggest a way to formally state this, or an online reference to a similar problem, that would be very helpful.</p>

<p>Thanks in advance,</p>

<p>Neil</p>
",graph_theory
"<p>Let's consider a query set $Q$ and a larger superset $S$. Each element of $Q$ exists in $S$. The goal is to express $Q$ using the smallest number of (connected) ""components"" of $S$.</p>

<p>Here is a concrete example:
$Q=\{\textrm{I love France and wine}\}$
$S=\{(\textrm{I live here}), (\textrm{I love you and her}), (\textrm{France is beautiful}), (\textrm{cheese and wine})\}$</p>

<p>A solution for $Q$ might:
- ""I"" from ""I live here""
- ""love"" from ""I love you and her""
- ""France"" from ""France is beautiful""
- ""and"" from ""I love you and her""
- ""wine"" from ""cheese and wine""
This results in 5 ""components"", i.e. ""I"", ""love"", ""France"", ""and"", ""wine""</p>

<p>A better solution is:
- ""I love"" from ""I love you and her""
- ""France"" from ""France is beautiful""
- ""and wine"" from ""cheese and wine""
This results in 3 ""components"", i.e. ""I love"", ""France"", ""and wine""
which might be the optimal solution for this example. We want to minimize this number of ""components"".</p>

<p>Is there anyone who knows how such algorithm is called?
I searched in text parsing, text mining and so on but I did not find anything appropriate.</p>
",graph_theory
"<p>Let $W$ be the non-negative, symmetric adjacency/affinity matrix for some connected graph. If $W_{ij}$ is large, then vertex $i$ and vertex $j$ have a heavily weighted edge between them. If $W_{ij} = 0$, then no edge connects vertex $i$ to vertex $j$. </p>

<p>Now $L = \mathrm{diag}(W\mathbf{1})-W$ is the (unnormalized) graph Laplacian. Let $v$ be the Fiedler vector of $L$, that is, a unit eigenvector corresponding to the second smallest eigenvalue of $L$. As $W_{ij}$ increases, all else equal, $|v_i - v_j|$ tends to decrease---at least this is the idea behind spectral clustering. What is an upper bound on $|v_i - v_j|$, given quantities that don't require computing $v$, like $W_{ij}$ and $\|W\|$? </p>

<p>Any suggestions or thoughts would be greatly appreciated.</p>
",graph_theory
"<p>I am having difficulties with problem 3.27 of Algorithms by Dasgupta, Papadimitriou and Vaziran. It reads:</p>

<blockquote>
  <p>Two paths in a graph are called edge-disjoint if they have no edges in
  common. Show that in any undirected graph, it is possible to pair up
  the vertices of odd degree and find paths between each such pair so
  that all these paths are edge-disjoint.</p>
</blockquote>

<p>I am new to graphs and have no idea how to start.</p>

<p>Could anyone help?</p>

<p>Thank you, any help will be appreciated</p>
",graph_theory
"<p>I know that if $A$ is a 0-1 adjacency matrix then $[A^k]_{ij}$ is the number of walks of length $k$ from $i$ to $j$. Does this generalize nicely? The reason for this question is to interpret a result in <a href=""http://press.princeton.edu/titles/8767.html"" rel=""nofollow"">Matthew O. Jackson's Social and Economic Networks</a> where he considers a model in which each person $i$ assigns assign weights $g_{ij}$ to how much he cares about the action of person $j$ (actions are numbers in $[0,\infty))$. Each player chooses an action taking into account the actions of all the other people in the network with respect to the weights that they place on those actions. I'll leave the details, but he comes up with this</p>

<p><img src=""http://i.stack.imgur.com/NR0V6.png"" alt=""enter image description here""></p>

<p>I am trying to understand what (9.9) is saying. </p>
",graph_theory
"<p>Given a set of points in 3D space, and a set of links between them which form a connected graph - is there a general strategy for extracting all simple loops from such an object?</p>

<p>I refer to simple loops as being those cycles in the graph which have no other edges on, or vertices intersecting with, the surface enclosed by the loop.</p>
",graph_theory
"<p>In a collection {$S_1, S_2, ... S_n$} of $n\geq 2$ nonempty sets, no two sets have the same number of elements. Show that this collection has a system of distinct representatives</p>

<p>(a) by using Hall's theorem:
A collection {$S_1, S_2, ... S_n$} of $n$ nonempty finite sets has a system of distinct representatives if and only if, for each integer $k$ with $1\leq k\leq n$, the union of any $k$ of these sets contains at least $k$ elements.</p>

<p>(b) without using Hall's theorem.</p>

<p>It seems that I should begin by letting $|S_1|&lt;|S_2|&lt;\cdots&lt;|S_n|$ and showing that, for any union of these sets, I will always get at least $k$ elements. It seems clear to me that the result is true, but I don't know how to prove this exactly.</p>
",graph_theory
"<p>Let $G$ be a simple, connected graph with $n\ge k+1$ vertices and $m\ge (k-1)(n-k-1)+{k+1 \choose 2}$ edges.<br>
Show there is a subgraph of $G$ with minimum degree at least $k$.  </p>

<p>(Not necessarily looking for a full solution yet, just some hints on how to go about proving this.)</p>
",graph_theory
"<p>It is known that one of the eigenvalues in the $k$-regular graph is $k$.</p>

<p>I have to prove that for a connected graph with eigenvalue $\Delta$, in which $\Delta$ is the maximum degree in G, the graph is regular.</p>

<p>For a generic graph, all it's eigenvalues are less or equal than $\Delta$, mi question is thus the following, is there a graph which has eigenvalue $\Delta$ and it's not regular? If not, then the statement is easily to prove.</p>
",graph_theory
"<p>I've been given the following statement, I need to decide if it's true/false and if true, prove it:</p>

<blockquote>
  <p>Every simple graph with no loops and more than one vertex has at least 2 vertices of the same degree.</p>
</blockquote>

<p>Could you guys give me some general advise on how to start these kind of proofs and some hints?</p>

<p>I just started learning graph theory, so these kind of proofs seem pretty hard.</p>
",graph_theory
"<p>In trying to deduce the lower bound of the ramsey number R(4,4) I am following my book's hint and considering the graph with vertex set $\mathbb{Z}_{17}$ in which $\{i,j\}$ is colored red if and only if $i-j\equiv\pm2^i,i=0,1,2,3$; the set of non-zero quadratic (mod 17) and blue otherwise. This graph shows that $R(4,4)\ge 18$. That's all fine but how am I expected to convince myself of this without drawing a 17-vertex graph.</p>

<p>Is there some way to mathematically justify that such a graph will not contain a monochromatic $K_4$ without drawing this graph?</p>

<p>Thanks.</p>
",graph_theory
"<p>I have a hard time to find a way to construct a <code>k</code>-regular graph out of <code>n</code> vertices. There seems to be a lot of theoretical material on regular graphs on the internet but I can't seem to extract construction rules for regular graphs.</p>

<p>My preconditions are</p>

<pre><code>k&lt;n and (n%2 == 0 or k%2 == 0)
</code></pre>

<p>Is an adjacency matrix the way to go here? If so, how would I use it?</p>

<p>Is this even a mathematical problem?</p>
",graph_theory
"<p>Could anyone describe for me why the maximum number of edge in simple diagraph with no cycle is $\text{combination}(2,n)$?</p>

<p>My thought:</p>

<p>If you have $N$ nodes, there are $N - 1$ directed edges than can lead from it (going to every other node). Therefore, the maximum number of edges is $N \times (N - 1)$.</p>
",graph_theory
"<blockquote>
  <p>Assume that $10$ people are sitting around a table. Determine the number of ways to choose a committee, where the committee is made up of two people who are NOT sitting next to each other.</p>
</blockquote>

<p>Take ${10 \choose 2}$ and take away the pairs with partners, which is still the $10$ which gives me the same result. ${10 \choose 2}-10=35$.</p>

<hr>

<blockquote>
  <p>Assume that $10$ people are sitting around a table. Determine the number of ways to choose a committee, where the committee is made up of <strong>three</strong> people of which NONE are sitting next to each other.</p>
</blockquote>

<p>${10\choose 3}=130$ take away the pairs that are sitting beside each other: (still 10??)</p>

<p>$120$</p>
",graph_theory
"<p><strong>Question:</strong></p>

<blockquote>
  <p>Decide if the following expression is true or false. Prove or give a counterexample.</p>
  
  <p>If $G$ is a simple, no loops graph, with $n$ vertices and $e$ edges, whose vertices have degree $k$ or $k+1$ then G has $n_k=(k+1)n-2e+1$ vertices of degree $k$.</p>
</blockquote>

<p><strong>Attempt:</strong></p>

<p>I think this is false, I tried to construct a counterexample but I think I haven't gotten it right.</p>

<p>Consider the graph $G$ of $1$ vertex and no edges. Then the $deg(v)=0$ and $n_k=k+2$.</p>

<p>I then separated in two cases, $deg(v)=k$ and $deg(v)=k+1$.</p>

<p>If $k=0$ then $n_0=2$ which is false, as there's only one vertex of degree $0$.</p>

<p>If $k+1=0$ then $n_{-1}=1$ which doesn't make much sense as the degree must be nonnegative, so where did I go wrong?</p>
",graph_theory
"<p>I would like to learn more about Graph Theory.  Just a ""Ted Talk"" caliber understanding.   I've played with Bridges of K. and 4-color map.  I get that stuff like Facebook or Netflix movie reviews may use some form of graph theory to represent people as vertices connected by edges in a graph.  I want to revisit some basic examples like traveling salesman, etc.  Can anyone point me in the right direction?  Links!</p>
",graph_theory
"<p>Let $G$ be a simple 2-connected graph with at least 4 vertices.<br>
If $V(G)$ the set of vertices, let $U,W$ be subsets of $V$, with no common elements, with $|U|=|W|=2$.<br>
Show that there are 2 distinct (that pass through different vertices) paths that connect $U$ and $W$.</p>
",graph_theory
"<p>I am trying to prove that if a finite graph has no isolated or pendant vertices then it contains at least one simple circuit.</p>

<p>Let the graph with no isolated or pendant vertices be $(V,E)$. A path in the graph cannot exceed $|V|-1$ since a path of length $m$ passes through $m+1$ vertices. I do not know where to go from here.</p>
",graph_theory
"<p>I'm studying for a graph theory exam. And while looking at some exams of previous years <strong>which were handed out by the professor</strong>, I found the following question.</p>

<p><img src=""http://i.stack.imgur.com/y5kWh.png"" alt=""Consider the bipartite graph G below: (unweighted bipartite graph). (a) Construct a maximal matching of G of size exactly 3.""></p>

<p>As I understand it, a maximal matching is a matching with the highest possible weight, but this graph doesn't display weights.</p>

<p>The next part of the question, not shown in the image, asks for a maximum matching, given the initial matching from (a), which I know how to construct using augmenting paths.</p>
",graph_theory
"<p>I have a question:</p>

<p>I have a set of points that represent a graph (x0,x1..x9) Lets say 10 points. They are at a linear 45 degree angle up (Gradient 1). I am also told that (x0+x1+x2..x9 = 1).</p>

<p>How can I solve for each xi? Can I get an idea of how to start?</p>
",graph_theory
"<p>These days I am reading the research paper <em><a href=""http://www.sciencedirect.com/science/article/pii/S0021869308002901"" rel=""nofollow"">Graphs associated to co-maximal ideals
of commutative rings</a></em> by Hsin-Ju Wang.</p>

<p>In this paper, $ R $ denotes a commutative ring with the identity element. $ \Gamma(R) $ is a graph with vertices as elements of $ R $, where two distinct vertices $ a $ and $ b $ are adjacent if and only if $ Ra + Rb = R $. $ \Gamma_{2}(R)$ denotes the subgraph of $ \Gamma(R) $ which consists of non-unit elements. In addition, $ J(R) $ is the Jacobson radical of $ R $ .</p>

<p>I am trying to understand the proof of Theorem 3.5. Theorem 3.5. states</p>

<blockquote>
  <p>The following are equivalent for $ \Gamma_{2}(R)\smallsetminus J(R) $.</p>
  
  <p>(i). $ \Gamma_{2}(R)\smallsetminus J(R) $ is a forest.</p>
  
  <p>(ii). $ \Gamma_{2}(R)\smallsetminus J(R) $ is either totally disconnected or a star graph.</p>
  
  <p>(iii). $ R $ is either a local ring which is not a field or $ R $ is isomorphic to $ \mathbb{Z}_{2}\times F $, where $ F $ is a field.</p>
</blockquote>

<p><img src=""http://i.stack.imgur.com/coWEE.png"" alt=""enter image description here""></p>

<p>Unfortunately, I can't understand the cases $ (i)\Rightarrow (ii) $ and $ (iii)\Rightarrow (i) $.</p>

<p>Can anyone please explain me how to show if $ \Gamma_{2}(R)\smallsetminus J(R) $ is a forest then it is either totally disconnected or a star graph and if $ R $ is either a local ring which is not a field or $ R $ is isomorphic to $ \mathbb{Z}_{2}\times F $, where $ F $ is a field then $ \Gamma_{2}(R)\smallsetminus J(R) $ is a forest ?</p>

<p>Any hints/ideas are much appreciated.</p>

<p>Thanks in advance for any replies.</p>
",graph_theory
"<p>i think if the graph G has an odd cycle, it's not two-colorable, otherwise it can be two colorable. </p>

<p>i read in one notes that the following is True: we couldent two-colorable any graph G that has cycle.  </p>

<p>anyone could clarify me ?</p>
",graph_theory
"<p>I found a statement in a book that I don't understand, it suggests that the number of DAGs on N nodes can be bounded from below by $$\prod \limits^N_{n=1} 2^{n-1}  = 2^{N(N-1)/2}$$
My way of thinking is, if we have a DAG it should have maximum of N-1 edges. So $2^{N-1}$ should be the number of different subsets of N-1 edges (so it already includes all DAGs with N-2, N-3 edges). </p>

<p>However formula suggest that we still have to multiply this number by number of DAGs that has less edges than N-1, which I can't understand, since we already have all the N-2, N-3 subsets included in $2^{N-1}$. </p>
",graph_theory
"<p>Consider a planar graph, where each node is associated with a weight. I would like to partition the graph such that the sum of the node weights in each group satisfy a minimum requirement. However, I would also like as much 'resolution' as possible - that is, I want to maximize the number of groups (minimize the number of nodes per group). Internal edges should be rewarded, to avoid long 'daisy chains' of nodes.</p>

<p>Does anyone have any suggestions as to how I can compute an (approximately) optimal solution? My instinct is to approach this using Monte Carlo, but I'm not sure how I would implement it here.</p>

<p>Thanks in advance for any insights or comments you might have!</p>
",graph_theory
"<p>Let $G$ be a graph such that $\delta(G) \geq k$.</p>

<ol>
<li><p>Prove that $G$ has a path of length at least $k$.</p>

<p>Solution: We know that 
$\delta(G) = \min\lbrace \deg(v) \mid v \in V(G) \rbrace$ </p>

<p>If $\delta(G) = k$ then there exists some $v \in V(G)$ such that $\deg(v) = k$.  This means all other vertices $u \in V(G)$ have $\deg(u) \geq k$.</p>

<p>Now I know this must be part of the proof. How would I prove that there exists a path of at least $k$?</p></li>
<li><p>If $k \geq 2$, prove that $G$ has a cycle of length at least $k+1$.</p></li>
</ol>
",graph_theory
"<p>Prove that if $T$ is a tree on at least $k+1$ vertices and max degree at most $d$, then there exists an edge $e$ such that the removal of $e$ causes $T$ to split into two trees where at least one of them has between $k$ and $dk$ vertices.</p>

<p>Obviously I know that if $T$ has at most $dk+1$ vertices then removing an edge leading to a leaf gives what we need. But what if there are more vertices? Where does the max degree come into play?</p>

<p>Thanks.</p>
",graph_theory
"<blockquote>
  <p>Given a graph $G = (V,E)$, $r-\text{regular}$, with no triangles/squares (no cycles of length $3$ or $4$,) prove that $|V(G)| \geq r^2 +1 $</p>
</blockquote>

<p>I'll be more than happy to get a direction, thanks!</p>
",graph_theory
"<p>The concrete example is:</p>

<p>I am given <code>n</code> currencies and pairwise exchange rates, and I have to change say dollars for euros. And I don't have to change money directly, for example, I could change dollars to British pounds first and then to euros and make more money than I would have by direct exchange. So my first idea was to draw complete graph with exchange rates as weights of edges and use Dijkstra's algorithm with a small change, I multiply weight, not sum. Actually it seems to be logical: if I go through a path and each time make appropriate multiplications I get number of units (in currency that corresponds to the node I have come to) I would have after these exchanges. And on each iteration of Dijkstra's algorithm if I see that the way I exchange the money at this step is better than previous one for this node (if visited) then I change the value. So when I finish a tree I can easily find a shortest path between to nodes, i.e. optimal way to exchange money from one currency to all another. Is there something what contradicts this idea?</p>

<p>Thanks in advance,
Cheers</p>
",graph_theory
"<p>If there exists a set of <code>n</code> points in a 2D coordinate system and an <code>n</code>-dimensional vector <code>V</code> that describes the shortest path containing all the <code>n</code> points and a second set of <code>n+1</code> points is created containing all the <code>n</code> points from the first set and another, arbitrary, point, can vector <code>V</code> be used to reduce the number of steps required to find an <code>(n+1)</code>-dimensional vector <code>V'</code> describing the shortest path in the second set? More precisely, must the <code>V'</code> be evaluated independently of <code>V</code>?</p>
",graph_theory
"<p>What are some good books on Ramsey theory? I have Van Lints book on Combinatorics: is this enough preparation to start reading about Ramsey theory? I want a book that includes important results and has good proofs.</p>
",graph_theory
"<p>Are laplacians for directed graphs used in any algorithms ? For example laplacians for the undirected graphs are used in algorithms such as spectral clustering.</p>
",graph_theory
"<p><img src=""http://i.stack.imgur.com/MtWvb.png"" alt=""enter image description here""></p>

<p>I have tried to understand the question but I got really confused.</p>

<p>So starting from node 3, the distance to other nodes are</p>

<p>3 to 1 = 3</p>

<p>3 to 2 = 1</p>

<p>3 to 4 = 4</p>

<p>3 to 5 = 2</p>

<p>3 to 6 = 3</p>

<p>3 to 7 = 2</p>

<p>and the question asks what is the third node added to the set S.</p>

<p>What I think it should be is 2->5->7->1->6->4 therefore the answer should be (B.7)</p>

<p>but the actual answer is (A.5)</p>

<p>Where did I made a mistake with the question? </p>
",graph_theory
"<p>The solution to the number of spanning trees of the graph below is given by $3 \times 2 \times 3 = 18$. I'm not sure how to get this. Please assist. Thanks! </p>

<p><img src=""http://i.stack.imgur.com/3OyuJ.jpg"" alt=""enter image description here""></p>

<p>Notes:
Just in case anyone was wondering, I drew the graph using the tool on <a href=""http://illuminations.nctm.org/Activity.aspx?id=3550"" rel=""nofollow"">http://illuminations.nctm.org/Activity.aspx?id=3550</a> and got the image by using the snipping tool on Windows.</p>
",graph_theory
"<p>Given a graph, G = (V,E), and conditions on members of V (that they must be connected to some m vertices, and disconnected to some n vertices), how can I efficiently find candidates for removal, based on m and n?
I keep coming up with the fact that once I've removed some v in V, I must then start again and search through the set V again to find objects that meet this criteria (as removing some v from V is going to have an affect on other members of V). 
Am I missing something obvious - or should I be looking into achieving what I'm trying in some other way?</p>
",graph_theory
"<p>I need to learn about Razborov's ""flag algebras"" (see <a href=""http://bit.ly/1u1a1NB"" rel=""nofollow"">http://bit.ly/1u1a1NB</a>) to solve a problem about graphs. Flag algebras are a very general new algebraic tool for studying combinatorial structures. The theory of flag algebras uses some elementary model theory in its definition which is something I have not encountered before (in fact I have not taken any classes in formal logic beyond the first-year undergrad stuff). I've read through the first few sections of Marker's ""Model Theory: An Introduction"" (<a href=""http://amzn.to/1zGuyKq"" rel=""nofollow"">http://amzn.to/1zGuyKq</a>) and I have easily understood the definitions and general approach; in particular, I think I only really need to understand the general concepts of <em>languages</em> $\mathcal{L}$, $\mathcal{L}$-<em>structures</em>, embeddings of $\mathcal{L}$-structures and some general facts about $\mathcal{L}$-<em>theories</em> and <em>models</em>, all of which seems fine.</p>

<p>Reading the beginning of Razborov's paper [p4], though, I found some terms that I have not seen defined which I'd like to clear up. In particular, he writes</p>

<p><em>""Let $T$ be a universal first-order theory with equality in a language $\mathcal{L}$ containing only predicate symbols; we assume that $T$ has infinite models. Our assumptions imply that every set of elements of a model of $T$ induces a model of $T$, and that $T$ has at least one finite model of every given size.""</em></p>

<p>I have two essential questions:</p>

<ul>
<li>what does ""universal"" mean in this context?</li>
<li>why do the assumptions imply that any subset of a model of $T$ induces a model of $T$?</li>
</ul>
",graph_theory
"<p>Is the statement below correct?</p>

<p>A graph which doesn't have a complete graph of order $4$ or more can be colored with $3$ colors, so that no two adjacent vertices have same color.</p>

<p>I don't know it is correct or not; if it is not correct, please someone give me a counterexample to that.</p>
",graph_theory
"<p>I am interested in counting the number of hyperedges in the complete, $t$-uniform hypergraph on $n$ vertices which intersect a specified set of $k$ vertices.  This is trivial, the answer is:</p>

<p>$$\sum_{i=1}^t {k \choose i}{n-k \choose t-i}.$$</p>

<p>My questions is whether there is a nice simplification of this expression; I'd like to get rid of the sum if possible.  Anyone know?</p>

<p>Thanks a lot for the help!</p>
",graph_theory
"<p>The solution to the number of spanning trees of the graph below is given by $6$ and $4 \times 4 - 1$ for Graph A and B respectively. I'm not sure how to get this. Please assist. I did ask a similar question a while ago but I'm still not able to figure out for these 2 figures. Thanks! </p>

<p>Graph A :</p>

<p><img src=""http://i.stack.imgur.com/7AXZS.jpg"" alt=""Graph A""></p>

<p>Graph B :</p>

<p><img src=""http://i.stack.imgur.com/zRThk.jpg"" alt=""Graph B""></p>

<p>What I know:</p>

<p>1) Number of spanning trees of a cycle with n vertices is, $\tau(C_n) = n$
2) I know how to solve the above using the contraction deletion theorem but I'm interested in other methods, thanks!</p>
",graph_theory
"<p>If $S$ is a strongly connected component of a digraph, then $S$ is the union of cycles of it's vertices, I conjecture. Is this true? I can nowhere find such a statement.</p>
",graph_theory
"<p>Let $G$ be a graph of order $n$. If deg $u$ $+$ deg $v$ $+$ deg $w$ $\geq n-1$ for every three pairwise nonadjacent vertices $u,v$ and $w$ of $G$, must $G$ be connected?</p>

<p>I know that if $H$ is a graph of order $n$ and deg $u$ $+$ deg $v$ $\geq n-1$ for every two nonadjacent vertices $u$ and $v$ of $H$, then $H$ is connected. Does this imply even further that $G$ is connected? Any help or hints would be greatly appreciated.</p>
",graph_theory
"<p>The question is as follows: Prove that in a graph $G$ a set of edges $X$ which is not contained in any spanning tree is a cycle (or possibly an edge disjoint union of cycles).</p>

<p>My thoughts: Proceed by contradiction. </p>

<p>Any help will be appreciated.</p>
",graph_theory
"<p>I am trying to brush up my graph theory skills. I have not done any in over 4 years and i am rusty...If someone could help me out with this simple proof i would appreciate it.</p>

<p>Prove that for any graph $G$ of order at least 2, the degree sequence has at least one pair of repeated entries.</p>

<p>So the degree sequence if a list of the degrees of each vertex (usually written in descending order).</p>

<p>I know that the sum of the degrees of the vertices of a graph is equal to $2|E|$ and that the number of vertices of odd degree is even.</p>

<p>If someone could help me out and point me in the right direction I would appreciate it.</p>
",graph_theory
"<p>I have seen lots of answers proving this theorem via induction. However, I'd like to know how to prove that every digraph such as all vertices have in degree equal to its out degree is Eulerian, using the concept of maximum trail.</p>

<p>Does anyone have a clue?</p>
",graph_theory
"<p>G = (V, E) - hamiltonian graph. </p>

<p>$A$ - is a some(any) set of vertex in $G$. $N(A)$ - number of vertexes in $G$ connected with at least one vertex in $A$.</p>

<p>I'm trying to prove that $|A| \leq |N(A)|$.</p>

<p>Generally, it seems to be obvious. If we have a hamiltonian cycle in G than to visit all vertexes in A we need at least |A| vertexes(different) connected by edges with nodes in A.</p>

<p>However, teacher says to build rigorous proof. But I can't see more rigorous way to prove it . 
Could you help me with it?</p>
",graph_theory
"<p>Let $P_{20}$ be a path of length 20 like so: $x_0$-$x_1$-$~\cdots~$-$x_{20}$ and $G$ a cycle of order 3.</p>

<p>Allegedly there are $3 \cdot 2^{20}$ mappings $P_{20}\rightarrow G$, which I don't quite see.</p>

<hr>

<p>We defined a mapping $\Psi$ of graphs $(V,E)\rightarrow (V',E')$ as a pair of mappings $\Psi_1:V\rightarrow V'$ and $\Psi_2:E\rightarrow E'$, such that $\forall e\in E, e=[x_1,x_2],\; \Psi_2(e)=[\Psi_1(x_1),\Psi_1(x_2)]$ </p>

<hr>
",graph_theory
"<p>The question is:</p>

<blockquote>
  <p>Does there exist a simple connected undirected graph $G$ with $7$ vertices with minimal degree $3$ but does not contain any hamiltonian cycle?</p>
</blockquote>

<p>I've been trying to find an example for quite long time, but I still cannot think of one. The restriction ""minimal degree 3"" is giving me an headache, since I can always find a graph with no-hamiltonian cycle with ""almost minimal degree 3"", but whenever one edge is added so to satisfy the condition, it becomes hamiltonian... </p>

<p>So the question comes. Is there even a single graph with above properties? Maybe I am being a bit un imaginative, but I've found questions about finding non-hamiltonian graphs with certain properties quite hard so far. </p>

<p>It would be great if you could explain your strategy too with an example, since I seem to lack what is needed in this kind of exercise: I can't get the ""feel"" of it.</p>

<p>Thanks in advance,</p>
",graph_theory
"<p>Why do people use the letter ""K"", rather than ""C"", to represent a complete graph? Does it come from German ""komplett""?</p>
",graph_theory
"<p>It is well known that the Petersen Graph is not Hamiltonian. I can show it by  case distinction, which is not too long - but it is not very elegant either.</p>

<p>Is there a simple (short) argument that the Petersen Graph does not contain a Hamiltonian cycle? </p>
",graph_theory
"<p>Could I get some help for part b(i) of below please? Thanks. (Part (a) follows from Hall's Marriage Thm, and b(ii) follows quickly from b(i) I think).</p>

<p>Let $G$ be a bipartite graph with parts $X$ and $Y$ , and with maximum degree $r$.</p>

<p>(a) Let $X_0$ be the set of vertices $x$ in $X$ with degree $d(x) = r$. Show that there is a matching covering $X_0$ (that is, such that each vertex in $X_0$ is incident with an edge in the matching).</p>

<p>(b) Let $X_1 \subseteq X$ and $Y_1 \subseteq Y$ , and suppose that there is a matching $R$ covering $X_1$ and a matching $B$ covering $Y_1$.</p>

<ul>
<li>(i) Consider the subgraph containing just the edges in exactly one of $R$, $B$. Suppose that some component of this subgraph is a path with first edge in $R$ and last edge in $B$. Let $Z$ be the set of vertices in $X_1 \cup Y_1$ on the path. Show that either the edges in $R$ on the path cover $Z$, or the edges in $B$ on the path cover $Z$.</li>
<li>(ii) Show that there is a matching in $G$ covering $X_1 \cup Y_1$.</li>
</ul>
",graph_theory
"<p>Given $n$ distinct nodes $1,2...n$, I wish to find the number of connected graphs with these $n$ nodes. I have seen the previous question : <a href=""http://math.stackexchange.com/questions/154941/how-to-calculate-the-number-of-possible-connected-simple-graphs-with-n-labelle"">How to calculate the number of possible connected simple graphs with $n$ labelled vertices</a>. But in my case multi-edges are allowed. </p>

<p>By multi-edges I mean, if I have $n$ nodes a multi edge is a subset of vertices connecting all those vertices. For example in case of $3$ nodes $\{1,2,3\}$ is a multi-edge connecting all the three edges. For example following are the few ( out of $96$ different ways ) ways of connecting three nodes:</p>

<ol>
<li>Select edge $\{1,2,3\}$.</li>
<li>Select edges $\{1,2,3\}$ , $\{1,3\}$ , $\{2,3\}$ and $\{1,2\}$.</li>
<li>Select edges $\{1,2,3\}$ and $\{1,3\}$.</li>
<li>Select edges $\{1,3\}$ and $\{2,3\}$ and so on.</li>
</ol>

<p>I am just looking for hints not solutions. As this is part of question from Project Euler question: <a href=""https://projecteuler.net/problem=553"" rel=""nofollow"">Power set of power sets</a>.</p>

<p>A friend of mine gave the above method of multi-edges as a hint to me and told me I had to modify the recurrence in the question: <a href=""http://math.stackexchange.com/questions/154941/how-to-calculate-the-number-of-possible-connected-simple-graphs-with-n-labelle"">How to calculate the number of possible connected simple graphs with $n$ labelled vertices</a>. But I am unable to figure it out and just need a new direction for thinking.</p>
",graph_theory
"<p>I'm struggling with drawing a graph from following exercise:
Set of vertices in undirected graph Gn is built from words of length n from alphabet {a,b,c,d}. Two words are adjacent when they have Hamming distance 1. Whats degree of Gn. How many vertices and edges does Gn have?</p>

<p>Now I know that degree is 3n, number of vertices: 4^n and edges: (3/2) * 4^n * n.
I'm unsure how to correctly picture edges for example in G2.</p>
",graph_theory
"<p>I have a problem with the following assignment.</p>

<p>Describe all graphs which do not contain a path whose length 3.
Could you help me solve it?</p>
",graph_theory
"<p>Prove the theorem 4.19: A non-decreasing sequence $\pi:s_1,s_2,\ldots,s_n$ of nonnegative integers is a score sequence of a strong tournament if and only if </p>

<p>$$\sum_{i=1}^ks_i &gt; \binom k 2 $$</p>

<p>for $1≤k≤n-1$ </p>

<p>and </p>

<p>$$\sum_{i=1}^ns_i = \binom n 2 $$</p>

<p>Furthermore, every tournament whose score sequence satisfies these conditions is strong.</p>

<p>I know how to show that $\pi$ is the score sequence of $T$ if and only if it satisfy these 2 conditions, but I can't see how these 2 conditions make the tournament strong</p>
",graph_theory
"<p>Is the following statement about Euclidean MSTs true, and if so could someone help me with a proof? Between any two nodes, the EMST minimizes the maximum edge cost of any edge required to traverse from one node to the other.</p>

<p>Edited Statement: Show that in a Euclidean MST-- found by Kruskal's algorithm, given any path between two points, there cannot have been any other path between those two points that used an edge of a smaller cost than any edge used in the original path.</p>
",graph_theory
"<p>For a tournament $T$ of order $n$, let 
$Δ=max \{od v:v∈V(T)\}$
And 
$δ=min\{od v:v∈V(T)\}$
Prove that if $Δ-δ&lt; \frac n2$, then $T$ is strong</p>

<p>Here is my final attemp. Prove this by contrapositive.</p>

<p>Assume that $T$ is not strong, by the result of some previous exercise, $T$ is not regular. So there exists a vertex $v$ such that $id(v) &lt;od(v)$. Note that $T$ is a tournament which is an oriented completed graph so</p>

<p>$$deg(v)=id(v)+od(v)=n-1$$</p>

<p>Since $id(v)&lt;od(v)$, $ \delta \leq od(v)&lt; \frac {n-1}2$</p>

<p>Let $\pi: s_1,s_2,...,s_n$ be the score sequence of $T$, then </p>

<p>$$\Delta= s_n= \sum_{i=1}^n S_i -\sum_{n=1}^{n-1}S_i \geq \left( \begin{array}{ccc}
n  \\
2  \\
 \end{array} \right) -\left( \begin{array}{ccc}
n-1  \\
2  \\
 \end{array} \right)=n-1$$</p>

<p>So</p>

<p>$$\Delta -\delta &gt;(n-1) -\frac {n-1}2= \frac {n-1}2 \geq \frac n2$$</p>

<p>By contrapositive, if $Δ-δ&lt; \frac n2$, then $T$ is strong</p>

<p>Is my reasoning acceptable?</p>
",graph_theory
"<p>The complement of a disconnected graph is necessarily connected, but the converse is not true. For instance, $C_5$ is connected and isomorphic to its complement. The following picture shows a graph and its complement which are both connected (and non-isomorphic).</p>

<p><img src=""http://i.stack.imgur.com/Nbbhv.jpg"" alt=""Example graph""></p>

<p>Is there a name for connected graphs whose complements are also connected? In the same vein as coplanar, I tried searching for ""co-connected"" graphs but didn't find anything. Are there any useful necessary or sufficient conditions for a connected graph to have this property? </p>

<p>Thanks. </p>
",graph_theory
"<p>In $O(|V|+|E|)$, we can detect whether a Directed Graph has a cycle or not. ---> True</p>

<p>In depth-first seach on DAG, there is no Back Edge. ---> True</p>

<p>With known Number of Edges, in $O(|V|)$ and not $O(|V|+|E|)$, we can detect whether a simple undirected Graph has a cycle or not. ---> True</p>

<p>Am I right about the above three questions about Graph Algorithm? I think all of them is True?</p>
",graph_theory
"<p>I have been reading a number of ""network science"" papers where the authors perform transformations on networks that seem to preserve the topology of those networks.  By ""topology"", I mean a collection of heuristics commonly used to probe the network: modularity, clustering coefficient, and mean path length.  Is there a name for these kinds of transformations and/or some review somewhere of their properties?  I don't have a good mental model for said properties and it would be helpful to have a list of examples or a formal treatment of them.</p>
",graph_theory
"<p>I have a graph with two sets, vertices and edges, $G=(V,E)$. In my case every vertex and every edge have some attributes like $type$.</p>

<p>What is the mathematical correct way to get the value of a vertex' property? Maybe $property(v)$ where $property$ is the property name and $v$ the single vertex?</p>

<p>What is the correct way to get only the vertices (a set of vertices) that have a specific value? For example if I want a set of vertices that only have $1$ as the value of $type$? </p>
",graph_theory
"<p>Consider a tournament with $799$ contestants. Each contestant plays against all other contestants exactly one; there are no draws. Prove that there exist two disjoint groups $A,B$, of $7$ contestants each, such that everyone in $A$ beats everyone in $B$.</p>

<p>Suppose we choose $B$ by choosing any $7$ contestants randomly. If we can show that the expected number of contestants we can put into $A$ is at least $7$, we will be done. But is that true?</p>
",graph_theory
"<p>I will be doing a course in Information Theory soon and to get some early learning in I have been attempting a question with a joint probability mass function represented by the following table:</p>

<p><img src=""http://i.stack.imgur.com/KG6I6.jpg"" alt=""joint probability mass function represented by a table""></p>

<p>In the question I have been asked to find the value of D(X || Y).</p>

<p>I have been attempting this question for a few hours now and cannot seem to get the right answer and any sources I have found have not featured an example like this.</p>

<p>As I am not a person with a background in maths any help to understand this question would be greatly appreciated.</p>

<p>Thank you very much for your time.</p>
",graph_theory
"<blockquote>
  <p>Given a simple and connected graph $G = (V,E)$, and an edge $e \in E$. Prove:</p>
  
  <p>$e$ is a cut edge <strong><em>if and only if</em></strong>  $e$ is in every spanning tree of $G$.</p>
</blockquote>

<p>I have been thinking about this question for a long time and have no</p>
",graph_theory
"<p>This is an extension over this question:
<a href=""http://math.stackexchange.com/questions/126216/inter-causal-reasoning-how-to-solve-probability-with-two-conditions"">Inter-causal reasoning: How to solve probability with two conditions?</a></p>

<p>I'm a beginner in probability, and trying to deeply understand what is happening underneath.</p>

<p>To sum up what the question is about:</p>

<p>We've got a graph of (binary) events:</p>

<p>$$
A \rightarrow C \leftarrow B
$$</p>

<p>We're given probabilities of:
$$
P(A), P(\bar A), P(B), P(\bar B)
\\
P(C|A, B)\\
P(C|A, \bar B)\\
P(C|\bar A, B)\\
P(C|\bar A, \bar B)
$$
Where $P(A)$ is a probability of occurrence of event $A$ and $P(\bar A)$ is a probability of event $A$ not occurring.</p>

<hr>

<p>We have to find probability of: $P(B|C)$ and $P(B|C,A)$.</p>

<p>Before going further I'd like to say, that I'd like to find out a bit more things and, of course, be aware of theorems used.</p>

<p>I'll begin with really simple ones (numbering done to ease answering the questions):</p>

<ol>
<li><p>Does $P(B|C,A)$ means: <em>Probability that event $B$ will occur given event $A$ and event $C$ occurred</em> ?</p></li>
<li><p>Are the events $A$ and $B$ independent? I see a <em>V-structure</em> in here, so we've got no <em>active trail</em> in here, right? So they're independent.</p></li>
<li><p>We can write (<em>Bayes theorem</em>) that $P(B|C) = \frac{P(C|B)P(B)}{P(C)}$. </p>

<p>3.1. To get $P(C|B)$ can we do conditioning and reduction on $B$ ?</p>

<p>3.1.1. If yes, then does it equals to (why, what is the rule; my intuition says ""B""): 
$$
Option~A\\
P(C|B) = P(C|B,A)+P(C|B,\bar A)\\
\\
Option~B\\
P(C|B) = P(C|B,A)P(A)+P(C|B,\bar A)P(\bar A)
$$</p>

<p>3.1.2. Does the (in)dependence of $A$ and $B$ affects somehow the way we can count $P(C|B)$ ?</p>

<p>3.2. How can we count $P(C)$? Is it:
$$
P(C) = ( P(C|A,B)+ P(C|A, \bar B) ) * ( P(C| \bar A,B) + P(C|\bar A, \bar B) )
$$</p></li>
<li><p>Counting $P(B|C,A)$:</p>

<p>4.1. <strong>I have counted it</strong>, but I cannot recall how, and I don't have my notes in here. It only means, that I didn't understood it, as I cannot do it again ;) I thought I can use a <em>Bayes theorem</em> in here, but will this turn out to be $\frac{P(C,A|B)P(C,A)}{P(B)}$ ? It doesn't look well.. And, can I use somehow the fact of (in)dependence of $A$ and $B$ in here?</p>

<p>4.2. I know there's an answer in the connected question, but it's not about getting the answer. I want to understand how to figure out this answer.</p></li>
</ol>
",graph_theory
"<p>I am having a hard time understanding the answer to the following problem from Grimaldi:</p>

<p>""At Professor Alfred's science camp, 17 students have lunch together each day at a circular table. They are trying to get to know one another better, so they make an effort to sit next to two different colleagues each afternoon. For how many afternoons can they do this? How can they arrange themselves on these occasions?""</p>

<p>They have solved it in the context of Hamilton cycles, which I have not understood at all. I have a feeling it can be solved by some other method of counting also. 
Any help will be nice..</p>
",graph_theory
"<p>How can I prove mathematically that the spectral radius of a binary tree approaches e as the number of nodes tends to infinity? 
I mean it is true that the increase in nodes number is exponential but so far I have computed the spectral radius by finding the largest nontrivial eigenvalue of det [A(G)- lambda*I]=0. How can I prove that if N tends to infinity, the spectral radius is exp(1)??</p>
",graph_theory
"<p>I found a proof of the fact that if a graph G is bipartite(1), then it cannot have any odd cycles(2). I have a question about $(2) \Rightarrow (1)$. Why is it sufficient to assume that  G is connected?</p>
",graph_theory
"<p>Is there a graph with $n$ vertices and $\lfloor n^2/4\rfloor$ edges that isn't bipartite and contains no triangles ($K_3$)?</p>

<p>Rather, what I am asking is whether Mantel's Theorem implies that every graph on $n$ vertices with $\lfloor n^2/4\rfloor$ edges and contains no triangles must also be bipartite. </p>

<p>EDIT: I apologize. I forgot to add that the graph must also not contain any triangles. Sorry, I realize that it was a trivial question before.</p>
",graph_theory
"<p>I know of Zero One laws for Random graphs (such as those concerning <a href=""http://link.springer.com/article/10.1007%2FBF02579198"" rel=""nofollow"">monotonic</a> or <a href=""https://jeremykun.com/2015/02/09/zero-one-laws-for-random-graphs/"" rel=""nofollow"">first-order-logic properties</a>). I also know about <a href=""https://en.wikipedia.org/wiki/Kolmogorov%27s_zero%E2%80%93one_law"" rel=""nofollow"">Kolmogorov's zero one law</a> for tail sigma algebras. </p>

<p>Apart from the obvious statements of these laws (a property exists or it doesn't), is there any relation between them? Is Kolmogorov a generalization or extension of Random Graph Zero One Laws in any way? </p>
",graph_theory
"<p>Let $G$ be a <em>color critical</em> graph and $S$ any independent set of $G$ then $\chi(G−S)=\chi(G)−1.$</p>

<p>I tried to show that any independent set induce one color, but I cannot match it with the <em>color critical</em> hypothesis.</p>
",graph_theory
"<p>Dyer and Frieze in ""ON THE COMPLEXITY OF PARTITIONING INTO CONNECTED SUBGRAPHS"" showed that the problem of deciding whether a planar graph has a connected-$k$-partition is NP-complete.</p>

<p>On a graph with fewer than $k$ nodes, of course the partition is impossible. Cutting a graph with sufficient nodes into pieces strikes me as trivial. Is there a planar graph of $k$ or more nodes that can't be partitioned into $k$ subgraphs? When does Dyer and Frieze's problem result in a ""no""?</p>
",graph_theory
"<p>A cubic cheese consists of 27 smaller cubes of cheeses (3x3x3). A mouse will eat the first cheese cube and then eat an adjacent cheese cube (no diagonal eating allowed). Show that the mouse can't end up eating the middle cheese cube last.</p>

<p><strong>EDIT:</strong> </p>

<p>The mouse has to eat every cube and can't move into empty space.</p>

<p>Any ideas on how to show this?</p>
",graph_theory
"<p>Following graph is a composition of $K_{4,4}$ bipartite graphs with all the edges are of same length. How do I know whether it is minor-closed or not?</p>

<p><img src=""http://i.stack.imgur.com/fItF8.jpg"" alt=""enter image description here""></p>

<p>The definition in the Wikipedia is as follows.</p>

<blockquote>
  <p>A family F of graphs is said to be closed under the operation of
  taking minors if every minor of a graph in F also belongs to F.</p>
</blockquote>

<p>I think to answer to the question, we have to find the smallest complete graph $K_n$ which is a minor of the graph but not present. Can anyone think of such a $K_n$?</p>
",graph_theory
"<p>In an undirected graph, we have that the $a_{ij}$ entry in the adjacency matrix $A$ is equal to $1 \iff$ there is an edge between $i$ to $j$.</p>

<p>Now for undirected graphs we know that if there is an edge from $i \to j$ then this edge is also considered as an edge from $j \to i$.</p>

<p>Does that mean that $A$ will always be a symmetric matrix and that $A= A^T$ for all undirected graphs ?</p>

<p>I think the answer is true, But I just want to make sure If I am right or not</p>
",graph_theory
"<p>I Have the following question :</p>

<blockquote>
  <p>Give three examples of simple, connected graphs, all with 8 vertices
  with degrees 2, 2, 2, 2, 3, 3, 4 and 4, no pairs of which are
  isomorphic</p>
</blockquote>

<p>What is the best method to find such 3 graphs ? In general how can I proceed to find 2 or more non isomorphic Graphs that have the same numer of vertices with the same  degree?  </p>

<p>Thank you !</p>
",graph_theory
"<p>There's a research project i'm currently working on which requires me to analyze various aspects of ""worlds"" represented by transition probability matrices, where the nodes represent objects in the world that our ""learner"" travels through.
I'm looking for a way to measure the degree to which the structure of the connections in a given a graph provide the learner with any predictive power, for example, in a graph where all the vertices have the same value, the learner has absolutely no ability to predict the next node/nodes given the current one.</p>

<p>The graphs are all weighted and directed, with the sum of outgoing connections from each node normalized to one.</p>

<p>I'm having a bit of trouble coming up with a good way to measure this and would really appreciate some advice,
Thanks,
Ron</p>
",graph_theory
"<p>I need to construct a graph that has the following properties: the vertices of G are the edges of a complete graph $K_5$ on 5 vertices. The vertices of G are adjacent if and only if the corresponding edges of $K_5$ have an endpoint in common. I then need to determine the chromatic number of this graph. </p>

<p>Can someone help me with at least the construction of the graph?</p>
",graph_theory
"<p>You have a herd of cattle moving in different directions. The cows in the herd are more or less always moving, at different direction and in different velocities.When a cow bumps another cow it affects its direction and perhaps its speed so that they would not keep brushing up against each other. If we take a snapshot of this herd of cattle, we can try to predict the eventual direction of the herd by looking at the edges - for example, if all cattle at the bottom of the herd and at the sides are moving up in a forceful manner, we can imagine the cattle in the middle will change their direction upwards as well (because that's the path of least resistance).</p>

<p>We can also think of a different example. We can imagine a group of academic researchers such that each researcher has some degree of influence on others. Each researcher also has his own topic, which could range from biotechnology to environmental science to algebra. When we observe this system over time, we can imagine that researchers (assuming they're not particularly independent) will change their ""research direction"" over time to fit the direction of the science herd, and we can probably point out the researchers that will have the most ""pull"" in setting this direction.</p>

<p>My question is, given this sort of setting in the abstract and in a specific moment in time, how do we identify which actors will have the most influence on the eventual direction of the group (Human beings seem to be able to do this quite intuitively!)? Has this problem been studied? </p>
",graph_theory
"<p>I am reading a paper which is regarding to the graph theory.</p>

<p>It is applied theory to computer science.</p>

<p>My background was industrial and management engineering, and computer science and engineering right now.</p>

<p>I am freshman at a grad school. Maybe because of the reason, I don't fully understand and know about graph theory.</p>

<p>By the paper's author, <strong>the density of a graph seems like</strong></p>

<p><strong>(density) = (the number of edges) / (the number of nodes)</strong></p>

<p><strong>The authors followed E. Lawler (1976), <em>Combinatorial Optimization: Networks and Matroids</em>.</strong></p>

<p>And they recommeded to see chapter 4 of that book.</p>

<p>I can't find about the density at the book.</p>

<p>So I searched google, maybe people say the density of a graph is</p>

<p><strong>(density) = (the number of edges) / (the number of possible edges)</strong></p>

<p>Those two definitions are different.</p>

<p>I would like to make it sure.</p>

<p>Thank you for your help in advance.</p>
",graph_theory
"<p>One of the defining characteristics of a Markov Chain is that it is memoryless: the next state depends only on the current state, and not on the set of preceding states.</p>

<p>I'm looking for a mathematical structure that is, essentially, a Markov Chain with memory. All the same, except for that the next state depends on some set of preceding states. Is there such a thing?</p>
",graph_theory
"<p>I don't know if I am asking a silly question, but what is the exact definition of a graph homomorphism (throughout, the graphs may be assumed to be simple, i.e. undirected, no loops, no multiple edges, etc)? 
I have a slight confusion with the existing definition, which says that a function f : V(G) to V(H) is called a graph homomorphism, if whenever (i,j) is an edge of G, (f(i),f(j)) is an edge of H. The confusion is that, suppose that f(i) = f(j), and suppose that (i,j) is an edge of G. Then, is f still a homomorphism? Or does a graph homomorphism necessarily have to be an injective function (in set-theoretic sense)?
Please help me settle this issue, as it would be very embarassing to have his kind of a misconception at the beginning of my study of graph theory!    </p>
",graph_theory
"<p>In the towers of Hanoi game, how do we know that we have the optimal algorithm for solving it? I thought about this and it seemed like any deviation from the standard strategies would be putting you back a step, but I had no idea how to demonstrate this rigorously.</p>

<p>All I know is that the proof involves the Lucas correspondence between the Hanoi graph and the odd coefficients in Pascal's triangle. How is Pascal's triangle turned into a graph? I assume the coefficient are the vertices, but I don't see how you form the edges?</p>

<p>I was also wondering how to generalize the strategy to n discs and k rods because it seems like this correspondence argument wouldn't really work in the general case.</p>

<p>Basically, I am wondering how the odd coefficients of the Pascal triangle are turned into a graph and whether or not there is a similar method to find and prove optimal strategy when we increase the number of rods.</p>
",graph_theory
"<p>(I have posted the following in theoretical CS stackexchange, but realized that it's the wrong place, so I'm reposting it here)</p>

<p>I'm reading CLRS's (Cormen et.a al) <em>Introduction to Algorithm</em>, and arrived at the maximum flow section. It shows that Edmonds-Karp algorithm runs in $O(E^2V)$ time by showing that:</p>

<p>1) If we let $\delta_f(s, u)$ be the shortest distance from source $s$ to vertex $u$ in the residual graph after flow $f$ is picked, then CLRS shows that $\delta_f(s, u)$ does not decrease as $f$ gets augmented, for a fixed $u$.</p>

<p>2) Let $c_f(e)$ be the capacity of edge $e$, and $c_f(p)$ the capacity of a path $p$ (the minimum of all $c_f$ on the edges in the path $p$) in the residual graph after flow $f$. If we say that an edge $(u, v)$ in a residual network $G_f$ is <em>critical</em> on an augmenting path $p$ if $c_f(p) = c_f(u, v)$, then CLRS shows that each edge can't become critical more than $|V|/2$ times, and therefore, there can be at most $|E||V|$ augmenting flows, if we sum up this bound over all of the potential $2|E|$ edges in residual graphs.</p>

<p>In particular, CLRS's proof of the 2nd point goes as follows:</p>

<p>If $(u, v)$ becomes critical at $f$, then $\delta_f(s, v) = \delta_f(s, u) + 1$, because we have picked the shortest path from $s$ to $t$.</p>

<p>The next time it becomes critical, there must have been some flow $f'$ that ran through $(v, u)$. Then $\delta_{f'}(s, u) = \delta_{f'}(s, v) + 1$. This must mean $\delta_{f'}(s, u) \ge \delta_f(s, u) + 2$. </p>

<p>Hence every time $(u, v)$ becomes critical after the 1st, $\delta_f(s, u)$ must have increased by 2. As this minimal distance can't exceed $|V|$, each edge can become critical at most $|V|/2$ times. Therefore, there can at most be $O(EV)$ augmenting paths and hence the number of augmentations.</p>

<p>So my comment now comes in as a possible improvement over this proof. Why can't we say the following:</p>

<p>If we augment the edge $(u, v)$ $k$ times,then $\delta_f(s, u)$ increases at least by $2(k-1)$. Now instead of looking at edges, we look at vertices and their degrees. We just need to guarantee the edges going out from any particular vertex $v$ become critical infrequently enough so that $\delta(v)$ doesn't exceed $|V|$ (from now on for convenience I will shorten $\delta_f(s, v)$ to $\delta(v)$). I claim that for any vertex $v$, $\sum_{(v,u)\in E \text{ or } (u, v)\in E} \text{number of times $(v, u)$ becomes critical}$ is at most $indegree(v)+outdegree(v)+|V|/2$. (we are looking at ""reverse"" edges here too because they may appear in the residual graph)</p>

<p>Indeed, the first time any edge becomes critical is ""free"": it doesn't bump up $\delta(v)$. But for every time after that $\delta(v)$ goes up by 2. So we can get every edge going out from $v$ to become critical once (this is the $indegree(v)+outdegree(v)$ term) and then all other times are bounded by $|V|/2$ for the same reason CLRS writes. </p>

<p>Now if we sum up this bound for all vertices, we get
$$\sum_v indegree(v)+outdegree(v)+|V|/2 = 2|E| + |V|^2/2 = O(V^2)$$</p>

<p>This bound is better than the $O(EV)$ bound given by CLRS. Combined with the $O(E+V)=O(E)$ bound for BFS, we find Edmonds-Karp is actually $O(EV^2)$ instead of $O(E^2V)$.</p>

<p>I'm suspicious that I'm missing something, since every where I looked, the bound given for Edmonds-Karp is $O(E^2V)$. So please nitpick away and see where I reasoned incorrectly.</p>
",graph_theory
"<p>Let $T$ be a tree with exactly two vertices of degree $7$ and exactly $20$ vertices of degree $100$. What is the minimum possible number of vertices in a tree $T$ that satisfies those restrictions?</p>
",graph_theory
"<p>I am doing a few tests with the Average Path Length formula. I am testing with a directed acyclic graph. I am generating all the shortest path using a breath first walk.</p>

<p>Everything works fine. However, I am trying to relate what I did with the Average Path Length formula I am seeing everywhere: <a href=""http://en.wikipedia.org/wiki/Average_path_length"" rel=""nofollow"">wikipedia</a>, <a href=""http://mathinsight.org/network_mean_path_length_definition"" rel=""nofollow"">math insight</a>, etc.</p>

<p>All the definitions says:
$$
\bar P = \frac{1}{n \cdot (n \mathbin{-} 1)} \cdot \sum_{i \neq j}^{} d(v_{i},v_{j})
$$</p>

<p>All of them says that $n$ is the number of nodes in $G$. </p>

<p>The problem is that I am about 20 000 nodes in my graph and about 600 000 shortest paths. If I do:</p>

<p>$$
\bar P = \frac{1}{S} \cdot \sum_{i \neq j}^{} d(v_{i},v_{j})
$$</p>

<p>where $S$ is the number of shortest paths (600 000) then I get an average of 6.05 which is what I am expecting after looking at the distribution of my shortest path on an histogram.</p>

<p>However, if I do what I think that the formula is telling me, then I endup with doing:</p>

<p>$$
\bar P = \frac{1}{400000000} \cdot \sum_{i \neq j}^{} d(v_{i},v_{j})
$$</p>

<p>which is clearly not the average of my shortest paths.</p>

<p>So my question is: what is my issue with understanding this formula? I am clearly missing something in my thinking, but I don't know what.</p>
",graph_theory
"<p>A Paley graph is strongly regular with parameters $(p,\frac{p-1}{2},\frac{p-5}{4},\frac{p-1}{4})$. I need to prove that, and obtain the parameters too. Proving it is regular valency $\frac{p-1}{2}$ is easy but for the rest I am struggling. Also, proofs I found are very vague and only prove the third parameter and then use the equation $k(k-a-1)=b(v-k-1)$ to find the other. However, I dont think we can use that as we have not yet proved it is strongly regular, so we dont know if the equation holds.. is that right? Can someone please provide a proof of the statement? </p>

<p><a href=""http://en.wikipedia.org/wiki/Paley_graph"" rel=""nofollow"">http://en.wikipedia.org/wiki/Paley_graph</a></p>
",graph_theory
"<p>Given a definition below (source: On Hedetniemi's Conjecture and the color template scheme by C. Tardiff and X Zhu): <br/>
The exponential graph $G^H$ has all the functions from vertex-set of $H$ to that of $G$ as vertices and two of these functions $f,g$ are joined by an edge if $[f(u),g(v) ∈ E(G)]$ for all $[u,v] ∈ E(H)$.<br/>
Can anyone give me an example of exponential graph based on that definition?
Thank you.</p>
",graph_theory
"<p>I'm am trying to define a data structure to represent road networks.  The immediately obvious structure is that of a graph - a set of nodes and edges that connect pairs of nodes.  The nodes would represent things like intersections, and the edges would represent lanes.  </p>

<p>However, the basic concept of a graph is insufficient to describe what I want.  I also want to be able to describe how certain lanes are ""reachable"" or ""adjacent"" to other lanes.  (Imagine parallel lanes with no median between them.  You can just switch lanes.)  This seems to imply a need to have some sort of meta-edge that connects pairs of edges.  Is there any mathematical structure that sounds like this?  Is this reducible to the standard concept of a graph? Thanks.</p>
",graph_theory
"<p>This is an extension of the problem at this thread: <a href=""http://math.stackexchange.com/q/239120/74947"">Graphs, line graph and complement of graph</a>.</p>

<p>Just to reiterate definitions:</p>

<blockquote>
  <p>The <em>line graph</em> $L(G)$ of a graph $G$ is defined in the following way: the vertices of $L(G)$ are the edges of $G$, $V(L(G))=E(G)$, and two vertices in $L(G)$ are adjacent if and only if the corresponding edges in $G$ share a vertex.</p>
</blockquote>

<p><strong>Question</strong>: </p>

<p>Suppose $G$ has $n$ vertices, labeled $v_1,v_2,\ldots,v_n$ and the degree of vertex $v_i$ is $r_i$. Let $m$ denote the size of $G$, so $r_1+r_2+\ldots+r_n=2m$. Find formulas for the order and size of $L(G)$ in terms of $n,m,$ and $r_i$.</p>

<p><strong>So far</strong>:</p>

<ol>
<li>Clearly, the order is $m$.</li>
<li>Suppose that the edge $e=(v_i,v_j)$ exists in $G$. Then, the $\deg(e)=r_i+r_j - 2$ in $L(G)$, because at the $v_i$ end, $e$ shares $v_i$ with $r_i - 1$ other edges, and at the $v_j$ end, $e$ shares $v_j$ with $r_j - 1$ other edges.</li>
<li>I tried to use the above to sum over all the edges in $G$, but this depends on knowing which edges exist in the graph $G$, which we are not given. We only know the <em>degree sequence</em>, not the edges.</li>
<li>Another approach I tried was to find this expression for a regular graph with degree $k$, and this can be found using the above: $$m(2k - 2) = 2|E(L(G))| \implies |E(L(G))| = m(k - 1).$$ I then tried this for a complete graph (so $k = m - 1$), and then removing edges one at a time until it becomes $G$, but this also requires knowledge of the edges.</li>
</ol>

<p>Any help would be greatly appreciated. One piece of information that I seem to be not using is the variable $n$, the order of $G$, but I am not sure where it would be appropriate to use.</p>
",graph_theory
"<p>I am working on the statement "" A graph $G$ is a $nKn$ (collection of $n$ number of complete graph each of order $n$) graph if and only if $\bar{G}$ is $α(G) = α(\bar{G}) = n$ and $(p-n)$-regular , where $p$ is the order of $G$ and $α(G)$ is the independence number of $G$ with $n\geqslant 1$.""</p>

<p>The converse part seem to be a confusion. Kindly help me with it.</p>
",graph_theory
"<p>I was given this problem to solve by a professor who promised an A if anyone could solve it. I'm nearly certain it is impossible, because at some point you have too many vertices and inevitably box yourself in, but I would like to know how to prove it.</p>

<p>How can you prove that it is impossible to connect every <code>*</code> with every <code>0</code> without overlapping lines?</p>

<pre><code>*    *    *   

0    0    0
</code></pre>

<p>EDIT: Professor said you get an A if you <strong>solve it</strong>, not prove it's impossible. I'm not even in the class, it was my friend's question, I am just curious.</p>
",graph_theory
"<p>Let $G=(V,E)$ be a planar graph. Suppose a planar representation of $G$ has been chosen and that $$v-e+f=2,$$ where $v,e$ and $f$ are the number of vertices, edges and faces respectively. See <a href=""http://en.wikipedia.org/wiki/Planar_graph#Euler.27s_formula"" rel=""nofollow"">Wikipedia</a>.</p>

<p>Does this imply that $G$ must be connected?</p>
",graph_theory
"<p>So I have a 10 cube insanity puzzle, I constructed the graph (I'll post pc later) based on the colors the problem is that there is just way to many lines and nodes to see the solution. Is there any way to find those paths in the graph without trying every permutation. Guess I was unclear. The puzzle is that each cube has 3 different colors, I need to line them up so that each side will have no repeating colors, so with 10 cubes we have 10 unique colors, now when constructing a graph based on problem I need to find a path that will take me through each node but wont repeat same number path (paths are numbered based on cube numbers). so question is how can I find the path from the graph I attached.
<img src=""http://i.stack.imgur.com/2chgj.jpg"" alt=""enter image description here""></p>
",graph_theory
"<p>Prove that a bipartite graph has a unique bipartition if and only if it is connected. </p>

<p>I am completely stuck on this question. I assume it is a proof that involves a mixing of definitions but I am not sure. </p>
",graph_theory
"<p>How would you connect each black box once to each colored box without any lines overlapping, this is racking my brain so please help.</p>

<p>Note that you can move the boxes where ever you want.</p>

<p>Maybe there's some math trickery involved as I have spent hours trying to crack it but cannot seem to without having no option but to overlap (which I can't) or start again.</p>

<p><a href=""http://i.stack.imgur.com/ACEFt.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/ACEFt.png"" alt=""boxes_to_connect""></a></p>

<p>I am unsure if this is the correct forum to post in.</p>
",graph_theory
"<p><a href=""http://i.stack.imgur.com/upWTS.png"" rel=""nofollow"">Graph</a></p>

<p>I need to show this graph is not planar. I've attempted to find $K_5$ and $K_{3,3}$ as a subgraphs but haven't been successful yet. It's possible but unlikely this graph <em>is</em> planar but I haven't been able to draw it as a plane graph.</p>
",graph_theory
"<p>suppose you have the $K_{2n}$ covered by a multigraph consisting of $2n-1$ bicliques, each consisting of a partition of the vertex set into two sets of equal size.</p>

<p>Here is a picture of $K_{6}$ with 5 bicliques. </p>

<p><img src=""http://i.stack.imgur.com/01hOM.jpg"" alt=""enter image description here""></p>

<p>My question is: under which circumstances is it possible to pick a perfect matching of each biclique, such that every edge of $K_{2n}$ is covered exactly once?</p>

<p>I know so far, that obviously every edge should be covered at least once and every vertex has $n$ edges of one color. Moreover a biclique can only occur at most $n-1$ ($n$ odd) or $n$ ($n$ even) times.</p>

<p>Is there any theory regarding this question? </p>
",graph_theory
"<p>Prove that if $G$ is a graph in which every edge is a part of at most one odd length cycle, then the graph is 3 colorable.</p>

<p>I want to show that if a graph is 4-critical there are two odd cycles which share an edge, which would prove the question. I'm not sure how to get that. I thought to take a maximum path, and then an end point has at least 3 neighbours in the path, which ensures 3 cycles, but I don't see a reason they can't all be even.</p>
",graph_theory
"<p>I know that a hamilton cycle exists for a bipartite graph $K_{m,n}$ if and only if $m=n$</p>

<p>But my question is why is it not possible to have a bipartite graph if $m=n=1$</p>

<p>I mean we would go from $x$ to $y$ and back to $x$</p>

<p>Why this is not allowed, We don't have a restriction on the edges, I mean we are allowed to use an edge more than once in a Hamilton cycles unlike Euler cycles.</p>

<p>So I am just surprised why is it not possible, does someone have an explanation for that ?</p>

<p>Because according to the definition of a Hamilton cycle, It's basically a cycle that begins and ends on the same vertex and we don't have restrictions as I said on the usage of the edges more than once.</p>
",graph_theory
"<p>Is there a name for the subset of graph theory dealing with vertices and edges of distinct classes? For example, I could have a graph in which each vertex must be either blue, yellow or red and each vertex must be either dashed or solid. </p>

<p>I'm working on a problem with these characteristics but I have no background in graph theory. This makes it hard to find the right terminology to search to find solutions.</p>
",graph_theory
"<p>an agent is works between n producer and m consumers. i'th producer, generate $s_i$ candy and j'th consumer, consumes $b_j$ candy, in this year. for each candy that sales, agent get 1 dollar payoff. for some problems, one strict rule was defined that a producer should be sales candy to any producer that the distance between them is not greater than 100 KM (kilometers). if we have list of all pairs of producer-consumer that the distance  between them is lower than 100 KM, which of the following algorithm is goof for finding maximum payoffs? (suppose $s_i$ and $b_j$ may be becomes very large).</p>

<pre><code>1) Maximal Matching

2) Dynamic Programming

3) Maximum Flow 

4) 1 , 3
</code></pre>

<p>this is a last question on 2013-Final Exam on DS course.  any hint or idea? </p>
",graph_theory
"<p>I saw this interesting problem, I did my best so solve it but I failed.</p>

<p>In the graph $G = (V,E)$ , if  $|V| = 10$ and number of ordered pairs $(x,y)$ of vertices equals to <strong>72</strong> such that $d(x,y) \ge 2$, then how many edges G has? the answer is one of the following choices.</p>

<ol>
<li><p>9</p></li>
<li><p>18</p></li>
<li><p>28</p></li>
<li><p>36</p></li>
</ol>
",graph_theory
"<p>Let G be a forest with two components and at least four vertices. Is it true that G has at least four leaves?</p>

<hr>

<p><img src=""http://i.stack.imgur.com/79ch3.png"" alt=""enter image description here""></p>

<p>the graph is which is I mentioned you</p>
",graph_theory
"<p>Given a CNF SAT formula, we can turn it into a Hamiltonian graph, which is Hamiltonian iff the formula is satisfiable. Now, we can transform the CNF formula into a DNF one. My question is, can the graph be transformed into a ""DNF"" graph, from which the property of satisfiability or Hamiltonian-ness can be observed obviously?</p>
",graph_theory
"<p>Let $V = v_1, \dots, v_n$ be the locations the items can spawn at, and let $U = u_1, \dots, u_k$ be the current positions of the items. We will assume a new items spawns instantly every time we collect an item, so there are always $k$ items (Assume uniform distribution for spawn location). Let $w$ be the current position of the character. Then $S = (V, U, w)$ is the state of the game.</p>

<p>Assume the character can move at a constant speed, so the time metric we care about is proportional to the distance between two points.</p>

<p>Essentially I want a function $\text{bestItem}(S)$ that tells me which item in $U$ to go to first to maximize the number of items I collect per hour.</p>

<p>This seems similar to shortest path on a clique with weighted edges, but it doesn't stop after one step. Or a traveling salesman problem where the traveling salesman doesn't know all the locations he needs to visit from the start.</p>

<p>Is there a name for this problem? I am curious if it is already solved, and how good the greedy method of just always taking the nearest item is compared to the optimal method. Or the method of computing the shortest path through the points of $U$, and updating it after some number of spawns.</p>

<p>Has anyone worked with this type of problem and point me at some reading material? My interest is inspired by video games which have mechanics like this.</p>

<p>Thanks.</p>
",graph_theory
"<p>I am reading on my own the notes of this lecture series from 2012: <a href=""http://www.cs.yale.edu/homes/spielman/561/2012/lect04-12.pdf"">http://www.cs.yale.edu/homes/spielman/561/2012/lect04-12.pdf</a>. In section 4.7.2 (page 8) it's mentioned that we can prove a lower bound of $O(1/n)$ for the 2nd eigenvalue of the binary tree. I found a proof of this fact here: <a href=""https://www.cs.cmu.edu/~glmiller/Publications/Papers/GuMi94-tr.pdf"">https://www.cs.cmu.edu/~glmiller/Publications/Papers/GuMi94-tr.pdf</a> (lemma 3.8), but I could not prove it using the methods suggested in the lecture. Could someone help me understand this?</p>
",graph_theory
"<p>Consider a random walk on an undirected graph which, at each step, moves to a uniformly random neighbor. Define $T(u,v)$ to be the expected time until such a walk, starting from $u$, arrives at $v$, and let $T = \max_{u,v} T(u,v)$. Define $G(u)$ to be the expected time until such a walk, starting from $u$, visits every vertex and let $G = \max_u G(u)$. Is it true that  $$G \leq cT$$ for some constant $c$ which does not depend on the graph and any of its parameters (e.g., number of nodes)?</p>
",graph_theory
"<p>This is a followup to my question <a href=""http://math.stackexchange.com/questions/143245/cover-times-and-hitting-times-of-random-walks"">Cover times and hitting times of random walks</a>.</p>

<p>Consider a random walk on an undirected graph with $n$ vertices which, at each step, moves to a uniformly random neighbor. Define $T(u,v)$ to be the expected time until such a walk, starting from $u$, arrives at $v$, and let $T = \max_{u,v} T(u,v)$. Define $G(u)$ to be the expected time until such a walk, starting from $u$, visits every vertex and let $G = \max_u G(u)$. Is it true that  $$G \leq cT \log^k n$$ for some constants $c,k$ which do not depend on the graph or on $n$? </p>
",graph_theory
"<p>This concerns a problem from Extremal Combinatorics by Jukna that I cannot solve myself. </p>

<p>First some preliminaries. A biclique covering of a graph is a covering of a graph with complete bipartite graphs (so that every edge of the initial graph belongs to at least one of the bipartite graphs that cover the initial graph). For each such covering of a graph, let the weight of a covering be the number of vertices of each of the subgraphs (the bipartite graphs) all added together. (i.e. if the graphs $H_1, H_2, \dots, H_m$ are the bipartite graphs that cover $G,$ then the weight of this covering will be $\displaystyle\sum_{i=1}^m |V(H_i)|,$ where $|V(H_i)|$ denotes the number of vertices in $H_i.$) The covering with the minimum such weight is $\text{bc}(G)$ for the graph $G.$ </p>

<p>If $\mu_G$ is the minimum over all the $(a+b)/ab$ for pairs of integers $a,b \ge 1$ such that $G$ contains a copy of the complete bipartite graph: $a \times b$ (or $K_{a,b}$). Prove that $\text{bc}(G) \ge \mu_G \cdot |E|.$ (Where $|E|$ denotes the number of edges of $G.$) </p>

<p>Thank you very much for the help. </p>
",graph_theory
"<p>A 3 regular, plane, connected graph have all surfaces either $4$ or $6$ edges (including the outer surface). How many surfaces has $4$ edges?</p>

<p>Let $x$ be the number of surfaces that have $4$ edges</p>

<p>Let $y$ be the number of surfaces that have $6$ edges</p>

<p>Euler's formula gives:</p>

<p>$$v - e+ (x+y) = 2$$</p>

<p>I am stuck here. Ideally I would like another equation that has $x$ and $y$ in it so I thought of the one that says that the sum of the grade of every vertex is twice the edges. </p>

<p>$$3v = 2e$$</p>

<p>But it don't see how that would help. </p>

<p>Any ideas?</p>
",graph_theory
"<p>Given an undirected graph G(V,E). A and B are elements of V. Identify a subgraph of G containing A &amp; B with 2 edge disjoint spanning trees (or prove one doesn't exist).</p>

<p>I have found several sources stating to convert the problem to a directed graph and use max-flow min-cut.</p>

<p><a href=""http://stackoverflow.com/questions/3271763/how-to-find-two-disjoint-spanning-trees-of-an-undirected-graph"">http://stackoverflow.com/questions/3271763/how-to-find-two-disjoint-spanning-trees-of-an-undirected-graph</a></p>

<p>I'm not seeing how this proves edge disjoint spanning trees (only edge disjoint paths). I have seen it cited multiple times, so I am guessing I am just missing something.</p>
",graph_theory
"<p>I came across this question and I tried to give myself a direction but couldn't:</p>

<blockquote>
  <p>Given $T1 = (V, E_1)$ and $T2 = (V, E_2)$ two trees with same group of vertices. Prove that there is a vertex $v$ such that $deg(v)_{T1} + deg(v)_{T2} \leq 3$.</p>
</blockquote>

<p>Now I thought about that in a tree there are at least two leafs, we take one and we show that its' degree in $T2$ is less or equal 2, but that is obviously not a condition and not always correct.</p>

<p>I would be happy for a direction!</p>
",graph_theory
"<p>Show that in a graph $G$ where every two different edges are connected (i.e there is an edge incident with both) we have that $\delta&lt;\omega+{\omega \choose 2}$ where $\delta$ is the min degree and $\omega$ is the clique number.</p>

<p>It looks like it should some kind of combinatoric argument where we get a larger clique by contradiction.</p>

<p>Note that the original question was to show that in a graph $G$ where every two different edges are connected (i.e there is an edge incident with both) we have that $\chi \le \omega+{\omega \choose 2}$, and what I did was assume by negation that this wasn't true and found a subgraph with min degree at least that, looking to find a contradiction. It looks to me like it should be a valid direction with some kind of combinatoric argument as mentioned, however I just can't find one.</p>

<p>Thanks</p>
",graph_theory
"<p>I tried to find a book or paper to understanding discrete association scheme but I could not get any book for that. What is the good references for that?</p>
",graph_theory
"<blockquote>
  <p>let $G=(V,E)$ be a connected graph, with $|E| = 19$ and $deg(v) \geq
 4$ for all vertices $v$ in $V$</p>
  
  <p>What is the largest possible value of $|V|$ ?</p>
</blockquote>

<p>Well I know that the sum of the degree is equal to two times the number of edges and so $\sum deg(v) = 2 \times 19 = 38$ </p>

<p>Now I think if we want to find the largest possible value of $|V|$ then we try to minimize the degree of every vertex but we have that $deg(v) \geq 4$ and so $\frac{38}{4} = 9.5$ but we can't have fractions in our answer, and if we take $9 \times 4 = 36$  that can't happen, then we can have $8$ vertices each with degree $4$ and the last one should be degree $38 -32 = 6$</p>

<p>So My final answer is $9$ vertices, $8$ of them with degree $4$ and one of them has degree $6$ does that make sense ?</p>
",graph_theory
"<blockquote>
  <p>If the edges of $K_6$ are coloured blue or red, prove that there is a
  red triangle or a blue triangle that is a sub-graph.</p>
</blockquote>

<p>Well I am having a hard time proving this, I try to prove it by contradiction, Meaning that Assume that there is no red or blue triangle that is a sub-graph and I argue that You can't avoid but to have a red or a blue triangle.</p>

<p>But I can't even start the argument.</p>

<p>That was my attempt, </p>

<p>We consider all cycles of length $3$ in $K_6$ which are the triangles,</p>

<p>Now We start coloring one of the edge in this triangle with one red and the other edge with blue, Now the third vertex can be either red or blue, but without loss of generality we choose blue. So now we have a triangle with two blue edges and one red edge.</p>

<p>But then what can I say ?</p>
",graph_theory
"<p>I'm having trouble knowing whether this graph is planar or nonplanar - a seven vertex graph with each vertex of degree 4.</p>

<p><a href=""http://imgur.com/09u1UlH"" rel=""nofollow""><img src=""http://i.imgur.com/09u1UlH.png"" title=""source: imgur.com"" /></a></p>

<p>So it's planar if e ≤ 3v - 6, and there are 14 edges and 7 vertices, so 14 ≤ 15. So it is planar then? I can't seem to find any way this would be planar, and if it is nonplanar, I can't find a sensible k3,3 configuration.</p>
",graph_theory
"<p>Let $(G,E)$ be a finite undirected graph, and $d$ be the usual shortest path distance on $G$. The graph is not necessary connected, so $d(v',v'') = \infty$ if there are no paths from $v$ to $v'$. For $A\subseteq G$ we put
$$
d(v,A) = \min\limits_{u\in A}d(v,u).
$$
My question is the following: let us define for $A\subseteq G$
$$
m(A) = \max\limits_{v\in A}d(v,G\setminus A).
$$
Is there a name for $m(A)$, maybe you can give a reference on this?</p>
",graph_theory
"<p>Hint: Suppose that the chromatic number is at least 6 and consider graphs induced by 3 colour classes.</p>

<p>Any hints would be appreciated. I do not understand what a graph induced by 3 colour classes are. They have not been defined in my lectures. </p>

<p>Thanks</p>
",graph_theory
"<p>I am having trouble with the following Question:
Prove that a graph is 2-connected(biconnected) iff for every triple distinct vertices u,v,w there is a path connecting u and v and goes through w.
Now , proving $\leftarrow$ is really easy, but I am having trouble proving the $\rightarrow$ part was harder for me and I will be happy if someone could ge me a clue :)
p.s. : our lecturer defined the connectivity of a graph by the number of vertices that need to be removed in order for the graph to become disconnected.  </p>
",graph_theory
"<blockquote>
  <p>Suppose that four judges $J_1$, $J_2$, $J_3$, and $J_4$ each rank eight objects: $O_1,O_2,\ldots,O_8$ independently. Their rankings are</p>
  
  <p>$$\begin{array}{cc}
J_1: &amp; O_1\ O_2\ O_3\ O_4\ O_5\ O_6\ O_7\ O_8 \\
J_2: &amp; O_2\ O_4\ O_6\ O_8\ O_1\ O_3\ O_5\ O_7 \\
J_3: &amp; O_3\ O_5\ O_4\ O_8\ O_7\ O_6\ O_2\ O_1 \\
J_4: &amp; O_6\ O_7\ O_1\ O_2\ O_3\ O_4\ O_5\ O_8
\end{array}$$</p>
  
  <p>Construct a digraph which reflects these rankings. Use component analysis to interpret these rankings. </p>
</blockquote>

<p>This is question 7.1 (pages 120-121) from the text <a href=""http://dx.doi.org/10.1007/978-1-4612-0933-1"" rel=""nofollow"">Graph Theory Applications</a> by L. R. Foulds.</p>

<p>I tried to answer this question but I am confused about how to construct the graph. Because what I am thinking is that this digraph should be considered as a tournament and use tournament analysis to interpret rankings. But when I am drawing edges based on the judges rankings there is more than one edges between two vertices like $O_1 \rightarrow O_2$ based on $J_1$ and $O_2 \rightarrow O_1$ based on $J_3$. These cannot be present in a tournament. So I am confused how to approach this question.</p>

<p>Please help me to solve this question</p>
",graph_theory
"<p>Say you have a sparse matrix in CSC or CSR format (or whatever format is suitable for this to work) and all you know are it's dimensions: $n$, $m$ and $nz$, and the data in the structure. You are told nothing about the structure or layout.</p>

<p>A description of the CSR format: <a href=""http://netlib.org/utk/papers/templates/node91.html#SECTION00931100000000000000"" rel=""nofollow"">http://netlib.org/utk/papers/templates/node91.html#SECTION00931100000000000000</a></p>

<p>How would you determine (from the $row\_ptr$ and $col\_ind$ arrays) if a sparse matrix is structurally symmetric?
Is there a simple and efficient method?</p>

<p>An (obvious) property of a structurally symmetric matrix is that every row $x$ in the matrix has the same number of elements as each corresponding column $x$. </p>

<p>Is that one of the defining properties of a sparse symmetric matrix?</p>

<p>If we had a square sparse matrix $A$ where every row had the same number of elements as its corresponding column, i.e.:</p>

<ul>
<li>$numel(A(i,:)) = numel(A(:,j))$ where $i = j $ $\ \forall i,j \in n$</li>
</ul>

<p>Would it be then true that $A$ is structurally symmetric?</p>

<p>Experimentally this does seem to be the case. Unfortunately my Linear Algebra and Graph Theory is not up to any sort of proof.</p>

<p><strong>EDIT:</strong>
Ok. The above does not hold true for a permutation matrix where every row/column just has a single entry.
However, can anyone suggest a matrix where $nz&gt;n$ or there is a at least one row/column with 2 or more elements, which is not symmetric?</p>

<p>Cheers,</p>

<p>-- El Bee</p>
",graph_theory
"<p>I am having some difficulty following the concept of shrinking a set of node as given in the paper <a href=""http://www.zib.de/Publications/Reports/ZR-06-22.pdf"" rel=""nofollow"">On the Bottleneck Shortest Path Problem</a></p>

<p>It says:</p>

<blockquote>
  <p>Shrinking a set of nodes can be done
  in linear time. More precisely, given
  a set S ⊆ V of nodes of an
  (undirected) graph G = (V,E), one can
  construct in linear time another graph
  with nodes (V \S)$\cup${vnew} (where vnew
  represents the shrunken set S), where
  v,w ∈ V \ S are adjacent if and only
  if v and w are adjacent in G (in this
  case,the edge keeps its weight), and
  vnew and w ∈ V \ S are adjacent if and
  only if there is some v ∈ S such that
  v and w are adjacent in G (in which
  case the edge receives the biggest
  weight of any edge connecting S and w
  in G).</p>
</blockquote>

<p>I am particularly confused about the last sentence of how vnew and w are adjacent.  Actually I am pretty much confused about it all and any clarity would be appreciated.</p>
",graph_theory
"<p>Ramsey number $R(3,6)=18$. How to construct a graph of $17$ nodes which does not contain neither a clique of order $3$ or an independent set of order $6$. could you show me the tactics or the adjacency matrix?</p>
",graph_theory
"<p>I'm stuck on this problem, posting my progress so far below. I've looked at similar questions <a href=""http://math.stackexchange.com/questions/237134/prove-by-induction-that-every-connected-undirected-graph-with-n-vertices-has-at"">here</a> and <a href=""http://math.stackexchange.com/questions/457042/prove-that-a-connected-graph-with-n-vertices-has-at-least-n-1-edges"">here</a>, but neither seem to directly prove the predicate by induction, with a base case followed by the inductive step. </p>

<p><strong>Solution(?):</strong></p>

<p>Let P(n) be the predicate (All n, n >= 1, any tree with n vertices has (n-1) edges).</p>

<p><strong>Base case (n=1):</strong></p>

<p>P(1): (n=1, any tree with 1 vertice has 0 edges). A tree <em>G</em> is a connected graph with no cycles of length at least three. An edge <em>E</em> is a two-element subset of the set of all vertices <em>V</em> of <em>G</em>. In the base case, <em>V</em> contains one vertice. Thus there are zero two-element subsets of <em>V</em>, or zero edges, in <em>G</em>.</p>

<p><strong>Inductive Step:</strong></p>

<p><s>For every n>0, P(n) => P(n+1).</p>

<p>For P(n+1), where n>0 in <em>G</em>, n+1 vertices will form exactly n edges. All vertices are of degree 1, which means there is exactly one less edge than vertice (one edge per vertice, excluding the root vertice). Thus, any tree with n vertices will have exactly n-1 edges.</p>

<hr>

<p>Assume P(n) is true. Then, we want to prove that the graph <em>G</em>, for P(n+1), has n edges. </p>

<p><em>G</em> contains no cycles of length at least three. Thus, <em>G</em> must contain only one region, meaning that the edges in <em>G</em> do not form any regions. This means that <em>G</em> must contain at least one leaf (vertex with degree of 1). </p>

<p>Obtain a graph <em>G'</em> by removing one leaf from <em>G</em>. Because a leaf is a vertex of 1, by the definition of vertex degree, the leaf is connected to exactly one edge. Thus, removing the leaf will remove one vertex and one edge from <em>G</em>, to create <em>G'</em>. This means that for all n, n>=1, any tree with (n+1) vertices will have ((n+1)-1). or n, edges. </p>

<p>We have proven that the case base P(1) is true, and assuming that P(n) is true, we see that the statement remains true for n => n+1. Thus, the predicate (All n, n >= 1, any tree with n vertices has (n-1) edges) is true by induction.
</s></p>

<hr>

<p>Assume P(n) is true. Then, we want to prove that the graph <em>G</em>, for P(n+1), has n edges.</p>

<p><em>G</em> contains no cycles of length at least three. Thus, <em>G</em> must contain only one region, meaning that the edges in <em>G</em> do not form any regions. This means that <em>G</em> must contain at least one leaf (vertex with degree of 1).  </p>

<p>Remove a leaf <em>l</em> from <em>G</em> to obtain a tree <em>G′</em> with n vertices. Then, <em>G'</em> has n−1 edges, by the inductive hypothesis. The addition of <em>l</em> to <em>G′</em> produces a graph with n+1 vertices and n edges, since <em>l</em> has degree 1.</p>

<p>P(1) is true, and for every n>0, P(n) => P(n+1). Thus, the predicate must be true.</p>

<hr>

<p>I'm not exactly sure how to proceed for the inductive step., or if I doing it correctly. Any hints, or confirmation that I'm going in the right direction would be greatly appreciated. </p>
",graph_theory
"<p>I have a strong feeling that complete graph minors ($K^i$ minors) are like a sort of cycles in a simplicial complex. Is there a homology theory (for graphs) counting complete graph minors?</p>
",graph_theory
"<p>Assuming a single source, single sink digraph with |V| vertices, including source s and sink t. How many “cuts” does a flow network have? </p>
",graph_theory
"<blockquote>
  <p>Let $G=((2,3,4,5,6,7),E)$ be a graph such that {$x$,$y$} $\in E$ if and only if the product of $x$ and $y$ is even, decide if G is an Eulerian graph.</p>
</blockquote>

<p><strong>My attempt</strong></p>

<p>I tried to plot the graph, this is the result:</p>

<p><img src=""http://i.stack.imgur.com/jeo9w.jpg"" alt=""enter image description here""></p>

<p>So, if my deductions are true, this is <strong>not</strong> an Eulerian graph because it's connected but all the vertices doesn't have an even degree. For example $deg(2)=5$. Moreover, there is no trace of Eulerian trails.</p>

<p>I cannot figure out if this assumptions are presumably correct.</p>
",graph_theory
"<p>What are some interesting partial orders on the set of all finite graphs (identified up to isomorphism), apart from the usual (induced) subgraph relation and the (topological) minor relation, and why are they interesting?</p>
",graph_theory
"<p>From ""Lecture Notes in Computer Science"" by Christoph M. Hoffmann ,</p>

<blockquote>
  <p>Assume that both $X$ and $X'$ have $n$ vertices. We plan to code the
  graph labels as suitable subgraphs which we attach to the vertices of
  $X$ and of $X'$. In time polynomial in the length of the input we can rename 
  the labels and may assume, therefore, that $L = \{1 ..... k\}$ is
  the set of labels assigned by $\lambda$ and $\mu$. <strong>Note that $k\leq2n$</strong> .We describe
  how to construct $Z$ from $(X,\lambda)$. The construction of
  $Z'$ is done in the same way. Let $X = (V,E), V = \{v_1..... v_n\}$.
  Intuitively, we obtain $Z$ from $X$ by attaching to each vertex $v_i$ a
  complete graph with $n + r$ vertices, where $\lambda (v_i) = r$. <strong>Note that $r\leq2n$.</strong>
  The vertices of the attached complete graph will be, for $v_i$, $\{v_{(i,1)},..... v_{(i,n+r)} \}$
   The subgraph is atached to $v_i$ by an edge $(v_i, v_{i,1})$.</p>
  
  <p>It is easy to see that $(X,\lambda)$ is
  isomorphic to $(X,\mu)$ iff $Z$ is isomorphic to $Z'$. <strong>Since there are at most</strong>
  <strong>$2n$ distinct labels</strong>, the graphs $Z$ and $Z'$ have no more than
  $2n^2+n$ vortices each and can thus be constructed in
  polynomial time.</p>
</blockquote>

<p>the definition of graph label is given as-</p>

<blockquote>
  <p>Let $X = (V,E)$ be a graph, $\lambda$ is  a mapping from $V$ onto a set $L = \{ l_1,...l_k\}$.
   Then the pair  $(X,\lambda)$ is a labelled graph.</p>
</blockquote>

<p>Question 1: Why $k\leq 2n$ which implies $r\leq2n$?   It seems that it should be $k\leq n$ since <a href=""https://en.wikipedia.org/wiki/Graph_labeling"" rel=""nofollow"">the passage of wikipedia here</a> tells</p>

<blockquote>
  <p>When used without qualification, the term labeled graph generally
  refers to a vertex-labeled graph with all labels distinct. Such a
  graph may equivalently be labeled by the consecutive integers $\{1, …,
&gt; |E |\}$, where $|E |$ is the number of vertices in the graph.</p>
</blockquote>

<p><strong>Question 2:</strong>  What is the explanation of -</p>

<blockquote>
  <p>Since there are at most
  $2n$ distinct labels, the graphs $Z$ and $Z'$ have no more than
  $2n^2+n$ vortices each and can thus be constructed in</p>
</blockquote>

<p>Thanks in advance.</p>
",graph_theory
"<p>I've been reading up on <a href=""http://en.wikipedia.org/wiki/Cycle_graph_%28algebra%29"" rel=""nofollow"">cycle graphs</a>, and the different and unique structures that groups produce really interest me. My question is, what is the requirements for a graph to be the cycle graph of a group?</p>

<p>For example, the graph on the left is not the cycle graph of a group, and the graph on the right is the cycle graph of $S_3$:</p>

<pre><code>    o       o  o  o
    |        \ | /
    e          e
   / \        / \ 
  o - o      o - o
</code></pre>

<p>By hand I know how I could tediously prove that the graph on the right isn't a cycle graph by showing that is doesn't have closure. The proof would go somehting along the lines of:</p>

<p>From the graph, we know that the group has four elements. We'll call them $e$ (identity), $b$ (element at the top), $a$ and $a^2$ (elements in the cycle at the bottom).</p>

<p>We now prove that $ab$ cannot be in the group by trying all the possibilities and come to contradictions in each case:
$$ab=e \implies b=a^2$$
$$ab=a \implies b=e$$
$$ab=a^2 \implies b=a$$
$$ab=b \implies a=e$$</p>

<p>and since each element is unique, none of these statements can be true.</p>

<p>This method works for this graph, however I run into trouble with more complicated graphs, and I am just wondering if there is an easier way of doing this or if there is a certain criteria for a graph to be a cycle graph of a group.</p>
",graph_theory
"<p>I am struggling with this problem for hours but it seems to be easy. Here is the problem:</p>

<p>Proof that every vertex $v$ in 2-connected graph $G$ has neighbour $u$ such that $G - v - u$ is connected.</p>

<p>Any help is highly appreciated! I think that I might be missing a trivial solution here =(</p>

<p>EDIT:
So far, I tried to create an incremental process that will yield an appropriate neighbour for selected vertex $v$. So, one can remove $v$ and any $v$'s neighbour $u$ from $G$. The resulting graph can be connected or not. If it is connected, then we have found our neighbour and can stop the process. Otherwise, Graph $G$ is spliced into several components. It is clear that in each component should be at least one neighbour of $v$ as $G$ is 2-connected. I think that on this step I should choose one of these neighbours and remove it instead of initial $u$. But I cannot find the proof that it will not lead to another cut of the graph.</p>
",graph_theory
"<p>In Paul Erdős and Rényi's 1959 paper <em><a href=""http://www.renyi.hu/~p_erdos/1959-11.pdf"" rel=""nofollow"">On Random Graphs I</a></em>, they describe the number of edges in a random graph by the function</p>

<blockquote>
  <p>(1) Nc = [1/2 * nlogn + cn]</p>
</blockquote>

<p>where <em>n</em> is the number of nodes in the graph, <em>c</em> is ""an arbitrary fixed real number"" and [x] denotes the integer part of x. They go on to use a number of graphs of the form G(n, Nc), where G(n, Nc) denotes a random graph with <em>n</em> nodes and <em>Nc</em> edges.</p>

<p>Nc appears to be an arbitrary (?) function to return a number of edges based on some <em>c</em> and <em>n</em>, but I don't understand how <em>c</em> is selected or why the function is relevant. When the authors discuss graphs of the type G(n, Nc), is there any special property besides the graph just having some arbitrary number of edges? I.e, could I replace Nc with some function for a random number of edges between 0 and the maximum possible edges for the graph with the same results?</p>
",graph_theory
"<p>Let $\textbf{Grph}$ be the category whose objects are graphs $G = (V,E)$ such that $V$ is a set and $E \subseteq \mathcal{P}_2(V) := \{\{a,b\} \subseteq V: a\neq b\}$. We sometimes write $E(G)$ for $E$. The morphisms are maps $f:G\to H$ such that whenever $\{v,w\}\in E(G)$ then $\{f(v),f(w)\}\in E(H)$.</p>

<p>How can regular epimorphisms in $\textbf{Grph}$ be characterized?</p>
",graph_theory
"<p>I'm trying to figure out a way to detect highly popular (very high in-degree) nodes in a <strong>directed*</strong> graph (its an unstructured p2p network), without using the global knowledge of the topology. Each node has its own neighbor list and a regular node has access to its neighbors' neighbor lists as well. A node should be able to check its neighbor list and figure out which one of its neighbors has the highest in-degree.</p>

<ul>
<li>if node a has node b in its neighbor list:  a ---> b</li>
</ul>

<p><strong>Edit: Makes more sense to ask how to find the local sink of a directed graph, using the above mentioned info</strong></p>
",graph_theory
"<blockquote>
  <p>If $k$ is an integer such that $\operatorname{rad}G\le k\le\operatorname{diam}G$, then show that there is a vertex $w$ such that $e(w)=k$.</p>
</blockquote>

<p>For a connected graph $G$ , we define the distance $d(u,v)$ between two vertices $u$ and $v$ as the minimum of the lengths of the $u-v$ paths of G.</p>

<p>The eccentricity $ e(v)$ of a vertex $v$ of a connected graph $G$ is the number $\max_{u \in V}(d(u,v))$. that is ,$e(v)$ is the distance between $v$ and a vertex furthest from $v$.</p>

<p>The <strong>radius</strong> $\operatorname{rad}G$ of $G$ is the minimum eccentricity among the vertices of $G$ ,</p>

<p>while the <strong>diameter</strong> $\operatorname{diam} G$ is greatest distance between any two vertices of $G$.</p>

<p>In other words:<br>
$\operatorname{diam} G=\max_{u \in V}(e(v))$
and</p>

<p>$\operatorname{rad}G=\min_{ v \in V}(e(v))$ </p>

<p>and
$e(v)=\max_{u \in V}(d(u,v))$.</p>

<p>Reference: <a href=""http://gen.lib.rus.ec/book/index.php?md5=CCE6AA121C9935E19EC651802ADF7B09"" rel=""nofollow"">Original Book, <em>Graphs and Digraphs</em> By Chartrand, page 24</a></p>
",graph_theory
"<p>Among all $5-regular$ graphs, let $s$ be the smallest chromatic number, and $t$ be the largest chromatic number . For each integer $k$ such that $s \leq k \leq t$, show that there exist a $5-regular$ graph $G_k$ such that $\chi(G_k)=k$</p>

<p>For this problem, the book say $s=2$ and $t=6$. It's easy to see that </p>

<p>$$\chi(G_k) \leq 1+ \Delta(G)$$$</p>

<p>Since this is a $5-regular$, $\Delta(G)=5$, so $\chi(G_k)=k\leq 6$. However, I can't see why $s=2$.</p>

<p>I know that $\chi(G) \geq \omega(G)$ for every graph $G$, but there nothing guarantee that the largest complete subgraph of $G$ has order $2$</p>
",graph_theory
"<p>I was studying graph theory in Bollobas book's and I found a result given without proof that I wasn't able to understand. Here is my problem:
""Le G be an eulerian graph, then its planar dual is a bipartite graph"". Can anyone explain me why it is true.
Thanks in advance for the help.</p>
",graph_theory
"<p>I am interested in exhaustively rendering quartic (4-regular) simple graphs of increasing order and bi-colored black and white such that the closed neighborhood of each vertex contains an even number of black vertices. Here, the closed neighborhood of a vertex is defined as the vertex itself plus its adjacent vertices. </p>

<p>A non-trivial (not 'all white') example is provided by the quartic graph of order five ($K_5$, the complete graph with 5 vertices) with two or four vertices colored black and the remaining ones colored white. </p>

<p>How to generate non-trivial graphs of higher order? Can this be done exhaustively?</p>
",graph_theory
"<p>I really don't understand this definition from <a href=""http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.69.3223"" rel=""nofollow"">this</a> paper which is: </p>

<p>$A-bridge$: if $A \subseteq V(G)$, then an $A-bridge$ of $G$ is either an edge joining two vertices of $A$ or an edge-maximal sub-graph $H$ of $G$ that does not contain an edge between two vertices of $H$ and such that there is a path between any two vertices of $H$ with all its inner vertices distinct from the vertices of A.</p>

<p>Another thing to add is,that all the graphs in this paper are series parallel graphs.</p>

<p>It would be great to clarify this definition with some pictures or reference to some good sources!</p>
",graph_theory
"<p>Let $G$ be a <a href=""http://en.wikipedia.org/wiki/Directed_graph"" rel=""nofollow"">directed graph</a> and $A$ the corresponding <a href=""http://en.wikipedia.org/wiki/Adjacency_matrix"" rel=""nofollow"">adjacency matrix</a>. I'll denote with $\rho$ the <a href=""http://en.wikipedia.org/wiki/Adjacency_matrix"" rel=""nofollow"">spectral radius</a>, and with $I$ the <a href=""http://en.wikipedia.org/wiki/Identity_matrix"" rel=""nofollow"">identity matrix</a>.</p>

<p>What can we say about $G$ when the spectral radius of $A$ is less then $1$? Is there eny graph property what show us that fact? More general which is equivalent to it?</p>

<p>I know that this is spectral graph theory topic, but I'm not an expert in this field. I know that classic result, that $[A^k]_{ij}$ shows the $k$ length walks from $i$ to $j$, and when $\rho(A) &lt; 1$, then exist $(I-A)^{-1}$, and the <a href=""http://en.wikipedia.org/wiki/Neumann_series"" rel=""nofollow"">Neumann-series</a> of $A$ converges to it. Furthermore because $A$ is nonnegative $\rho(A)=\lambda_{\max}$ without abolute value, and $(I-A)^{-1}$ is also nonnegative. That's all I know. Is there any result, that say some graph property which is equivalent to $\rho(A)&lt;1\,$?</p>
",graph_theory
"<p>In the plane, Euler's Polyhedral formula tells us that $V - E + F = \chi$, where for graph embeddings we have that $\chi = 1$. Alternatively, we can think of a graph embedding as a simplicial $1$-complex embedded in the plane.</p>

<p>My question is about if there exists a straightforward generalization of the value of the Euler characteristic to higher dimensions. In particular, for a graph embedded in 3-space, or equivalently a simplicial 2-complex or simplicial 3-complex embedded in $\mathbb{E}^3$, is there a simple expression that defines the Euler characteristic as a constant value, as there is for the plane? (namely $\chi =1$).</p>

<p>Thank you!</p>

<p>EDIT: I am aware that there is a general formula for $\chi$ if you know the number of faces of a given dimension, I am looking to determine those faces by knowing what the Euler characteristic is from external information.</p>
",graph_theory
"<p>I have a dense, adjacency matrix (square, symmetric) representing a graph. I want to threshold that graph so that it only contains the largest weights (cells in the matrix), but is still fully connected. Do you know of any fast algorithms?</p>
",graph_theory
"<p>I have difficulties understanding the proof given below showing that there exist 2 distinct vertices $u,v$ in $G$  such that $d(u) = d(v)$ where $G$ is a non-trivial graph.</p>

<p>Proof:
It's clear that $0 \leq d(x) \leq n-1$ for each $x \in G$. If the above statement is false, then there exist 2 vertices $y$ and $z$ in $G$ such that $d(y) = 0$ and $d(z)=n-1$, which however is impossible.  </p>

<p>I'm not sure how they deduce from the falsity of $0 \leq d(x) \leq n-1$ that there exist 2 vertices $y$ and $z$ in $G$ such that $d(y) = 0$ and $d(z)=n-1$.</p>
",graph_theory
"<p>Consider a simple lazy random walk on an $n$-vertex undirected, connected graph: this is the Markov chain which transitions from $i$ to $j$ with probability $p_{ij}=1/(2d(i))$ where $d(i)$ is the degree of node $i$. Note that $p_{ii}=1/2$ for all $i$.  Define $C(i)$ be the expected time until a walk starting from node $i$ visits every vertex and let $C = \max_i C(i)$. Let $I(k,l)$ be the expected time until two random walks, starting at vertices $k$ and $l$, intersect (i.e., until they visit the same vertex at the same time). Let $I = \max_{k,l} I(k,l)$.</p>

<p>My question is: how big can $I/C$ get as a function of the number of vertices $n$? Is it true that $I/C$ is upper bounded by a constant which is independent of $n$ or of the graph? If not, is it true that $$ \frac{I}{C} \leq k \log^l n$$ for some constants $k,l$ independent of $n$ and of the graph? </p>
",graph_theory
"<p>What formula would find the number of vertices within a 'normal' hexagonal graph, based on its radius (number of hexagons from center to edge)?</p>

<p>I've figured with pseudo code:</p>

<p><code>for (int i = 0; i &lt; r; i++)
{
   vertices += ((r + i) * 2) + 1;
}
vertices = vertices * 2;</code></p>

<p>Given the graph below, with a radius of 2, the above results in:</p>

<p>([((2 + 0) *2) +1] + [((2 + 1) *2) +1]) *2 = 24</p>

<p><img src=""http://i.stack.imgur.com/O5KMM.png"" alt=""enter image description here""></p>

<p>So... Is there a formula that can do this for a radius of n?</p>

<p>Or, given V - F + E = 2, and knowing F = (3* r^2) - (3* r) + 1; a formula to derive the number of edges would work just as well.</p>

<p>Thanks in advance!!</p>
",graph_theory
"<p>I am currently studying Graph Theory and want to know the difference in between Path , Cycle and Circuit. </p>

<p>I know the difference between Path and the cycle but What is the Circuit actually mean. </p>
",graph_theory
"<p>The <a href=""https://en.wikipedia.org/wiki/Hemi-dodecahedron"" rel=""nofollow"">Hemi-dodecahedron</a> can be nicely represented in five dimensions.  Here are the six faces, where all edges have length 2.  </p>

<p>{{{0,0,0,1,1},{1,1,0,0,0},{0,0,1,1,0},{1,0,0,0,1},{0,1,1,0,0}},<br>
{{1,1,0,0,0},{0,0,1,1,0},{0,1,0,0,1},{1,0,0,1,0},{0,0,1,0,1}},<br>
{{1,0,1,0,0},{0,1,0,1,0},{1,0,0,0,1},{0,0,1,1,0},{0,1,0,0,1}},<br>
{{0,1,1,0,0},{1,0,0,1,0},{0,0,1,0,1},{0,1,0,1,0},{1,0,0,0,1}},<br>
{{0,0,0,1,1},{0,1,1,0,0},{1,0,0,1,0},{0,1,0,0,1},{1,0,1,0,0}},<br>
{{0,0,0,1,1},{1,1,0,0,0},{0,0,1,0,1},{0,1,0,1,0},{1,0,1,0,0}}}    </p>

<p>Is there a nice set of coordinates in 4D or 5D (or higher) for the <a href=""https://en.wikipedia.org/wiki/57-cell"" rel=""nofollow"">57-cell</a>?  Could the above hemi-dodecahedron be used as one of the cells?</p>

<p>EDIT:  In 4D, these coordinates can be used for the six faces of the hemi-dodecahedron / Petersen graph. All edges have length 1, and the angle between edges is always 3/4. But I'm still unclear on how to glue these cells together.</p>

<p>$$(  
((\sqrt{5},1,1,1),(0,0,-2,0),(\sqrt{5},-1,1,-1),(0,0,0,2),(0,0,0,-2)),  
((\sqrt{5},1,1,1),(0,-2,0,0),(\sqrt{5},1,-1,-1),(0,0,2,0),(0,0,-2,0)),    
((\sqrt{5},1,-1,-1),(0,0,2,0),(\sqrt{5},-1,-1,1),(0,0,0,-2),(0,0,0,2)),    
((\sqrt{5},-1,1,-1),(0,0,0,2),(\sqrt{5},1,-1,-1),(0,-2,0,0),(0,2,0,0)),    
((\sqrt{5},-1,-1,1),(0,0,0,-2),(\sqrt{5},1,1,1),(0,-2,0,0),(0,2,0,0)),    
((\sqrt{5},-1,-1,1),(0,2,0,0),(\sqrt{5},-1,1,-1),(0,0,-2,0),(0,0,2,0)))/4$$</p>
",graph_theory
"<p>I received a review of one of my papers in which the reviewer made an objection:</p>

<p>""...from the equations e(G) = v(G) you derive that there is a unique simple cycle of G. This is false for non-simple graphs (with loops).""</p>

<p>Here e(G) and v(G) are the number of edges and vertices of the graph, respectively. G is assumed to be connected.</p>

<p>I think the definition of a simple cycle is a path that begins and ends at the same vertex and does not repeat any vertices or edges (and uniqueness is up to cyclic permutation, i.e., the starting point doesn't matter).</p>

<p>I can't think of any counterexample even when I allow multiple edges between vertices, or loops (an edge from a vertex to itself). In fact, I feel like this should be easy to prove. Am I missing something?</p>
",graph_theory
"<p>I never worked in this field before, I just thought about this set of rules and never saw something similar before. I apologise if I don't use the right mathematical vocabulary for my question.</p>

<p>Imagine a graph, in which bulbs are linked. The light can whether be <strong>on</strong> or <strong>off</strong>.
Bounds between bulbs are one-way. But more than one bound between two bulbs are possible.</p>

<p><img src=""http://i.stack.imgur.com/mHmwF.png"" alt=""Quick example of connected bulbs lighten or not""></p>

<p>Then there is this rule : Each time the clock ticks, the bulbs who receive light from at least two alight bulbs become lit too. The others are turned off.</p>

<p>For example, the previous graph will, the next time the clock ticks, become like this :
<img src=""http://i.stack.imgur.com/NFINq.png"" alt=""Next tick""></p>

<p>And then it will become : <img src=""http://i.stack.imgur.com/a26J0.png"" alt=""enter image description here""></p>

<p>I made a quick search, but I'm not used to the mathematical vocabulary of this field but I'm pretty sure it exists. Then I studied this... ""set of rules"" a little bit.</p>

<p>Before the question, here are some interesting and maybe useful circuits.</p>

<p>This narcissistic bulb will never get off, because it's connected to itself by two bounds.
<img src=""http://i.stack.imgur.com/WHfom.png"" alt=""Narcissistic turned on bulb (wow)""></p>

<p>This is an AND gate because, the bulb C will be lit (after 1 cycle) if and if only the bulb A AND the bulb B are lit.</p>

<p><img src=""http://i.stack.imgur.com/9MXZ8.png"" alt=""AND gate""></p>

<p>This is an OR gate because, the bulb C will be lit (after 1 cycle) if and if only the bulb A OR the bulb B is lit.</p>

<p><img src=""http://i.stack.imgur.com/A16wE.png"" alt=""OR gate""></p>

<p>I wanted to determine if I could build a computer with this set of rules. This is why I tried to determine the classical logic Boolean gates. But the NOT gate is essential to Boolean arithmetic, and I can't think of a way to create it or to prove it's impossible.</p>

<p>A NOT gate is supposed to be a circuit where if a bulb A is lit, then after a predetermined clock ticks, the bulb B will be off, and if A is off, B will be lit. A kind of inverter.</p>

<p>My questions are : </p>

<ul>
<li>How is this field named in mathematics ?</li>
<li>Is it possible to create a NOT gate ?</li>
</ul>
",graph_theory
"<p>Given a set of vertices $\{x_\alpha\}$ whose cardinality exceeds $\aleph_1$, (assume the axiom of choice) connect each vertex with its successor by an edge, forming a linear graph. Choose two vertices $x_i$ and $x_j$ such that $card\{x|x_i \lt x \lt x_j\} \gt \aleph_1$. On one hand, it is impossible to construct a path corresponding to the edge path from $x_i$ to $x_j$, since there does not exist a continuous, surjective map $\mathcal f: \mathbf I \to \mathbf S$, from the unit interval to the subgraph $\mathbf S$ between $x_i$ and $x_j$. On the other hand, the graph is connected and locally path-connected, and thereby path-connected, so that there must exist a path from $x_i$ to $x_j$, a contradiction.</p>
",graph_theory
"<p>A cycle on n vertices has n maximum cliques (i.e. K_2). [Except n=3] </p>

<p>Can you do better than this? </p>
",graph_theory
"<p>Given a graph $G$ on $n$ vertices and $m$ edges a standard existence proof for a cut of size $\geq \frac{m}{2}$ is to randomly assign vertices to a cut $S\subseteq G(V)$ and then in expectation half of the edges cross the cut from $S$ to $\bar{S}.$ Again using a similar (or perhaps even the same) randomized method, how does one increase the existence bound to $\frac{mn}{(2n-1)}$? I've attempted using the same vertex assignment scheme but have not been able to improve upon $\frac{m}{2}.$</p>
",graph_theory
"<p>Let $G$ be a $k$-connected graph. An $x,U$-fan is a set $U\subseteq V(G)$ of size $|U|\ge k$ together with a vertex $x\in V(G)\backslash U$ and a set of disjoint $x,U$-paths whose only common vertex is $x$. The number of disjoint $x,U$-paths is the size of the $x,U$-fan.</p>

<p>The problem is to show that in a $k$-connected graph there is always an $x,U$-fan of size $k$.</p>

<p>I was thinking induction over $k$, but the inductive step is rather messy.</p>
",graph_theory
"<p>What is the meaning of the term ""edge percolation""? </p>

<p>Context is graph theory, specifically, random graphs. In general, what does ""percolation"" mean in the context of random graphs?</p>

<p>Thanks.</p>
",graph_theory
"<p>Let $T_{1},T_{2}$ be two trees lying inside some common larger graph, say $G$. Under the hypothesis that $T_{1}\cap T_{2}$ is connected, is the union $T_{1}\cup T_{2}$ also a tree? This seems 'right' to me, but I've been unable to provide a proof of this intuitively 'right' assertion. Please help!</p>
",graph_theory
"<p>![image]<a href=""https://www.dropbox.com/s/o5ybtns0qd7t4b4/s.png?dl=0"" rel=""nofollow"">https://www.dropbox.com/s/o5ybtns0qd7t4b4/s.png?dl=0</a></p>

<p>Give an example of a Eulerian Path of the graph that starts at A</p>

<p>Isn't the graph Eulerian if it has 2 odd number of degrees?
when i counted the degrees they were all 4 so how do calculate the eulerian path?</p>
",graph_theory
"<p>What freely available graph theory resources are there on the web? In particular, I am interested in books and lecture notes containing topics such as trees, connectivity, planar graphs, the probabilistic method ect., though no resources is expected to be comprehensive. </p>

<p>Note that I have searched MathOnline, which yielded the book Graph Theory by Reinhard Diestel. This resources seems to be good, but I prefer to have multiple resources when studying a topic.</p>

<p>Note: I am aware of the many questions on this site regarding book suggestions for particular topics. While this question is related, I am only interested in freely available resources, as I am a broke college student. </p>
",graph_theory
"<p>I'm reading the book Probabilistic Graphical Models (Koller and Friedamn). I'm not quite sure about this example:</p>

<p>Given the next graph:</p>

<p><a href=""http://i.stack.imgur.com/DIzDz.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/DIzDz.jpg"" alt=""enter image description here""></a></p>

<p>The updwardly closed subgraph K+[C] is:</p>

<p><a href=""http://i.stack.imgur.com/ADoTz.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/ADoTz.png"" alt=""enter image description here""></a></p>

<p>I don't get it. I understand why nodes A and D are present but why B and E? Thanks.</p>

<p><strong>EDIT</strong>: Definition of upwardly closed subgraph</p>

<p><a href=""http://i.stack.imgur.com/clA6E.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/clA6E.png"" alt=""enter image description here""></a></p>
",graph_theory
"<p>Can someone please point me in the direction of any theory on graphs where the edge weights are not scalars but represent some relation between the nodes that is a simple function of a single variable (simple, say piecewise linear). </p>

<p>In particular, I'm interested in various basic graph properties and also thinking of the graph as representing a network. So, for example, if the graph represented a communication network over time then the edge weights would be a function represented connectivity as a function of time, how do you find a valid path between nodes? I'm looking for help both on specific algorithms but also general theory if it exists?</p>

<p>I'm aware of time-extended networks where you explicitly expand out the dependence on the variable but, from what I've read, this incomplete and of limited applicability. </p>
",graph_theory
"<p>In my book, it's written that the following are equivalent. I don't understand why it is so. </p>

<ul>
<li>G is bipartite;</li>
<li>G is 2-colourable;</li>
<li>G does not contain any odd length cycles.</li>
</ul>
",graph_theory
"<p>Given $n$, what is the smallest number $N=N(n)$ with the property that there exists a tree on $N$ (unlabelled) vertices that contains a copy of every tree on $n$ vertices?</p>

<p>That such $N$ must exist is easy to see in a number of ways.</p>
",graph_theory
"<p>Is there any intuition behind Cayley's formula $n^{n-2}$ for the number of spanning trees of a graph?</p>
",graph_theory
"<p>Let $G$ be a graph with $n$ vertices, whose average degree is $k$. What is the probability that between any two vertices, there exists a path of length at most $l$? 
NOTE: For the above problem the random graphs follow a $G(n, p)$ model, i.e., in a random graph, each edge occurs with a probability $p=k/n$.</p>
",graph_theory
"<p>To show that 2-colorable belongs to $\mathsf P$, I have a straightforward mental description in mind that I don't think will be considered as a formal proof. Hence I am interested to know how this must be said as an answer to this question. Here's what I think: Say we have 2 colors and n vertices. 2-coloring will be applied such that no two adjacent vertices have the same color. If a vertex is in color A, the other is B and so on. Is my reasoning correct?</p>

<p><strong>Appendix:</strong> A graph G is said to be k-colourable if and only if a k-colouring of G exists.</p>

<p>A k-colouring is an assignment of k colours to the vertices of a graph G such that no edge joins two vertices of the same colour.</p>
",graph_theory
"<p>Is there any undergraduate textbook on graph theory using linear algebra? A request is a beginning with graph matrices that explain most concepts in graph theory? </p>

<p><em>P.s. This thread has more specific requests than this thread <a href=""http://math.stackexchange.com/questions/27480/what-are-good-books-to-learn-graph-theory"">What are good books to learn graph theory?</a>.</em></p>
",graph_theory
"<p>I am trying to work with graphs in MAGMA, but to my surprise I noticed that the vertices of the graph are no longer considered elements of the set I started with.
Here is an example:</p>

<p>X:={1.. 13};
g:=Graph&lt; X | { {u,v} : u,v in X |(u-v)^6 mod 13 eq 1}>;
Random(Vertices(g)) in X;</p>

<p>The output is:</p>

<p>Runtime error in 'in': No valid universe containing all elements</p>

<p>This is a bit unfortunate for my purposes, because I want to construct cliques and cocliques and then compare this to other structural relations in the original set.
How can I solve this?</p>

<p>Many thanks,
Kind regards</p>
",graph_theory
"<p>Let $G_n$ denote the $2^n$ vertices graph in which every vertex is labeled with a string of $n$ bits. A pair of vertices are adjacent if and only if their bit strings differ in exactly 3 digits.</p>

<blockquote>
  <p>i)Show $G_4\simeq Q_4$ where $Q_n$ denotes the <a href=""http://mathworld.wolfram.com/HypercubeGraph.html"" rel=""nofollow"">hypercube graph</a>.</p>
  
  <p>ii) Decide if true or false. Prove or give a counterexample: $G_n$ is bipartite for all $n\geq 4$.</p>
</blockquote>

<p><strong>Attempt:</strong></p>

<p>For $i)$ what I did was to draw both graphs and tried to find an isomorphism, although I obviously couldn't get it right (pretty hard with 16 vertices), is there a simpler way?</p>

<p>For $ii)$ I drew $G_4$ and saw it was bipartite, so then I tried to use induction on the number of vertices, but I couldn't get it right either.</p>
",graph_theory
"<p>Suppose that we have a decision tree of height $r + 1$ that describes how to increment an $n$-bit integer in the range $[0, 2^n -1]$. That is, the internal nodes are labelled with a bit position that you read, then depending on its value, you either go left or right and proceed to read the next bit indicated. The leaf nodes are labelled with a set of bits that are flipped to perform the increment operation. Note that the sequence of integers may not be the traditional Standard Binary Code, but could be any cyclic sequence of the $2^n$ integers. A Gray Code is another example of a sequence that may be produced (which corresponds to a Hamiltonian cycle in the hypercube graph).</p>

<p>Now, consider the root to ""right before"" leaf paths as sets of size $r$ from a universe of size $n$. I am trying to argue the following claim: Suppose that the root node of our decision tree is labelled by index $i$. If we take the paths on the left side of the tree (when $i$ is read as  $0$) such that bit $i$ is not flipped, together with the paths on the right side of the tree (when $i$ is read as $1$) such that bit $i$ is flipped, then I am interested in bounding the size of the common intersection of those sets. In particular, we know that every set will contain index $i$ since it sits at our root node, but I would like to show that these sets must also have another bit in common.</p>

<p>I know that I do not want to use the sunflower lemma, as these sets may not have the same pairwise intersection, but I believe that I may be interested in something similar that characterizes the global intersection of all of these sets). Perhaps it may help to view the problem as a hypergraph, though I am not sure of results that may be of use. The other thing to note is that these are not arbitrary sets, as they are derived from a decision tree for increment integers, so there is a lot of structure involved.</p>

<p>Any help would be greatly appreciated, whether it's some guidance on how to prove this, or perhaps references to potentially useful theorems.</p>

<p>Edit: If it helps, we can restrict our attention to when $r = n - 1$, though I am ultimately interested in the general case as well.</p>
",graph_theory
"<p>In this particular question I'm asked to find all the isomorphism classes of simple graphs, without loops whose degree sequence is: $3,3,2,2,2$, and to prove the ones I found are all the ones that exist.</p>

<p>I don't know how to do this, and I want to learn how to solve these kind of questions. Also, if I'm given the amount of vertices and edges, is there a closed form for the amount of isomorphism classes?</p>
",graph_theory
"<p><strong>Question:</strong></p>

<blockquote>
  <p>Prove the statement:</p>
  
  <p>If $G$ is a  connected graph with no cycles, then it has at least two vertices with degree 1.</p>
</blockquote>

<p>This seems pretty obvious, as if the graph has no cycles then it must have 2 ""endpoints"" which must have degree $1$, but obviously enough this is nothing quite like a proof.</p>

<p>E: The question didn't actually said the graph had no loops or that it was simple, I accidentally added that in.</p>
",graph_theory
"<ol>
<li><p>Let $G=(V,E)$ be a graph with $|V|=n$. Prove that $G$ is connected if $d(v)\geq \frac{n-1}{2}$ for all $v\in V$.</p></li>
<li><p>Let $G=(V,E)$ be a graph with $|V|=n$ and $|E|=m$. Prove that $\min\limits_{u\in V} d(u) \leq 2\dfrac{m}{n}\leq \max\limits_{v\in V}d(v)$.</p></li>
</ol>

<hr>

<p>My attempts:</p>

<ol>
<li><p>$|E|\leq n(n-1)$ since every node can have at most $n-1$ edges, and there are $n$        nodes in total. Hence making use of the formula $\sum\limits_{v\in V}d(v)=2|E|$, we obtain $\sum\limits_{v\in V}d(v)\leq 2n(n-1)$. I don't know how to proceed from here.</p></li>
<li><p>All I can come up with is that $\max\limits_{v\in V}d(v)=n-1$. I don't think this helps me though.</p></li>
</ol>

<hr>

<p>Could anyone please provide any additional hints to these problems? Thank you in advance</p>
",graph_theory
"<p>According to wikipedia, the Traveling Salesman Problem (TSP) is:</p>

<blockquote>
  <p>Given a list of cities and the distances between each pair of cities,
  what is the shortest possible route that visits each city exactly once
  and returns to the origin city?</p>
</blockquote>

<p>Okay, that's a cool problem, but the part about ""visiting each city exactly once"" makes little sense to me. If I were a traveling salesman, I would just want to minimize the length (time, cost, whatever) of my route, and if visiting the same city $17$ times achieves this (say, because that city has an especially ""central"" position in the graph) then so be it. There seems to be little sense in restricting attention to Hamiltonian cycles (i.e. cycles in which each vertex occurs precisely once); in particular, I would imagine that this restriction simultaneously makes the problem harder (computationally) and also less applicable (e.g. to problems ""from the real world."")</p>

<p>Wikipedia goes on to say that:</p>

<blockquote>
  <p>The problem was first formulated in 1930 and is one of the most
  intensively studied problems in optimization.</p>
</blockquote>

<p>In light of my previous comments, I find this surprising.</p>

<blockquote>
  <p><strong>Question.</strong> Why has the TSP been so intensively studied, while the variant (which I find more natural) has apparently received much less
  attention?</p>
  
  <p>In simple terms: why visit each city only once?</p>
</blockquote>

<p>Let me just add that according to wikipedia, the general problem does not include the assumption that the triangle inequality holds; that special case is called the <a href=""http://en.wikipedia.org/wiki/Travelling_salesman_problem#Metric_TSP"" rel=""nofollow"">metric TSP</a>. In this case, the restriction to Hamiltonian cycles is of course innocuous. </p>
",graph_theory
"<p>I am having quite a hard-time with this question, been thinking about it for a few hours and have not got a clue on how to even start proving this, because it is trivial but proving it has been hard for me.</p>

<blockquote>
  <p>Given two forests $F_1 = (V,A)$ and $F_2 = (V,B)$ with same vertices group $V$. It is also given that $|B| &gt; |A|$. Prove: there exists an edge $e \in B \backslash A$ where $F_1 \cup \{e\}$ is still a forest.</p>
</blockquote>

<p>Any help will be appreciated!</p>
",graph_theory
"<p>In real world networks, we have no further information about the structure of the networks. For example, in the Facebook network, we assume each one has some known particular probabilities to influence his friends. But how can we know the probability that I influence some guy who is randomly selected in the network?</p>

<p>If the network is like a chain, or like a complete graph and all the probabilities are equal, it seems easy. However, in a real world network, it is usually not the case.</p>

<p>I mean, how can classical random graph theory be applied to real world networks? Maybe I have fallen into a trap. I am not sure if such question is legal to ask here. But I am very interested about how to deal with the gap between theoretical things with real world things.</p>
",graph_theory
"<p>This might come across as a slightly petty question. Apologies for this, I am only asking as I have an exam on Graph Theory soon and want to make sure I do things correctly.</p>

<p>The definition of a Hamilton path is a path which includes every vertex of the graph exactly once.</p>

<p>The definition of a circuit is a path whose first and last vertices are the same.</p>

<p>A Hamilton circuit is a Hamilton path which is a circuit.</p>

<p>Question - isn't this a contradiction (it is supposed to include every vertex exactly once but then include the initial vertex twice)? What exception on these rules is brought in so it isn't contradictory?</p>

<p>Furthermore, if I wanted to quote a Hamilton circuit in the undirected and unweighted cyclic graph G, with vertices a,b,c where edges are { (a,b) , (b,c) , (c,a) } - would I quote the Hamilton circuit as abca or abc ?</p>

<p>Thanks for any help on this.</p>
",graph_theory
"<p>How to partition $n$ weighted elements into $m$ disjoint subsets such that the sum of weight of all elements in a subset is less than equals to the capacity of $j$th subset ($c_j$) . It is given that $m&lt;n$</p>

<p>Example:
$x_1,x_2,x_3$ are weights of 3 elements (here $n=3$). Divide these 3 elements into 2 subsets (here $m=2$) such that the $sum(X_1)&lt;= c_1$ and $sum(X_2)&lt;= c_2$. Here $sum(X_1)$ and $sum(X_2)$ are the summation of weights of all elements in subset 1 and 2 respectively.</p>

<p>The answer of the given problem is ($x_1,x_3$),($x_2$) if $x_1+x_3&lt;=c_1$ and $x_2&lt;=c_2$             </p>
",graph_theory
"<p>Find an example of a regular triangle-free $4$-chromatic graph</p>

<p>I know that for every $k \geq 3$ there exists a triangle-free $k$-chromatic graph.</p>

<p>So if I can find a triangle-free graph $H$ such that $\chi(H)=3$, then I can use the Mycielski construction to obtain a triangle-free graph $G$ such that $\chi(G)=4$. However, the regular part keep getting me stuck. I try some odd cycle, I also tried the Petersen graph but still can't get a regular triangle-free $4$-chromatic graph.</p>

<p>I wonder if anyone can give me a hint, please.</p>
",graph_theory
"<p>Let $k$ be the maximum length of a path in a connected graph $G$. If $P, Q$ are paths of
length $k$ in $G$, prove that $P$ and $Q$ have a common vertex. </p>

<p>My solution:</p>

<p>Suppose that $P$ and $Q$ are vertex disjoint. Let $P = (u_1, u_2,...,u_k)$ and $Q = (v_1, v_2,...,v_k)$. Let $S = (u_i = w_1, w_2,...,w_l = v_j)$ be the shortest path form a vertex in $P$ to a vertex in $Q$. This path exists because $G$ is connected. $w_2, w_3,...,w_{l-1}$ are not vertices in $P$ and $Q$ since $S$ is the shortest path. Assume that $i, j &gt;= k/2$. The path $u_1, u_2,..., u_i, w_2,..., w_{l-1}, u_j, u_{j-1},..., u_1$ has length at least $i + j + 1 &gt;= k + 1$. And therefore a contradiction. </p>

<p>Is this correct?</p>
",graph_theory
"<p>I'm currently trying to solve this problem:</p>

<p>""Show that the number of isomorphism classes of tree on n vertices is at least $\frac{n^{n-2}}{n!}$.""</p>

<p>I'm pretty stumped to be honest.  I know of Cayley's formula; there are $n^{n-2}$ trees on n labelled vertices, so I'm guessing that this may come in handy.  </p>

<p>One idea I had was to find the most number of isomorphism classes.  This, I believe, should be n-2, for $n \geq 2$, and 1, for $n=0, 1$.  But then I don't particularly think this would be of any use or would lead to a very forced way to prove it.</p>

<p>Any hints / ideas? 
Thanks!</p>
",graph_theory
"<p>I'm having a bit of a problem with producing a venn diagram of this relationship. I have three circles:  $U$, $V$, $W$. The identity I have to create is:</p>

<p>$$( U \setminus V ) \setminus W = U \setminus ( V \cup W)$$</p>

<p>I thought the shaded region would be the parts that are only in $U$, but that really seems like a wrong answer. Can someone help me out? Cheers</p>
",graph_theory
"<p>A function $f$ is defined on the set $\{0,1,2,3,…,n-1\}$ to itself. This is a function such that if you take any $k$ from the set $\{0,1,2,3,…,n-1\}$ then $f^m (k)=0$ for some natural number $m$. </p>

<blockquote>
  <p>Question is how many such $f$ exist? </p>
</blockquote>

<p>My strong conviction about the answer is $n^{n-1}$. </p>

<p>If it is, how can we prove this. I need the proof.</p>
",graph_theory
"<p>Determine if there exists a graph whose degree sequence is the one specified. Draw a graph, or explain why no graph exists. The sequence is 5,4,3,2,1,1</p>
",graph_theory
"<p>I realize this is a quite a general request. I'm just looking for examples of path searching algorithms for directed graphs which are capable of utilizing simple modifications (adding vertices, adding edges, deleting edges; all from a set of specific allowed modifications). I've been looking everywhere online for information on dynamic algorithms for graphs, but so far almost everything I've found is almost exclusively concerning run time of such algorithms. Run time is irrelevant to me as there are very few modifications that are allowed to be made in the problem I'm working on. Does anyone know of any algorithms like this? </p>
",graph_theory
"<p>I'm reading Bondy and Murthy's <em>Graph Theory</em>, and I'm doing the proposed exercise in the title. I've tried to do the following:</p>

<blockquote>
  <p>$m$: Edges</p>
  
  <p>$n$: Vertices</p>
</blockquote>

<p>A simple graph with $n$ vertices has a maximum of $m=(n-1)+(n-2)+\dots+(n-n)$ and hence </p>

<p>$$m=(n-1)n-\frac{(n-1)(n)}{2}=\frac{n^2-n}{2}$$</p>

<p>Which is $(n-1)$ times the number of $n$'s and the sum of the first $(n-1)$ natural numbers. Knowing that the maximum number of edges in a simple graph is ${n \choose 2}$, we can write:</p>

<p>$$\begin{eqnarray*}
  {m}&amp;\leq&amp;{{n \choose 2}}\\
  {}&amp;&amp;{}\\
  {\frac{n^2-n}{2}}&amp;\leq&amp;{\frac{n!}{2(n-2)}}\\
  {}&amp;&amp;{}\\
  {n^2-n}&amp;\leq&amp;{\frac{n!}{(n-2)!}}\\
  {}&amp;&amp;{}\\
  {n^2-n}&amp;\leq&amp;{n \cdot (n-1)}\\
  {}&amp;&amp;{}\\
  {n^2-n}&amp;\leq&amp;{n^2-n}\\
  {}&amp;&amp;{}\\
  {n^2-n}&amp;\leq&amp;{n^2-n}
\end{eqnarray*}$$</p>
",graph_theory
"<p>Here's the proof: <a href=""http://www.cs.cornell.edu/courses/CS6820/2014fa/matchingNotes.pdf"" rel=""nofollow"">http://www.cs.cornell.edu/courses/CS6820/2014fa/matchingNotes.pdf</a></p>

<p>What I don't understand is why ""For an edge f there can be f(e) for up to at most two edges e, conflicting with edge f at the two different ends.""</p>
",graph_theory
"<p>This question seems similar to <a href=""http://math.stackexchange.com/questions/354551/is-a-loop-actually-a-circuit"">Is a loop actually a circuit?</a> but it is different. The linked question refers to a undirectional graph so the vertex of the self-loop ends up with degree 2. Also the linked question talks about circuits which might not be same as a cycle.</p>
",graph_theory
"<p>I saw in my graph theory notes this statement ""Up to isomorphism, there is one and only one $K_4$"". What does the phrase ""up to isomorphism"" mean? </p>
",graph_theory
"<p>[HOMEWORK]</p>

<p>I asked my professor and he said that a counter example would be two nodes, by which the pathw ould go from one node and back. this would be a closed path but does not contain a cycle. But I am confused after looking at this again. Why is this not a cycle? Need there be another node?</p>
",graph_theory
"<p>It is stated that path exists between two vertices. </p>

<p>My idea is that if there is a direct path from source to vertex then the length is 1 which is less than n. But we need the minimum path to be as maximum as possible to disprove the statement.
So we include as many vertices as possible in the path. The maximum can be n. If all n are included in the path, then a simple path would have n-1 length. We can't go any longer than that. So, it is proved. 
Can you help me present this formally? And also please correct any mistakes I may have in my idea.</p>

<p>n is the number of vertices.</p>
",graph_theory
"<p>I have noticed a recurring theme in Graph Theory / Theoretical Computer Science (abbreviated GT and TCS throughout this post) in that notions typically belonging to differential calculus / geometry / topology are ""discretized"" (by which I mean ""reformulated for a discrete-mathematical setting"") to be used for the service of GT/TCS. Examples include:</p>

<ul>
<li>Discrete Morse Theory, which has been useful in the analysis of Boolean functions,</li>
<li>The Laplacian matrix, which carries a lot of worthwhile algebro-graphtheoretical properties,</li>
<li>The Cheeger constant for graphs, which is useful in the theory of expander graphs, as well as in the theory of distributed computing.</li>
</ul>

<p>Of course these are based on, respectively, the usual Morse Theory, the Laplace operator, and the Cheeger constant from Riemannian geometry.</p>

<p>My (soft) question is simple: Are there any other cases in GT, TCS or discrete math in general where this type of discretization has occurred? And why are those notions useful discretized? </p>

<p>For example, the Cheeger constant measures the ""bottle-neckedness"" of a graph, which when interpreted as describing a network used for distributed computing gives us limits on how fast we can compute things in a distributed network. The Laplacian is used heavily in algebraic GT / combinatorics and carries analogous structure to the ordinary Laplace operator, and Discrete Morse theory proves powerful theorems based on inequalities and critical points…(ok, I haven't delved too deep into any form of Morse theory yet…).</p>

<p>(Sure, this is a list-based question, but I figure there can't be that many examples to list?) </p>

<p><strong>Additional Examples, suggested by comments:</strong></p>

<ul>
<li>Discrete Fourier Transform / Analysis has many applications in TCS and combinatorics too, and are obviously based on ordinary Fourier analysis.</li>
</ul>
",graph_theory
"<p>Let $G$ be a <strong>connected</strong> graph. Prove that two longest paths in $G$ have atleast one node in common. Note that two longest paths do not neccessarily have the same length.</p>

<p>I began by defining two paths namely $P_1 = &lt;v_1,...,v_k&gt;$ and $P_2 =&lt;u_1,...,u_m&gt;$ where $m\neq k$ because of the note given. Now I state the definition of a conneted graph. </p>

<blockquote>
  <p>A graph G is connected if for each pair of vertices u; v, there is a u; v-walk
  in G.</p>
</blockquote>

<p>now my first intuition is to consider the fact that if no node was shared than connecting the two paths would give a (slightly ?) longer path which would make them not the largest paths. Given the fact that they are the two largest (say $n$ and $n-1$). They should be connected via atleast one node.</p>

<p>HOWEVER it seems odd for me to now state that this is a proof.</p>
",graph_theory
"<p>I am going through <a href=""http://www.sciencedirect.com/science/article/pii/0012365X81902533"" rel=""nofollow"">Degree sequences of random graphs</a> by Béla Bollobás.</p>

<p>On page $3$ the author introduces the quantity $S(n: K, L)$ without any explanation. </p>

<p><a href=""http://i.stack.imgur.com/P0HAj.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/P0HAj.png"" alt=""enter image description here""></a></p>

<p>Could anyone please help me in understanding the significance of the quantity?</p>
",graph_theory
"<p>From wikipedia's page <a href=""http://en.wikipedia.org/wiki/Cage_graph"" rel=""nofollow"">Cage graph</a></p>

<blockquote>
  <p>Formally, an $(r,g)$-graph is defined to be a graph in which each
  vertex has exactly $r$ neighbors, and in which the shortest cycle has
  length exactly $g$. <strong>It is known that an $(r,g)$-graph exists for any
  combination of $r \geq 2$ and $g \geq 3$</strong>.</p>
</blockquote>

<p>Can someone provide a proof of this claim?</p>

<p>Thanks.</p>
",graph_theory
"<p>Suppose we have a graph on $n$ nodes. We would like to assign to each node either a $+1$ or a $-1$. Call this a configuration $\sigma \in \{+1,-1\}^n$. The number of $+1$s that we have to assign is exactly $s$ (hence the number of $-1$s is $n-s$.) Given a configuration $\sigma$, we look at each node $i$ and sum the values assigned to its neighbors, call this $\xi_i(\sigma)$. We then count the number of nodes for which $\xi_i(\sigma)$ is nonnegative:</p>

<p>$$ N(\sigma) := \sum_{i=1}^n 1\{ \xi_i(\sigma) \ge 0\}. $$</p>

<p>The question is: what is the configuration $\sigma$ that maximizes $N(\sigma)$? Can we give a bound on $(\max N)/n$ in terms of $s/n$. If it helps, the graph can be assumed to be Erdos-Renyi.  </p>
",graph_theory
"<p><strong>Why edg-chromatic number of Cartesian product of two graph equal maximum degree of Cartesian product G and H?</strong>
for example G and k2</p>
",graph_theory
"<p>Let $G=(V,E)$ be a graph with $|V|=n$ and $|E|=m$ prove that
$$
\min_{u\in V} \{d(u)\}\leq 2\frac{m}{n}\leq \max_{v\in V} \{ d(v)\} 
$$
now my first intuition is to assume that $\min\limits_{u\in V} \{d(u)\} =0$ holds because it is not a connected graph. And my second assumption is to use $\max\limits_{v\in V} \{ d(v)\} =n -1$ (connected to everything, except it self) , and from another exercise we got</p>

<blockquote>
  <p>$$
d(v)\geq \frac{n-1}{2}
$$</p>
</blockquote>

<p>which could be interpreted as
$$
n-1\leq 2d(v)
$$
which would help in getting the right side, the only thing baffling me at the moment is the $\frac{m}{n}$ part, any intuition on this?</p>
",graph_theory
"<p>I'll appreciate any help in the following question:</p>

<blockquote>
  <p>Let $G=(V,E)$ be a connected undirected finite graph.
  Let $\def\MaxD{\mathrm{MaxD}}\MaxD(v)$ ($v$ is a vertex) be the <em>maximal distance</em> of $v$ from any vertex in $G$.</p>
  
  <p>Prove for every two vertices $v_1$,$v_2 \in V$:
  $\MaxD(v_1)/\MaxD(v_2) \le 2$.</p>
</blockquote>
",graph_theory
"<p>Evan Chen's recount of the Taiwanese IMO team's journey recorded a game the team members played at their free time, which runs as the following:</p>

<p>There are $n$ team members (in the actual case $n=6$ but here we simply take $n\geq2$)Every team member points at another team member (whom must be different from him/herself) and thus we obtain a (directed) graph with $n$ vertices and $n$ edges. It has one more edge than a tree and therefore must contain a cycle. Any member who is a vertex of any cycle in this graph loses the game. (So it is possible that everyone loses but it's impossible that no one loses.)</p>

<p>Assume everyone chooses the person s/he points at randomly, what is the probability of a player losing the game? </p>

<p>Reference: <a href=""http://www.mit.edu/~evanchen/handouts/IMO-2014/IMO-2014.pdf"" rel=""nofollow"">Evan Chen's recount</a></p>
",graph_theory
"<p>I'm trying to show that all graphs with 5 vertices, each of degree 2, are isomorphic to each other.  Is there a more clever way than simply listing them all out?</p>
",graph_theory
"<p>Given is a graph defines a flow network. 
I need to formal proof the following :</p>

<blockquote>
  <p>If we multiply all edge capacities by a positive number $X$, the minimum cut remains unchanged</p>
</blockquote>
",graph_theory
"<p>I believe this is a standard graph theory problem, but I am not sure. I am having a lot of trouble with it though. Give it a go</p>

<p>You have n jelly beans. You want to ship them all to a friend. For 1 ≤ i ≤ m, you can buy any number of boxes, where each box can hold Bi jelly beans. The smallest box fits one bean (b1 = 1). Every box you use must be fully packed. Each box costs a dollar. The goal is to ship your beans with the smallest cost. What is the time and space complexity of finding the optimal solution?</p>

<p>Thanks a lot!</p>
",graph_theory
"<p>I am considering a route planning problem, which I try to model with a graph.
I understand that 
1. to find a shortest path in a graph, we need to know the weights on the edges. 
2. as some places are more desirable to visit than others, we can also have some kind of 'weight' on the nodes. In the case that we want to find a path that maximize the sum of the weights of the nodes passed through, we can convert the original graph to a new one and solve the problem as a shortest path problem in that graph.</p>

<p>I want a way to incorporate both the distance b/w bus stops and the desirability of the bus stops in my consideration of choosing the path. </p>

<ol>
<li>Is there way a sensible way to still model this situation by using a graph? </li>
<li>How can we define the vertices and the edges of this new graph?</li>
<li>What would be the weight function on the edges?</li>
</ol>

<p>edit: Not sure why this gets downvoted. Is the question meaningless or a well-known exercise?</p>
",graph_theory
"<p>A minimally imperfect graph is a graph that is not perfect but all of it's proper induced subgraphs are. I can prove that, when G is a minimally imperfect graph with n vertices: </p>

<ol>
<li><p>alpha(G)omega(G)+1=n (so I have proved the Perfect Graph Theorem) </p></li>
<li><p>G has two sequences S_0,...S_n of maximum stable sets and C_0,...C_n of maximum cliques such that S_i intersects C_j unless i=j. So they come in nonintersecting pair. </p></li>
</ol>

<p><strong><em>Apparently</em></strong>, these are all the maximum stable sets, and maximum cliques. So there are exactly n of each. But how do I prove this? </p>
",graph_theory
"<p>I would like to learn Graph Theory from the beginning. It seems to me that one does not need to be familiar with many abstract type subjects to be able to understand the more basic concepts of graphs.</p>

<ol>
<li><p>Which subjects should one know prior to learn Graph Theory at the introductory level?</p></li>
<li><p>And which book or lecture notes would you advise to learn it? </p></li>
</ol>
",graph_theory
"<p>Given an $n$ by $n$ grid of which some of the squares are black and some are white. I'm allowed to mark some of these squares and the question is to prove whether a given grid with given black squares can meet these conditions:</p>

<p>1) Each column has only one marked square.</p>

<p>2) Each row has only one marked square.</p>

<p>3) Only white squares can be marked.</p>

<p>This is similar to how sudoku can only have the same number on only one column and one row. In fact it's an easier problem. However...</p>

<p>I am struggling to figure out an algorithm that reduces this problem to a max flow network problem.</p>

<p>I'm thinking something along the lines of making each square in the grid a  node in a graph. Then connect your source point to all the white nodes.</p>

<p>I also believe that in the end the way you prove whether such conditions can be met is by whether or not the max flow through this graph is exactly $n$. Because a solution to the above problem requires that there are exactly $n$ marked squares. Any less means that there was a row or column that doesn't have any white square or that there is no way of adding points that end up in distinct rows/columns.</p>
",graph_theory
"<blockquote>
  <p>Must the number of people at the party who do not know an odd number of people be even? Describe a graph model and then answers the question. </p>
</blockquote>

<p>I'm confused because I do not understand the question. For example if we take people to be a vertex, then if there is an edge between them it means that people know each other, 
and the formula is $$\sum d(v) = 2*e$$ $\Rightarrow$ the sum of degrees of all vertices should be even so it means that there should be an even number of vertices. But why in the question is ""people who do not know an odd number of other people be even""..?</p>
",graph_theory
"<p>I'm traying to prove (or disprove) the following statement:</p>

<p>Any connected $r$-regular graph of <a href=""http://en.wikipedia.org/wiki/Girth_%28graph_theory%29"" rel=""nofollow"">girth</a> $g$ such that every edge is shared by the same number of minimum length cycles (that is, cycles of length $g$), is <a href=""http://en.wikipedia.org/wiki/Vertex-transitive_graph"" rel=""nofollow"">vertex-transitive</a> and <a href=""http://en.wikipedia.org/wiki/Edge-transitive_graph"" rel=""nofollow"">edge-transitive</a>.</p>

<p>This is not a textbook exercise. Any ideas appreciated.</p>

<p>Thanks.</p>
",graph_theory
"<p>First of all - what's a directed graph? Is this just some normal graph but with no loops or edges? I don't really understand definitions found in the web...</p>

<p>What is a path? I mean, as far as I know, it is a directed chain, where the chain is a ""path between two vertices, connected anyhow"". Ok, I understand what the chain is, but what is the DIRECTED chain?</p>
",graph_theory
"<p>Let $A$ be a $k$ by $n$ matrix where the rows are permutations of $\{1,2,3,..,n\}$ and in each column all elements are different (i.e columns are subsets of permutations of $\{1,2,3,..,n\}$). 
Show that there exists an $n$ by $n$ matrix $B$ such that each row and column is a permutation of $\{1,2,3,..,n\}$ and its first $k$ rows are the rows of $A$.</p>

<p>I can see that this should be an application of Hall's theorem but I'm having trouble choosing the graph.</p>

<p>Thanks.</p>
",graph_theory
"<p>Let's say you have a graph such that every vertex has exactly 3 edges. You try to number every edge of the graph with either a 0, 1, or 2 so that every vertex has exactly one of each type of edge. Is this always possible to do? </p>
",graph_theory
"<p>Consider a simple graph $G$ with $n$ vertices. For any two vertices, either they are connected by an edge, or there is a third vertex which is connected to both of them by an edge. (It is possible that both conditions hold.) Show that there exists a set $W$ of no more than $\sqrt{n\log n}+1$ vertices such that every vertex in $G$ is connected to some vertex in $W$.</p>

<p>If some vertex $u$ has degree $\leq \sqrt{n\log n}$, then the set of neighbors of $U$ can be seen to satisfy the condition. What if every vertex $u$ has degree $&gt;\sqrt{n\log n}$?</p>
",graph_theory
"<p>For a given order $n$, the number of graphs that are determined uniquely by their  <a href=""http://en.wikipedia.org/wiki/Chromatic_polynomial"" rel=""nofollow"">chromatic polynomial</a> is <a href=""http://oeis.org/A137568"" rel=""nofollow"">A137568</a>. This sequence starting with n=1 is:</p>

<pre><code>1, 2, 4, 7, 16, 41, 139, 704, 7270, 183606
</code></pre>

<p>I am looking for something slightly different, the sequence formed by the number of <strong>distinct chromatic polynomials</strong> for <strong>connected</strong> graphs.</p>
",graph_theory
"<p>Given following graph 
<img src=""http://i.stack.imgur.com/sGmX3.png"" alt=""enter image description here""></p>

<p>a) Find the upper bound for $\chi(G)$ using theorem 8.20</p>

<p>b)What is $\chi(G)$?</p>

<blockquote>
  <p><strong>Theorem 8.20</strong>: For every graph $G$, $\chi(G) \leq 1+\max\{\delta(H)\}$, where maximum is taken over all subgraph $H$ of $G$</p>
</blockquote>

<p>I know that $\chi(G)=5$ so part b) is done. For part a), I'm not quite sure about $\max\{\delta(H)\}$ part, so I need to find the minimum degree in all subgraph $H$ and pick the biggest one? Is $\max\{\delta(H)\}=5$? Do I need to prove it?</p>
",graph_theory
"<p>How many different triangles are there in $K_5$?</p>

<p><a href=""http://i.stack.imgur.com/sOgqv.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/sOgqv.png"" alt=""enter image description here""></a></p>

<p>The Answer is 35.(The Moscow Mathematics Puzzle) </p>

<p>Then I asked what about $K_6$, $K_7$ and so on ...?</p>

<p>With my intuition I arrived at this conjecture   </p>

<blockquote>
  <p>Conjecture: The number of different triangles in a complete graph of order $n$ ($K_n$) is </p>
  
  <p>\begin{cases}
\frac{n^2(n-2)^2(n-1)^2)}{6^2},&amp;\mbox{ where } \binom{n}{3} \mbox{ is odd.}\\
\frac{(n^2-n)(n^2-4)(n^2-5n+12)}{12^2} ,&amp;\mbox{where }\binom{n}{3} \mbox{is even.}
\end{cases}
  What do you say about this?</p>
</blockquote>
",graph_theory
"<p>How to build a 4-regular, vertex-transitive, 'least diameter' graph with $v$ vertices?</p>

<p>This implies to know what is the minimum diameter of a 4-regular vertex-transitive graph with $v$ vertices.</p>

<hr>

<h1>What I found</h1>

<p>If $v &lt;= 4 + 1$, the diameter is $1$, and in the particular case $v = 4 + 1$, the only matching graph is $K_5$.</p>

<p>In the case $v = 6$, the graph shown below matches, with a diameter of $2$. The diameter can't be less than 2, since it would then be 1, meaning every vertex is adjacent to the five others, what contradicts with the 4-regularity.</p>

<p><a href=""http://i.stack.imgur.com/Ao9FL.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/Ao9FL.png"" alt=""4-regular graph with 6 vertices""></a></p>

<p>The cases $v=6,7,8$ and $9$ are diameter 2 as well and can be treated with the same pattern: putting a star in a polygon. Example of star used :</p>

<ul>
<li>6: Two triangles (A double edge between opposed vertices works too)</li>
<li>7: Star formed by jumping over one vertex. (Over two vertices works too)</li>
<li>8: Two squares (The star formed by jumping over two vertices works too)</li>
<li>9: Three triangles (Seems to be the only possibility)</li>
</ul>

<p>For the case $v=10$, the least diameter is 2 too. A matching graph can be obtained  from Petersen graph, by adding parallel edges to the ones linking the pentagon to the central star.</p>
",graph_theory
"<p>In a previous <a href=""http://math.stackexchange.com/questions/1888216/how-can-i-prove-that-left-sum-i-0r-1i-binomai-binomn-ar-i-ri"">question</a> I asked about the maximum module reached by the quantity  $f_{n,r} (a) = \sum_{i=0}^r (-1)^i \binom{a}{i} \binom{n-a}{r-i}$. Now I ask when this maximum value can be reached. </p>

<p>This is a conjecture:</p>

<blockquote>
  <p>How can I prove that the equality</p>
  
  <p>\begin{equation}
\left|\sum_{i=0}^r (-1)^i \binom{a}{i} \binom{n-a}{r-i}\right| = \binom{n}{r}
\end{equation}</p>
  
  <p>where $0\leq a \leq n$, $0\leq r \leq n$ and $n,r,a \in \mathbb{N}$, $\mathbf{r \neq n, r\neq0}$, holds only for $a=0$ and for $a=n$?</p>
</blockquote>

<p>What I'm trying to prove is that for $r$ even I cannot have, for any $0\leq a \leq n$ with $r \neq n, r\neq0$:</p>

<p>\begin{equation}
\sum_{i=0}^r (-1)^i \binom{a}{i} \binom{n-a}{r-i} = - \binom{n}{r}
\end{equation}</p>
",graph_theory
"<p>In spectral graph partition theory, the eigenvector corresponding to the second smallest eigenvalue of the laplacian matrix of a graph, in general, is used to partition the graph. </p>

<p>What is the underlying philosophy behind this? Any reference to any related proofs on this?</p>
",graph_theory
"<p>Let $G$ be a $5$-regular triangulation of the plane. By Euler's formula, $G$ must have $12$ vertices. My question is, how can we conclude that $G$ is isomorphic to the icosahedral graph?</p>
",graph_theory
"<p>For $p$ and $q$ distinct primes.
Two conditions are given:</p>

<p>vertices of graph $G$ are integers in the set $\{0, 1, 2, \ldots, pq-2, pq-1\}$; </p>

<p>there is an edge of graph $G$ between $a$ and $b$ if $ab$ either $p∣a−b$ or $q∣a−b$. In this case, how many edges of $G$ are there?</p>
",graph_theory
"<p>Are graphs with eigenvalue $1$ of multiplicity more than $1$, important one? Please guide me to any book or article discussing such graphs.</p>
",graph_theory
"<p>Given any undirected connected graph. If we redefine the weight of a spanning tree to the maximum weight of an edge (if the largest weight is 10 the weight of the tree is 10) are there any cases where there minimum spanning tree will be different based on this assumption? By this I mean are there any cases where we can use a more costly route in order to have a lower maximum edge weight?</p>
",graph_theory
"<p>An automorphism is a mapping of a graphs nodes onto it's own nodes. Whereas an isomorphism is the mapping of a graphs nodes onto another graphs nodes. </p>

<p>Doesn't this mean the are fundamentally the same thing, it's just a matter of what the nodes are labelled (for example in one graph the nodes may numbered sequentially, but in the other graph they are labelled alphabetically)?</p>

<p>So will the number of automorphisms be the same as the number of isomorphisms?</p>
",graph_theory
"<p>Is there (sufficient and) nessary condition for which a graph $G$ has a homomorphism but no surjective homomorphism to $H$? Where the surjective means both vertex and edge are surjective.</p>

<p>Or say if $H$ is a fixed graph like $K_n$, is there sufficient and nessary condition?</p>
",graph_theory
"<p>Let $G$ be a <a href=""http://en.wikipedia.org/wiki/Directed_graph"" rel=""nofollow"">directed graph</a> which contains $N$ vertices, and which satisfies the following condition: each vertex of $G$ has at least one incoming edge.</p>

<p>(For clarity, a vertex $V_1$ has an ""incoming edge"" if there is an edge $E$ which connects $V_1$ to some other vertex on the graph, $V_2$, for which $E$ is directed from $V_2$ to $V_1$)</p>

<p>Then I believe it follows that $G$ contains a closed cycle.  The reason I am posting this is because the result seems straightforward/obvious, and yet it would apparently solve an <a href=""http://mathoverflow.net/questions/16857/existence-of-a-zero-sum-subset"">open problem on MO regarding zero sum subsets</a>, so I am concerned that I may have a mistake.  (To be frank, I am not comfortable posting on MO)</p>

<p>The basic idea is to show that starting with a set of $N$ vertices, and no edges.  That it is impossible to construct a directed graph with no closed cycles by adding one (directed) edge at a time.</p>

<p>Let a set of $N$ vertices be given, and let us attempt to construct a directed graph with no closed cycle by adding one directed edge at a time.  Choose some arbitrary vertex $V_1 \in G$, then by the defining condition of $G$, $V_1$ must have an incoming edge, say from $V_2$.  It's clear that $V_2$ has an incoming edge, if this edge originates from $V_1$, then the graph would have a closed cycle, so we choose some other vertex which connects to $V_2$: and in this way we are forced to create a chain of $N-1$ vertices, $V_1$, has an edge coming from $V_2$, which has an edge coming from $V_3, \ldots, V_{N-2}$, which has an edge coming from $V_{N-1}$.  It's clear that if any of the vertices in this chain has an incoming edge originating from another vertex on the chain, that $G$ will contain a closed cycle.  So once we construct a chain of $N-1$ distinct vertices, there is one vertex left, and since this vertex must have an incoming edge originating from another vertex which is already on the chain, $G$ must contain a closed cycle.</p>

<p>Now let me explain why I think this fairly trivial result solves the <a href=""http://mathoverflow.net/questions/16857/existence-of-a-zero-sum-subset"">open zero sum subset problem</a> on MO.</p>

<p>This question asks: given a finite set of real numbers $S$ with the property that every number in the set can be written as the sum of two numbers in the set (not necessarily different), if there exists a subset $S$ which sums to zero.</p>

<p>Well, clearly a set $S$ which satisfies the condition of the problem stated above corresponds to a directed graph for which each vertex has at least one incoming edge (each real number in the set $S$ is associated with a vertex, and if given three numbers $a,b,c \in S$, with $a = b + c$, then the vertex associated with $a$ will have incoming edges from the vertices associated with $b$ and $c$).   Therefore the graph corresponding to an arbitrary S which satisfies the condition contains a closed cycle.  By adding the numbers in the closed cycle, we obtain a sum of the form:</p>

<p>$a + b + c + \ldots = a$, hence it follows that $b + c + \ldots = 0$, i.&thinsp;e. a set $S$ which satisfies the condition must contain a zero sum subset.  Have I made a mistake somewhere, or does this solve the problem? </p>
",graph_theory
"<p>How can we describe a polynomial-time algorithm to find an edge $e$ in a graph $G$ such that $G/e$ is 3-connected. Given the fact that $G$ is 3-connected and $\lvert V(G) \rvert \geq 5$.</p>
",graph_theory
"<p>Why is there only the trivial automorphism on the Frucht graph?</p>

<p>We have a rooted tree in the Frucht graph which allows to totally order the vertices. But how does this imply that there is only the identity on the Frucht graph?</p>
",graph_theory
"<p>i just started going through biconnected components can someone explain me this</p>

<p>Show that if G is a connected undirected graph, then no edge of G can be in two different
biconnected components</p>
",graph_theory
"<p>I am looking at a graph theory problem that describes the partite sets of a bipartite as two copies of the $(m+1)$-dimensional vector space over the finite field $\mathbb{F}_{p^n}$ ($p$ is prime and $n\geq 1$ is an integer), $P$ and $L$. They call the elements of $P$ ""points"" and the elements of $L$ ""lines"". </p>

<p>They say a point $(p)=(p_1, \ldots, p_{m+1})\in P$ is adjacent to a line $[l]=[l_1, \ldots, l_{m+1}]$ if and only if</p>

<p>$$ l_{i+1}+p_{i+1}=l_ip_1  $$</p>

<p>for every $i\in \left\{1,2,\ldots, m \right\}$.</p>

<p>I would like to know what the sum on the left hand side and the product on the right side mean geometrically in terms of lines and points. Perhaps I should ignore the geometric meaning? I just want to know how I should be viewing the above definition.</p>

<p>Thank you!</p>
",graph_theory
"<p>Let $G$ be a connected graph and $v$ be a vertex in $G$. Suppose a DFS traversal from $u$ is performed resulting in a tree $T$, and a BFS from $u$ also results in the same tree $T$. I would like to show that $T = G$.</p>

<p>My main problem for this is that I am not sure how to initially approach this proof, and given my current approach is within reason I am stuck as for my next step. </p>

<p>My current thought is to go by contradiction and suppose that $T$ is both the DFS and BFS tree of $G$ with $u$ being the root, but $T \neq G$. As $T \subset G$, there must exist an edge $e \in G$ such that $e \notin T$ (since $G$ is connected it cannot be the case that there is a vertex in $G$ that is not in $T$). From here I believe my contradiction will come from the DFS and BFS traversals not being equivalent, but this is where I am stuck in this approach. </p>

<p>Could anyone hint at my next step or give me an idea for another approach to the proof?</p>
",graph_theory
"<p>According to the Law of mathematics, the product of slopes of $2$ perpendicular lines has to be $ -1 $.</p>

<p>Then, how do you prove that the following lines are perpendicular.</p>

<p>$x=4$ , $y=6 $</p>

<p><img src=""http://i.stack.imgur.com/7fUDz.gif"" alt=""Perpendicular  lines""></p>

<p>My Calculation :</p>

<p>Slope of line $1$ ($x=4$) = Infinity</p>

<p>Slope of line $2$ ($y=6$) = $0$</p>

<p>Product of both slopes != $0$</p>
",graph_theory
"<p>I have seen some relation about the simple graph $G$ which is not directed. </p>

<p>Suppose $G$ has $n=|V|\ge1$ vertices, $m$ edges, $k$ connected components, $p$ odd cycles, $q$ even cycles. Do the following hold?</p>

<ol>
<li><p>$p+q\ge 1$ then $m\ge n$ </p></li>
<li><p>$p+q=1, k=1,$ then $ m=n$</p></li>
<li><p>$k\ge n-m$</p></li>
<li><p>If $p = 0$, then $G$ is bipartite.</p></li>
<li><p>If $q = 0$, then there are $2k$ proper colorings of $G$ using $2$ colors.</p></li>
</ol>

<p>Attempts: For question i, I believe it is False as we may have many isolated vertices.
for question 2 i think it is true. $p+q=1$ mean there exist cycle and k=1 mean that it is a connected graph. I believe it is true but then i have no idea how to show m=n.</p>

<p>for Q4, i think that it is true as it may a graph with no cycle is bipartile and also a graph with even with even cycle only seems to be a bipartitle too.</p>

<p>For question 5 i think it is false as for the case that the graph has no cycle, q=0 but we cna actually colour with 2 colours.</p>

<p>Is my interpretation or guess true? and is there any hints about the proof of some details?</p>
",graph_theory
"<p>Show that if $G$ is a connected graph that is not regular, then $G$ contains adjacent vertices $u$ and $v$ such that deg $u$ does not equal deg $v$.</p>
",graph_theory
"<p>$K_4$ is an example of a graph that requires 4 colours to be coloured but it contains triangle cycles and a square cycle too.</p>

<p>I've tried drawing ever more complicated graphs made up of pentagons, hexagons, etc. but I've been able to colour all of them with 3 colours. </p>

<p>If such a graph exists without any triangle or square cycles does anyone have a hint as to how I could discover it? </p>
",graph_theory
"<p>I am a student from Iraq studying Graph to get in to a college in Georgia. I have trouble understanding this question.</p>

<p>Show that the two definitions below are logically equivalent.
Definition 1. A graph G = (V, E) is disconnected if there exist non-empty subgraphs H1 = (V1,E1) and H2 = (V2,E2) such that V1 and V2 partition V and E1 and E2 partition E. A graph is connected if it is not disconnected.
Definition 2. A graph G is connected if for any two vertices v, w there is a walk between v and w.</p>

<p>Can someone kindly explain this situation???</p>
",graph_theory
"<p>This <a href=""http://www.dis.uniroma1.it/~leon/tcs/lecture2.pdf"" rel=""nofollow"">tutorial</a> (page 22) on Hopcroft-Karp algorithm for maximum bipartite matching states the following:</p>

<blockquote>
  <p>Let $M^*$ be a maximum matching, and let $M$ be any matching in $G = (V, E)$. ...</p>
  
  <p>Let us consider the graph $G'=(V, M \oplus M^*)$. It contains at most $|M^*|-|M|$ augmenting paths with respect to $M$.</p>
</blockquote>

<p>Here $M\oplus M^*$ is the symmetric difference between $M$ and $M^*$. But how does the last line (<em>It contains at most $|M^*|-|M|$ augmenting paths with respect to $M$</em>) follow?</p>
",graph_theory
"<p>I'm trying to solve the following exercise from the book A Textbook of Graph Theory by R. Balakrishnan and K. Ranganathan</p>

<blockquote>
  <p>Show that for a simple bipartite graph, $m\leq \frac{n^2}{4}$</p>
</blockquote>

<p>$m$ is the size of the graph.</p>

<p>$n$ number of vertices.</p>

<p>I was considering the following cases:</p>

<p>Let $X$ and $Y$ be a partition of the set of vertices of $V(G)$ and I tried to verify some cases accordingly to the cardinality of the each set. If $|V(G)|=n$ and $|X|=|Y|=\frac{n}{2}$ it is easy to see, but I got stuck trying to show the case when the cardinalities are $|X|&lt;|Y|$</p>

<p>Any help will be greatly appreciated!</p>

<p>Thanks!</p>
",graph_theory
"<p>In a <a href=""http://demonstrations.wolfram.com/GracefulGraphs/"" rel=""nofollow"">graceful graph</a>, the vertices have number values that range from 0 to $n$ and $n$ edges with all values from 1 to $n$ that are differences between the vertex values. Here's a graceful but boring path graph with an Eulerian tour.</p>

<p><a href=""http://i.stack.imgur.com/MmgzQ.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/MmgzQ.png"" alt=""enter image description here""></a></p>

<p>A more interesting graph is the <a href=""http://mathworld.wolfram.com/PetersenGraph.html"" rel=""nofollow"">Petersen graph</a>, which can be labeled gracefully.</p>

<p><a href=""http://i.stack.imgur.com/FoLor.gif"" rel=""nofollow""><img src=""http://i.stack.imgur.com/FoLor.gif"" alt=""Graceful Petersen graph""></a></p>

<p>In this graph, 1-2-3 is a path for vertices 2-3-5-8. Three edges out of 15 means this is a 20% path.  An <a href=""https://en.wikipedia.org/wiki/Eulerian_path"" rel=""nofollow"">Eulerian path</a> would be 100%.  Is there a graceful Eulerian labelling for anything other than the path graph? For a partial <a href=""http://mathworld.wolfram.com/QueenGraph.html"" rel=""nofollow"">queen graph</a> on a 4x4 grid, here is a semi-graceful labeling with length 36. </p>

<p><a href=""http://i.stack.imgur.com/epQWc.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/epQWc.jpg"" alt=""increment maze""></a></p>

<p>Here is a similar semi-graceful graph. If vertices had values ranging from 0 and 29, then it would be a graceful graph. Let's call this an Eulerian semi-graceful graph.</p>

<p><a href=""http://i.stack.imgur.com/vbt4J.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/vbt4J.png"" alt=""Eulerian semi-graphful graph""></a></p>

<p>For semi-graceful Eulerian graphs, are any of them interesting graphs? The vertex sequence 9, 10, 8, 5, 9, 14, 8, 1, 9, 0, 10, 21, 9, 22, 36, 21, 5, 22, 40, 21, 1, 22, 0, 23, 47, 22, 48, 21, 49, 78, 48, 79, 47, 14, 48, 83, 47, 10, 48, 9, 49, 90, 48, 5, 49, 94, 48, 1, 49, 0 can be used to make a 20 vertex graph with path length 49, but it isn't all that interesting. Is it possible to find a <a href=""http://mathworld.wolfram.com/PolyhedralGraph.html"" rel=""nofollow"">polyhedral graph</a> with an Eulerian semi-graceful labeling?</p>

<p>For $n$ vertices, what is the longest possible path?</p>

<p>EDIT: Leen Droogendijk points out an Eulerian graceful graph. Are there others?</p>

<p><a href=""http://i.stack.imgur.com/5kuXp.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/5kuXp.png"" alt=""Leen Droogendijk graph""></a></p>

<p>EDIT 2:  Turns out there are many Eulerian graceful graphs. So far, all of them seem to have at least one vertex with valence 1 or 2.</p>

<p><a href=""http://i.stack.imgur.com/tbKV1.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/tbKV1.png"" alt=""Large Eulerian graceful graph""></a></p>
",graph_theory
"<p>So far I've come across a bunch of different terms for matrices used in graph theory - adjacency matrix, connectivity/connection matrix, vertex matrix, etc.</p>

<p>Are there any differences between these matrices or are all of these terms just referring to the same thing?</p>
",graph_theory
"<p>Was reading an introductory graph theory book, and it says that nets of solids can be represented using adjacency graphs, and new nets can be discovered by searching for all the spanning trees of the graph.</p>

<p>It also mentions that for some solids known as non-manifold, the spanning trees might not result in feasible nets. It does not elaborate.</p>

<p>I have tried searching this on the internet but it seems quite obscure and all I got were discussions about 3D graphic renderers</p>
",graph_theory
"<p>Source is in <a href=""http://mathworld.wolfram.com/HamiltonianGraph.html"" rel=""nofollow"">Mathworld</a>, but it has no proof. Also, I am not completely sure what ""unbalanced"" means here. Non-equal number of even and uneven degrees?</p>

<p>What I am interested in, are there some universal properties of (connected) graphs that prevent hamiltonicity? Something to do with number of vertices versus edges, or average degrees or such? Something that is easy to demonstrate?</p>

<p>I will (hopefully) be using them as counterexamples of hamiltonian graphs in my thesis.</p>
",graph_theory
"<p>Sorry for the english, I tried to make it the most clear possible.</p>

<p>Be $G$ a connected graph not directed, I have to find an algorithm that given $n$ the quantity of vertex and $0&lt;k&lt;n$ disjoint components gives a graph such the weight of it's maximum edge is the minimum possible. Then, proof that this algorithm is correct.</p>

<p>So the algorithm I came up with is:</p>

<p>First whit some known algorithm, generate the minimum spanning tree. (for example whith the prim <a href=""http://en.wikipedia.org/wiki/Prim%27s_algorithm"" rel=""nofollow"">algorithm</a>)</p>

<p>For 1 to k get the maximum edge of this Minimum spanning tree and delete it.</p>

<p>done.</p>

<p>Proof that this work: </p>

<p>By induction:</p>

<p>Base Step($k=1$) :</p>

<p>Let $G$ be our graph of $n$ vertex and connected, getting a minimum spanning tree of $G$, we know we have a subgraph such all the vertex are connected there are no circuits and the sum of the weights of the edges is minimum.</p>

<p>If the sum of the weights of the edges is minimum, then this means the maximum weight of an edge is minimum. Then this step holds.</p>

<p>Inductive step(if $i-1 \rightarrow i$):</p>

<p>Let $G'$ be the minimum spanning tree. By Inductive hypothesis I know i can get the firsts $i-1$ edges and I get the disjoint graph the maximum weight of an edge is minimum for $i-1$ connected components. Then deleting the maximum weight edge, I get the disjoint graph the maximum weight of an edge is minimum for $i$ connected components.</p>

<p>I'm not very convinced this proof is correct, the inductive step feels very rare, and I think I used it wrong. </p>

<p>What do you think?</p>
",graph_theory
"<p>I have a lemma that say:</p>

<p>Let $G$ be a planar graph whose exterior face is bounded by a cycle $u_1,...,u_k$. Then there is a vertex $u_i$ ($i\neq 1,k$) not adjacent to any $u_j$ other than $u_{i-1}$ and $u_{i+1}$.</p>

<p>But for example $K_4$ is planar and this condition doesn't look satisfy. So I don't really understand this lemma.</p>

<p><img src=""http://i.stack.imgur.com/lcfrA.png"" alt=""enter image description here""></p>
",graph_theory
"<p>Suppose we know that a simple graph (no multiedges or loops) with finitely many vertices is connected, regular (every vertex has the same degree), and bipartite. Must the graph be a hypercube or an even cycle?</p>
",graph_theory
"<p>Where:</p>

<p>SCC - strongly connected components<br>
DFS - depth first search</p>

<p>This is the graph I was trying to ""solve"" this way is:</p>

<p><img src=""http://i.stack.imgur.com/oO5nX.jpg"" alt=""enter image description here""></p>

<p>So I'm starting from the A vertex and go straight to G, setting proccessing times all the way - A = &lt;1, 0> and G = &lt;7, 0>.</p>

<p>Then I go back, G = &lt;7, 8>, then to H = &lt;6, 9>, I = &lt;5, 10>, E = &lt;4, 11>...is this correct? And what's next? I can go to C = &lt;3, 0>, or to F which was not visited yet...I guess I should do:</p>

<p>F = &lt;12, 0>, D = &lt;13, 0>, D = &lt;13, 14>, F = &lt;12, 15>, E = &lt;4, 16>, C = &lt;3, 17>, B = &lt;2, 18>, A = &lt;1, 19></p>

<p>Is this correct?</p>

<p>Then I reverse the edges (arrows)...How to get SCC now?</p>
",graph_theory
"<p>I know the <a href=""http://en.wikipedia.org/wiki/Four_color_theorem"" rel=""nofollow"">four colour theorem</a> was solved by a computer checking a large number of cases. What I don't understand is why there are only a large but finite number of cases. It seems like there should be infinitely many planar graphs... What is the intuition behind cutting this down to a finite number of configurations?</p>
",graph_theory
"<p>A polyomino is a connected subset of $\mathbb{Z}^2$ - a set of squares joined along their edges such that the resulting form is connected (or, more shortly, a generalized form of Tetris cube). A polyomino can be easily thought of as graph with vertices being elements of $\mathbb{Z}^2$ and edges between two vertices of hamming distance 1 (i.e. with one coordinate equal and the other different by 1).</p>

<p>The Hamiltonian path/cycle problem is the problem of determining for a given graph whether it contains a path/cycle that visits every vertex exactly once. It is known to be NP-complete for general graphs and even for planar graphs. My question is whether it's still NP-complete when restricting the graphs to be polyominoes (and if it is NP-complete, how it is shown).</p>
",graph_theory
"<p>In a graph $G$, a <em>diametral path</em> is a path of length $\text{diam}(G)$ joining two vertices that are at a distance $\text{diam}(G)$ from each other. Given a tree $T$, consider the set of all diametral paths of $T$. For example, if $T$ is say the star graph $S_4$, it is not true that the set of all diametral paths would share an edge. But when do they?</p>

<p>How can we characterize trees where every diametral path has an edge in common? Looking at some examples, it seems always true for at least <a href=""http://mathworld.wolfram.com/BicenteredTree.html"" rel=""nofollow"">bicentered trees</a>. The intuition would be that every such path passes through the center, and thus have the edge between the two centers in common.</p>
",graph_theory
"<p>I know that many types graphs have unique names, ie. a directed graph where each node has exactly one outbound edge is known as a <code>functional</code> graph. Do the graphs with exactly 2 inbound/outbound edges have a name?</p>

<p><strong>Bonus</strong>: If the 2 inbound/outbound graph is named, is the nth inbound/outbound graph named?</p>
",graph_theory
"<p>Each <strong>Problem</strong> has one or many <strong>Solution(s)</strong>.</p>

<p>Each <strong>Solution</strong> has its <strong>Weight</strong>.</p>

<p>Each <strong>Solution</strong> leads to zero or many <strong>Consequent Problems</strong>, that must be solved if this solution is used.</p>

<p>There are <strong>no cycles possible</strong>.</p>

<p>Given the root problem, goal is to find <strong>optimal combination of {Problem:Solution} pairs</strong> that gives minimum (or maximum) Total Weight (sum of weights of all used solutions), so all consequent problems of all used solutions are resolved.</p>

<p>Is there any algorithm with the runtime less or equal to $O((P+S)^2)$ that calculates the goal? other words - without recursively enumerating all possible combinations (via cartesian product).</p>
",graph_theory
"<p>Is it possible to quantify the number of dimensions in combinatorial spaces.  The space I am particularly interested is all partitions of a set, bounded by the Bell number, where objects in this space are particular partitions.</p>
",graph_theory
"<p>The graphs that I consider are:</p>

<ol>
<li>labelled (so, I do not want to count them up to isomorphism).</li>
<li>simple (no loops and at most one edge between two nodes).</li>
<li>connected.</li>
</ol>

<p>In </p>

<p><a href=""http://math.stackexchange.com/questions/154941/how-to-calculate-the-number-of-possible-connected-simple-graphs-with-n-labelle"">How to calculate the number of possible connected simple graphs with $n$ labelled vertices</a></p>

<p>there is an answer to the count of such graphs given $n$ vertices.  Would there be a formula of the number of such graphs if the number of vertices $n$ and the number of edges $m$ are given?  My situation is that I need to estimate the number of such graphs when $n$ is large (say 3000), but $m$ is small.  </p>
",graph_theory
"<p>Say we have a undirected, connected graph that represents a network of streets.  How would you prove that there always exists a tour of the network, where one ``drives'' in both directions on every street exactly once?</p>
",graph_theory
"<p>Put another way ... Colour the edges of the complete graph with 3 colours, so that three subgraphs are each a copy of the Petersen Graph.
I heard somewhere that it can be done (Maybe I should not go on MathOverFlow !) but I have spent all weekend trying and have convinced myself it is impossible. Thanks in advance for your comments.</p>
",graph_theory
"<p>On our practice exam, our teacher gave us this problem and this solution:</p>

<blockquote>
  <p>What is the fewest number of vertices required to construct a complete
  graph with at least $500$ edges? (Show your work but do not attempt to
  simplify your answer too much!)</p>
</blockquote>

<p><strong>Answer:</strong> We need to select $n$ such that $\dbinom{n}{2} \geq 500$.</p>

<p>I do not understand how she got to this answer. I tried to start with the definition of a complete graph, but where to go from there, I had no idea. </p>
",graph_theory
"<p>On our practice exam, our teacher gave us this problem and this solution:</p>

<p>Let $G$ be a forest with $k \geq 1$ components. What type of (sub)graph is each component? Suppose each component has $n_i$ vertices with $n_i \geq 1$. How many edges does $G$ have? (Show your work!)</p>

<p>ANSWER: Each component is a tree. Suppose there are $c$ components. Then $|E(G)| =\sum_{i=1}^c  n_i − 1 = |V(G)| − c$.</p>

<p>I am confused as to how she got that answer. I do not understand how she knows to use that summation for the number of edges.</p>
",graph_theory
"<p>This is a vague question asking about the existence of a mathematical object, instead of properties of a well defined one. I am sorry if this is not the correct forum.</p>

<p>I know if you have a random graph $g \in G(n, p)$ on $n$ vertices ($n$ large) where each edge is included with probability $p$, as you increase $p$ from zero there is a very acute point where the probability that $g$ is connected becomes almost certain. That it goes from the state of ""being disconnected"" to ""being connected""</p>

<p>I am wondering if there is discrete structure $s \in S(n, p, q)$ on an underlying set of size $n$, parameterized with two probabilities $p$ and $q$, over which you can describe three mutually exclusive states. In such a structure can there exist a point $(p_t, q_t) \in [0,1]\times[0,1]$ that in a reasonably small neighborhood (with an $\epsilon$ which shrinks as $n$ grows) each of the states become almost certain. A mathematical equivalent to a triple point.</p>
",graph_theory
"<p>I need to use the Euler's formula. I know there are $62$ faces...first, how do I find the number of vertices it has. From there, I can get the amount of edges, which will then in turn get me the number of faces. The question states as follows: A rhombicosadodecahedron is a polyhedron whose every vertex is incident to one triangular, one pentagonal, and two (opposite) quadrilateral faces. Find the number of faces. </p>
",graph_theory
"<p>Say I have some collection of ordered sets $C = \{S_i\}$.  Is there an efficient way to determine the minimal ordered set $S^*$ such that each of the original $S_i \subseteq S^*$, with order preserved?</p>

<p>Simple example: $C = \{\{a, b, c\}, \{b, d, f\}, \{b, c, d\}\}$, then $S^* = \{a, b, c, d, f\}$</p>

<p>More complex example: $C = \{\{a, b, c\}, \{b, c, d\}, \{x, a, d\}, \{b, b, a, c\}, \{y, b, c, b\}\}$, then one solution is $S^* = \{y, x, a, b, c, b, a, c, d \}$.</p>

<p>Another example: $C = \{\{a, b, c\}, \{b, a, c\}, \{c, a, b\}, \{b, c, a\}, \{c, b, c\}, \{b, b, c\}\}$, $S^* = \{b, c, a, b, c\}$</p>

<p>The naïve solution is to just concatenate the $S_i$. When $\cap S_i = \emptyset$, then of course this happens to also be the minimal solution.</p>

<p>Perhaps finding some traversal of a digraph representing all elements and their ordering?</p>
",graph_theory
"<p>Let $G=(V,E)$ be a graph, $M$ a matching in $G$. I have read that $M$ is maximal iff there is no augmenting path of $M$ in $G$.</p>

<p>Now consider the graph $G=(\{a_1,b_1,a_2,b_2\},\{a_1b_1,a_2b_2\})$, which is just 4 vertices where two of them are pairwise connected. Now $M=\{a_1b_1\}$ is a matching in $G$, but there is no alternating path to augment it to $M'=\{a_1b_1,a_2b_2\}$, because $G$ does not support any edges for that.</p>

<p>Where is my mistake?</p>

<p>In general, I am trying to proof that given any graph $G$ and some matching $M$ in $G$. Then there always exists an alternating path $P=p_1p_2...p_k, p_i\in V(G)$ w.r.t. to $M$, i.e. $p_1 \not\in V(M)$ and the edges are alternating being in and not in $M$. In the case that $M$ is not maximal, one of these alternating paths is augmenting.</p>
",graph_theory
"<blockquote>
  <p>Describe a graph model for solving the following problem: Can the permutations of $\{1,2,\ldots,n\}$ be arranged in a sequence so that the adjacent permutations $$p:p_1,\ldots,p_n \text{ and }  q:q_1,\ldots,q_n$$ satisfy $p_i\neq q_i$ for all $i$?</p>
</blockquote>

<p>I have problem understanding what the exercise asks. What does ""adjacent permutation"" mean? Also, in a follow-up question, it says that the statement is true for $n\geq 5$. </p>
",graph_theory
"<p>I'm doing a research project in graph theory and need to program some stuff to help me study it. I used to have access to Mathematica but now I don't. So, when I'm programming things I'm entering the graph data in by hand which is really time consuming. So I was wondering if there was anywhere on the internet that contained a file I could download a file or files containing the descriptions of a variety cubic graphs to help automate this process. </p>

<p>Does anyone know of such a website? </p>
",graph_theory
"<p>Well to start off, $5n=2e$ since there will be $n$ number of vertices of degree 5 and with the handshaking lemma, there will be $2e$.  The problem is finding the number of vertices and faces. What do I do?</p>
",graph_theory
"<p>In group theory we have Cayley graphs. Are there analogous or anyway useful visual representations of magma structures?</p>

<p>I am unsure about how to construct a graph representing, for instance, a free magma with two generators.</p>
",graph_theory
"<p>Let $G,H$ be finite graphs with $|V(H)| &gt; |V(G)|$. </p>

<p>Let $\mathcal{f}:G\rightarrow H$ be an injective homomorphism - that is, $\mathcal{f}$ is:</p>

<p>$1.$ Injective - $\mathcal{f}(g_1)\neq\mathcal{f}(g_2)$, $\forall g_i\in V(H)$.</p>

<p>$2.$ Homomorphic - $g_1g_2\in E(G)\implies \mathcal{f}(g_1)\mathcal{f}(g_2)\in E(H)$.</p>

<p>Let $\odot$ imply one of the graph products:</p>

<p>$1.$ Tensor</p>

<p>$2.$ Cartesian</p>

<p>$3.$ Strong</p>

<p>$f \odot f:G \odot G \rightarrow H\odot H$ is injective.</p>

<p>Is $f \odot f:G \odot G \rightarrow H\odot H$ a homomorphism?</p>

<p>Is there a reference for this fact?</p>
",graph_theory
"<p>Let $A$ be the adjacency matrix of some directed graph with $m$ vertices labeled as $v_1, v_2, \ldots, v_m$. So here $A_{ij} = 1$ if there is an edge from $v_i$ to $v_j$, and $A_{ij} = 0$ otherwise. By induction it is not too hard to show that $(A^n)_{ij}$ is the number of $n$-step walks from $v_i$ to $v_j$.</p>

<p>Why is this the case? Is there some geometric explanation, or some explanation using linear algebra? The definition of matrix multiplication comes from composition of linear maps, and it seems surprising to me to see this connection between linear maps and graphs.</p>
",graph_theory
"<p>I would like to know how to define the chain complex of a given graph, 0-cell are the vertices of the graph and 1-cell are the edges. How about 2-cell? are they cycles, or triangles?</p>

<p>does anyway who can give me an example how to compute the homology group of $K_4$ and $K_5$? </p>
",graph_theory
"<p>Is it true that any undirected graph is a union of maximal cliques? 
Since an edge is a size 2 clique?</p>
",graph_theory
"<p>Here's a question I came upon while fiddling around with yarn on spindles.</p>

<p>I joined three spindles so that they were orthogonal.. then, beginning at the base of a particular spindle (A), wound it around another spindle, creating an arc connecting the two. After making some interesting figures I started to wonder about the combinatorial question of how many possible patterns could be created in this manner.</p>

<p><img src=""http://i.stack.imgur.com/aO7Vl.jpg"" alt=""Basic graphic example of question""></p>

<p>Assuming that each half spindle can hold some number ( arbitrary, but the same for all spindles) of winds (visits, essentially), and not excluding redundant patterns due to symmetry (once the basic question is answered, I will consider excluding these degenerate patterns).</p>

<p>A spindle <strong>can</strong> have arcs going back to itself (loops).</p>

<p>I've tried figuring it out using markov graphs, basic linear algebra and combinatoric techniques, but am very curious as to how other people would go about it.</p>

<p>-There will be times when the yarn 'paints itself into a corner', e.g. when 4/6 spindles have filled their holding capacity, and the thread must travel within the remaining nodes, ultimately cornering itself to eventually loop back its own node until completion (possibly even excluding some nodes entirely, leaving them untouched and unreachable). How could this be figured in to the problem?</p>

<p>I'm very excited to see how more mathematically mature problem solvers attack this :) </p>
",graph_theory
"<p>In my textbook, they provide a graph $H$ and then list examples of the cliques and the independent sets in $H$. $$\begin{align*}V(H)&amp;=\{1,2,3,4,5,6,7,8,9\}\\E(H)&amp;=\{12,23,39,98,87,74,41,26,25,56,36,69,68,57\}\end{align*}$$</p>

<p>They list the set $\{4\}$ to be both a clique and an independent set.
I am having trouble understanding why $\{4\}$ is both a clique and an independent set. </p>

<p>I know that a subset $S$ is a clique provided that any two distinct vertices are adjacent. So, since $\{4\}$ has only vertex, is it vacuously a clique?</p>

<p>I know that a set $S$ is independent provided $G[S]$ is an edgeless graph. I can see clearly how $\{4\}$ is an edgeless graph since it only has one vertex. </p>

<p>So, can a subset be both a clique and an independent set? Is $\{4\}$ both a clique and an independent set?</p>
",graph_theory
"<p>I would like to ask you if there is a way for checking if we can decompose a specific graph into $N$ planar sub-graphs that can be drawn on $N$ planes without an edge crossing any of the planes.</p>
",graph_theory
"<p>I am confused with this question. My teacher asked us at class but I cannot solve it. Can you help me?</p>

<p>""Let $T$ be a tree with exactly two vertices of degree $7$ and exactly $20$ vertices of degree $100.$ What is the minimum possible number of vertices in a tree $T$ that satisfies those restrictions?""</p>
",graph_theory
"<p>I understand vertex transitivity of a graph $G$ as the property that the local environment, i.e., all incident edges and their vertices, of any 2 vertices looks the same. </p>

<p>What if we extend this notion of similarity to k-hop neighborhood of vertices, including the environment up to some distance k? Is there a generalization of this property such that the k-hop environments of any 2 vertices look the same?</p>
",graph_theory
"<p>As most of you know, the problem of finding a minimal vertex cover for an arbitrary graph is an NP-hard problem. I was wondering, if there existed a non-constructive way of calculating the size of a minimal vertex cover. That is, if you find a minimal vertex cover, this tells you the minimum size of a vertex cover. However, what if you know that the size of a minimal vertex cover is m, does this help you find such a covering?</p>

<p>My back of the envelope calculation tells me that, on a graph with n vertices, if you know that the size of a minimal vertex cover is m, you just need to check all subsets of V (the set of verticies) of size m, that is ${n \choose m} $. As a function of n, this has growth $O(n^n)$ i.e. not polynomial. So naively you don't get a polynomial reduction, and so the problem doesn't appear to be NP-hard.</p>

<p>So is finding the minimum size of a vertex cover an easier problem than finding a minimal vertex cover?</p>
",graph_theory
"<p>I have a graph $G=(V,E)$ where to each vertex $v$ I have associated a value, $\hat{v}$ (ie I have a ""network"" in the terminology here <a href=""http://snap.stanford.edu/snap/index.html"" rel=""nofollow"">http://snap.stanford.edu/snap/index.html</a> ).</p>

<p>Let $\phi : \hat{V} \rightarrow \hat{V}$ be the function which takes the value associated to each node and replaces it with median of the values of the adjacent nodes.</p>

<p>Empirically, iterating $\phi$ converges. Why?</p>
",graph_theory
"<p>I'm not sure what topic in math this is (probably Graph Theory), but maybe you can help me. </p>

<h1><strong>The Challenge</strong></h1>

<p>My task is like this: I have to create an automatic program that will assign each student in a class (of variable size, but my own class now has 11 students) a reviewer for his assignment, according to a set of rules:</p>

<ul>
<li>The students sit in a row</li>
<li>One cannot review himself</li>
<li>Two students cannot review each other (reciprocally)</li>
<li>One cannot review his neighbor (from both sides)</li>
<li>One cannot review the student he reviewed the last time</li>
</ul>

<p>And the real trouble maker: </p>

<ul>
<li>One cannot review the student he reviewed two times before</li>
</ul>

<p>The programming implementation of this problem is not important – though so far the logic and algorithms that I've tried to implement have all failed (i.e. reaching a dead-end, or in the case of my programs, an infinite loop).</p>

<h1><strong>My previous approaches</strong></h1>

<p>At first I tried to simply throw a random number between 1 and the class size (11), check if it follows the rules (updating the availability of each student as we go, of course), and if so assigning that student as a reviewer. I found out very quickly that it often gets stuck on the last student, because the random assignments done prior leave the last student with no available reviewers according to the rules. </p>

<p>So this reminded me of the problem of coloring the map of the US states with 4 colors, and I tried another approach where before each assignment the program checks if that assignment will leave another student without any available reviewers – and only if it doesn't it assigns the reviewer, otherwise it looks for another random reviewer. </p>

<p>And this worked for 2 to 3 times, until it ALSO GOT STUCK (!!) And the reason is that it came into a situation where, say, after assigning 8 students, student 9 had two possibilities, and choosing 1 of them would leave student 10 with no available students while choosing the other would leave student 11 without one…</p>

<p>I didn't want to go up two levels and solve this problem, because it seemed I'm just pushing the problem one level higher each time. So I went for another approach:</p>

<blockquote>
  <p>Before each assignment check for the students with the least number of possible reviewers, and assign to him/her first. (Though I didn't implement it, you could probably still make it random after adding the rule that if there is more than one student who has the lowest number, choose one of them randomly.)</p>
</blockquote>

<p>This worked for about 10 times, until… you guessed it, it also got stuck. And for the last student there was no reviewer left which abided by the restrictions.</p>

<h1><strong>What I'm Looking For</strong></h1>

<ol>
<li>Well, an algorithm which will solve my problem; </li>
</ol>

<p>or</p>

<ol start=""2"">
<li>A proof that shows it cannot be done, i.e. that you cannot guarantee you would not get stuck at some point (at least not with 11 students and checking 2 times back);</li>
</ol>

<p>or at the very least</p>

<ol start=""3"">
<li>Some help of finding relevant material that can advance me in my quest for the holy grail. </li>
</ol>

<p><strong>NOTE:</strong> When checking only 1 time back, I didn't encounter any problem, though I'm not sure if this means that you can't encounter any dead-ends, or that it's just rarer to encounter them. </p>

<h2><strong>Big Note</strong></h2>

<p>I think there's an easy way, where you just assign each student the first available option, and rotate everyone exactly the same. </p>

<p>i.e.:</p>

<pre><code>    1 2 3 4 5 6 7 8 9 . ..
1   m 0 l s 1 1 1 1 1 1 1
2   0 m 0 l s 1 1 1 1 1 1
3   1 0 m 0 l s 1 1 1 1 1
4   1 1 0 m 0 l s 1 1 1 1
5   1 1 1 0 m 0 l s 1 1 1
6   1 1 1 1 0 m 0 l s 1 1
7   1 1 1 1 1 0 m 0 l s 1
8   1 1 1 1 1 1 0 m 0 l s
9   s 1 1 1 1 1 1 0 m 0 l
10  l s 1 1 1 1 1 1 0 m 0
11  1 l s 1 1 1 1 1 1 0 m
</code></pre>

<p>(m - self, l - last review , s - second last, 1 - available option, 0 - not available)</p>

<p>so, for the first student you choose number 5, for the 2nd you choose 6, etc. And the next time you rotate everyone one position.</p>

<p>It guess this will work, but I'm looking for a solution that doesn't require such a tidy arrangement of the students. Also – this is not random at all – it will be a series of (in this case) 8 other reviewers that each student will traverse, and it will keep repeating itself. I would prefer a more random assignment.</p>

<p>Though if you can show this is the only/best way, that would be good enough for me. </p>

<p>Thanks,
David</p>
",graph_theory
"<blockquote>
  <p>find equation of a line perpendicular to the given line through the given point
  the line is y=1/2x-2 
  the point is (3,6) 
  I don't know what to do ,or try , please help me , its probably very easy to other people</p>
</blockquote>
",graph_theory
"<blockquote>
  <p>your classmate juan missed the lesson on graphing linear  equations using slope-intercept form. you attend the class and what to help juan understand the material he missed. assume juan knows how to graph y=x</p>
  
  <p>part A= write a explanation for juan that describes the y-intercept of a line and what happens to the graph of y=x as you change the y- intercept. be specific and consider several cases </p>
  
  <p>part b= write an explanation for juan that describes the slope m of a line  and what happens to the graph of y=x as you change the slope. be specific and consider several cases</p>
  
  <p>well here it it seems hard right... well it does to me , I really don't know what to do</p>
</blockquote>
",graph_theory
"<p>You can move from 1 to 2, 2 to 3, and so on, step by step, till 100.
Also, between the points give below, you can move directly within every pair:</p>

<p>(10 and 60)</p>

<p>(50 and 100)</p>

<p>(70 and 100)</p>

<p>(80 and 100)</p>

<p>How many different paths exist?
I tried it, and could find only 7. But a c-program i created says 8 paths. so, what do you think?</p>

<p>Here are the 7 paths in could find:</p>

<p>1-2-3....99-100;</p>

<p>1-2-3....10-60-61-62....100;</p>

<p>1-2-3....50-100;</p>

<p>1-2-3....10-60-61-62....70-100;</p>

<p>1-2-3....10-60-61-62....80-100;</p>

<p>1-2-3....70-100;</p>

<p>1-2-3....80-100;</p>
",graph_theory
"<p>There are four groups of people who want to be carried to a destination. If we have three vehicle to carry the following number of people:</p>

<blockquote>
  <p>Veh 1, five; </p>
  
  <p>Veh 2, four; </p>
  
  <p>Veh 3, four. </p>
</blockquote>

<p>Each group has four people, and no vehicle can carry more than two people from any of the given group. How do we use network flow to find the maximum number of people who can be carried in the three vehicles. </p>

<p>I have built a digraph where A, B, C and D represent the edges for the groups and V1, V2 and V3 represent the three vehicles. Here's the solution I came up with. Can someone look at it and see if I am doing it right?</p>

<p><img src=""http://i.stack.imgur.com/1pbT5.png"" alt=""enter image description here""></p>
",graph_theory
"<p>Given a DAG $G=(V,E)$, Let $\dot{G}$ be $G$ after flipping the direction of a single edge $e\in E$. Are there sufficient (and\or necessary) conditions under which $\dot{G}$ is guaranteed to be DAG ? Are there known classes of DAGs that maintain this property? </p>
",graph_theory
"<h3>Background:</h3>

<p>I was studying Theorem 2.3.3 from Introduction to Graph Theory by W. B. West. The main idea of his proof is as follows:
<br>
<b>T</b>, resulting tree.
<br>
<b>T<sup> *</sup></b>, spanning tree of minimum weight.
<br>
Let, T $\neq$ T<sup> *</sup>, then there are edges in T<sup> *</sup> that are not in T.
We first consider only 1 edge. Let's name it e. Hence, T<sup> *</sup> has all the edges that are in T, except e. Now, if we add e to T<sup> *</sup>, we should get a cycle, say 'C'. This implies, C has an edge that is not in T. Let's name it e'. Now we get spanning tree T<sup> *</sup>+ e - e'.
Now, let us think what happened when Kruskal ran and produced T. It examined all edges in G. Including e and e'. But, it included only e. So, w(e)$\leq$w(e').</p>

<blockquote>
  <p>Thus T<sup> *</sup>+ e - e' is a spanning tree with weight at most T<sup> *</sup> that agrees with T for a <em>longer initial list</em> of edges than T<sup> *</sup> does.</p>
</blockquote>

<ul>
<li>What does it mean actually?</li>
<li>Anybody knows any other proof?</li>
</ul>
",graph_theory
"<p>What is the degree of Johnson graph $J(n,k)$ where $n&gt;k$?
<a href=""http://en.wikipedia.org/wiki/Johnson_graph"" rel=""nofollow"">http://en.wikipedia.org/wiki/Johnson_graph</a></p>

<p>What are some good examples of subgraphs of Johnson graphs? The Johnson graph I am interested in is $J(n,2)$.</p>
",graph_theory
"<blockquote>
  <p>Is the graph connected? Justify.</p>
</blockquote>

<p>Because there is a path connecting all pairs of vertices, this graph is therefore connected?</p>

<p>Is that right?</p>

<p><img src=""http://i.stack.imgur.com/tMaUp.png"" alt=""graph""></p>
",graph_theory
"<p>I have the following adjacency matrix:</p>

<pre><code>   a  b  c  d 
a [0, 0, 1, 1]
b [0, 0, 1, 0]
c [1, 1, 0, 1]
d [1, 1, 1, 0]
</code></pre>

<p>How do I draw the graph, given its adjacency matrix above (I've added <code>a,b,c,d</code> to label vertices).</p>

<p>I don't understand how the vertex $d$ (e.g., the row $d$) is adjacent to the vertex $b$, but the vertex $b$ (the row $b$) is not adjacent to the vertex $d$ (the column $d$).</p>

<p>Is this possible?</p>

<p>Thanks!</p>

<p>EDIT:  Maybe it's directed?  If so, would that explain why d --> b, but b =/ d?</p>
",graph_theory
"<p>I found a nice introduction on how to <a href=""https://crazyproject.wordpress.com/2011/03/04/use-grbner-bases-to-construct-the-colorings-of-a-finite-graph/"" rel=""nofollow"">Use Gröbner bases to construct the colorings of a finite graph</a>. </p>

<p>Now my graphs $G=(V,E)$ are the line graphs planar of cubic graphs, so they are $4$-regular. The corresponding edge-adjacency matrices can be constructed, as shown <a href=""http://math.stackexchange.com/q/1629748/19341"">here</a> (in a crude way, I admit...). 
Planarity assures the existence of $3$-colorings of the edges! </p>

<p>Now let there be a field $F = \mathbb{Z}/3\mathbb{Z}$ and let $S = F = \{0,1,2\}$ be our set of colors.</p>

<p>Let's define two types of polynomials on $F$: </p>

<ul>
<li>$f(z) = z(z-1)(z-2) = z^3-z$ </li>
<li>$g(y,w) = y^2+yw+w^2-1$. </li>
</ul>

<p>Let $I$ be the ideal $I = (x_t^3-x_t \ |\ t \in [1,n]) + (x_r^2+x_rx_s+x_s^2-1 \ |\ \{r,s\} \in E)$. </p>

<blockquote>
  <p>Moreover, every solution to this system yields a coloring and can be calculated by using the reduced Gröbner bases for the ideal $I \subseteq F[x_1, \ldots, x_m]$</p>
</blockquote>

<p>Is it possible to calculate the number of solutions of the system of equations using Gröbner bases and if so how to do that?</p>
",graph_theory
"<p>If $G$ is 2 - self centered graph. then how to prove that $G$ has at least $2n - 5$ edges?
where $n\geq 5$.</p>

<p>I started by assuming if number of edges $\mid E\mid\leq 2n-6$
then there exist a vertex say $u$ such that $deg = 2$ otherwise if no such vertex exists then</p>

<p>$\mid E\mid\geq \frac{3n}{2}&gt;2n-5$ (I am stucked here. How to prove this. Sincerely thanks for giving me time.)</p>
",graph_theory
"<p>Let $m\leq n-1$. Is there a closed expression counting the subgraphs of minimum degree $\geq m$ (resp. maximum degree $\geq m$) on $n$ labelled vertices?   </p>
",graph_theory
"<p>Let's say I'm given several degree sequences like</p>

<p>{4,3,3,2,2}</p>

<p>{3,3,3,3}</p>

<p>{5,3,3,2,2,1}</p>

<p>I can find the number of edges using the handshaking lemma</p>

<p><img src=""http://upload.wikimedia.org/math/7/a/b/7abc7ac49467cd9bcc2260f59a190d00.png"" alt=""graph""></p>

<p>But how do I construct a graph just given these degree sequences? There are multiple types of graphs that satisfy the degree sequences, but beyond guess &amp; checking, is there a logic/pattern to follow when making graphs? Right now I'm at the guess &amp; check stage.</p>
",graph_theory
"<p>Given two Prufer sequences $P_1$ and $P_2$ that correspond to trees $T_1$ and $T_2$ of order $n$  what is the most efficient method to determine whether $T_1$ is isomorphic to $T_2$ as an <em>unlabelled</em> tree? </p>

<p>Having read about the difficulty of detecting isomorphic graphs via graph invariants (<a href=""http://mathoverflow.net/questions/11631/complete-graph-invariants"">http://mathoverflow.net/questions/11631/complete-graph-invariants</a>) I suspect this is a hard problem.   </p>
",graph_theory
"<p>The efficient algorithm needs to be done and proved for the best solution for the given problem:</p>

<p><strong>User inputs:</strong> (#) Size of the NxN Grid. (N); <strong>(#)</strong> No. of Paths:  Z; <strong>(#)</strong> Source and Destination Coordinates of each of the individual Z paths.</p>

<p><strong>Given:</strong> (#) Each path comprises of the cells which are ADJACENT to each other and NOT diagonal.
<strong>(#)</strong> Time taken to cross each cell is EQUAL and is an unit time.
<strong>(#)</strong> Travelling starts from the respective source coordinates of each path in the grid SIMULTANEOUSLY.
<strong>(#)</strong> Paths may intersect, BUT after say 'x'th unit time no two paths must intersect in one particular cell at a time. If such case arises, then one of the paths need to bypass into a new path taking alternate adjacent cell just before the clashing cell.</p>

<p><strong>Output:</strong>
Z no. of paths which are SHORTEST possible without clash.</p>

<p>[Say there are two paths (Z=2), say X to Y and W to Z. While travelling, both X and W start simultaneously from their respective source coordinates, going to their respective destinations Y and Z such that they should take the SHORTEST possible path, AND after 'x'th unit time, they must not CLASH (when both the paths have traveled exactly (x-1) no. of cells and clashing into the 'x'th cell) into one single cell. If that happens, one of the path needs to be bypassed towards its destination keeping in mind without clash, shortest possible path. And this has to be implemented for Z no. of lines starting simultaneously in the grid.]</p>

<p>P.S.- Yes, I should have mentioned it clearly. I mean the total of all the path lengths must be as less as possible. And, since I'm a new user, I wasn't allowed to use any image. Please check the image link as follows so that you can get an idea about the clash thing as how it is supposed to happen: mediafire.com/view/?6y7t8vbtex0s299</p>
",graph_theory
"<p>The <a href=""https://en.wikipedia.org/wiki/Friendship_paradox"" rel=""nofollow"">friendship paradox</a> is sometimes summarised as stating that:</p>

<ol>
<li><strong>Most people have fewer friends than most of their friends.</strong></li>
</ol>

<p>However, the mathematical explanation provided usually shows something different: namely, that</p>

<ol start=""2"">
<li><strong>The average number of friends that a typical person has is less than the average number that a typical friend has.</strong></li>
</ol>

<p>In other words, the average degree of a randomly selected vertex in an undirected graph is less than the average degree of a randomly selected endpoint of a randomly selected edge.</p>

<p>Furthermore, the following variation of the paradox is <em>not</em> always true:</p>

<ol start=""3"">
<li><strong>Most people have fewer friends than their friends have on average.</strong></li>
</ol>

<p>This can be seen by removing one edge from the complete graph $K_5$: 3 out of 5 people then have more friends (4) than their friends do on average (3.5). Note however, that statement 1 is still true for this graph (assuming less-than-or-equals definitions of 'most' and 'fewer') as those 3 don't actually have more friends than half of their friends.</p>

<p><strong>Is statement 1 always true? If not, under what conditions does it hold?</strong></p>

<p><strong><em>Clarification</strong>: statement 1 asserts that for an arbitrary finite undirected graph, fewer than half of the vertices are popular, where a vertex is popular iff it has a greater degree than over half of its neighbours.</em></p>
",graph_theory
"<p>If $G$ be a Tree with degree $(5,r,s,1,1,1,1,1) $. (I wrote degree in non-increasing order). why all of this condition is True sometimes (I means on some condition)? I try to find an example that includes all following condition. any friends could help me?</p>

<p>1) $G$ has a vertex of degree 2.</p>

<p>2) $G$ has a vertex of degree 3.</p>

<p>3) there is two vertices in $G$ that distance between them is 3.</p>

<p>4) there is two vertices in $G$ that distance between them is 4.</p>

<p>Thanks.</p>
",graph_theory
"<p>I am trying to understand the proof to a random graph problem (the threshold for connectivity of $G \sim G(n,p)$ being $\frac{logn}{n}$). I am struggling to see exactly why the following holds:</p>

<p>$\text{When } p^{*} \ll p,\\
n(1-p) ^{n-1} \leq ne^{-p(n-1)} = o(ne^{-\log n}) = o(1).\\$</p>

<p>I am aware that the following inequalities may be used in the derivation but my further deductions (after the $\implies$ symbol) show that the LHS of ($\text{*}$) and RHS of ($\text{**}$) are both greater or equal to the same quantity. However, the line of the proof provided above states something different, to which I am unable to arrive.</p>

<p>$\text{(*) }(1-p)^{n-1} \geq 1 - (n - 1)p, \forall 0 \leq p \leq 1, \text{and}\\
\text{(**) }e^{p} \geq p + 1, \forall p \implies e^{-p(n-1)} \geq 1-(n-1)p.$</p>

<p>Another amateurish question follows here - is the following the case in the last part of the aforementioned line from the proof:
$ne^{-\log n} = nn^{-1} \text{?}$</p>
",graph_theory
"<p>I have been doing practise problems in designing algorithms and came across the following in a past test from an American university (see attached): </p>

<p>A directed graph is <em><strong>unilaterally connected</strong></em> if, for each pair of vertices, there exists a path from one of the vertices to the other. </p>

<p>Design an algorithm to decide whether or not a given graph is unilaterally connected. </p>

<p>Can I please have some help with this? I so far have:</p>

<p>-Run a strongly connected components algorithm on the graph (this then produces a directed acyclic graph where the vertices are the strongly connected components)</p>

<p>-since we have a DAG, we can produce a topological ordering of the DAG</p>

<p>-then we need to somehow use this ordering to decide whether the graph is unilaterally connected or not. </p>

<p>I would appreciate any help/feedback and also any pseudocode to help with visualising exactly how this would work. And obviously suggestions of better algorithms would help too! Thank you. </p>

<p><a href=""http://cs.smith.edu/~streinu/Teaching/Courses/252/Fall00/AllEx/THfinF00.html"" rel=""nofollow"">http://cs.smith.edu/~streinu/Teaching/Courses/252/Fall00/AllEx/THfinF00.html</a> (past test)</p>
",graph_theory
"<p>$\chi(G)$ ( vertex-chromatic number of a graph like $G$) is the minimum number of colors which is enough to color every vertex of $G$ such that no two adjacent vertices have the same color.  </p>

<p>A graph like G is called k-vertex-critical if $\chi(G)=k$ and for each $v \in V(G)\space\space\space\space\chi(G-v) \lt \chi(G)$  .  </p>

<p>$\chi'(G)$ ( edge-chromatic number of a graph like $G$) is the minimum number of colors which is enough to color every edge of $G$ such that no two edges of the same color share a common vertex.  </p>

<p>A graph like G is called k-edge-critical if $\chi'(G)=k$ and for each $e \in E(G)\space\space\space\space\chi'(G-e) \lt \chi'(G)$  .  </p>

<p>Now the question :<br>
Can you find a vertex-critical graph which is not edge-critical?  </p>

<p>Note:  <strong>I don't want</strong> a graph with critical vertices and without critical edges. This question is different. Here, we deal with every edge and every vertex not just one.</p>

<p>Thanks in advance.</p>
",graph_theory
"<p>I am self studying graph theory and was wondering: is there a simple way to count/compute the number of subgraphs G that are isomorphic to another graph (say, G')?</p>

<p>For instance, if G = the complete graph ""K_10"" with 10 vertices, and G' = Hypercube H_3 with 3 vertices</p>

<p>Or, if G = Hypercube ""H_4"" with 4 vertices, and G' = Complete biparite graph ""K_1, 3"".</p>
",graph_theory
"<p>Let $G=(V,E)$ be a countably infinite directed acyclic graph and $L$ be a finite set of vertex labels. The number $\left|V\right|$ of vertices is countable infinity and some vertices may have an infinite number of ingoing edges. I am interested in the existence of labelings $f: V \rightarrow L$ where the label $f(v)$ is determined by the labels of the predecessors of $v$.</p>

<p>More formally, let there be a function $g_v:L^{\mathrm{indeg}(v)} \rightarrow L$ for each vertex $v \in V$. Does there exist a labeling $f : V \rightarrow L$ such that for every vertex $v \in V$ with predecessors $p_0, p_1,\ldots$ the following holds?
$$f(v) = g_v(f(p_0), f(p_1), \ldots)$$</p>

<p>Intuitively, it appears very clear to me that the acyclicity of $G$ guarantees the existence of such labelings $f$. But how do I prove that?</p>

<p>For a trivial example, consider the infinite path $G = (\mathbb{Z}, \{(v,v+1):v\in\mathbb{Z}\})$, $L = \{0, 1\}$ and $g_v:L\rightarrow L:x\mapsto 1 - x$. In this case there are exactly two labelings, one that assigns 0 and 1 to every even and odd vertex, respectively, and the other with 0 and 1 switched.</p>

<p>If we drop the requirement of acyclicity, a counterexample would be an odd directed cycle graph and $L$ and $g$ as in the example above. Here no labeling exists.</p>

<p>In the case of finite DAGs, I would prove the existence inductively over an topological ordering of $G$, starting by an arbitrary label-assignment for vertices without ingoing edges and then iteratively constructing the labeling for vertices whose predecessors have already been labeled. However, I fail to generalize this technique to infinite graphs in the absence of an induction basis.</p>
",graph_theory
"<p>I have to answer the question : ""Is it true that in all finite graphs (connected graphs) wchich $\delta \ge 2$ ($\delta$ is the smallest degree of vertices in a graph) exists the cycle of length equal to $\delta+1$ or longer"". I believe this statement is true. I drew some graphs and it seems to be true. I do not know how to prove this in mathematical way. I will glad for help and advice.</p>
",graph_theory
"<p>Let $f:G \to G$ be a bijective function on a finite simple connected graph which preserves adjacency (if $x$ is adjacent to $x'$ then $f(x)$ is adjacent to $f(x')$). Is $f$ automatically a graph automorphism?</p>
",graph_theory
"<p>I was reading up on probabilistic graphical theory and it's not very clear how the flow of probabilistic influence differs between directed and undirected graph. My initial assumption was that flow is one way i.e. from parent to child only in case of directed graphs but that does not seem to be the case. </p>

<p>I will highly appreciate if anyone can elaborate upon this? </p>
",graph_theory
"<p>How to prove that the number of unlabeled binary trees is the same as the number of Binary Search Tree possible. I know the number of binary search tree is equal to nth catalan number but how would I prove that this is equal to the number of unlabeled binary tree.</p>
",graph_theory
"<p>Can someone explain to me how these graphs are homeomorphic?</p>

<p><img src=""http://i.imgur.com/BocvrbP.png"" alt=""1"">
<img src=""http://i.imgur.com/Yif4Yqw.png"" alt=""2""></p>
",graph_theory
"<ol>
<li><p>Can every disconnected graph be decomposed into 2 disjoint subgraphs ? If yes then edge-disjoint or vertex-disjoint ? and Why ?
If not then what are the exceptions ?</p></li>
<li><p>Given n vertices is it always possible to draw edges such that the graph has a hamiltonian circuit ?</p></li>
<li><p>Can we say that every connected graph is either an Euler graph or an unicursal graph ?</p></li>
</ol>

<p>PS:I am fairly new to Graph Theory, and I am learning on my own. Please don't mind if the question is not technically correct. I just want to get the concepts clear.</p>
",graph_theory
"<p>I am currently working on determining the maximum number of times the minimum spherical distance can occur among $n$ points in $\mathbb{S}^2$, and I have the following question.</p>

<blockquote>
  <p>In $\mathbb{E}^2$, I cite from Pach and Agarwal's Combinatorial Geometry: ""The internal angle of a simple closed polygon $C$ which bounds a graph $G$ at a vertex of degree $d$ is at least $(d-1)\frac{\pi}{3}$."" How does this statement generalize to $\mathbb{S}^2$?</p>
</blockquote>

<p>In particular, I am not sure how the statement is arrived at in $\mathbb{E}^2$, and for this reason I am unable to generalize it to $\mathbb{S}^2$.</p>

<p>EDIT: To make the question clear, I am asking for a proof or explanation of the statement quoted in $\mathbb{E}^2$, and maybe an idea for how to generalize it to $\mathbb{S}^2$. An explanation of the statement in $\mathbb{E}^2$ is sufficient for an accepted answer though. When I try constructing a graph the $(d-1)\frac{\pi}{3}$ makes sense and gives a lower bound for the angle at a vertex of degree $d$ but I don't know where it is coming from.</p>
",graph_theory
"<p>Suppose I have an linear transformation described by a square matrix $A$.
Then, $A$ takes a vector $x\in\mathbb{R}^n$ to a vector $y\in\mathbb{R}^n$ related to $x$ by the equation $y=Ax$.</p>

<p>Grant Sanderson defined the determinant of $A$ on his youtube series on linear algebra in the following way:</p>

<p>Two vectors $x$ and $y$ determine a unique paralelogram. On the same way $Ax$ and $Ay$ determine another paralelogram. The ratio between its areas is defined to be the determinant of $A$. That is $|\det(A)|=\text{Area}(Ax,Ay)/\text{Area}(x,y)$. (The sign of the determinant is given by the orientation of the vectors. If $A$ preserves orientation, its determinant is positive.)</p>

<p>Can't we define a determinant to non-square matrices by the same formula?</p>

<p>Link to Grant's video: <a href=""https://www.youtube.com/watch?v=v8VSDg_WQlA"" rel=""nofollow"">https://www.youtube.com/watch?v=v8VSDg_WQlA</a></p>

<p>EDIT: (Example)
Take 
$$A=\begin{bmatrix}
1 &amp; 2 \\
3 &amp; 4
\end{bmatrix}$$
and
$$x=\begin{bmatrix} 1 \\ 0\end{bmatrix}, \quad y=\begin{bmatrix} 0 \\ 1\end{bmatrix}.$$
Using the notation defined above, we clearly have $\text{Area}(x,y)=1$.
We have that $$Ax=\begin{bmatrix} 1 \\ 3\end{bmatrix}, \quad Ay=\begin{bmatrix} 2 \\ 4\end{bmatrix}$$ too. So, $\text{Area}(Ax,Ay)=2$. Then the ratio between the areas is $2$, which coincides with the modulus of the determinant of $A$. (Of course $A$ changes the orientation of the vectors, so it's determinant is negative.)</p>

<p>EDIT 2: Here's an explicit definition of the determinant.
$$|\det(A)| =
  \begin{cases}
    \text{Area}(Ax,Ay)/\text{Area}(x,y)       &amp; \quad \text{if } \text{kernel}(A) \text{ is zero}\\
    0  &amp; \quad \text{if } \text{kernel}(A) \text{ is non-zero}\\
  \end{cases},$$
for any linearly independent vectors $x$ and $y$.</p>

<p>If $A$ preserves orientation, then $\det(A)&gt;0$. $\det(A)\leq 0$ otherwise.</p>
",linear_algebra
"<p>Let $T$ be a linear operator on a vector space $V$ such that its matrix representation with respect to the basis $(v_1, v_2, v_3, v_4, v_5, v_6)$ is</p>

<p>\begin{bmatrix}
    1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
    0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 \\
\end{bmatrix}</p>

<p>Find a basis for $V$ such that the matrix associated to $T$ is</p>

<p>\begin{bmatrix}
    2 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 2 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
    0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}</p>

<p>From the first matrix, I can tell the following information:
$$T(v_1)=v_1,$$
$$T(v_2)=v_1+v_2,$$
$$T(v_3)=v_3,$$
$$T(v_4)=2v_4+v_5,$$
$$T(v_5)=2v_5+v_6,$$
$$T(v_6)=2v_6.$$</p>

<p>Does that information help me attain any information on the basis associated to the second matrix? These matrices look like they are in Jordan form (almost), but I don't know what to do with that information. Please help me! Thank you.</p>
",linear_algebra
"<p>Let $\left\{ q_1, q_2, q_3, q_4 \right\}$ be an orthonormal basis of an inner product space $H$, and let</p>

<p>$$H_1=\text{span} [q_1, q_2], \quad H_2=\text{span} [q_3, q_4]. $$</p>

<p>Let $T$ be an operator on $H$ that satisfies</p>

<p>$$ Tw= \alpha w \quad \forall w\in H_1, \quad \quad Tw'=I\alpha w' \quad\forall w'\in H_2, $$</p>

<p>where $\alpha \neq 0$ is a complex number and $I$ is the imaginary unit. Show that $T^4=\alpha^4 I$. Use this to give a closed form for $T^{-1}$.</p>

<p>Here is what I have done:</p>

<p>Since $\left\{ q_1, q_2, q_3, q_4 \right\}$ is an orthonormal basis of $H$, then $H=H_1 \oplus H_2$ $\,$ ($H$ is the direct sum of $H_1$ and $H_2$), since every vector in $H_1$ is orthogonal to every vector in $H_2$, and vice versa. </p>

<p>Let $v\in H$. Then we can uniquely express $v=w+w'$, where $w \in H_1$ and $w'\in H_2$. Then
$$Tv=Tw+Tw'=\alpha(w+iw'),$$
$$T^2v= \alpha T(w+iw')=\alpha^2(w-w'),$$
$$T^3v=\alpha^2T(w-w')=\alpha^3(w-iw'),$$
$$T^4v=\alpha^3T(w-iw')=\alpha^4(w+w')=\alpha^4v=\alpha^4Iv.$$</p>

<p>Hence, $T^4=\alpha^4 I$.</p>

<p>How can I use this to find a closed form for $T^{-1}$? Since $T^4=\alpha^4 I$ I know that $T^4$ is invertible, but I am not sure where to go from there. I appreciate any help.</p>
",linear_algebra
"<p>Define a series of matrices$$H_N=
\begin{bmatrix}
1&amp;1/N&amp;1/N&amp;\cdots&amp;1/N\\
1/N&amp;2&amp;1/N&amp;\cdots&amp;1/N\\
1/N&amp;1/N&amp;3&amp;\cdots&amp;1/N\\
\vdots&amp;\vdots&amp;\vdots&amp;&amp;\vdots\\
1/N&amp;1/N&amp;1/N&amp;\cdots&amp;N
\end{bmatrix}$$
My question is, when $N\to+\infty$, would the eigenvalues of $H$ be different from $\{1,\ldots,N\}$ ?
The answer is not obvious, as,  for the matrix series
$$G_N=\begin{bmatrix}
1&amp;1/N&amp;1/N&amp;\cdots&amp;1/N\\
1/N&amp;1&amp;1/N&amp;\cdots&amp;1/N\\
1/N&amp;1/N&amp;1&amp;\cdots&amp;1/N\\
\vdots&amp;\vdots&amp;\vdots&amp;&amp;\vdots\\
1/N&amp;1/N&amp;1/N&amp;\cdots&amp;1
\end{bmatrix}$$
You can verify that $G_N$ has an eigenvalue of $2$.</p>
",linear_algebra
"<p>Number of 2x2 matrix over $z_3$ with determinant 1 
I know number of elements in $z_3$ are {0,1,2} now possibly determinant can be 1 in this case </p>

<p>$$
\begin
{bmatrix}
1&amp;2\\
0&amp;1\\
\end{bmatrix}
$$
and there can be many more but how to find the exact number of such matrices? ""the answer is 24""</p>
",linear_algebra
"<p>If there are two subspaces of Euclidean space of dimension $n$, denoted as $R_1$ and $R_2$. Suppose that $M$ is $n$ by $n$ matrix, and suppose that $R_1$, $R_2$ and their orthogonal complement are invariant with left multiplication of $M$.</p>

<p>The problem is to prove that the orthogonal complement of intersection of $R_1$ and $R_2$ are invariant with $M$ as well.</p>
",linear_algebra
"<p>For each of the following linear operators:</p>

<ul>
<li>Choose a basis in each of L, M</li>
<li>Find the corresponding matrix of given linear operator D : L → M</li>
</ul>

<p>a) L = {f(x); f(x) is a polynomial, degree of f is ≤ 3}, </p>

<p>M = {f(x); f(x) is a polynomial, degree of f is ≤3 and f(1)=f′(1)=0},</p>

<p>D(f)=(x−1)2f′′</p>

<p>This is what work is done thus far, any suggestions after this?</p>

<p>f: ax<sup>3</sup> + bx<sup>2</sup> + cx + d</p>

<p>f ': 3ax<sup>2</sup> 2bx + c</p>

<p>f '': 6ax + 2b</p>

<p>f<sub>new</sub>: 6ab(x-1)<sup>2</sup> + 2b = 6a(x<sup>2</sup>-2x+1)+2b = 6ax<sup>2</sup>-12ax+6a+2b</p>
",linear_algebra
"<blockquote>
  <p>Consider a linear map $L:\mathbb{R}^3 \to \mathbb{R}^3$ with
  $L\left( {\bf x} \right) = \left[ {\begin{array}{*{20}{c}}
1&amp;0&amp;1\\
1&amp;1&amp;2\\
2&amp;1&amp;3
\end{array}} \right]{\bf x}$. Show that this $L$ is not one-to-one.</p>
</blockquote>

<p>I know this is not one-to-one because the kernel of $L$ is not $\{{\bf 0}\}$. However, if I want to stick with the one-to-one definition, I got some trouble there. Here is my thinking: Assume
$L({\bf x}) = L({\bf y})$, then I must show ${\bf x} = {\bf y}$. So pick 
${\bf x} = [x_1, x_2, x_3]^T$ and ${\bf y} = [y_1, y_2, y_3]^T$ both lives in $\mathbb{R}^3$.
Then from the hypothesis of $L({\bf x}) = L({\bf y})$, I got
$$\left[ \begin{array}{l}
{x_1} + {x_3}\\
{x_1} + {x_2} + 2{x_3}\\
2{x_1} + {x_2} + 3{x_3}
\end{array} \right] = \left[ \begin{array}{l}
{y_1} + {y_3}\\
{y_1} + {y_2} + 2{y_3}\\
2{y_1} + {y_2} + 3{y_3}
\end{array} \right]$$
I think this should gives me $x_i = y_i$ for $i=1,2,3.$ which means ${\bf x} = {\bf y}$. and I got $L$ one-to-one but this contradicts to the kernel statement...</p>

<p>Can anyone help to pointing out which part I went wrong. Thank you.</p>
",linear_algebra
"<p>In the last 2 lectures of linear algebra we have talked about linear mappings and other stuff, but I missed actually the last one and I am quite in bad situation.</p>

<p>What matrix transforms $\left(\begin{matrix} 1 \\ 0\end{matrix}\right)$ into $\left(\begin{matrix} 2 \\ 6\end{matrix}\right)$ and tranforms $\left(\begin{matrix} 0 \\ 1\end{matrix}\right)$ into $\left(\begin{matrix} 4 \\ 8\end{matrix}\right)$?</p>

<p>I think I understood what I need to find: a matrix that multiplies our initial matrix formed by our initial vectors $$\left(\begin{matrix} 1 &amp; 0 \\ 0 &amp; 1\end{matrix}\right)$$ </p>

<p>and the resulting matrix is:
$$\left(\begin{matrix} 2 &amp; 6 \\ 4 &amp; 8\end{matrix}\right)$$</p>

<p>Am I right?</p>

<p>Is there a way to automate this process? </p>
",linear_algebra
"<p>Like the title says, ""If an $n\times n$ matrix $A$ is diagonalizable and has only one eigenvalue $\lambda$ with multiplicity $n$, then $A = \lambda I$. True or False?"" </p>

<p>My gut is telling me that this is true, but I'm having a little difficulty proving it formally. There's probably a very obvious proof, but thus far it has alluded me. </p>

<p>In any case, this is what I've done:</p>

<p>Since $A$ is diagonalizable, there exists a factorization such that $A = S^{-1}\Lambda S$. Since we know the eigenvalues are $\lambda$ with multiplicity $n$, $\Lambda = \text{diag}(\lambda, \lambda, ...)$. </p>

<p>If I'm given $A = \lambda I$, it's easy to show $\lambda I = S^{-1}\Lambda S$ where $S = I$ and $\Lambda = \text{diag}(\lambda, \lambda, ...)$. (Having normalized the eigenvectors). The trouble I'm having is showing $A = \lambda I$ under the given conditions. </p>

<p>I can simply let $S = \lambda I$, and thus $A = \lambda I$, but something about this approach feels off. (This is just my line of thought right now).</p>

<p>Any input would be appreciated.</p>
",linear_algebra
"<p>I have just started auditing Linear Algebra, and the first thing we learned was how to solve a system of linear equations by reducing it to row echelon form (or reduced row echelon form). I know how to solve a system of linear equations using determinants, and so the using row echelon form seems to be very inefficient and an easy way to make mistakes.</p>

<p>The lecturer seemed to indicate that this will be useful in the future for something else, but a friend who has a PhD in mathematics said it is totally useless.</p>

<p>Is this true? Is this technique totally useless or is there some ""higher mathematics"" field/ technique where row echelon form will be useful?</p>
",linear_algebra
"<p>I am working a bit on a collection of Linear Algebra examples, 
as well as some examples on induction. This is what is taught freshman year at our university.</p>

<p>I intend to release this to the public, either by selling printed copies or releasing it online. </p>

<p>Since I do not have experience using such material myself, there are some questions I would like some opinions on:</p>

<ul>
<li>How much theory should I include? Is references to course litterature enough?</li>
<li>Is there a format preference? Small text, so that the collection is more enviromental-friendly, or with big marginals for notes?</li>
<li>Best way to deal with misprints?</li>
<li>Should induction and Linear algeba be separate pieces? </li>
</ul>

<p>Please share your experience if you have done something similar.</p>

<p>EDIT:
An answer I seek is something along the lines of:
""I am a ""something"" stident, and I prefer ""something"", and would like to see more of ""something"".</p>
",linear_algebra
"<p>I have a 2x2 matrix A with rows (1 0) and (1 1).  How can I find their matrix exponential, e^A ?</p>

<p>I understand I need to plug it into the Taylor series but I'm lost at how to solve the series here.</p>
",linear_algebra
"<p>A tutorial sheet has the following problem.</p>

<blockquote>
  <p>Find a unit normal vector and a basis for the tangent space of the
  following smooth manifold $M \subseteq \mathbb{R}^2$ at a point $(a,b) \in M$. $$M=\{(x,y) \in \mathbb{R}^2 : x^2+y^2=1\}$$</p>
</blockquote>

<p>The idea is to do it without finding an explicit parametrization for $M$ (although of course, that is quite easy.)</p>

<p>The solution sheet says this:</p>

<blockquote>
  <p>Have $f(x,y) = x^2+y^2 = 1$ so a normal is $\nabla f = (2x,2y) = (2a,2b)$ at $(x,y) = (a,b)$.</p>
  
  <p>Tangent space = $\mathrm{ker}(Df) = (\nabla f)^\perp = \{v \in \mathbb{R}^2 : v \cdot (2a,2b) = 0\}$ has basis $\{(-b,a)\}$.</p>
</blockquote>

<p>The stuff about normals makes sense, but I don't get the line about tangent spaces. In particular:</p>

<ol>
<li>What is the difference between $Df$ and $\nabla f$? Aren't they the same?</li>
<li>How do we get from $\mathrm{ker}(Df)$ to $(\nabla f)^\perp$? What is the general principle here?</li>
</ol>
",linear_algebra
"<p>Hi I am trying to work on a proof question that I took note of because the answer did not come to mind immediately. I also found it was a good question to illustrate something I do not understand very well.</p>

<p>The question asks to prove, or disprove that if the system $AX=0$ has infinite solutions, then so to does the system $AX=B$ for any choice of $B$.</p>

<p>First off, I get confused by ""For any choice of $B$"". I thought $B$ represented the column of constants? How could you choose any $B$? Is that not implying that $B$ can be $(a,b,c,,,n)$ for any $a,b,c,,n$, in the real numbers?</p>

<p>Anyways, in regards to the proof. I know that if $AX=0$ has infinite solutions, then there must be atleast one parameter, thus $(n-r)\geq 1$ where $n$ is the number of variables and $r$ the rank of the matrix. I am not sure where to go from here. </p>

<p>Hopefully you guys can help me with this and get a better understanding!</p>

<p>Thank you,</p>
",linear_algebra
"<p>Denote: $[A]$ as the span of $A$. <br></p>

<p>Theorem: Every linearly independent subset of a vector space is a subset of a basis of a space. <br></p>

<p><em>Proof:</em> Let $A$ be a linearly independent subset of a vector space $V$ and let $\,B\,$ be a basis of $\,V$. <br></p>

<p>Case 1. $B\subseteq [A]\,$. Then $\,[B]\subseteq [A]\,$. But $\,[B]=V\,$ , hence, $\,A=B\,$. <br></p>

<p>Case 2. $B\not\subseteq [A]$. Then there exists $\alpha \in B$ such that $\alpha \not\in [A]$.
Thus $A\cup \{\alpha\}$ is linearly independent. Repeat the argument until an enlarged set is produced that spans $V$.</p>

<blockquote>
  <blockquote>
    <p>My question is: In case 2, how is it that $A$ is contained in a basis $B$? I just can't get the idea in the <em>repeating the argument</em> part. Thanks for your help.</p>
  </blockquote>
</blockquote>
",linear_algebra
"<p>In my class we're learning vector spaces, and in the text book there's an example with no solution and it goes like this:</p>

<blockquote>
  <p>If the domain of functions $f$ and $g$ is $[-1,1]$ and if they are defined $f(x) = \arcsin\left(\displaystyle\frac{2x}{1+x^2}\right)$ and $g(x) = \arctan(x)$, then $(f,g)$ is linearly independent?</p>
</blockquote>

<p>I don't know how to prove this, if I can make a linear combination of one of them using the other it's dependent, but how should I go about doing that?</p>

<p>Thanks in advance.</p>
",linear_algebra
"<p>Let $P_3(R)$ be the vectorspace of all real polynomials $\le 3$, such that the polynomial $p(x)=a_0+a_1x+a_2x^2+a_3x^3$ and let T be the linear operator on $P_3(R)$ that we get by defining $T$ as $T(p(x))=(x^3+x)p''(x)-2x^2p'(x)$ for all polynomials $p(x)\in P_3(R)$. Now decide a basis for the nullspace and the columnvector-space(Is this the same as $Im\,T$ in  english?) for $T$ or show that is only contains the zero-polynomial. Furthermore, find all eigenvalues for $T$, and examine if $T$ is diagonalizable(correct translation?)?</p>

<p>$p'(x)=a_1+2a_2x+3a_3x^2$, $p''(x)=2a_2+6a_3x$ </p>

<p>$Attempt:$
$T(a_0+a_1x+a_2x^2+a_3x^3)=(x^3+x)(2a_2+6a_3x)-2x^2(a_1+2a_2x+3a_3x^2) = x(2a_2)+x^2(-2a_1-4a_2+6a_3)+x^3(2a_2)=a_0(0)+a_1(-2x^2)+a_2(x-4x^2+2x^3)+a_3(6x^2)$</p>

<p>For the nullspace, let us find the solutions to $T(a_0+a_1x+a_2x^2+a_3x^3)=0$
Which means that $2a_2=-2a_1-4a_2+6a_3=2a_2=0 \to a_1=a_2=a_3=0$ If this is true then $a_0=0$. And the nullspace only contains the zero-polynomial. Im confused here, is this correct?   </p>

<p><em>Edit</em>: After correcting the computation mistake - I tried to convert to matrix-format, and got that the nullspace is spanned by $[1,3x+x^3]$. If this is correct, I should be able to continue.</p>

<p>For the $Im(a)$(?) we have $a_0(0)+a_1(-2x^2)+a_2(x-4x^2+2x^3)+a_3(6x^2)$ so we get the basis $[-2x^2, x-4x^2+2x^3,6x^2]$. I dont really understand this, and it´s probably wrong.</p>

<p>To find the eigenvalues we need to get this in matrix-form, right? How do we translate it into a matrix? If I could do that it would probably be easier for me to uderstand the basis aswell...</p>
",linear_algebra
"<p>Let $K/k$ be an extension of fields and let $v_1,\ldots,v_r,u_1,\ldots,u_r\in k^n$.  If the span of the $v$'s over $K$ equals the span of the $u$'s over $K$, must the two spans also be equal over $k$?</p>

<p>$$_K\langle v_1,\ldots,v_r\rangle=_K\langle u_1,\ldots,u_r\rangle\qquad\overset{?}\Longrightarrow\qquad_k\langle v_1,\ldots,v_r\rangle=_k\langle u_1,\ldots,u_r\rangle$$</p>

<p>Here is another way to look at this question: Given a subspace $U\subset K^n$ with some basis in $k^n$, is the procedure of restricting scalars to $k$ well-defined, or does it depend on the choice of basis of $U$?</p>
",linear_algebra
"<p>The information I have is for a matrix transformation from R^3 to R^3 (denoted by L()), L(a_1) = 3(a_1) and L(2(a_1))= (5,-3,6). Find L(3a_1-22a_1), L(-4a_1), L(0), L(4a_1).</p>

<p>What I tried to do was first solve for a_1. I factored out the two of L(2a_1) and then replaced L(a_1) with 3a_1. Resulting in the equation 2*3a_1 = (5,-3,6) so a_1 = (5/6,-1/2,1). </p>

<p>Now I tried to reduce L(3a_1 - 22a_1) to -19L(a_1) but that was not the correct answer, tried the same process with L(-4a_1)  = -2L(2a_1) which was also not the right result. </p>

<p>Not sure about L(0), I am assuming the zero represents the zero vector for R^3, but I would think that transforms to the zero vector but apparently not. </p>

<p>I'm sure I am misunderstanding the theory somewhere but I am not sure where. One thought I had was that I was using the properties of linear transformations but the problem only specified that it was a ""matrix transformation"". Any help is greatly appreciated. </p>
",linear_algebra
"<p>What is the derivative of Hadamard product of two matrices with respect to one of them?
I.e. what is $D(AB)$ with respect to $A$?</p>
",linear_algebra
"<p>Let $\ell^\infty$ be the bounded sequence space over the complex numbers and let $c_0$ the subspace of all sequences converging to $0$. </p>

<p>I am attempting to show that $\ell^\infty/c_0$ has infinite dimension. </p>

<p>I have looked at several different ways to show this but I think perhaps the easiest is to show that there exists an infinite linearly independent set in the quotient. It is easy to find an infinite countable set in $\ell^\infty$ (just take the sequences of the form $(0,\dots,0,1,0,\dots)$, but of course this set is identified in the quotient). I also was thinking of doing a proof by contradiction, and show that no matter what finite linearly independent set in $\ell^\infty/c_0$ you give, we can construct a sequence not in the span. But the precise way to construct such a sequence is not evident to me at this point (some sort of diagonal argument, perhaps).  </p>

<p>Will a cardinality argument be necessary?</p>
",linear_algebra
"<p>For the dynamic system $\dot x = Ax + Bu$ </p>

<p>There's a saying that this system is controllable when $Ker(B) \in Ker(A)$, which means that $u$ have the control in every dimension of $x$.</p>

<p>I have no problem with this theorem when you have single input $u$, which means $u$ is just a number and $B$ is with $n\times1$ dimension.</p>

<p>But I cannot completely understand when $u$ is a vector. Look at this example:</p>

<p>$A = \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 
                     0 &amp;0&amp;0&amp;0\\0 &amp;0&amp;0&amp;0\\0 &amp;0&amp;0&amp;0\\ \end{bmatrix}$ , 
$B = \begin{bmatrix} 0&amp;0\\0&amp;0\\0&amp;0\\0&amp;0\\\end{bmatrix}$</p>

<p>This is obvious uncontrollable. However, look at the null space:</p>

<p>$Ker(A)=span\{\begin{bmatrix} 0\\1\\0\\0\\ \end{bmatrix},
            \begin{bmatrix} 0\\0\\1\\0\\ \end{bmatrix},
            \begin{bmatrix} 0\\0\\0\\1\\ \end{bmatrix} 
            \}$</p>

<p>$Ker(B)=span\{\begin{bmatrix} 1\\0 \end{bmatrix},
              \begin{bmatrix} 0\\1 \end{bmatrix}
            \}
$</p>

<p>Thus we have $Ker(B) \notin Ker(A)$, but this system is uncontrollable.</p>

<p>Can anyone help me with this contradictory?</p>

<p>Thank you very much and I appreciate all of your replies!</p>
",linear_algebra
"<p>Let $A \in \mathbb{C}^{n \times n}$ be an upper triangular matrix that satisfies $A^{*}A=AA^{*}$. Prove that $A$ must be diagonal.</p>

<p>My attempt is to partition $A$ as follows:</p>

<p>$$
A = \left[\begin{array}{cc} a_{11} &amp; \alpha\\
0 &amp; \hat{A}\end{array}\right]
$$</p>

<p>where $\alpha = (a_{12}, a_{13}, \cdots , a_{1n})$ and $\hat{A}$ is $A$ with the first row and column removed. Using this partitioning, we have:</p>

<p>$$
A^{*}A = \left[\begin{array}{cc} a_{11}^{2} &amp; a_{11}\alpha\\
a_{11}\alpha^{*} &amp; \alpha^{*}\alpha + \hat{A}^{*}\hat{A}\end{array}\right]
$$
$$
AA^{*} = \left[\begin{array}{cc} a_{11}^{2} + \alpha\alpha^{*} &amp; \alpha\hat{A}^{*}\\
\hat{A}\alpha^{*} &amp; \hat{A}\hat{A}^{*}\end{array}\right]
$$</p>

<p>Examining entry (1,1) of each of these matrix products, we see that $\alpha\alpha^{*} = 0$. From this, I would like to conclude that $\alpha = 0$ and thus, the first row of $A$ has non-zero entry only at (1,1). Then repeat this process continuously on $\hat{A}$.</p>

<p>However, I can see a flaw in my argument. If the entries of A were real, then this argument seems like it would work. But since the entries can be complex, this means that $\alpha\alpha^{*} = 0$ even with $\alpha \ne 0$. For example, $\alpha = (1, i, 1, i)$ gives $\alpha\alpha^{*} = 0$.</p>

<p>Any ideas how to proceed here? I know that with this partitioning, I must have $\alpha = 0$ since the problem statement is true (i.e. $A$ is diagonal).</p>
",linear_algebra
"<blockquote>
  <p>Let $\mathbb{R}^3$ be a vector space with canonical product, and $\alpha \in \mathbb{R}$. For each $\alpha$ let $F_{\alpha}=\{(x,y,z) \in \mathbb{R}^3: x=\alpha y \wedge \alpha y=\alpha z\}$ be a subspace.</p>
  
  <p>Find a basis for $F_{\alpha}$, based on $\alpha$.</p>
</blockquote>

<p>My work was:</p>

<p>$$
\begin{cases}
x=\alpha y \\
\alpha y=\alpha z
\end{cases} \Leftrightarrow\begin{cases}
x=\alpha y \\
\alpha y-\alpha z=0
\end{cases} \Leftrightarrow\begin{cases}
x=0 \\
\alpha=0 
\end{cases} \vee \begin{cases}x= \alpha z \\y=z \end{cases} $$</p>

<p>If $\alpha=0$ then $F_{0}=\{(0,y,z): y,z \in \mathbb{R}\}$. So $F_{0}=\langle (0,1,0),(0,0,1)\rangle$.</p>

<p>If $\alpha \neq0$ then $F_{\alpha}=\{(\alpha z,z,z): \alpha, z \in \mathbb{R}\}$. So $F_{\alpha}=\langle (\alpha,1,1)\rangle$.</p>

<p>But now which will be the basis of $F_{\alpha}$ based on $\alpha$ ? Thanks.</p>
",linear_algebra
"<p>I have determined a tangent plane to be
$$z = a(-b+y) + x(b-1)$$
$$ab = x(b-1) + ay - z$$
At the point (a,b)</p>

<p>I want to determine the normal to this plane as a function of a and b. I am not entirely sure as to what this means ""As a function of a and b"".</p>

<p>So I assume I will find the normal using the dot product of plane to normal = 0.
$$(b-1, a,-1) * (\zeta,\beta,\gamma) = 0$$
$$\zeta(b-1) + \beta*a - \gamma = 0$$
$$-\frac{\zeta(b-1) + \gamma,}\beta = a$$
$$\frac{a\beta - \gamma,}\zeta + 1 = b$$</p>

<p>I am not sure if this is what is wanted, or if there is a better way to solve this. If anyone can shed some light, that would be appreciated. This is from a past exam 2012S2 UQ, for course 'Multivariate Calculus and Ordinary Differential Equations'.</p>
",linear_algebra
"<p>Is it true that If the 2-norm of a symmetric real matrix is small, then the trace of the matrix is also small? I played around with some matrices in MATLAB and discovered this phenomenon. Does there exist any theorem that relates the 2-norm of a symmetric real matrix to the magnitude of its trace? </p>

<p>Thanks.</p>
",linear_algebra
"<p>Consider 
$$ S = \left\{(x,y) \in \mathbb{R}^2; -N-\frac{1}2 \le x \le N + \frac{1}2, |\alpha x-y| \le \frac{1}N \right\}$$</p>

<p>where $N \in \mathbb{N}, \alpha \in \mathbb{R}$.</p>

<p>I'm having a hard time beliveing that $S$ is convex and Area $S &gt; 4$. Can someone please elaborate why? </p>

<p>Thanks.</p>
",linear_algebra
"<p>So, I used Gaussian elimination on this matrix</p>

<p>$$\left( \begin{array}{c} -1 &amp; 3 &amp; 5 &amp; 13 \\ 3 &amp; -2 &amp; 2 &amp; 16 \end{array}\right)$$</p>

<p>to turn it to this:</p>

<p>$$\left( \begin{array}{c} -1 &amp; 3 &amp; 5 &amp; 13 \\ 0 &amp; 7 &amp; 17 &amp; 55 \end{array} \right)$$</p>

<p>I don't think this could be eliminated any further. </p>

<p>Which gives me these two equations:</p>

<p>$$-1a + 3b + 5c = 13$$</p>

<p>$$          7b + 17c = 55$$</p>

<p>Is there another method after this to simplify finding what the variables are, or is the only way to guess and check?</p>

<p>Thank you.</p>
",linear_algebra
"<p>If I have a set $S$ of vectors, say,
$$S=\{[4,6,2],[8,3,8],[2,4,5] \}.$$</p>

<p>How can I get all linear combinations of these vectors such that the linear combination will equal $[180,180,90]$ ?</p>

<p>edit:</p>

<p>I should be more specific, I am concerned with a set $S$ of arbitrary size. if the size of $S$ is greater than $3$, I will have free variables in my solution, right? Doesn't that mean that there are infinitely many solutions to the equality</p>

<p>suppose I am interested in all of those such that all constant multiples of the vectors in $S$ are greater than $0$. How would I go about finding the existence, and the exact values of such constants.</p>
",linear_algebra
"<p>Assume $A,B \in M_{n\times m}(\Bbb{R})$,and $A^TA=B^TB$,show that there exists an orthogonal matrix $P$, such that $A=PB$. </p>
",linear_algebra
"<p>Let $A$ be a linear operator which acts on the vector space $V=\langle x_1,x_2, \ldots,x_n\rangle$  by permutation of the basis vectors. Suppose we know its eigenvalues ( some roots of unity  ): $\lambda_1, \lambda_2, \ldots, \lambda_n.$</p>

<p>Now consider the vector space $V^{(2)} \subset {\rm Sym}^2 V$ generated by elements $x_i x_j, i&lt;j,$ $\dim V^{(2)}=\binom{n}{2}.$ Let us expand the operator $A$ on $V^{(2)}$    by linearity and by $A(x_i x_j)=A(x_i)A(x_j)$. Denote the extension by $A^{(2)}$. It is clear that  $A^{(2)}$ permutes the basis vectors of   $V^{(2)}$ so $A^{(2)}$   is an endomorphism of $V^{(2)}$.</p>

<p><strong>Question.</strong> What is the trace  of the $A^{(2)}?$ </p>

<p>By  method of trial and error I have found a formula for the trace
$$
{\rm Tr}(A^{(2)})=\sum_{i=1}^n\lambda_i^2+\sum_{i&lt;j}\lambda_i \lambda_j-\sum_{i=1}^n \lambda_i
$$
but I can't prove it. Any ideas?</p>
",linear_algebra
"<p>We need to determine values of k for which these have zero, one and infinite solutions.
$$x-2y=1,x-y+kz=-2,ky+4z=6$$
Now what I did:
$$A=\begin{pmatrix}1&amp;-2&amp;0\\1&amp;-1&amp;k\\0&amp;k&amp;4\end{pmatrix}$$ and $|A|=4-k^2$. When it has zero solution or when it is inconsistent we have $k^2=4\implies k=\pm 2$</p>

<p>When it is consistent or has one or infinite solutions then $|A|\ne0\implies k\ne\pm2$. How to differentiate between one and infinite solutions case of k.</p>

<p>I have also made rref:
$$M\sim\left[\begin{array}{ccc|c}1&amp;-2&amp;0&amp;1\\1&amp;-1&amp;k&amp;-2\\0&amp;0&amp;4-k^2&amp;6+k\end{array}\right]\sim\left[\begin{array}{ccc|c}1&amp;-2&amp;0&amp;1\\0&amp;1&amp;k&amp;-3\\0&amp;0&amp;4-k^2&amp;6+k\end{array}\right]\sim\left[\begin{array}{ccc|c}1&amp;-2&amp;0&amp;1\\0&amp;1&amp;k&amp;-3\\0&amp;0&amp;1&amp;\frac{6+k}{4-k^2}\end{array}\right]$$</p>
",linear_algebra
"<p>Given a $n \times n$ matrix $A = \begin{bmatrix}
a_1 &amp; a_2 &amp; \dots &amp; a_n
\end{bmatrix}$, where each $a_i$ are columns of $A$ for $i = 1 \dots n$.</p>

<p>Column mean is calculated by $\bar{a} =(a_1 + a_2 + \dots + a_n)/n$.</p>

<p>Then, define:</p>

<p>$B = \begin{bmatrix}
a_1 - \bar{a} &amp; a_2 - \bar{a}&amp; \dots &amp; a_n - \bar{a}
\end{bmatrix}$.</p>

<p>May I know why the rank$(B)$ is $n-1$?</p>

<p>I did try many times with computer program to prove but I want a proof of this.</p>

<p>Thanks in advance.</p>
",linear_algebra
"<p>I have the following 2 equations:</p>

<p>${6x + 9y = 3}$</p>

<p>${6x -3y = -2}$</p>

<p>The textbook asks to use the substitution method so I would appreciate if we stuck to this method, I could use the addition method but the book asks for this method.</p>

<p>So my steps of doing this are to isolate x in the first equation:</p>

<p>${6x + 9y = 3}$</p>

<p>I then divide both sides by 3 to give</p>

<p>${2x + 3y = 1}$</p>

<p>I then get:</p>

<p>${x = {-3y + 1\over 2}}$</p>

<p>I'm not entirely sure you to take this further using the substitute method.</p>
",linear_algebra
"<p>What is the generalization of the Pauli matrices and Dirac matrices in higher dimensions? I am actually looking for $\sqrt{\mathbb{I}}$ but I can't use the principal root which is just $\mathbb{I}$. For $n=3$, I found that the Gell-Mann matrices don't work. I'm thinking that these actually are the $SU(n)$ generators. Any ideas?</p>
",linear_algebra
"<p>I'm wondering about this problem on bilinear forms :</p>

<p>We have $\phi : \mathbb{M_{n}(R)}*\mathbb{M_{n}(R)} \rightarrow \mathbb{R}$ $$(A,B) \rightarrow trace(AB)$$</p>

<p>I've proved $\phi$ is a bilinear form and symetric, but how could we do to prove it is a non generate form ? </p>

<p>Besides if we have $\mathbb{S_{n}(R)}$ the subspace of $\mathbb{M_{n}(R)}$ formed by symmetric matrix, prove the restriction of $\phi$ to $\mathbb{S_{n}(R)}*\mathbb{S_{n}(R)}$ is also a non degenerate form, and then determine the orthogonal of $\mathbb{S_{n}(R)}$ for $\phi$</p>

<p>Thanks</p>
",linear_algebra
"<p>First of all, i don't know if the correct word is normalise or not, but I'll try to explain my issue.</p>

<p>I have a relationship between an object <code>A</code> and an object <code>B</code> equals 0.5 (max is 1)</p>

<p>you can consider this relationship as a vector that its length is 0.5</p>

<p>I have another vector between <code>A</code> and <code>C</code> and its value is 0.3</p>

<p>I have another vector between <code>A</code> and <code>D</code> and its value is 0.2</p>

<p>so these are the values that I have:</p>

<pre><code>A -&gt; B = 0.5
A -&gt; C = 0.3
A -&gt; D = 0.2
</code></pre>

<p>Now I want to <strong>give more weight to the relationships</strong>. In other words, I really care about <code>A -&gt; B</code> a lot, but I don't care so much about <code>A -&gt; C</code></p>

<p>so I want to give weight to those numbers, the weights are as this:</p>

<pre><code>the value of A -&gt; B should be multiply by 4
the value of A -&gt; C should be multiply by 1 (so no change)
the value of A -&gt; D should be multiply by 2
</code></pre>

<p>my problem is that if i multiply <code>A -&gt; B</code> by 4, then the result is 2, which is bigger than 1. all the values must be between 0 and 1.</p>

<p>my question is how (and what is the abstract equation) to normalise all these values in a correct way?</p>

<p>Regards</p>

<h3>update 1</h3>

<p>In the example I gave to you, it was co incidence that the sum of the values is 1, that's not necessary at all</p>
",linear_algebra
"<blockquote>
  <p>Let $N\in \text{Mat}(10 \times 10,\mathbb{C})$ be nilpotent. Furthermore let $\text{dim} \ker N =3 $, $\text{dim} \ker N^2=6$ and $\text{dim} \ker N^3=7$. What is the Jordan Normal Form?</p>
</blockquote>

<p>The only thing I know is that there have to be three blocks, since $\text{dim} \ker N = 3$.</p>

<p>Thank you very much in advance for your help.</p>
",linear_algebra
"<p>Let $A\in M_n$ and $\operatorname{rank}A=k$. Is the following true?</p>

<blockquote>
  <p>There are $A_i\in M_n$ ($i=1,...,k$), such that $\operatorname{rank}A_i=1$ and $A=A_1+....+A_k$.</p>
</blockquote>
",linear_algebra
"<p>There is an array which contains points as shown below;</p>

<pre><code>[ -0.0249795, -0.00442094, -0.00397789, -0.00390947, -0.00384182, -0.0037756, -0.00371057, 0.00180882, 0.00251853, 0.00239539, 0.00244367, 0.00249255, 0.00254166, 0.00259185, 0.0116467, 0.0155782, 0.016471 ]
</code></pre>

<p>First of all, honestly, i don't know whether there is a measurement of nonlinearity or not. If there is, i would like to know what that's name is.</p>

<p>So how can i calculate the linearity or nonlinearity of this points distribution. I mean, after you draw a line from these points, how much will the line be linear and non-linear?</p>

<p>e.g. some line points, <code>p1= [1,-0.0249795], p2= [2, -0.00442094] ...</code></p>
",linear_algebra
"<p>Given a basis $U$, what conditions are needed for an orthogonal basis for it?</p>

<p>For example, in the following vector space $U$, if $U =sp\{(1,1,1),(1,3,7)\}$ then what conditions are needed for an orthogonal basis for it? </p>

<p>Is it enough to have a basis of dimension $2$ that's orthogonal? or are there more conditions? </p>

<p>EDIT: If for example I find an orthogonal span of dimension 2, say $V=sp\{(1,1,1), v_2\} $ such that $v_2$ is orthogonal to $(1,1,1)$, is any vector that's orthogonal to $(1,1,1)$ fine for it to be an orthogonal span for $U$?</p>

<p>PS: I know there's GS algorithm, but I'm asking if other bases that we get in other ways are also fine.</p>
",linear_algebra
"<p>$Tr(XY) = 1$ and $Tr(Y) = 1$ implies that $Tr(X) = 1$.</p>

<p>I tried to prove by contradiction and switch the dummy variable of $X$ and $Y$. But I don't think my approach is right and if there is any much easier proof.</p>
",linear_algebra
"<p>Question 3: (6 pts) A company makes 3 kinds of snacks, using almonds and raisins. The Fruity snack
contains 100g of almonds and 300g of raisins. The Nutty snack contains 300g of almonds and 100g of
raisins. The Variety snack contains 200g of almonds and 200g of raisins. There are currently 900g of
almonds and 700g of raisins available, and we want to determine how many of each kind of snacks can be
made so that all the ingredients are completely used.
a) Define variables and set up a linear system in order to solve the problem.
b) Find all the realistic solutions to the problem.</p>

<p>I answered A)</p>

<pre><code>100x + 300y + 200z = 900

300x + 100y + 200z = 700
</code></pre>

<p>How do I do B)?</p>
",linear_algebra
"<p>Let $T :R2[X]→R2[X]$be linear and such that$T(1)=1+X$,$T(X)=X+X^2$ and
$T (X^2) = 1 − X^2$. Is $T$ an isomorphism?</p>

<p>ok so Ive noticed that $T(1)-T(X)= 1- X^2$ which is $T(X^2)$, but that disproves that its linear, which is already given, also how is this related to it being an isomorphism, am I missing something here or?</p>
",linear_algebra
"<p>Given two $n \times n$ symmetric matrices $A$ and $B$, is there a generic way to construct a larger block matrix $M$ such that $\det(M) = \det(A) - \det(B)$?</p>

<p>A simple block expression is desired, in the sense that the block components of $M$ are constant matrices or obtained by solving matrix equations involving $A$ and $B$.  Constructions of $M$ involving short algebraic expressions for its components in terms of the components of $A$ and $B$ would also be interesting, but not something that expands to an exponential number of terms in the components of $A$ and $B$ like just sticking $\det(A)$ in as a term of $M$.</p>

<p>If this is not possible in the general case, what restrictions can be placed on $A$ and $B$ to make this possible?</p>

<p>The only case I know of is when the difference of $B$ and $A$ can be written as a product of a column vector $C$ and its transpose: $B-A = CC^T$. This allows us to construct a matrix $M$ such that:</p>

<p>$$ M = \begin{bmatrix} A &amp; C \\ C^T &amp; 0 \end{bmatrix} $$
$$ \det(M) = \det(A) - \det(A + CC^T) = \det(A) - \det(B) $$</p>

<p>I'm curious if there is some way to construct an appropriate block matrix to make this possible for arbitrary symmetric matrices $A$ and $B$.</p>

<p>The first comment to this question<br>
<a href=""http://math.stackexchange.com/questions/1834227/find-a-matrix-with-determinant-equals-to-deta-detd-detb-detc"">Find a matrix with determinant equals to $\det{(A)}\det{(D)}-\det{(B)}\det{(C)}$</a><br>
suggests the answer is trivial by choosing
$$M = \begin{bmatrix} A &amp; B \\ I &amp; I \end{bmatrix}$$
but that doesn't appear to work when I tried some numerical examples.</p>
",linear_algebra
"<p>I need help in formulating an optimization problem. I have a system of equations as follows:<br>
    $c_1x_1+c_2x_2+c_3x_3=1$<br>
    $b_1x_1+b_2x_2+b_3x_3=1$<br>
    $a_1x_1+a_2x_2+a_3x_3=1$<br>
In my case the system is not necessarily in three variables (the number of variables can increase).</p>

<p>The chosen $x_1$, $x_2$, $x_3$ should also satisfy the following system of equations:<br>
    $c_1'x_1+c_2'x_2+c_3'x_3&lt;1$<br>
    $b_1'x_1+b_2'x_2+b_3'x_3&lt;1$<br>
    $a_1'x_1+a_2'x_2+a_3'x_3&lt;1$<br>
where<br>
$0&lt;c_1'&lt;c_1$, $0&lt;c_2'&lt;c_2$, $0&lt;c_3'&lt;c_3$<br>
$0&lt;b_1'&lt;b_1$, $0&lt;b_2'&lt;b_2$, $0&lt;b_3'&lt;b_3$<br>
$0&lt;a_1'&lt;a_1$, $0&lt;a_2'&lt;a_2$, $0&lt;a_3'&lt;a_3$  </p>

<p>I have no idea where should I look for a solution. Any pointers in the right direction would also be appreciated.</p>

<p><strong>UPDATE</strong>: I understand that the constraints $0&lt;c_1'&lt;c_1$, $0&lt;c_2'&lt;c_2$, $0&lt;c_3'&lt;c_3$ would form a rectangular area and the value of $x_1$, $x_2$, $x_3$ should be chosen so that over this rectangular area the inequalities should be met. But I don't know how to formulate the constraints into an equation.</p>
",linear_algebra
"<p>The non-homogenous system is as follows:
$$3x+2y+5z=10\\
3x-2y=7\\
6x+4y-10z=k$$</p>

<p>I have determined that:
$$z=1-\frac{k}{20}\\
y=\frac{k}{16}-\frac{1}{2}\\
x=2+\frac{k}{24}$$</p>

<p>What are the values of $k$ to form a matrix which is inconsistent and then consistent?</p>
",linear_algebra
"<p>T:V→V ; prove that if T*T = T ⇒ ImT ∩ NullT = 0v and V = ImT ⊕ NullT.</p>

<p>let v∈V.</p>

<p>T(T(v)) = T(v) ⇒ T(v) = v</p>

<p>⇒ T is the identity transformation.</p>

<p>⇒ DimNullT = 0 ⇒ ImT ∩ NullT = 0v ⇒ V = ImT ⊕ NullT</p>

<p>Is the answer correct?</p>

<p>Also does an example exist where the ImT ∩ NullT ≠ 0v? Isn't the intersection empty by definition?</p>
",linear_algebra
"<p>Let $x=(a,b)$, where $a,b$ are in $N$</p>

<p>Now we have the transformations:
$$T_1(x) = (ka, b+1)$$ 
$$T_2(x) = (b,a)$$ where $k$ is in $N$.
Where the order of choosing a transformation is not fixed. 
(E.g. you can first apply 3 times $$T_1(x)$$, then $$T_2(x)$$</p>

<p>Will we for all $(a,b)$ produce $a=b$ by only being allowed to use these two transformations? If so, is this true for every $k$? I'm specifically interested in the case $k=2$ though.</p>
",linear_algebra
"<p>I know that the following statement shouldn't be true :</p>

<blockquote>
  <p>Let $A$ be a real $n\times n$ matrix which satisfies $f_A(x)=(x+3)^2(x-1)^2$ and $m_A(x) \ne f_A(x)$ then $A$ is diagonalizable over $\mathbb R$. </p>
</blockquote>

<p>Notice that $f_A(x)$ is the characteristic polynomial of $A$ and $m_A(x)$ is the minimal polynomial of $A$.</p>

<p>I'm trying to look for a counter-example but I can't find any. I tried to pick some diagonal matrices but I found out it cannot be an appropriate counter-example because a diagonal matrix is always diagonalizable. Besides that, all I tried is some other guessing where the diagonal contains $-3,-3,1,1$ with different combinations of $1$'s on the upper diagonal and the lower diagonal.</p>

<p>Is there any way to construct such a matrix?</p>

<p>$\underline {\mbox {Note:}}$</p>

<p>I know that the opposite statement is correct (that is, if we knew that $A$ is diagonalizable over $\mathbb R$ then $m_A(x) \ne f_A(x)$ because $m_A(x)$ must be simple in that case and we know $f_A(x)$ is not simple).</p>
",linear_algebra
"<p>A study buddy and I were going through this question and while we made some progress, we were ultimately unsure if what we were doing was correct or not.</p>

<p>The question is:</p>

<p>Let <em>A</em> be a diagonalizable matrix and let <em>X</em> be the diagonalizing matrix. Show that the column vectors of <em>X</em> correspond to the nonzero eigenvalues of <em>R</em>(<em>A</em>).</p>

<p>What we did was this:</p>

<p>Say that <em>A</em> is <em>n</em> x <em>n</em>. Therefore <em>X</em> must be <em>n</em> x <em>n</em> and a matrix <em>D</em> must be <em>n</em> x <em>n</em> since if A is diagonalizable and X is the diagonalizing matrix:</p>

<p><em>A</em> = <em>X</em> <em>D</em> <em>X</em> $^{-1}$</p>

<p>Since <em>X</em> is invertible, its eigenvectors must be linearly independent. Therefore, because <em>X</em> is <em>n</em> x <em>n</em>, there are <em>n</em> linearly independent eigenvectors. These eigenvectors span $\mathbb{R}$$^n$.</p>

<p>Because of this, <em>R</em>(<em>A</em>) $\subset$ $\mathbb{R}$$^n$, we've shown that the the column vectors of <em>X</em> correspond to the nonzero eigenvalues of <em>R</em>(<em>A</em>)... except we haven't. My buddy and I got stuck here and we weren't sure what to do since we haven't accounted for the eigenvalues that are equal to 0.</p>

<p>Thanks for any help in advance. </p>
",linear_algebra
"<p>Suppose that $V$ is an n-dimensional vector space over a field $F$ and $\{\vec{v_1}, ...,\vec{v_m}\}$ is a linearly independent set in $V$. How do I show that $m \leq n$ and $\exists \{\vec{v_{m+1}},...\vec{v_n}\} $ such that $\{\vec{v_1}, ...,\vec{v_m},\vec{v_{m+1}},...\vec{v_n}\}$ is a basis for $V$? </p>

<p>The book I'm using gives a hint involving using the basis for $V$ and creating the set of vectors composed of $\{\vec{v_1}, ...,\vec{v_m}\}$ and the basis of $V$, but i don't really understand what it is asking with that.</p>
",linear_algebra
"<p>My intuition says no. But what if W is a zero vector?</p>
",linear_algebra
"<p>Suppose $A$ is a $4×4$ matrix over $C$ s.t. $Rank(A)=2$ and $A^3=A^2\neq0$. If $A$ is not diagonalizable then how to prove that:</p>

<p>There exists a vector $v$ s.t. $Av\neq 0$ and $A^2v=0$.</p>

<p>I know it is to be proved that $Imsp(A)$ is contained in $Nullsp(A)$, but really got no clue how to approach.</p>

<p><strong>My work:</strong>
$x^2(x-1)$ is  the annihilating polynomial for $A$, but I am stuck in finding the characteristic polynomial. The only two possibilities are $x^3(x-1)$ and $x^2(x-1)^2$, but how to reject the later one?</p>

<p>Thanks for any hint.</p>
",linear_algebra
"<p>I know that the component of <code>x</code> along <code>u</code> is $\frac{u.x}{|u|}.$ ($x$,$u$ are both vectors) but my teacher said that this is equal to $u^T x u$ (||u|| = 1). I understand the first formula, But I cant understand the second one well.  </p>
",linear_algebra
"<p>Both matrix multiplication and quaternion multiplication are non-commutative; hence the use of terms like ""premultiplication"" and ""postmultiplication"". After encountering the concept of ""quaternion matrices"", I am a bit puzzled as to how one may multiply two of these things, since there are at least four ways to do this.</p>

<p>Some searching has netted <a href=""http://en.cnki.com.cn/Article_en/CJFDTOTAL-LXXB198402006.htm"">this paper</a>, but not having any access to it, I have no way towards enlightenment except to ask this question here.</p>

<p>If there are indeed these four ways to multiply quaternion matrices, how does one figure out which one to use in a situation, and what shorthand might be used to talk about a particular version of a multiplication?</p>
",linear_algebra
"<p>I need to find eigenvalues/eigenvectors of different kinds of $n \times n$ matrices. For example, how would I determine these for the matrices listed below? What is the typical process? Should I always go by the route of finding eigenvalues by finding roots of characteristic polynomial and then getting eigenvectors by solving $(\mathbf{A} - \lambda \mathbf{I})\mathbf{x} = 0$?<br><br></p>

<p>$\begin{bmatrix}
2&amp;0&amp;0\\ 1&amp;2&amp;0\\ 
0&amp; 1 &amp; 2
\end{bmatrix}
$
 <br><br>
$\begin{bmatrix}
4 &amp;1  &amp;1  &amp;1 \\ 
 1&amp;4  &amp;1  &amp;1 \\ 
 1&amp;1  &amp;4  &amp;1 \\ 
 1&amp;  1&amp;  1&amp; 4
\end{bmatrix}$ <br><br>
These are just examples. Typically I want to find eigenvectors of $n \times n$ matrices. If you can show me the process of finding solution of one of these matrices, that would be helpful.</p>
",linear_algebra
"<p>How would you find eigenvalues/eigenvectors of a $n\times n$ matrix where each diagonal entry is scalar $d$ and all other entries are $1$ ? I am looking for a decomposition but cannot find anything for this. <br>For example:</p>

<p>$\begin{pmatrix}2&amp;1&amp;1&amp;1\\1&amp;2&amp;1&amp;1\\1&amp;1&amp;2&amp;1\\1&amp;1&amp;1&amp;2\end{pmatrix}$</p>
",linear_algebra
"<p>Consider $n$ real, symmetric, and positive semi-definite matrices as: $A_1,A_2,\cdots,A_n$. These matrices are convertible to each other under appropriate permutation ($A_i(p_i,p_i)=A_j$). Moreover, we have $A_i=Q_iV_iQ^{-1}_i$ because of symmetry. Can we say that $\rho(A_1+A_2+\cdots+A_n )= \rho(V_1+V_2+\cdots+V_n)$ where $\rho(X)$ represents spectral radius of $X$? </p>
",linear_algebra
"<p>I am reading <a href=""http://biomet.oxfordjournals.org/content/61/2/383.full.pdf"" rel=""nofollow"">an old paper dated back in 70'</a>, where I encounter this
$$\mid\text{det}(A,G)\mid=(\text{det}\{(A,G)'(A,G)\})^{\frac{1}{2}}.$$</p>

<p>We compute the determinant of a single matrix, don't we? What doest it mean by $\mid\text{det}(A,G)\mid$?</p>
",linear_algebra
"<p>The question is the following: Given a matrix $A$ with rank $k$, we are looking for a matrix $B$ of rank $j$, where $j&lt;k$ such that $\|A-B\|_2$ is minimal.</p>

<p>My idea was to choose, if $A=P \operatorname{diag}(\sigma_1,\ldots,\sigma_k,0,\ldots) Q^H$ then $B=P \operatorname{diag}(\sigma_1,\ldots,\sigma_j,0,\ldots) Q^H$.</p>

<p>Is this approach correct? if so, then i would try to proove that this is actually the best approximation.</p>
",linear_algebra
"<p>Would someone please explain the proof strategy at <a href=""http://math.stackexchange.com/q/462982/53259"">Need verification - Prove a Hermitian matrix $(\textbf{A}^\ast = \textbf{A})$ has only real eigenvalues</a>? I brook the algebra so I'm not asking about formal arguments or proofs. For example, $1.$ How would you determine/divine/previse to take the Hermitian conjugate and to right-multiply by $\color{orangered}{\vec{v}}$?</p>

<p>$2.$ Since we are given that $A$ is Hermitian and has eigenvalues, why not start the proof with $A^*\mathbf{v} = \lambda^*\mathbf{v}$? Here, $\mathbf{v}$ is an eigenvector and so by definition $\neq \mathbf{0}$.</p>

<p>Then $\begin{align} LHS = Av &amp; = \\ \lambda v &amp; = \end{align}$</p>

<p>$\iff \lambda \mathbf{v} = \lambda^*\mathbf{v} \iff \mathbf{0} = (\lambda^* - \lambda )\mathbf{v} \iff \mathbf{v}  \neq \mathbf{0}, so \, (\lambda^* - \lambda )=0. $</p>
",linear_algebra
"<p>Suppose I am going to locate an emergency point on a field having 100 houses.</p>

<p>If we see this as a scatter graph with 100 points on it, I need to find a point (or let's call it an optimal point) which is the optimal choice for the emergency point. In other words, the SUM of travelling from the emergency point to all the houses (i.e. Emgncy point to Hous.No1 + Emgncy point to Hous.No2 + ... Emgncy point to Hous.No100) is the lowest possible value.</p>
",linear_algebra
"<p>When does the circulant matrix have only integral roots? <br>
For example: adjacency matrix for $K_n$ has all the roots integral which is circulant, but in case of Cycle on $n&gt;3$ it is circulant but it may not have an integral roots. </p>
",linear_algebra
"<p>If A and B are n dimensional vector spaces </p>

<p>1) Is A+B a vector space?</p>

<p>2) Is A and B a vector space?</p>
",linear_algebra
"<p>Question is as follows:</p>

<p>Suppose $A^2 = I$ (the identity matrix) and F = Q, R or C. Eigenvalues of A are then $\lambda=1$ or $\lambda=-1$. Show that $\ker(L (I+A))=E(-1)(A)$ and that $im(L (I+A))=E(1)(A)$.</p>

<p>$E(-1)(A)$ means eigenspace of eigenvalue $-1$.</p>

<p>I have managed to do the part with kernel, but I'm struggling with image and eigenspace.</p>

<p>I know how to prove that image is included in eigenspace $(E)$, but I don't know how to show the other way round.</p>

<p>Definition of $E$ I'm using: $E(1)(A) = \{x : Ax = x\}$.</p>

<p>Definition of image: $im(In + A) = \{y : y=(I + A)x\}$.</p>

<p>This is how I proved image is in eigenspace:
need to be shown: $Ay = y$</p>

<p>LHS: $Ay=A(I+A)x=A(Ix + Ax)=Ax + AAx= Ax + Ix=(A + I)x = y =$ RHS</p>
",linear_algebra
"<p><img src=""http://i.stack.imgur.com/SJ6MW.jpg"" alt=""enter image description here""></p>

<p>This is a very basic definition of orientable and very basic example 20.5 however ı could not understand definition in an good way so ı want you to explain my green writing please :) and my example please help me ı want to learn orientation on manifold if ı could not understand in a good way this ı will not understand in a good way rest of the subject please help me </p>
",linear_algebra
"<p>The eigenspace corresponding with the eigenvalue <strong>zero</strong> is the same as the null space of the original matrix. All vectors in the null space are linearly independent so the eigenvectors of <strong>zero</strong> are also independent.</p>

<p>Is this conclusion right?</p>
",linear_algebra
"<p>Hi could you help me with following</p>

<p>$$
\begin{pmatrix}
1 &amp; a &amp; a \\
a &amp; 1 &amp; a \\
a &amp; a &amp; 1
\end{pmatrix}
$$</p>

<p>is a $3 \times 3$ matrix.</p>

<p>Find the largest interval for a such that this matrix is positive definite.</p>

<p>How to do this??</p>

<p>Thanks a lot!</p>
",linear_algebra
"<p>Let $d_1$, $d_2$, ..., $d_n$ be positive integers. Let $B$ be the $n \times n$ matrix
$$\begin{pmatrix}
d_1 &amp; 1 &amp; 1 &amp; \cdots &amp; 1 \\
1 &amp; d_2 &amp; 1 &amp; \cdots &amp; 1 \\
1 &amp; 1 &amp; d_3 &amp; \cdots &amp; 1 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; 1 &amp; 1 &amp; \cdots &amp; d_n \end{pmatrix}.$$
When does $B$ have a square root in $\mathrm{Mat}_n(\mathbb{Z})$?</p>

<p>Motivation: The <a href=""http://en.wikipedia.org/wiki/Friendship_graph"" rel=""nofollow"">Friendship Theorem</a> states that the only graph in which every pair of vertices is joined by a path of length $2$ is the ""Friendship Graph"", which you can see at the linked article. If $A$ is the adjacency matrix of such a graph, with degree sequence $(d_1, d_2, \ldots, d_n)$, then $A^2=B$. So this contributes the solution $(d_1, d_2, \ldots, d_n) = (2,2,2,\ldots,2,2m)$, with $n=2m+1$.</p>

<p>I was preparing notes on the friendship theorem and got distracted by trying to figure out when this matrix has an integer square root at all. It seemed like it might make a nice challenge for here.</p>
",linear_algebra
"<p>I am currently going through ""Log-gases and random matrices"" by PJ Forrester. I'm coming from a totally different academic background, and I cannot understand a point of his notation. More precisely, he defines an <em>antinunitary</em> time reversal <strong>operator</strong> $T=\mathbf{Z}_{2N}K$ where $\mathbf{Z}_{2N}$ is the tensor product of the $N\times N$ identity matrix and of the $2\times2$ matrix $\begin{bmatrix}0 &amp;-1\\ 1 &amp; 0 \end{bmatrix}$, and where $K$ is the complex conjugate operator. So if I understand correctly, $T$ acts on a matrix $\mathbf{A}$ like so
\begin{equation}
T\mathbf{A} =\mathbf{Z}_{2N}\bar{\mathbf{A}},
\end{equation}
right?
Where I stop following is how one should deal with $K$ in ""mixed operations"", i.e. since it is not presented as a martix, how does one invert $K$, apply it ""from the right"", etc. </p>

<p>The property i'm trying to understand is the following: commutation relations between Hermitian matrices $\mathbf{A}$ and $T$ lead to
\begin{equation}
\mathbf{A} = T \mathbf{A} T^{-1} = \mathbf{Z}_{2N}K\mathbf{A} K^{-1} \mathbf{Z}_{2N}^{-1}   = \mathbf{Z}_{2N}K\mathbf{A} K \mathbf{Z}_{2N}^{-1}  = \mathbf{Z}_{2N}\bar{\mathbf{A}}\mathbf{Z}_{2N}^{-1}
\end{equation}
From what I gather, $T$ is more or less treated as a matrix (at least with regard to inversion operation), and $K$ is it's own inverse (that, i understard). The puzzling point for me is the last equality. Does The second $K$ disappears because it is applied (with no effect) to the real matrix $\mathbf{Z}_{2N}^{-1}$? I cannot seem to find anything on the subject easily... I just need a confirmation of my understanding, and possibly further reading material! </p>
",linear_algebra
"<p>I have a formula I use to determine how opaque some validation text should be based upon the length of a user's input compared to the maximum lenth allowed.  I want to modify it so that the ""ramping up"" of the opacity percentage only starts when they are at 80% of max, and then scales up proportionally from there.</p>

<p>Here is my current function:</p>

<p><strong>OpacityPercentage = CharactersEntered / MaxCharacters</strong></p>

<p>Therefore, if I have MaxCharacters of 50, then the opacity is as follows:</p>

<ul>
<li>30 chars = 60%</li>
<li>40 chars = 80%</li>
<li>41 chars = 82%</li>
<li>45 chars = 90%</li>
<li>50 chars = 100%</li>
</ul>

<p>What I want is for the opacity to be 0% until I get to 80% of max, then scale up from there.  So I would want the table to look as follows:</p>

<ul>
<li>30 chars = 0%</li>
<li>40 chars = 0%</li>
<li>41 chars = 10%</li>
<li>45 chars = 50%</li>
<li>50 chars = 100%</li>
</ul>

<p>I thought this would be simple, but I can't seem to figure out what I need to change in my existing formula.  Any advise is appreciated!</p>
",linear_algebra
"<p><em>Problem</em></p>

<p>Determine whether the indicated subset is a subspace of the given euclidean space:</p>

<p>$ \{[x,y,z]\ |\ x,y,z \in \mathbb{R} $ and $z=3x+2\}$ in $\mathbb{R}^{3}$</p>

<p><em>Solution</em></p>

<p>By definition, in order for a subset to be a subspace 3 conditions must be occur:</p>

<ol>
<li><strike>To pass by the origin</strike> To contain the origin.</li>
<li>To be closed under addition. </li>
<li>To be closed under scalar multiplication.</li>
</ol>

<p>So I try to solve the exercise by this way:</p>

<p>$1.$ The origin $(0,0,0) \in \mathbb{W} $</p>

<p>$2.$ Let $\vec u$ and $\vec v \in \mathbb{W} $. We have</p>

<p>$$ 
\begin{cases}
3u_1 + 2 - u_3 = 0 \\
3v_1 + 2 - v_3 = 0 \\
\end{cases}
$$
The sum is $ 6(u_1 + v_1) + 4 - (u_3+v_3) = 0 $ (which $\in \mathbb{W} $)</p>

<p>$3.$ Let $\vec u$ $ \in \mathbb{W} $ and  $\ r$ $ \in \mathbb{R} $. We have</p>

<p>$r(3u_1) + r(2) - r(u_3) = 0 \\$</p>

<p>Which, also, $ \in \mathbb{W} $</p>

<p>So, why is the book's answer: It <strong>isn't</strong> a subspace? </p>
",linear_algebra
"<p>I'm (reasonably) familiar with <a href=""http://en.wikipedia.org/wiki/Cholesky_decomposition"" rel=""nofollow"">factoring</a> a positive definite matrix $\mathbf{P} = \mathbf{L} \mathbf{L}^T =  \mathbf{R}^T \mathbf{R}$, and is supported by  <a href=""http://www.mathworks.com.au/help/techdoc/ref/chol.html"" rel=""nofollow"">MATLAB</a> and <a href=""http://eigen.tuxfamily.org/dox-devel/TopicLinearAlgebraDecompositions.html"" rel=""nofollow"">Eigen</a>.</p>

<p>However, I have also seen a factorization of the (same)  $\mathbf{P} = \mathbf{U} \mathbf{U}^T =  \mathbf{L&#39;}^T \mathbf{L&#39;}$</p>

<p>The following illustrates:</p>

<pre><code>&gt;&gt; A = rand(3, 4)

A =

    0.2785    0.9649    0.9572    0.1419
    0.5469    0.1576    0.4854    0.4218
    0.9575    0.9706    0.8003    0.9157

&gt;&gt; P = A * A.'

P =

    1.9449    0.8288    2.0991
    0.8288    0.7374    1.4513
    2.0991    1.4513    3.3379

&gt;&gt; R = chol(P)

R =

    1.3946    0.5943    1.5052
         0    0.6198    0.8982
         0         0    0.5153

% This function computes such that U * U.' = A * A.'
% Part of: http://www.iau.dtu.dk/research/control/kalmtool2.html 
&gt;&gt; U = triag(A)

U =

   -0.7475    0.2571   -1.1489
         0   -0.3262   -0.7944
         0         0   -1.8270

&gt;&gt; P2 = R.' * R

P2 =

    1.9449    0.8288    2.0991
    0.8288    0.7374    1.4513
    2.0991    1.4513    3.3379

&gt;&gt; P3 = U * U.'

P3 =

    1.9449    0.8288    2.0991
    0.8288    0.7374    1.4513
    2.0991    1.4513    3.3379
</code></pre>

<p>I haven't seen this particular factorization  $\mathbf{P} = \mathbf{U} \mathbf{U}^T$ before. I have a couple of questions:</p>

<ul>
<li>Is it still, by definition, Cholesky factoriation? If not, what is it called? </li>
<li>Is the simple means to compute this particular variant (e.g. a MATLAB command)</li>
<li>Is there a specific relationship between $\mathbf{U}$ and $\mathbf{R}$?</li>
</ul>
",linear_algebra
"<p>Choose a possible $a$ such that the linear equations have a root</p>

<p>$$\begin{matrix} x+2y+3z=a \\
                 4x+5y+6z=a^2 \\
                 7x+8y+9z=a^3 \end{matrix}$$</p>

<p>Do I begin by finding the possible values of $a$ such that the system is consistent?</p>
",linear_algebra
"<p>I am stuck trying to solve the following problem:</p>

<p>In diagonalizing a symmetric matrix $S$, we find that two of the eigenvalues ($\lambda_1$ and $\lambda_2$) are equal but the third ($\lambda_3$) is different. Show that <em>any</em> vector which is normal to $\hat{n}_3$ (which is the eigenvector corresponding to $\lambda_3$) is then an eigenvector of $S$ with eigenvalue equal to $\lambda_1$</p>

<p>Can anyone offer hints on, or an outline of, the solution?</p>

<p>Thank you. </p>
",linear_algebra
"<p>Vectors $\vec{b}$ and $\vec{c}$ are given. ∠(b,c)=2pi/3. Find vector $\vec{a}$, coplanar with $\vec{b}$ and $\vec{c}$, length $|\vec{a}|=4$ and ∠(a,b)=pi/6</p>

<p>I know it's something with triple product. Not sure where that gets me.</p>

<p>EDIT: $|\vec{b}|$=$|\vec{c}|$=1</p>
",linear_algebra
"<p>Given a set of linear equations $AX=B$, say $A$ is an ill posed matrix (has a few singular values equal or very close to zero), which numerical algorithm (conjugate gradient, least squares or steepest decent etc ) should be used to obtain the best solution? More specifically, is there a concrete comparison between these methods?</p>
",linear_algebra
"<p>Are these sets of equations linear? What is the number of variables and equations in each system? Please correct me if my answer is wrong:</p>

<p><strong>a)</strong> $Ax = b, x \in R^n$ - <strong>yes</strong>, classic system of linear equations, $var = n, eq = m$ where $A \in R^{m \times n}$</p>

<p><strong>b)</strong> $x^TAx = 1, x \in R^n$ - <strong>no</strong>, its a quadratic form, $var = n, eq = 1$</p>

<p><strong>c)</strong> $a^TXb = 0, X \in R^{m \times n}$ - <strong>yes</strong>, $var = m*n, eq = 1$</p>

<p><strong>d)</strong> $AX + XA^T = C,X \in R^{m \times n}$ - <strong>yes</strong>, not sure</p>

<p>Thanks for any help..</p>

<p>EDIT: are the first 3 solutions correct now?</p>
",linear_algebra
"<p>I have a few proofs I need some help with.</p>

<p><strong>a)</strong> Prove that $AB-BA = I$ does not have any solutions for any $A,B$. All matrices are regular.</p>

<p>I based my proof on matrix traces. $tr(AB) = tr(BA)$. Since $tr(X+Y) = tr(X) + tr(Y)$, it holds that $tr(AB - BA) = tr(AB) - tr(BA) = 0$ and $tr(I) = m$ so the diagonal numbers cant be ""önes"". Is this proof correct or do I have to use some other method?</p>

<p><strong>b)</strong> Prove that $(AB)^{-1} = B^{-1}A^{-1}$. I believe that I can prove this by simply writing all the matrices products down.. is there some simplier and more ""elegant"" way how to prove this?</p>

<p><strong>c)</strong> Prove that $A + A^T$ is symetric for a square $A$. Not sure abotu this one...</p>

<p>Thanks for any help in advance!</p>

<p>EDIT: $A$ in c) is square, not rectangular!</p>
",linear_algebra
"<p>In the vector space of $f:\mathbb R \to \mathbb R$, how do I prove that functions $\sin(x)$ and $\cos(x)$ are linearly independent. By def., two elements of a vector space are linearly independent if $0 = a\cos(x) + b\sin(x)$ implies that $a=b=0$, but how can I formalize that? Giving $x$ different values? Thanks in advance.</p>
",linear_algebra
"<p>I have a $t \times l$-polynomial matrix $A$ over $\mathbb{F}_q[x]$. The entries of $A$ are of degree $\le m$. I want to reduce $A$ to upper-triangular form by Gaussian elimination in case of using the Euclidean division instead of the exact one. What the worst-case computational (time) complexity it will take?</p>
",linear_algebra
"<p>I have several subspaces where I have to determine their dimension and whether they are affine or linear? These are my answers- are they correct? Thanks for help!</p>

<p><strong>a)</strong> $X = \{ x \in R^n | a^Tx = 0 \}, a \in R^n$ is given</p>

<ul>
<li>linear since any linear combination $\alpha x + \beta y, x, y \in X$ is in X. I believe its affine, too, since actual coefficients $\alpha, \beta$ doesnt really matter in this case because $\alpha(a_1x_1 + \dots + a_nx_n) + \beta(a_1y_1 + a_ny_n) = 0$ every time...</li>
<li>dimension? Im guessing its max $n-1$ but Im not sure</li>
</ul>

<p><strong>b)</strong> $X = \{ x \in R^n | a^Tx = c \}, a \in R^n, c \in R$ are given</p>

<ul>
<li>affine because in order for the linear combination to be in $X$, $\alpha_i$ must sum to 1</li>
<li>dimension again max $n-1$?</li>
</ul>

<p><strong>c)</strong> $X = \{ x \in R^n | x^Tx = 1 \}$</p>

<ul>
<li>affine (same justification as in b)) </li>
</ul>

<p><strong>d)</strong> $X = \{ x \in R^n | a^Tx = I \}, a \in R^n$ is given</p>

<ul>
<li>not sure at all
Are my assumptions correct</li>
</ul>
",linear_algebra
"<p>Let $A$ and $B$ be isomorphic unitary rings. Suppose that both of them admit a structure of (maybe finite dimensional) vector space over some field $k$. I would like to know if then $A$ and $B$ are isomorphic as vector spaces over $k$ (if they are forced to have the same dimension). Notice that in general I am not requiring $A$ and $B$ to be $k$-algebras, i.e. I am not requiring any kind of compatibility between the multiplicative structure and the product with scalars from the field. My guess is that in this generality the answer is no, but I can't provide nor find any example.</p>

<p>Here I gather some things I can prove:</p>

<p>1) if the field is $k=\mathbb{Q}$ and $A$ and $B$ are $k$-algebras, then the answer is yes.</p>

<p>2) if the field is $k=\mathbb{R}$, $A$ and $B$ are $k$-algebras and they are fields, then the answer is yes again.</p>

<p>3) if $A$ and $B$ are finite $k$-algebras (and so $k$ is finite too) the answer is yes again.</p>

<p>Unfortunately these rule out most of the examples from a first course in ring theory, so I suspect the answer would be more exotic than this, but I can't find anything. Maybe the answer is yes even in the general setting (or maybe just for $k$-algebras), and in this case I'd like to see a proof.</p>

<p>Thanks in advance.</p>
",linear_algebra
"<p>For example, I want to this to happen:
$$\begin{bmatrix}1&amp; 2&amp; 3\end{bmatrix}\times\begin{bmatrix}2&amp; 3&amp; 4\end{bmatrix} = \begin{bmatrix}2&amp; 6&amp; 12\end{bmatrix}$$
It's not exactly matrix multiplication, but I hope you can see what I'm getting at. Is there some notation in linear algebra that allows this function to be valid?</p>
",linear_algebra
"<p>I want a rotation matrix $R$ that transforms +x axis to +y, +y to +z, and +z to +x. One way of doing it is by a rotation about +x by 90 deg anti-clockwise, followed by a rotation about +y by 90 deg anti-clockwise. The matrices respectively are:</p>

<p>$$R_1 = \begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; -1 \\
0 &amp; 1 &amp; 0 \\
\end{bmatrix}$$</p>

<p>$$R_2 = \begin{bmatrix}
0 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 0 \\
-1 &amp; 0 &amp; 0 \\
\end{bmatrix}$$</p>

<p>Since R1 first operates first followed by R2, the resultant, I think, is R=(R2)(R1). But when I cross-check by applying R to an arbitrary point, say (1,2,3), I don't get the right transform of (3,1,2). Instead, I get it right when I do R=(R1)(R2)  which doesn't make sense to me. Please help</p>
",linear_algebra
"<blockquote>
  <p>Let $c_0=\{ (x_n) : x_n\in \Bbb{R}, x_n \to 0\}$ and $M=\{(x_n)\in c_0 : x_1+x_2+\cdots + x_{10}=0\}$. Then, what is dim($c_0/M$) ?</p>
</blockquote>
",linear_algebra
"<p>In the textbook that I'm using the standard inner product is defined as </p>

<p>$$\langle x,y\rangle = \sum_{i=1}^{n}a_{i}\overline{b_{i}}$$</p>

<p>where $x=(a_{1}, a_{2}, {...}, a_{n})$ and $y=(b_{1}, b_{2}, {...}, b_{n})$ and the bar denotes complex conjugation. </p>

<p>In one the practice problems I was doing they used the fact that </p>

<p>$\langle x,y\rangle = y^{*}x$</p>

<p>where $y^{*}$ denotes the conjugate transpose of y. I'm having trouble understanding why the definition for the standard inner product is the same as $y^{*}x$. </p>

<p>I tried doing an example where $x = (i,i)$ and $y = (-i,-i)$ </p>

<p>For $$\langle x,y\rangle = i*i+i*i=-2$$  </p>

<p>On the other hand </p>

<p>$y^{*}x=\begin{pmatrix} i\\i\\ \end{pmatrix} \begin{pmatrix} i &amp; i\\ \end{pmatrix} = \begin{pmatrix} -1 &amp; -1\\ -1 &amp; -1\\ \end{pmatrix} $</p>

<p>I was wondering why I am getting $\langle x,y\rangle \ne y^{*}x$</p>
",linear_algebra
"<p>If the characteristic polynomial $f_A(x)$ has multiples of the same product, for example $f_A(x)= (x+2)^2(x-1)$ so  $(x+2)$ has a multiple of $2$, then is there a condition on $A$ such that we know for sure that $m_A(x)= (x+2)(x-1)$ or $(x-1)$ or $(x+2)$ ? i.e, no multiples. </p>
",linear_algebra
"<p>Is there a simple way to show that the least square solution of an overdetermined linear system is equal to the right singular vector of the coefficient matrix corresponding to the smallest singular value?</p>
",linear_algebra
"<p>I was reading up on the Fibonacci Sequence when I've noticed some were able to calculate specific numbers. So far I've only figured out creating an array and counting to the value, which is incredibly simple, but I reckon I can't find any formula for calculating a Fibonacci number based on it's position.</p>

<p>Is there a way to do this? If so, how are we able to apply these formulas to arrays?</p>
",linear_algebra
"<p>By matrix-defined, I mean</p>

<p>$$\left&lt;a,b,c\right&gt;\times\left&lt;d,e,f\right&gt; = \left| 

\begin{array}{ccc}
i &amp; j &amp; k\\
a &amp; b &amp; c\\
d &amp; e &amp; f
\end{array}

\right|$$</p>

<p>...instead of the definition of the product of the magnitudes multiplied by the sign of their angle, in the direction orthogonal)</p>

<p>If I try cross producting two vectors with no $k$ component, I get one with only $k$, which is expected. But why?</p>

<p>As has been pointed out, I am asking why the algebraic definition lines up with the geometric definition.</p>
",linear_algebra
"<p>As I've understood it, what I've learned is that the dot product is just one of many possible <strong>inner product spaces</strong>. Can someone explain this concept? When is it useful to define it as something other than the <strong>dot product</strong>?</p>
",linear_algebra
"<p>Given two points around an origin $(0,0)$ in $2D$ space, how would you calculate an angle from $p_1$ to $p_2$?</p>

<p>How would this change in $3D$ space?</p>
",linear_algebra
"<p>I've recently started reading about Quaternions, and I keep reading that for example they're used in computer graphics and mechanics calculations to calculate movement and rotation, but without real explanations of the benefits of using them.</p>

<p>I'm wondering what exactly can be done with Quaternions that can't be done as easily (or easier) using more tradition approaches, such as with Vectors?</p>
",linear_algebra
"<p>What purposes do the Dot and Cross products serve? </p>

<p>Do you have any clear examples of when you would use them?</p>
",linear_algebra
"<p>I wonder how can I find the largest delta in which if initial condition is inside circle (How do I specify radius of that circle) bounded by delta then the solution is always within the dashed circle in the figure?
How do you approach this solely based on geometry of phase portrait since no equation is given?</p>

<p><img src=""http://i.stack.imgur.com/dovTu.jpg"" alt=""enter image description here""></p>
",linear_algebra
"<p>A simple question. Why is the sum of the singular values of a matrix called its <a href=""http://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms"" rel=""nofollow"">nuclear norm</a>? What is the origin of, and motivation for, this term?</p>

<p>Apparently the term <em>nucleus</em> is sometimes used to refer to the kernel of a linear transformation, but that doesn't seem to have anything to do with singular values.</p>

<p>To save you the effort, neither <em>nucleus</em> nor <em>nuclear</em> have entries in <a href=""http://jeff560.tripod.com/n.html"" rel=""nofollow""><em>Earliest Known Uses of Some of the Words of Mathematics</em></a>.</p>
",linear_algebra
"<ol>
<li><p>In the process of proving some theorem, I have assumed that if $A B$
is invertible, then the matrices $A$ and $B$ are invertible as
well. However I'm not sure about it. I know that if $A$ and $B$ are
invertible then $AB$ is also invertible. But does it hold in the
opposite direction?</p></li>
<li><p>Is $AB=I$ enough to deduce that $A$ is invertible? Or must I prove that $BA=I$ also holds? </p></li>
</ol>

<p>(I'm dealing only with square matrices)</p>

<p>Thanks in advance.</p>
",linear_algebra
"<p>I have a set of vectors:</p>

<p>$$V=\lbrace x\in\Bbb{R}^5:x_1+x_2+x_3+x_4+x_5=0\rbrace$$</p>

<p>I need to find basis for this set of vectors. What is the ""algorithm"" for solving such problems? Where should I start?</p>

<p>EDIT:</p>

<p>Is this a valid basis:
$\lbrace[1,0,0,0,-1]^T,[0,1,0,0,-1]^T,[0,0,1,0,-1]^T,[0,0,0,1,-1]^T\rbrace$?</p>
",linear_algebra
"<p>Can someone explain how Cramer's rule works. I understand the mechanics of it, and it's fairly straightforward to show algebraically that it's equivalent to GJ and substitution, but what's happening under the hood? I'm guessing it has to do with properties of determinants but...</p>
",linear_algebra
"<p>My linear algebra book (<a href=""http://www.cin.ufpe.br/~jrsl/Books/Linear%20Algebra%20Done%20Right%20-%20Sheldon%20Axler.pdf"" rel=""nofollow"">Linear Algebra Done Right</a> by Sheldon Axler) has the following problem as exercise 1.6:</p>

<blockquote>
  <p>Give an example of a nonempty subset $U$ of $\mathbb{R}^2$ such that $U$ is closed under addition and under taking additive inverses (meaning $-u \in U$ whenever $u \in U$), but $U$ is not a subspace of $\mathbb{R}^2$.</p>
</blockquote>

<p>It seems to me that such a set cannot exist, since the only subspace condition it's not mandated to fulfill is containing $0$, and for any $u \in U$, I can negate it to get $-u$ and then get $u + (-u) = 0$.</p>

<p>What is going on?</p>
",linear_algebra
"<p>I have problem with this:
$$\| BC\| \leq \| B\|\| C\|$$
where $\|\cdot\|$ means spectral norm defined as $$\|A\|=\text{max}\lbrace\|Ax\|:x\in\mathbb{C^n, \|x\|=1}\rbrace$$ 
where the norms on the are according to standard scalar product. </p>

<p>For my homework I had to solve $\|A+B\|\leq\|A\|+\|B\|$ which I managed to do by myself but this second inequality seems to be (at least for me) much harder. Any ideas? </p>
",linear_algebra
"<p>I need some help with this problem please: </p>

<p>Let $V$ be a vector space finitely generated over $\mathbb Q$ and
let $α, β ∈ \operatorname{ End}(V )$ satisfy $3α^3 + 7α^2 − 2αβ + 4α − σ_1 = σ_0$. Show that $αβ = βα$.</p>

<p>Thanks.</p>

<p>This is an exercise from the book: The Linear Algebra a Beginning Graduate Student Should Know by Golan.</p>
",linear_algebra
"<p>I need some help with this problem please:</p>

<p>Let $V$ be as vector space over a field $F$ and let $α, β, γ ∈
\operatorname{End}(V )$ satisfy $αβ = σ_1 = αγ$. Show that $βγ \neq γβ$.</p>

<p>$σ_1$ is the identity function and $\operatorname{End}(V )$ the endomorphism of $V$.</p>

<p>I think this problem is wrong for if we take $β=γ$ that is not true, but if someone have an idea it will be appreciated.
Thanks.</p>

<p>This is an exercise from the book: The Linear Algebra a Beginning Graduate Student Should Know by Golan.</p>
",linear_algebra
"<p>Apologies for the poor title.</p>

<p>What I'm wondering is:
Say that we have a non-surjective operator $A:X\rightarrow X$ where $X$ is a Banach space, and the operator is defined in terms of the basis vectors $ê_i$:
$$
A(x)=\sum\limits_{i,k=1}^\infty\alpha_{i,k}\cdot x_{k}\cdotê_i=\sum\limits_{k=1}^\infty{y_k\cdotê_k}
$$
edit: where there are countably many $i$ for which $\alpha_{i,k}$ is non-zero for some $k$.</p>

<p>A <strike>restriction</strike> projection of the operator is:
$$
A'(x)=\sum\limits_{i\in I,k=1}^\infty\alpha_{i,k}\cdot x_{k}\cdotê_i=\sum\limits_{k\in I}{y_k\cdotê_k}
$$
Where $I$ is a finite index set.</p>

<p>Given $y=\sum\limits_{k=1}^\infty{y_k\cdotê_k}$ that is not in the image of $A$, is it always possible to take such a projection in a way so that the finite set of linear equations you get don't have a solution?</p>

<p>If one of the basis vector isn't in the image it's easy to realise that you can, for example the right shift operator:$$(x_1,x_2,x_3,x_4,...) \rightarrow (0,x_1,x_2,x_3,x_4,...)$$</p>

<p>My next thought was that there has to be a basis vector not in the image, because otherwise the image would span $X$ but I don't think that's enough.</p>

<p>This isn't a homework problem, it's just something that's been distracting me.</p>
",linear_algebra
"<p>Let's assume that $V$ and $W$ are vector spaces over a field $\mathbb{K}$, $\lambda\in\mathbb{K}$, $\lambda\neq0$.</p>

<p>$S: V\rightarrow W$ and $T: W\rightarrow V$ are linear maps. Prove, that</p>

<p>$\lambda$ is an eigenvalue of $TS\iff\lambda$ is an eigenvalue of $ST$</p>

<p>What can be stated about the eigenvalues of the maps $TS$ and $ST$?
Would it also be correct if $\lambda=0$?</p>

<p>That's how far I've come:
I have to prove, that </p>

<ol>
<li>$\lambda$ is an eigenvalue of $TS\Rightarrow\lambda$ is an eigenvalue of $ST$ </li>
<li>$\lambda$ is an eigenvalue of $ST\Rightarrow\lambda$ is an eigenvalue of $TS$</li>
</ol>

<p>Assuming $V=\mathbb{K}^n$ and $W=\mathbb{K}^m$, such that $S:\mathbb{K}^n\rightarrow\mathbb{K}^m$ and $T:\mathbb{K}^m\rightarrow\mathbb{K}^n$. Hence, $TS: \mathbb{K}^n\rightarrow\mathbb{K}^n$ and $TS: \mathbb{K}^m\rightarrow\mathbb{K}^m$. $TS$ and $ST$ are both endomorphisms. Since the eigenvalue is not zero, the matrices must be invertible and the determinant of both matrices is not zero. Let's say $A$ is the transformation matrix of $TS$ and $B$ the transformation matrix of $ST$</p>

<p>That's where I'm stuck right now. How do I go on from here?</p>

<p>Do I have to prove, that $det(A-2*I_3)=0=det(B-2*I_2)$?</p>
",linear_algebra
"<p>Is it true that if $A$ is unitary diagonalizable (i.e. $A$ is normal) and $B$ is similar to $A$ then $B$ is also unitary diagonalizable (i.e. $B$ is normal) ?</p>

<p>Here are my thoughts:</p>

<p>If $A$ is unitary diagonalizable matrix then there exist unitary matrix $P$ and diagonal matrix $D$ such that $P^*AP=D$.  $(*)$</p>

<p>We also know from the Spectral theorem that $A$ is normal ($\because$ $A$ is unitary diagonalizable $ \iff A$ is normal).</p>

<p>From the fact that $B$ is similar to $A$ we can derive that there exists invertible matrix $Q$ such that $Q^{-1}BQ=A$.</p>

<p>Finally, by replacing $A$ in $(*)$ with $Q^{-1}BQ$ we get:</p>

<p>$$ P^*Q^{-1}BQP=D \ \ (**)$$</p>

<p>The only thing I can derive from this equation $(**)$ is that $B$ is diagonalizable, because :</p>

<p>$$ P^*Q^{-1}BQP=D \implies P^{-1}Q^{-1}BQP=D \implies (QP)^{-1}B(QP)=D \implies C^{-1}BC=D$$ </p>

<p>Am I missing something? Is it possible that I can also derive that $B$ is <strong>unitary</strong> diagonalizable ?</p>
",linear_algebra
"<p>I'm a little bit confused by this sentence:</p>

<p>""The matrix A is the sum of two matrices that can be diagonalised independently,
and hence A is trivially reducible.""</p>

<p>How can I show that A is reducible? </p>
",linear_algebra
"<p>I'm able to prove $44$, but how would one deduce $43$ from it without further industry, forthwith?<br>
 $43$ seems like a reduced, 2D version of $44$? I'm not enquiring about individual proofs.</p>

<blockquote>
  <p>$44.$ Let $P$ be a point not on the plane that passes through the
  points $Q, R, S$.<br>
  Show that the distance $h$ from $P$ to the plane $ = \dfrac {\left| \left( \mathbb{a} \times \mathbb{b} \right) \cdot \mathbb{p}\right| } {\left| \mathbb{a} \times \mathbb{b}\right| }$. 
  <img src=""http://i.stack.imgur.com/IB6o9.png"" alt=""enter image description here""></p>
  
  <p>$43 = 39$ (5th edition). Let $P$ be a point not on the line $L$ that passes through the
  points $Q,R$.<br>
  Show that the distance $d$ from the point P to the line $L = \dfrac {\left| \mathbb{a} \times \mathbb{b} \right| } {\left| \mathbb{a}\right| }$. 
  <img src=""http://i.stack.imgur.com/gMcvB.png"" alt=""enter image description here""></p>
</blockquote>
",linear_algebra
"<p>$37.$ Find an equation of the plane that passes through the point $(1, -2, 1)$<br>
and contains
the line of intersection of the planes $x + y - z = 2$ and $2x - y + 3z = 1$. 
<img src=""http://i.stack.imgur.com/EdLNj.png"" alt=""enter image description here"">
$\bbox[3px,border:2px solid grey]{\text{ Official solution : }}$My modified <a href=""http://www.mathematics-online.org/kurse/kurs8/seite41.html"" rel=""nofollow"">picture</a> illustrates that the red line of intersection belongs to both planes. A normal vector of each plane $\perp$ to this red line of intersection. Thus, the direction vector of the red line = $\mathbb{n_1} \times \mathbb{n_2} = (1, 1, -1) \times (2, -1, 3) = \color{#C154C1}{(2, -5, -3)}$</p>

<p>For want of a normal vector to the requested plane, require another direction vector on this requested plane. Thus need the vector containing any point on the red line of intersection to the given point $(-1, 2, 1)$ in the plane. WLOG, set $\color{#FF4F00}{x = 0}$:
$\begin{cases} x + y - z = 2 \\ 2x - y + 3z = 1 \end{cases} \implies \begin{cases} y - z = 2 \\ -y + 3z = 1 \end{cases}$ $\implies (\color{#FF4F00}{x}, y, z) = (\color{#FF4F00}{0}, 7/2, 3/2).$<br>
Thus another vector parallel to the plane is $(-1, 2, 1) - (\color{#FF4F00}{0}, 7/2, 3/2) = \color{#C154C1}{(-1, -3/2, -1/2)}$. </p>

<p>In toto, a normal vector to the plane $= \color{#C154C1}{(2, -5, -3) \times (-1, -3/2, -1/2)} = 2(-1, 2, -4).$  $... \blacksquare$</p>

<p>$\bbox[3px,border:2px solid grey]{\text{ My solution : }}$
♦ Any vector on the line of intersection of the two planes produces one vector $\parallel$ to the requested plane.</p>

<p>♠ The other vector $\parallel$  the requested plane is any vector connecting any point on this line of intersection with the given point $(-1, 2, 1)$ in the plane.</p>

<p>♦ Subtract the two equations of the plane to produce their line of intersection: $3x + 2z = 3$. For a direction vector of this line, subtract any two vectors on it. WLOG, put $z = 0 \implies \color{brown}{(1, 0, 0)}$ and put $z = 3 \implies \color{brown}{(-1, 0, 3)}$. Thus direction vector $= (-1, 0, 3) - (1, 0, 0) =  (-2, 0, 3)$. </p>

<p>♠ Observe the given point $(-1, 2, 1)$ isn't on this line (but is given to be on the plane). Thus either $\color{brown}{(1, 0, 0)} - (-1, 2, 1) = (2, -2, -1)$ or $\color{brown}{(-1, 0, 3)} - (-1, 2, 1)$ are on the plane. </p>

<p>In toto, a normal vector to the plane = $(-2, 0, 3) \times (2, -2, -1) = 2(3, 2, 2) \neq k(-1, 2, -4)... \blacksquare$</p>

<p>Since the solution's and my normal vectors differ already, what's wrong with my solution? </p>
",linear_algebra
"<p>So far I have:</p>

<p>$\boldsymbol{f^{-1}} \circ \boldsymbol{f}(\boldsymbol{a}) = \boldsymbol{a}
\implies [\boldsymbol{D}(\boldsymbol{f^{-1}}(\boldsymbol{a}) \circ \boldsymbol{f}(\boldsymbol{a}))] = I_n
\implies [\boldsymbol{D}\boldsymbol{f^{-1}}(\boldsymbol{f}(\boldsymbol{a}))][\boldsymbol{D}\boldsymbol{f}(\boldsymbol{a})] = I_n $ by the chain rule.</p>

<p>Interpreting $[\boldsymbol{D}\boldsymbol{f^{-1}}(\boldsymbol{f}(\boldsymbol{a}))]$ as the matrix composed of row-reduction operations, $[\boldsymbol{D}\boldsymbol{f}(\boldsymbol{a})]$ row-reduces to $I_n$. Now $[\boldsymbol{D}\boldsymbol{f}(\boldsymbol{a})]$ is a $m \times n$ matrix, therefore we have $m \le n$: Is this convincing? How do I make it rigorous?</p>

<p>This looks like a similar question to <a href=""http://math.stackexchange.com/questions/257599/the-existence-of-an-inverse-to-a-differentiable-function"">Existence of an inverse to differentiable function</a></p>
",linear_algebra
"<blockquote>
  <p>Describe all $m$ by $n$ matrices $A$ and $B$ such that $ref(A) + ref(B) = ref(A + B)$.<br>
  Is it true that $ref(A) = A$ and $ref(B) = B$? Does $ref(A - B) = rref(A - B)$?<br>
  Here, ref = Row Echelon Form, rref = Reduced Row Echelon Form.</p>
  
  <p><strong>Terse Answer:</strong> I think $ref(A) = A$ and $ref(B) = B$ are true.<br>
  But $REF(A) - REF(B)$ may have $-1$ in some pivots.</p>
</blockquote>

<p>Would someone please explain and uncloak how to start, still less solve, this question?</p>
",linear_algebra
"<p>Let $V$ be finite dimensional real vector space and let $f$ and $g$ be non zero linear functionals on $V$.  Assume that $\ker(f) \subset \ker(g).$ Which of the following are true??</p>

<p>a. $\ker(f)=\ker(g)$</p>

<p>b. $f=\lambda g$ for some real number $\lambda \ne 0$.</p>

<p>c. The linear map $A\colon V\to \mathbb{R}^2$ defined by $Ax=(f(x),g(x))$ for all $x \in V$, is onto.</p>

<p>Since $\ker(f)\subset \ker(g)$ we get $\ker(f)=\ker(g)$ and hence (a) and (b) are true. Now the linear map will look like $Ax=(\lambda g(x),g(x))$ . I guess (c) will be false. Not sure though.</p>
",linear_algebra
"<p>Let $T_1$ and $T_2$ be diagonalisable operators on a real vector space $V$. Does it follow that $T_1+T_2$ is a diagonalisable operator?</p>

<p>My intution says no. But I can't find any counterexample.</p>
",linear_algebra
"<p>A cashier has a total of 30 bills, made up of ones, fives, and twenties. The number of twenties is 9 more than the number of ones. The total value of the money is $351. How many of each denomination of bills are there? (Hint: Let x = the number of ones, y = the number of fives, and z = the number of twenties)</p>

<p>I'm having a hard time figuring out the three equations for this problem.</p>
",linear_algebra
"<p>For $S-N$ Decomposition of a linear operator $T$ i.e $T=S+N$(Unique Expression) where $S$ is a semi-simple opearator and $N$ is a nilpotent operator and $SN=NS$ then prove that semi-simple part and nilpotent part of $T$ commutes with $A$ if $T$ commutes with $A$, where $A$ is a linear operator.</p>
",linear_algebra
"<p>Do you know is there any way to compute SVD or Cholesky decomposition of a matrix such as $$\begin{pmatrix}1&amp;-\infty \\ 0 &amp; 2 \end{pmatrix}$$ or not?</p>
",linear_algebra
"<p>I think that I should to rewrite the matrix in a appropriate form, but I can't find it. For a $2\times2$ matrix I get the characteristics polynomial $x^2-1$ and the eigenvalues $-1,1$. For $3\times3$ matrix I get $-x^3+3x+2$ and the eigenvalues are $2,-1,-1$.</p>
",linear_algebra
"<p>Let $A,B \in M(n,F)$ be such that $AB=BA$. Then show that $A$ and $B$ has same characteristic polynomial.</p>

<p>How can I proceed to this? If I take $|B||\lambda I-A|=|\lambda B- BA|= |\lambda B- AB|$ But this will not help me..</p>
",linear_algebra
"<p>Is matrix $Svv^\top S$ positive semidefinite, given $S$ is symmetric positive semidefinite? Where $v\in\mathbb{R}^n$,  $S\in \mathbb{R}^{n\times n}$</p>
",linear_algebra
"<p>Let $T(θ) : \Bbb R^2 → \Bbb R^2$ be the transformation that rotates each vector counterclockwise by angle $θ$.</p>

<p>(a) Write the standard matrix for $T(θ)$.</p>

<p>(b) Explain in words or pictures why $T(θ_1+θ_2) = T(θ_1) ◦ T(θ_2)$.</p>

<p>(c) Derive the angle sum formula for cosine and sine by finding the standard matrix for $T(θ_1+θ_2) = T(θ_1) ◦ T(θ_2)$; that is, prove that $\cos(θ_1+θ_2) = \cos(θ_1)\cos(θ_2)−\sin(θ_1) \sin(θ_2)$ and $\sin(θ_1+θ_2) = \sin(θ_1)\cos(θ_2) + \sin(θ_2)\cos(θ_1)$.</p>

<p>For part a - I'm not sure how to find the standard matrix when I don't know the initial values of the matrix before the vectors rotate.</p>

<p>Part b - I know $T(θ_1) ◦ T(θ_2)$ is the Hadamard product of $T(θ_1)$ and $T(θ_2)$, but I was never taught any properties to prove part b.</p>

<p>Part c - this problem completely confuses me.</p>

<p>Any help would be appreciated.</p>
",linear_algebra
"<p>Lyapunov's equation says: given any $Q &gt; 0$ ($Q$ positive definite) there is $P &gt; 0$ such that $A^T P + P A + Q = 0$ if and only if for $\frac{dx(t)}{dt}=A x(t)$ it is the case that the real part of each eigenvalue of $A$ is negative. Then, the ellipsoid $x^T P x \leq 1$ is an invariant of $\frac{dx(t)}{dt}=A x(t)$.</p>

<p>The geometric interpretation of $P$ is such that the eigenvectors of $P$ form the principal axes of the ellipsoid and each eigenvalue is related to the length of the ellipsoid along the axis represented by the corresponding eigenvector.</p>

<p>What is the geometric interpretation of $Q$ resp. how does the choice of $Q$ affect $P$?</p>
",linear_algebra
"<p>Let A =</p>

<p>\begin{bmatrix}1/4&amp;\sqrt3/4\\\sqrt3/4&amp;3/4\end{bmatrix}</p>

<p>(a) Show that for each x ∈ R, Ax is the projection of x onto the line passing through the origin making an angle of 60 degrees with the positive x-axis.</p>

<p>(b) Show that null(A) is the line passing through the origin making an angle of 30 degrees with the negative x-axis.</p>

<p>(c) Show that null(A) = row(I − A).</p>

<p>For part a - I created an Ax augmented matrix, but after reducing the matrix I'm not sure how to determine that the lines formed make an angle of 60 degrees.</p>

<p>Part b - How would I find the null space of the matrix when the reduced form of A doesn't have any free variables?</p>

<p>Part c - I can't really prove part c since I'm not sure how to find the null space or row space of I-A.</p>
",linear_algebra
"<p>Let $F$ be a field and let $n$ be a positive integer. Let $A,B ∈ M_{n×n}(F)$ be matrices
satisfying $A^2 + B^2 = I$ and $AB + BA = O$. Show that $tr(A) = tr(B) = 0$.</p>

<p>I know that $tr(A^2)+tr(B^2)=n$ and that $(A+B)^2=I$. I'm having a hard time showing this. I've been playing around for a bit with no success. Any solutions/hints are greatly appreciated.</p>
",linear_algebra
"<p>Let $\mathbf C$ be a positive-definite $k\times k$ matrix. For all vectors $\mathbf u\in \mathbb R^k$ of length $\|\mathbf u\|=1$, consider vectors $\mathbf {uu}^\top\mathbf{Cu}$; they form a surface in $\mathbb R^k$. What is this surface? In particular, what is it in case of $k=2$?</p>

<p>Here is an example for $\mathbf C = \left(\begin{array}{cc}4&amp;2\\2&amp;2\end{array}\right)$:</p>

<p><a href=""http://i.stack.imgur.com/fztne.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/fztne.png"" alt=""Weird shape""></a></p>

<p>I do realize that the ""main axes"" (the longest and the shortest cuts) of this curve are given by the eigenvectors of $\mathbf C$ scaled by the respective eigenvalues. But the whole shape looks weird.</p>
",linear_algebra
"<p>the time averaged total energy, $\bar E$,
has the following $\varepsilon$ expansion in $D$ dimension:
\begin{equation}
\bar{E}=\varepsilon^{2-D}\frac{E_0}{2\lambda}+ \varepsilon^{4-D}E_1
\end{equation}
 from the above equation how can we write 
\begin{equation}
\omega_{\rm m}^2=
1-\frac{1}{2\lambda}\frac{(D-2)E_0}{(4-D)E_1}\,.
\end{equation}
where $$\omega_{\rm m}^2=1-\varepsilon_{\rm m}^2,$$  and $\lambda$ is a constant factor.
m denotes that angular frequency $\omega $ is minimum.</p>

<blockquote>
  <p>Can someone explain me how equation (2) can be written from equation
  (1)
  If you feel problem or need more information then please comment. 
  thanks in advance.
  for more info see <a href=""http://arxiv.org/abs/0802.3525"" rel=""nofollow"">here in equation (39 and 40)</a></p>
</blockquote>
",linear_algebra
"<p>Let's say I have the following equalities</p>

<p>$a_1x_1 + a_2x_2 + a_3x_3 + a_4x_4 = b_1x_1 + b_2x_2 + b_3x_3 + b_4x_4 = c_1x_1 + c_2x_2 + c_3x_3 + c_4x_4$</p>

<p>Where the $a$'s, $b$'s, and $c$'s are known, non-negative integers.</p>

<p>Is there an efficient way to check if a solution exists (the $x$'s) such that they are non-negative real numbers (except for the trivial case of all $x$'s being 0)? I don't need to actually calculate them, just need some way to see if a solution even exists.</p>
",linear_algebra
"<p>I'm trying to figure out what the dimension of the set of self-adjoint operators on V would be, or in more concrete terms:</p>

<p>Let $dim V =n$. Let $S(V)$ denote the set of self-adjoint linear operators on V. What is its dimension?</p>

<p>The only thing I know that somewhat resembles this might be that $dim L(V) = (dim V)^2$ but I'm not sure how I might be able to apply that to this problem.</p>

<p>Any tips or assistance would be greatly appreciated. Thanks!</p>

<p>EDIT: Also, V is a finite dimensional inner product (or Hermitian) space.</p>
",linear_algebra
"<p>Find the absolute extreme values taken by $f(x,y) = x^2 + 4y^2 + x - 2y$ on the closed region enclosed by the ellipse $1\over4$$x^2 + y^2 = 1$. </p>

<p>I know this might be a basic question but could someone please explain how to solve this problem?</p>

<p>Thanks in advance.</p>
",linear_algebra
"<p>What does it say about the eigenvectors of a matrix $A$ if the row-reduced form of the characteristic polynomal in coefficient matrix form has a row of 0's?</p>

<p>I know that it indicates something about the eigenvectors of $A$ but I can't remember what exactly... </p>
",linear_algebra
"<p>I just wanted to ask whether my proof is correct:</p>

<p>Suppose instead that $\mathbb{R}$ had a countable $\mathbb{Q}$-basis, say $v_1,v_2,v_3,\ldots$ (possibly finite).</p>

<p>Since $\mathbb{Q}$ is countable, $\,\text{span}(v_1,\ldots,v_k)$ is countable for each $k$ (possibly finitely many).</p>

<p>We have $\mathbb{R}=\bigcup_{k}\text{span}(v_1,\ldots,v_k)$ which is a countable union of countable sets.</p>

<p>It follows that $\mathbb{R}$ is countable. Contradiction.</p>

<p>I would be very grateful for any feedback.</p>

<p>Best wishes!</p>
",linear_algebra
"<p>Please help me in solving the recursion   $F(n)=K_0\frac{F(n-1)}{n-1}+K_1\frac{F(n-2)}{n-2}$, preferably using power series for the values of $F(n)$ in terms of $n$. Here $K_1$ and $K_2$  are constants. We are given  $F(0)=0,F(1)=3,F(2)=3/2$. Any methods of solution is welcome, even partial answers. We can discuss further. Thanks for taking time to read my question.</p>
",linear_algebra
"<p>Suppose the inner product on $P(R)$ is defined by $\langle p,q\rangle = \int^1_0 p(x)q(x)dx$.</p>

<p>Let $\phi$ be the linear functional on $P(R)$ defined by $\phi (p) = p(0)$ for each polynomial $p \in P(R)$. Prove that there does not exist $q \in P(R)$ such that $\phi (p) = \langle p, q\rangle$ for every $p \in P(R)$.</p>

<p>This is what I have so far:</p>

<p>Let $e_1,...,e_n$ be an orthonormal basis for $P(R)$.</p>

<p>$\phi (p) = \phi(\langle p, e_1\rangle e_1 + \dots + \langle p, e_n\rangle e_n) = \langle p, e_1\rangle \phi(e_1) + \dots + \langle p, e_n\rangle \phi(e_n)$</p>

<p>Thus, $\phi(e_1)e_1 + \dots + \phi(e_n) e_n = p(0)e_1 + \dots p(0) e_n$</p>

<p>I'm not sure where to go from here, help? Thank you!</p>
",linear_algebra
"<p>This came up in a practical problem involving a state change in a digital filter system.</p>

<p>Find $X$ given $A$ and $K$, where $A,X,K$ are all $n$ x $n$ square matrices:</p>

<p>$$
   X - A X A = K
$$
I couldn't find a direct way to do this, eventually I realized that it's just $n^2$ linear equations in $n^2$ unknowns, and it can be solved as follows:</p>

<ul>
<li>Restate so $X$ and $K$ are column vectors $\vec x$ and $\vec k$, each with $n^2$ elements</li>
<li>The term $A X A$ becomes $A_L A_R \vec x$, where $A_L, A_R$ are $n^2$ x $n^2$ matrices which perform the equivalent of multiplying by $A$ on the left and right in the original form</li>
<li>Find $\vec x = \left(I-A_L A_R \right)^{-1} \vec k$ and reorder to get $X$</li>
</ul>

<p>For $n=3$, for instance, if
$$
 A = \begin{bmatrix}
     a &amp; b &amp; c \\ d &amp; e &amp; f \\ g &amp; h &amp; i \end{bmatrix}
$$
then
$$
A_L = \begin{bmatrix}
  a &amp; 0 &amp; 0 &amp; b &amp; 0 &amp; 0 &amp; c &amp; 0 &amp; 0 \\
  0 &amp; a &amp; 0 &amp; 0 &amp; b &amp; 0 &amp; 0 &amp; c &amp; 0  \\
  0 &amp; 0 &amp; a &amp; 0 &amp; 0 &amp; b &amp; 0 &amp; 0 &amp; c  \\
  d &amp; 0 &amp; 0 &amp; e &amp; 0 &amp; 0 &amp; f &amp; 0 &amp; 0 \\
  0 &amp; d &amp; 0 &amp; 0 &amp; e &amp; 0 &amp; 0 &amp; f &amp; 0 \\
  0 &amp; 0 &amp; d &amp; 0 &amp; 0 &amp; e &amp; 0 &amp; 0 &amp; f \\
  g &amp; 0 &amp; 0 &amp; h &amp; 0 &amp; 0 &amp; i &amp; 0 &amp; 0 \\
  0 &amp; g &amp; 0 &amp; 0 &amp; h &amp; 0 &amp; 0 &amp; i &amp; 0 \\
  0 &amp; 0 &amp; g &amp; 0 &amp; 0 &amp; h &amp; 0 &amp; 0 &amp; i \end{bmatrix}
$$
and (in block form):
$$
A_R = \begin{bmatrix}
  A^T &amp; 0 &amp; 0 \\
   0 &amp; A^T &amp; 0 \\
   0 &amp;  0 &amp; A^T \end{bmatrix}
$$</p>

<p>Question is: is there any easier way to solve this? I'm now thinking that the relationship between the $n^2$ variables is such that you can't solve it without this kind of rewriting, but I'd be happy to be proven wrong. Is there a name for the procedure of restating the problem as above? Or a name for the type of the original equation? Perhaps it would be more natural with tensor notation - I'm not that familiar with that area.</p>

<p>One other note: the original equation can be be rewritten as the following two forms:</p>

<p>$$ 
X = A X A + K
$$
and (assuming $A$ is not singular)
$$
X = A^{-1} \left( X -  K \right) A^{-1}
$$
... and it seems to me that one of these (depending on the properties of $A$) may be usable as a iterator that will converge to the correct value of $X$. In some applications this may easier to work with than the full solution.</p>
",linear_algebra
"<p>I have a very stupid and simple question, which I do not have a clear idea on. One article that I read said, </p>

<blockquote>
  <p>""As a basic relationship in linear algebra states,
  the scalar product of vectors $x$ and $y$ in a base space of $A$ is
  $xAy$."" </p>
</blockquote>

<p>What does the 'base space' specifically represent? Is there any other term that indicates the same concept? What is the difference between ordinary scalar or inner product $xy$ and $xAy$? What role base space A does play? What are the impacts by converting $xy$ into $xAy$? Thank you so much in advance!</p>

<p>(I have uploaded the corresponding page below or you can have an access to the article via <a href=""http://www.sciencedirect.com/science/article/pii/S0378873310000031"" rel=""nofollow"">http://www.sciencedirect.com/science/article/pii/S0378873310000031</a> , in page 199, third paragraph.)</p>

<p><a href=""http://i.stack.imgur.com/tJMI5.jpg"" rel=""nofollow"">enter image description here</a></p>
",linear_algebra
"<ul>
<li>I want to show the following: For any square  matrix $A$ n $\times$ n of the form: $A=\begin{pmatrix} 
0 &amp; a_{1,2} &amp; . &amp; . &amp; . &amp; a_{1,n} \\ 
0 &amp; 0 &amp; a_{2,3} &amp; . &amp; . &amp; a_{2,n} \\ 
0 &amp; 0 &amp; 0 &amp; . &amp; .  &amp; .\\
. &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; a_{n-1,n} \\
. &amp; . &amp; . &amp; . &amp; . &amp; 0  
\end{pmatrix}$,</li>
</ul>

<p>$A^n=0$</p>

<p>In order to do that, I want to show that if you multiply such a matrix b times. All the coefficients $(a)_{ij}$ such that $i&lt;i+b-1$is equal to 0</p>

<ul>
<li><strong>My attempt</strong></li>
</ul>

<p>I am trying to show that $\forall b, \leq n$ $(A^b)_{i,i+b-1}= 0$</p>

<p>I will try to show this by induction</p>

<ul>
<li><strong>basis</strong> Let's show that $(A^2)_{i,i+1}=0$
By definition, $(A^2)_{i,i+1} = \Sigma^n_{k=0}a_{i,k}a_{k,i+1}$</li>
</ul>

<p>For $i \geq k$, $a_{i,k}=à \implies a_{i,k}a_{k,i+1} = 0$</p>

<p>For $i=k-1$, $i+1=k \implies i+1 \geq k \implies a_{k,i+1} = 0 \implies a_{i,k}a_{k,i+1} = 0$ And therefore, for $i &lt; k, a_{i,k}a_{k,i+1}=0$</p>

<p>Therefore, $(A^2)_{i,i+}=0$</p>

<p>We now have a matrix of the form: $A^2 = \begin{pmatrix} 
0 &amp; 0 &amp; a_{1,3} &amp; . &amp; . &amp; a_{1,n} \\ 
0 &amp; 0 &amp; 0 &amp; a_{2,4} &amp; . &amp; a_{2,n} \\ 
0 &amp; 0 &amp; 0 &amp; . &amp; .  &amp; .\\
. &amp; . &amp; . &amp; . &amp; . &amp; a_{n,n-2} \\
. &amp; . &amp; . &amp; . &amp; . &amp; 0 \\
. &amp; . &amp; . &amp; . &amp; . &amp; 0  
\end{pmatrix}$</p>

<ul>
<li><strong>Inductive step</strong> And here is where the struggle starts (I cannot finish this step).</li>
</ul>

<p>Let $(A^b)_{i,i+b-1}$ be TRUE, let's show that it implies that $(A^{b+1})_{i,i+b}$ is TRUE:</p>

<p>$(A^b)_{i,i+b-1}=0$</p>

<p>$\implies$ $(A)_{i,i+b-1}(A^b)_{i,i+b-1}=0$</p>

<p>$\implies \Sigma^n_{k=0} a_{i,i+b-1}(a^b)_{i,i+b-1}= 0$.</p>

<p><strong>EDIT: I think I have solved my problem, can you guys confirm</strong></p>

<p>We now have a multiplication of the form: $A \times A^b =\begin{pmatrix} 
0 &amp; a_{1,2} &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; a_{1,n} \\ 
0 &amp; 0 &amp; a_{2,3} &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; a_{2,n} \\ 
0 &amp; 0 &amp; 0 &amp; . &amp; .  &amp; . &amp; . &amp; . &amp; . &amp; .\\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; a_{n-1,n} \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; 0 \\
\end{pmatrix} \times  \begin{pmatrix} 
0 &amp; 0 &amp; . &amp; 0 &amp; a_{1,b+1} &amp; a_{1,b+2} &amp; . &amp; . &amp; . &amp; a_{1,n} \\ 
0 &amp; 0 &amp; 0 &amp; . &amp; 0 &amp; a_{2,b+2} &amp; a_{2,b+3} &amp; . &amp; . &amp; a_{2,n} \\ 
0 &amp; 0 &amp; 0 &amp; . &amp; .  &amp; 0 &amp; . &amp; . &amp; . &amp; .\\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; a_{n-b,n} \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; 0 \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
. &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . \\
0 &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; . &amp; 0 \\ 
\end{pmatrix}$</p>

<p>Let's call the first matrix $N$ and the second matrix $M$.</p>

<p>Let's show that $(NM)_{i,i+b} = 0$:</p>

<p>$(NM)_{i,i+b} = \Sigma_{k=0}^n n_{i,k}m_{k,i+b} = (0 \times \Sigma_{k=0}^i n_{k,i+b}) + (\Sigma_{k=n-i}^n a_{i,k} \times 0) = 0$</p>

<p>Therefore $(NM)_{i,i+b} = (AA^b)_{i,i+b} = (A^{b+1})_{i,i+b} = 0$</p>

<p><strong>I think I have succeeded to prove by induction that $(A^b)_{i,i+b-1} = 0$ But I am not certain</strong></p>

<p>Can someone confirm that my proof by induction is right?</p>
",linear_algebra
"<p>Let $T$ is a linear operator on a vector space V such that $dim(RangeT)=k$ , then how to prove  $T$ can have $at$ $most$ $k+1$ distinct eigen values ??</p>
",linear_algebra
"<p>How do you show that two matrices are similar? I know that if they are similar, then B=(v^-1)AV, but how do you find V^-1 and V? For example, the matrices {[1,2]T, [3,2]T} and {[0,4]T, [2,2]T}, how would you find the P and P^-1 (if they are similar)? Or would you have to show they are similar in a different way?</p>

<p>Thank you!</p>
",linear_algebra
"<p>Suppose we have a $(n+m)\times(n+m)$ matrix
$$A=\begin{pmatrix}
  0 &amp; B \\
  B^T &amp; C \\
 \end{pmatrix},$$
where $B$ is a $m\times n$ matrix and $C$ is a symmetric $n\times n$ matrix. Now suppose $B\ll C$ (in terms of eigenvalues), then matrix $A$ has two distinct sets of eigenvalues. $n$ of them are of order of the eigenvalues of $C$, the remaining three are suppressed by two powers of 
$$\theta=BC^{-1}.$$
One can block-diagonalize $A$ by expanding $\theta$. On one hand one obtains $m\times m$ matrix 
$$D=-\theta C\theta^T$$. On the other hand there is the $n\times n$ matrix 
$$E=C+\frac{1}{2}(\theta^\dagger\theta C+C^T\theta^T\theta^*).$$</p>

<p>Could anyone tell me how to do the block-diagonalization by expanding $\theta$?</p>
",linear_algebra
"<p>Let $A\in M_n({\Bbb F}_p )$. Suppose that $A^p = I_n$. Show that$(A-I_n)^p = 0$, and $A$ has an eigenvector $v\in {\Bbb F}^n_p$ with eigenvalue 1.</p>

<p>I know that $p$ divides the binomial coefficient $(^p_i)$ for $1\leq i\leq p-1$.
But what is the next?</p>

<p>Thnaks!</p>
",linear_algebra
"<p>Every basis of $\mathbb R^6$ can not be reduced to a basis of $5$-dimensional  subspace of $\mathbb R^6$ by removing one vector . Can anyone give an example for that?</p>
",linear_algebra
"<p>For any values of parameter $a$ solve the following system of linear equations:
$$\begin{cases} x+y+2z=1 \\ 2x+ay-z=4 \\ 3x+y+3z=1 \end{cases} $$</p>

<p>Calculating the value of determinant I found out, after I equalled it with zero, that $a$ has the value $-4\over 3$. So I thought that if it's required to solve this equation for any $a$ , then first of all I had to suppose that $D=0$, this means that $a={-4\over 3}$. For this value I found out that there is an infinite number of solutions for this system. But now my question is: what do I have to do with the case when $D\neq 0$? </p>

<p>Thank you!</p>
",linear_algebra
"<p>Let $X$ be a normed vector space and $Y \subset X$ a closed subspace. We consider the quotient $X / Y$ and equip it with the quotient norm. Then we may form the completion $\overline{X / Y}$.</p>

<p>We compare $\overline{X / Y}$ to the following space: denote by $\overline{X}$ the completion of $X$ and by $\overline{Y} \subset \overline{X}$ the closure of $Y \subset \overline{X}$. Now we form the quotient $\overline{X} / \overline{Y}$ with the quotient norm.</p>

<blockquote>
  <p>Are $\overline{X / Y}$ and $\overline{X} / \overline{Y}$ (naturally) isomorphic, i.e., is there a linear, bijective isometry between them?</p>
</blockquote>
",linear_algebra
"<p>I am asked to write a Matlab program to find the coefficients of the resulting polynomial which is the product of two other polynomials. However, I need someone to clarify the underlying concepts for me. In this post, I will use $P_a(x)=1+2x+3x^2$ and $P_b=1+2x+3x^2+4x^3$ as our examples for the two polynomials. Using matrix formulation (which is the requirement):
$$
a = \left(\begin{array}{c}
1\\
2\\
3\\
0\\
0\\
0\end{array} \right)
\qquad b = \left(\begin{array}{c}
1\\
2\\
3\\
4\\
0\\
0\\\end{array} \right)
$$
And we are looking for the vector $c$ that is the coefficients of our product polynomial. Since the degree of the resulting polynomial is $5$, we will have $6$ coefficients including the constant term. And I know that $c$ is a product of the circulant matrix of $a$ and the vector $b$:
$$
c = \left(\begin{array}{c}
c_0\\
c_1\\
c_2\\
c_3\\
c_4\\
c_5\end{array} \right)=
\left(\begin{array}{cccccc}
1&amp;0&amp;0&amp;0&amp;3&amp;2\\
2&amp;1&amp;0&amp;0&amp;0&amp;3\\
3&amp;2&amp;1&amp;0&amp;0&amp;0\\
0&amp;3&amp;2&amp;1&amp;0&amp;0\\
0&amp;0&amp;3&amp;2&amp;1&amp;0\\
0&amp;0&amp;0&amp;3&amp;2&amp;1\\
\end{array} \right)
\&gt;\dot\
\&gt;\left(\begin{array}{c}
1\\
2\\
3\\
4\\
0\\
0\\
\end{array} \right)
$$
and we denote the circulant matrix $A$. I know I can construct $A$ by using $FFT$: $$
A = F^{-1}\&gt;diag(F\,a)\&gt;F
$$
And here's what confuses me. From this point on, do I just multiply the matrix A by the vector b <strong>directly</strong>? I am required to implement the algorithm in $O(n\&gt;logn)$ time. And Let me repeat the requirement: <strong>1. Matrix formulation of the problem 2. Using FFT 3. Overall run time being $O(n\&gt;logn)$</strong> Any input is greatly appreciated. Thanks!</p>
",linear_algebra
"<p>Given two square matrices $A, B$, when is
$$\det(A+tB) = 0$$
for all $t\in \mathbb{R}$?</p>

<p>An easy sufficient condition is that $A$ and $B$'s kernels have nontrivial intersection. Per Henning's comment below, this is not also necessary.  Does there exist a nice necessary and sufficient characterization?</p>
",linear_algebra
"<p>Let $f \in \textrm{O}(n, \mathbb R)$. (O is the orthogonal group) Show:</p>

<p>i) If $f(W) \subset W$ for a subspace $W \subset \mathbb R^n$, then $f(W^\perp) \subset W^\perp$.</p>

<p>ii) If $f(\langle v \rangle ) \subset \langle v \rangle$ for a vector $0 \neq v \in \mathbb R$, then $v$ is an eigenvector of $f$ with value $1$ or $-1$.</p>
",linear_algebra
"<p>Find a projection $E$ wich projects $\mathbb{R}^2$ onto the subspace spanned by $(1,-1)$ along the subspace spanned by $(1,2)$.</p>

<p>What is the way to approach this problem? Almost to start! </p>

<p>Any suggestion is welcome, thanks.</p>
",linear_algebra
"<p>let $P_5 = \{ a_0 + a_1x + a_2x^2 + a_3x^3 + a_4x^4 + a_5x^5 \}$ be the vector space of polynomials of degree $\leq 5$ over $\mathbb{Q}$. Denote $D: P_5 \to P_5$ as the differentiation linear map, i.e. $D(\alpha) = \dfrac{d\alpha}{dx}$</p>

<p>1)Find the inverse of $D^4 + D^2 + Id$,</p>

<p>my answer: $Id - D^2$ as $D^6 - Id = (D^2-Id)(D^4 + D^2 + Id)$</p>

<p>2) find a unique solution to $\alpha \in P_5$ to the differential equation $\dfrac{d^4\alpha}{dx} + \dfrac{d^2\alpha}{dx^2} + \alpha = x^5 + 2x^3$</p>

<p>Could someone explain how I can use (1) to solve part (2)?</p>
",linear_algebra
"<p>Find the equation of the plane that passes through the line of intersection of the planes $4x - 2y + z - 3 = 0$ and $2x - y + 3z + 1 = 0$, and that is perpendicular to the plane $3x + y - z + 7 = 0$.</p>

<p>I have attached a picture and that is what I got.</p>

<p>Can someone please tell me if my answer is right because the answer at the back of the textbook is different but I am pretty confident with my solution. Thanks!</p>

<p><img src=""http://i.stack.imgur.com/5yp08.jpg"" alt=""enter image description here""></p>
",linear_algebra
"<p>Let the projector be the $N \times N$ matrix $A$. Let its rank be $r$. Let the dimension of the space for which it is the projector be $m$. Is $m==r$?</p>
",linear_algebra
"<p>Let $0$ denote the function ${T}$ that takes each element of some vector space to the additive identity of another vector space. Prove that $T$ is linear.</p>

<p>I just want to make sure I understand the basic properties of a linear map with this very simple function.</p>

<p>$ 0 \in\mathcal{L}(V,W)$ defined by $0v = 0$.</p>

<p>Additivity: $0(v+w) = 0v + 0w$ for all $v,w \in V$.</p>

<p>Homogeneity: $0(av) = a(0v)$ for all $a \in \mathbb{F}$ and all $v \in V$.</p>

<p>Therefore $T$ is linear.</p>

<p>Is this verification correct?</p>
",linear_algebra
"<p>$$\vec{v}^{t}\textbf{A}\vec{v} &gt; \textbf{0}\text{ and }\textbf{A}\vec{v} = \lambda\vec{v}\quad \Rightarrow \lambda&gt;\textbf{0}\quad(\mathbb{F}=\mathbb{R}) $$</p>

<p>proof:
$$\vec{v}^{t}\textbf{A}\vec{v} &gt; \textbf{0} \text{ and } \textbf{A}\vec{v}=\lambda\vec{v} $$
$$\Rightarrow\vec{v}^{t}\lambda\vec{v} &gt; \textbf{0} $$
$$\Rightarrow\lambda\vec{v}^{t}\vec{v} &gt; \textbf{0} $$
$$\Rightarrow\lambda\langle v, v\rangle&gt; \textbf{0} $$
$$\vec{v} \neq \vec{0}$$
$$\Rightarrow\langle v, v\rangle &gt; \textbf{0} $$
$$\Rightarrow\lambda &gt; \textbf{0}$$</p>
",linear_algebra
"<p>This question is somewhat simple: </p>

<p>If we write the transposition of a matrix like this:</p>

<pre><code>A_transposed = T.A
</code></pre>

<p>where T is the operator performing the transposition, can I find a matrix form for this operator, that is independent of the matrix A ? (In other words that would transpose any matrix the size of A? </p>
",linear_algebra
"<p>Find the equation of the plane tangent to the surface:
$$x^{\frac{1}{3}}+y^{\frac{1}{3}}+z^{\frac{1}{3}}=1$$ at the point:
$$P=\left(1,-1,1\right)$$
How to find it? I know i have to calculate a gradient which is:
$$\left(\frac{1}{3}x^{-\frac{2}{3}}, \frac{1}{3}y^{-\frac{2}{3}}, \frac{1}{3}z^{-\frac{2}{3}} \right)$$ but what should i do next? I think i need to substitute point into the gradient but how to substitute this point if i have $-1$ under the root?</p>
",linear_algebra
"<p>So, why do eigenvalues exclusively form the main diagonal in a diagonalizable matrix?</p>

<p>If we have $n\times n$ matrix ($n$ being a natural number) that is diagonalizable, why is it eigenvalues (exclusively eigenvalues) that make up the main diagonal? </p>
",linear_algebra
"<p>In the beginning of linear algebra courses, there are vectors in $\mathbb R^n$ and the dot product is introduced. We learn that if the dot product of two vectors is zero, then these vectors are called orthogonal and there is a right angle between them. Therefore, we understand perpendicularity from the definition of orthogonality. </p>

<p>In the last chapters, all previous notions are generalized as vector spaces and inner products are introduced. Then we learn vectors $\vec u$ and $\vec v$ are orthogonal if $\langle \vec u, \vec v \rangle=0$ in inner product spaces. Our previous knowledge guides us to seek a right angle between them. </p>

<p>Let $P$ be the vector space of first degree polynomials. Let $p(x)=ax+b$ and $q(x)=cx+d$. Define $\langle p(x), q(x) \rangle$ as</p>

<p>$$\langle p(x), q(x) \rangle=ac+bd$$</p>

<p>Then if we consider $p(x)=x-2$ and $q(x)=4x+2$, we find that $\langle p(x), q(x) \rangle=0$. But if we draw them, we see that there is $30.96$ degrees between them. So orthogonality in inner product spaces does not necessarily mean perpendicularity. If not perpendicularity, what should we understand from orthogonality in inner product spaces?</p>
",linear_algebra
"<p>$A$  is  an $n\times n$ matrix. Now  if  the  row-reduced  echelon  form  for  this  $A$  is   $E$  then  after  all  the  row  operations  we  have $\det(A)=M\det(E)$   where  $M$  is  a non-zero  scalar  from  the   field. 
 If  $E$  is  the  $n\times n$ identity  matrix  then  $\det(A) \neq 0$.
For  the  converse, $\det(A)$   is  non-zero, so  is  $M$. Then obviously $\det(E)\neq0$. How to  reach the  conclusion  that  $E$  is  the  identity matrix,from  here  just  need  a  little  help  with  that.</p>
",linear_algebra
"<p>The problem is to minimize the largest eigenvalue of a function of $x$.</p>

<p>objective:
$$ \min\{\lambda_{\max}(A(x))\}$$
where
$$A(x) = A_0+x_1A_1+x_2A_2+...x_nA_n$$ and all $A$ is positive semidefinite.</p>

<p>This problem can be solved by equivalent  SDP:
$$\text{minimize} \ \ t \\ \text{subject to} \ \ \ A(x)\leq tI$$
since
$$\lambda_{\max}(A(x)) \leq t \ \ \\ \text{iff} \ \ \ A(x)-tI \leq0$$
My question is why is that?</p>

<p>I can't find special property of eigenvalue for  positive semidefinite matrix where the above inequality holds</p>

<p>Can someone give me a brief proof? or point out where I can find the proof.</p>
",linear_algebra
"<p>Let $A\in \Bbb R^{n\times n}$ be a matrix such that $\mathrm{rank}(A) = n-1$ and consider the equation 
$$
  Ax = 0.
$$
Clearly, its solutions span a $1$-dimensional space, thus an additional assumption may lead to a unique solution. Let $a\in \mathbb R^n$ be a vector and consider a system of equations
$$ \tag{1}
\begin{cases}
  Ax &amp; = 0,
\\
 a\cdot x &amp; = 0
\end{cases}
$$
where $a\cdot x = \sum_i a_ix_i$ is the inner product. I have two questions: </p>

<ol>
<li><p>What are necessary and sufficient conditions on $a$ for $(1)$ to have the unique solution?</p></li>
<li><p>Can we rewrite $(1)$ in an equivalent matrix form, e.g. $(A+C)x = 0$ for some $C$.</p></li>
</ol>
",linear_algebra
"<p>Is the following true always for a matrix norm </p>

<p>$$\lVert AB\rVert \leqslant \lVert A\rVert \cdot \lVert B\rVert \text{ ?}$$</p>

<p>Related to this
 given $r$ is positive constant, $H$ is symmetric positive definite
 is the following true :</p>

<p>$$\lVert (rI - H)(rI + H)^{-1}\rVert &lt; 1 $$</p>

<p>or</p>

<p>$(rI - H)(rI + H)^{-1}$  has the spectral radius less than $1$ certainly?</p>

<p>Thank you.</p>
",linear_algebra
"<p>Let $A$ be any $n \times n$ matrix and $\| \cdot \|$ be the matrix norm induced by vector norm  on $\mathbb{R}^n$
(Euclidean
n-dimensional space). </p>

<p>If $\|I - A\| &lt; 1$, then show that $A$ is invertible 
and
derive the estimate</p>

<p>$\|A^{-1}\| &lt; \frac{1}{ 1 - \| I - A \|}$.</p>

<p>Similarly 
when can we expand $\frac{1}{ 1 - \| I - A \|}$ as a power series only is it if and only if the norm is less than $1$?</p>

<p>Thanks a lot!</p>
",linear_algebra
"<p>Line <em>m</em> goes through a point D(2, -4). Line <em>m</em> is parallel to line <em>l:</em> $5x+3y=-17$. Describe line <em>m</em> with an equation of type $ax+by=c$.</p>

<p>The solution should be $c=5*2+3*-4=-2$ so $\text{m: }5x+3y=-2$</p>

<p>The lines are parallel so $a=5$, $x$ and $y$ are known so: $5*2+b(-4)=c$. At this point I lack some information I should know to push that equation further. I suppose I should be able to fill either $b$ or $c$, but which one and why?</p>
",linear_algebra
"<p>Let $A_1, A_2, A_3, \ldots , A_m$ be positive semi-definite Hermitian matrices and then consider the polynomial $p(z,z_1,z_2,\ldots,z_m) = \det(z+z_1A_1 + z_2A_2 + \cdots+z_mA_m)$</p>

<p>Now Tao argues that if $z,z_1,z_2,\ldots,z_m$ have a positive imaginary part then the ""skew-adjoint part"" (what is this?) of $z+z_1A_1 + z_2A_2 + \cdots+z_mA_m $ is strictly positive definite and hence the quadratic form $\operatorname{Im} [ \langle (z+z_1A_1 + z_2A_2 + \cdots+z_mA_m)v, v \rangle   ]$ is non-degenerate and hence it follows that $z+z_1A_1 + z_2A_2 + \cdots+z_mA_m$ is non-singular.</p>

<p>Can someone kindly help understand what happened here? </p>
",linear_algebra
"<p>I'm losing my mind over this question.
For $H$ a Hilbert space, $A,B$ closed subspaces, and $B$ is of dimension $1$, I want to prove that $A+B$ is also closed.</p>

<p>I'm looking for a straightforward proof, with minimum use of high theorems (without Hahn-Banach, etc).</p>

<p>What I did so far was taking a converging sequence in A+B, and mark it as:
$x_k=a_k+\lambda_kv$, for $v$ the base of $B$.
I figured out that I could write the limit, $x$, as $x=P_Ax+P_{A^\perp}$ and do the same on $B$, and maybe work something from there.</p>

<p>I also thought that somehow it would be good to take advantage of the sequence $\lambda_k$ which is in $\mathbb{R}$ resp. $\mathbb{C}$. Maybe prove that it converges somehow..</p>

<p>Thanks so much</p>
",linear_algebra
"<p>I have a question on my assignment asking me to prove that if $A$ is an $n\times n$ orthogonal matrix, then $\det(A) = \pm1$. What I did so far is:</p>

<p>We know that $A\cdot A^t = I$ (since it is orthogonal), and that would mean that if $A$ is a matrix with elements $a,b,c,d$ then :</p>

<p>\begin{cases}a^2 + b^2 = 1\\
ac + bd = 0\\
c^2 + d^2 = 1\end{cases}</p>

<p>which implies that \begin{align}\det(A)&amp;= ad - bc\\
&amp;= -\frac{bd^2}{c} - cb\\
&amp;= -\frac{bd^2}{c} - \frac{c^2b}{c}\\
&amp;= -\frac{bd^2 + bc^2}{c}\\
&amp;= -\frac{b(d^2 + c^2)}{c}\\
&amp;= -\frac{b(1)}{c}\\
&amp;= -b/c\end{align}</p>

<p>I might be doing something wrong here, could someone please help me out understand this?</p>
",linear_algebra
"<p>Finding whether a given set is subspace of</p>

<p>$$ P_n$$</p>

<p>which is for $n\ge 0$ the set of all polynials of degree at most consist of all polynomial of the form</p>

<p>$$p(t)=a_0+a_1t^1+\cdots+a_nt^n$$</p>

<p>where coefficient and t are real numbers.</p>

<p>is </p>

<p>$$p(t)=a+t^2$$</p>

<p>where $a$ is a real number.</p>

<p>a subspace of $P_n$</p>

<p>I think no because the zero Vector of $P_n$ $0$ is not in</p>

<p>$$p(t)=a+t^2$$</p>

<p>if $t$ is zero then $a+0$ does not equal $0$?</p>
",linear_algebra
"<p>It's clear that for any field $\mathbb{F}$ any finite group $G$ can be embedded into $GL_{n}(\mathbb{F})$ for some $n$.</p>

<p>My question is about one modification of this result.
Let's fix positive integer $N$. Is it true that for any finite group $G$ there exist a field $\mathbb{F}$ such that $G$ is embeddable into $GL_N(\mathbb{F})$?</p>

<p><strong>UPD:</strong> For $N=1$ it's false. Let's consider $N&gt;1$.  </p>
",linear_algebra
"<p>What part of the definition of a vector space (see <a href=""https://en.wikipedia.org/wiki/Vector_space#Definition"" rel=""nofollow"">here</a>) requires it to be <strong>closed</strong> under addition and multiplication by a scalar in the field? I would understand if we defined a vector space as a group of vectors rather then a set but we don't, also non of the axioms require this to be a condition?</p>
",linear_algebra
"<p>Question goes: Law enforcement would like to know the time at which a person died. The investigator arrived on the scene at 8:15pm, which we will call $t$ hours after death. At 8:15 (i.e $t$ hours after death), the temp of the body was found to be $27.4°C$ (Degrees). One hour later, $t+ 1$ hours after death, the body was found to be $26.1°C$. Known constants are $T_s=21°C$, $T_o=36.8°C$.</p>

<p>At what time did the victim die?</p>

<p><strong>MY WORKING</strong></p>

<p>Formula: $T(t)=T_s+(T_o-T_s)e^{-kt}$</p>

<p><strong>1</strong>. $T(t)=T_s+(T_o-T_s)e^{-kt} \quad \rightarrow \quad  
27.4=21+15.8e^{-kt}$</p>

<p><strong>2</strong>.$T(t)=T_s+(T_o-T_s)e^{-kt} \quad \rightarrow \quad 26.1=21+15.8e^{-kt}$</p>

<ol>
<li><p>$27.4=21+15.8e^{-kt}\rightarrow  
6.4=15.8e^{-kt}\rightarrow  
\ln(6.4/15.8)=-kt\rightarrow  
-0.903=-kt$</p></li>
<li><p>$26.1=21+15.8e^{-kt} \rightarrow  
5.1=15.8e^{-k(t+1)} \rightarrow 
ln(5.1/15.8)=-k(t+1)  \rightarrow $</p></li>
</ol>

<p>$-1.131=-k(t+1)$</p>

<p>This is as far as I have got and I believe I should be doing simultaneous equations but am totally unsure if thats correct. Any help would be appreciated.</p>
",linear_algebra
"<p>How do I prove the statement: if there exist unique $u$ and $w$ such that for any $v$, $v=u+w$, then $V$ is the direct sum of $U$ and $W$? ($U,W,V$ are vector spaces, $u \in U, w \in W, v \in V$)</p>

<p>I have this vague feeling that I should negate the conclusion and show a contradiction occurs, but it's not so easy for me. How do I expand the logic? </p>
",linear_algebra
"<p>It may be that the title of my question is wrong but i am writing this question because i am struck while reading this paper  <a href=""https://projecteuclid.org/download/pdf_1/euclid.kjm/1250776060"" rel=""nofollow"">Brownian motion on rotational group</a> Where $^*\mathscr{f} $ is transpose of $\mathscr{f}$.</p>

<p>If $\mathcal{\gamma_1(=|\mathscr{f}|^2)\ge \gamma _2\ge\gamma _3} $  are the eigenvalues of  $\mathscr{f^*f}$ ,if the $p_1,p_2,p_3$ are the corresponding projections $(\gamma_1 p_1+\gamma_2p_2+\gamma_3p_3=\mathscr{f^*f})$,and if </p>

<p>$$\int_{S^2}do$$ </p>

<p>is the arithmetic average over the spherical surface $S^2$ ,then the </p>

<p>$$\int_{S^2}|p_1o|^2do=\int_{S^2}|p_2o|^2do=\int_{S^2}|p_3o|^2do=\frac{1}{3}$$and $$\int_{S^2 }of \ ^*fodo $$</p>

<p>where $o\ f\ ^*f\ o$ is the inner product of $o\in S^2 $ and $\mathcal{f}\in R^3$.
1. are f the skew hermitian matrix ?and where are these projections taken on?
2.what does it mean to have  inner product on two different basis  ?
any help will be appreciated</p>
",linear_algebra
"<blockquote>
  <p>The set of all polynomials in a single variable $x$ forms a vector space $P$ of infinite dimension. Differentiation is a
  linear transformation on this vector space: </p>
  
  <p>$\frac{d}{dx}: P → P, p(x) → p'(x)$.</p>
  
  <p>(a) What is the dimension of the kernel of $\frac{d}{dx}$
  as a linear transformation on $P$ ? </p>
  
  <p>(b) The linear transformation $\frac{d}{dx}
+ 2x$ acts on $P$ as $p(x) → p'(x) + 2xp(x)$. What is the dimension of its kernel?</p>
</blockquote>

<p>I do know what dimensions and kernels of matrices are but this question is confusing me and I don't really understand it. Would really appreciate some help.</p>
",linear_algebra
"<p>Show that reflecting $R_2$ across the line $y = x$ and then reflecting it across the $y$−axis is the same as rotating it counterclockwise by $90$ degrees.</p>

<p>I know how to prove this statement geometrically, but I'm assuming the question is asking me to prove this through rotational vectors, which I'm not sure how to prove.</p>
",linear_algebra
"<p>Let T : R2 → R2 be the linear transformation which rotates the plane clockwise by 45 degrees, then expands the plane by a factor of 2 in the direction of the x-axis, then finally rotates the plane counterclockwise by 45 degrees. </p>

<p>Find a standard matrix for T. </p>

<p>What does T do to the square whose vertices are (0, 0),(1, 1),(0, 2),(−1, 1)?</p>

<p>I'm struggling with this question at the moment. How would I find the standard matrix of T when I don't know the initial values of R2, before transformation?</p>

<p>For the transformation of the square, I'm not sure what the question is asking. Wouldn't the transformation of the square just be all four vectors rotated by 45 degrees, expanded towards the x-axis by a factor of 2 and then rotated counterclockwise by 45? How would I show that in terms of matrix T.</p>

<p>Help would be appreciated.</p>
",linear_algebra
"<p>Let $V$ be a matrix. </p>

<p>What conditions should we require so that we can find a random vector $X = (X_1, \dots, X_n)$ so that $V = Var(X)$? </p>

<p>Of course necessary conditions are:</p>

<ul>
<li>All the elements on the diagonal should be positive</li>
<li>The matrix has to be symmetric</li>
<li>$v_{ij} \le \sqrt{v_{ii}v_{jj}}$ (Because of $Cov(X_i, X_j) \le \sqrt{Var(X_i) Var(X_j)})$</li>
</ul>

<p>But I am sure these are not sufficient as I have a counterexample.</p>

<p>So what other properties we should require on a matrix so that it can be considered a covariance matrix? </p>
",linear_algebra
"<p>I have a collection of 3D points in the standard $x$, $y$, $z$ vector space. Now I pick one of the points $p$ as a new origin and two other points $a$ and $b$ such that $a - p$ and $b - p$ form two vectors of a new vector space. The third vector of the space I will call $x$ and calculate that as the cross product of the first two vectors.</p>

<p>Now I would like to recast or reevaluate each of the points in my collection in terms of the new vector space. How do I do that?</p>

<p>(Also, if 'recasting' not the right term here, please correct me.)</p>
",linear_algebra
"<p>Let $F:= \mathbb{F}_7[x]/(x^2+3x+1)$</p>

<ol>
<li>Is it a field?</li>
<li>Find all the roots in F of the polynom  $f (Y) := Y^2+[3]_{F}Y +[1]_{F} \in F[Y]$.</li>
</ol>

<p><strong>Attempt:</strong></p>

<ol>
<li>It is a field, because $x^2+3x+1$ is irreducible $\in \mathbb{F}_7[x]$. In fact it has no roots $\in \mathbb{F}_7$.</li>
<li>I suppose I can't just replace numbers from $0$ to $6$ in the place of the $Y$. What should you do to solve this problem?</li>
</ol>
",linear_algebra
"<p>My idea of proving every real symmetric matrix can be diagonalized is that, first prove two eigenvectors with different eigenvalues must be orthogonal, then I failed to prove that all the eigenvectors span the whole vector space.</p>

<p>To be specific, my question is, if $A$ is a real symmetric $n\times n$ matrix, let $p(t)=\det(tI-A)$ be the characteristic polynomial of $A$, and $\lambda$ be some eigenvalue of $A$, and $\lambda$ is a root of $p(t)$ of order $k$, then how to prove $\dim (\ker(\lambda I-A))=k$?</p>
",linear_algebra
"<blockquote>
  <p>\begin{align*}
  x - \alpha y &amp;= 1\\
  \alpha x - y &amp;= 1
  \end{align*}</p>
</blockquote>

<p>For which values of alpha does the system have an infinite number of solutions, no solutions and one solution.</p>

<p>Find the solution when it is unique.</p>

<p>My attempt:</p>

<p>$-\alpha \cdot \mathrm{eqn}_1 + \mathrm{eqn}_2$ resulting in $(\alpha^2 - 1)y = 1-\alpha$.</p>

<p>then we get $y = (1-\alpha)/(\alpha^2-1)$</p>

<p>so, $y = -1/(1+\alpha)$, but I am trying to proceed </p>
",linear_algebra
"<p>I'm having some trouble calculating the angle of an human joint in 3D using the Microsoft Kinect.</p>

<p>Here's an example of the angle of the elbow (using the shoulder and wrist joint):</p>

<p><a href=""http://i.stack.imgur.com/9tkQp.jpg"" rel=""nofollow"" title=""Example"">Image of example</a></p>

<p>Calculating angles between 0° and 180° is no problem, but when the person <strong>hyper</strong>extends his elbow my calculation returns 170° instead of 190°.</p>

<p>The calculation I'm using is as follows:</p>

<ol>
<li>$d = b - a$</li>
<li>$e = b - c$</li>
</ol>

<p>Where a, b and c are 3D-points and d and e are 3D-vectors.</p>

<p>My question is: <strong>How can I calculate the angle between $d$ en $e$ where the angle is between 0° and 360°?</strong></p>

<p>Thanks in advance!</p>
",linear_algebra
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://math.stackexchange.com/questions/119904/units-and-nilpotents"">Units and Nilpotents</a>  </p>
</blockquote>



<p>Given $A^{2012}=0$ prove that $A+I$ is invertible and find an expression for $(A+I)^{-1}$ in terms of $A$. ($I$ is the identity matrix).</p>
",linear_algebra
"<p>From <a href=""http://en.wikipedia.org/wiki/Basis_%28linear_algebra%29#Definition"" rel=""nofollow"">Wikipedia</a>:</p>

<p>""A basis $B$ of a vector space $V$ over a field $K$ is a linearly independent subset of $V$ that spans (or generates) $V$.(1)</p>

<p>$B$ is a minimal generating set of $V$, i.e., it is a generating set and no proper subset of B is also a generating set.(2)</p>

<p>$B$ is a maximal set of linearly independent vectors, i.e., it is a linearly independent set but no other linearly independent set contains it as a proper subset.""(3)</p>

<p>I tried to prove (1) => (3) => (2), to see that these are equivalent definitions, can you tell me if my proof is correct:</p>

<p>(1) => (3):
Let $B$ be linearly independent and spanning. Then $B$ is maximal: Let $v$ be any vector in $V$. Then since $B$ is spanning, $\exists b_i \in B, k_i \in K: \sum_{i=1}^n b_i k_i = v$. Hence $v - \sum_{i=1}^n b_i k_i  = 0$ and hence $B \cup \{v\}$ is linearly dependent. So $B$ is maximal since $v$ was arbitrary. </p>

<p>(3) => (2):
Let $B$ be maximal and linearly independent. Then $B$ is minimal and spanning:</p>

<p>spanning: Let $v \in V$ be arbitrary. $B$ is maximal hence $B \cup \{v\}$ is linearly dependent. i.e. $\exists b_i \in B , k_i \in K : \sum_i b_i k_i = v$, i.e. $B$ is spanning. </p>

<p>minimal: $B$ is linearly independent. Let $b \in B$. Then $b \notin span( B \setminus \{b\})$ hence $B$ is minimal.</p>

<p>(2) => (1):
Let $B$ be minimal and spanning. Then $B$ is linearly independent:
Assume $B$ not linearly independent then $\exists b_i \in B, k_i \in K: b = \sum_i b_i k_i$. Then $B \setminus \{b\}$ is spanning which contradicts that $B$ is minimal.</p>
",linear_algebra
"<p>I have seen the statement ""Every finite dimensional vector space has a basis."" (<a href=""http://www.cs.xu.edu/math/math240/07s/06_Bases.pdf"" rel=""nofollow"">Here</a> on page 5)</p>

<p>I'm confused about what this tells me. It seems to tell me nothing: by definition, the dimension of a vector space is the number of elements in a basis of it. Then saying a vector space is finite dimensional is the same as saying that it has a basis.</p>

<p>Or are there any other definitions of dimension than the number of basis elements?</p>
",linear_algebra
"<p>Let $w_1, \dots, w_m \in \mathbb{C}^d$.</p>

<p>Condition (1) is:</p>

<p>$\sum_i |\langle v, w_i \rangle |^2 = \eta$ whenever $\|v\| = 1$.</p>

<p>Condition (2) is:</p>

<p>$\sum_i u_i u_i^* = I^d$, where $u_i = w_i / \sqrt{\eta}$</p>

<p><a href=""http://arxiv.org/pdf/1306.3969v3.pdf"" rel=""nofollow"">This paper</a> claims that the two conditions are equivalent (top of page 3, just beneath the statement of Corollary 1.3).  I can't figure out why that would be.  Can you help point me in the right direction?</p>
",linear_algebra
"<p>Show that the rank of $ n\times n$ symmetric tridiagonal matrix is at least $n-1$, and prove that it has $n$ distinct eigenvalues.</p>
",linear_algebra
"<p>For each $m \in \{0,1,2,3\} $  find a subspace of {0,1,2,3} of dimension $m$ and verify answers. I'm not sure what is meant by this or how to begin solving? </p>
",linear_algebra
"<p>Hey so I got a question about Vector spaces </p>

<blockquote>
  <p>Let $V=(8,\infty)$. For $u,v$ in $V$ and $a$ in $\mathbb R$ define vector addition by $u\boxplus v:= uv-8(u+v)+72$ and scalar multiplication by $a\boxdot u :=(u-8)^a +8$. It can be shown that $(V,\boxplus,\boxdot)$ is a vector space over the scalar field $\mathbb R$. Find the additive inverse of 16. </p>
</blockquote>

<p>So what I did was find the zero vector which is 9, and set u to 16, but that was the incorrect answer. So I'm confused as to how you find the additive inverse.</p>

<p>Thanks!  </p>
",linear_algebra
"<p>Is there a formal proper way of finding the line between two points?</p>

<p>By that I don't mean the line connecting the two points, I mean a line that runs the same distance away from point 1 and point 2.</p>

<p>To phrase it another way, I want to find the equation of a line that divides the plane into two equal parts, where each of the two points are the same distance from the line.</p>

<p>I drew a picture. In this picture, how do I find the purple line?</p>

<p><img src=""http://i.stack.imgur.com/gDe5v.jpg"" alt=""Line equidistant from two points""></p>

<p>It may or not be relevant, but I'm asking because I am trying to learn about Support Vector Machines.</p>
",linear_algebra
"<p><strong>Question:</strong> </p>

<blockquote>
  <p>Using the Lagrange's Multipliers method, find the points on the ellipse $x^2+2y^2=1$, that are situated in the longest and shortest distance from the line $x+y=2$. </p>
</blockquote>

<p>I know how to use Lagrange's Method but I do not know how to restrict this question to: 'find a functions max and min on a given set', thus you need to help me solely with that.</p>
",linear_algebra
"<p>I'm trying to figure this out: we're dealing with real numbers only here, with the standard scalar product defined as $&lt;\mathbf{v},\mathbf{w}&gt; = \mathbf{v}^T\mathbf{w}$, and we are told, unusually perhaps, that orthogonal matrices are defined as those for which $&lt;R\mathbf{v},R\mathbf{w}&gt; = &lt;\mathbf{v},\mathbf{w}&gt;$, and I need to show from this that the matrix R can be characterised by $R^TR=\mathbf{1}$ (and also that $det(R)=(+/-)1$ but this is fine).</p>

<p>Using the definition of the scalar product, it is not hard to get to $\mathbf{v}^TR^TR\mathbf{w}=\mathbf{v}^T\mathbf{w}$, which I feel is a good starting point, and seems to be close; whilst $R^TR=\mathbf{1}$ would make this work, it isn't the only matrix it can be. I also know $\mathbf{v}^TR^TR\mathbf{w}=\mathbf{w}^TR^TR\mathbf{v}$ but I'm not sure if that helps.</p>

<p>Thanks</p>
",linear_algebra
"<p>Find the equation of a plane tangent to the surface given by $$xyz+x^2-3y^2+z^3=14$$ at $$P=\left( 5,-2,3 \right)$$
In my opinion answer is: $$4x+27y+25z-41=0$$ If not please tell me what am i doing wrong.</p>
",linear_algebra
"<p>Is $\{(x,y,z) \in \mathbb{R}^3 :x^2+3y^2+12z^2 = 0\}$ a vector space?</p>

<p>My inclination is that the only real solution to $x^2+3y^2+12z^2=0$ is $(0,0,0)$, which is the trivial subspace of $\mathbb{R}^3$. However my true/false assignment is telling me that this is incorrect, that this set is in fact NOT a vector space. Why?</p>
",linear_algebra
"<blockquote>
  <p>Let $\{e_1,\ldots,e_n\}$ be an arbitrary basis in a finite dimensional inner product space $V$. Prove there exists vectors $\{f_1,\ldots,f_n\}$ such that $(e_i,f_j)=\delta_{ij}$.</p>
</blockquote>

<p>I tried using the the Gram-Schmidt process to obtain the $f_i$'s but the resulting $f_i$'s should apparently be uniquely determined and $(e_i,f_j)=\delta_{ij}$ won't hold.</p>

<p>What other methods could I try to obtain the $\{f_1,\ldots,f_n\}$? Perhaps we could use induction on $\dim(V)$ for a proof?</p>
",linear_algebra
"<p>Doing some reviewing and I'm not 100% sure if my thought-process is correct.</p>

<p>I have the following two vectors and need to prove they're a basis for $R^3$:</p>

<p>$$B=
        \begin{bmatrix}
        1 \\
        0 \\
        -1 \\
        \end{bmatrix},
  \begin{bmatrix}
        0 \\
        1 \\
        -1 \\
        \end{bmatrix}
$$</p>

<p>Now these two vectors are linearly independent, and now I have to prove they span $\Re^3$.</p>

<p>So I have two arbitrary scalars: $\alpha$ and $\beta$ that belong to R:</p>

<p>$$\alpha
        \begin{bmatrix}
        1 \\
        0 \\
        -1 \\
        \end{bmatrix}+\beta
  \begin{bmatrix}
        0 \\
        1 \\
        -1 \\
        \end{bmatrix}=
 \begin{bmatrix}
        x \\
        y \\
        z \\
        \end{bmatrix}
$$</p>

<p>Not much solving to do here</p>

<p>$$
        \begin{bmatrix}
        1 &amp; 0 &amp; x \\
        0 &amp; 1 &amp; y \\
        -1 &amp; -1 &amp; z \\
        \end{bmatrix}
$$</p>

<p>I am left with:</p>

<p>$\alpha = x$, $\beta=y$ and $-\alpha - \beta=z$</p>

<p>Now what I'm having difficulties understanding is how this basis can span all of $R^3$ with z being: $-\alpha - \beta=z$</p>
",linear_algebra
"<p>Let $V := R^n$ be a vector space and let $I \in O(n)$ be an operator satisfying $I^2 = -Id$. I want to show that the $span\{x,Ix\}$ is an invarient subspace of $I$.</p>

<p>Let $W = span\{x,Ix\}$. I need to show that $IW \subseteq W$. That is, if we transform $W$ by $I$, then we are still within $W$. But, my linear algebra is bad and i'm struggling to figure how to do this. Can anyone show me how to do this or offer advice?</p>
",linear_algebra
"<p>$f:G \rightarrow H$  is a group homomorphism</p>

<p>$g\in G$ is an element of order $n$.</p>

<p>(a) Prove that $f (g)$ is a final order and that the order of the element $f (g)$ parts n.</p>

<p>(b) What is the order of the element $g^{-1}$? What is the order of the element $g ^ m$ for $m\in \Bbb N$?</p>

<p>(c) Whether there is any injective homomorphism $(\Bbb Z_{12}, +) \rightarrow (\Bbb Z_{18}, +)$?</p>

<p>What $(\Bbb Z_{12}; +) \rightarrow (\Bbb Z_{24}; +)$? If so, find example.</p>

<p>i did this:</p>

<p>a) $f(g)$- is final order and parts n
$f(g)^n = f(e)=e$
$f(g)$ - is final order</p>

<p>b) $g^n = e \iff (g^-1)=e$
$g^{-1})^m=e$   for $m&lt;n    \implies  g^m=e$</p>

<p>So how can i do second (b) and (c) THANKS</p>
",linear_algebra
"<p><img src=""http://i.stack.imgur.com/KfInK.png"" alt=""I am trying to calculate B"">I wondered how to prove a theory I have about calculating a point having only a line and a circle the line is tangent to.
If  $$\Delta{y}^2$$$$\Delta{x}^2$$ Thus the distance between any two integer numbers is $$\sqrt{\Delta{y}^2+\Delta{x}^2}=m$$ After seeing this I decided to ""create"" my very own formula $$n*r=m$$ where r is the distance between the point on the line, m is the gradient and $$n\Delta{y}(initial)= \Delta{y}(new)$$ and $$n\Delta{x}(initial)=\Delta{x}(new)$$ thus the new point will be $$(x+\Delta{x}(new);y+\Delta{y}(new)) or (x-\Delta{x}(new);y-\Delta{y}(new))$$ I believe it will work for all lines and points with a distance. I am actually afraid to post this here but how can I prove my theory?
In this example I am trying to calculate B.</p>
",linear_algebra
"<p>I was trying to generate a direct formula for this series but I am not sure whether it is possible to do so.</p>

<p>$$1\ln(1) + 2\ln(2) + 3\ln(3) + 4\ln(4)+\dots+(n-1)\ln(n-1) + n\ln(n)$$</p>
",linear_algebra
"<p><strong><em>How exactly can I convert the below equation into the vector form?</em></strong> (i.e. V(i,j,k) form or $a*i+b*j+c*k$ form):
$$\frac{x-5}{-10}=\frac{y-3}{-6}=\frac{z-2}{-4}$$</p>

<p>I'm actually trying to find the angle between two 3D lines, but I only know how to find out angles between vectors, so I'm trying to convert the above equation to vector form so as to carry out what I need to.</p>
",linear_algebra
"<p>Given a matrix $M$, we can compute its singular value decomposition $M=U\Sigma V^*$ where $^*$ is the complex conjugate transpose. $U$ and $V$ are unitary, so $UU^*=I$, $VV^*=I$. Let's take the $i$-th column of $U$, $u_i$. I've experimented with a few examples and I found that the matrix $u_iu_i^*$ always has rank 1. What theorem/property is behind this? Or even, is there a short and sweet proof of it?</p>
",linear_algebra
"<p>What is the basis for the intersection of the plane $x-2y+3z=0$ with the $xy plane$ in $R^3$ ? Also can the basis and dimensions  of these planes separately be found  ??</p>
",linear_algebra
"<p>Let $f : \mathbb{C}^{n}\rightarrow \mathbb{C}^{n}$ be a linear operator with  a simple spectrum, furthermore, let $g : \mathbb{C}^{n}\rightarrow \mathbb{C}^n
$ be a linear operator such that  $f$ and $g$ commute.</p>

<p>Show that there is $P$ a polynomial such that $g=P(f)$.</p>

<p><strong>Remark:</strong> The spectrum is simple when the characteristic polynomial has not multiple roots.</p>
",linear_algebra
"<p>\begin{equation}
P = \begin{bmatrix}1 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 3 \\ 3 &amp; 0 &amp; 1
\end{bmatrix}
\end{equation}</p>

<p>a) P is the transition matrix from what basis B to the standard
basis S = {e1, e2, e3} for R3?</p>

<p>b) P is the transition matrix from the standard basis
S = {e1, e2, e3} to what basis B for R3?</p>

<p>My attempt:</p>

<p>For a), if PB=S (is this even right?), can we just multiply inverse of P both sides to get B?</p>
",linear_algebra
"<p>Some years ago I was in a lecture where I met for the first time the matrix representation of some differential and integral operators (once discretized). Back then, someone mentioned me that every linear operator has its matrix representation. I liked the idea a lot, and I even think it sounded to me like a theorem. Unfortunately I have not been able to find a reference where the same affirmation (together with some worked-out examples) would be. There is this book of Burden and Faires ""Numerical Analysis"", where certainly one can find examples of the equivalence of, say elliptic partial differential equations, with the explicit matrix of the discretized equation (using finite differences), chapter 12, eight edition. But I would hope to find some references with something more general (as I said, with some theorems behind), and also some examples, even if they are confined to finite differences only from which to extract the elements to construct the matrices. </p>
",linear_algebra
"<p>Let $A$ and $B$ be real $n\times n$ matrices with $ABA=A$. How can I prove
$\operatorname{tr} AB\le n$?</p>
",linear_algebra
"<p>Let $T$ be a diagonalizable operator on a vector space $V$. Prove that the operator
$$a_nT^n + a_{n-1}T^{n-1}+\cdots+a_1T+a_0 Id_V$$
 on $V$ is also diagonalizable for any scalars $a_1, a_1,\dots,a_n$.</p>

<hr>

<p>First off, what is $Id_V$? I've never seen this before.</p>
",linear_algebra
"<p>The question:</p>

<p><em>Suppose in a single period investment problem we may divide our wealth between n assets and that the return on the ith security is given by</em></p>

<p><em>$r_i = \alpha + \beta_i\theta + \epsilon_i,$ $i = 1, ..., n$,</em></p>

<p><em>where $\alpha,$ $\beta_i$ are constants, and $\theta$ and $\epsilon_i$ are random variables. $\theta$ represents some underlying common economic variable (such as overall economic growth) that influences the return on all the securities. The $\epsilon_i$ are random variables assumed to be uncorrelated with each other and with $\theta$. Suppose that the $\epsilon_i$ have zero mean and common variance $\sigma_\epsilon^2$.</em></p>

<p><em>Denote the mean and variance of $\theta$ by $\mu_\theta$ and $\sigma_\theta^2$.
Determine the covariance matrix $\Sigma$ of the returns, and verify that $\beta =(\beta_1, ..., \beta_n)$ is one of its eigenvectors.</em></p>

<p><em>What can you say about the other eigenvectors? Hence find the inverse $\Sigma^{-1}$. Find the portfolio that has minimal risk, and determine its variance and expected return.
Let $\beta_i$ = $1$ for all $i = 1,2,... ,n$. Treating $\mu_\theta$, $\sigma_\theta^2$ and $\sigma_\epsilon^2$ as fixed, let $n$ tend to infinity, and comment on the minimal variance portfolio. Interpret this in terms of diversification as an investment strategy.</em></p>

<p>Basically, I have done all of this question except everything after computing $\Sigma^{-1}$. I have the following formula for $\Sigma^{-1}$:</p>

<p>$\Sigma^{-1}$ = $aI  + b$, where $a = \displaystyle\frac{1}{\sigma_\epsilon^2}$ and $b = \left(\displaystyle\frac{1}{\sigma_\epsilon^2 + \sigma_\theta^2\beta^T\beta} - \displaystyle\frac{1}{\sigma_\epsilon^2}\right) \displaystyle\frac{1}{\beta^T \beta}$, </p>

<p>which I'm almost certain is correct. The problem is, that is pretty messy! So when I want to compute the minimal variance portfolio which is given by</p>

<p>$w = \displaystyle \frac{\Sigma^{-1}1}{1^T\Sigma^{-1}1}$, so I can compute the mean return. The variance is just $\displaystyle \frac{1}{1^T\Sigma^{-1}1}$, but this is still messy. </p>

<p>I get the motivation behind the question, which is that the $\epsilon_i$ represent risk due to unforeseen circumstances where as $\theta$ is risk felt by everyone in the market, and that by letting $n \rightarrow \infty$ I can in essence ""diversify away"" the contribution of risk due to the $\epsilon_i$, but I cannot show this explicitly, which is frustrating. </p>

<p>So, does anybody have smart ways of calculating the minimum variance portfolio, weights, variance etc? </p>
",linear_algebra
"<p>The way I always understood linear functionals on a vector space $V$ is to consider then as measuring objects which give projections when they are given vectors. Now I wanted to make this a little bit more precise and I did as follows: let $\omega \in V^\ast$ be a linear functional, $\omega \neq 0$. Since $\omega : V\to K$ where $K$ is the underlying field, and since $\omega$ is not null, we have that $\operatorname{Im}(\omega) = K$ since $K$ has dimension $1$.</p>

<p>Because of that, the rank-nullity theorem gives $\dim V = \dim \ker \omega + \dim K$ and this implies $\dim \ker \omega = \dim V - 1$. In that case $\ker \omega$ is a hyperplane and we know we can split $V$ as:</p>

<p>$$V = \ker \omega \oplus W,$$</p>

<p>now ne can show that there exists just one $w\in W$ such that $\omega(w) = 1$. To prove it, suppose there's another, say $\tilde{w}\in W$, then since $W$ is one-dimensional one has $\tilde{w} = kw$. Because of that we have $\omega(\tilde{w}) = k\omega(w)$ and since we suppose that both $w$ and $\tilde{w}$ are such that $\omega(w) = \omega(\tilde{w}) = 1$ one has $k =1 $ and $w = \tilde{w}$.</p>

<p>Given that, one can define the operator $P_W : V\to V$ given by $P_W(v) = \omega(v)w$ where $w$ is the unique vector with $\omega(w) = 1 $. This linear operator is a projection operator because $P_W^2 = P_W$.</p>

<p>In that case we can think of it in the following way: $P_W$ is a projection operator in the direction of $W$ with the property that $\omega$ is the object which measures the projections. So this unique $w$ defines ""one unit"" of $\omega$ and $\omega$ measure projections with respect to this $w$.</p>

<p>Is that the correct way to think about linear functionals? Is that way they can be considered measuring objects capable of giving projections?</p>
",linear_algebra
"<p>Show that $ B_1 = \{\textbf{Av}| \textbf{v} \in B\} $ is also a basis for $\mathbb{R}^n.$</p>

<p>I apologize for my informality, but I would really like some feedback as to whether I am using the correct reasoning. </p>

<p>To begin, I noticed that this set $ B_1$ should contain an $\textit{n}\times 1$ vector. So, this means that I need to prove that this vector is linearly independent and spans $\mathbb{R}^n$. </p>

<p>Since no component of $\textbf{v}$ is $0$ because it is linearly independent, and $\textbf{A}$ only has the trivial solution for a homogeneous system, then any $\textbf{Av}$ should be linearly independent. Because the dimensions of $\textit{B}_1$ are the same as $\mathbb{R}^n$, then it is a basis.</p>
",linear_algebra
"<ol>
<li>$\{(x,y): x^2+y^2=0, x,y\in\mathbb{C}\}$, is it a subspace of $\mathbb{C}^2$?</li>
</ol>

<p>I thought yes atleast a trivial subspace as $\{(0,0)\}$ , the answer says No!</p>

<ol start=""2"">
<li>$\{(x,y): x^2-y^2=0, x,y\in\mathbb{R}\}$, is it a subspace of $\mathbb{R}^2$?</li>
</ol>

<p>I thought yes as it is  just $y=x$ or $y=-x$ so one dimensional subspace of the plane, but answer says No!</p>

<p>3.$\{(x,y): xy=0, x,y\in\mathbb{R}\}$, is it a subspace of $\mathbb{R}^2$?</p>

<p>I thought yes atleast a trivial subspace as $\{(0,0)\}$ , the answer says No!</p>

<p>please help</p>
",linear_algebra
"<p><strong>Background:</strong> Many (if not all) of the transformation matrices used in $3D$ computer graphics are $4\times 4$, including the three values for $x$, $y$ and $z$, plus an additional term which usually has a value of $1$.</p>

<p>Given the extra computing effort required to multiply $4\times 4$ matrices instead of $3\times 3$ matrices, there must be a substantial benefit to including that extra fourth term, even though $3\times 3$ matrices <em>should</em> (?) be sufficient to describe points and transformations in 3D space.</p>

<p><strong>Question:</strong> Why is the inclusion of a fourth term beneficial? I can guess that it makes the computations easier in some manner, but I would really like to know <em>why</em> that is the case.</p>
",linear_algebra
"<p>Let $V$ be a finite dimensional real vector space and let $A:V\to V$ be a linear map such that $A^2=A$. Assume that $A\ne0$ and that $A\ne I$. Which of the following statements are true?</p>

<p>a. $ker(A)\ne0$</p>

<p>b. $V=ker(A)\oplus R(A)$</p>

<p>c. The map $I+A$ is invertible</p>

<p>(c) is true since eigen value of $A$ cann't be $-1$. (a) and (b) are too true??. Not sure about them</p>
",linear_algebra
"<p>In each of the following cases, describe the smallest subset of $C$ which contains all the eigenvalues of every member of the set $S$.</p>

<p>(a) $S=\{A\in M_n(C) | A=BB^*$ for some $B\in M_n(C)\}$</p>

<p>(b) $ S=\{A\in M_n(C)| A=B+B^*$ for some $B\in M_n(C)\}$</p>

<p>(c) $ S=\{A\in M_n(C)| A+A^*=0 \}$</p>

<p>For $\lambda$ as an eigen value of $B$ , (a) will have $\lambda\lambda^*=|\lambda|^2\ge0.$ Hence The smallest subset will be $\{x\in R|x\ge0\}$.</p>

<p>(b) will have the set as $R$. </p>

<p>(c)  will have the set as the set of purely imaginary numbers</p>
",linear_algebra
"<p>Consider an $m\times m$ non-negative matrix $A$ where elements of $A$ can take many different values e.g. they are functions of a variable z. Suppose $A$ is such that one of its eigenvalues is equal to one. Can we say anything about the properties of matrix $A$? </p>

<p>For example, a sufficient condition is that the sum of all columns to be one [plus irreducibility]. Under this condition, irrespective of the values of the elements of the matrix, one eigenvalue is always equal to one. My question: is there a simple necessary condition?</p>
",linear_algebra
"<p>If $V$ and $W$ are vector spaces and $T$ is a linear transformation such that $T:V\longrightarrow W$. Furthermore, if $T$ is onto then $\mathrm{rank}(T) = \dim(W)$ right? The range is on the entire codomain then. This is not a homework question I'm reviewing. I know it sounds stupid but I want to make sure I'm not missing something. Shouldn't this be the definition of onto? It's funny because this statement isn't mentioned anywhere in the text.</p>
",linear_algebra
"<p>If a man can row at a speed of x m/sec , and the water in the river flows at a speed of  y m/sec ,  then if then man wants to cross the river from one bank to the opposite bank, i.e. he would be moving horizontally in the river , neither upstream nor downstream , then what would be the effect on the speed of rowing of the man . What would be his speed in terms of x and y ?</p>
",linear_algebra
"<p>Looking for an elegant proof of $\det(\textbf{A}) = \det(\textbf{A}^{t})$ without Schur decomposition.</p>

<p><strong>Proof 1 with Schur decomposition</strong>
$$\textbf{A} = \textbf{P}^{t}\Delta\textbf{P} \implies\textbf{A}^{t} = (\textbf{P}^{t}\Delta\textbf{P})^{t} = \textbf{P}^{t}\Delta^{t}\textbf{P}$$
So, $\textbf{P}$  is unitary matrix, $\textbf{P}^{t}=\textbf{P}^{-1}$.
$$\det(\textbf{P})=\det(\textbf{P}^{t})= \det(\textbf{P}^{-1})$$
 $\Delta$ is upper triangular matrix.
$$\det(\Delta)=\det(\Delta^{t}) \implies   \det(\textbf{A})=\det(\textbf{A}^{t})$$ </p>
",linear_algebra
"<p>How to solve matrix equation $AXH+AHX−BH=0$? All matrices are square, $A$, $B$ known constant matrices and invertible, $H$ can take any value, $X$ represent the solution to be found. </p>

<p>I have seen about the Sylvester Equation like in this post <a href=""http://math.stackexchange.com/questions/39906/solving-a-matrix-equation-ax-xb-in-a-cas"">Solving a matrix equation $AX=XB$ in a CAS</a>, but I'm not sure how to apply it because of the presence of matrix H.</p>
",linear_algebra
"<p>I have that the set of vectors:</p>

<p>$$\vec u, \vec v, \vec w$$
is L.I.</p>

<p>This means that:</p>

<p>$$a_1\vec u + a_2\vec v + a_3\vec w = \vec 0 \implies a_1 = a_2 = a_3 = 0$$</p>

<p>I need to prove that the set:</p>

<p>$$(\vec u + \vec v + \vec w, \vec u - \vec v, 3\vec v)$$</p>

<p>Is also L.I.</p>

<p>What I did was to make a linear combination with the vectors, so:</p>

<p>$$k_1(\vec u + \vec v + \vec w) + k_2(\vec u - \vec v) + k_3(3\vec v) = \vec 0 \tag{1}$$</p>

<p>If this set is L.I., then $k_1 = k_2 = k_3 = 0$.</p>

<p>Expanding the sum:</p>

<p>$$k_1\vec u + k_1\vec v + k_1\vec w + k_2\vec u - k_2\vec v + 3k_3\vec v = \vec 0$$</p>

<p>So I have:</p>

<p>$$(k_1+k_2)\vec u + (k_1 -k_2 + 3k_3)\vec v + k_1 \vec w = \vec 0$$</p>

<p>By $(1)$ I have that this is a L.I. set iff 
$$(k_1+k_2) = (k_1 -k_2 + 3k_3) = k_1 = 0$$</p>

<p>Am I correct? How do I prove, then, that $(k_1+k_2) = (k_1 -k_2 + 3k_3) = k_1 = 0$?</p>
",linear_algebra
"<p>In general the inverse of a sparse matrix is dense. A notable (but trivial) exception from that rule are diagonal matrices. Is there any other (broad) class of sparse matrices whose inverse is also sparse?</p>
",linear_algebra
"<p>There exists a continuous function $f$ whose domain is $[2,5]$ and the range is $(3,4)$. We have to prove that there exists at least one point $p \in (2,5)$ such that $f(p)=p$.</p>

<p>Now this is easy to see intuitively. The values of $f$ increase more slowly than the values of $x$ do. In the beginning, $f(x)&gt;x$, in the end, $f(x)&lt;x$. So, there must be at least one point at which $f(x)=x$.</p>

<p>But how do I prove this rigourously, using some mathematical arguments?</p>
",linear_algebra
"<p>(Long time observer, first time asking a question, so excuse me if I get any of the rules wrong)</p>

<p>I am having trouble wrapping my head around this problem and presenting the proof. </p>

<p>If I know A, B is invertible, given: $X^{T}$$(BA)^{T}$$A^{T}$=$V^{T}$ I would like to show X = $A^{-1}$$B^{-1}$$A^{-1}$V </p>

<p>This is what I have so far</p>

<p>Given $X^{T}(BA)^{T}A^{T} = V^{T}$  and since we know $A, B$ is invertible then by property of transposes  $(AB)^{T}= B^{T}A^{T}$;</p>

<p>then $X^{T}A^{T}B^{T}A^{T} =V^{T}$;</p>

<p>$(XABA)^{T} = V^{T}$ by transposing both sides - ""involution"" </p>

<p>$XABA = V$ Then since $ABA $is invertible, it can be moved to the other side</p>

<p>as required I am left with $X = A^{-1}B^{-1}A^{-1}V$</p>

<p>Any comments or suggestions are appreciated!</p>
",linear_algebra
"<p>Can we define a vector space structure on $\mathbb {R}^n$ other than usual scalar multiplication and usual addition such that the dimension of $\mathbb {R}^n$ over $\mathbb {R}$ is not $n$ but some $m$ not equal to $n$?</p>
",linear_algebra
"<p>An ellipsoid centered at the origin is defined by the solutions $\mathbf{x}$ to the equation $\mathbf{x}^TM\mathbf{x} = 1$, where M is a positive definite matrix.</p>

<p>How can I see why M needs to be positive definite, based on the equation of an ellipse $Ax^2 + Bxy + Cy^2 = 1$ where $B-4AC &lt; 0$? It looks like the idea is to make $B-4AC &lt; 0$ equate to the requirement that all eigenvalues of $M$ are positive for a 2x2 matrix, but I can't seem to make it work.</p>

<p>Also, what other shapes can we represent with $\mathbf{x}^TM\mathbf{x} = 1$ when $M$ is not positive definite?</p>
",linear_algebra
"<p>There's a theorem in Linear Algebra which says that if ${\bf A}$ is an $m \times n$ matrix and $m &lt; n$, then the homogeneous system of linear equations ${\bf A}{\bf X}=0$ has a non trivial solution.</p>

<p>I read a proof but what happens if I have a matrix like ${\bf B}$, whereas</p>

<p>B =        \begin{pmatrix}
        1 &amp; 0 &amp; 0 &amp; 0\\
        0 &amp; 0 &amp; 0 &amp; 0\\
        0 &amp; 0 &amp; 0 &amp; 0\\
        \end{pmatrix}</p>

<p>For ${\bf B}$, $m &lt; n$ but the only solution for ${\bf B}$ is the trivial one, unless I am getting something wrong, which I suspect and I would appreciate a lot if you help me find what is it.</p>

<p>Thank you in advance.</p>
",linear_algebra
"<p><a href=""http://i.stack.imgur.com/podWE.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/podWE.png"" alt=""The problem:""></a></p>

<p><a href=""http://i.stack.imgur.com/LqSh7.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/LqSh7.png"" alt=""enter image description here""></a></p>

<p>I understand how to find the image($A$). The basis of Im($A$) would be the first two columns of the matrix $A$ (given the two leading 1's in ref are in the first and second columns). </p>

<p>So the $\text{Ker}(B) = [1,1,1,1],[1,2,3,4]$ </p>

<p>But I do not get how to find $B$ based on its kernel? Any ideas? </p>
",linear_algebra
"<blockquote>
  <p><strong>Problem Statement</strong>: Let $A=\begin{bmatrix} 2 &amp;&amp; 1 \\ 1 &amp;&amp; 2 \end{bmatrix}$. Find an orthonormal basis for $\mathbb{C}^2$ with respect to the Hermitian form $\bar{x}^TAy$.</p>
</blockquote>

<p>I am trying to figure out this proof, but not sure if what I am currently trying to do will help me. I was goin to start out by taking an arbitrary basis $B=\left\{v_1,v_2\right\}$ and write two arbitrary vectors in $\mathbb{C}^2$ as linear combinations of basis elements:
$$v=x_1v_1+x_2v_2$$ $$w=y_1v_1+y_2v_2$$</p>

<p>Then break down the Hermitian form $$\langle v,w \rangle=\langle x_1v_1+x_2v_2, y_1v_1+y_2v_2 \rangle=\bar{x_1}\langle v_1, y_1v_1+y_2v_2 \rangle+\bar{x_2}\langle v_2, y_1v_1+y_2v_2 \rangle=\bar{x_1}y_1\langle v_1, v_1 \rangle+\bar{x_1}y_2\langle v_1, v_2 \rangle+\bar{x_2}y_1\langle v_2, v_1 \rangle+\bar{x_2}y_2\langle v_2, v_2 \rangle=\sum_{i=1,j=1}^2 \bar{x}_iy_j\langle v_i, v_j\rangle=\bar{x}^TAy$$</p>

<p>Then I want to use the fact that we're given $A$ in order to define $v_1,v_2$, but I am confused with one thing:
In my notes, I have that $$a_{ij}=\langle v_i,v_j\rangle$$ but my notes also say for any orthonormal basis, that $$\langle v_i,v_j\rangle:=\begin{cases} 1\ \mathrm{if}\ i=j \\ 0\ \mathrm{if}\ i\neq j \end{cases}$$
which conflicts with the fact that $A=\begin{bmatrix} 2 &amp;&amp; 1 \\ 1 &amp;&amp; 2 \end{bmatrix}$ because that would mean that $$\langle v_i,v_j\rangle:=\begin{cases} 2\ \mathrm{if}\ i=j \\ 1\ \mathrm{if}\ i\neq j \end{cases}$$</p>

<p>Is there a more straightforward approach to this problem?</p>
",linear_algebra
"<p>Suppose that $X$ is $n\times K$ with full column rank and $y$ $n\times 1$. I understand that if $\beta$ satisfies the system $X\beta=y$, then $\beta=(X'X)^{-1}X'y$ (dimension $k\times 1$). But how do I verify the reverse direction
$$
\beta=(X'X)^{-1}X'y\implies X\beta=y?
$$
This question is self-contained but it is related to what I asked <a href=""http://math.stackexchange.com/q/983816/178464"">earlier</a>. Thank you for your help. </p>
",linear_algebra
"<p>Consider the following homogeneous equation where $A$ and $X$ are matrices.</p>

<p>$$AX = 0$$</p>

<p>I want to know whether there are non trivial solutions for this equations.
Now, if $A^{-1}$ exists, then I can multiply throughout by it and get $X = 0$, so if $A$ is invertible, only the trivial solution exists.
However, I do not understand why $A$ being non-invertible would imply that non-trivial solutions exists, shouldn't it just imply that no solutions exist?</p>
",linear_algebra
"<p>I have been given the quadratic form $$A(x,x) = 2x^2-\frac{1}{2}y^2-2xy-4xz$$ and been asked to diagonalize it, find the change of basis matrix, and find the new basis in which A is diagonalized.</p>

<p>I found the diagonalized version of A to be $$2\xi_1^2-\frac{1}{2}\xi_2^2-2\xi_3^2$$ where $\xi_1 = x-\frac{y}{2}-z$,$\xi_2=y$,$\xi_3=\frac{y}{2}+z$.  I was then able to calculate the change of basis matrix $$B = \begin{pmatrix} 0 &amp;0 &amp;-1\\0 &amp; 1 &amp; -\frac{1}{2} \\ 1 &amp; 2 &amp; 2 \end{pmatrix}$$</p>

<p>This leads to my question.  How do I find the new basis?  Do I just perform Gaussian elimination on the diagonalized version of A?  So the new basis would just be the stardard basis $$\begin{pmatrix} 1 &amp;0 &amp; 0\\0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix}$$</p>
",linear_algebra
"<p>Let n=1,2,3,... and $i^2=-1$ and:</p>

<p>$$F=[e^{i\frac{2\pi kl}{n}}]_{k,l=0}^{n-1}\in\Bbb{C}^{n,n}$$</p>

<p>Find $F^HF$ and $F^{-1}$.</p>

<p>In this quite challenging (at least for me) problem I started from finding the matrix $F^HF$. In order to do that you need find $F^H$ first. I think the equation of this matrix is $F^H=[e^{-i\frac{2\pi kl}{n}}]_{k,l=0}^{n-1}$. So now let's think about matrix $F^HF$. To do that we need to know what is the k'th row of $F^H$. It looks like this:</p>

<p>$[e^{-i\frac{2\pi k0}{n}} e^{-i\frac{2\pi k1}{n}} e^{-i\frac{2\pi k2}{n}}... e^{-i\frac{2\pi k(n-1)}{n}}]$.</p>

<p>Now what about j'th column of $F$? According to definition it should look like that:
$[e^{i\frac{2\pi 0j}{n}} e^{i\frac{2\pi 1j}{n}} e^{i\frac{2\pi 2j}{n}}... e^{i\frac{2\pi (n-1)j}{n}}]^T$</p>

<p>So let's think about indices k,j of $F^HF$. It should be sum of multiplication of corresponding elements of k'th row of $F^H$ and j'th column of $F$. So the value at indices k,j of $F^HF$ should look like that:</p>

<p>$e^{-i\frac{2\pi k0}{n}}*e^{i\frac{2\pi 0j}{n}} + e^{-i\frac{2\pi k1}{n}}*e^{i\frac{2\pi 1j}{n}}+...+e^{-i\frac{2\pi k(n-1)}{n}}*e^{i\frac{2\pi (n-1)j}{n}}$</p>

<p>So we can write $F^HF$ down as:</p>

<p>$[\sum_{m=0}^{n-1}e^{\frac{i2\pi m}{n}(j-k)}]_{k,j=0}^{n-1}$</p>

<p>Have I done everything right? Or maybe I completely screwed up this part of the problem?</p>

<p>Also, how to proceed with finding $F^{-1}$?</p>
",linear_algebra
"<p>I want to find the projection from $\mathbb{R}^n$ onto a vector subspace of $\mathbb{R}^n$. Can I do this by adding the projections to each basis vector, even if the basis vectors are not orthogonal?
Specifically, projecting $x$ onto $V$, can I define the projection $$\operatorname{proj}_V(x) = \sum_i \frac {v_i\cdot x}{v_i\cdot v_i}v_i$$ for basis vectors $v_i$?</p>
",linear_algebra
"<p>Let $L_A$ :$R^{3}_{col}$ $\rightarrow$ $R^{3}_{col}$ , X $\rightarrow$ AX be operator of left multiplication by matrix $$A=\begin{bmatrix}1 &amp; 2 &amp; 1 \\ 0 &amp; 1 &amp; 1 \\ -1 &amp; 3 &amp;4\end{bmatrix}$$Find bases of :</p>

<p><strong>a.</strong> kernel Ker $L_A$</p>

<p><strong>b.</strong> image Im $L_A$</p>

<p><strong>c.</strong> Ker $L_A$ + Im $L_A$ and Ker $L_A$ $\cap$ Im $L_A$</p>

<p>I found the null space of $L_A$ as [1,-1,1] and the image as [1,0,-1] and [2,1,3].  But I couldn't think of something for part c.
Do we use the fact that dim Ker $L_A$ + dim Im $L_A$= dim $L_A$??</p>
",linear_algebra
"<p>Let $V$ be a real vector space equipped with a scalar product $\langle, \rangle$ (i.e. a positive definite symmetric bilinear form). </p>

<p>We say that an endomorphism $J: V \to V$ is an almost complex structure if $J^2=-Id.$ </p>

<p>$J$ is said to be compatible with the scalar product if $\langle J v, J w \rangle = \langle v, w \rangle. $</p>

<p>I'd like a very simple example of a scalar product and almost complex structure such that $J$ FAILS to be compatible with $\langle, \rangle.$   This is very basic -and hopefully trivial- but I can't find any counterexamples. </p>
",linear_algebra
"<p>H is an inner product space with inner product $( . , . )$ over the complex numbers, and $T∈L(H,H)$.  Let $R=T+T^*$, $S=T-T^*$ .   Supposing that T is normal and $T(\alpha)=(x+iy)\alpha$, how do I compute $(R∘S)(\alpha)$ in terms of $x,y,\alpha$ if I know that $R∘S=T∘T-T^*∘T^*$?  Thanks for any and all help!</p>
",linear_algebra
"<p>I have a problem with the following question.</p>

<p>For which $n$ does the following equation have solutions in complex numbers</p>

<p>$$|z-(1+i)^n|=z $$</p>

<p>Progress so far.</p>

<ol>
<li><p>Let $z=a+bi$.</p></li>
<li><p>Since modulus represents a distance, the imaginary part of RHS has to be 0. This immediately makes $b=0$.</p></li>
<li><p>If solutions are in the complex domain $|a-(1+i)^n|=a $ by 2., and $a$ is Real. </p></li>
<li><p>?</p></li>
</ol>

<p>I don't know where to go from here.  </p>
",linear_algebra
"<p>Define operatot $L$ :$R^{3}_{col}$$\rightarrow$ $R^{3}_{col}$ by equation $L(x_1,x_2,x_3)=(3x_1+x_3,-2x_1+x_2,-x_1+2x_2+4x_3)$.</p>

<p><strong>a.</strong> Find matrix L in the standard basis of $R^{3}_{col}$.</p>

<p><strong>b.</strong> and in the basis $f_1=(1,0,1)$, $f_2=(-1,2,1)$,$f_3=(2,1,1)$.</p>

<p><strong>c.</strong> Show that L is invertible and evaluate $L^{-1}(x_1,x_2,x_3)$.</p>

<p>Do we write the linear equation in the form $$A=\begin{bmatrix}3 &amp; 0 &amp; 1 \\ -2 &amp; 1 &amp; 0 \\ -1 &amp; 2 &amp;4\end{bmatrix}$$. And then from here by row reducing to row echelon matrix find the basis.Right??</p>
",linear_algebra
"<p>I have two vectors, 1 is the current direction of a moving object and the other is the new direction that I want that object to change to.</p>

<p>What I'm trying to achieve is to get the current direction to gradually change to the new direction but I'm not really sure how to do this. It would be similar a ship slowly turning I guess.</p>

<p>Could someone help me out please?</p>
",linear_algebra
"<p>Is it true that there are irreducible hyperbolic polynomials $p(x,y,z) \in \mathbb{R}[x,y,z]$, $p$ homogeneous of any degree? Are there even concrete examples for such polynomials?</p>

<p>I know that there are irreducible polynomials of any degree and that there are hyperbolic polynomials of any degree in this setting, but I do not see whether also polynomials which have both properties exist of any degree. </p>

<p>Thank you for your help.</p>

<p>Edit: By hyperbolic I mean the following: </p>

<p>$p$ is hyperbolic with respect to $\textbf{e} \in \mathbb{R}^3$ if $p(\textbf{e}) &gt; 0$ and for all vectors $\textbf{x} \in \mathbb{R}^3$ the univariate polynomial $t \mapsto p(\textbf{x} - t\textbf{e})$ has only real roots.</p>
",linear_algebra
"<p>If $X,Y,Z$ are three random variables with normal distribution, how can we define the joint distribution of $(X,Y,Z)$? Can we define a similar covariance tensor $\Sigma=Cov(X,Y,Z) = E[(X-E[X])(Y-E[Y])(Z-E[Z])]$? </p>

<p>Notice that knowing only the joint distribution of any two is not sufficient to know the joint distribution. We need the know the information of such a tensor $\Sigma$.</p>

<p>My question comes from in the following problem. Consider $\Sigma$ to be symmetric, $\Sigma_{ijk} = \Sigma_{ikj}=\Sigma_{jik}=\Sigma_{jki}=\Sigma_{kij}=\Sigma_{kji}$. </p>

<p>If 
$$\partial_t \Sigma_{ijk} + \Sigma_{sjk} \partial_{x_s} u_i  +\Sigma_{isk} \partial_{x_s} u_j +\Sigma_{ijs} \partial_{x_s} u_k = 0, $$
can we find a function $f=f(\Sigma)$ such that 
$$\partial_t f + \partial_{x_s} u_s = 0$$
Here we use that Einstein summation notation. And for $\sigma$ being a matrix, this is easy. Since if $\partial_t \sigma_{ij} + \sigma_{sj} \partial_{x_s} u_i+\sigma_{is} \partial_{x_s} u_j=0$, we have $f(\sigma)=\ln \det \sigma$ satisfying $f_t + 2 \nabla \cdot u = 0$.</p>

<p>These two questions are related, which I will not show here.</p>
",linear_algebra
"<blockquote>
  <p>Let $c_{00} (\mathbb{N})$ denote the space of finitely non-zero sequences, and let $(\beta_n)_{n \in \mathbb{N}} \subset \mathbb{F}$ be a sequence of scalars. Then the subsets
  $$X := \{(x_n)_{n \in \mathbb{N}} \in c_{00} (\mathbb{N}) \; | \; x_{2n} = 0, \; \forall n \in \mathbb{N} \}, \quad Y := \{(x_n)_{n \in \mathbb{N}} \in c_{00} (\mathbb{N}) \; | \; x_{2n-1} + \beta_n x_{2n} = 0, \; \forall n \in \mathbb{N} \}$$ are complementary subspaces of $c_{00} (\mathbb{N})$, that is, the subsets $X, Y$ are closed subspaces and $c_{00} (\mathbb{N})$ is the internal direct sum of $X$ and $Y$.</p>
</blockquote>

<p>It follows readily that $X$ and $Y$ are closed subspaces of $c_{00} (\mathbb{N})$. However, I do not succeed in showing that $c_{00} (\mathbb{N})$ is the internal direct sum of $X$ and $Y$.</p>
",linear_algebra
"<p>The theory of commutative absolutely flat rings (a.k.a. commutative von Neumann regular rings) is algebraic and furthermore it is the smallest variety containing all fields. Being a variety the category of (set-theoretic) models is arguably much better behaved than the category of fields.</p>

<blockquote>
  <p>How does linear algebra in modules over commutative absolutely flat rings compare
  to plain linear algebra, i.e. working with vector spaces? Is is it
  basically the same or are there some major differences?</p>
</blockquote>

<p>Let's ask some more concrete questions:</p>

<p>Let $R$ be an commutative absolutely flat ring: Are finitely generated $R$-modules always free? Assuming the axiom of choice: Are <em>all</em> $R$-modules free?</p>
",linear_algebra
"<blockquote>
  <p>How to prove that eigenvalues of a rotation matrix in $\text{SO}(3)$ are $e^{(i\theta)}$ , $e^{(−i\theta)}$?</p>
</blockquote>

<p>Here, $\theta$ is the angle of rotation and $i$ is $\sqrt{-1}$ . </p>

<p>Edit 1:</p>

<p>I have been able to prove that there is one eigenvalue of 1, and other two are complex conjugates of each other. This comes from the fact that the rotation matrix can be written as an exponential $R = e^\omega $ where R is the rotation matrix and $\omega$ is a skew symmetric matrix. I also was able to determine that the axis of rotation is the eigenvector corresponding to eigenvalue 1. What I'm not being able to prove is that how are the other eigenvalues related to the angle of rotation. </p>
",linear_algebra
"<p>I saw the following question a book of mine:</p>

<blockquote>
  <p>Show that an $n\times n$ orthogonal matrix has $n(n-1)/2$ independent parameters.</p>
</blockquote>

<p>I have no idea what an <em>independent parameter</em> is. Could you explain it to me?</p>
",linear_algebra
"<p>List all diagonalizable $2\times 2$ matrices over the a field $F$ consisting of two elements $0$ and $1$.</p>

<p>I want to try and do this using C++, but perhaps this isn't the place to ask. I have an idea as to how I'd do it.</p>
",linear_algebra
"<p>I have a differential equation $$N'_x(x)=G(x)N(x)$$ where $N, G$ are $2\times2$ matrices depending on $x$, and $G$ satisfies $\sigma G+G\sigma=0$, $\sigma$ is one half of the pauli matrix, i.e. $$\sigma=\begin{pmatrix}\frac{1}{2}&amp;0\\
0&amp;\frac{-1}{2}\end{pmatrix}$$ My question is:</p>

<blockquote>
  <p>Would $N^{\ast}\sigma N$ then be independent of $x$? Why or why not?</p>
</blockquote>
",linear_algebra
"<p>I would like to determine if the following map $T$ is a linear transformation:</p>

<p>\begin{align*}
T: P_{2} &amp;\to P_{2}\\
A_{0} + A_{1}x + A_{2}x^{2} &amp;\mapsto A_{0} + A_{1}(x+1) + A_{2}(x+1)^{2}
\end{align*}</p>

<p>My attempt at solving:</p>

<p>\begin{align}
T(p + q) &amp;= p(x+1) + q(x+1)\\
&amp;= \left[A_{0} + A_{1}(x+1) + A_{2}(x+1)^2\right] + \left[b_{0} + b_{1}(x+1) + b_{2}(x+1)^2\right]\\
&amp;= \left(A_{0} + b_{0}\right) + \left(A_{1} + b_{1}\right)(x+1) + \left(A_{2} + b_{2}\right)(x+1)^2\\
&amp;= T(p) + T(q)
\end{align}</p>

<p>Is this right so far? If not, what am I doing wrong?</p>
",linear_algebra
"<p>The question: </p>

<blockquote>
  <p>Show that if $A$, $B$, and $A+B$ are invertible matrices with the
  same size, then: $$A(A^{-1}+B^{-1})B(A+B)^{-1} = I$$</p>
</blockquote>

<p>I began by multiplying the first $A$:</p>

<p>$I+AB^{-1}B(A+B)^{-1}=I$</p>

<p>and then</p>

<p>$I + A(A+B)^{-1} = I$</p>

<p>At this point I'm not sure what to do. Should I just assume $A(A+B)^{-1} = 0$, or does that not work to prove this?</p>
",linear_algebra
"<p>Say I have the following <em>second</em> order 7 x 7 system of equations:</p>

<ul>
<li>$x_1'' = 10(x_2- x_1- 1)$ </li>
<li>$x_2'' = 10(x_3- 2x_2+ x_1)$</li>
<li>$x_3'' = 10(x_4- 2x_3+ x_2)$</li>
<li>$x_4'' = 10(x_5- 2x_4+ x_3)$</li>
<li>$x_5'' = 10(x_6- 2x_5+ x_4)$</li>
<li>$x_6'' = 10(x_7- 2x_6+ x_5)$</li>
<li>$x_7'' = 10(x_6- x_7)$.</li>
</ul>

<p>How would I convert this second order 7 x 7 system into a <em>first</em> order 14 x 14 system using the additional equations $v_j = x'_j$, where $j = 1, 2, 3, ..., 7$?</p>
",linear_algebra
"<p><strong>Problem:</strong> Solve the following system in function of the parameter $b$:</p>

<p>\begin{align*} \begin{cases} -bx + 2y - (2+b^2)z + bu &amp;= -2 \\ x -2y + bz -u &amp;= 0 \\ x + (2b-4)y + (2-b)z + (b-1)u &amp;= 2 \\ x -2by -(3b+2)z + (4b-5)u &amp;= 2b-4 \end{cases} \end{align*}</p>

<p><strong>Attempt at solution:</strong> We write down the augmented matrix of this system, and then apply the operations: $R_1 \leftrightarrow R_2, R_2 \rightarrow R_2 + b R_1$. This gives us the matrix: \begin{align*} \left(\begin{array}{cccc|c} 1 &amp; -2 &amp; b &amp; -1 &amp; 0 \\ 0 &amp; (2-2b) &amp; (2+b^2) &amp; 0 &amp; -2b \\ 1 &amp; (2b-4) &amp; (2-b) &amp; (b-1) &amp; 2 \\ 1 &amp; -2b &amp; -(3b+2) &amp; (4b+5) &amp; (2b-4) \end{array}\right) \end{align*} After that, we do $R_3 \rightarrow R_3 - R_1$ and $R_4 \rightarrow R_4 - R_1$: \begin{align*}\left(\begin{array}{cccc|c} 1 &amp; -2 &amp; b &amp; -1 &amp; 0 \\ 0 &amp; (2-2b) &amp; (2+2b^2) &amp; 0 &amp; -2b \\ 0 &amp; (2b-2) &amp; (2-2b) &amp; b &amp; 2 \\ 0 &amp; (-2b+2) &amp; (-4b-2) &amp; (4b-4) &amp; (2b-4) \end{array}\right) \end{align*} Now I want a leading $1$ at the position $a_{22}$. </p>

<p><strong>Case 1.</strong> Let $b = 1$. Then our matrix reduces to \begin{align*} \left(\begin{array}{cccc|c} 1 &amp; -2 &amp; 1 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; 4 &amp; 0 &amp; -2 \\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2 \\ 0 &amp; 0 &amp; -6 &amp; 1 &amp; -2 \end{array}\right) \end{align*} From the second row we see than that $u =2$. Substituting this in the last equation gives $z = - \frac{2}{3}$. But from the second row $z = - \frac{1}{2}$, which is a contradiction. Does this mean I can conclude the system has no solutions in this case?</p>

<p>Then if $b \neq 1$, should I just proceed with Gauss-elimination untill I hit another case distinction?</p>
",linear_algebra
"<p>I was reviewing my homework and it seems I overlooked something crucial while proving some ring has no Invariant Basis Number property. This is exercise VI.1.12 in Aluffi's <em>Algebra: Chapter 0</em></p>

<p>The setup: $V$ is a $k$-vector space and let $R = \mathrm{End}_{k}(V)$.</p>

<ol>
<li>Prove that $\mathrm{End}_{k}(V\oplus V) \cong R^4$ as an $R$-module</li>
<li>Prove that $R$ doesn't satisfy the IBN property if $V = k^{\oplus \mathbb N}$.</li>
</ol>

<p>For the first, I used to the fact that $V \oplus V$ is both the product and coproduct (in $k$-Vect) of $V$ with itself to get the isomorphism. What I just realized is I only showed that the two are isomorphic as groups not $R$-modules. So what would be the $R$-module structure on $\mathrm{End}_{k}(V \oplus V)$? </p>

<p>For the second, I used the fact that $V = k^{\oplus \mathbb N}$ implies $V \cong V \oplus V$ which in turn implies $R = \mathrm{End}_{k}(V) \cong \mathrm{End}_{k}(V \oplus V)$. Again, I just realized that I only showed the latter two are isomorphic as groups. </p>

<p>It may be obvious (and maybe why my professor let it pass?) but I can't come up with a good $R$-module structure that makes the two group isomorphisms $R$-linear.</p>

<p><strong>Edit:</strong></p>

<p>Explicitly, these are the isomorphisms I'm dealing with. Let $\pi_j, i_j$ be the natural projection/inclusion maps of the $j$-th factor resp. and $\psi: k^{\oplus \mathbb N} \oplus k^{\oplus \mathbb N} \to k^{\oplus \mathbb N}$ the isomorphism given by $\psi(e_i, 0)=e_{2i-1}$ and $\psi(0, e_i)=e_{2i}$.</p>

<p>Then the first isomorphism $\mathrm{End}_k(V \oplus V)\to R^4$ is given by $\varphi \mapsto (\pi_1\varphi i_1,\pi_2\varphi i_1,\pi_1\varphi i_2,\pi_2\varphi i_2)$</p>

<p>The second isomorphism $R \to \mathrm{End}_k(V \oplus V)$ is given by $\alpha \mapsto \psi^{-1} \alpha \psi$</p>

<p>The composition doesn't seem to be $R$-linear if I use the obvious $R$-module structure on $R$ and $R^4$.</p>
",linear_algebra
"<p>No matter what I do I can't seem to get this in the proper form.  Here is the system:</p>

<p>$$
\left\{
\begin{aligned}
3x+3y+12z&amp;=6 \\
3x_1+x_2-2x_3&amp;=2 \\
2x_1+2x_2+x_3&amp;=10 \\
-x+2y+8z&amp;=4
\end{aligned}
\right.
$$</p>

<p>Here is my base matrix:</p>

<p>$$ \left[
      \begin{array}{cccc|c}
        3&amp;3&amp;12&amp;6\\
        1&amp;1&amp;4&amp;2 \\
        2&amp;5&amp;20&amp;10 \\
        -1&amp;2&amp;8&amp;4
      \end{array}
    \right]$$</p>

<p>$\left(\frac{1}{3}\right)R_1-&gt;R_1$</p>

<p>$$ \left[
      \begin{array}{cccc|c}
        1&amp;1&amp;4&amp;2\\
        1&amp;1&amp;4&amp;2 \\
        2&amp;5&amp;20&amp;10 \\
        -1&amp;2&amp;8&amp;4
      \end{array}
    \right]$$</p>

<p>$(-2)R_1+R_3-&gt;R_3$
$$ \left[
      \begin{array}{cccc|c}
        1&amp;1&amp;4&amp;2\\
        1&amp;1&amp;4&amp;2 \\
        0&amp;3&amp;12&amp;6 \\
        -1&amp;2&amp;8&amp;4
      \end{array}
    \right]$$</p>

<p>$R_2&lt;-&gt;R_4$
$$ \left[
      \begin{array}{cccc|c}
        1&amp;1&amp;4&amp;2\\
        -1&amp;2&amp;8&amp;4 \\
        0&amp;3&amp;12&amp;6 \\
        1&amp;1&amp;4&amp;2
      \end{array}
    \right]$$</p>

<p>$R_2&lt;-&gt;R_3$
$$ \left[
      \begin{array}{cccc|c}
        1&amp;1&amp;4&amp;2\\
        0&amp;3&amp;12&amp;6 \\
        -1&amp;2&amp;8&amp;4 \\
        1&amp;1&amp;4&amp;2
      \end{array}
    \right]$$</p>

<p>$R_3+R_4-&gt;R_4$
$$ \left[
      \begin{array}{cccc|c}
        1&amp;1&amp;4&amp;2\\
        0&amp;3&amp;12&amp;6 \\
        -1&amp;2&amp;8&amp;4 \\
        0&amp;1&amp;4&amp;2
      \end{array}
    \right]$$</p>

<p>$R_2&lt;-&gt;R_3$, $R_1+R_2-&gt;R_2$
$$ \left[
      \begin{array}{cccc|c}
        1&amp;1&amp;4&amp;2\\
        0&amp;-1&amp;-4&amp;-2 \\
        0&amp;3&amp;12&amp;7 \\
        0&amp;1&amp;4&amp;2
      \end{array}
    \right]$$</p>

<p>$\left(\frac{1}{3}\right)R_3-&gt;R_3$
$$ \left[
      \begin{array}{cccc|c}
        1&amp;1&amp;4&amp;2\\
        0&amp;-1&amp;-4&amp;-2 \\
        0&amp;1&amp;4&amp;2 \\
        0&amp;1&amp;4&amp;2
      \end{array}
    \right]$$</p>

<p>$R_1&lt;-&gt;R_2$
$$ \left[
      \begin{array}{cccc|c}
        0&amp;-1&amp;-4&amp;-2\\
        1&amp;1&amp;4&amp;2 \\
        0&amp;1&amp;4&amp;2 \\
        0&amp;1&amp;4&amp;2
      \end{array}
    \right]$$</p>

<p>$R_1+R_2-&gt;R_2$
$$ \left[
      \begin{array}{cccc|c}
        0&amp;-1&amp;-4&amp;-2\\
        1&amp;0&amp;0&amp;0 \\
        0&amp;1&amp;4&amp;2 \\
        0&amp;1&amp;4&amp;2
      \end{array}
    \right]$$</p>

<p>$R_1&lt;-&gt;R_2$
$$ \left[
      \begin{array}{cccc|c}
        1&amp;0&amp;0&amp;0 \\
        0&amp;-1&amp;-4&amp;-2 \\
        0&amp;1&amp;4&amp;2 \\
        0&amp;1&amp;4&amp;2
      \end{array}
    \right]$$</p>

<p>$R_2&lt;-&gt;R_3$
$$ \left[
      \begin{array}{cccc|c}
        1&amp;0&amp;0&amp;0\\
        0&amp;1&amp;4&amp;2 \\
        0&amp;-1&amp;-4&amp;-2 \\
        0&amp;1&amp;4&amp;2
      \end{array}
    \right]$$</p>

<p>$R_2+R_3-&gt;R_3$
$$ \left[
      \begin{array}{cccc|c}
        1&amp;0&amp;0&amp;0\\
        0&amp;1&amp;4&amp;2 \\
        0&amp;0&amp;0&amp;0 \\
        0&amp;1&amp;4&amp;2
      \end{array}
    \right]$$</p>

<p>I stopped here because I felt like I was going to be going into a circle and I felt like I've done way too many steps.  Please help!</p>

<p>Sorry for any mistakes, it took me awhile to type this up.</p>
",linear_algebra
"<p>Apparently, my previous question didn't get no satisfactory answer, when I asked for two equations having a fixed value for each, <em>not necessarily linear</em>. As XenoGraff states, WolframAlpha does the task, but counts permutations of values among variables, and is thus impractical to test any two equations.</p>

<p>Actually, I ask, is it possible that there could be a system of X equations that can be solved for more than X variables, all having whole number values, considering that these X equations have an unique solution?</p>

<p>As Gerry Myerson states in the previous thread, there is the unproven conjecture that $x^{5}+y^{5}=N$ will have only one solution for $x,y$ for a given $N$, which can be modified to satisfy $x^{5}+y^{5}=x+y$ for only one set of values for $x,y$.</p>

<p>So... are there any such equations? What about differential equations (I don't understand them, anyway) and multivariates? And Diophantine equations?</p>
",linear_algebra
"<p>I've sort of gotten a grasp on the Chain rule with one variable.  If you hike up a mountain at 2 feet an hour, and the temperature decreases at 2 degrees per feet, the temperature would be decreasing for you at $2\times 2 = 4$ degrees per hour.</p>

<p>But I'm having a bit more trouble understanding the Chain Rule as applied to multiple variables.  Even the case of 2 dimensions </p>

<p>$$z = f(x,y),$$ </p>

<p>where $x = g(t)$ and $y = h(t)$, so</p>

<p>$$\frac{dz}{dt} = \frac{\partial z}{dx} \frac{dx}{dt} + \frac{\partial z}{dy} \frac{dy}{dt}.$$</p>

<p>Now, this is easy enough to <em>""calculate""</em> (and figure out what goes where).  My teacher taught me a neat tree-based graphical method for figuring out partial derivatives using chain rule.  All-in-all, it was rather hand-wavey.  However, I'm not sure exactly how this works, intuitively.</p>

<p>Why, intuitively, is the equation above true?  Why <strong>addition</strong>?  Why not multiplication, like the other chain rule?  Why are some multiplied and some added?</p>
",linear_algebra
"<p>I just came back from an intense linear algebra lecture which showed that linear transformations could be represented by transformation matrices; with more generalization, it was later shown that affine transformations (linear + translation) could be represented by matrix multiplication as well.</p>

<p>This got me to thinking about all those other transformations I've picked up over the past years I've been studying mathematics.  For example, polar transformations -- transforming <code>x</code> and <code>y</code> to two new variables <code>r</code> and <code>theta</code>.</p>

<p>If you mapped <code>r</code> to the <code>x</code> axis and <code>theta</code> to the <code>y</code> axis, you'd basically have a coordinate transformation.  A rather warped one, at that.</p>

<p>Is there a way to represent this using a transformation matrix?  I've tried fiddling around with the numbers but everything I've tried to work with has fallen apart quite embarrassingly.</p>

<p>More importantly, is there a way to, given a specific non-linear transformation, construct a transformation matrix from it?</p>
",linear_algebra
"<p>If you have the following matrix can $k$ be any number?</p>

<p>\begin{pmatrix}
  1 &amp; 0 &amp; 0 \\
  0 &amp; k &amp; 0 \\
  0 &amp; 0 &amp; 1
 \end{pmatrix}</p>

<p>So this is obviously an assignment question, but I couldn't find a concrete answer anywhere.</p>

<p>I would just liketo double check my reasoning with other people (long distance learning, so no other students to chat too)</p>

<p>I say no, because $k$ cannot be zero. To my understanding, an elementary matrix can only be created using a single row operation on an Identity matrix. I can't think of any operation that would create a row of zeros from an Identity matrix.</p>

<p>Is my assumption correct: $k$ can be any number except for zero.</p>
",linear_algebra
"<blockquote>
  <p>Define D:$\wp_{2}$($\mathbb{R}$) $\mapsto$$\wp_{2}$($\mathbb{R}$)
  by $D(p)(x) = p'(x)$ , Find the matrix of $D$ with respect to the basis
  $\{1, 1+x, 1+x+x^2 \}$ </p>
</blockquote>

<p>I was thinking this would be the matrix $\left(\begin{array}[t]{ccc}
0 &amp; 1 &amp; 2\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0
\end{array}\right)$ by differentiating each of the terms in the basis, 
but i have a feeling this is wrong? </p>
",linear_algebra
"<p>I am trying to teach my self some linear algebra in preparation for a module in machine learning. I am using Gilbert Strang's text Introduction to Linear Algebra and am having some difficulties.</p>

<p>My specific question is: How is the last equation below an example of integration by parts? It seems to be missing $x(t)y(t)$ to me and I don't know where that has gone.</p>

<p>The book gives the following equations leading up to it:</p>

<p>$$x^Ty = (x,y) = \int_{-\infty}^\infty x(t)y(t)~dt$$ </p>

<p>From what I can tell, the above is saying that the inner product of the vectors $x$ and $y$ is equivalent or at least approximate to taking the integral of those two vectors as functions. Does the $(x,y)$ just mean inner product? I don't really understand what a vector of a function even is though.</p>

<p>$$(Ax)^Ty = x^T(A^Ty)$$</p>

<p>This associative rule for matrix-vector multiplication was given as a more rigorous view of what the transpose of $A$ actually is. It then partnered it with this:</p>

<p>$$\int_{-\infty}^\infty\frac{dx}{dt}y(t)~dt = \int_{-\infty}^\infty x(t)\left(-\frac{dy}{dt}\right)~dt$$</p>

<p>I can see how the two equations relate to eachother and that this suggests that $A^T$ is anti-symmetric. Gil mentions integration by parts here which I can definitely recognise but it doesn't seem complete, there should be an extra $x(t)y(t)$ surely?</p>
",linear_algebra
"<p>Suppose T: $\mathbb{R}^{2}$$\rightarrow\mathbb{R}$$^{2}$ is linear
and has matrix $\begin{pmatrix}4&amp;9\\1&amp;1\end{pmatrix}$ with </p>

<p>respect to the standard basis of $\mathbb{R}$$^{2}$. What is the
matrix of T with respect to the basis </p>

<p>$\beta$= {(1,-1), (-3,2)} ?.</p>

<p>How do we approach these sort of problems, commutative diagram? And if so how would it look?</p>
",linear_algebra
"<p>Let $$\mathcal{B}=\left \{\frac{1}{\sqrt{2\pi}},\frac{\cos x}{\sqrt{\pi}},\frac{\sin x}{\sqrt{\pi}},\frac{\cos 2x}{\sqrt{\pi}},\frac{\sin 2x}{\sqrt{\pi}},\dots\right \}$$.
This is an orthonormal basis of $L^2(a,a+2\pi)$ since its elements are orthonormal and $\overline{\operatorname{span}_{\mathbb{R}}B}=L^2(a,a+2\pi)$. 
Is it true that these vectors are also linearly independent?</p>
",linear_algebra
"<p>Hy i have a small problem. I need to prove that a transformation $$\mathbb{R}_{3}[ x ] \rightarrow \Bbb{R}^{3}$$ $$\phi (p):= [p(-1), p(0), p(1)]^T$$  is linear. 
The $$\mathbb{R}_{3}[ x ]$$ vector space is a degree of max 3.
Then i need to find the basis of the transformation kernel and basis of the image.</p>

<p>How would i do that ?</p>

<p>Thanks</p>
",linear_algebra
"<p>I have a problem understanding getting the KERNEL and IMAGE of a linear transformation. We have the following transformation given: 
$$ \mathbb{R}_{2}[ x ] \rightarrow \mathbb{R}_{2}[ x ] $$
$$ (\phi (p))(x) = (x p(x+1))' - 2p(x) $$</p>

<p>We first have to find its matrix in basis $$ \{ 1, x, x^2 \} $$
which I know how to get. The transformation matrix result is:</p>

<p>$$ 
\begin{bmatrix}
 -1&amp; 1&amp; 1\\ 
 0&amp;  0&amp; 4\\ 
 0&amp;  0&amp; 1
\end{bmatrix}
 $$</p>

<p>How do I get the KERNEL and the IMAGE from it ?</p>

<p>Would really appretiate an explanation, not just the result.</p>

<p>THANKS !</p>
",linear_algebra
"<p>In $\mathbb{R}$3 we declare  an inner product as follows: $\langle v,u \rangle \:=\:v^t\begin{pmatrix}1 &amp; 0 &amp; 0 \\0 &amp; 2 &amp; 0 \\0 &amp; 0 &amp; 3\end{pmatrix}u$  </p>

<p>we have operator $f \colon V \to V$ , $f\begin{pmatrix}x \\y \\z\end{pmatrix}\:=\begin{pmatrix}1 &amp; 2 &amp; 3 \\4 &amp; 5 &amp; 6 \\7 &amp; 8 &amp; 9\end{pmatrix}\begin{pmatrix}x \\y \\z\end{pmatrix}$</p>

<p>The question is : calculate $f^*$.  </p>

<p>So far, as i know, i need to find orthonormal basis $B$, and find $\left[f\right]_B^B$, and after that just do transpose to $\left[f\right]_B^B$.<br>
 is That correct?  it's a question from  test that i had and i didn't know how to answer it so i forwarding this to you. tnx!</p>
",linear_algebra
"<p>In $\mathbb{R}^3$ we declare an inner product as follows: $\langle v,u \rangle \:=\:v^t\begin{pmatrix}1 &amp; 0 &amp; 0 \\0 &amp; 2 &amp; 0 \\0 &amp; 0 &amp; 3\end{pmatrix}u$  </p>

<p>How can I find an orthonormal basis for this inner product space using the Gram–Schmidt process?</p>
",linear_algebra
"<blockquote>
  <p>Let matrix $A$ be
  $$\begin{bmatrix}
 -5&amp; 1&amp; 0&amp; 0\\
  a &amp;2&amp; 1 &amp;0\\
  0&amp; 1 &amp;1 &amp;1\\
  0 &amp;0&amp;1&amp; 0
\end{bmatrix}$$ 
  where $a$ is a constant between 1 and 3.</p>
  
  <p>Show that the dominant eigenvalue is real.</p>
</blockquote>

<p>Thanks a lot!!</p>
",linear_algebra
"<p>I have a system of linear equations as follows.</p>

<blockquote>
  <p>$$M(p) = 1+\frac{n-p-1}{n}M(n-1) + \frac{2}{n} N(p-1) + \frac{p-1}{n}M(p-1)$$
   $$N(p) = 1+\frac{n-p-1}{n}M(n-1) + \frac{p}{n}N(p-1)$$
   $$M(1) = 1+\frac{n-2}{n}M(n-1) + \frac{2}{n}N(0)$$
   $$N(0) = 1+\frac{n-1}{n}M(n-1)$$</p>
</blockquote>

<p>$M(p)$ is defined for $1 \leq p \leq n-1$.  $N(p)$ is defined for $0 \leq p \leq n-2$.  What is $M(n-1)$?</p>
",linear_algebra
"<blockquote>
  <p>Let $P \in \mathbb{R}_{n-1}[X]$ be a polynomial of degree $n-1 \geqslant 0$.</p>
  
  <ol>
  <li><p>Let $\mathbb{R}_{n-1}[X]$ be the vector space of polynomials with degree $\leqslant n-1$ over $\mathbb{R}$. Show that $(P(X),P(X+1),\ldots ,P(X+n-1))$ is a basis of $\mathbb{R}_{n-1}[X]$.</p></li>
  <li><p>Let $M_n = \begin{pmatrix} P(X) &amp; P(X+1) &amp; P(X+2) &amp; \ldots &amp; P(X+n) \\
				P(X+1) &amp; P(X+2) &amp; P(X+3) &amp; \ldots &amp; P(X+n+1) \\
				\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
				P(X+n) &amp; P(X+n+1) &amp; P(X+n+2) &amp; \ldots &amp; P(X+2n) \end{pmatrix}$.</p></li>
  </ol>
  
  <p>Show that $\det{M_n} = 0$ for every $X \in \mathbb{R}$.</p>
</blockquote>

<p>My thoughts on (1): $\mathbb{R}_{n-1}[X]$ is $n$-dimensional, because $(1,X, \ldots ,X^{n-1})$ is a basis of $\mathbb{R}_{n-1}[X]$. So it suffices to show that $(P(X),P(X+1),\ldots ,P(X+n-1))$  is a generating set/linearly independent. I tried proving it with induction and using the binomial theorem, but I am not getting anywhere.</p>

<p>My thoughts on (2): $\det{M_n} = 0$ implies that the columns are linearly dependent. (1) is probably useful here, but I don't even know how to start.</p>

<p>Any help is appreciated, thanks.</p>
",linear_algebra
"<p>There is a notation used in many sources (e.g. Wikipedia: <a href=""http://en.wikipedia.org/wiki/Exponential_family"" rel=""nofollow"">http://en.wikipedia.org/wiki/Exponential_family</a>) for the natural parameters of exponential family distributions which I do not understand, and I cannot find a description of.</p>

<p>With vector parameters and variables, the exponential family form has the dot product between the vector natural parameter, ${\boldsymbol\eta}({\boldsymbol\theta})$ and the vector sufficient statistic, ${\mathbf{T}}({\mathbf{x}})$, in the exponent. i.e. $e^{{\boldsymbol\eta}({\boldsymbol\theta})^{\top}{\mathbf{T}}({\mathbf{x}})}$. </p>

<p>However, many examples of these parameters for different distributions are vectors composed of matrices &amp; vectors. E.g. the multivariate Normal distribution has parameter $[\Sigma^{-1}\mu\space\space-\frac{1}{2}\Sigma^{-1}]$ and sufficient statistic $[\mathbf{x}\space\space\mathbf{xx^{\top}}]$.</p>

<p>So what are these ""vectors"" and moreover, how is the dot product between them defined? Does this notation have a name?</p>
",linear_algebra
"<p>How to prove the following?</p>

<p><strong>Lemma.</strong> Let $C=[A,A^{\star}]$. $A$ is normal iff $[A,C]=0$.</p>

<p>One direction is trivial. The other direction reduces to showing that $A^2 A^\star+A^\star A^2=0$ implies that $A$ is normal, but I don't see why that holds.</p>
",linear_algebra
"<p>I must construct this triangle:</p>

<p>Consider the triangle $ABC$. Take $D$ in the line of $BC$ such that $C$ is the mid point of $BD$ and take $Y$ in the line $AC$ such that the lines $AB$ and $BY$ are parallel. </p>

<p>I constructed the point $D$, but I don't see how I can construct the point $Y$ without this point being $A$. Does another possibility exists? I don't see how.</p>
",linear_algebra
"<p>I'm interested in the algorithm of LU decomposition in order to solve a LSE like $Ax=b$, where $A$ is a square matrix.</p>

<p>My question is: When I compute $PA=LU$ do I also need to interchange rows in $L$ whenever I interchange rows in $A$? It is clear, that I get $P$ by interchanging rows in $Id$ whenever I interchange rows in $A$, but is $L$ also affected?</p>

<p>Is it right that after that I need to solve $Lz = Pb$ and $Ux = z$?</p>
",linear_algebra
"<p><strong>I do not want the answer given to me, I just want assistance.</strong></p>

<p>Problem: <em>Marcus invests $750 in an account that pays 9.8% interest compounded annually. Write a function that describes the account balance, A, in terms of the number of years, t, that have passed.</em></p>

<p>I know that to find the account balance after one year: </p>

<p>A + (A * 0.098)
A + 0.098A (simplified)</p>

<p>But I don't know how to implement the time variable.</p>

<p>initial balance is $750
after one year 750 + (750*0.098) = 1348.5</p>

<p>after 2 years:
1348.5 + (1348.5*0.098) = 1480.653</p>
",linear_algebra
"<p>How to find inverse of an infinite lower triangular matrix all of whose diagonal entries are 1 and the entries of each column are given by coefficients of some power series rings?</p>
",linear_algebra
"<ol>
<li>How can one intuitively understand the definition of a bilinear map? Is there some way of looking at it geometrically? I found the following definition:</li>
</ol>

<p>Let $\mathit{A}$,$\mathit{B}$,$\mathit{C}$ be vector spaces. A map $f:\mathit{A}\times \mathit{B}\to C$ is said to be bilinear if for each fixed element $b\in \mathit{B}$, $f(.,b):\mathit{A}\to\mathit{C}$ is a linear map. Similarly, for each fixed element of $\mathit{A}$.</p>

<p>Matrix multiplication is an example of a bilinear map.Following my definition, I can prove that it is a bilinear map, but I don't understand the intuitive idea behind it. In my opinion, it is simply a linear map with one element fixed.</p>

<ol start=""2"">
<li>Is there some formal definition of a bilinear algorithm? I could find an explanation for it only in the context of matrix multiplication: <a href=""http://www.issac-symposium.org/2014/tutorials/ISSAC2014_tutorial_handout_LeGall.pdf"" rel=""nofollow"">http://www.issac-symposium.org/2014/tutorials/ISSAC2014_tutorial_handout_LeGall.pdf</a></li>
</ol>

<p>Kindly help me with these questions.
Thanks!</p>
",linear_algebra
"<p>Given that $A$ is a symmetric matrix, find $X$ that solves
$$\mathop {\min }\limits_X {\left\| {A - X{X^T}} \right\|_F}$$</p>

<p>I think that the problem can be solved using eigenvalue or singular value decomposition technics. $XX^T=A$ seems an obvious solution, but the problem is that $XX^T$ is positive semidefinite, while $A$ may not be, although they are both symmetric.</p>

<p>At this point I am thinking about taking eigenvalue decomposition of A, then replacing the negative eigenvalues in the middle diagonal matrix with 0-s (denote the resulting matrix by $\bar{A}$). But am having difficulties to understand why  $XX^T=\bar{A}$ gives the $X$ with minimal distance from A.</p>
",linear_algebra
"<p>I hope to solve this problem.</p>

<p>$$\min \quad \left\| CX \right\|_{1} $$
$$ \text{s.t.}\quad AX=b, X &gt;0 $$</p>

<p>where $C \in \mathbb{R}^{m \times m}$, $X \in \mathbb{R}^{m \times n}$, $A \in \mathbb{R}^{k \times m}$, $b \in \mathbb{R}^{k \times n}$. $C$ is known weight, $X$ is unknown matrix. My problem is how to calculate the proximal operator of $ \left\| CX \right\|_{1}$, I know, if without $C$ the proximal operator will be apply Shrinkage elementwise. </p>

<p>This problem will be easy if $x$ is a vector, we just need to solve a LP, but my $X$ is a matrix.</p>

<p>$$ \min \quad c^Tx $$ 
 $$ \text{s.t.}\quad Ax=b , x&gt;0 $$</p>

<hr>

<p>the overall problem I hope to solve is:
$$ \min \left\| CX \right\|_{1} + \lambda \left\| Y \right\|_{*} $$
$$ \text{s.t.}\quad AX+Y=b , X&gt;0 $$
Y has the same dimension with $b \in \mathbb{R}^{k \times n}$. X is known to be sparse.</p>
",linear_algebra
"<p>This is a question from a review package that is causing me some trouble.</p>

<p>Let $U,W$ be subspaces of a finite dimensional vector space. Show if $\dim(U+W) = 1+\dim(U \cap W)$, then $\{U+W,U\cap W\}=\{U,W\}$.</p>

<p>I know that for $\{U+W,U\cap W\}=\{U,W\}$ to be true, one of two cases must happen. Either $U\subseteq W$ or $W\subseteq U$, since $U \cap W$ must equal $U$ or $W$. However we can assume without loss of generality that either one is true. </p>

<p>I'm not sure how to show the implication (maybe through contraposition?). Any hints and help is greatly appreciated. </p>
",linear_algebra
"<p>In one book on differential equations and dynamical systems I read that if <strong>(1)</strong> $(A-\lambda I)^{k_j} \vec{v_j} = \vec{0}$ then <strong>(2)</strong> $(A-\lambda I)\vec{v_j} = V_j$ and $V_j\in \ker(A-\lambda I)^{k_j-1}$. But I don't see how (2) follows from (1). Can someone please explain?</p>
",linear_algebra
"<blockquote>
  <p>I've been given an $(n+1)\times(n+1)$ square matrix, which is written in the form of a block matrix with the following dimensions
  $$ \begin{bmatrix}
    (1\times1)       &amp; (n\times1)\\
    (n\times1)       &amp; (n\times n) 
\end{bmatrix} .$$
  I need to compute the determinant. </p>
</blockquote>

<p>I've tried to understand what is shown <a href=""https://en.wikipedia.org/wiki/Determinant#Block_matrices"" rel=""nofollow"">here</a> on how to solve this but I'm still confused. Can someone offer any insight as to how I would go about solving this? Also, is there any decomposition, factorization, etc I can take advantage of with the off diagonals being $(n\times 1)$ and $(1\times n)$? I feel like there's some simplification I can utilize. Thoughts?</p>
",linear_algebra
"<p>Let's say that we have linear subspaces $V$ and $W$ of $Y$.</p>

<p>What is the difference between the following sets:</p>

<ol>
<li>$V+W$ </li>
<li>$V\cup W$ </li>
<li>$V\oplus W$</li>
</ol>
",linear_algebra
"<p>Let $u = \left( \begin{matrix} 2 \\-5   \\1\end{matrix} \right)$</p>

<p><strong>Find an operator $T \in L(U) $ such that $T(u)=u $ and $T$ is self-adjoint.</strong> </p>

<p>I have to show that $T=T^*$ to have a self-adjoint operator T but I know how to start off.</p>

<p>I all I can think is $ T(u) = \left( \begin{matrix} 2 \\-5   \\1\end{matrix} \right)$</p>

<p>Any sort of help is appreciated! </p>

<p>Thanks!</p>
",linear_algebra
"<p>Given a % of change and the resulting value after the change, how do you calculate the original value?</p>

<p>For example, X increased by 50% = 150. In this case we can easily use guess and check to see that X = 100, but how do you calculate this given any percentage of change and any resulting value?</p>

<p>I though this formula should work, but it does not. As you can see my algebra is quite rusty, so maybe you can help.</p>

<pre><code>start = x
percentage of change = p
resulting value = r

x * (p / 100) + x = r
</code></pre>

<p>Which can be simplified to</p>

<pre><code>2(p / 100)x = r
</code></pre>

<p>which is equivalent to</p>

<pre><code>x = r / 2(p / 100)
</code></pre>

<p>But when I check my work, this is wrong:</p>

<pre><code>100 = 150 / 2(50 / 100)
100 = 150 / 2(.5)
100 = 150 / 1
100 = 150
</code></pre>
",linear_algebra
"<p>Suppose that A is an $n\times m$ matrix with $ n\neq m$.</p>

<p>Here's my reasoning.</p>

<p>Every nonpivot column corresponds to a free variable in the system Ax = 0. Each free
variable becomes a parameter, and each parameter is multiplied times a basis vector
of null(A). Therefore the number of nonpivot
columns equals nullity(A). Since rank(A) + nullity(A) = m, the nullity(A) must be greater than zero.</p>

<p>I'm not sure if I'm justified in stating the last sentence. Any suggestions or can you provide a different proof?</p>
",linear_algebra
"<p>Let Ax=b be a nonhomogenous system of linear equations with the unknown x ∈ |R^n. Assume that X1 ∈ |R^n and X2 ∈ |R^n are both solutions of the nonhomogenous system. Which ONE of the following statements must be true?</p>

<pre><code>a) x1 + x2 is a solution of Ax = 0
b) x1 - x2 is a solution of Ax = 0
c) x1 + x2 is a solution of Ax = b
d) x1 - x2 is a solution of Ax = b
</code></pre>

<p>I'm not really sure how to approach this question. My current approach is to make up a system of equations such that Ax = b is nonhomogenous.</p>

<p>So I have:</p>

<pre><code>5x - 2y = 1
8x - 3y = 2
</code></pre>

<p>The solutions of (x,y) are (1,2) for both equations.</p>

<pre><code>5(1) - 2(2) = 1
8(1) - 3(2) = 1
</code></pre>

<p>Not sure what to do next, if I plug in ( x , y ) for ( x1 , x2 ) in the answer choices, none of them seem to be consistent.</p>
",linear_algebra
"<p>Let $A$ be a non-negative irreducible $n\times n$ matrix. Then the function
$$f(t)=\rho(tA+(1-t)A^T)$$
is increasing on $[0,1/2]$, and is decreasing on $[1/2,1]$.</p>

<p>Here are the notations.</p>

<ol>
<li><p>$A$ is non-negative if any entry of $A$ is greater than or equal to $0$.</p></li>
<li><p>$A$ is irreducible if $A$ is not reducible; and $A$ is reducible if there exists a permutation matrix $P$ such that $$P^T AP=\begin{pmatrix}
B&amp;0\\
C&amp;D\end{pmatrix},$$ or equivalently, there exists a permutation $\sigma$ of $\{1,2,\cdots,n\}$ and a $1\leq k\leq n-1$ such that the sub-matrix of $A$ in rows $\sigma(1),\cdots,\sigma(k)$ and columns $\sigma(k+1),\cdots,\sigma(n)$ being $0$.</p></li>
<li><p>$A^T$ is the transpose of $A$.</p></li>
<li><p>$\rho(A)$ is the spectral radius of $A$, that is, the largest modulus of the eigenvalues of $A$.</p></li>
</ol>

<p>And now I have no idea on it. However, it is intuitively right. As there are more symmetry in the matrix, the spectral radius becomes larger.</p>
",linear_algebra
"<p>Let $A$ be a non-negative primitive matrix. Then $$\lim_{n\to\infty}\left[\frac{A}{\rho(A)}\right]^n=xy^T,$$
where $x, y$ are the Perron roots of $A$ and $A^T$ respectively, they satisfy $x^Ty=1$.</p>

<p>Here are the notations.</p>

<ol>
<li><p>$A$ is non-negative if any entry of $A$ is greater than or equal to $0$.</p></li>
<li><p>$A$ is primitive if $A$ is non-negative irreducible, and the number of eigenvalues of $A$ with modulus equal to $\rho(A)$ (the spectral radius of $A$) is $1$.</p></li>
<li><p>$A$ is irreducible if $A$ is not reducible; and $A$ is reducible if there exists a permutation matrix $P$ such that $$P^T AP=\begin{pmatrix}
B&amp;0\\
C&amp;D\end{pmatrix},$$ or equivalently, there exists a permutation $\sigma$ of $\{1,2,\cdots,n\}$ and a $1\leq k\leq n-1$ such that the sub-matrix of $A$ in rows $\sigma(1),\cdots,\sigma(k)$ and columns $\sigma(k+1),\cdots,\sigma(n)$ being $0$.</p></li>
<li><p>The Perron root $x$ of $A$ is an eigenvector $x$ corresponding to the eigenvalue $\rho(A)$, the entries of $x$ are positive.</p></li>
<li><p>$A^T$ is the transpose of $A$.</p></li>
</ol>

<p>It is easy to show that the limit exists. In fact, we could just use Jordan carnonical form to find there exists a invertible matrix $T$ such that 
$$T^{-1}AT=\begin{pmatrix}
\rho(A)&amp;0\\
0&amp;*\end{pmatrix},$$
and thus
$$
\lim_{n\to\infty}T^{-1}\left[\frac{A}{\rho(A)}\right]^nT
=\begin{pmatrix}
1&amp;0\\
0&amp;0\end{pmatrix}.$$
However, I could not prove that the limit if $xy^T$.</p>
",linear_algebra
"<p>I have some data points that define a curve and what i need to find is the slope of the lines definedby
line 1 = p1&amp;p2
line 2 = p1&amp;p3
line 3 = p1&amp;p4
.
.
.
line29= p1&amp;p30
line30= p2&amp;p3
line31= p2&amp;p4</p>

<p>linexxx = p29&amp;p30 being the last </p>

<p>and I as I go i need to determine if the lines above  <em>ONLY</em> have 2 points in common with the curve?
image below the blue line is valid the green isnt how can I tell this? </p>

<p><img src=""http://i.stack.imgur.com/Vw0k8.png"" alt=""enter image description here""></p>

<p>point 1     0.128250002 6.235036978 <br>
point 2     0.197718753 6.239911671 <br>
point 3     0.281734379 6.22376425  <br>
point 4     0.336656255 6.233513636 <br>
point 5     0.347343755 6.20761683  <br>
point 6     0.472625007 6.238083661 <br>
point 7     0.491625008 6.205484151 <br>
point 8     0.553968759 6.244786364 <br>
point 9     0.601765634 6.200609458 <br>
point 10    0.740703137 6.243263022 <br>
point 11    0.797703137 6.225287592 <br>
point 12    0.927140639 6.245091032 <br>
point 13    1.078546892 6.239911671 <br>
point 14    1.159890643 6.249661057 <br>
point 15    1.291703145 6.238997666 <br>
point 16    1.404812522 6.262457126 <br>
point 17    1.506937524 6.248747052 <br>
point 18    1.6057969   6.213405528 <br>
point 19    1.684765651 6.243263022 <br>
point 20    1.770859403 6.235341646 <br>
point 21    1.94037503  6.247833047 <br>
point 22    2.059125032 3.903410396 <br>
point 23    2.189453159 3.681916534 <br>
point 24    2.330468786 4.359194189 <br>
point 25    2.398453162 6.237169656 <br>
point 26    2.55728129  6.279213883 <br>
point 27    2.692656292 6.248747052 <br>
point 28    2.844359419 6.254840418 <br>
point 29    2.992203172 6.264589804 <br>
point 30    3.167062549 6.243263022 <br></p>
",linear_algebra
"<p>I've been researching for a while and trying to wrap my head around spanning of vector spaces completely (by visualizing them in R3) before moving on to Linear Independence, Basis' and anything else taught after subspaces. (had no calc 3 unfortunately =/)Based on what I'm reading, the span of a set of vectors is every possible linear combination of those vectors. After reading/looking at this figure:</p>

<p><img src=""http://i.stack.imgur.com/iMrLI.png"" alt=""enter image description here""></p>

<p>I think I understand it for two vectors in R3. It looks like any two arbitrary vectors (that arent scalar multiples of eachother) in R3 will span a never ending plane through the origin. </p>

<p>Does this mean that the span of any 3 arbitrary vectors in the vector space R3 will form a never ending 3d shape spanning all of R3? (as long as two of them arent scalar multiples of eachother (EDIT: or as long as they don't span R2?)</p>

<p>also, what if you have any random set of more than 3 vectors (that qualify as being in R3), is the span of that set also all of R3? (as long as the vectors dont end up being scalar multiples of eachother so that the set spans a line)(EDIT: or as long as they don't span R2?)</p>

<p>while I'm at it, does this mean that any 4 (or more?) vectors in R4 that arent multiples of any of the other 4 span all of R4? (EDIT:if not R2 or R3?)</p>

<p>if this is all true, I think I had a big epiphany and everything now makes sense to me..... such as being able to visualize linear dependent and linear independent.. I'm guessing that a set of vectors is L.D. if at least one vector can be written as a scalar multiple of another vector in the set. and LI means they are all unique, as in they have no scalar multiples of eachother, which also means that if the only solution to a set of 3 vectors in R3 is (0,0,0) or the homogeneous solution, or the trivial solution.... then that set spans R3? and the same applies to sets of vectors in R4, such as if there is 4 or 5 vectors satsifying R4 rules, and the only solution to their system of equations is homogeneous, they are LI, they span R4, and the 4x4 systems determinant is not equal to 0....</p>
",linear_algebra
"<p>I don't have a clue of what's going on. We haven't learn this in class so I need all the help possible. The more detailed of an explanation, the better. Thanks in advance. The only info I have is that this matrix is Orthogonal. Which means I know the answer, just don't know how to get it.</p>

<p>\begin{bmatrix}
       \cos\theta &amp; -\sin\theta \\
       \sin\theta &amp; \cos\theta 
     \end{bmatrix}</p>
",linear_algebra
"<p>Let $T:\mathbb{V} \rightarrow \mathbb{W}$ be an injective linear transformation and $S:\mathbb{W}\rightarrow \mathbb{V}$ be a surjective linear transformation with $\mathbb{V}$ and $\mathbb{W}$ finite-dimensional vector spaces.</p>

<p>How can I show that $S\circ T=id_{\mathbb{V}}$?</p>
",linear_algebra
"<p>I have this problem I'm working on, which I cannot entirely solve:</p>

<blockquote>
  <p>Let $V$ be a finite dimensional vectorspace over a field $K$ with a symmetric bilinear
  form $\langle \cdot, \cdot \rangle$. Define for every $v \in V$ the
  map $$ l_v : V \mapsto K: w \mapsto \langle v, w \rangle. $$ Consider
  now the map $$f: V \rightarrow V^{*}: v \mapsto l_v. $$ </p>
  
  <p>(i) Prove that $f$ is a linear map.</p>
  
  <p>(ii) Prove that $f$ is surjective if and only if $\langle \cdot, \cdot
 \rangle $ is non degenerate.</p>
</blockquote>

<p><strong>Attempt:</strong>
(i) Let $v, w \in V$ be vectors, and let $\lambda, \mu \in K$ be scalars. We need to prove that $$f(\lambda v + \mu w) = \lambda f(v) + \mu f(w). $$ This is equivalent to proving $$l_{\lambda v + \mu w} = \lambda l_v + \mu l_w. $$ Let $x \in V$ be another vector. Then the above equality is true since $$ l_{\lambda v + \mu w} (x) = \langle \lambda v + \mu w, x \rangle = \lambda \langle v, x \rangle + \mu \langle w, x \rangle = \lambda l_v(x) + \mu l_w(x). $$ This proves that $f$ is linear.</p>

<p>(ii) Suppose first that $f$ is surjective. To prove that $\langle \cdot, \cdot \rangle$ is non degenerate, we need to prove that $$ \forall w \in V: [ (\forall v \in V: \langle v, w \rangle = 0 ) \Rightarrow w = 0 ]. $$ So let $w \in V$ be arbitrary, and suppose that $\forall v \in V: \langle v, w \rangle = \langle w, v \rangle = 0$, since the bilinear form is symmetric. This means that $\forall v \in V : l_v(w) = l_w(v)= 0. $ </p>

<p>Now I'm not sure how to use the fact that $f$ is surjective to deduce from this that $w = 0$. I know that the linear functional $l_v \in V^{*}$. So since $f$ is surjective, I can take a $v \in V$ such that $f(v) = l_v$. But what can I conclude from this about $w$? </p>

<p>Help is appreciated.</p>
",linear_algebra
"<p>I'm trying to implement some determinant routines for some CUDA C++ code that I'm writing. The only issue is, my code is returning nan's and inf's! It turns out that it's my pivoting routine that's bad.</p>

<p>Right now, my overall approach has been ripped straight from rosetta code's C implementation (without those awful macros). But it seems like their pivoting routine isn't robust enough for my needs.</p>

<p>Right now, my pivoting routine will take a column, start at the row corresponding to the column index and then search for the column's largest element below the current row and only swap if a larger value is found.</p>

<p>This is far too naive in practice. Is there a more robust pivoting algorithm I can/should be using?</p>

<p>Here's a link to the source code test: <a href=""https://github.com/LeonineKing1199/cuda-stuff/blob/master/tests/matrix-tests.cu#L182"" rel=""nofollow"">https://github.com/LeonineKing1199/cuda-stuff/blob/master/tests/matrix-tests.cu#L182</a></p>

<p>If you look at that matrix, that's the properly permuted one. In my actual data,  the rows of the matrix can be in any order! I just needed a static test to make sure it would eventually work. So, what kind of pivoting algorithm would I need to help me produce that same matrix assuming the rows were permuted in any order?</p>

<p>Sorry if I haven't given enough information. My main matrix class is here: <a href=""https://github.com/LeonineKing1199/cuda-stuff/blob/master/include/math/matrix.hpp"" rel=""nofollow"">https://github.com/LeonineKing1199/cuda-stuff/blob/master/include/math/matrix.hpp</a></p>
",linear_algebra
"<blockquote>
  <p>Let $V$ be a vector space with dimension $n$ and let $T: V\rightarrow V$ satisfy $T^2=0$.</p>
  
  <p>(a) Prove Im$ T \subseteq$  Ker $T$ and $\dim($Ker$(T))\geq \frac{n}{2}$ (SOLVED BY ME)</p>
  
  <p>(b) Assume $n=3, T\neq 0$ Prove there exists a basis $B$ of $V$ such that $[T]_B=\begin{bmatrix}
0 &amp; 0 &amp; 1\\ 
 0&amp;0  &amp; 0\\ 
0 &amp;0 &amp; 0
\end{bmatrix}$</p>
</blockquote>

<p>My attempt at (b):</p>

<p>By (a) we know $\dim(\ker T)\geq \frac{3}{2}$, hence it's either 2 or 3. Assuming it's 3 we get $V=\ker T$ which contradicts $T\neq 0$. So $\dim(\ker T)=2$</p>

<p>Basically we can take a basis of $\ker T$, $(v_1,v_2)$. And we need to show there exists $v_3\in V$ such that $T(v_3)=v_1$ and $(v_1,v_2,v_3)$ is a basic of $V$ (ahm show theyr'e linearly independent). this is have I'm having trouble with.</p>

<p>Thanks in advance.</p>
",linear_algebra
"<p>$A\in \mathbb{C}^{n,n}$ is hermitian. Then:<br>
a. $A$ is congruent to some diagonal matrix $D\in\mathbb{R}^{n,n}$.<br>
b. if matrix $A$ is positively defined then all eigenvalues of $A$ are equal to $1$.<br>
c. if matrix $A$ is positively defined then $A$ is congruent to matrix $I_n$.  </p>

<p>b. not true, counterexample:<br>
$\left[ \begin{array}{ccc}
5 &amp; 0 \\
0 &amp; 3 
 \end{array} \right]$.  Of course this matrix is positively defined. Is also hermitian. However, eigenvalues are $5$ and $3$.  </p>

<p>c.  Yes, hermitian positively defined matrix $A$ has unique Cholesky decomposition: $A=LL^H$ where $L$ is lower triangular matrix with real positive (strictly) numbers on diagonal. Then $A=LI_nL^H$ and $L$ is nonsingular. Hence, c. is true.    </p>

<p>What about b, c?   Could you help me with a. ?</p>
",linear_algebra
"<p>I need to algebraically prove minimum for $\frac{1}{2}x^TAx-x^Tb$ using $r = A^{-1}x-b.$</p>

<p>I can write $x$ as $A(r+b)$ and whole expression as 
$$
\begin{align}
f(x) &amp;=\frac{1}{2}(r+b)^TA^3(r+b) - (r+b)^TAb \\
&amp;= \frac{1}{2}(Ar)^TA(Ar) - (Ar)^Tb \\
&amp; + \frac{1}{2}(Ab)^TA(Ab) - (Ab)^Tb \\
&amp; + (Ar)^TA^2b \\
\end{align}
$$</p>

<p>And i don't know how to proceed.</p>
",linear_algebra
"<p>I need some help here. It's hard to me to tackle this kind of question and I'm not used to write math proofs. I need to find values of $t$ that make $$\langle(x_1, x_2), (y_1, y_2)\rangle = x_1y_1 + tx_2y_2$$ an internal product in $\Bbb R^2$.</p>

<p>I have showed that for $3$ of the $4$ properties, t does not matter at all. But for the property that $$\langle u,u\rangle \gt 0, u \neq 0$$ I have $$x_1^2 +tx_2^2 \gt 0$$ and them $$t \gt -((x_1/x_2)^2)$$ The answer seems to be $t \gt 0$ and I'm lost in this. Could anyone give me the right direction to complete the proof?</p>
",linear_algebra
"<p><a href=""http://i.stack.imgur.com/NHbGu.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/NHbGu.png"" alt=""set of vectors, S""></a></p>

<p>Firstly, my apologies for attaching the question as an image. I was having a lot of problems typing it in MathJax.<br>
The question asks to show S is independent. From my understanding, I have to prove that:<br>
$$
\alpha{\begin{pmatrix}
 1\\
 1\\
 0\\
 \end{pmatrix}} +\beta{\begin{pmatrix}
 1\\
 0\\
 1\\
 \end{pmatrix}}= {\begin{pmatrix}
 0\\
 0\\
 0\\
 \end{pmatrix}}
$$if and only if $\alpha$ =$\beta$ = 0. I try to solve this using an augmented matrix, and reduce it to row-echelon form.
$$ \left[
    \begin{array}{cc|c}
      1&amp;1&amp;0\\
      1&amp;0&amp;0\\
      0&amp;1&amp;0
    \end{array}
\right] $$ $\underrightarrow{R2+R3}$
$$ \left[
    \begin{array}{cc|c}
      1&amp;1&amp;0\\
      1&amp;1&amp;0\\
      0&amp;1&amp;0
    \end{array}
\right] $$ $\underrightarrow{R3-R2}$
$$ \left[
    \begin{array}{cc|c}
      1&amp;1&amp;0\\
      1&amp;1&amp;0\\
      0&amp;0&amp;0
    \end{array}
\right] $$ But, 
$$ \left[
    \begin{array}{cc|c}
      0&amp;0&amp;0\\
    \end{array}
\right] $$ means that the system has infinitely many solutions. Therefore, $\alpha,\beta$ could have infinitely many solutions, and so the set $S$ is dependent.<br>
But the solution says that the set is independent because $\alpha,\beta = 0$. Could someone please assist me by pointing out where I have gone wrong? I would appreciate if you could stick to my method of solving (proving $\alpha,\beta=0$) because this is how I would like to approach it)</p>
",linear_algebra
"<p>I am doing some problems outside of class and have a couple of questions that I cannot figure out how to start. </p>

<ol>
<li>If $f$ and $g$ are independent polynomials and $h$ is a nonzero polynomial over $F$, show that $fh$ and $gh$ are independent.</li>
</ol>

<p>I think this is relatively intuitive, but cannot find a proof for it. </p>

<p>Since f and g are independent, that means they should each form a basis for the fields they are over (in terms of polynomials). Consequently, I believe multiplying by a nonzero polynomial is the equivalent of scaling it in the field. So, the only way they would be dependent is if $h=0$ or if $f=g=0$.</p>
",linear_algebra
"<p>Suppose I have a matrix $A$, not telling you what it looks like, and the set of eigenvalues associated with $A$ = $\{-1,-1,-1,4\}$</p>

<p>Suppose the geometric multiplicity of $-1$ is $2$, what would be the geometric multiplicity of $4$?</p>

<p>Possible answer could be $1$, $2$, since any more then our jordan form will blow up</p>

<p>Obviously here the algebraic multiplicity of $4$ is one. </p>

<p>Does it equal to the geometric multiplicity?</p>

<p>What is a condition to check when they are equal and how can I see that?</p>
",linear_algebra
"<p>a) Suppose $S = \{v_1, v_2, v_3, v_4, v_5\}$, where</p>

<p>$v_1 = \left(  
\begin{array}{c}
    1 \\
    -1 \\
    -1 \\
    2
  \end{array}
\right)$, 
$v_2 = \left(  
\begin{array}{c}
    1 \\
    -1 \\
    0 \\
    -1
  \end{array}
\right)$, 
$v_3 = \left(  
\begin{array}{c}
    5 \\
    -5 \\
    -2 \\
    1
  \end{array}
\right)$, 
$v_4 = \left(  
\begin{array}{c}
    1 \\
    -1 \\
    1 \\
    -4
  \end{array}
\right)$, 
$v_5 = \left(  
\begin{array}{c}
    0 \\
    0 \\
    3 \\
    -9
  \end{array}
\right)$,</p>

<p><strong>Without doing any row operations, explain why $S$ is a linearly dependent set</strong></p>

<p>I don't know how to start by just looking at it, all I can do is just Row Operation and see the leading columns then judge if it is linearly dependent or not. </p>

<p>Would someone please tell me how to judge if the set is a linearly dependent or independent set please?</p>

<p>Thank you.</p>
",linear_algebra
"<p>Solve the system: The last column is the vector b
$$
        \begin{bmatrix}
        1 &amp; 1 &amp; 4 &amp; -5 \\
        4 &amp; 3 &amp; -5 &amp; 8 \\
        \end{bmatrix}
$$</p>

<p>I reduced it down to</p>

<p>$$
        \begin{bmatrix}
        1 &amp; 0 &amp; -17 &amp; 23 \\
        0 &amp; 1 &amp; 21 &amp; -28 \\
        \end{bmatrix}
$$</p>

<p>Now I have to express it in terms of:</p>

<p>$$
        \begin{bmatrix}
        x1 \\
        x2 \\
        x3 \\
        \end{bmatrix}
$$</p>

<p>x3 is free and I believe the answer to be something along the lines of</p>

<p>$$
        \begin{bmatrix}
        1 &amp; 0\\
        0 &amp; 1\\
        ? &amp; ?\\
        \end{bmatrix}
$$</p>

<p>Not sure what the ? values are.</p>
",linear_algebra
"<p>I'm trying to write a Fortran subroutine to compute a QR factorization using the Householder method. To test my routine, I compute the factorization of the following matrix:
$$
A =
 \begin{pmatrix}
  12 &amp; -51 &amp; 4 \\
  6 &amp; 167 &amp; -68  \\
  -4 &amp; 24 &amp; -41 
 \end{pmatrix},
$$
which, if done correctly, will reduce to the following upper triangular matrix:
$$
R =
 \begin{pmatrix}
  14 &amp; 21 &amp; -14 \\
  0 &amp; 175 &amp; -70  \\
  0 &amp; 0 &amp; 35 
 \end{pmatrix}.
$$
However, the matrix I actually get is:
$$
R =
 \begin{pmatrix}
  -14 &amp; -21 &amp; 14 \\
  0 &amp; -175 &amp; 70  \\
  -0 &amp; 0 &amp; 35 
 \end{pmatrix},
$$
which looks almost correct, except for some strange sign changes. I've been staring at my subroutine all day trying to see where these sign changes are being introduced, but I can't identify the problem. </p>

<p>My algorithm is as follows:</p>

<p>$
for \:\: k \:=\: 1\: to\: n
$</p>

<p>$
\qquad x(k:m) = A(k:m,k)
$ </p>

<p>$
\qquad v(k:m) = \mathtt{sign}(x(k))||x(k:m)||_{2}e1 + x(k:m)
$</p>

<p>$
\qquad v(k:m) = v(k:m)/||v(k:m)||_{2}
$</p>

<p>$
\qquad A(k:m,k:n) = A(k:m,k:n) - 2vv^{\top}A(k:m,k:n)
$</p>

<p>To calculate the factor $2vv^{\top}A(k:m,k:n),$ I made another subroutine called outer_product to compute the outer product of $v$ with itself, i.e. $vv^{\top}$, and then matrix multiply the result into my submatrix $A(k:m,k:n)$. However, I'm not sure if this is legitimate - I suspect herein lies the problem.</p>

<p>I would really appreciate it if someone could glance at my code to see if there is any obvious reason for the incorrect sign changes: </p>

<pre><code>integer, parameter :: dp = selected_real_kind(15)

integer, intent(in) :: m, n
real(dp), dimension(m,n), intent(inout) :: A
real(dp), dimension(m,m), intent(out) :: Q

integer :: k
real(dp) :: two_norm
real(dp), dimension(m) :: x, e1
real(dp), dimension(m,n) :: v
real(dp), dimension(m,m) :: outprod_vv

v = 0.0_dp

do k=1,m
    Q(k,k) = 1.0_dp
end do

!Householder triangularization
do k=1,n

    e1(k) = 1.0_dp

    x(k:m) = A(k:m,k)
    v(k:m,k) = sign( sqrt(dot_product(x(k:m),x(k:m))), x(k) )* &amp;
        e1(k:m) + x(k:m)

    v(k:m,k) = v(k:m,k)/(sqrt(dot_product(v(k:m,k),v(k:m,k))))
    call outer_product(v(k:m,k), m-k+1, outprod_vv(k:m,k:m))

    A(k:m,k:n) = A(k:m,k:n) - &amp;
        2.0_dp*matmul(outprod_vv(k:m,k:m), A(k:m,k:n)) 

    !Form Q implicitly    
    Q(k:m,k:m) = Q(k:m,k:m) - 2.0_dp* &amp;
        matmul(outprod_vv(k:m,k:m), Q(k:m,k:m))

end do

Q = transpose(Q)
</code></pre>
",linear_algebra
"<p>What does it mean when someone says ""find a fundamental set of solutions for the system <strong>y'</strong> $=A$ <strong>y</strong>""?</p>

<p>That is, the system</p>

<p>$$ {\bf{y'}} =A {\bf{y}}. $$</p>
",linear_algebra
"<p>I've got a section in my textbook about non-parallel vectors, it says:</p>

<p>For two non-parallel vectors <strong>a</strong> and <strong>b</strong>, if $\lambda a + \mu b = \alpha a + \beta b$
then $\lambda  = \alpha $ and $\mu  = \beta $</p>

<hr>

<p>Okay I get that you can equate coefficients and solve for mu and lambda, but how are the two sides of the equation equal in the first place? How can you just equate two different vectors to each other like that? I'm just confused and i'm not entirely sure what about. I've tried googling but not much turns up.. I'd love it if someone could explain in basic terms what this equation is telling me.. (that non parallel vectors are equal?) as I've only just been introduced to this topic recently.. Thank you.</p>
",linear_algebra
"<p>The famous identity $\sin^2 x+\cos^2x =1$ can be written as follows:</p>

<blockquote>
  <p>The polynomials $P(x)=x^2$ and $Q(x)=1-x^2$ satisfy 
  $$P(\sin x)= Q(\cos x),\quad \text{for all }x\in\mathbb R$$</p>
</blockquote>

<p>What are other such pairs of polynomials. In other words, what is the sufficient and essential condition for two real polynomials $P(x)$ and $Q(x)$ to satisfy $P(\sin x)= Q(\cos x)$ for all $x$?</p>
",linear_algebra
"<p>This question is more general in the sense that I want to know how one finds a particular (say matrix) representation for any object. For the case of Grassmann numbers we have from <a href=""http://en.wikipedia.org/wiki/Grassmann_number#Matrix_representations"" rel=""nofollow"">Wikipedia the following representation</a>: </p>

<blockquote>
  <p>Grassmann numbers can always be represented by matrices. Consider, for example, the Grassmann algebra
  generated by two Grassmann numbers $\theta_1$ and
  $\theta_2$. These Grassmann numbers can be represented by
  4&times;4 matrices:</p>
  
  <p>$$\theta_1 = \begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0\\ 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp;
 0 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 1 &amp; 0\\ \end{bmatrix}\qquad \theta_2 =
 \begin{bmatrix} 0&amp;0&amp;0&amp;0\\ 0&amp;0&amp;0&amp;0\\ 1&amp;0&amp;0&amp;0\\ 0&amp;-1&amp;0&amp;0\\
 \end{bmatrix}\qquad \theta_1\theta_2 = -\theta_2\theta_1 =
 \begin{bmatrix} 0&amp;0&amp;0&amp;0\\ 0&amp;0&amp;0&amp;0\\ 0&amp;0&amp;0&amp;0\\ 1&amp;0&amp;0&amp;0\\ \end{bmatrix}.
 $$</p>
</blockquote>

<p>How do one find these matrices? Do you guess them or is there a procedure? What about finding differenct matrix-representations for <strong>Dirac $\gamma$-matrices? How do you find them?</strong></p>
",linear_algebra
"<p>I am currently working no a linear algebra question and do not understand how to solve it. The questions gives:</p>

<pre><code>Four corners of a cube are (0,0,0), (2,0,0), (0,4,0) and (0,0,10).
</code></pre>

<p>I am asked to find:</p>

<pre><code>Find the remaining 4 corners.
Find the coordinates of the center point of the cube.
</code></pre>

<p>Can someone help me on the right path to this question?</p>

<p>How would find the other 4 corners of the cube? I dont understand how to find the width of the cube.</p>

<p>Thank you</p>
",linear_algebra
"<p>For an uknown 3x3 matrix $A$ we know that $\operatorname{tr} A = 0$, $\det(A) = 1/4$ and we also know that two eigenvalues are the same. Proove that $4A^3 = -3A - I$. Problem says to use Vieta to find characteristic polynomial and Cayley-Hamilton after.</p>

<p>I get that $2L_1 + L_3 = 0$ and $L_1^2 = 1/4$ but i do know how to proceed.</p>

<p>Thanks in advance</p>
",linear_algebra
"<p>I was just wondering, for a dynamic system does the origin always have to be an attractor, saddle point, or repellor?</p>

<p>Also if a matrix isn't diagonalizable then does that mean the origin cannot be a repellor the matrix?</p>
",linear_algebra
"<p>Determine if $\vec b$ is a linear combination of $\vec a_1,\vec a_2,\vec a_3$.</p>

<p>$\vec a_1 = \left[\begin{array}{c}
1     \\
-2   \\
0    \\
\end{array}\right], \vec a_2 = \left[\begin{array}{c}
0    \\
1   \\
2    \\
\end{array}\right], \vec a_3=\left[\begin{array}{c}
5     \\
-6   \\
8    \\
\end{array}\right], \vec{b} = \left[\begin{array}{c}
2    \\
-1   \\
6    \\
\end{array}\right]$</p>

<p>Okay, so I made my constants $x_{1}, x_{2}, x_{3}$ for $\vec a_1, \vec a_2,\vec a_3$, respectively. I end up getting the following consistent system:
$$\left[\begin{array}{cccc}
1 &amp; 0 &amp; 5 &amp; 2    \\
0 &amp; 1 &amp; 4 &amp; 3   \\
0 &amp; 0 &amp; 0 &amp; 0    \\
\end{array}\right]$$
Which has the general solution: $$
\begin{cases}
x_{1} = 2 - 5x_{3} \\
x_{2} = 3 - 4x_{3} \\
x_{3} = \text{free}.
\end{cases}
$$
So $\vec b$ is equal to infinitely  many linear combinations of $\vec a_1,\vec a_2,\vec a_3$, right? Why does my book say that $\vec b$ is <em>not</em> a linear combination of these three vectors? Must the constants be a unique solution?</p>
",linear_algebra
"<p>It is clear that a reordering of the elements in a chosen basis for an n-dimensional vector space induces a permutation on n elements, and conversely such a permutation corresponds to a re-ordering of the basis.</p>

<p>I am wondering why the signature of a permutation is associated to the orientation induced by a basis. I understand that one can do this technically - but is there an intuitive way to understand why this is so? </p>

<p>That is, is there a way to understand  why the concept of orientation, as experienced in 1,2 and 3 dimensional Euclidean space, is formalized (and thereby generalized to abstract vector spaces of arbitrary finite dimension) using the signature? </p>
",linear_algebra
"<p>Suppose $A$ is a $2\times2$ matrix. How do I prove that, if $\det(A) &lt; 0$, then $A$ is a diagonalizable matrix over $\mathbb{R}$?</p>
",linear_algebra
"<p>I want to find the least squares solution to $\boldsymbol{Ax}=\boldsymbol{b}$ where $\boldsymbol{A}$ is a highly sparse square matrix.<br>
I found two methods that look like they might lead me to a solution: <a href=""http://en.wikipedia.org/wiki/QR_decomposition"" rel=""nofollow"">QR factorization</a>, and <a href=""http://en.wikipedia.org/wiki/Singular_value_decomposition#Pseudoinverse"" rel=""nofollow"">singular value decomposition</a>. Unfortunately, I haven't taken linear algebra yet, so I can't really understand most of what those pages are saying. I can calculate both in Matlab though, and it looks like the SVD gave me a smaller squared error. Why did that happen? How can I know which one I should be using in the future?</p>
",linear_algebra
"<p>I have a problem which is interesting: given a real matrix $A_{n\times n}$, when this matrix has a largest real eigenvalue which is strictly bigger than 1. If possible, can you give some conditions that can  guarantee this  statement? Equivalently, this statement says that the entropy of the subshift of finite type is strictly bigger than 0. </p>
",linear_algebra
"<blockquote>
  <p>Let $\mathbb{F}$ be an arbitrary field and $A\in M_{n\times n}(\mathbb{F})$ such that $$tr(A)=0$$
  Now show that there exists $P$,$Q$ $\in M_{n\times n}(\mathbb{F})$ such that $$A=PQ-QP$$</p>
</blockquote>

<p>It is so natural because we know that $tr(XY-YX)=0$ for all $X,Y$.</p>

<p>I know some proof by induction and canonical forms. Can somebody say another easy and elementary way.</p>
",linear_algebra
"<p>Let $A$ and $B$ be two real $n\times n$ matrices s.t. $AB=BA$. We now that $\det(A^2+B^2) \geq 0$. Is  the similar question true for $n$ matrices which commute with each other? If not, how do I generalize this question?</p>
",linear_algebra
"<blockquote>
  <p>Let $V$ be a vector space where dot product is defined. Then the following is true:
  $$\forall x, y\in V \quad \langle x,y\rangle^2  \leq \langle x,x \rangle\langle y,y \rangle$$
  <strong>Proof:</strong></p>
  
  <p>Consider the following linear combination: $z=\langle x,y\rangle x - \langle x,x\rangle y$. Let's find the dot product $\langle z,z\rangle \ge 0$: 
  $$\langle z,z\rangle = \langle \langle x,y\rangle x - \langle x,x\rangle y,\langle x,y\rangle x - \langle x,x\rangle y\rangle\\
\stackrel{?}= \langle x,x\rangle \left[ \langle x,x\rangle\langle y,y\rangle - \langle x,y\rangle^2\right] \ge0.
$$</p>
</blockquote>

<p>This is a proof from my linear algebra course book. I fail too see how the transition which I marked with $?$ was made. I will appreciate a clear explanation.</p>
",linear_algebra
"<p>Let $T,S: V\to V$ be 2 linear transformations, and $\ker(T)=\{0\}$.
I need to prove why $\ker(T\circ S)=\ker(S)$.<br>
I have no idea how to prove it.</p>
",linear_algebra
"<p>Let $A$ be a matrix so $A=A^2$.</p>

<p>I need to show that the eigenvalues of $A$ are only $1$ or $0$.</p>

<p>I tried some ways but none of them help.</p>
",linear_algebra
"<p>Let $x_{k+1} = Bx_k + c$
where $B$ is $n \times n$ matrix $c$ is a vector.</p>

<p>Assume $\|B\| \le \beta &lt;1$</p>

<p>$\|x_k - x_{k-1}\| \le \varepsilon$ for some $k$</p>

<p>Show that $\| x - x_k\| \le \dfrac{\beta\varepsilon}{1 - \beta}$</p>

<p>Thanks a lot...</p>
",linear_algebra
"<p>Naturally we can describe graphs via tables of ""yes there is an edge"" or ""no there is not"" between each pair of vertices, so the definition of an adjacency matrix is easily understood.  Thinking of these tables as <em>matrices</em>, however, adds structure - specifically, an interpretation as a linear operator.  Why do we look at them in this light?  Is it just for application - for example, efficiently obtaining a lot of data about a graph by computing its spectrum?  Or is there also an intuitive geometric (or algebraic) motivation behind the adjacency matrix?</p>

<p>For example, the $2$-path <img src=""http://i.stack.imgur.com/bSdoS.png"" alt=""2-path""> has adjacency matrix
 $$\mathcal{A}(P_2)=\left(\begin{array}{cc} 0 &amp; 1\\1 &amp; 0\end{array}\right)$$ which acts on a $2$-dimensional vector space by flipping the coordinates, $(x,y)\mapsto (y,x)$.  Can we somehow intuitively connect this action to the $2$-path?  What about for other simple graphs?</p>
",linear_algebra
"<p>Write vector 
u = $$\left[\begin{array}{ccc|c}2 \\10 \\1\end{array}\right]$$</p>

<p>as a linear combination of the vectors in S. Use elementary row operations on an augmented matrix to find the necessary coefficients. </p>

<p>S = {
$v1$$\left[\begin{matrix}1\\2\\2\end{matrix}\right] , v2\left[\begin{matrix}4\\2\\1\end{matrix}\right],  
v2\left[\begin{matrix}5\\4\\1\end{matrix}\right]
$ }. If it is not possible, explain why?</p>

<hr>

<p>This is what i have so far: </p>

<p>S = {
$v1$$\left[\begin{matrix}1\\2\\2\end{matrix}\right] , v2\left[\begin{matrix}4\\2\\1\end{matrix}\right],  
v3\left[\begin{matrix}5\\4\\1\end{matrix}\right].
v4\left[\begin{matrix}2\\10\\1\end{matrix}\right]
$ } 
<br><br>
$c1$$\left[\begin{matrix}1\\2\\2\end{matrix}\right] , c2\left[\begin{matrix}4\\2\\1\end{matrix}\right],  
c3\left[\begin{matrix}5\\4\\1\end{matrix}\right].
c4\left[\begin{matrix}2\\10\\1\end{matrix}\right]
=\left[\begin{matrix}0\\0\\0\end{matrix}\right]$</p>

<p>$c1$$\left[\begin{matrix}1\\2\\2\end{matrix}\right] , c2\left[\begin{matrix}4\\2\\1\end{matrix}\right],  
c3\left[\begin{matrix}5\\4\\1\end{matrix}\right].
c4\left[\begin{matrix}2\\10\\1\end{matrix}\right]$</p>

<p>$
\begin{bmatrix}
1 &amp; 4 &amp; 5 &amp; 2\\
2 &amp; 2 &amp; 4 &amp; 10\\
2 &amp; 1 &amp; 1 &amp; 1\\
\end{bmatrix}
$</p>

<p>Now i don't know how to do this. Help will greatly be appreciated.</p>

<p>Thanks</p>
",linear_algebra
"<p>I am stuck with the following linear algebra problem:</p>

<p>given a basis $ \{e_{1} ... e_{n}\} $, I can define products $ \{p_{1} ... p_{m} \} $ as linear combination of the basis and the products itself:</p>

<p>$$
p_{i} = \sum_{j=1}^m u_{ij} p_{j} + \sum_{j=1}^n a_{ij}e_{ij} 
$$</p>

<p>My goal is to represent each product only as a combination of the basis. </p>

<p>$$
p_{i} = \sum_{j=1}^n s_{ij} e_{j} 
$$</p>

<p>any hint for a solution?</p>
",linear_algebra
"<p>I have the following question :</p>

<p>Let $A_{n \times n}$ that implies : $A^2-2A+I=0$ </p>

<ul>
<li>Proof $1$ is an eigevalue of $A$</li>
</ul>

<p>I don't really know how to approach this this what I manage to do (its not much though):</p>

<ul>
<li>$A(A-2I)=-I$ </li>
</ul>

<p>We know that if $\lambda$ is an eigenvalue then $Ax=\lambda x$ $(x \neq 0)$</p>

<p>$$A(A-2I)=I$$
Can I say now that since $Ax=\lambda x$ and Let $x=(A-2I)$ but $x$ is vector, not a matrix.</p>

<p>I don't really understand what to do next.</p>

<p>Any help will be be dearly appreciated, Thanks.</p>
",linear_algebra
"<p>Let $A$ be a linear operator which acts on the vector space $V=\langle x_1,x_2, \ldots,x_n\rangle$. Suppose we know its eigenvalues - $\lambda_1, \lambda_2, \ldots, \lambda_n.$</p>

<p>Now consider the vector space $V^{(2)} \subset {\rm Sym}^2 V$ generated by elements $x_i x_j, i&lt;j,$ $\dim V^{(2)}=\binom{n}{2}.$ Let us extend the operator $A$ on $V^{(2)}$    by linearity and by $A(x_i x_j)=A(x_i)A(x_j)$. Denote the extension by $A^{(2)}$  <em>and suppose that $A^{(2)}$ is an injective endomorphism of $V^{(2)}$.</em></p>

<p><strong>Question.</strong> What is the eigenvalues of the $A^{(2)}?$ 
My first answer    was that the set of eigenvalues consists of elements  $\lambda_i \lambda_j, i&lt;j$ but simple examples with small $n$  show  that is wrong answer.</p>

<p><strong>Edit.</strong> We may assume  that $A$ is  a permutation of the basis vectors.</p>
",linear_algebra
"<p>Let's say I am using the $Ham(2,11)$ code - the hamming code for which r = 2 and q=11 (length of alphabet). Can I detect errors caused by the transposition of 2 letters? If not, why?</p>
",linear_algebra
"<p>Assuming I have a $[n,k,d]$ linear code, how can it be shown that $d \leq n-k+1$ ?</p>
",linear_algebra
"<p>Suppose $A$ is a $m \times n$ matrix and $V$ is a $m \times 1$ matrix with both $A$ and $V$ having rational entries and suppose the system $AX=V$ has a solution in $\mathbb{R}^n$. Then the equation has a solution with rational entries.</p>

<p>Is the above statement true or false?</p>
",linear_algebra
"<p>$A$ is invertible, but it does not say that $A$ is symmetric.
By $B^T$ I mean that $B$ is transposed.</p>
",linear_algebra
"<p>Not all matrix with positive eigenvalues is positive definite, i.e. $\mathbf{x}^\mathsf{T}A\mathbf{x}&gt;0$ for all non zero vector $\mathbf{x}$. For example consider matrix</p>

<p>$$A = \begin{bmatrix} 1 &amp; -3 \\ 0 &amp; 1 \end{bmatrix}.$$</p>

<p>How to prove that if we add symmetry into hypothesis then the assertion is true? That is, a symmetric matrix with positive eigenvalues is positive definite. </p>
",linear_algebra
"<p>If $A\in L(X)$ then prove that $A^{-1}$ is linear and invertible.</p>

<p><strong>Proof:</strong> Since $A$ is invertible then $A$ is injective and surjective. We know that $A^{-1}$ defines by $A^{-1}(Ax)=x$. </p>

<p><em>Remark:</em> Also we can prove that $A(A^{-1}x)=x$. Indeed, if $x\in X$ and $A$ is surjective then exists $y\in X$ such that $x=Ay$. Hence $A(A^{-1}x)=A(A^{-1}Ay)=Ay=x$.</p>

<p>$A^{-1}(x+y)=A^{-1}(Ax_0+Ay_0)=A^{-1}A(x_0+y_0)=x_0+y_0=A^{-1}x+A^{-1}y$ and<br>
$A^{-1}(\alpha x)=A^{-1}(\alpha Ax_0)=A^{-1}A(\alpha x_0)=\alpha x_0=\alpha A^{-1}x$. Hence $A^{-1}$ is linear operator.</p>

<p>We have to prove that $A^{-1}$ is invertible, i.e. $A^{-1}$ is injective and surjective. </p>

<p>If $A^{-1}x=A^{-1}y$ then $x=Ax_0$ and $y=Ay_0$ for some $x_0,y_0\in X$. Then $A^{-1}Ax_0=A^{-1}Ay_0$ $\Rightarrow$ $x_0=y_0$ $\Rightarrow$ $x=y$.</p>

<p>For any $x\in X$ exists $y\in X$ such that $x=A^{-1}y$. For example, we can take $y=Ax$.</p>

<p>Thus, $A^{-1}$ is invertible and $\exists$ $(A^{-1})^{-1}$. We have prove that $(A^{-1})^{-1}=A$. Let $A^{-1}=F$ and $F^{-1}=G$.</p>

<p>For any $x\in X$ we have: $Gx=F^{-1}x$ since $F$ is invertible $\Rightarrow$ surjective then $\exists $$y\in X$ such that $x=Fy.$ Hence $$Gx=F^{-1}x=F^{-1}Fy=y=Ax.$$ Thus $(A^{-1})^{-1}=A.$</p>

<p>Please can anyone check my solution? I would be very grateful for any answer.</p>
",linear_algebra
"<p>The following is a discussion on the following second differential equation</p>

<p>$$  \frac{dy^2}{dx} - y = 0 $$</p>

<p>So, let us introduce the following, convention and definition, represent the derivative operator by</p>

<p>$$ D = \frac{d}{dx} $$</p>

<p>So that our first equation can be represented as</p>

<p>$$ \left( D^2 - 1 \right) y(x) = 0 $$</p>

<p>My professor discussed on the idea, on ""factoring"" (The space on which the derivative acts?) the operators, his discussion lead to the apparent nonuniqueness of factoring as either</p>

<p>$$ (D - \tanh(x))(D + \tanh(x)) y = 0 \quad \textrm{and } \quad (D - 1)(D + 1) = 0 $$</p>

<p>My first question is that how is that  $ (D - \tanh(x))(D + \tanh(x))  ``="" (D^2 - 1) $ and how is unfoiled?, because I think is not commutative because</p>

<p>$$ f(x)\frac{d}{dx}y \neq \frac{d}{dx}f(x)y(x) $$</p>

<p>One is first derive something and multiply by $f$, and the other is derive the product.</p>

<p>Second, my professor move to the general</p>

<p>$$ y'' + a(x)y' + b(x) = 0 $$</p>

<p>or</p>

<p>$$ \big(D^2 + a(x)D + b(x)\big)y(x) = 0 $$</p>

<p>and he wants to factor the above as</p>

<p>$$ \big( D + A(x)\big)\big(D + B(x)\big)y(x) = 0 $$</p>

<p>So then he unfoils the above equation as:</p>

<p>$$ \big( D^2 + AD + AB + B' + BD \big)y = 0 $$</p>

<p>and he argues that the terms $B'$ and $BD$ comes from the fact that either we take the derivative of $B$ or take the derivative and multiply by B (Why that doesn't apply to the terms $ AD  $ and we should add $ A'$ ? </p>

<p>Also, do you happen to know where to find reference on solving ODEs by this approach? Thanks</p>
",linear_algebra
"<p>Find the jordan form of the matrix
$$A = \begin{pmatrix}
 1 &amp; 1 &amp; 2 &amp; 2\\
 1 &amp; -2 &amp; -1 &amp; -1\\
 -2 &amp; 1 &amp; -1 &amp; -1\\
1 &amp; 1 &amp; 2 &amp; 2 \\
\end{pmatrix}$$</p>

<p>Hint: check that the matrix A has a single eigenvalue, and $trace(A) = 0$.</p>

<p>How can I check that the matrix has a single eigenvalue without using the determinant?</p>

<p>That's what I managed to do so far:</p>

<p>Let $G$ the Jordan form of $A$, using the hint that there is a single eigenvalue:
$$trace(A) = 0\implies 0 = trace(A) = trace(G) = 4a \implies a = 0$$</p>

<p>meaning that theres a single eigenvalue which is zero.</p>

<p>Then the characteristic polynomial is $A^4$  and the minimal polynomial is $A^3$.</p>

<p>Then:
$G = diag\{J_3(0), J_1(0)\}$</p>

<p>But how do I prove that there is a single eigenvalue?</p>
",linear_algebra
"<p>What is  an example of  a  $C^{*}$  algebra with an idempotent $e$ such that $e$ is  not Murray-von Neumann equivalent to $e^{*}$?</p>
",linear_algebra
"<p>For any $i \in \{1,2,3\}$, let:</p>

<ul>
<li>$w_i \in [0,1]$ is an <em>unknown</em> number such that $\sum_{i \in \{1,2,3\}} w_i = 1$.</li>
<li>$t$ is a <em>known</em> number in $[0,1]$. Suppose that $t = 0.8$.</li>
<li>$f_i$ is also a <em>known</em> number in $[0,1]$. Suppose that $f_1 = 0.2$, $f_2=0.6$, and $f_3=0.5$.</li>
</ul>

<p>Which are related by the equation: $t = \sum_{i \in \{1,2,3\}} w_i \times f_i$. It is assumed that there is only one true solution, and the rest are not true (maybe close estimations).</p>

<p>The questions are: </p>

<ul>
<li>What are the possible values of $w_1, w_2, w_3$ that satisfy the equation above? </li>
<li>How to find them?</li>
<li>In case too many possible values exist, what is the best method in estimating the values of $w_1,w_2,w_3$?</li>
</ul>

<h2>A brute-force by Python</h2>

<p>By brute-forcing answers, I found these which give a priority to ensuring that the sum $w_1+w_2+w_3=1$ (without ensuring that $t=0.8$):</p>

<pre><code>w1, w2, w3, w1+w2+w3, t
0, 0.01, 0.99, 1.0, 0.501
0, 0.02, 0.98, 1.0, 0.502
0, 0.02, 0.99, 1.01, 0.507
0, 0.03, 0.98, 1.01, 0.508
0, 0.03, 0.99, 1.02, 0.513
0, 0.04, 0.98, 1.02, 0.514
0, 0.04, 0.99, 1.03, 0.519
0, 0.05, 0.98, 1.03, 0.52
0, 0.05, 0.99, 1.04, 0.525
0, 0.06, 0.98, 1.04, 0.526
0, 0.06, 0.99, 1.05, 0.531
0, 0.07, 0.98, 1.05, 0.532
0, 0.07, 0.99, 1.06, 0.537
0, 0.08, 0.98, 1.06, 0.538
0, 0.08, 0.99, 1.07, 0.543
0, 0.09, 0.98, 1.07, 0.544
0, 0.09, 0.99, 1.08, 0.549
0, 0.1, 0.98, 1.08, 0.55
0, 0.1, 0.99, 1.09, 0.555
0, 0.11, 0.98, 1.09, 0.556
</code></pre>

<p>There are solutions, but none of them correspond to a $t$ that is close enough to 0.8.</p>

<p>Here I gave a high priority to ensuring that $t=0.8$ (while ignoring the sum = 1):</p>

<pre><code>w1, w2, w3, w1+w2+w3, t
0, 0.51, 0.99, 1.5, 0.801
0, 0.55, 0.94, 1.49, 0.8
0, 0.6, 0.88, 1.48, 0.8
0, 0.65, 0.82, 1.47, 0.8
0, 0.7, 0.76, 1.46, 0.8
0, 0.75, 0.7, 1.45, 0.8
0, 0.8, 0.64, 1.44, 0.8
0, 0.85, 0.58, 1.43, 0.8
0, 0.9, 0.52, 1.42, 0.8
0, 0.95, 0.46, 1.41, 0.8
0.01, 0.53, 0.96, 1.5, 0.8
0.01, 0.58, 0.9, 1.49, 0.8
0.01, 0.63, 0.84, 1.48, 0.8
0.01, 0.68, 0.78, 1.47, 0.8
0.01, 0.73, 0.72, 1.46, 0.8
0.01, 0.78, 0.66, 1.45, 0.8
0.01, 0.83, 0.6, 1.44, 0.8
0.04, 0.82, 0.6, 1.46, 0.8
0.06, 0.83, 0.58, 1.47, 0.8
0.07, 0.81, 0.6, 1.48, 0.8
0.09, 0.82, 0.58, 1.49, 0.8
0.1, 0.8, 0.6, 1.5, 0.8
0.11, 0.83, 0.56, 1.5, 0.8
0.12, 0.81, 0.58, 1.51, 0.8
0.13, 0.54, 0.9, 1.57, 0.8
0.13, 0.59, 0.84, 1.56, 0.8
0.13, 0.64, 0.78, 1.55, 0.8
0.13, 0.69, 0.72, 1.54, 0.8
0.13, 0.74, 0.66, 1.53, 0.8
0.13, 0.79, 0.6, 1.52, 0.8
0.14, 0.52, 0.92, 1.58, 0.8
0.14, 0.57, 0.86, 1.57, 0.8
0.14, 0.62, 0.8, 1.56, 0.8
0.14, 0.67, 0.74, 1.55, 0.8
0.14, 0.72, 0.68, 1.54, 0.8
0.14, 0.77, 0.62, 1.53, 0.8
0.14, 0.82, 0.56, 1.52, 0.8
0.15, 0.5, 0.94, 1.59, 0.8
0.15, 0.55, 0.88, 1.58, 0.8
0.15, 0.6, 0.82, 1.57, 0.8
0.15, 0.65, 0.76, 1.56, 0.8
0.15, 0.7, 0.7, 1.55, 0.8
0.15, 0.75, 0.64, 1.54, 0.8
0.15, 0.8, 0.58, 1.53, 0.8
0.16, 0.53, 0.9, 1.59, 0.8
0.16, 0.58, 0.84, 1.58, 0.8
0.16, 0.63, 0.78, 1.57, 0.8
0.16, 0.68, 0.72, 1.56, 0.8
0.16, 0.73, 0.66, 1.55, 0.8
0.16, 0.78, 0.6, 1.54, 0.8
0.16, 0.83, 0.54, 1.53, 0.8
0.17, 0.51, 0.92, 1.6, 0.8
0.17, 0.56, 0.86, 1.59, 0.8
0.17, 0.61, 0.8, 1.58, 0.8
0.17, 0.66, 0.74, 1.57, 0.8
0.17, 0.71, 0.68, 1.56, 0.8
0.17, 0.76, 0.62, 1.55, 0.8
0.17, 0.81, 0.56, 1.54, 0.8
0.18, 0.54, 0.88, 1.6, 0.8
0.18, 0.59, 0.82, 1.59, 0.8
0.18, 0.64, 0.76, 1.58, 0.8
0.18, 0.69, 0.7, 1.57, 0.8
0.18, 0.74, 0.64, 1.56, 0.8
0.18, 0.79, 0.58, 1.55, 0.8
0.19, 0.52, 0.9, 1.61, 0.8
0.19, 0.57, 0.84, 1.6, 0.8
0.19, 0.62, 0.78, 1.59, 0.8
0.19, 0.67, 0.72, 1.58, 0.8
0.19, 0.72, 0.66, 1.57, 0.8
0.19, 0.77, 0.6, 1.56, 0.8
0.19, 0.82, 0.54, 1.55, 0.8
0.2, 0.5, 0.92, 1.62, 0.8
0.2, 0.55, 0.86, 1.61, 0.8
0.2, 0.6, 0.8, 1.6, 0.8
0.2, 0.65, 0.74, 1.59, 0.8
0.2, 0.7, 0.68, 1.58, 0.8
0.2, 0.75, 0.62, 1.57, 0.8
0.2, 0.8, 0.56, 1.56, 0.8
0.21, 0.53, 0.88, 1.62, 0.8
0.21, 0.58, 0.82, 1.61, 0.8
0.21, 0.63, 0.76, 1.6, 0.8
0.21, 0.68, 0.7, 1.59, 0.8
0.21, 0.73, 0.64, 1.58, 0.8
0.21, 0.78, 0.58, 1.57, 0.8
0.21, 0.83, 0.52, 1.56, 0.8
0.22, 0.51, 0.9, 1.63, 0.8
0.22, 0.56, 0.84, 1.62, 0.8
0.22, 0.61, 0.78, 1.61, 0.8
0.22, 0.66, 0.72, 1.6, 0.8
0.22, 0.71, 0.66, 1.59, 0.8
0.22, 0.76, 0.6, 1.58, 0.8
0.22, 0.81, 0.54, 1.57, 0.8
0.23, 0.54, 0.86, 1.63, 0.8
0.23, 0.59, 0.8, 1.62, 0.8
0.23, 0.64, 0.74, 1.61, 0.8
0.23, 0.69, 0.68, 1.6, 0.8
0.23, 0.74, 0.62, 1.59, 0.8
0.23, 0.79, 0.56, 1.58, 0.8
0.24, 0.52, 0.88, 1.64, 0.8
0.24, 0.57, 0.82, 1.63, 0.8
0.24, 0.62, 0.76, 1.62, 0.8
0.24, 0.67, 0.7, 1.61, 0.8
0.24, 0.72, 0.64, 1.6, 0.8
0.24, 0.77, 0.58, 1.59, 0.8
0.24, 0.82, 0.52, 1.58, 0.8
0.25, 0.5, 0.9, 1.65, 0.8
0.25, 0.55, 0.84, 1.64, 0.8
0.25, 0.6, 0.78, 1.63, 0.8
0.25, 0.65, 0.72, 1.62, 0.8
0.25, 0.7, 0.66, 1.61, 0.8
0.25, 0.75, 0.6, 1.6, 0.8
0.25, 0.8, 0.54, 1.59, 0.8
0.26, 0.53, 0.86, 1.65, 0.8
0.26, 0.58, 0.8, 1.64, 0.8
0.26, 0.63, 0.74, 1.63, 0.8
0.26, 0.68, 0.68, 1.62, 0.8
0.26, 0.73, 0.62, 1.61, 0.8
0.26, 0.78, 0.56, 1.6, 0.8
0.26, 0.83, 0.5, 1.59, 0.8
0.27, 0.51, 0.88, 1.66, 0.8
0.27, 0.56, 0.82, 1.65, 0.8
0.27, 0.61, 0.76, 1.64, 0.8
0.27, 0.66, 0.7, 1.63, 0.8
0.27, 0.71, 0.64, 1.62, 0.8
0.27, 0.76, 0.58, 1.61, 0.8
0.27, 0.81, 0.52, 1.6, 0.8
0.28, 0.54, 0.84, 1.66, 0.8
0.28, 0.59, 0.78, 1.65, 0.8
0.28, 0.64, 0.72, 1.64, 0.8
0.28, 0.69, 0.66, 1.63, 0.8
0.28, 0.74, 0.6, 1.62, 0.8
0.28, 0.79, 0.54, 1.61, 0.8
0.29, 0.52, 0.86, 1.67, 0.8
0.29, 0.57, 0.8, 1.66, 0.8
0.29, 0.62, 0.74, 1.65, 0.8
0.29, 0.67, 0.68, 1.64, 0.8
0.29, 0.72, 0.62, 1.63, 0.8
0.29, 0.77, 0.56, 1.62, 0.8
0.29, 0.82, 0.5, 1.61, 0.8
0.3, 0.5, 0.88, 1.68, 0.8
0.3, 0.55, 0.82, 1.67, 0.8
0.3, 0.6, 0.76, 1.66, 0.8
0.3, 0.65, 0.7, 1.65, 0.8
0.3, 0.7, 0.64, 1.64, 0.8
0.3, 0.75, 0.58, 1.63, 0.8
0.3, 0.8, 0.52, 1.62, 0.8
0.31, 0.53, 0.84, 1.68, 0.8
0.31, 0.58, 0.78, 1.67, 0.8
0.31, 0.63, 0.72, 1.66, 0.8
0.31, 0.68, 0.66, 1.65, 0.8
0.31, 0.73, 0.6, 1.64, 0.8
0.31, 0.78, 0.54, 1.63, 0.8
0.31, 0.83, 0.48, 1.62, 0.8
0.32, 0.51, 0.86, 1.69, 0.8
0.32, 0.56, 0.8, 1.68, 0.8
0.32, 0.61, 0.74, 1.67, 0.8
0.32, 0.66, 0.68, 1.66, 0.8
0.32, 0.71, 0.62, 1.65, 0.8
0.32, 0.76, 0.56, 1.64, 0.8
0.32, 0.81, 0.5, 1.63, 0.8
0.33, 0.54, 0.82, 1.69, 0.8
0.33, 0.59, 0.76, 1.68, 0.8
0.33, 0.64, 0.7, 1.67, 0.8
0.33, 0.69, 0.64, 1.66, 0.8
0.33, 0.74, 0.58, 1.65, 0.8
0.33, 0.79, 0.52, 1.64, 0.8
0.34, 0.52, 0.84, 1.7, 0.8
0.34, 0.57, 0.78, 1.69, 0.8
0.34, 0.62, 0.72, 1.68, 0.8
0.34, 0.67, 0.66, 1.67, 0.8
0.34, 0.72, 0.6, 1.66, 0.8
0.34, 0.77, 0.54, 1.65, 0.8
0.34, 0.82, 0.48, 1.64, 0.8
0.35, 0.5, 0.86, 1.71, 0.8
0.35, 0.55, 0.8, 1.7, 0.8
0.35, 0.6, 0.74, 1.69, 0.8
0.35, 0.65, 0.68, 1.68, 0.8
0.35, 0.7, 0.62, 1.67, 0.8
0.35, 0.75, 0.56, 1.66, 0.8
0.35, 0.8, 0.5, 1.65, 0.8
0.36, 0.53, 0.82, 1.71, 0.8
0.36, 0.58, 0.76, 1.7, 0.8
0.36, 0.63, 0.7, 1.69, 0.8
0.36, 0.68, 0.64, 1.68, 0.8
0.36, 0.73, 0.58, 1.67, 0.8
0.36, 0.78, 0.52, 1.66, 0.8
0.36, 0.83, 0.46, 1.65, 0.8
0.37, 0.51, 0.84, 1.72, 0.8
0.37, 0.56, 0.78, 1.71, 0.8
0.37, 0.61, 0.72, 1.7, 0.8
0.37, 0.66, 0.66, 1.69, 0.8
0.37, 0.71, 0.6, 1.68, 0.8
0.37, 0.76, 0.54, 1.67, 0.8
0.37, 0.81, 0.48, 1.66, 0.8
0.38, 0.54, 0.8, 1.72, 0.8
0.38, 0.59, 0.74, 1.71, 0.8
0.38, 0.64, 0.68, 1.7, 0.8
0.38, 0.69, 0.62, 1.69, 0.8
0.38, 0.74, 0.56, 1.68, 0.8
0.38, 0.79, 0.5, 1.67, 0.8
0.39, 0.52, 0.82, 1.73, 0.8
0.39, 0.57, 0.76, 1.72, 0.8
0.39, 0.62, 0.7, 1.71, 0.8
0.39, 0.67, 0.64, 1.7, 0.8
0.39, 0.72, 0.58, 1.69, 0.8
0.39, 0.77, 0.52, 1.68, 0.8
0.39, 0.82, 0.46, 1.67, 0.8
0.4, 0.5, 0.84, 1.74, 0.8
0.4, 0.55, 0.78, 1.73, 0.8
0.4, 0.6, 0.72, 1.72, 0.8
0.4, 0.65, 0.66, 1.71, 0.8
0.4, 0.7, 0.6, 1.7, 0.8
0.4, 0.75, 0.54, 1.69, 0.8
0.4, 0.8, 0.48, 1.68, 0.8
0.41, 0.53, 0.8, 1.74, 0.8
0.41, 0.58, 0.74, 1.73, 0.8
0.41, 0.63, 0.68, 1.72, 0.8
0.41, 0.68, 0.62, 1.71, 0.8
0.41, 0.73, 0.56, 1.7, 0.8
0.41, 0.78, 0.5, 1.69, 0.8
0.41, 0.83, 0.44, 1.68, 0.8
0.42, 0.51, 0.82, 1.75, 0.8
0.42, 0.56, 0.76, 1.74, 0.8
0.42, 0.61, 0.7, 1.73, 0.8
0.42, 0.66, 0.64, 1.72, 0.8
0.42, 0.71, 0.58, 1.71, 0.8
0.42, 0.76, 0.52, 1.7, 0.8
0.42, 0.81, 0.46, 1.69, 0.8
0.43, 0.54, 0.78, 1.75, 0.8
0.43, 0.59, 0.72, 1.74, 0.8
0.43, 0.64, 0.66, 1.73, 0.8
0.43, 0.69, 0.6, 1.72, 0.8
0.43, 0.74, 0.54, 1.71, 0.8
0.43, 0.79, 0.48, 1.7, 0.8
0.44, 0.52, 0.8, 1.76, 0.8
0.44, 0.57, 0.74, 1.75, 0.8
0.44, 0.62, 0.68, 1.74, 0.8
0.44, 0.67, 0.62, 1.73, 0.8
0.44, 0.72, 0.56, 1.72, 0.8
0.44, 0.77, 0.5, 1.71, 0.8
0.44, 0.82, 0.44, 1.7, 0.8
0.45, 0.5, 0.82, 1.77, 0.8
0.45, 0.55, 0.76, 1.76, 0.8
0.45, 0.6, 0.7, 1.75, 0.8
0.45, 0.65, 0.64, 1.74, 0.8
0.45, 0.7, 0.58, 1.73, 0.8
0.45, 0.75, 0.52, 1.72, 0.8
0.45, 0.8, 0.46, 1.71, 0.8
0.46, 0.53, 0.78, 1.77, 0.8
0.46, 0.58, 0.72, 1.76, 0.8
0.46, 0.63, 0.66, 1.75, 0.8
0.46, 0.68, 0.6, 1.74, 0.8
0.46, 0.73, 0.54, 1.73, 0.8
0.46, 0.78, 0.48, 1.72, 0.8
0.46, 0.83, 0.42, 1.71, 0.8
0.47, 0.51, 0.8, 1.78, 0.8
0.47, 0.56, 0.74, 1.77, 0.8
0.47, 0.61, 0.68, 1.76, 0.8
0.47, 0.66, 0.62, 1.75, 0.8
0.47, 0.71, 0.56, 1.74, 0.8
0.47, 0.76, 0.5, 1.73, 0.8
0.47, 0.81, 0.44, 1.72, 0.8
0.48, 0.54, 0.76, 1.78, 0.8
0.48, 0.59, 0.7, 1.77, 0.8
0.48, 0.64, 0.64, 1.76, 0.8
0.48, 0.69, 0.58, 1.75, 0.8
0.48, 0.74, 0.52, 1.74, 0.8
0.48, 0.79, 0.46, 1.73, 0.8
0.49, 0.52, 0.78, 1.79, 0.8
0.49, 0.57, 0.72, 1.78, 0.8
0.49, 0.62, 0.66, 1.77, 0.8
0.49, 0.67, 0.6, 1.76, 0.8
0.49, 0.72, 0.54, 1.75, 0.8
0.49, 0.77, 0.48, 1.74, 0.8
0.49, 0.82, 0.42, 1.73, 0.8
0.5, 0.5, 0.8, 1.8, 0.8
0.5, 0.55, 0.74, 1.79, 0.8
0.5, 0.6, 0.68, 1.78, 0.8
0.5, 0.65, 0.62, 1.77, 0.8
0.5, 0.7, 0.56, 1.76, 0.8
0.5, 0.75, 0.5, 1.75, 0.8
0.5, 0.8, 0.44, 1.74, 0.8
0.51, 0.53, 0.76, 1.8, 0.8
0.51, 0.58, 0.7, 1.79, 0.8
0.51, 0.63, 0.64, 1.78, 0.8
0.51, 0.68, 0.58, 1.77, 0.8
0.51, 0.73, 0.52, 1.76, 0.8
0.51, 0.78, 0.46, 1.75, 0.8
0.51, 0.83, 0.4, 1.74, 0.8
0.52, 0.51, 0.78, 1.81, 0.8
0.52, 0.56, 0.72, 1.8, 0.8
0.52, 0.61, 0.66, 1.79, 0.8
0.52, 0.66, 0.6, 1.78, 0.8
0.52, 0.71, 0.54, 1.77, 0.8
0.52, 0.76, 0.48, 1.76, 0.8
0.52, 0.81, 0.42, 1.75, 0.8
0.53, 0.54, 0.74, 1.81, 0.8
0.53, 0.59, 0.68, 1.8, 0.8
0.53, 0.64, 0.62, 1.79, 0.8
0.53, 0.69, 0.56, 1.78, 0.8
0.53, 0.74, 0.5, 1.77, 0.8
0.53, 0.79, 0.44, 1.76, 0.8
0.54, 0.52, 0.76, 1.82, 0.8
0.54, 0.57, 0.7, 1.81, 0.8
0.54, 0.62, 0.64, 1.8, 0.8
0.54, 0.67, 0.58, 1.79, 0.8
0.54, 0.72, 0.52, 1.78, 0.8
0.54, 0.77, 0.46, 1.77, 0.8
0.54, 0.82, 0.4, 1.76, 0.8
0.55, 0.5, 0.78, 1.83, 0.8
0.55, 0.55, 0.72, 1.82, 0.8
0.55, 0.6, 0.66, 1.81, 0.8
0.55, 0.65, 0.6, 1.8, 0.8
0.55, 0.7, 0.54, 1.79, 0.8
0.55, 0.75, 0.48, 1.78, 0.8
0.55, 0.8, 0.42, 1.77, 0.8
0.56, 0.53, 0.74, 1.83, 0.8
0.56, 0.58, 0.68, 1.82, 0.8
0.56, 0.63, 0.62, 1.81, 0.8
0.56, 0.68, 0.56, 1.8, 0.8
0.56, 0.73, 0.5, 1.79, 0.8
0.56, 0.78, 0.44, 1.78, 0.8
0.56, 0.83, 0.38, 1.77, 0.8
0.57, 0.51, 0.76, 1.84, 0.8
0.57, 0.56, 0.7, 1.83, 0.8
0.57, 0.61, 0.64, 1.82, 0.8
0.57, 0.66, 0.58, 1.81, 0.8
0.57, 0.71, 0.52, 1.8, 0.8
0.57, 0.76, 0.46, 1.79, 0.8
0.57, 0.81, 0.4, 1.78, 0.8
0.58, 0.54, 0.72, 1.84, 0.8
0.58, 0.59, 0.66, 1.83, 0.8
0.58, 0.64, 0.6, 1.82, 0.8
0.58, 0.69, 0.54, 1.81, 0.8
0.58, 0.74, 0.48, 1.8, 0.8
0.58, 0.79, 0.42, 1.79, 0.8
0.59, 0.52, 0.74, 1.85, 0.8
0.59, 0.57, 0.68, 1.84, 0.8
0.59, 0.62, 0.62, 1.83, 0.8
0.59, 0.67, 0.56, 1.82, 0.8
0.59, 0.72, 0.5, 1.81, 0.8
0.59, 0.77, 0.44, 1.8, 0.8
0.59, 0.82, 0.38, 1.79, 0.8
0.6, 0.5, 0.76, 1.86, 0.8
0.6, 0.55, 0.7, 1.85, 0.8
0.6, 0.6, 0.64, 1.84, 0.8
0.6, 0.65, 0.58, 1.83, 0.8
0.6, 0.7, 0.52, 1.82, 0.8
0.6, 0.75, 0.46, 1.81, 0.8
0.6, 0.8, 0.4, 1.8, 0.8
0.61, 0.53, 0.72, 1.86, 0.8
0.61, 0.58, 0.66, 1.85, 0.8
0.61, 0.63, 0.6, 1.84, 0.8
0.61, 0.68, 0.54, 1.83, 0.8
0.61, 0.73, 0.48, 1.82, 0.8
0.61, 0.78, 0.42, 1.81, 0.8
0.61, 0.83, 0.36, 1.8, 0.8
0.62, 0.51, 0.74, 1.87, 0.8
0.62, 0.56, 0.68, 1.86, 0.8
0.62, 0.61, 0.62, 1.85, 0.8
0.62, 0.66, 0.56, 1.84, 0.8
0.62, 0.71, 0.5, 1.83, 0.8
0.62, 0.76, 0.44, 1.82, 0.8
0.62, 0.81, 0.38, 1.81, 0.8
0.63, 0.54, 0.7, 1.87, 0.8
0.63, 0.59, 0.64, 1.86, 0.8
0.63, 0.64, 0.58, 1.85, 0.8
0.63, 0.69, 0.52, 1.84, 0.8
0.63, 0.74, 0.46, 1.83, 0.8
0.63, 0.79, 0.4, 1.82, 0.8
0.64, 0.52, 0.72, 1.88, 0.8
0.64, 0.57, 0.66, 1.87, 0.8
0.64, 0.62, 0.6, 1.86, 0.8
0.64, 0.67, 0.54, 1.85, 0.8
0.64, 0.72, 0.48, 1.84, 0.8
0.64, 0.77, 0.42, 1.83, 0.8
0.64, 0.82, 0.36, 1.82, 0.8
0.65, 0.5, 0.74, 1.89, 0.8
0.65, 0.55, 0.68, 1.88, 0.8
0.65, 0.6, 0.62, 1.87, 0.8
0.65, 0.65, 0.56, 1.86, 0.8
0.65, 0.7, 0.5, 1.85, 0.8
0.65, 0.75, 0.44, 1.84, 0.8
0.65, 0.8, 0.38, 1.83, 0.8
0.66, 0.53, 0.7, 1.89, 0.8
0.66, 0.58, 0.64, 1.88, 0.8
0.66, 0.63, 0.58, 1.87, 0.8
0.66, 0.68, 0.52, 1.86, 0.8
0.66, 0.73, 0.46, 1.85, 0.8
0.66, 0.78, 0.4, 1.84, 0.8
0.66, 0.83, 0.34, 1.83, 0.8
0.67, 0.51, 0.72, 1.9, 0.8
0.67, 0.56, 0.66, 1.89, 0.8
0.67, 0.61, 0.6, 1.88, 0.8
0.67, 0.66, 0.54, 1.87, 0.8
0.67, 0.71, 0.48, 1.86, 0.8
0.67, 0.76, 0.42, 1.85, 0.8
0.67, 0.81, 0.36, 1.84, 0.8
0.68, 0.54, 0.68, 1.9, 0.8
0.68, 0.59, 0.62, 1.89, 0.8
0.68, 0.64, 0.56, 1.88, 0.8
0.68, 0.69, 0.5, 1.87, 0.8
0.68, 0.74, 0.44, 1.86, 0.8
0.68, 0.79, 0.38, 1.85, 0.8
0.69, 0.52, 0.7, 1.91, 0.8
0.69, 0.57, 0.64, 1.9, 0.8
0.69, 0.62, 0.58, 1.89, 0.8
0.69, 0.67, 0.52, 1.88, 0.8
0.69, 0.72, 0.46, 1.87, 0.8
0.69, 0.77, 0.4, 1.86, 0.8
0.69, 0.82, 0.34, 1.85, 0.8
0.7, 0.5, 0.72, 1.92, 0.8
0.7, 0.55, 0.66, 1.91, 0.8
0.7, 0.6, 0.6, 1.9, 0.8
0.7, 0.65, 0.54, 1.89, 0.8
0.7, 0.7, 0.48, 1.88, 0.8
0.7, 0.75, 0.42, 1.87, 0.8
0.7, 0.8, 0.36, 1.86, 0.8
0.71, 0.53, 0.68, 1.92, 0.8
0.71, 0.58, 0.62, 1.91, 0.8
0.71, 0.63, 0.56, 1.9, 0.8
0.71, 0.68, 0.5, 1.89, 0.8
0.71, 0.73, 0.44, 1.88, 0.8
0.71, 0.78, 0.38, 1.87, 0.8
0.71, 0.83, 0.32, 1.86, 0.8
0.72, 0.51, 0.7, 1.93, 0.8
0.72, 0.56, 0.64, 1.92, 0.8
0.72, 0.61, 0.58, 1.91, 0.8
0.72, 0.66, 0.52, 1.9, 0.8
0.72, 0.71, 0.46, 1.89, 0.8
0.72, 0.76, 0.4, 1.88, 0.8
0.72, 0.81, 0.34, 1.87, 0.8
0.73, 0.54, 0.66, 1.93, 0.8
0.73, 0.59, 0.6, 1.92, 0.8
0.73, 0.64, 0.54, 1.91, 0.8
0.73, 0.69, 0.48, 1.9, 0.8
0.73, 0.74, 0.42, 1.89, 0.8
0.73, 0.79, 0.36, 1.88, 0.8
0.74, 0.52, 0.68, 1.94, 0.8
0.74, 0.57, 0.62, 1.93, 0.8
0.74, 0.62, 0.56, 1.92, 0.8
0.74, 0.67, 0.5, 1.91, 0.8
0.74, 0.72, 0.44, 1.9, 0.8
0.74, 0.77, 0.38, 1.89, 0.8
0.74, 0.82, 0.32, 1.88, 0.8
0.75, 0.5, 0.7, 1.95, 0.8
0.75, 0.55, 0.64, 1.94, 0.8
0.75, 0.6, 0.58, 1.93, 0.8
0.75, 0.65, 0.52, 1.92, 0.8
0.75, 0.7, 0.46, 1.91, 0.8
0.75, 0.75, 0.4, 1.9, 0.8
0.75, 0.8, 0.34, 1.89, 0.8
0.76, 0.53, 0.66, 1.95, 0.8
0.76, 0.58, 0.6, 1.94, 0.8
0.76, 0.63, 0.54, 1.93, 0.8
0.76, 0.68, 0.48, 1.92, 0.8
0.76, 0.73, 0.42, 1.91, 0.8
0.76, 0.78, 0.36, 1.9, 0.8
0.76, 0.83, 0.3, 1.89, 0.8
0.77, 0.51, 0.68, 1.96, 0.8
0.77, 0.56, 0.62, 1.95, 0.8
0.77, 0.61, 0.56, 1.94, 0.8
0.77, 0.66, 0.5, 1.93, 0.8
0.77, 0.71, 0.44, 1.92, 0.8
0.77, 0.76, 0.38, 1.91, 0.8
0.77, 0.81, 0.32, 1.9, 0.8
0.78, 0.54, 0.64, 1.96, 0.8
0.78, 0.59, 0.58, 1.95, 0.8
0.78, 0.64, 0.52, 1.94, 0.8
0.78, 0.69, 0.46, 1.93, 0.8
0.78, 0.74, 0.4, 1.92, 0.8
0.78, 0.79, 0.34, 1.91, 0.8
0.79, 0.52, 0.66, 1.97, 0.8
0.79, 0.57, 0.6, 1.96, 0.8
0.79, 0.62, 0.54, 1.95, 0.8
0.79, 0.67, 0.48, 1.94, 0.8
0.79, 0.72, 0.42, 1.93, 0.8
0.79, 0.77, 0.36, 1.92, 0.8
0.79, 0.82, 0.3, 1.91, 0.8
0.8, 0.5, 0.68, 1.98, 0.8
0.8, 0.55, 0.62, 1.97, 0.8
0.8, 0.6, 0.56, 1.96, 0.8
0.8, 0.65, 0.5, 1.95, 0.8
0.8, 0.7, 0.44, 1.94, 0.8
0.8, 0.75, 0.38, 1.93, 0.8
0.8, 0.8, 0.32, 1.92, 0.8
0.81, 0.53, 0.64, 1.98, 0.8
0.81, 0.58, 0.58, 1.97, 0.8
0.81, 0.63, 0.52, 1.96, 0.8
0.81, 0.68, 0.46, 1.95, 0.8
0.81, 0.73, 0.4, 1.94, 0.8
0.81, 0.78, 0.34, 1.93, 0.8
0.81, 0.83, 0.28, 1.92, 0.8
0.82, 0.51, 0.66, 1.99, 0.8
0.82, 0.56, 0.6, 1.98, 0.8
0.82, 0.61, 0.54, 1.97, 0.8
0.82, 0.66, 0.48, 1.96, 0.8
0.82, 0.71, 0.42, 1.95, 0.8
0.82, 0.76, 0.36, 1.94, 0.8
0.82, 0.81, 0.3, 1.93, 0.8
0.83, 0.54, 0.62, 1.99, 0.8
0.83, 0.59, 0.56, 1.98, 0.8
0.83, 0.64, 0.5, 1.97, 0.8
0.83, 0.69, 0.44, 1.96, 0.8
0.83, 0.74, 0.38, 1.95, 0.8
0.83, 0.79, 0.32, 1.94, 0.8
0.84, 0.52, 0.64, 2.0, 0.8
0.84, 0.57, 0.58, 1.99, 0.8
0.84, 0.62, 0.52, 1.98, 0.8
0.84, 0.67, 0.46, 1.97, 0.8
0.84, 0.72, 0.4, 1.96, 0.8
0.84, 0.77, 0.34, 1.95, 0.8
0.84, 0.82, 0.28, 1.94, 0.8
0.85, 0.5, 0.66, 2.01, 0.8
0.85, 0.55, 0.6, 2.0, 0.8
0.85, 0.6, 0.54, 1.99, 0.8
0.85, 0.65, 0.48, 1.98, 0.8
0.85, 0.7, 0.42, 1.97, 0.8
0.85, 0.75, 0.36, 1.96, 0.8
0.85, 0.8, 0.3, 1.95, 0.8
0.86, 0.53, 0.62, 2.01, 0.8
0.86, 0.58, 0.56, 2.0, 0.8
0.86, 0.63, 0.5, 1.99, 0.8
0.86, 0.68, 0.44, 1.98, 0.8
0.86, 0.73, 0.38, 1.97, 0.8
0.86, 0.78, 0.32, 1.96, 0.8
0.86, 0.83, 0.26, 1.95, 0.8
0.87, 0.51, 0.64, 2.02, 0.8
0.87, 0.56, 0.58, 2.01, 0.8
0.87, 0.61, 0.52, 2.0, 0.8
0.87, 0.66, 0.46, 1.99, 0.8
0.87, 0.71, 0.4, 1.98, 0.8
0.87, 0.76, 0.34, 1.97, 0.8
0.87, 0.81, 0.28, 1.96, 0.8
0.88, 0.54, 0.6, 2.02, 0.8
0.88, 0.59, 0.54, 2.01, 0.8
0.88, 0.64, 0.48, 2.0, 0.8
0.88, 0.69, 0.42, 1.99, 0.8
0.88, 0.74, 0.36, 1.98, 0.8
0.88, 0.79, 0.3, 1.97, 0.8
0.89, 0.52, 0.62, 2.03, 0.8
0.89, 0.57, 0.56, 2.02, 0.8
0.89, 0.62, 0.5, 2.01, 0.8
0.89, 0.67, 0.44, 2.0, 0.8
0.89, 0.72, 0.38, 1.99, 0.8
0.89, 0.77, 0.32, 1.98, 0.8
0.89, 0.82, 0.26, 1.97, 0.8
0.9, 0.5, 0.64, 2.04, 0.8
0.9, 0.55, 0.58, 2.03, 0.8
0.9, 0.6, 0.52, 2.02, 0.8
0.9, 0.65, 0.46, 2.01, 0.8
0.9, 0.7, 0.4, 2.0, 0.8
0.9, 0.75, 0.34, 1.99, 0.8
0.9, 0.8, 0.28, 1.98, 0.8
0.91, 0.53, 0.6, 2.04, 0.8
0.91, 0.58, 0.54, 2.03, 0.8
0.91, 0.63, 0.48, 2.02, 0.8
0.91, 0.68, 0.42, 2.01, 0.8
0.91, 0.73, 0.36, 2.0, 0.8
0.91, 0.78, 0.3, 1.99, 0.8
0.91, 0.83, 0.24, 1.98, 0.8
0.92, 0.51, 0.62, 2.05, 0.8
0.92, 0.56, 0.56, 2.04, 0.8
0.92, 0.61, 0.5, 2.03, 0.8
0.92, 0.66, 0.44, 2.02, 0.8
0.92, 0.71, 0.38, 2.01, 0.8
0.92, 0.76, 0.32, 2.0, 0.8
0.92, 0.81, 0.26, 1.99, 0.8
0.93, 0.54, 0.58, 2.05, 0.8
0.93, 0.59, 0.52, 2.04, 0.8
0.93, 0.64, 0.46, 2.03, 0.8
0.93, 0.69, 0.4, 2.02, 0.8
0.93, 0.74, 0.34, 2.01, 0.8
0.93, 0.79, 0.28, 2.0, 0.8
0.94, 0.52, 0.6, 2.06, 0.8
0.94, 0.57, 0.54, 2.05, 0.8
0.94, 0.62, 0.48, 2.04, 0.8
0.94, 0.67, 0.42, 2.03, 0.8
0.94, 0.72, 0.36, 2.02, 0.8
0.94, 0.77, 0.3, 2.01, 0.8
0.94, 0.82, 0.24, 2.0, 0.8
0.95, 0.5, 0.62, 2.07, 0.8
0.95, 0.55, 0.56, 2.06, 0.8
0.95, 0.6, 0.5, 2.05, 0.8
0.95, 0.65, 0.44, 2.04, 0.8
0.95, 0.7, 0.38, 2.03, 0.8
0.95, 0.75, 0.32, 2.02, 0.8
0.95, 0.8, 0.26, 2.01, 0.8
0.96, 0.53, 0.58, 2.07, 0.8
0.96, 0.58, 0.52, 2.06, 0.8
0.96, 0.63, 0.46, 2.05, 0.8
0.96, 0.68, 0.4, 2.04, 0.8
0.96, 0.73, 0.34, 2.03, 0.8
0.96, 0.78, 0.28, 2.02, 0.8
0.96, 0.83, 0.22, 2.01, 0.8
0.97, 0.51, 0.6, 2.08, 0.8
0.97, 0.56, 0.54, 2.07, 0.8
0.97, 0.61, 0.48, 2.06, 0.8
0.97, 0.66, 0.42, 2.05, 0.8
0.97, 0.71, 0.36, 2.04, 0.8
0.97, 0.76, 0.3, 2.03, 0.8
0.97, 0.81, 0.24, 2.02, 0.8
0.98, 0.54, 0.56, 2.08, 0.8
0.98, 0.59, 0.5, 2.07, 0.8
0.98, 0.64, 0.44, 2.06, 0.8
0.98, 0.69, 0.38, 2.05, 0.8
0.98, 0.74, 0.32, 2.04, 0.8
0.98, 0.79, 0.26, 2.03, 0.8
0.99, 0.52, 0.58, 2.09, 0.8
0.99, 0.57, 0.52, 2.08, 0.8
0.99, 0.62, 0.46, 2.07, 0.8
0.99, 0.67, 0.4, 2.06, 0.8
0.99, 0.72, 0.34, 2.05, 0.8
0.99, 0.77, 0.28, 2.04, 0.8
0.99, 0.82, 0.22, 2.03, 0.8
</code></pre>

<p>It seems that the closest solution is:  $w_1=0$, $w_2=0.9$, $w_3=0.52$, which gives the sum $w_1+w_2+w_3=1.42$, and maintains $t=0.8$.</p>

<p>Among all of the runs, I found this: $w_1=0$, $w_2=0.29$, $w_3=0.99$, $w_1+w_2+w_3=1.28$, $t=0.669$ --- is this a good compromise? (just an example).</p>

<p>Is there a mathematical method in identifying a solution that generally minimizes the error $((w_1+w_2+w_3) - 1)^2 + (t-0.8)^2$. Feel free to propose an alternative error metric.</p>

<h2>A preliminary guess of mine:</h2>

<p>How about finding $w_1,w_2,w_3$ that minimize $\Big(\big((w_1+w_2+w_3) - 1\big)^2 + (t-0.8)^2\Big)$?</p>

<p>Is there a way to do this using calculus?</p>
",linear_algebra
"<p>I have a cyclotomic field $\mathbb{Q}(\zeta_3)$, and want to know how I can find a minimal polynomial of  $\zeta_{10}$, and $\zeta_{12}$. I have determined that both the polynomials should be of degree 2. I am trying to use a basis argument for both of them. That is: </p>

<p>$(x+m\zeta_3)(x+n\zeta_3)=0$; here $x=\zeta_{10}$</p>

<p>$(y+p\zeta_3)(y+q\zeta_3)=0$; here $y=\zeta_{12}$</p>

<p>and trying to find some explicit restrictions for m,n and p,q. But I am having trouble doing that.</p>
",linear_algebra
"<p>Suppose I have a vector field $F(x)=Ax$ where $A$ is a matrix. How can I express $Sx$ without $A$ (use $F$ instead)? Here $S=\dfrac{A+A^T}2$ is symmetric part of $A$.</p>
",linear_algebra
"<p>Find all matrices similar <em>only</em> to themselves, i.e., $PTP^{-1}=T$ for any invertible $P$.</p>

<p>My attempt: $PT = TP$.</p>

<p>Am I going about this correctly? If so, how do I find all matrices that are commutative (where $P$ is invertible)?</p>
",linear_algebra
"<p>Let $S$ and $W$ be subsets of a vector space $V$. Show that if $S$ is a subset of $W$, then $\mathrm{span}(S)$ is a subspace of $\mathrm{span}(W)$.</p>

<p>Ok I'm finally understanding what each of these things mean.. but I'm running out of ideas on how to actually show it without using arbitrary vector space examples like Rn. Since sets and subspaces are kind of new its hard to figure out how to write correct proofs with them. </p>

<p>I can see how if $V = \mathbb{R}^3$ and $S = \{(1,1,1)\}$ and $W = \{(1,1,1), (1,1,2)\}$ then $\mathrm{span}(S) = R1(line), span(W) = R2(plane)$ and that R1 is a subspace of R2... im just having trouble showing this officially when all vector spaces and sets are completely in general....</p>

<p>I could get as far as writing out $S=(u_1,u_2,\dots,u_n)$, $u_i \in V$ and same with $W$, but I can't really figure out what else to do in this sort of proof.</p>
",linear_algebra
"<p>I know that if $L$ is a linear transformation from $V$ to $W$ where $V,W$ are finite dimensional, then we can conclude that the dimension of image (rank) of $L$ is same as that of its transpose, i.e., $L^t$.</p>

<p>But what happens when: $\dim V,\dim W=\infty$, or just one of them has infinite dimension? If there is any difference in the above statement, why such difference arises?</p>
",linear_algebra
"<p>I had a question on some h/w that asked if $row(A)=col(A)$ then $A = A^t$.</p>

<p>I answered false and found somewhere that if $A^t = - A$ then $row(A) = col(A)$</p>

<p>does this go the other way as well? </p>
",linear_algebra
"<p>Given two vectors $\vec{u}$, $\vec{v}$ indexed by $2^X$ for some finite set $X$, define $\vec{u} \star \vec{v}$ as the vector of similar type whose dimension indexed by $S \subseteq X$ is:
$$\sum_{\begin{array}{c}S = A \cup B\\[-2em]A\cap B = \emptyset\end{array}} u_A v_B\enspace.$$
<strong>Question:</strong> Does this operation have a name?  Am I seeing that from the wrong point of view?</p>

<p>As a concrete example, if $X = {1, 2}$, $\vec{u} = (x, x_1, x_2, x_{12})$ and $\vec{v} = (y, y_1, y_2, y_{12})$, where the components are, in order, indexed by $\emptyset, \{1\}, \{2\}, \{1, 2\}$, then:
$$\vec{u} \star \vec{v} = (xy,\quad x_1y + xy_1, \quad x_2y + xy_2, \quad x_{12}y + x_1y_2 + x_2y_1 + xy_{12})\enspace.$$</p>
",linear_algebra
"<p>Here's the entire question: Let $A$ be an 8 x 5 matrix of rank 3, and let $b$ be a nonzero vector in $N(A^T)$.</p>

<p><strong>a) Show that the system $Ax = b$ must be inconsistent.</strong>
Gonna take a wild stab at this one... If the rank is 3, that means the dimension of the column space is 3. But $A$ has 5 columns, so they are not all linearly independent and therefore $Ax = b$ is inconsistent.</p>

<p><strong>b) How many least squares solutions will the system $Ax = b$ have? Explain.</strong></p>

<p>On previous problems, I found the best least squares linear fit, where the approximation of $x$ was a vector that contained sometimes regular numbers, and sometimes variables. Does this mean that there must be either 1 linear solution or infinite (because you can always find an approximation)? In the example that apparently had an infinite number of least squares solutions, it appeared that one row of $A^TA$ was a constant multiple of another row, leading to a row of zeros in reduced row echelon form. From this problem I know that $A^TA$ is a 5x5 matrix, but I don't think I can prove that any rows are a scalar multiple of other rows, so I'm guessing I have to use some other means of figuring this out.</p>

<p>Sorry if I sound like I have no idea what I'm talking about. Just wanted to try out the problem to my best ability before asking about it.</p>
",linear_algebra
"<p>Sorry but I'm not a mathematician, so please bear with me.
I understand what idempotence is from a communications point of view, and am wondering if it is correct to include linear algebraic formulas as being idempotent.  After all, if <code>y= 2x</code>, then for a given input X, you always get the same result.  Is <code>y=2x</code> idempotent?</p>

<p>Cheers,
Nap</p>
",linear_algebra
"<p>Find the coordinates of bivector u⊗v with the respect to cannonical basis and basis M = ((1,2),(1,3)), u = (1,1) v=(1,-2). Please help, does it even have the solution? After the tensor multiplication the matrix is singlular?</p>
",linear_algebra
"<p>To prove: </p>

<blockquote>
  <p>A symmetric matrix has only real eigenvalues.</p>
</blockquote>

<p>For this I took a symmetric matrix $A$, an eigenvalue $k$ and an eigenvector $X$. </p>

<p>$AX=kX$</p>

<p>Taking $X$ transpose on both sides</p>

<p>$X'AX=X'kX$</p>

<p>Taking transpose</p>

<p>$(X'AX)'=(X'kX)'$</p>

<p>After solving<br>
$X'AX=k'X'X$<br>
$X'kX=k'X'X$<br>
$(k-k')X'X=0$<br>
$k-k'=0$<br>
$k=k'$</p>

<p>$k$ is equal to the transpose of $k$. How does it prove that $A$ symmetric matrix has only real eigenvalues?</p>
",linear_algebra
"<p>Cayley Hamilton Theorem states that if $A$ is an $n \times n$ matrix over the field $F$ then $p(A) = 0$.</p>

<p>We note that $p(\lambda) = \det(\lambda I - A)$. Hence, why can't we just substitute $\lambda$ with $A$ and directly prove Cayley-Hamilton Theorem by saying that $p(A) = p(\lambda) = \det(\lambda I - A) = \det(AI - A) = 0$?</p>
",linear_algebra
"<p>$x_1 - x_2 - 2x_3 + x_4 = 0 \\
-3x_1 + 3x_2 + x_3 - x_4 = 0 \\
2x_1 - 2x_2 + x_3 = 0$</p>

<p>How do I solve this system of equations? I know this is a homogenous system. 
By applying elementary row operations, I get the following:</p>

<p>$x_1 - x_2 + 1/5x_4 = 0$</p>

<p>$x_3 - \frac{2}{5}x_4 = 0$</p>
",linear_algebra
"<p>Let's assume that $V$ and $W$ are vector spaces over a field $\mathbb{K}$, $\lambda\in\mathbb{K}$, $\lambda\neq0$.</p>

<p>$S: V\rightarrow W$ and $T: W\rightarrow V$ are linear maps. Prove, that</p>

<p>$\lambda$ is an eigenvalue of $TS\iff\lambda$ is an eigenvalue of $ST$</p>

<p>What can be stated about the eigenvalues of the maps $TS$ and $ST$?
Would it also be correct if $\lambda=0$?</p>

<p>Proof:</p>

<ol>
<li>$\lambda$ is an eigenvalue of $TS\Rightarrow\lambda$ is an eigenvalue of $ST$ </li>
</ol>

<p>$TSv=\lambda v$ that is $S(TSv)=S(\lambda v)$ that is $ST(Sv)=\lambda (Sv)$</p>

<ol start=""2"">
<li>$\lambda$ is an eigenvalue of $ST\Rightarrow\lambda$ is an eigenvalue of $TS$</li>
</ol>

<p>$STw=\lambda w$ that is $T(STw)=T(\lambda w)$ that is $TS(Tw)=\lambda (Tw)$</p>

<p>I do not understand why the statement is proven by finding two eigenvectors. What would happen if we couldn't construct $Sv$ out of $v$ and $Tw$ out of $w$?
I also don't understand how to answer the latter two questions.</p>
",linear_algebra
"<p>I'm having trouble finding the Eigen values for this matrix:</p>

<p>$$ A =\begin{pmatrix} 0&amp;1&amp;-2 \\ 1&amp;3&amp;0 \\ -2&amp;0&amp;5 \end{pmatrix} $$</p>

<p>I did $A - \lambda I $ and ended up with this matrix:</p>

<p>$$ A - \lambda I =\begin{pmatrix} -\lambda&amp;1&amp;-2 \\ 1&amp;3-\lambda&amp;0 \\ -2&amp;0&amp;5-\lambda \end{pmatrix} $$</p>

<p>I then took the determinant and got $ -\lambda^3 + 8 \lambda^2 - 10\lambda - 17 $, but I don't know what I can do from here. The above polynomial is not factorable. How would I find the Eigen values? </p>
",linear_algebra
"<p>The second order equation </p>

<p>$\frac{d^2\vec{x}}{dt^2} = A\vec{x}\ + \vec{g}(t)$</p>

<p>models an earthquake's effect on a 7-story building. Let $x_j(t)$ be the displacement of the $j$th floor with respect to its equilibrium position. The ground moves with displacement $g(t)$. </p>

<p>Here</p>

<p>$\vec{x} = 
\begin{pmatrix}
x_1\\
x_2\\
\vdots\\
x_7
\end{pmatrix}$</p>

<p>$\vec{g}(t) = 
\begin{pmatrix}
g(t)\\
0\\
\vdots\\
0
\end{pmatrix}$ . </p>

<p>A <em>second</em> order $7\times7$ system in $x_j(t)$ is given by</p>

<ul>
<li>$x_1'' = 10(x_2- x_1- 1)$ </li>
<li>$x_2'' = 10(x_3- 2x_2+ x_1)$</li>
<li>$x_3'' = 10(x_4- 2x_3+ x_2)$</li>
<li>$x_4'' = 10(x_5- 2x_4+ x_3)$</li>
<li>$x_5'' = 10(x_6- 2x_5+ x_4)$</li>
<li>$x_6'' = 10(x_7- 2x_6+ x_5)$</li>
<li>$x_7'' = 10(x_6- x_7)$.</li>
</ul>

<p>Write the above second order system as a <em>first</em> order $14\times14$ system using the additional equations $v_j = x'_j$.</p>
",linear_algebra
"<p>Need some help and hints on how to prove this one:</p>

<p>Let $F=\mathbb{R}$ or $\mathbb{C}$, and $_FV=M_{n,1}(F)$. Let $A \in M_n(F)$ be Hermitian (i.e $A^* = \bar{A}^T=A$) and $f(x,y)=x^*Ay$, for all $x,y \in V$. Show that $f$ is a Hermitian form, and that $f$ is an inner product on $_FV$ if and only if all the eigenvalues of $A$ are positive. </p>

<p>I already proved that $f$ is a Hermitian form. </p>

<p>Can I have some help on the if and only if part? Thanks a lot. </p>
",linear_algebra
"<p>It's an exercise of the book Linear Algebra Done Right.
I'm not clear about how to prove these problems, would you please offer me some suggestion about how to improve this kind of ability, thanks a lot.</p>
",linear_algebra
"<blockquote>
  <p>I'm asked to find the equation of plane satisfying the given conditions:</p>
  
  <ul>
  <li>Passing through the line given by:
  \begin{cases}
x+y=2 \\
y-z=3
\end{cases}</li>
  <li>Perpendicular to the plane:
  $$
2 x+3 y+4 z=5
$$
  Knowing that the normal to the plane is 
  $2 i+3 j+4 k$</li>
  </ul>
</blockquote>

<p>I would have hade no problems finding this out if I was given the point. However I am not able to figure it out.
My first tought was to find the point where these lines intersect and then use this point to create the plane with these coinditions, 
$$
x+y-2=y-z-3\Rightarrow z=-x-1
$$</p>

<p>Which I could have expected since I am dealing with tree variables. </p>

<p>Now how could I solve this?</p>

<p>Answer should be $x+6 y-5 z=17$</p>
",linear_algebra
"<p>I am having struggle with this question.</p>

<p>suppose I have two unitary matrices.</p>

<p>Is their sum is  normal ?</p>

<p>I am try to give an example to show it is not true and I can not find.</p>

<p>I try to proof and I reach this results:</p>

<p>$T$,$S$ are unitary then:</p>

<p>$(T+S)(T+S)^{*}=(T+S)^{*}(T+S)$</p>

<p>$(T+S)(T^{*}+S^{*})=(T^{*}+S^{*})(T+S)$</p>

<p>$(T+S)T^{*}+(T+S)S^{*}=(T^{*}+S^{*})T+(T^{*}+S^{*})S$</p>

<p>$TT^{*}+ST^{*}+TS^{*}+SS^{*}=T^{*}T+S^{*}T+T^{*}S+S^{*}S$</p>

<p>$ST^{*}+TS^{*}=S^{*}T+T^{*}S$</p>

<p>and I can not continue from here.</p>

<p>I can not tell is this equation is true or not.</p>

<p>and BTW </p>

<p>matrix is unitary iff matrix is symmetric ?</p>

<p>Thanks in advanced !!</p>
",linear_algebra
"<p>Given a transition matrix of a Markov chain, $P$, I want to solve the left eigenvector of $P$, namely a row vector $\alpha$ such that
$$
\alpha P = \alpha
$$</p>

<p>I know the algorithm to solve a linear equation takes $O(n^3)$, using LU decomposition.</p>

<p>I wonder if there is any faster algorithm?</p>

<p>By the way, I may not need the exact solution, approximate one is OK.</p>
",linear_algebra
"<p>I asked this on mathoverflow as well and apologies for cross-posting. I am trying to compute this so-called bending energy matrix. The bending energy of a thin plate in 3D is given by:</p>

<p>$$
BE = \int_0^{X}\int_0^{Y}\int_0^{Z} \sum_{d=1}^{3}\left\{\left(\frac{\partial^2u_d}{\partial x^2}\right)^2+\left(\frac{\partial^2u_d}{\partial y^2}\right)^2+\left(\frac{\partial^2u_d}{\partial z^2}\right)^2 + 2\left[\left(\frac{\partial^2u_d}{\partial x \partial y}\right)^2 + \left(\frac{\partial^2u_d}{\partial x \partial dz}\right)^2 + \left(\frac{\partial^2u_d}{\partial y \partial z}\right)^2\right]\right\}dx dy dz
$$</p>

<p>Now, I am trying to embed this so that the above equation would be equal to </p>

<p>$$
BE = u'\Sigma u
$$</p>

<p>where u would be a vector that defines the components of the field $u_d$ in the bending energy equation. Now, I need to find this matrix $\Sigma$ so that the above equality can be specified. This should be a large and sparse matrix. However, I have been struggling all day to formulate the form of this matrix and what it's entries should be. I was hoping someone here might give me some pointers on how to construct this matrix.</p>

<p>I would really appreciate any help you can give me.</p>
",linear_algebra
"<p>I just started studying vectors in linear algebra, and I didn't understand the idea of the geometric description of a vector.</p>

<p><strong>Why do we treat the vector entries as coordinates?</strong> </p>

<p>As far as I understand, the entries of a column vector are the coefficients of the same variable of different equations. If I'm right on the previous sentence then why do we use them as a coordinate $(x,y)$ (for $\Bbb R^2$) and why do we treat them as different entries?</p>

<p>My English is poor, so if you didn't understand me let me try it with an example.</p>

<p>Let's say there are two equations with two variables.</p>

<p>$$\begin{align}
2x + 3y &amp;= 4 \\
x + 5y &amp;= 15 
\end{align}$$</p>

<p>$$\left[\begin{matrix} 
2 &amp; 3 &amp;|&amp; 4 \\
1 &amp; 5 &amp;|&amp; 15 
\end{matrix}\right]$$</p>

<p>If I take $(2, 1)$ as a column vector, $2$ is a run and $1$ is a rise. This is what I didn't understand as far as $2$ and $1$ are the same $x$ value, why do we use one as a run and the other as a rise? </p>

<p>Thank you.</p>

<p>correction<br />
 i just changed the 2nd entire from 1 to 3 just to make it more clear and understandable </p>
",linear_algebra
"<p>I'm learning Linear Algebra using MIT's Open Courseware <a href=""http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2005/"">Course 18.06</a></p>

<p>Quite often, the professor says ""... assuming that the matrix is invertible ..."".</p>

<p>Somewhere in the lecture he says that using a determinant on an $n \times n$ matrix is on the order of $O(n!)$ operations, where an operation is a multiplication and a subtraction.</p>

<p><strong>Is there a more efficient way?</strong>  If the aim is to get the inverse, rather than just determine the invertibility, what is the most effecient way to do this?</p>
",linear_algebra
"<p>In my AP chemistry class, I often have to balance chemical equations like the following:</p>

<p>$$ \mathrm{Al} + \text O_2 \to \mathrm{Al}_2 \mathrm O_3 $$</p>

<p>The goal is to make both side of the arrow have the same amount of atoms by adding compounds in the equation to each side.</p>

<p>A solution:</p>

<p>$$ 4 \mathrm{Al} + 3 \mathrm{ O_2} \to 2 \mathrm{Al}_2 \mathrm{ O_3} $$</p>

<p>When the subscripts become really large, or there are a lot of atoms involved, trial and error is impossible unless performed by a computer. What if some chemical equation can not be balanced?  (Do such equations exist?) I tried one for a long time only to realize the problem was wrong.</p>

<p>My teacher said trial and error is the only way. Are there other methods?</p>
",linear_algebra
"<p>What is the dimension of the space of $\{A\ {^t\!A}: A\in M(n\times n,\mathbb{R})\}$? I think it should be $n(n+1)/2$ if one knows already the dimension of the special orthogonal group, but I would love to derive the latter from the former.</p>
",linear_algebra
"<p>I have an operator</p>

<p>$$h: \mathbb R^4 \to \mathbb R^3\text{ given by } h(x, y, u, v) = (2x + 3y - u + 2v, x - 5y + 6v, 2y + u + v)$$</p>

<p>What is the easiest way to proove that this operator is linear?</p>

<p>I looked over on wiki etc., but I didn't really find the way to prove it mathematically.</p>
",linear_algebra
"<p>Homework problem.</p>

<p>Let $a_1, a_2, ..., a_n$ and $b_1,b_2,...,b_n$ be sets of real numbers.  Show that: 
$$ \left(\sum_{k=1}^n a_kb_k\right)^2 \leq \left(\sum_{k=1}^n ka_k^2\right) \left(\sum_{k=1}^n\frac{b_k^2}{k}\right)$$</p>

<p>for all $n \geq 1$.</p>

<hr>

<p>The hint given to us was not to prove this with induction, but to think of the problem ""in linear algebra terms"".</p>

<p>I've pondered this for a few days now, and come up with this: You can think of the $a$'s as a vector $\langle a_1,...,a_n\rangle$, and the $b$'s as a vector $\langle b_1,...,b_n\rangle$ and then the problem can be rephrased as inner products:
$$\langle A,B\rangle\langle A,B\rangle  \space \leq \space \langle A,A\rangle\langle K^{-1}B,B\rangle\;,$$</p>

<p>where $A$ and $B$ are defined above and $KA$ is $\langle 1a_1, 2a_2, ..., na_n\rangle$ and $K^{-1}B$ is 
$\langle 1b_1, \frac{1}{2}b_2,...,\frac{1}{n}b_n\rangle$.</p>

<p>I'm aware of the similarity with the Cauchy-Schwarz inequality, but can't figure out how to manipulate what I have any further.</p>

<p>Any insights are appreciated.</p>
",linear_algebra
"<p>This is a question from Serre's Exercise book in Matrix theory. I don't even know how to start. Any help would be appreciated. </p>

<p>Assume that the characteristic of the field $k$ is not equal to 2. Given $M \in GL_n(k)$, show that the matrix
\begin{align}
\begin{pmatrix}0_n &amp; M^{-1} \\ M &amp; 0_n\end{pmatrix}
\end{align}</p>

<p>is diagonalizable. Find its eigenvectors and eigenvalues. More generally, show that every involution ($A^2=I$) is diagonalizable. </p>
",linear_algebra
"<p>I've been working through ""Groups and Symmetry"" (Armstrong) and came across this problem in chapter 9 which I can't figure out. Any hints/help would be greatly appreciated!</p>

<p>Show that every $2\times 2$ unitary matrix has the form</p>

<p>$$
\left(\begin{array}{c c}
w &amp; z \\
-e^{i \theta} z^{*} &amp; e^{i \theta} w^{*}
\end{array}\right)
$$</p>

<p>for some $\theta\in\mathbb{R}$ and $w,z\in\mathbb{C}$. (A matrix is said to be <em>unitary</em> if it is invertible with its adjoint as the inverse. The symbol ""*"" denotes complex conjugate.)</p>
",linear_algebra
"<p>Hi could you help me with the following:</p>

<blockquote>
  <p>Show that for a symmetric positive definite matrix $B$, $$b_{ij} + b_{jk} + b_{ki} \leqslant b_{ii} + b_{jj} + b_{kk}$$ holds for any $1 \leqslant i,j,k \leqslant n$ with $b_{ij}$ being the entry at $(i,j)$ of matrix $B$.</p>
</blockquote>

<p>Thanks a lot.</p>
",linear_algebra
"<p>For any non-zero $\mathbf{y}\in\mathbb{R}^\mathcal{l}$  one half-space through origin is defined by $H_{\mathbf{y}}^{\leq}(\mathbf{0})=\left\{\mathbf{x}\in\mathbb{R}^{\mathcal{l}}:\mathbf{y}\cdot \mathbf{x}\leq\mathbf{0} \right\}$. I want to show $\mathbf{a}\in H^{\leq}_{\mathbf{y}}(0)$ iff $\mathbf{a}=\mathbf{x}-s\mathbf{y}$, where $\mathbf{x}$ is orthogonal to $\mathbf{y}$ and $s\geq 0$.</p>

<p>$\Leftarrow$ side is straightforward, but I couldn't prove $\Rightarrow$ side. I defined $x_i=a_i$ if $ y_i=0$ and $x_i=0$ if $y_i\neq 0$, but couldn't come up with something.Thanks for any help.</p>
",linear_algebra
"<p>Suppose $A$ is a $m\times n$ matrix. Show that $\mbox{rank}\,A=m$ if and only if there exists a $n\times m$ matrix $B$ such that $AB=I_m$.<br>
I have proved the case  $AB=I_m$ eventuates $\mbox{rank}\,A=m$, but the main part, the inverse, I couldn't establish.<br>
Would be grateful for your help.</p>
",linear_algebra
"<p>If $A$ and $B$ are two positive definite matrices such that $A - B$ is nonnegative definite, is it true that $B^{-1} - A^{-1}$ is positive definite?</p>

<p>The doubt came to me when working with confidence regions in multivariate statistics that are usually obtained as hyper ellipsoids.</p>
",linear_algebra
"<blockquote>
  <p>Example: Find all quadratic polynomials that are orthogonal to the function $e^x$ with respect to the $L^2$ inner product on the interval $[0,1]$.</p>
  
  <p>Solution: $p(x)=a((e-1)x-1)+b(x^2-(e-2)x)$ for any $(a,b\in\mathbb{R})$.</p>
</blockquote>

<p>The textbook didn't give any further explanations or steps.  Can someone please help me understand how to get this result??</p>
",linear_algebra
"<p>Given $\{U_i\}_{i\in\mathbb N}=\{U_1,U_2,U_3,...\}$ an infinite family of subspaces of $V$ is $\bigcap_{i\in\mathbb N}U_i$ a subspace of V?</p>

<p>I know that it's right for $n$ subspaces with a pretty simple proof, but I don't know how to deal with the infinity.</p>
",linear_algebra
"<p>How to find a matrix $A$ when you are given some parameters and the basis for the null space?</p>

<p>The problem I've been scratching my head over is this. The basis  for the null space of $A-4I$ is</p>

<p>$$\left\{
\begin{pmatrix} 1\\0\\0\end{pmatrix}, 
\begin{pmatrix} 1\\1\\1\end{pmatrix}
\right\}
$$</p>

<p>We also know that the matrix $A$ is square.</p>

<p>I'm pretty confused about what to do; this seems to be implying that there are two free variables but I'm not sure how. </p>
",linear_algebra
"<p>Let's say I have 2 linear codes, $C_1 = [n,k_1]$ and $C_2 = [n,k_2]$, and I have the parity check matricies $H_1,H_2$ for them. I use the Plotkin construction to create the code $C$ out of them (for every $u\in C_1$, $v\in C_2$, $(u|u+v)\in C$). How can I construct the parity check matrix $H$ of $C$?</p>
",linear_algebra
"<p>Assume that we have $6$ vectors in $\mathbb R^4$ such that every two of them is independent. can we generate $\mathbb R^4$ with them?</p>
",linear_algebra
"<p>I came across such an exercise:</p>

<blockquote>
  <p>Let $V$ be a linear space over $K$ such that $\dim V = n$. Show that for any $\alpha_1, \alpha_2, \dots, \alpha_m$ with $ m &gt; n + 1$ there exist
  $a_1, \dots, a_m \in K$ such that 
  $\sum_{i=1}^m a_i \triangleright \alpha_i = 0_V$
  and
  $\sum_{i=1}^m a_i = 0_K$</p>
</blockquote>

<p>But then the answer is trivial: it is $a_1 = \dots = a_m = 0$. What could've this exercise been meant to be?</p>
",linear_algebra
"<p>How do I prove or disprove if $\{1, \cos x, \cos 2x,..., \cos nx\}$ is linearly independent?</p>

<p>I tried solving the problem using the definition of linear independence,</p>

<p>$\sum_{k=0}^n a_k\cos kx = 0$</p>

<p>$\Rightarrow a_k =0 $</p>

<p>but I am not able to prove/disprove it.</p>
",linear_algebra
"<p><a href=""http://i.stack.imgur.com/MDMX0.png"" rel=""nofollow"">Question</a></p>

<p>I have some methodological questions with this exercise:</p>

<blockquote>
  <p><strong>1.</strong> You are given that the transition matric $P_{\mathcal C,\mathcal B}$ from a basis $\mathcal B=\{b_1,\ b_2,\ b_3\}$ to a basis $\mathcal C=\{c_1,\ c_2,\ c_3\}$ is
  $$\frac12\begin{bmatrix}0&amp;-1&amp;1\\-1&amp;1&amp;1\\1&amp;0&amp;0\end{bmatrix}$$</p>
  
  <p>$(a)$ Compute the vector $u=b_1+b_2+2b_3$ as a linear combination of the vectors in $\mathcal C$ and from this write down $[u]_\mathcal C$ (i.e. the coordinates of the vector $u$ w.r.t. $\mathcal C$)</p>
  
  <p>$(b)$ Calculate $P_{\mathcal B,\mathcal C}$</p>
  
  <p>$(c)$ Suppose
  $$\begin{matrix}c_1=(1,2,3),&amp;c_2=(1,2,0),&amp;c_3=(1,0,0)\end{matrix}$$
  Compute $P_{\mathcal S,\mathcal B}$, where $\mathcal S$ is the standard basis, and from this read off the explicit for of the vectors $b_1,\, b_2,\,b_3$.</p>
</blockquote>

<p>$1.a)$
The question asks to find $u$ in terms of $\mathcal C$. To do this do I simply use the transition matrix on $u$ in the form of $(1, 1, 2)$ to get $\frac12(1, 2, 1)$?<br>
If so, what would $[u]_\mathcal C$ in this case? Have we just found it?</p>

<p>$1.c)$ Do I just use the formula here? (the transition matrix one, I can't quite recall it on the spot).</p>

<p>Thanks</p>
",linear_algebra
"<p>The solution to a linear algebra problem I'm working on reads: </p>

<blockquote>
  <p>$$\det(A-\lambda I) = \det\begin{pmatrix}-\lambda &amp; 1 &amp; 0 \\ 0 &amp; -\lambda &amp; 1\\ 1 &amp; -1 &amp; 1-\lambda\end{pmatrix} = -\lambda(-\lambda(1-\lambda)+1)+1$$
  This may be written as $\lambda^2(1-\lambda)+(1-\lambda) = (\lambda^2+1)(1-\lambda)$.</p>
</blockquote>

<p>I understand how the determinant is calculated, but am struggling to understand the algebraic manipulation at the end. By my math, $-\lambda(-\lambda(1-\lambda)+1))+1$ simplifies to 
 $-\lambda(-\lambda + \lambda^2 +1)+1$, which simplifies to $(\lambda^2 - \lambda^3 - \lambda)+1$ </p>

<p>What am I misunderstanding here? </p>
",linear_algebra
"<p>Suppose there is a square binary matrix (Adjacency matrix of a graph), $A$.</p>

<p>I got that, the matrices, $A^2$ and $A^3$ are distinct but the set of eigenvalues are same for $A^2$ and $A^3$. It is to be noted that the set of eigenvalues of $A$ is different from the same of $A^2$ and $A^3$. Other powers of $A$ are same as $A^3$. </p>

<p>What does the above result interpret?</p>

<p>Please let me know. </p>

<p>Thanks in advance!  </p>
",linear_algebra
"<p>Is strict/weak negative/positive definiteness/semidefiniteness of matrices preserved under matrix addition?</p>

<p>I tried to do this for 2x2 matrix but even this wasn't easy. (I tried to use the principal minors definition of definiteness)</p>
",linear_algebra
"<p>This is the problem: Let $A$ be a real symmetric $n \times n$ matrix with non negative entries. Prove that $A$ has an eigenvector with non-negative entries</p>

<p>I looked at the answer key and don't quite understand it. In the expression containing max, why should it correspond to the eigenvalue $\lambda_0$? I thought that this may be because if Ax is parallel to x, then the dot product between $Ax$ and $x$ is maximised, but is it not possible that it still attains a large value if $A$ transforms $x$ in a way that scales x by so much that Ax is large enough to make $\langle Ax,x\rangle$ large even though they may not be parallel?</p>

<p>Solution(as in answer key):</p>

<p>Let $\lambda_0$ be the largest eigenvalue of $A$. We have</p>

<p>$$\lambda_0 = \max{\{\langle Ax, x\rangle\mid x\in\mathbb{R}^n,\|x\| = 1\}}$$</p>

<p>and the maximum it attains precisely when $x$ is an eigenvector of $A$ with 
eigenvalue $\lambda_0$. Suppose $v$ is a unit vector for which the maximum is attained, and let $u$ be the vector whose coordinates are the absolute values of the coordinates of $v$. Since the entries of $A$ are nonnegative, we have</p>

<p>$$\langle Au,u \rangle \ge \langle Ax,x\rangle =\lambda_0$$ implying that $\langle Au,u\rangle = \lambda_0$, so that $u$ is an eigenvector of $A$ for the eigenvalue $\lambda_0$.</p>
",linear_algebra
"<p>I have tried it in the following manner. We know that $$rank(XY)\ge rank(X)+rank(Y)-n$$ where $X$ and $Y$ are two matrices of order $n$ and also $$rank(XY) \le \min{\{rank(X),rank(Y)\}}$$ If we take $X=Y=A^3$ then using the above two inequalities we obtain $1\le rank(A^6)\le 2$ i.e. rank of $A^6=1 \text{ or } 2$. Is it correct at all? I have failed to obtain a definite rank of $A^6$ by the above process. Is it ok?</p>
",linear_algebra
"<p>Let $W$ be a linear subspace  of $\mathbb{R}^n$ of dimension at most $n-1$. Determine which of the following hold:<br>
(1) $W$ is nowhere dense.<br>
(2) $W$ is closed.<br>
(3) ${\mathbb{R}^n}\setminus W$ is connected.<br>
(4) $\mathbb{R}^n\setminus W$ is not connected.    </p>

<p>""$W$ is closed"" is  equivalent to saying that $W'=\mathbb{R}^n\setminus W$ is open. Now by hypothesis $W'$ is of dimension at least 1. In standard basis, this would mean that $W'$ would consist of the <em>n</em>-th column vectors whose at least one component is non-zero. Take any such $t$ in $W'$, take $\epsilon=||t||$, then i guess it is very clear that $B(t;\epsilon)$ is a subset of $W''$. So this proves that $t$ is an interior point of $W$. 
I can not do the parts. Any hint will be well appreciated. </p>
",linear_algebra
"<p>What can we conclude about a square matrix $A$ if we know the following?</p>

<ol>
<li>The characteristic polynomial of the matrix is $f(t)=(t-3)^4(t-2)^3$ and</li>
<li>$(A-2I)(A-3I)^2=0$</li>
</ol>

<p>Extracting information from 1) is easy but I don't know what to conclude from 2). Maybe something about the minimal polynomial? </p>
",linear_algebra
"<p>Find all values of $t$ such that 
$$
        \begin{pmatrix}
        t &amp; 7 \\
        3 &amp; t \\
        \end{pmatrix}
$$
is not a basis for $\mathbb{R}^2$</p>

<p>$$
        \begin{pmatrix}
        t &amp; 0 \\
        1 &amp; t \\
        \end{pmatrix}
$$
is a basis for $\mathbb{R}^2$</p>

<p>For first question I know i have to show that its either linear dependent or it's span is not $\mathbb{R}^2$ but I'm not sure how I would go about showing that. I'm new to linear algebra please help me as much as possible sorry.</p>
",linear_algebra
"<p>From the structure of this all i getting is that</p>

<blockquote>
  <p>If $V$ an n-dimensional vector space with an ordered basis
  $\beta=(x_1,x_2,x_3,\dots,x_n)$ among them (say) first $k$-vectors
  form the basis for $W$.Let $\beta*=\{f_1,f_2,f_3,\ldots,f_n\}$ be the
  dual basis for $V$, then the functional elements of$\beta* $
  corresponding to last $n-k$ vectors of $\beta$ forms the basis for
  $W^0$</p>
</blockquote>

<p>Showing $\{f_{k+1},f_{k+2},f_{k+3},\ldots,f_n\}$ is a basis for $W^0$ .</p>

<p>We know that,inorder to show $T=\{f_{k+1},f_{k+2},f_{k+3},\ldots,f_n\}$ to be a basis for $W^0$ it is sufficient to show that $\operatorname{span} T=W^0$.Since $T$ is a subset of $\beta*  $ so $T $ is linearly independent. Since $W^0$ is a subset of $V*$,every element of $f$ in $W^0$ we could write as a linear combinations of elements of $\beta*$.</p>

<p>From,here I lost the track.</p>
",linear_algebra
"<p>I am doing a self study in linear algebra and I am trying to solve the problem bellow. </p>

<blockquote>
  <p>Suppose $P$ is the projection matrix onto the subspace $\mathbf{S}$ and $Q$ is the projection onto the orhogonal complements $\mathbf{S}^{\perp}$. What are $P+Q$ and $PQ$? Show that $P-Q$ is its own inverse. </p>
</blockquote>

<p>Given $P$ and $Q$ and a vector $b$ we take the projection of $b$ onto $\mathbf{S}$ and $\mathbf{S}^{\perp}$ by $p = Pb$ and $q = Qb$ respectively. </p>

<ul>
<li><p>Geometrically, we may say that $b$ equals $p+q$, but is it possible to prove this algebraically?</p></li>
<li><p>Given $b=p+q$, we have $b = p + q = Pb+ Pq = (P+Q)b$. It seems that $P+Q=I$ but how we prove this algebraically? [taking $(I-P-Q)b=0 \implies P+Q=I$ give me doubts.]</p></li>
<li><p>Finally, applying $PQ$ in $b$ geometrically (think in 3D), $b$ projects in zero vector. How can we prove this algebraically? [taking $PQb=0\implies PQ = 0$ again does not fill very right to me.]</p></li>
</ul>

<p>Any help would by priceless.</p>

<p>Thanks.</p>
",linear_algebra
"<p>What is exact relationship between matrix R and input matrix A in QR factorization? Say, R gives the structure of A or R is a representation of A. How? We have Q'A = R. Does it mean A is projected to the subspcae of Q? If so, is R a representation of A in another space?</p>
",linear_algebra
"<p>If $A$ is a $ \displaystyle  10 \times 10 $ matrix such that $A^{3} = 0$ but $A^{2}  \neq 0$ (so A is nilpotent) then I know that $A$ is not invertible, but why does at least one eigenvalue of $A$ have to be equal to zero? How would one show that all eigenvalues of $A$ are equal to zero?</p>
",linear_algebra
"<p>$A$ is a $ \displaystyle  10 \times 10 $ matrix such that $A^{3} = 0$ but $A^{2}  \neq 0$ and therefore, by definition, $A$ is nilpotent. Is there a non-zero vector that lies in both the column space and null space of $A$? This would mean that the $\text{col}(A) \cap \text{nul}(A) \neq {0}$, right?</p>
",linear_algebra
"<p>Find the eigenvectors of
$$
A = \begin{bmatrix} 0 &amp; 2 \\ 1 &amp; 1 \end{bmatrix}.
$$
I know you can solve $ \det(A - \lambda I) = 0 $ to find the eigenvalues of $ A $, but I keep getting no free variables. However, I thought this was impossible, but I know this problem works.</p>
",linear_algebra
"<p>I'm going through Spivak's Calculus on Manifolds, and I'm currently working on Problem 2-13 part (b). The problem statement is</p>

<blockquote>
  <p>If $f,g: \mathbb{R} \rightarrow \mathbb{R}^{n}$ are differentiable and $h: \mathbb{R} \rightarrow \mathbb{R}$ is defined by $h(t) = \langle f(t),g(t)\rangle$, show that
  $h'(a) = \langle f'(a)^T,g(a) \rangle + \langle f(a),g'(a)^T \rangle.$ </p>
</blockquote>

<p>What's confusing me is that $f'(a)$ is a vector in $\mathbb{R}^{n}$ and taking its transpose yields a vector in the dual space to $\mathbb{R}^{n}$, so taking the inner product with $g(a)$, which is a vector in $\mathbb{R}^{n}$ yields a scalar in $\mathbb{R}$, corresponding to the left term in the equation. Whereas the right term in the equation is an outer product, so it sends a vector and a dual vector to a linear map in Hom($\mathbb{R}^{n}$), since the vector $f(a)$ is $n\times 1$ and the dual vector $g'(a)^T$ is $1\times n$ so their product is $n\times n$. How can these two terms be added to yield a scalar in $\mathbb{R}$?</p>
",linear_algebra
"<p>If we're given a $ \displaystyle  2 \times 2 $  Markov Matrix (so all entries are non-negative and columns add to 1) <strong>M</strong>$(a,b)$ such that $$M = M(a,b) := \begin{bmatrix}1 - a &amp; b\\a &amp; 1 - b \end{bmatrix}$$ where $a$ and $b$ are $ 0 ≤ a ≤ 1, 0 ≤ b ≤ 1$, how could you define $N := 1 - M$? I'm confused how to show that if $⟨µ,u⟩$ is an eigenpair for <strong>M</strong>, why is $⟨1 − λ,u⟩$ in an eigenpair for <strong>N</strong>?</p>
",linear_algebra
"<p>I know that generally, for any square matrix $ B $, $ \text{rank}(B^{2}) $ is less than or equal to $ \text{rank}(B) $, but I’m having trouble with this proof.</p>
",linear_algebra
"<p>I want to find possible solution satisfying both the equation:</p>

<p>$\sum_{i=1}^{n} f_i^{2} = n$</p>

<p>$\sum_{i=1}^{n} f_i=0$</p>

<p>As the number of equations less than number of variables can we just comment on some properties that solutions will have like the following below:</p>

<p>For example a possible solution to the above equation set can be(I got it by hit and trail and intuition) </p>

<p>$f_i$ =
   \begin{cases} 
      \sqrt{\frac{|\overline{A}|}{|A|}} &amp; v_i \in A \\
      \sqrt{\frac{|A|}{|\overline{A}|}} &amp; v_i \in \overline{A} \\
   \end{cases}</p>

<p>where $A$ is any set and $|A|=n$</p>
",linear_algebra
"<p>I am stuck on the following problem :  </p>

<blockquote>
  <p>Let $v_1 = (1, 0); v_2 = (1,-1) \space\text{and} \space v_3 = (0, 1).$ How many linear transformations
  $T \colon \Bbb R^2 \to \Bbb R^2$ are there such that $Tv_1 = v_2; Tv_2 = v_3$ and $Tv_3 = v_1?$ The options are as follows:   </p>
  
  <p>(A) $3!$<br>
  (B) $3$<br>
  (C) $1$<br>
  (D) $0$  </p>
</blockquote>

<p>What I observed that $v_2=v_1-v_3$ and so $T(v_2)=T(v_1)-T(v_3) \implies v_3=v_2-v_1$.<br>
But I do not know how to progress from here. Any idea?</p>
",linear_algebra
"<p>Consider the strictly convex quadratic function $f(x) = \frac{1}{2}x^tPx - q^tx + r,$ where $P \in \mathbb{R}^{n \times n}$ is a positive definite matrix, $q \in \mathbb{R}^n$ and $r \in \mathbb{R}.$ Let $\mathcal{H} := \{H: H \text{ is a }k- \text{dimensional subspace in } \mathbb{R}^n\}.$ Clearly, the restriction of $f$ to any $H \in \mathcal{H}$ is again a strictly convex function. For any $H \in \mathcal{H},$ we will use $x_H$ to denote the <em>unique</em> optimal point of the following problem</p>

<p>\begin{equation*}
\underset{x \in H}{\text{min.}} \;  f(x).
\end{equation*}</p>

<p>Now consider the map, $\psi(H) = x_H.$ </p>

<p>Prove / Disprove: The map $\psi$ is bijective.</p>

<p>Remark: It is assumed that $P$ is invertible and $q \neq \mathbf{0}.$</p>
",linear_algebra
"<p>As a follow-up of <a href=""http://math.stackexchange.com/questions/1011644/which-rings-containing-a-field-are-as-a-vector-space-over-the-field-is-i"">this question</a>, I would like to ask, what are the $2$-dimensional algebras over $\mathbb R$, $\mathbb Q$, or any arbitrary field? Can we classify them?</p>
",linear_algebra
"<p>Problem: If $A$ and $B$ are positive semidefinite matrices such that $A^2 = B^2$, show $A = B$, where $A, B$ are $n$-by-$n$ matrices.</p>

<p>This problem is taken out of Linear Algebra (4th edition) by Friedberg, Insel, and Spence. </p>

<p>EDIT: Problem is in Section $6.4$ number $17(d)$</p>

<p>Before posting my question, I looked at this specific question on the website: <a href=""https://math.stackexchange.com/questions/889963/a-b-in-lx-is-positive-semidefinition-hermitian-operators-and-a2-b2-then"">$A,B\in L(X)$ is positive semidefinition hermitian operators and $A^2=B^2$, then $A=B.$</a></p>

<p>This seems like the answer draws from materials outside this textbook. I am not familiar with the square root of a matrix as denoted in that thread. This is not a homework question, but I suspect that there should be a shorter and simpler proof (whether there is one or not) that does not draw materials outside of this textbook.</p>

<p>However, I am stumped as to show how given the hypothesis above (been at it for an hour), how I can deduce that $A = B$. I also attempted to show the contraposition but I am uncertain as how to proceed other than using the fact that there exists an orthonormal basis $\beta$ for $\mathbb{R}^n$ consisting of eigenvectors of $A$ since it is symmetric. </p>

<p>I would appreciate it if anyone can point me in the right direction. </p>
",linear_algebra
"<blockquote>
  <p>Let a linear transformation $T:\mathbb{R}^3\to \mathbb{R}^3$ defined as $T(v_1, v_2, v_3) = (v_1, v_3 - 2v_2, -v_3)$. Calculate $f(T)$ where $f(X) = -X^2 + 2 \in \mathbb{R}[X]$</p>
</blockquote>

<p>I'm not so sure how to evaluate $f(T)$. I'll be glad for an explanation.</p>

<p>Maybe $T(v)$ can be viewed as the polynomial $v_1 + (v_3 - 2v_2)x -v_3x^2$?</p>
",linear_algebra
"<p>Let $A, B \in \mathbb{R}^{m,n}$, with SVDs $A = U_A \Sigma_A V_A^T$ and $B = U_B \Sigma_B V_B^T$. I want to show that
$$
  || \Sigma_A - \Sigma_B ||_F \leq || A - U B V^T ||_F
$$ 
where $U, V$ are arbitrary unitary matrices of appropriate dimension (this exercise comes from <a href=""http://math.ecnu.edu.cn/~jypan/Teaching/books/SVD.pdf"" rel=""nofollow"">http://math.ecnu.edu.cn/~jypan/Teaching/books/SVD.pdf</a>, 17.5, problem 5). </p>

<p>I know that by unitary invariance of the Frobenius norm we have $ || B ||_F = || U B V ||_F$ for any appropriately sized $U, V$. Thus, I can show that
$$
  || \Sigma_A - \Sigma_B ||_F = || A - U_A U_B^T B V_B V_A^T ||_F
$$</p>

<p>How do I relate this to $U$,$V$? </p>
",linear_algebra
"<blockquote>
  <p>Let $A$ be some matrix over $\mathbb{Q}$ (then it's also over
  $\mathbb{R}$). Suppose $A$ is invertible over $\mathbb{R}$ (that is,
  $A^{-1}$ is over $\mathbb{R}$). Prove that $A^{-1}$ is also over
  $\mathbb{Q}$.</p>
</blockquote>

<p>I know that I have to prove that $A^{-1}$ contains no irrational numbers but I fail to do so. I would appreciate any suggestions.</p>
",linear_algebra
"<p>My task is to figure out determinant of following matrix depending on $n$.  I want to solve it without altering the rows!
$$
A^{n,n} = \begin{vmatrix} 
0  &amp;    &amp; ... &amp; 0  &amp; -1\\
   &amp;    &amp;     &amp; -1 &amp; 0 \\
   &amp;    &amp; ... &amp;    &amp;   \\
0  &amp; -1 &amp;     &amp;    &amp;   \\
-1 &amp; 0  &amp; ... &amp;    &amp;0  \\
 \end{vmatrix}
$$</p>

<p>This will be $\pm1$ depending on following two things.</p>

<ol>
<li>Multiplication of $-1$. This is simply $-1^n$</li>
<li>The number of left-down positions - 1. For $1\times1$ det is simply $(+1)*(-1)$. For $2\times2$ it's $(-1)*(1)$ and so on.</li>
</ol>

<p>So the rule should look like so:</p>

<p>$$det(A) = -1^n \times -1^{ld_positions - 1}$$</p>

<p>Now the only complicated thing was to figure out the nuber of left-down positions to know the second part. I believe it's $$\sum_{0}^{n-1}n$$ where $n$ is the matrix dimension.</p>

<p>But my solution did not pass my test calculations, so it must be wrong.</p>
",linear_algebra
"<p>Let $(\theta,A\theta)=\theta_i A_{ij}\theta_j$ where $A$ is some $(2\times2)$ antisymmetric matrix. </p>

<p>I want to generalize the following </p>

<p>$$I(A) =\int d\theta_1d\theta_2~ \exp\Bigg[\frac{1}{2}(\theta,A\theta)\Bigg]=\int d\theta_1d\theta_2~ (1+\theta_1\theta_2A_{12}) = A_{12}=\sqrt{\det A}$$</p>

<p>to the $n$-tuple case. </p>

<p>Let now $$A:=\begin{bmatrix}
0    &amp; 1       &amp; \;     &amp; \;    \\
\;-1    &amp; 0     &amp;  &amp; \;    \\     
\;     &amp; \;      &amp; 0 &amp; 1     \\
\;     &amp; \;      &amp; -1 &amp; 0     \\
\;     &amp; \;      &amp; \;     &amp; \, &amp;\ddots   \\
\end{bmatrix}.$$</p>

<p>I evaluate, I get the following 
$$I(A) = \int d\theta_n\dots d\theta_1\,\exp\Bigg[\frac{1}{2}(\theta,A\theta)\Bigg]\\ = 
\int d\theta_n\dots d\theta_1\, (\theta_1\theta_2+\theta_3\theta_4+\cdots)\\=0$$</p>

<p>The answer should be $$I(A) = 1.$$ </p>

<p>In the above I use (perhaps incorrectly?) </p>

<p>$$\int d\theta_n\dots d\theta_1\, \theta_n\dots \theta_1\, = 1 $$
and
$$\int d\theta_n\dots d\theta_1= 0. $$</p>

<p>Where do I err? </p>

<p>EDIT: I think I know how to fix this: it is the last term in the expansion of the exponential the contributes. All other terms give zero (just like the one above). I will add the solution later. </p>
",linear_algebra
"<blockquote>
  <p>Let $A \in M_2(\mathbb R)$ be a matrix which is not a diagonal matrix . Which of the following statements are true??</p>
  
  <p>a. If $tr(A)=-1$ and $detA=1$, then $A^3=I$.</p>
  
  <p>b. If $A^3=I$, then $tr(A)=-1$ and $det(A)=1$.</p>
  
  <p>c. If $A^3=I$, then $A$ is diagonalizable over $\mathbb R$.</p>
</blockquote>

<p>For (a), it is clear that $A$ will satisfy $\lambda^2+\lambda+1=0$ giving $A^2+A+I=0$. Multiplying $A$ through out gives $A^3+A^2+A=0\implies A^3=-A^2-A=I$</p>

<p>For (b), the only possibilities of eigen values are $1, \omega, \omega^2$. Now if the eigen values are only $1$ and $1$ then $A$ will satisfy $(\lambda-1)^2=0$. We already know that $A^3=I$. From these two facts it is not difficult to see that $A=kI$. Hence the only possible eigen values can be $\omega, \omega^2$. Hence (b) is true.</p>

<p>For(c), $A$ is definitely diagonalizable over $\mathbb C$. Is there any condition which would force a matrix to be diagonalizable over $\mathbb R$ when it is already diagonalizable over $\mathbb C$?</p>
",linear_algebra
"<p>In my linear algebra class, we just talked about determinants. So far I’ve been understanding the material okay, but now I’m very confused. I get that when the determinant is zero, the matrix doesn’t have an inverse. I can find the determinant of a $2\times 2$ matrix by the formula. Our teacher showed us how to compute the determinant of an $N \times N$ matrix by breaking it up into the determinants of smaller matrices, and apparently there is a way by summing over a bunch of permutations. But the notation is really hard for me and I don’t really know what’s going on with them anymore. Can someone help me figure out what a determinant is, intuitively, and how all those definitions of it are related?</p>
",linear_algebra
"<p>In least-squares approximations the normal equations act to project a vector existing in N-dimensional space onto a lower dimensional space, where our problem actually lies, thus providing the ""best"" solution we can hope for (the orthogonal projection of the N-vector onto our solution space).  The ""best"" solution is the one that minimizes the <strong>Euclidean distance (two-norm)</strong> between the N-dimensional vector and our lower dimensional space. </p>

<p>There exist other norms and other spaces besides $\mathbb{R}^d$, what are the analogues of least-squares under a different norm, or in a different space?</p>
",linear_algebra
"<p>The notion (rank-2) ""tensor"" appears in many different parts of physics, e.g. stress tensor, moment of inertia tensor, etc.</p>

<p>I know mathematically a tensor can be represented by a 3x3 matrix. But I can't grasp its geometrical picture — unlike scalar (a number) and vector (an arrow with direction and magnitude) which I can easily see what's going on.</p>

<p>How to visualize a tensor?</p>
",linear_algebra
"<p>I asked this question on Stack Overflow but it was closed as ""not programming related"". So I think this is probably the best place for it...</p>

<hr>

<p>I read over the wikipedia <a href=""http://en.wikipedia.org/wiki/Linear_programming"">article</a>, but it seems to be beyond my comprehension. It says it's for optimization, but how is it different than any other method for optimizing things?</p>

<p>An answer that introduces me to linear programming so I can begin diving into some less beginner-accessible material would be most helpful.</p>
",linear_algebra
"<p>The absolute value of a $2 \times 2$ matrix determinant is the area of a corresponding parallelogram with the $2$ row vectors as sides.</p>

<p>The absolute value of a $3 \times 3$ matrix determinant is the volume of a corresponding parallelepiped with the $3$ row vectors as sides.</p>

<p>Can it be generalized to $n-D$? The absolute value of an $n \times n$ matrix determinant is the volume of a corresponding $n-$parallelotope?</p>
",linear_algebra
"<p>I know there is a double covering map between SU(2) and SO(3) but I have no idea how I would go about proving this or showing this. </p>

<p>can someone point me in the right direction please?</p>
",linear_algebra
"<p>Let's suppose we have  a function $Y=A\cdot t^B$ and the values for $Y$ are $30,60,90,120,150$ and the values for $t$ are respectively $0.974, 1.331, 1.718, 1.971, 2.356$. Can you find $A$ and $B$ with the method of linear regression? I have to do a lab work and this is a very small part of it, which does not count but I still have to do it and I have never done linear regression, I need this now? please?</p>
",linear_algebra
"<p>Let's look at the well-known definition of orthogonal vectors:</p>

<blockquote>
  <p>Let $V$ be a vector space. Two vectors $x, y \in V$ are <em>orthogonal</em> to each other when the following condition is fulfilled: $$\langle x,y \rangle = 0$$</p>
</blockquote>

<p>Let me explain, where I see a contradiction in this definition.</p>

<p>As I understand the inner product $\langle\cdot \rangle$ of two vectors is not unambiguous (like a norm of a vector, for instance). It can be defined in many ways for different vector spaces, it just needs to satisfy <a href=""http://mathworld.wolfram.com/InnerProduct.html"" rel=""nofollow"">some properties</a>.</p>

<p>As inner product can be defined differently, it can presumably take different values for the same two vectors, depending on which 'version' of the inner product is applied to these vectors. Just analogically with the definition of the norm. Let me illustrate this on an example:</p>

<blockquote>
  <p>Consider a vector $x=(1,-3,2)^T$. Its <a href=""http://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm"" rel=""nofollow"">Euclidean norm</a> is $\lVert x\rVert_2=\sqrt {14} = 3.74\dots$, its <a href=""http://en.wikipedia.org/wiki/Norm_(mathematics)#Maximum_norm_.28special_case_of:_infinity_norm.2C_uniform_norm.2C_or_supremum_norm.29"" rel=""nofollow"">Maximum norm</a> is $\lVert x\rVert_\infty = \max(\lvert 1 \rvert, \lvert -3 \rvert, \lvert 2 \rvert) =3.$ Clearly these two norms are not equal.</p>
</blockquote>

<p>So I guess the same generalization is applied to the definition of the inner product: for some vector space it can be defined in many different ways and thus can take different values upon the applied definition. So theoretically in some special case it might happen so, that the value of an inner product of two vectors, that was defined in one way can be equal $0$ which will imply that the vectors are orthogonal, while the value of an inner product defined in another way applied to the same two vectors will not be equal $0$, which will imply that the vectors are not orthogonal. There's an obvious contradiction here. </p>

<p>There's no such contradiction in the definition of norm as there's a theorem that specifies equivalence of two norms:</p>

<blockquote>
  <p>For some finite-dimensional vector space $V$ let $\lVert x\rVert$ and $\lVert x \rVert '$, $x\in V$ be two different norms. Then $$\exists c \ge 0 \; \forall x \in V: \quad \frac 1c \lVert x\rVert ' \leq \lVert x\rVert \leq c\lVert x\rVert '$$</p>
</blockquote>

<p>Clearly when some norm evaluates for some definite vector to $0$ (thus the vector has 'zero length') any other norm will evaluate to $0$ according to the equivalence theorem. So it cannot happen so, that a zero vector can have a 'non-zero length'. </p>

<p>Therefore the one way to solve this contradiction is to prove that for some vector space $V$ an inner product is defined unambiguously. Another way would be to set an analogical theorem for inner products stating their equivalence, from which will follow, that if some inner product is evaluated to zero, all other will do so. Let's again consider Euclidean space, for which the inner product (also called dot product) is defined as $$\langle x,y \rangle = a_xa_y + b_xb_y,$$ where $a_i$ and $b_i$ are the corresponding coordinates of the vectors $x$ and $y$. This is really an inner product as it fulfills the properties. However has it been proved that in the Euclidean space there can't exist any other prescription, which, when applied to two vectors will fulfill the properties of the inner product and thus be another type of the inner product for this space? Or does some theorem exist that states equivalence of two inner products?</p>
",linear_algebra
"<p>I'm using Linear Algebra by Jim Hefferon (freely available, links below with solution).</p>

<p>I'm having trouble understanding Exercise 1.18 on page 117.</p>

<p>1.18 Decide if each is a basis for $P_2$.
(a) $(x^2 + x - 1, 2x + 1, 2x - 1)$</p>

<p>First, I try to prove that it spans $P_2$ $(ax^2 + bx + c)$. However, I do not understand how to set up the matrix. I usually do not have any trouble when there are column vectors given to me and I simply have to row-reduce using Gauss' Method, however whenever given equations with variables I have trouble. </p>

<p>Can someone walk through this step by step? That would be really helpful. I'm trying to teach myself Linear Algebra so there may be many missing gaps of knowledge.</p>

<p>Book: <a href=""http://joshua.smcvt.edu/linearalgebra/book.pdf"" rel=""nofollow"">http://joshua.smcvt.edu/linearalgebra/book.pdf</a></p>

<p>Answer Key: <a href=""http://joshua.smcvt.edu/linearalgebra/jhanswer.pdf"" rel=""nofollow"">http://joshua.smcvt.edu/linearalgebra/jhanswer.pdf</a></p>
",linear_algebra
"<p>I've just seen a proof of the statement: ""Given $\alpha$ in a commutative ring $K$ there is a unique alternating multilinear function $f$ with $f(Id)=\alpha$.""</p>

<p>The determinant is defined as the unique $f$ such that $f(Id)=1$. I don't understand why for each alternating multilinear function $f$ we have $$f(A)=\det(A)f(Id)$$</p>

<p>I would appreciate if anyone could explain me why this is true. Thanks in advance.</p>
",linear_algebra
"<p>How to find the linear transformation $T: \mathbb R^3 \to \mathbb R^3$ such that the set of all vectors satistfying $4x_1-3x_2+x_3=0$ is</p>

<p>a) Null space of $T$</p>

<p>b) Range of $T$</p>

<p>I'm not able to approach this problem.
Any help would be appreciated.</p>
",linear_algebra
"<blockquote>
  <p>Let $A$ be a square matrix of order $3$. Prove that 
  $$
\operatorname{adj}(A) 
= \tfrac{1}{2} \bigl[ 
(\operatorname{tr} A)^2 - \operatorname{tr}(A^2) \bigr] I_3 
- [\operatorname{tr} A] A + A^2
$$ 
  where $\operatorname{tr}A$ is the trace of $A$.</p>
</blockquote>

<p>To begin, I'm not quite sure how to start proving this. I've considered using brute force, but I suspect there should be a much more elegant way of doing it. Is there a need to prove this for both $(i,i)$ and $(i,j)$ entries? I'd appreciate an explanation that is not too complex. Thanks in advance!</p>
",linear_algebra
"<p>Given that $A$ is a complex square matrix of order $n$, $\lambda$ is an eigenvalue of $A$ with geometric and algebraic multiplicity $1$, and $x,y$ are entrywise nonzero vectors such that $Ax=\lambda x$ and $y^*A=\lambda y^*$. Show that every proper principal submatrix of $\lambda I-A$ has nonzero determinant.</p>

<p>I know that $\operatorname{adj}(\lambda I -A) = \gamma xy^*$ where $\gamma$ is nonzero, hence has only nonzero entries. So I know every principal submatrix of  $\lambda I-A$ of size $n-1$ has nonzero determinant. I don't know how to prove this is true for smaller principal submatrices.</p>

<p>Any help is appreciated.</p>
",linear_algebra
"<p>Assume that the following is used:</p>

<p>$$ 
A = \begin{pmatrix}
 0&amp;  1&amp;\\
 2&amp;  3&amp;\\ 
 4&amp;  5&amp;\\
 6&amp;  7&amp;\\
 8&amp;  9&amp; 
\end{pmatrix}
$$</p>

<p>Then calculating the Coveriance matrix, which, gives me:</p>

<p>$$ 
C = \begin{pmatrix}
 40&amp;  40&amp;\\
 40&amp; 40&amp;\\ 
\end{pmatrix}
$$</p>

<p>Then using the following:</p>

<p>$$
det = (a+b) \cdot (a+b)-4 \cdot(a \cdot b - c \cdot c),
$$</p>

<p>where in this case, $a = 40, b = 40, c = 40$ gives the answer:</p>

<p>$$
\lambda_{1} = 80, \\
\lambda_{2} = 0,
$$</p>

<p>These are therefore the correct Eigen values. However, using this formula, if I have the following:</p>

<p>$$ 
A = \begin{pmatrix}
 -4&amp;  -2&amp;\\
 -1&amp;  -3&amp;\\ 
 4&amp;  5&amp;\\
 6&amp;  7&amp;\\
 8&amp;  9&amp; 
\end{pmatrix},
$$</p>

<p>where the Covariance matrix is given: </p>

<p>$$
C = \begin{pmatrix}
 99.2&amp;  103.4&amp;\\
 103.4&amp; 116.8&amp;\\ 
\end{pmatrix},
$$</p>

<p>gives the Eigenvalues as: </p>

<p>$$
\lambda_{1} = 218.119 \\
\lambda_{2} = -15.5189
$$</p>

<p>When the actual values are:
$$
\lambda_{1} =211.774 \\
\lambda_{2} = 4.226
$$</p>

<p>Could anyone tell me where I am calculating this wrong please?</p>

<p>EDIT:</p>

<p>For
$\lambda_{1} = (a + b + det)/2 \\
 \lambda_{2} = (a + b - det)/2
$</p>
",linear_algebra
"<p>I have a 10x10 symmetrical variance-covariance matrix, such that the variances for 10 vectors are on the main diagonal and the covariance between all vectors are on the off-diagonals.</p>

<p>I want to quantify the amount of variance in total. I can easily take the matrix trace as the sum of the eigenvalues on the main diagonal.</p>

<p>However, the matrix can be split into meaningful (biologically meaningful, in my case) sub-matrices: 4 submatrices, 5x5 each, in each corner of the original matrix. If I then want to quantify the variation within each sub-matrix  using the matrix trace, I run into some trouble with the top-right/bottom-left sub-matrices. These are formed of covariance estimates and are therefore not necessarily positive. My question is, what is the correct way to calculate the matrix trace here? If I sum the eigenvalues, I will have some negative values subtracting from the total, so should I use absolute values? Is the matrix trace the best method to use here or is there a more appropriate way of summarising the amount of variance in the sub-matrices?</p>

<p>Any guidance would be gratefully received.</p>

<p>Thanks,</p>

<p>Fiona </p>
",linear_algebra
"<ol start=""2"">
<li>Find matrix of a given linear transformation L->M in given new bases:</li>
</ol>

<p>a) $L =&lt; e_1,e_2,e_3 &gt;, M =&lt; g_1,g_2 &gt;, f(e_1) = g_1 − 2g_2, f(e_2) = g_1 + g_2, f(e_3) = 2g_1 + 3g_2,
$
$
\bar e_1 = 2e_1 − e_3, \bar e_2 = e_2 + e_3,  \bar e_3 = e_1 − e_2, \bar g_1 = g_1 + 2g_2, \bar g_2 = 2g_1 − g_2
$$</p>

<p>I know similar questions have been asked but they didn't help me because I am unsure if my data matches the data in the other answers. Please note there is a difference between $e_1$ and $\bar e_1 $.</p>
",linear_algebra
"<p>What is the dimension of a kernel with the basis {[0,0,0]}?</p>

<p>I'm confused because the definition of the dimension is number of vectors in a basis. So there is 1 vector here which is [0,0,0]. </p>

<p>Why does my professor say that the dimension of kernel is zero? He mentioned something about the zero vector space.</p>
",linear_algebra
"<p>Let $T$ be the Toeplitz operator on $\ell_p$ with symbol $\alpha(\lambda)=a/2\cdot \lambda-(a+1/2)+\lambda^{-1}$, where $a$ is complex. I want to solve the following </p>

<p>$$
Tx=y
$$</p>

<p>for $x\in \ell_p$ and $y=(1,q,q^2,\ldots),|q|&lt;1$. Therefore, I (Wiener-Hopf) Factorized the symbol:</p>

<p>$$\alpha(\lambda)=\alpha_{-}(\lambda)\alpha_{+}(\lambda)=(1/2-\lambda^{-1})(a\lambda-1).$$</p>

<p>So, $T^{-1}=T_{\alpha_+^{-1}}T_{\alpha_-^{-1}}$ (only if $a\not=1/\lambda$, not sure if this is true though. When is $T$ one-sided invertible?). Hence (again, not sure),</p>

<p>$$T^{-1}= 2a(S-2I)^{-1}(I-aS_{backw.})^{-1}$$</p>

<p>Now, I want tot compute $T^{-1}y$ to obtain $x$, but I got stuck here. Any hints? My second question is: How is the spectrum of $T$ defined, is there an easy way to compute $\sigma(T)$?</p>
",linear_algebra
"<p>I am asked to determine all faces of the $n$-dimensional hypercube
$$C_n = \left\lbrace x\in\mathbb R^n \;|\;\forall i\in\lbrace1\ldots n\rbrace : |x_i|\leq1\right\rbrace $$</p>

<p>I already know that the the $k$-dimensional faces of $C_n$ are defined by $n-k$ equalities $|x_i|=1$. <br/>
So in total there are $2^{n-k}{n\choose k}$ of those $k$-dimensional faces.</p>

<p>I understand how those faces look like and for a fixed particular $n$ I would be able to write them all down one by one, but I am struggeling to write down some general expression for all faces.</p>
",linear_algebra
"<p>Find a basis of subspace $ U_1 +U_2 $ of a vector space $V$. $ U_1, U_2 \subseteq V$:
$V = \mathbb R[t]$, $U_1 = \{ f \mid t^2-4t+3 \text{ divides } f \}, U_2 = \{g \mid t^2-5t+4 \text{ divides } g\}. $</p>
",linear_algebra
"<p>I don't understand this really good and couldnt find anything helpful on internet. I only found in book the following: A is the matrix with reflection over line through the origin with direction vector $\left(\cos(\frac{\alpha }{2} ) , \sin(\frac{\alpha }{2} ) \right) ^{T}$
$A=\begin{pmatrix} \cos(\alpha ) &amp; \sin(\alpha ) \\ \sin(\alpha )  &amp; -\cos(\alpha )    \end{pmatrix}$
I'm not sure how to connect this from book to solve it, because there is another direction vector.</p>
",linear_algebra
"<p>How to prove that $\det(A^{T}A) \neq 0$ if coloumns of $A$ are linearly independent, without using Cauchy-Binet formula? $A$ is real matrix.</p>
",linear_algebra
"<p>How do I prove this proposition:</p>

<blockquote>
  <p>If $A$, $B$ are similar matrices then for every $\lambda$ $\in$
  $\mathbb{R}$ the matrices $A-\lambda I$ and $B-\lambda I$ are similar.</p>
</blockquote>

<p>Now, from what I was given I know $A = P^{-1} B P$ and $B = PBP^{-1}$, and</p>

<p>I need to show that $A-\lambda I = M^{-1} (B-\lambda I)M$ and I am done.</p>

<p>I can't see how to solve this, I hope someone does,</p>

<p>Thank you in advance.</p>
",linear_algebra
"<p><strong>For 5 months!</strong> I have been struggling to solve the following equations analytically without numeric method (i,e, Newton method):</p>

<blockquote>
  <p><strong>Main equation:</strong></p>
  
  <p>$$
 \biggl(M^2-\cfrac{\mathbf{x^{\text{T}}}M^2\mathbf{x}}{\mathbf{x^{\text{T}}}\mathbf{x}}E\biggr)\mathbf{x}=\mathbf{1}
$$</p>
  
  <p><strong>Constraint equations:</strong></p>
  
  <p>$$
\begin{cases}
 \mathbf{x^{\text{T}}1}=0 \\
\\
\mathbf{x^{\text{T}}x}=u 
\end{cases} $$</p>
  
  <p>where $\{M,E\}\in\mathbf{R}^{n \times n}$ and $\{\mathbf{1},\mathbf{x}\}\in\mathbf{R}^n$ are defined, then $M$ is an arbitrary symmetric matrix, $E$
  is an identical matrix,
  $\mathbf{1}$ is all one vector, $\mathbf{x}$ is a
  variable vector and $u\in\mathbf{R}$ is a scalar.
  Furthermore, as a knowledge, the below equation form is called <a href=""https://en.wikipedia.org/wiki/Rayleigh_quotient"" rel=""nofollow"">Rayleigh
  quotient</a> $R(M^2,\mathbf{x})$:</p>
  
  <p>$$R(M^2,\mathbf{x}):=\cfrac{\mathbf{x^{\text{T}}}M^2\mathbf{x}}{\mathbf{x^{\text{T}}}\mathbf{x}}$$</p>
</blockquote>

<p>Now, we attempt to estimate the $\mathbf{x}$. Does the analytic solution or method exist? My ability is shortage but, I guess that this problem has a beautiful solution. Also, main equation is a simultaneous cubic equation. Theoretically, this is solvable. Just, this is my theme question.</p>

<p>Furthermore, same question is already asked on <a href=""http://mathoverflow.net/questions/238431/explicit-solution-to-a-rayleigh-quotient-equation"">math overflow</a>. Then answerers provided worthful information which may be solution to clue. </p>
",linear_algebra
"<p>The property states, ""A square matrix A is invertible iff it can be written as the product of elementary matrices""</p>

<p>I'm confused on the part of the theorem where they're trying to show that if A is invertible, then it can be written as the product of elementary matrices.</p>

<p>This is that section of the proof:</p>

<p>""Assume A is invertible. You know the system of linear equations represented by Ax=0 has only the trivial solution. But this implies that the augmented matrix [A 0] can be rewritten in the form [I 0] (using elementary row operations corresponding to E<sub>1</sub>,E<sub>2</sub>,...,E<sub>k</sub>). So, E<sub>k</sub>,...,E<sub>2</sub>,E<sub>1</sub>A I and it follows that A = E<sub>1</sub>-1E<sub>2</sub>-1...E<sub>k</sub>-1 . A can be written as the product of elementary matrices.""</p>

<p>I just don't get how knowing that Ax=0 has only the trivial solution implies that [A 0] can be written in the form [I 0]. Wasn't it already obvious that A can be rewritten as I since it's invertible? And obviously if there's a 0 matrix adjoined A to it it's going to stay the zero matrix no matter what row operations are done on it? What's the point of doing that?</p>

<p>I'm just generally confused on this proof</p>
",linear_algebra
"<p>Compute $det(OE[A](t))$ with $tr(A)=0$, where $OE[A]$ is defined <a href=""http://en.wikipedia.org/wiki/Ordered_exponential"" rel=""nofollow"">here</a>.</p>

<p>Attempt: First I computed the following derivative $\frac{d}{dt}det(OE[A](t))=tr((OE[A])^{-1}\frac{d}{dt}OE[A])det(OE[A](t))$. Since the ordered exponential can be written as a product of infinitesimal exponentials, I can use the product rule and simplify:
$tr((OE[A])^{-1}\frac{d}{dt}OE[A])=tr(\Delta t \sum_{i=1}^\infty A(t_i))=\Delta t \sum_{i=1}^\infty tr(A(t_i))=0$. Hence the determinant is independent on the parameter $t$ and now I choose $t=0$ (it's arbitrary) and get $det(OE[A](t))=1$.</p>

<p>Are there built errors? Are there formulas for the determinant of a ordered exponentials?
Hints would be greatly appreciated.</p>
",linear_algebra
"<blockquote>
  <p>Suppose $A,B$ are $n\times n$ positive definite. Then which of the followings are positive definite:</p>
  
  <ol>
  <li><p>$A+B$</p></li>
  <li><p>$ABA$</p></li>
  <li><p>$A^2+I$</p></li>
  <li><p>$AB$</p></li>
  </ol>
</blockquote>
",linear_algebra
"<p>I would like if someone could look over my proof. It feels odd to me.</p>

<blockquote>
  <p>Let $W$ be a subspace of a vector space $V$ over a field $F$. Prove that $v + W = \{v + w \mid w \in W\}$ is a subspace of $V$ if and only if $v \in W$.</p>
</blockquote>

<p><strong>Proof:</strong> ($\Rightarrow$) Suppose $v + W$ is a subspace of $V$. Note that $v = v + 0_W \in v + W$ and as a result $(-1)v = -v \in v + W$ as $v + W$ is a subspace. Therefore, $-v = v + w$ for some $w \in W$. Solving for $w$, we get $w = -2v$ and since $W$ is a subspace $(\frac{-1}{2})w = (\frac{-1}{2})(-2v) = v \in W$ as desired. </p>

<p>($\Leftarrow$) Suppose $v \in W$. As $W$ is a subspace, $-v \in W$ and therefore $0 = v + (-v) \in v + W$. If $x, y \in v + W$ then $x = v + w$ and $y = v + w'$ for some $w,w' \in W$. Then $x + y = (v + w) + (v + w') = v + (v + w + w') \in v + W$ as $v,w,w'\in W$ and $W$ is a subspace. Furthermore, note that $cx = c(v + w) = cv + cw = v + (cv + cw - v) \in v + W$ as $v,w \in W$ and $W$ is a subspace. Therefore, $v + W$ is a subspace of $V$ as it contains the $0$ element and it is closed under addition and scalar multiplication. $_\Box$</p>

<p>I'd appreciate any feedback. Thank-you. </p>
",linear_algebra
"<p>I am trying to optimize the output of a given neural network with a single hidden layer.  To accomplish this, I intend to find solve for all combinations of inputs where the derivative of the neural network = 0 and select the input vector with the highest (or lowest, depending on the problem) neural network output.  It uses the activation function</p>

<p>$$
H_i,_j = \frac{1}{(1 + e^{-t})}
$$</p>

<p>where </p>

<p>$$
t = X_i\theta_j
$$</p>

<p>for a given input vector i and hidden node j. </p>

<p>The activation values of each hidden node are multiplied by a separate weight matrix to produce the outputs.  The output k of a given input vector i is the product of the hidden node activation values i and the weight vector k.</p>

<p>$$
O_i,_k = H_iW_k
$$</p>

<p>Could someone please explain the steps I would use to create the derivative formula for an input vector of arbitrary length, an arbitrary number of hidden nodes, a single hidden node layer, and a given output k?  Thank you so much.</p>
",linear_algebra
"<p>I've a task to find the distance in $E^4$ between:</p>

<p>$L = [1,2,-1,4] + \text{lin}((1,2,-1,0))$</p>

<p>and</p>

<p>$M = [2,3,1,5] + \text{lin}((2,1,0,2))$</p>

<p>My efforts to find the correct solution:</p>

<p>Let</p>

<p>$\alpha_{1}=(1,2,-1,0)
 , \alpha_{2}=(2,1,0,2)$</p>

<p>$p_{0}=[2,3,1,5]$</p>

<p>$p\in R^{4}
  p\in L$</p>

<p>$p=(1+t,2+2t,-1-t,4)$</p>

<p>$\overrightarrow{p_{0}p}=(t-1,2t-1,2t,-1)$</p>

<p>$f(t)=
 d(p,M)$</p>

<p>Then (W is a determinant of grammian matrix)</p>

<p>$f(t)=\sqrt{\frac{W(\alpha_{2},\overrightarrow{p_{0}p})}{W(\alpha_{2})}}$</p>

<p>$&lt;\alpha_{2},\alpha_{2}&gt;=3$</p>

<p>$W(\alpha_{2})=3$</p>

<p>$W(\alpha_{2},\overrightarrow{p_{0}p})=\det\left(\begin{array}{cc}
&lt;\alpha_{2},\alpha_{2}&gt; &amp; &lt;\alpha_{2},\overrightarrow{p_{0}p}&gt;\\
&lt;\overrightarrow{p_{0}p},\alpha_{2}&gt; &amp; &lt;\overrightarrow{p_{0}p},\overrightarrow{p_{0}p}&gt;
\end{array}\right)$</p>

<p>$&lt;\overrightarrow{p_{0}p},\overrightarrow{p_{0}p}&gt;=\sqrt{(t-1)^{2}+(2t-1)^{2}+4t^{2}+1}=\sqrt{t^{2}-2t+1-4t^{2}+1+4t^{2}+1}=\sqrt{t^{2}-2t+1}=\sqrt{(t-1)^{2}}=t-1$</p>

<p>$&lt;\alpha_{2},\overrightarrow{p_{0}p}&gt;=&lt;\overrightarrow{p_{0}p},\alpha_{2}&gt;=\sqrt{2t-2+2t-1-2}=\sqrt{4t-5}$</p>

<p>$W(\alpha_{2},\overrightarrow{p_{0}p})=\det\left(\begin{array}{cc}
3 &amp; \sqrt{4t-5}\\
\sqrt{4t-5} &amp; \mid t-1\mid
\end{array}\right)=\\3\cdot\mid t-1\mid-\mid4t-5\mid=\begin{cases}
-3t+3+4t-5 &amp; \iff t&lt;1\\
3t-3+4t-5 &amp; \iff t\in[1,\frac{5}{4})\\
3t-3-4t+5 &amp; \iff t&gt;\frac{5}{4}
\end{cases}=\begin{cases}
t-2 &amp; \iff t&lt;1\\
7t-8 &amp; \iff t\in[1,\frac{5}{4})\\
-t+2 &amp; \iff t\geq\frac{5}{4}
\end{cases}$</p>

<p>From that I noticed, that distance can be negative, and I don't know how to fix it</p>

<p>Could you help me to point, where I made an error in reasoning?</p>

<p>Thanks in advance for all advices! </p>
",linear_algebra
"<p>We are given the following problem:</p>

<blockquote>
  <p>Let $S$ be the set of all functions $y$ that satisfy the following differential equation
  $$2\dfrac{d^2y}{dx^2}  - 3\dfrac{dy}{dx} + y = 0.$$
  Show that $S$ is a subspace of the vector space $A$, where $A$ is the set of all functions $f : \mathbb{R} \rightarrow \mathbb{R}$.</p>
</blockquote>

<p>I do not know how to approach the problem.</p>
",linear_algebra
"<p>So I was able to figure out the first part of this problem, but I have no concept of how it relates to Schur complements, so I'm not sure (no pun intended) how to proceed. The question is as follows:</p>

<p>Consider $2x^2 + 2xy + 2y^2 + z^2 + 2xz$. Write the symmetric matrix representing this quadratic form. Now, express this as a sum of squares by using this symmetric matrix and Schur complements.</p>

<p>I determined the symmetric matrix representation as:</p>

<p>$$\begin{bmatrix}
        2 &amp; 1 &amp; 1 \\
        1 &amp; 2 &amp; 1 \\
        1 &amp; 0 &amp; 1 \\
        \end{bmatrix} $$</p>

<p>And that's as far as I've gotten. Any help would be much appreciated.</p>
",linear_algebra
"<p>If we're given a $ \displaystyle  2 \times 2 $  Markov Matrix (so all entries are non-negative and columns add to 1) <strong>M</strong>$(a,b)$ such that $$M = M(a,b) := \begin{bmatrix}1 - a &amp; b\\a &amp; 1 - b \end{bmatrix}$$ where $a$ and $b$ are $ 0 ≤ a ≤ 1, 0 ≤ b ≤ 1$, I know that $λ1 = 1$ is an eigenvalue for $M(a,b)$, but how would I find a corresponding eigenvector $u_{1}(a, b)$ such that when normalized, $e^{T}u1(a, b) = 1$? There should also be a second eigenvalue / eigenvector right?</p>
",linear_algebra
"<p>Let T:P2->P2 be a linear transformation and A be the matrix of the linear transformation. Prove that if det(A) does not equal 0 then T is one-to-one.</p>

<p>I know that for T to be 1-1 then the kernel is a zero vector and therefore A would reduce to an identity matrix I'm just not sure how to tie that into the determinant?</p>
",linear_algebra
"<p>Define a function $ T: P_{3} \to \text{M}_{2 \times 2} $ by
$$
  T \! \left( a_{0} + a_{1} x + a_{2} x^{2} + a_{3} x^{3} \right)
= \begin{pmatrix} a_{3} &amp; a_{0} \\ a_{2} &amp; a_{1} \end{pmatrix}.
$$
I know how to show that $ T $ is a linear transformation, i.e.,
$$
T(\vec{u} + k \cdot \vec{v}) = T(\vec{u}) + k \cdot T(\vec{v}).
$$
I also know how to show that $ T $ is an isomorphism (one-to-one and onto), but how do I find the matrix representation of $ T $ with respect to the standard bases of $ P_{3} $ and $ \text{M}_{2 \times 2} $?</p>
",linear_algebra
"<p>I am not seeing why a subspace must include $ 0 $. From what I am told, this inclusion means that the subspace is not “empty”, but I cannot see how the inclusion of $ 0 $ does this. For instance, can you not have a subspace of $ \Bbb{R}^{2} $ that is a line represented by $ y = x + 1 $, which will not intersect $ (0,0) $ of $ \Bbb{R}^{2} $ at all? This subspace appears to exists and to be an element of $ \Bbb{R}^{2} $ by addition and scalar multiplication, but unless I am mistaken, it does not satisfy this $ 0 $-vector inclusion requirement (unless this means it is NOT a subspace, but then that is not making sense).</p>
",linear_algebra
"<p>I'm having a bit trouble with this excercise:</p>

<p><strong>The problem:</strong><br>
Let there be a polynomial $f(x)=a_1x^{t_1} + a_2x^{t_2} + ... + a_nx^{t_n}$
Where $t_1, t_2, ..., t_n$ are not-negative integers.
The polynomial has a root $b$ which occurs $n$ times.
Prove that $b = 0$.</p>

<p><strong>What I have so far:</strong><br>
I can presume that $a_1, a_2, ..., a_n \neq 0$<br>
If $n = 1$, then it's obviously true.<br>
If $n = 2$, I tried using this:<br>
$f^{(n-1)}(b) = 0
\\
f^{(n)}(b) = 0$<br>
So:<br>
$f(b) = a_1b^{t_1} + a_2b^{t_2} = 0
\\
f'(b) = t_1*a_1b^{(t_1-1)} + t_2*a_2b^{(t_2-1)} = 0
\\
f''(b) = (t_1-1)t_1*a_1b^{(t_1-2)} + (t_2-1)t_2*a_2b^{(t_2-2)} \neq 0$<br>
Why can't $b \neq 0$ be true?</p>
",linear_algebra
"<p>Let $V$ be a vector space of dimension $n$ over $\mathbb{F}_q$, and let $U$ be a subspace of dimension $k$. I want to compute the number of subspaces $W$ of $V$ of dimension $m$ such that $W\cap U=0$.</p>

<p>I know why the number of subspaces of $V$ that contain $U$ and have dimension $m$ is $\binom{n-k}{m-k}_q$, but I don't understand why $q^{km}\binom{n-k}{m}_q$ is number of these subspaces?</p>
",linear_algebra
"<p>how to prove $\|(A^HA)^k\| =||A||^{2k}$ using singular value decomosition. $A^H$ is a hermitian matrix. $A$ element of $C^{p\times q}$, for every positive integer $k$.</p>
",linear_algebra
"<p>Suppose one has the following system of linear equations
$$(A + \Delta A) x = b$$
where $A$ and $\Delta A$ are large sparse matrices and $\Delta A$ is ""small"" compared to $A$, furthermore vector $x$ is unknown (the solution) and vector $b$ is known. </p>

<p>The system needs to be solved many times, in which only $\Delta A$ varies (the perturbation). Therefore it is relatively cheap to obtain $A^{-1}$ and may be considered to be known.</p>

<p>The best solution I've found thus far is to apply the Neumann series expansion on the inverse
$$A(I + A^{-1} \Delta A) x = b$$
$$A(I + P) x = b$$
$$\Rightarrow \quad x = (I + P)^{-1} A^{-1} b = \lbrace I - P + P^2 - P^3 + \cdots \rbrace A^{-1} b$$</p>

<p>Does any one know of a better alternative, preferably a method that doesn't require a series expansion?</p>
",linear_algebra
"<p>I have a polynomial $p_a(x,y)= x^2F(a)+y^2G(a)-xH(a)-I(a)$ where $F(a)$, $G(a)$, $H(a)$ and $I(a)$ some real fuctions of $a$ are. Which conditions must satisfy $a$ so that I can factorize the polynomial $p_a(x,y)$ in lineal real factors?</p>
",linear_algebra
"<p>If both roots of the equation $(a-b)x^2+(b-c)x+(c-a)=0$ are equal, prove that $2a=b+c$.</p>

<blockquote>
  <p><strong>Things should be known:</strong></p>
  
  <ul>
  <li><p>Roots of a Quadratic Equations can be identified by:</p>
  
  <p>The roots can be figured out by: 
  $$\frac{-b \pm \sqrt{d}}{2a},$$ 
  where
  $$d=b^2-4ac.$$</p></li>
  <li><p>When the equation has equal roots, then $d=b^2-4ac=0$.</p></li>
  <li><p>That means $d=(b-c)^2-4(a-b)(c-a)=0$</p></li>
  </ul>
</blockquote>
",linear_algebra
"<p>My question is: </p>

<p>How to solve this equation:</p>

<p>$ax²+by²+cxy=0$</p>

<p>with respect to $x$ and $y$ in the same time. Here $a,b,c$ are real constants.</p>
",linear_algebra
"<p>How would one go about proving that there is no embedding of a vector space into it's dual that is independent of a choice of basis? Thanks</p>
",linear_algebra
"<p>Given the matrix $A= \begin {pmatrix} 1 &amp; 1 &amp;1  \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; 2 &amp;1 \end{pmatrix}$.</p>

<p>(i) Determine the orthogonal projection $p:\mathbb{R}^3 \rightarrow \mathbb{R}^3$ on $Im(A)$</p>

<p>(ii) Calculate an orthonormal basis of $(\ker(A))^{\perp}$</p>

<p>(iii) Determine the pseudoinverse $A^+$ of $A$</p>

<p>I was wondering about the sequence of the subtasks. Normaly, i would do (iii) first and then (i) &amp; (ii) using that $AA^+:\mathbb{R}^m\rightarrow Im (A)$ and $A^+A:\mathbb{R}^n\rightarrow(\ker(A))^{\perp}$. So my question is: Is there a way to to (i) and (ii) without determine the pseudoinverse?</p>
",linear_algebra
"<p>$T:P(\mathbb{R}) \mapsto P(\mathbb{R})$ defined by</p>

<p>$(Tp)(x) = x^2p(x)$</p>

<p>Verify that multiplication by $x^2$ is a linear map.</p>

<p>Additivity: $x^2(p+q) = x^2p+x^2q$</p>

<p>Homogeneity: $x^2(ap) = a(x^2p)$</p>

<p>Is this a correct verification?</p>
",linear_algebra
"<p>Let $$V=\{x \in \mathbb{R} : x&gt;0\}$$</p>

<p>For $x,y,a \in \Bbb{R}$, define $x\oplus y=xy$ and $x\odot a=x^a$. Is $V$ a vector space under these operations? Justify your answer.</p>
",linear_algebra
"<p>I know that normally for commutators that [A,B]=-[B,A] where A and B are operators.  But under what conditions does [A,B]=[B,A]?</p>
",linear_algebra
"<blockquote>
  <p>Can someone give me some examples of unit vectors that's in the same direction as vector, let's say $v=(1,2,-3)^T$ for:</p>
</blockquote>

<p>(i) Euclidean norm</p>

<p>(ii) Weighted norm $||V||^2=2V_1^2+v_2^2+\frac13v_3^2$</p>

<p>(iii) The 1 norm</p>

<p>(iv) The infinite norm</p>

<p>(v) The norm based on their inner product $2v_1w_1-v_1w_1-v_2w_1+2v_2w_2-v_2w_3-v_3w_2+2v_3w_3$.</p>

<p>Ty.</p>
",linear_algebra
"<p>How can I show that for a particle in an infinite square well in a stationary state, that the expectation value $\langle[\hat{H},\hat{O}]\rangle=0$ where $\hat{H}$ is the Hamiltonian operator and $\hat{O}$ is an arbitrary operator?</p>
",linear_algebra
"<p>I'm studying for an exam and I don't understand how my prof finds the basis for eigenspaces using the matrix representation of a linear map. Once I find an eigevalue then how do I find the basis for its eigenspace. I've attached a screenshot of the part that I don't understand (from an example). Can someone please explain it to me in detail? Thanks<img src=""http://i.stack.imgur.com/78iPC.png"" alt=""![enter image description here"">]<a href=""http://i.stack.imgur.com/78iPC.png"" rel=""nofollow"">1</a></p>
",linear_algebra
"<blockquote>
  <p>Even if an isomorphism between two linear spaces $L$ and $M$ over a field $\mathbb{K}$ exists, it is defined uniquely only in two cases:</p>
  
  <ol>
  <li><p>$L=M=\{0\}$ and</p></li>
  <li><p>$L$ and $M$ are one-dimensional, while $\mathbb{K}$ is a field consisting of two elements.</p></li>
  </ol>
</blockquote>

<p>How can I show this fact? Does anyone have any hints?</p>
",linear_algebra
"<p>I would like to generate a semi-unitary matrix, i.e., $UU^T=~I$ where U is a non-square matrix whose number of rows is bigger than its number of columns.
I tried it by solving the optimization problem $\min_U\|UU^T - I\|_F$ but didn't work at all since the problem is not convex. </p>
",linear_algebra
"<p>I have a question:
Suppose I have a  $n\times n$ matrix:
$$
        \begin{bmatrix}
        1 &amp; 1 &amp;...&amp; 1 \\
        1 &amp; 1 &amp;...&amp;1 \\
        \vdots&amp;\vdots &amp;\ddots &amp; \vdots&amp;\\
        1 &amp; 1 &amp; ...&amp;1 \\
        \end{bmatrix}
$$
,then is there a easy way to compute the eigenvalues of the matrix?</p>

<p>How can I compute this matrix eigenvalue?</p>
",linear_algebra
"<p>Find a system of linear equations whose solution set is the line in the 3 dimensional space.</p>

<p>$$  \begin{pmatrix} x \\ y \\ z \\  \end{pmatrix} =\begin{pmatrix} t-4 \\ t-10 \\ 2t-20 \\  \end{pmatrix}$$</p>

<p>What i tried</p>

<p>The question is asking to link the variables $x$ $y$ and $z$ into a single equation while removing the $t$. I first equate $x=t-4$,$y=t-10$ and $z=2t-20$. Then i tried combining the equations to form $$x=y+6$$ and $$z=2x-12$$ and $$z=2y$$. However i could not combine all these 3 variable into a single equation. Could anyone explain. Thanks</p>
",linear_algebra
"<p>I have a panel 1200 pixels wide, and am filling in smaller subpanels to fill the length. Each sub-panel is of a different color ($p$ = purple, $g$ = green, etc). It's for a navigation bar on a website, each subpanel corresponds to a link to another page.</p>

<p>In one situation, there's three purple subpanels, a yellow subpanel, two blue subpanels, one each of green and red subpanels; in another situation, there's 3 purple subpanels, a yellow ($e$ for clarification) subpanel, two more purple subpanels, and a green subpanel. The width of each subpanel (irrespective of situation) must add up to 1200px. </p>

<p>Lastly, $e$ is always the middle panel, with some panels to the left or right. The combined widths of the left must equal the combined widths of the right in both situations.</p>

<p>Since all subpanel widths must add up to 1200px irrespective of situation, two equations can be made:</p>

<p>$$\begin{align}
3p + e + 2b + g + r &amp;= 1200 \\
3p + e + 2p + g &amp;= 1200
\end{align}$$</p>

<p>Since $e$ is in the center of the panel, subpanels to the left and right of $e$ in the above equations must equal. This gives me two more:</p>

<p>$$\begin{align}
3p &amp;= 2b + g + r \\
3p &amp;= 2p + g
\end{align}$$</p>

<p>I think I can derive two more equations, but I'm not sure their relevance. Since $e$ is in the middle ($e$'s midpoint is in the middle of the panel), the left and right halves each contain half of $e$:</p>

<p>$$\begin{align}
3p + \frac{1}{2}e &amp;= \frac{1}{2}e + 2b + g + r \\
3p + \frac{1}{2}e &amp;= \frac{1}{2}e + 2p + g
\end{align}$$</p>

<p>Alternatively:</p>

<p>$$\begin{align}
3p + \frac{1}{2}e &amp;= 600 \\
\frac{1}{2}e + 2b + g + r &amp;= 600 \\
\frac{1}{2}e + 2p + g &amp;= 600
\end{align}$$</p>

<p>I want to find <em>any solution</em> given a couple of rules:</p>

<p>$$\begin{align}
p &amp;&gt; 150\\
b &amp;&gt; 100 \\
e &amp;&gt; 90 \\
g &amp;&gt; 80 \\
r &amp;&gt; 60
\end{align}$$</p>

<p>As long as any solution fits those minimum values, things are kosher.</p>

<p>Forming a matrix and bringing to RREF yields three free variables, which is why I'm stumped.</p>

<p>The illustrate the first situation, $3p + e + 2b + g + r = 1200$:</p>

<p><a href=""http://i.stack.imgur.com/hOst4.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/hOst4.png"" alt=""enter image description here""></a></p>
",linear_algebra
"<p>In $P_2 = {ax^2 + bx + c: a,b,c \in\mathbb{R}}$, why do coefficients in $ax^2$ form reduce with coefficients in $bx$ or $c$?</p>

<p>For example, lets look at the set {$x^2 + x - 1, 2x + 1, 2x - 1$}</p>

<p>If we wanted to check to see if its independent, we would rewrite this as </p>

<p>$C_1* (x^2 + x -1) + C_2 * (2x +1) + C_3 * (2x-1) = \vec{0} $</p>

<p>In matrix form this would be,</p>

<p>\begin{bmatrix}
    1 &amp; 0 &amp; 0 \\
    1 &amp; 2 &amp; 2 \\
    -1 &amp; 1 &amp; -1
\end{bmatrix}</p>

<p>When we apply Gaussian Elimination, in my head, when eliminating the $1$ found in the 1st column 2nd row and $-1$ in the 1st column 3rd row, it seems like I am subtracting x with $x^2$ and -1 with $x^2$ respectively. I understand that the first column all belongs to $C_1$. </p>

<p>I understand that we are subtracting $C_1$ from $C_1$ but why can we simply ignore the $x^2$ and $x$. I guess my problem with how this is all set up is that I'm relating it back to high school algebra where you had equations like.</p>

<p>$x + y = 5$</p>

<p>$x -y = 10$ </p>

<p>And you solved for $x$. Why can we ignore the $x$ or $x^2$?</p>

<p>Thanks.</p>
",linear_algebra
"<p>Let $A$ and $B$ be two real symmetric matrices in $M_n(\mathbb{R})$. I would like to learn about necessary and sufficient conditions for knowing when $B \in \overline{GL_n(\mathbb{R})\cdot A}$; where:
$$
GL_n(\mathbb{R})\cdot A:=\{(g^{-1})^{T} A g^{-1} : g \in GL_n(\mathbb{R})\},
$$
$(g^{-1})^{T}$ is the transpose of $g^{-1}$ and $\overline{GL_n(\mathbb{R})\cdot A}$ is the closure of $GL_n(\mathbb{R})\cdot A$ with respect to the usual topology of $M_n(\mathbb{R})$.</p>

<p>Help would be appreciated!</p>

<p>Thanks!</p>
",linear_algebra
"<blockquote>
  <p>If $V=\mathbb R[x]_k=\{\sum\limits_{i=1}^ka_ix^i:a_i\in\mathbb R, \forall i\}$ is a vector space of dimension $k+1$ over $K=\mathbb R$ and $\mathcal B=\{1,x,\dots,x^k\}$ is a basis of $V$. The dual space of $V$ is the vector space $V^*=\{F:V\to K:F\ \text{is linear}\}$ for all $i$;  $x^{i^*}$ is defined as $x^{i^*}(x^j)=\delta_{ij}=\begin{cases} 1 &amp; \textrm{if i=j}\\0 &amp; \textrm{else}\end{cases}$, let $\mathcal B^*=\{x^{i^*}:i\in\{0,\dots,k\}\}$ and $F:V\to K$ with $p(x)\mapsto\int_0^1 p(x)$ write $F$ as a linear combination of elements of $\mathcal B^*$</p>
</blockquote>

<p>First $\mathcal B^*$ is basis of $V^*$ because $Hom(V,K)\simeq Mat_{1\times(k+1)}(K)$ with $f\mapsto(f(1),\dots f(x^k)$(I can show it is injective and with our chosen $x^{i^*}$ also surjective, and since $x^{i^*}$s are linearly independent it is a basis, but how can I write $F$; </p>

<p>$F=\lambda_01^*+\lambda_1x^*+\dots\lambda_kx^{k^*}$, for examples if $p(x)=x$ then $\int_0^1 p(x)=\frac12$, so $F=\frac12x^*$ and in general $\lambda_k=\frac{1}{k+1}$, am I correct ?</p>
",linear_algebra
"<blockquote>
  <p>Given $A_{n\times n},B_{n\times n} \in \mathbb C$ then:</p>
  
  <ol>
  <li><p>if $A$ is unitary and the characteristic polynomial $f_A(x)=f_B(x)$ then $B$ is also unitary. </p></li>
  <li><p>if $A$ is normal and $f_A(x)=f_B(x)$ then $B$ is also normal. </p></li>
  <li><p>if $A$ is unitary and $f_A(x)=f_B(x)$ and $m_A(x)=m_B(x)$ then $A$ is similar to $B$. </p></li>
  </ol>
</blockquote>

<p>(1) if the matrix is unitary then the eigenvalues are $\pm 1$ but why would having eigenvalues that are  $\pm 1$ mean that the matrix is unitary? So that's probably false.</p>

<p>(2) similar reasoning, why would the normal property carry over because of the same eigenvalues? Probably false.</p>

<p>(3) since $A$ is diagonalizable because its unitary, then it has a similar diagonal matrix, and since $B$ has the same diagonal matrix then it has to be similar to it? How does the minimal polynomial help here?</p>
",linear_algebra
"<p>I am going through Linear Algebra right now, we are using the book Elementary Linear Algebra by Andrilli. In one of the theorems he uses this notation without really introducing it. Here is the theorem:</p>

<p>Theorem 2.3 Let <strong>AX</strong>=<strong>B</strong> be a system of linear equations. If [<strong>C</strong>|<strong>D</strong>] is row equivalent to [<strong>A</strong>|<strong>B</strong>], then the system <strong>CX</strong>=<strong>D</strong> is equivalent to <strong>AX</strong>=<strong>B</strong>.</p>

<p>I just don't know how to read the [C|D] notation there. I want to say C divides D because that's the symbol for integer division, but I know that's not right.</p>

<p>Thanks!</p>
",linear_algebra
"<p>The notion of <a href=""https://en.wikipedia.org/wiki/Linear_independence""><em>linear independence</em></a> is very well-known and well-understood.</p>

<p>However, is there a way to generalize the definition to other types of independence -- such as perhaps ""quadratic independence"", ""polynomial independence"", ""harmonic independence"", etc.?</p>

<p>(Sorry if <a href=""/questions/tagged/linear-algebra"" class=""post-tag"" title=""show questions tagged &#39;linear-algebra&#39;"" rel=""tag"">linear-algebra</a> isn't a good tag; I couldn't think of a better one.)</p>
",linear_algebra
"<p>Could anyone help me with this proof without using determinant? I tried two ways. </p>

<blockquote>
  <p>Let $A$ be a matrix. If $A$ has the property that each row sums to zero, then there does not exist any matrix $X$ such that $AX=I$, where $I$ denotes the identity matrix. </p>
</blockquote>

<p>I then get stuck. The other way was to prove by contradiction, and I failed too. </p>
",linear_algebra
"<p>Let $A$ be a $n\times n$ matrix. Choose the correct option.</p>

<p>a) if $A^2 =0$ then $A$ is diagonalisable.</p>

<p>b) if $A^2 =I$ then $A$ is diagonalisable.</p>

<p>c) if $A^2 - A =0$ then $A$ is diagonalisable.</p>

<p>Now... for a) I tried by transforming them using minimal polynomial (cayley Hamilton) so it should satisfy $t^2 =0$ hence the eigen values are $0$ (twice) hence its not convertible and not diagonalisable... similar arguments for b) and c).</p>

<p>But I am not sure whether I am right... please guide me..</p>
",linear_algebra
"<p>How to find a matrix $A$ over $\mathbb{R}$ such that $A^2-5A+6I=0$ is diagonalisable??</p>

<p>I tried by considering $A$ a particular matrix and putting the values in the given equation but it gives nine equations in nine variables and those too very complex .. is there any other way ??</p>
",linear_algebra
"<p>I am quite confused at the notation used for $J$ in the following question: </p>

<blockquote>
  <p>For a normed space $\Omega$, let $\Omega^{**}$ denote the dual space of the dual space. Let $J: \Omega \rightarrow \Omega^{**}$ be defined by $\langle x^*, J(x)\rangle   =  \langle x, x^*\rangle  = x^*(x)$. Show that $J$ is a linear isometry.</p>
</blockquote>

<p>Where, for $x^* \in \Omega$, $\langle x, x^*\rangle = x^*(x)$. </p>

<p>I am confused on how to decipher the notation for $J$. I am normally use to things like $J(x) = $ fill in the blank. Could someone please explain this notation? </p>
",linear_algebra
"<p>I have here a linear transformation $T : P_3(\mathbb{R})\rightarrow P_3(\mathbb{R}) $ defined by:</p>

<blockquote>
  <p>$ T(at^3 + bt^2 + ct + d) = (a-b)t^3 + (c-d)t $</p>
</blockquote>

<p>I'm very very new in this subject and I'm not going well with polynomials. I need find the $ Kernel $ and the $ Image $ of the transformation. Look what I've been thinking:</p>

<blockquote>
  <p>$Ker(T) =  \{ T(p) = 0 / p \in P_3\} $</p>
  
  <p>$ T(at^3 + bt^2 + ct + d) = (a-b)t^3 + (c-d)t = 0 $</p>
  
  <p>$(a-b) = 0 \ ;\ \ (c-d) = 0 \ ;\ \ a = b \ ; \ \ c = d $</p>
  
  <p>$ Ker(T) = \{ at^3 + at^2 + ct +c\ /\ a,c \in \mathbb{R} \} $</p>
</blockquote>

<p>And what about the $ Image $? I know that $Im(T) = \{ T(p) / p \in P_3 \}$, but how can I show it? And how can I test if a polynomial such as $ p(t) = t^3 + t^2 + t -1 \in Im(t)$?</p>
",linear_algebra
"<p>Let $T: V\rightarrow W$ be a linear mapping. Let $M$ be a linear subspace such that $M \subset ker(T)$. Let $Q$ be the quotient mapping  $Q:V \rightarrow V/M$ then I have to show there is unique mapping $S: V/M \rightarrow W$ such that $T=SQ$. </p>

<p>Thoughts: Is it a reasonable choice to choose $S(x+M) = T(x+m) = T(x)$ for any coset $x+M$ and any $m \in M$ since $M \subset ker (T)$ or have I drifted down the wrong path.</p>
",linear_algebra
"<p>Let $A\in\{0,1\}^{m\times n}$ where $m \gg n$. Take this matrix to be over $\mathbb{R}^{m\times n}$ (not the binary field). What is the probability that said matrix will have full rank? Is there some condition on the difference between $m$ and $n$ so that the probability approaches $1$? </p>
",linear_algebra
"<p>Assume $A$ is a $m \times n$ matrix. We want to see whether the linear system $Ax=b$ has any solution for $x$ given $b$. One way to check this is:</p>

<p>""This linear system of equation has a solution if the b is contained in the column space of A.""</p>

<p>1- Does anybody know a good reference for this?</p>

<p>2- How can we check that b is within the column space of A using projection? Any reference for this method?</p>
",linear_algebra
"<p>I was given as an assignment to diagonalize the following matrix:</p>

<blockquote>
  <p>$\left(\begin{array}{cc}
\cos\theta &amp; -\sin\theta\\
\sin\theta &amp; \cos\theta
\end{array}\right)$ </p>
</blockquote>

<p>I started by finding the eigenvectors and got:</p>

<blockquote>
  <p>$v_{1}=\left(\begin{array}{c}
1\\
-i
\end{array}\right)$,  $v_{2}=\left(\begin{array}{c}
1\\
i
\end{array}\right)$</p>
</blockquote>

<p>then I normalized the vectors and composed a unitary matrix:</p>

<blockquote>
  <p>$U=(v_1|v_2)=\frac{1}{\sqrt{2}}\left(\begin{array}{cc}
1 &amp; 1\\
-i &amp; i
\end{array}\right)$</p>
</blockquote>

<p>The problem is in the final step:</p>

<blockquote>
  <p>$U^{*}AU=\left(\frac{1}{\sqrt{2}}\left(\begin{array}{cc}
1 &amp; i\\
1 &amp; -i
\end{array}\right)\right)\left(\begin{array}{cc}
\cos\theta &amp; -\sin\theta\\
\sin\theta &amp; \cos\theta
\end{array}\right)\left(\frac{1}{\sqrt{2}}\left(\begin{array}{cc}
1 &amp; 1\\
-i &amp; i
\end{array}\right)\right)$</p>
</blockquote>

<p>This doesn't produce a diagonal matrix.</p>

<p>Is there any mistake in these stages?</p>

<p>Many thanks.</p>
",linear_algebra
"<p><strong>Question:</strong> 
Let V be the vector space of all functions $\Bbb R\to \Bbb R$.
Show that $V=U \oplus W$
for $U=${$f | f(x)=f(-x) \forall x$}$, $W={$f | f(x)=-f(-x) \forall x$}</p>

<p><strong>What I did</strong>:</p>

<p>I did prove that $U \cap W$={$0$}. But proving that any function from R to R can be displayed as a sum of odds and evens wasn't a success. I tried saying that for $v \in V, w \in W: v=v-w+w$ and proving that $v-w \in U$ but that didn't work (That trick worked with some linear transformations we saw, but this isn't a linear transformation).</p>
",linear_algebra
"<p>I'm not clear about the sum(and direct sum) operator on subspaces, how to use them? please offer me some applications about this operation, really really appreciate it.</p>
",linear_algebra
"<p>Let $V$ be the space of $n \times 1$ matrices over $F$ and let $W$ be the space of all $m \times 1$ matrices over $F$. Let $A$ be a fixed $m \times n$ matrix over $F$ and $T$ be a linear transformation $T : V\to W$ defined by $T(X)=AX$. Prove that $T$ is the zero transformation if and only if $A$ is the zero matrix.</p>

<p><strong>My try</strong></p>

<ol>
<li>I am thinking that if I set the matrix $A=0$, that is, the $0$ matrix, then the $0$ matrix times any other matrix will be zero. I don't know whether this is right or not. Can someone please check it?</li>
<li>What if I had to prove the converse of this? How am I supposed to prove that?</li>
</ol>
",linear_algebra
"<p>The $U_e$ and $U_o$ denote the set of all real-valued even/odd function on $\mathbb R$ respectively.</p>
",linear_algebra
"<p>I'm interested in algorithms to compute matrix multiplications. Is the Coppersmith-Winograd algorithm similar to the Strassen algorithm ?</p>

<p>I have two other questions:</p>

<p>1) Are the multiplications done at the end of the recursion, like the Strassen one ?</p>

<p>2) The $O(n^{2.38})$ refers to the number of multiplications or to any basic operations (additions...) ?</p>

<p>Thank you</p>
",linear_algebra
"<p>\begin{array}{rrrrr|r}
    b &amp; a &amp; a &amp; \cdot \cdot \cdot &amp; a \\
    a &amp; b &amp; a &amp; \cdot \cdot \cdot &amp; a \\
    a &amp; a &amp; b &amp; \cdot \cdot \cdot &amp; a \\
    \cdot &amp; \cdot &amp; \cdot &amp; \space &amp; \cdot\\
\cdot &amp; \cdot &amp; \cdot &amp; \space &amp; \cdot\\
a &amp; a &amp; a &amp; \cdot \cdot  \cdot &amp; b
  \end{array}</p>

<p>I have the above matrix $A\in M_{n\times n}(F)$ where $F$ is a field and $n\geq1$, $a,b\in F$.</p>

<p>I'm trying to find out how to use row operations to make it into an upper triangular matrix in order to figure out the determinant. But I'm not sure how I would approach it.</p>
",linear_algebra
"<p>Page 2 (506), line 18 of
<a href=""http://www-personal.umich.edu/~orosz/articles/NonlinScipublished.pdf"" rel=""nofollow"">http://www-personal.umich.edu/~orosz/articles/NonlinScipublished.pdf</a></p>

<p>says that ""The presence of translational symmetry in the nonlinear equations gives rise to a relevant zero eigenvalue in the linearized system at any of the trivial solutions"".</p>

<p>It looks like a general statement, but I don't see why (is it trivial?). Where can I find a precise statement about this and on what conditions does that hold? (I'd like to know the proof too.) Thank you.</p>
",linear_algebra
"<p>Let $A$ be a Hermitian matrix of size $n$ such that $A^5+A^3+A=3I_n$ , then is it true that $A=I_n$ ? What I got is if $a$ is an eigenvalue then $a^5+a^3+a-3=0=(a-1)(a^4+a^3+2a^2+2a+3)$ this doesn't seem to get anywhere , Please help . </p>
",linear_algebra
"<p><strong>Given data in the problem</strong> </p>

<ol>
<li>${\psi'(t)}_{3 \times 3}=A_{3 \times 3}\psi(t)_{3 \times 3}, \psi(0)_{3 \times 3}=R^{cl}_{3 \times 3}  \\
\phi'(t)_{3 \times 3}=t\hspace{.1cm}B_{3 \times 3} \phi(t)_{3 \times 3},\phi(0)_{3 \times 3}=R^{cl}_{3 \times 3}   \tag 1$</li>
<li>$A,B ,R^{cl}$ are constant matrices. A,B are skew symmetric matrices. $R^{cl}$ is a rotation matrix</li>
<li>We know the solutions of  equation (1). Implies we know about what is  $\psi(t)=e^{At}R^{cl}_{3 \times 3},\phi(t)=e^{B\frac{t^2}{2}}R^{cl}_{3 \times 3} \tag 2 $</li>
</ol>

<p><strong>Question</strong></p>

<p>What is the  the solution of $ R'(t)=AR(t)+tBR(t)\tag 3$ in closed form?</p>
",linear_algebra
"<p>If $T:\mathbb C^n \to \mathbb C^n$ is a linear transform such that $\ker(T-aI)=\ker(T-aI)^n , \forall a\in \mathbb C$ , then is $T$ diagonalizable ? </p>
",linear_algebra
"<p>Consider $\mathbb{R}^3$ with the standard inner product. Let $W$ be the plane spanned by $(1,1,1)$ and $(1,1,-2)$. Let $U$ be the linear operator defined as: $U$ is rotation through the angle $\theta$, about the straight line through the origin which is orthogonal to $W$. How to find the matrix of $U$ in the standard ordered basis.</p>
",linear_algebra
"<p>I have taken a Quadratic form and performed simultaneous row and column operations on it.  I started with $$A = \begin{pmatrix} 1 &amp; 2 &amp; 1\\2 &amp; 3 &amp; 4\\ 1 &amp; 4 &amp; 5\end{pmatrix}$$ and diagonalized to $$D = \begin{pmatrix} 1 &amp; 0 &amp; 0\\0 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; 8\end{pmatrix} S = \begin{pmatrix} 1 &amp; 0 &amp; 0\\-2 &amp; 1 &amp; 0 \\ -5 &amp; 2 &amp; 1\end{pmatrix}$$ where $SAS^T = D$.  How do I find the new basis for the diagonalized version of A?</p>

<p>EDIT:  I typed A incorrectly.</p>
",linear_algebra
"<p>I am currently working on a Computer Algebra System and was wondering for suggestions on methods of finding roots/factors of polynomials. I am currently using the Numerical Durand-Kerner method but was wondering if there are any good non-numerical methods (primarily for simplifying fractions etc).</p>

<p>Ideally this should work for equations in multiple variables.</p>
",linear_algebra
"<p>I understand what the Hodge dual is, but I can't quite wrap my head around the dual space of vector space. They seem very similar, almost the same, but perhaps they are unrelated. </p>

<p>For instance, in R^3, the blade a^b gives you a subspace that's like a plane, and the dual is roughly the normal to the plane.</p>

<p>Is there a similarly simple example for the dual space of a vector space, or is there a way to describe the vector space dual in terms of the Hodge dual?</p>
",linear_algebra
"<p>I have a simple linear operator:</p>

<p>$$\begin{align}g: \Bbb{R^4} &amp;\to \Bbb{R^3}\\g (x, y, u , v) &amp;= ( x + u, x + v, y + u)\end{align}$$</p>

<blockquote>
  <p>How would I determine the image of this linear operator?</p>
</blockquote>

<p>I thought that putting in the vectors</p>

<blockquote>
  <p>$(0, 0, 0, 1) \implies \dots$<br>
  $(0, 0, 1, 0) \implies \dots$<br>
  $\;\;\;\vdots$</p>
</blockquote>

<p>would yield the $4$ vectors of the image.</p>

<p>But the solution says there are only $3$ vectors in the image of this operator.</p>

<p>What am I missing?</p>
",linear_algebra
"<p>First I'll define what I talk about:</p>

<p>A <strong>bilinear form</strong> on a vector space V is a mapping:</p>

<p>$F: V \times V \rightarrow \mathbb{R}, (a,b) \mapsto F(a,b)$</p>

<p>which is linear in every argument:</p>

<p>$a, b, c \in V$ and $\lambda, \mu \in \mathbb{R}$:</p>

<ul>
<li>$F(\lambda a + \mu b, c) = \lambda F(a, c) + \mu F(b, c)$</li>
<li>$F(a, \lambda b + \mu c) = \lambda F(a, b) + \mu F(a, c)$</li>
</ul>

<p>If I get an expression which could be a bilinear form, I check those two. This can be quite long.</p>

<p>A bilinear form F is <strong>symmetric</strong>, if:</p>

<p>$\forall a, b \in V: F(a, b) = F(b, a)$</p>

<p>Now my <strong>question</strong>:
If I know that a mapping is symmetric, can I make the checks for bilinearity shorter? Something like that:</p>

<p>$F(\lambda a + b, c) = \lambda F(a, c) + F(b, c)$?</p>

<p>If it is not possible, do you have counterexamples where it doesn't work?</p>
",linear_algebra
"<p>Let $V$ a vector space and $W$ be its linear subspace. Give an example of a linear map that satisfies $\mathrm{im}(f)=W$ and $\ker(f) \oplus \mathrm{im}(f)=V$, but $f^2 \neq f$.</p>

<p>Would $f(v)=2v$ be the right example? Since the kernel of it is $0$ and the map itself is surjective so the condition $\ker(f)\oplus \mathrm{im}(f)=V$ satisfied, also $W=V$ in this case and $f^2 \neq f$ is also satisfied.</p>

<p>A next question is once I restrics $f$ to $W$ then will it be always isomorohism. My approach was that the map will be surely surjective, since $f:W\rightarrow W$ and $W=\mathrm{im}(f)$. But the injectivity I check by using the given $\ker(f)\oplus \mathrm{im}(f)=V$. Can someone help me on that. I am stuck. Please.</p>
",linear_algebra
"<p>I want to show the following:</p>

<p>Let $A,B \subseteq \mathbb{R}^n$ disjoint, nonempty, closed and convex sets. Then there exists a $h \in \mathbb{R}^n$, such that $A$ and $B$ gets separated in the following way:
$$
 \langle b, h \rangle \le \langle a, h \rangle \quad \forall a \in A, b \in B.
$$
I have the following proof: Consider $C := B - A$, which is convex too. Because $A$ and $B$ are disjoint, it must be that $0 \notin C$. (*) Then there exists a $h$ such that $\langle c, h \rangle \le 0$ for all $c \in C$ or $\langle c, h \rangle \ge 0$ for all $c \in C$. WLOG let $\langle c, h \rangle \le 0$, then
$\langle b - a, h \rangle \le 0$, which means $\langle b, h \rangle - \langle a, h \rangle \le 0$, i.e. $$\langle b, h \rangle \le \langle a, h \rangle.$$</p>

<p>But (*) uses the fact that: For every convex set $X$ and a point $u \notin X$, there exists a $h$ such that $\langle u, h \rangle = 0$ and $\langle x, h \rangle \le 0$  for all $x \in X$ or $\langle x, h \rangle \ge 0$  for all $x \in X$.</p>

<p>Which I feel is geometrically true because the Elements $h$ could be identified with hyperplanes, but I am not sure how to proof this?</p>
",linear_algebra
"<p>Show that the set of functions $1,x,x^2,x^3...x^n...$ is linearly independent on any interval $[a,b]$.</p>

<p>If $$c_1+xc_2+x^2c_3+x^3c_4...=0$$ we should show $$c_i=0,\quad i=1,2, \ldots$$
how could I start?</p>

<p>My second question: is it linearly independent on $C[0,1]$?</p>
",linear_algebra
"<p>Suppose I have an infinite set $U$ and let $M$ be the linear subspace of all real-valued functions $\nu$ on $2^U$ such that $\nu(\emptyset) = 0$. Here the sum of two such functions (and the product of such a function by a scalar) is taken simply; i.e. pointwise. </p>

<p>Now fix a member $\bar{\nu} \in M$. I am interested in linear transformations $T_{\bar{\nu}}$ of $M$ into itself of the following form: $$(T_{\bar{\nu}}\nu)(S) = \bar{\nu}(S)(\nu(S)), \quad S \subset U.$$ I would like to know if these types of transformations (or equivalent) have been studied before and, if so, under what name. Note I am not requiring that $\bar{\nu}$ be a measure, or even an outer measure, but would be willing to start there.</p>

<p>Thanks in advance for any pointers.</p>
",linear_algebra
"<p>I am taking linear algebra, and have learned about the vector dot product and cross product.  Is there a vector product defined by :
    $(a_1, a_2, \dots ,a_n)\times (b_1, b_2, \dots,b_n) = (a_1b_1, a_2b_2, \dots ,a_nb_n)$ ?
If so, what it it called?</p>
",linear_algebra
"<p>Suppose $v_1, \dots v_m$ is a linearly independent list in V. Show that there exists $w \in V$ such that $\langle w, v_j \rangle &gt; 0$ for all $j \in {1, \dots ,m}$.</p>

<p>I understand this question is saying given a linearly independent list, there is $w \in V$ such that the vector $w$ is not orthogonal to any $v$ in that linearly independent set. I'm also confused as to why it is significant that the inner product be greater than zero and instead of just $\neq 0$. Can someone give me a hint on how to do this problem?</p>

<p>I know that $\langle v, v \rangle &gt;0$ for all $v$ not equal to zero, and since $v_1, \dots v_m$ is linearly independent, then none of the $v_j$ will be zero, but it is impossible to have w equal to all $v_j$?</p>
",linear_algebra
"<p>In more rigorous language:
"" <strong>V</strong>: a vector space having an uncountable base
 <strong>S</strong>: The set of subspaces of <strong>V</strong> that have countable dimension.
 Can we construct explicitly a chain in the poset <strong>S</strong> (ordered by inclusion), such that this chain has NO upper bound in <strong>S</strong>? ""</p>

<p>Apparently, this chain must have uncountable terms. Also,because S doesn't satisfy Zorn's lemma, we know such chain must exist in <strong>S</strong>.</p>

<p>But how do we construct it?</p>
",logic
"<p>The following line well-defines a family of subsets $\{S_i\}_{i\in\mathbb N}$ of $\mathbb N$:</p>

<blockquote>
  <p>$n\in S_i$ iff $n=2i$ or $\exists j&lt;i$ such that $n\in S_j$.</p>
</blockquote>

<p>The following line does not:</p>

<blockquote>
  <p>$n\in S_i$ iff $n=2i$ or $\exists j$ such that $n\in S_j$.</p>
</blockquote>

<p>Now what about the following line?  I suspect that it does well-define a family of subsets, but I'm not sure how one would prove it; some clever application of the Recursion Theorem or Godel's fixed point theorem perhaps?</p>

<blockquote>
  <p>$n\in S_i$ iff $n=2i$ or $\mbox{Prov}_{PA}(\exists j\mbox{ such that }n\in S_j)$</p>
</blockquote>

<p>And similarly</p>

<blockquote>
  <p>$n\in S_i$ iff $n=2i$ or $\exists j$ such that $\mbox{Prov}_{PA}(n\in S_j)$</p>
</blockquote>

<p>In both cases $\mbox{Prov}_{PA}$ is a predicate symbol for provability from $PA$, and $\mbox{Prov}_{PA}(\phi)$ is shorthand for $\mbox{Prov}_{PA}(\ulcorner\phi\urcorner)$ where $\ulcorner\phi\urcorner$ is a Godel number of $\phi$.  I suspect the latter two lines, suitably formalized (how?), do well-define sets $S_i$:  because the ill-founded part (references to arbitrary $S_j$) are inside of $\mathrm{Prov}_{PA}$, they are not actually statements about $S_j$ at all, but only about what $PA$ proves about $S_j$ (which suggests using the Recursion Theorem).</p>

<p>In the literature, would it be acceptable to write either of the latter two lines while brushing aside the details?</p>
",logic
"<p>Is there a direct construction of the integers which does not involve taking any quotients?  I am of course aware of the <a href=""http://en.wikipedia.org/wiki/Integer#Construction"">usual construction</a>.  I am also aware of the nice <a href=""http://mathoverflow.net/questions/23193/axiomatic-definition-of-integers"">axiomatic characterization</a> of the integers.</p>

<p>I am most interested in a <strong>direct</strong> construction.  I am sure that one could probably use a disjoint union of $\mathbb{N}$ and $\mathbb{N}^{+}$ to construct $\mathbb{Z}$.  But this involves 2 intermediate constructions (as well as dealing with cases).</p>

<p>Edit: by direct construction, I mean something like the Peano construction for $\mathbb{N}$, seen as the inductive type built from $0$ and $\mathit{succ}$.  Then one also constructs the operations of addition, multiplication, etc.  Another way to think of it: suppose you wanted to have a datatype of 'integers' in a lambda calculus which only allows inductive constructions and no quotients, how would you do it?</p>
",logic
"<p>In </p>

<p><a href=""http://arxiv.org/pdf/math/9704205.pdf"" rel=""nofollow"">http://arxiv.org/pdf/math/9704205.pdf</a></p>

<p>they define the ultracoproduct of a sequence of compact Hausdorff spaces, $\sum_\mathcal{U}X_i$ along an ultrafilter $\mathcal{U}$ as the Wallman-Frink compactification of the ultraproduct </p>

<p>$\prod_\mathcal{U}A_i$ </p>

<p>where each $A_i$ is the normal lattice base of the closed sets of $X_i$. More generally, I it appears that you can do this for more general topological spaces (at least Tychonoff?): </p>

<p><a href=""http://www.susanjkleinart.com/compactification/Wsp3.pdf"" rel=""nofollow"">http://www.susanjkleinart.com/compactification/Wsp3.pdf</a> .</p>

<p>I'm wondering: is it possible to drop (or at least some how relax) the condition that the base is separating (condition 4, Definition P3.1) and have some sort of ultracoproduct construction?</p>

<p>If we consider compact Hausdorff spaces again, then for a sequence $(X_i)$ of spaces, I believe it is also true that </p>

<p>$C(\sum_{\mathcal{U}}X_i)\cong\prod_{\mathcal{U}}C(X_i)$</p>

<p>where $C(X)$ is the Banach space of continuous, real-valued functions on $X$ and $\prod_{\mathcal{U}}C(X_i)$ is the Banach ultraproduct. Would it make sense (for more general topological spaces $X_i$) to just define the ultracoproduct as </p>

<p>$C_b(\sum_{\mathcal{U}}X_i)\cong\prod_{\mathcal{U}}C_b(X_i)$</p>

<p>where $C_b(X_i)$ is the Banach space of bounded, continuous, real-valued functions on $X_i$? I suppose that this would make sense if there was a good way to recover the space $\sum_{\mathcal{U}}X_i$ from $C_b(\sum_{\mathcal{U}}X_i)$.</p>

<p>Also, 
Can an ultracoproduct be (perhaps naively) be seen as a kind of Kolmogorov quotient of an ultraproduct?</p>
",logic
"<p>As a person who has been spending significant time to learn mathematics, I have to admit that I sometimes find the fact uncovered by Godel very upsetting: we never can know that our axiom system is consistent.  The consistency of ZFC can only be proved in a larger system, whose consistency is unknown.</p>

<p>That means proofs are not like as I once used to believe: a certificate that a counterexample for a statement can not be found.  For example, in spite of the proof of Wiles, it is conceivable that someday someone can come up with integers a,b and c and n>2 such that a^n + b^n = c^n, which would mean that our axiom system happened to be inconsistent.</p>

<p>I would like to learn about the reasons that, in spite of Godel's thoerem, mathematicians (or you) think that proofs are still very valuable.  Why do they worry less and less each day about Godel's theorem (edit: or do they)?  </p>

<p>I would also appreciate references written for non-experts addressing this question. </p>
",logic
"<p><strong>Question</strong>. Is there is a model of ZF set theory with a set $X$ that does not inject into the cardinals? </p>

<p>I use the term ""cardinal"" here in the ZF sense, so they are not necessarily well-orderable.</p>

<p>To be more precise, I am asking whether there is a model of ZF with a set $X$ for which there is no assignment $$a\mapsto B_a,$$
such that whenever $a\neq b$ are distinct elements of $X$, then $B_a$ and $B_b$ are not equinumerous. </p>

<p>If $X$ is well-orderable, then we may map the $\alpha^{th}$ element of $X$ to the cardinal $\aleph_\alpha$. So no model of ZFC will have such a set $X$ with no assignment. Thus, the question is about models of ZF where AC fails.</p>
",logic
"<p>Is there a counter-example showing that Morley rank in the theory of compact complex spaces (as defined by Zilber, Pillay, Moosa, ...) is not definable in families?</p>

<p>Given the existence of such a counterexample in DCF (constructed by Hrushovski and Scanlon; it is a family of Abelian varieties) and the similarity between two theories from the model-theoretic point of view, I am inclined to think that there should be a counter-example in CCS. But I have difficulty ""translating"" (at least straightforwardly) the DCF example into the CCS world since it uses some facts, such as existence of certain definable families of polarized Abelian varieties, that I am not familiar with.</p>
",logic
"<p>I am not a logician or set theorist, so hopefully this makes sense.  Let $T$ be a theory which is expressive enough to make statements like ""Statement $A$ has a proof in $T$""; for example, $T$ might be capable of expressing elementary arithmetic and proving certain basic arithmetic facts.  </p>

<p>Let $\Pi^0(T)$ consist of those statements $A$ in $T$ such that either $A$ or $\neg A$ admits a proof in $T$.  In general, for $i\in \mathbb{N}$ let $\Pi^i(T)$ consist of those statements $A$ such that the statement ""Con(T) implies that there does not exist a proof of $A$, or a proof of $\neg A$, in $T$"" is in $\Pi^{i-1}(T)$.  Intuitively, $\Pi^1$ should consist of those statements $A$ for which one can prove in $T$ that neither $A$ nor $\neg A$ admits a proof in $T$, $\Pi^2$ should consist of those statements $A$ such that one can prove in $T$ that one cannot tell whether or not they admit a proof, but where one knows this fact, and so on.</p>

<p>Godel's first incompleteness theorem implies that $\Pi^0(T)$ does not contain every sentence of $T$; in particular, the proof amounts to constructing a sentence in $\Pi^1(T)$.</p>

<p>Now I'm sure that if this heirarchy is not nonsense for some reason that I'm missing, then it must be well-studied.  So here goes:</p>

<blockquote>
  <p>1)  If this set-up is studied, what is it called?</p>
  
  <p>2) In standard theories, e.g. ZFC, is every sentence contained in $\bigcup_{i\in \mathbb{N}} \Pi^i(T)$?  It seems to me that any ZFC proof that this is not the case must be non-constructive, and so would be pretty interesting.</p>
  
  <p>3) Are there any standard theories $T$ of finite (known) depth in this heirarchy, i.e. every sentence is contained in $\Pi^i(T)$ for some fixed $i&gt;0$?  If so, can this be proven in $T$?</p>
  
  <p>4) One can also define this heirarchy in a relative setting; e.g. one can take two theories $T\subset S$ and ask about $S$-proofs of statements about the existence of proofs in $T$.  Is this studied?  Are answers to the above questions known in these cases?</p>
</blockquote>

<p>Motivation:  I recently watched <a href=""http://video.ias.edu/voevodsky-80th"" rel=""nofollow"">this talk</a> by Voevodsky, and ever since I've been wondering about how much we actually know about what we can prove.  One might hope that even if we can't prove every ""true"" statement, then we can at least always prove that a statement does not admit a proof in our theory, if that is indeed the case.  That seems unlikely, and amounts to the claim that all statements in our theory are in $\Pi^1(T)$, but I think that it is the best situation one can hope for (at least naively) given Godel's theorems.  So, is the situation hopeless?  Give it to me straight, doc.</p>
",logic
"<p>An odd -- probably basic -- question about model theory:</p>

<p>For $\mathcal{M}$ a structure in a (first-order) signature $\Sigma$, let $\mathcal{M}'$ be the structure in signature $\Sigma\sqcup\lbrace U\rbrace$ -- with $U$ a unary relation -- whose reduct to $\Sigma$ is $\mathcal{M}$, and interprets $U$ as $$ U^{\mathcal{M}'}=\lbrace a: a\text{ is definable in $\mathcal{M}$}.\rbrace$$</p>

<p>Up to the choice of unary relation symbol $U$, this is well defined; moreover, we can iterate this through the ordinals: $$ \mathcal{M}^{(0)}=\mathcal{M}, \quad \mathcal{M}^{(\alpha+1)}=(\mathcal{M}^{(\alpha)})', \quad \mathcal{M}^{(\lambda)}=\bigcup_{\beta&lt;\lambda}\mathcal{M}^{(\beta)} \,\,(\lambda \text{ limit}).$$ (The union notation is technically inappropriate, but its meaning is clear.) Now, for any $\mathcal{M}$, let $$ D(\mathcal{M}, \alpha)=\lbrace a\in\mathcal{M}: a\text{ is definable in $\mathcal{M}^{(\alpha)}$}\rbrace$$ be the set of elements of $\mathcal{M}$ definable after stage $\alpha$. Let $D(\mathcal{M}, \infty)=\bigcup_{\alpha\in ON} D(\mathcal{M}, \alpha)$ be the set of all eventually definable elements, and for $a\in D(\mathcal{M}, \infty)$ let the <em>age</em> of $a$, $age_\mathcal{M}(a)$, be the least $\beta$ such that $a\in D(\mathcal{M}, \beta)$. Clearly for each $\mathcal{M}$ there is a least upper bound, $m_\mathcal{M}$, on the ages of elements of $D(\mathcal{M}, \infty)$.</p>

<p>Some very easy observations:</p>

<ul>
<li><p>If $\mathcal{M}=(M, &lt;)$ is a well-ordering, then $D(\mathcal{M}, \infty)=M$, since the $\alpha$th element of $\mathcal{M}$ is definable by stage $\alpha$ at the latest.</p></li>
<li><p>Even if $\mathcal{M}$ is strongly minimal, $\mathcal{M}'$ need not be: consider $\mathcal{M}=\mathbb{N}+\mathbb{Z}$ as a linear order. Presumably other niceness properties such as stability are also not preserved, but I don't have examples yet.</p></li>
</ul>

<p>My question is, what is known about the set $D(\mathcal{M}, \infty)$, the age function $age_\mathcal{M}$, or the invariant $m_\mathcal{M}$? I've been playing around with this idea for a bit, but my model theory is not very strong; I'm sure this has been treated before, but I haven't been able to find a reference. </p>

<p>(In case anyone is interested, I initially thought that there would be connections with notions of rank, as long as $\mathcal{M}$ is sufficiently nice; in fact, I came up with this question after using some dubious analogies to try to explain forking and rank to a friend. As far as I can tell, this initial hope is in fact bogus, but that's where this came from.)</p>

<hr>

<p>There are two other questions about this that I'm especially interested in. First, what if we augment first-order logic by adding a logical unary relation $D$ whose interpretation is stipulated to always be $D(\mathcal{M}, \infty)$ -- the resulting model theory seems wild (compactness and Lowenheim-Skolem fail extremely badly), but this logic ""comes from"" first-order logic in a natural way; is there anything nice we can say about it? Second, this time closer to computability theory: what if we replace ""definable"" with $\Sigma_1$-definable? Does $m_\mathcal{M}$ now have a recursion-theoretic interpretation? I consider these as just curiosities, compared to the main question (which, though more vague, I hope is still appropriate), but if anyone has anything to say on either count I'd be extremely interested.</p>
",logic
"<p>Andreas Blass states that proper classes do not exist and emphasizes that this is only his philosophical opinion, and not a mathematical fact.(<a href=""http://mathoverflow.net/questions/71765/are-proper-classes-objects/71773#71773"">link text</a>).</p>

<p>Is it really not a mathematical fact? I think there are some mathematical results that justify his philosophical opinion. Levy and Vaught prove that Ackermann's set theory proves the existence of the classes {V}, P{V}, PP{V},....(Pacific Journal of Mathematics, 11:1045-1062, 1961). Furthermore, Reinhardt proves that Ackermann's set theory equals ZF (Annals of Mathematical Logic, 2:189-249). My understanding of these results is that anything we can prove in Ackermann's set theory, we can prove in ZF as well. There is no need to assume the existence of the classes P{V}, PP{V}, PPP{V},...because there is nothing new math fact to obtain.</p>

<p>Is my understanding correct?</p>
",logic
"<p>Ultrafinitism is (I believe) a philosophy of mathematics that is not only constructive, but does not admit the existence of arbitrarily large natural numbers.  According to <a href=""http://en.wikipedia.org/wiki/Ultrafinitism"">wikipedia</a>, it has been primarily studied by Alexander Esenin-Volpin.  On his <a href=""http://www.math.rutgers.edu/~zeilberg/OPINIONS.html"">opinions page</a>,  Doron Zeilberger has often expressed similar opinions.</p>

<p>Wikipedia also says that Troelstra said in 1988 that there were no satisfactory foundations for ultrafinitism.  Is this still true?  Even if so, are there any aspects of ultrafinitism that you can get your hands on coming from a purely classical perspective?</p>

<p>Edit: Neel Krishnaswami in his answer gave a link to a paper by Vladimir Sazonov (<a href=""http://www.csc.liv.ac.uk/~sazonov/papers/lcc.ps"">non-Springer link</a>) that seems to go a ways towards giving a formal foundation to ultrafinitism.  </p>

<p>First, Sazonov references a result of Parikh's which says that Peano Arithmetic can be consistently extended with a set variable $F$ and axioms $0\in F$, $1\in F$, $F$ is closed under $+$ and $\times$, and $N\notin F$, where $N$ is an exponential tower of $2^{1000}$ twos.</p>

<p>Then, he gives his own theory, wherein there is no cut rule and proofs that are too long are disallowed, and shows that the axiom $\forall x\ \log \log x &lt; 10$ is consistent.</p>
",logic
"<p>There is an ubiquitous pattern of questions concerning assumedly any kind of mathematical object or structure: groups, graphs, numbers, categories, and so on. It goes like this (informally):</p>

<blockquote>
  <p>Can a class of objects or structures of a given kind <em>X</em> that is characterized by some ""external condition"" <em>Y</em> be defined by a condition <em>Z</em> in their respective ""internal""
  language, and if so: how?</p>
</blockquote>

<p>Well-known examples (""external condition"" <strong>=</strong> ""internal condition""):</p>

<ol>
<li><p>groups $G$ isomorphic to a subgroup of the symmetric group on $G$ <strong>=</strong> all groups (<em>Cayley's theorem</em>)</p></li>
<li><p>graphs embeddable in the plane <strong>=</strong> graphs not containing a subgraph that is a subdivision of $K_5$  or $K_{3,3}$ (<em>Kuratowski's theorem</em>)</p></li>
<li><p>numbers <em>n</em> of trees on <em>k</em> labeled vertices <strong>=</strong> numbers <em>n = k</em><sup><em>k</em>-2</sup> for some <em>k</em> &gt; 1 (<em>Cayley's theorem on trees</em>)</p></li>
<li><p>numbers <em>n</em> with only one group of order <em>n</em> <strong>=</strong> numbers <em>n = p<sub>1</sub> &middot; p<sub>2</sub> &middot;  ... &middot; p<sub>k</sub></em> for some <em>k</em> &gt; 0, where the <em>p<sub>i</sub></em> are distinct primes and no <em>p<sub>j</sub>-1</em> is divisible by any <em>p<sub>i</sub></em> (<em>cyclic numbers</em>, see <a href=""http://www.research.att.com/~njas/sequences/A003277"" rel=""nofollow"">Sloane's A003277</a>)</p></li>
</ol>

<p>Further examples from MO:</p>

<ul>
<li><p><a href=""http://mathoverflow.net/questions/14830/which-graphs-are-cayley-graphs"">Which graphs are Cayley graphs?</a></p></li>
<li><p><a href=""http://mathoverflow.net/questions/13155/can-we-recognize-when-a-category-is-equivalent-to-the-category-of-models-of-a-fir"">Can we recognize when a category is
equivalent to the category of models
of a first order theory?</a></p></li>
<li><p><a href=""http://mathoverflow.net/questions/9255/can-you-determine-whether-a-graph-is-the-1-skeleton-of-a-polytope"">Can you determine whether a graph is
the 1-skeleton of a polytope?</a></p></li>
</ul>

<blockquote>
  <p><strong>Question #1:</strong> What's the proper way to
  characterize this pattern of
  questions? What's the common
  context / rationale?</p>
</blockquote>

<hr>

<blockquote>
  <p><strong>Question #2:</strong> How is the introductory question to be
  posed properly?</p>
</blockquote>
",logic
"<p>Suppose $A&lt;_T B$ ($A$ is a set computable from $B$ but not vice versa). Is it always the case that there exists a $B$-computable function which eventually outgrows all $A$-computable functions?</p>

<p>Of my main interest is the case when $A\equiv_T 0$, and then the problem becomes: does there, for every nonrecursive set, exist a function computable relative to this set which eventually outgrows all recursive functions?</p>

<p>Thanks in advance. </p>
",logic
"<p>We know that Peano Arithmetic satisfies Löb's derivability conditions, which is required in the proof of Gödel's 2nd incompleteness theorem. Is this the best result? If not, is there any known weaker system have the derivability conditions, and is there a weakest?</p>
",logic
"<p>To show that the positive existential theory of $\mathbb{C}[t, e^{\lambda t} \mid \lambda \in \mathbb{C}]$ in the language $\{+, \cdot , ' , 0 , 1, t\}$ is undecidable we have to prove the following: $$n \in \mathbb{N} \leftrightarrow \exists x \left (n \in \mathbb{C} \land tx'=nx \land x(1)=1\right )$$  </p>

<p>So do we have to do the following? </p>

<p>We suppose that the positive existential theory of $\mathbb{C}[t, e^{\lambda t} \mid \lambda \in \mathbb{C}]$ in the language $\{+, \cdot , ' , 0, 1, t\}$ is decidable, i.e., there is an algorithm that answers to positive existential questions over  $(\mathbb{C}[t, e^{\lambda t} \mid \lambda \in \mathbb{C}];+, \cdot , ' , 0, 1, t)$. </p>

<p>We want to reduce the positive existential theory $\mathbb{N}$ in the language $\{+, \cdot , 0, 1\}$ into the positive existential theory of $\mathbb{C}[t, e^{\lambda t} \mid \lambda \in \mathbb{C}]$ in the language $\{+, \cdot , ' , 0, 1, t\}$. </p>

<p>Is this correct? </p>

<p>But which is the mapping of the reduction? </p>
",logic
"<p>I have read about the existence of functions of the kind described in the title in several places, but never seen an instance of them. Sorry if this is too much an elementary question to be posted here.</p>
",logic
"<p>Let me give an example:</p>

<ol>
<li>this is a definition in object language:
R(x,y) is a symmetric formula  ↔ （∀x∀y(R(x,y)→R(y,x))）</li>
</ol>

<p>2.this is a definition in metatheory:
R(x,y) is a symmetric formula   if and only if R(x,y)→R(y,x) is a theorem.
In other words:
R(x,y) is a symmetric formula   if and only if ⊢ R(x,y)→R(y,x).
In other words:
R(x,y) is a symmetric formula   if and only if ⊢∀x∀y(R(x,y)→R(y,x))</p>

<p>I have the following questions:
1. These two definitions seem to imply all of  theorems of object theory can be described in metatheory,Is that so ? How to precise state and prove this translation process for every theorem?</p>

<p>2.Our everyday reasoning in mathematics , in the end is in the object language or in the meta-language ? </p>

<p>another example:</p>

<p>I have seen a paragraph of text:</p>

<p>Thus, in the metatheory “P : A → A is an equivalence relation” means that “P ⊆ A × A and P is reflexive, symmetric, and transitive” is true, whereas in ZFC it means that the quoted (quasi) translation is provable (or has been taken as an assumption).</p>

<p>I consider the following words is another definition: ⊢ [(P : A → A is an equivalence relation)↔(P ⊆ A × A and The translations of the reflexive, symmetric, and transitive properties in the formal language)].</p>

<p>I want to know the difference between these two statements.</p>
",logic
"<p>For n an integer greater than 2, Can one always get a complete theory over a finite language with exactly n models (up to isomorphism)?</p>

<p>There's a theorem that says that 2 is impossible.</p>

<p>My understanding is this should be doable in a finite language, but I don't know how.</p>

<p>If you switch to a countable language, then you can do it as follows. To get 3 models, take the theory of unbounded dense linear orderings together with a sequence of increase constants &lt; c<sub>i</sub>: i &lt; &omega; >. Then the c<sub>i</sub>'s can either have no upper bound, an upper bound but no sup, or have a sup. This gives exactly 3 models. To get a number bigger than 3, we include a way to color all elements, and require that each color is unbounded and dense. (The c<sub>i</sub>'s can be whatever color you like.) Then, we get one model for each color of the sup plus the two sup-less models.</p>
",logic
"<p>I know that the natural numbers can be categorically characterized in  second-order logic with the standard semantics. However, I could not find an example of a non-standard Henkin structure (one that is closed under parametric definability) that is a model for these characterizing axioms. Is there a known example of such structure?</p>

<p>Thanks!</p>
",logic
"<p>Hello, recently I came upon some personal notes I'd made several years ago while reviewing some basic set theory (ordinals, transfinite recursion, inaccessible cardinals etc.), and I stumbled upon a loose thread which I obviously had not resolved at the time, and which I would like to lay to rest:
Assuming some standard set theory (say ZF, even though I prefer NBG), without the Axiom of Foundation (preferably), one may define an ordinal $\alpha$ (von Neumann's definition) as a transitive set whose elements are well-ordered with respect to the membership relation $\in$. This is seen to be equivalent to the statement that $\alpha$ is transitive, all its $\beta\in\alpha$ are transitive too, and (as we cannot rely on foundation) for each non-empty $x\subseteq\alpha$ there exists some $\beta\in x$ such that $x\cap\beta=\emptyset$ (except for the last condition, this is as in Schofield's book on Mathematical Logic). One then goes on to prove that the class of all ordinals is well-ordered with respect to membership etc.; along the way a useful intermediate step is to prove that any ordinal $\alpha$ is (ad hoc definition) $\textbf{strange}$ in the sense that one has $x\in\alpha$ for any transitive $x\subsetneq\alpha$.
My question finally (as this would provide an alternate definition of ordinal sets): are elements of strange sets themselves strange, or at least transitive ?
Thanks in advance for any useful comments ! Kind regards, Stephan F. Kroneck.</p>
",logic
"<p>The <em>undecidability of the halting problem</em> states that there is no general procedure for deciding whether an arbitrary sufficiently complex computer program will halt or not. </p>

<p>Are there some large $n$ and interesting computer languages (say C++, Scheme) for which we have a constructive halting algorithms for programs of length up to $n$? Note that for any fixed bound, there is some finite lists of zero's and one's that stores whether all the programs less than that bound halt or not, so non-constructively for any $n$ there is always a decision procedure for the bounded problem. But I would like to know whether we have some $n$ for which we can constructively write a decision procedure for programs of length less than that bound. By stipulating <em>large</em> $n$, I'd like to avoid $n$ and languages which are trivial in some sense, for instance, decision procedure for languages where the first number of programs all halt and we can easily see that they halt. </p>

<p>Note that the usual proof of the undecidability of the halting program <em>prima facia</em> does not apply, since the decision procedure for programs bounded by $n$ might have length much larger than $n$, so our decision procedure need not correctly apply to our diagonlization program.</p>

<p>What kind of work has been done on this? Are there any good references out there? Thank you!</p>
",logic
"<p>What is known, and what is published, on the reverse mathematics of the nest of results called <a href=""http://en.wikipedia.org/wiki/Hilbert%27s_Theorem_90"">Hilbert's Theorem 90</a>?</p>
",logic
"<p>According to <em>Higher Topos Theory</em> <a href=""http://arxiv.org/abs/math/0608040"">math/0608040</a> <strong>topos</strong> is </p>

<blockquote>
  <p>a category C which behaves like the
  category of sets, or (more generally)
  the  category of sheaves of sets on a
  topological space.</p>
</blockquote>

<p>Could one elaborate on that?</p>
",logic
"<p>Let $w$ be a group word with two variables $x$ and $y$.
Is the sentence $(\forall x)(\exists y)w=1$
true in every group if it is true
in every finite group?
The same question about the sentence $(\exists x)(\forall y)w=1$.</p>
",logic
"<p>In the <a href=""https://en.wikipedia.org/wiki/Formula"" rel=""nofollow"">Wikipedia article for Formula</a> (which has no references), it is claimed that: </p>

<p>""The informal use of the term formula in science refers to the general construct of a relationship between given quantities....
In mathematics, a formula is an entity constructed using the symbols and formation rules of a given logical language.""</p>

<p>This seems to suggest that a 'formula' can be defined as a regular expression in some language which contains a single equal sign. Is this true?</p>

<p>Also, this article is completely unreferenced. Is there any reference giving such a precise definition of 'formula'?</p>
",logic
"<p>When the paper <a href=""http://arxiv.org/abs/1006.3930"">The unification of Mathematics via Topos Theory</a> by Olivia Caramello, says ""one can generate a huge number of new results in any mathematical field without any creative effort."" is this an exaggeration, and if not is this a new idea or has it always been thought that topos theory could enable automatic generation of theorems.</p>
",logic
"<p>I am currently taking a graduate logic course on Modal Logic and I can't help notice that there are a certain class of graphs characterized by the modal axioms such as (4) $\Box p \rightarrow \Box \Box p$, (5) $\Diamond p \rightarrow \Box \Diamond p$, or (B) $p \rightarrow \Box \Diamond p$ which can characterize frames as being transitive, Euclidean, and symmetric, respectively. In general, I notice many similarities between the models used in Modal Logic and the graphs in Graph Theory and I'm wondering if anyone knows if there are applications of Modal Logic to Graph Theory, or if one subject might be a special case of the other?</p>

<p>In any case, if anyone has studied this before or knows of any references on the interplay between Modal Logic and Graph Theory I would be very interested to read about it, and if it has not been studied before then I would be interested of any ideas regarding what open research problems could be stated to tackle the correspondence between these two topics. (A category theory perspective on this interplay would also be very interesting)</p>
",logic
"<p>It is known that for symbols with finite many relations, the number of inequivalent class of first order sentence with quantifier rank $m$ is finite. But is it possible to list (classify) them? At least in special cases.</p>
",logic
"<p>Reading some old logic texts (written around 1930) I noticed that these texts make no difference between propositional variables and terms.</p>

<p>They do make difference between identity and truthvalue
 but for the rest they are just treated the same.</p>

<p>(p = q) -> ( p &lt;-> q) ( if p is identical to p then p and q have the same truthvalue, equivalent)
is a wellformed formula.</p>

<p>When did logicians start to differentiate between terms and propositional variables?</p>

<p>and more important why? </p>
",logic
"<p>Let we have following axioms and modus ponens  :
$$(A1):(B ⇒ (C ⇒B ))$$
$$(A2):((B ⇒ (C ⇒D )) ⇒ ((B ⇒C ) ⇒ (B ⇒D )))$$
$$(A3):( ( B ⇒C) ⇒(¬C ) ⇒ (¬B ))$$</p>

<p>now can we prove following theorem ?</p>

<p>$\vdash _{H^,} $(((¬C ) ⇒ (¬B )) ⇒( B ⇒C ))</p>

<p>I can prove transitive law in this system.</p>
",logic
"<p>Is there any connection between the <a href=""http://en.wikipedia.org/wiki/Type_%28model_theory%29"" rel=""nofollow"">definition of type in model theory</a> and the definitions from <a href=""http://en.wikipedia.org/wiki/Type_theory"" rel=""nofollow"">type theory</a>? Is there any explanation why the same term is used for these notions, maybe in the historical sense.</p>
",logic
"<p><strong>Context:</strong> Let $\Sigma=\{U,C,A,G\}$ and $L\subset\Sigma^*$, i.e. $L$ is a language over the alphabet $\Sigma$. Let $\Sigma'=\{0,1\}$ and define a homomorphism $f:\Sigma^*\to\Sigma'^*$ by extending $U \to 00$, $C \to 01$, $A \to 10$, and $G \to 11$ in the only possible way to a homomorphism. For $L':=f(L)$ we have $L=f^{-1}(L')$, because $f$ is injective. The languages $L$ and $L'$ are nearly the same for most practical purposes. However, defining a category where they are actually isomorphic is challenging, because $f^{-1}$ is only a partial function. Nailing down the notion of a partial homomorphism between monoids seems like a reasonable first step.</p>

<hr>

<p>A homomorphism $h:M_0\to M'_0$ between two monoids with zero $M_0$ and $M'_0$ is a monoid-homomorphism between $M_0$ and $M'_0$, which maps the zero of $M_0$ to the zero of $M'_0$.</p>

<p>(1) One idea to define partial homomorphisms between two monoids $M$ and $M'$ is to adjoint zeros to $M$ and $M'$ to get monoids with zero $M_0$ and $M'_0$, and define that the partial homomorphisms between $M$ and $M'$ are the restrictions of the homomorphisms between $M_0$ and $M'_0$.</p>

<p>(2) Another idea is that a partial homomorphisms $p:M\to M'$ is a partial function $p$ which satisfies</p>

<ol>
<li>$p(1)=1'$.</li>
<li>If $p(x)=x'$ and $p(y)=y'$, then $p(xy)=x'y'$.</li>
</ol>

<p>A partial homomorphism according to (1) satisfies the conditions (2), and additionally satisfies</p>

<ol start=""3"">
<li>If $x\notin\operatorname{dom}(p)$ and $y\in M$, then $xy\notin\operatorname{dom}(p)$ and $yx\notin\operatorname{dom}(p)$.</li>
</ol>

<blockquote>
  <p>Conditions 1, 2, and 3 together should be equivalent to definition (1). If not, please correct me.</p>
</blockquote>

<p>I always favored definition (1), because then a partial homomorphism would be uniquely determined by its values on a generating set. And for a <a href=""http://mathoverflow.net/a/123617"">quite natural definition of partial monoids</a>, the category of partial monoids and partial homomorphisms is equivalent to the category of monoids with zero, if definition (1) is extended appropriately to partial monoids.</p>

<hr>

<p><strong>Context continued</strong> Sadly, $f^{-1}$ is only a partial homomorphism according to definition (2), but fails to satisfy definition (1). This is sad, because the set of partial homomorphisms from $\Sigma^*$ to $\Sigma'^*$ according to definition (1) is easy to describe. For definition (2) it is not even clear whether $\operatorname{dom}(p)$ will always be computationally enumerable, let alone having any chance to computationally enumerate the set of partial homomorphisms itself. But maybe the partial isomorphisms are better behaved, so using definition (2) could still make sense.</p>

<hr>

<p>A further test for definitions (1) and (2) is to generalize them to define when a relation $R\subset M\times M'$ is a morphism between $M$ and $M'$. Now (1) no longer makes sense, but conditions 1, 2, and 3 still make sense and become</p>

<ol>
<li>$1\ R\ 1'$.</li>
<li>If $x\ R\ x'$ and $y\ R\ y'$, then $xy\ R\ x'y'$.</li>
<li>If $x\notin\operatorname{dom}(R)$ and $y\in M$, then $xy\notin\operatorname{dom}(R)$ and $yx\notin\operatorname{dom}(R)$.</li>
</ol>

<p>(Some authors require $\operatorname{dom}(R)=M$ for relational morphisms instead of condition 3. Thus nothing is said about partial homomorphisms, and the useful asymmetry between source and target is maintained.)</p>

<p>Condition 3 feels unnatural to me in this context, because it seems unable to ensure that a morphism is uniquely determined by its behavior on a generating set. But at least $\operatorname{dom}(R)$ would still be determined by its intersection with a generating set, so even this test is not fully conclusive.</p>

<blockquote>
  <p>Questions: Is definition (1) ever used to define partial homomorphisms? Can definition (2) be fixed to reduce its drawbacks? Maybe by using it only to define partial isomorphisms? Is the ""unfixed"" definition (2) ever used?</p>
</blockquote>
",logic
"<p>I remember reading somewhere that it takes about a week to convert a page of math into something a proof-assistant like Isabelle or HOL Light would accept.</p>

<p>Is this type of conversion something that requires a lot of search and creativity, or is it near-mechanical?</p>
",logic
"<p>In number theory there are several operators like ‎addition, ‎multiplication and ‎exponentiation defined from ‎$‎‎‎\omega‎‎\times‎‎\omega‎$ ‎to ‎‎$‎‎‎\omega‎$. Each ‎of ‎them ‎is defined as an ‎iteration of ‎‎‎the other. ‎The sequence of building such iterated operators can go further to define faster and faster <a href=""http://en.wikipedia.org/wiki/Hyperoperation"">hyperoperators</a>‎. The first of them is <a href=""http://en.wikipedia.org/wiki/Tetration"">tetration</a> which is defined as iterated exponentiation. Let ‎$‎‎m\uparrow n$ ‎denote the tetration of ‎$‎‎m$ and ‎$‎n‎$‎ ‎that ‎is‎ ‎‎$‎‎\underbrace{m^{m^{m^{.^{.^{.}}}}}}_{n - times}$. This operator appears in several interesting occasions in logic, computations and combiantorics, for example see these Wikipedia articles on <a href=""http://en.wikipedia.org/wiki/Graham%27s_number"">Graham's number</a>, <a href=""http://en.wikipedia.org/wiki/Ackermann_function"">Ackermann's function</a>, <a href=""http://en.wikipedia.org/wiki/Graham%27s_number"">busy Beaver function</a> and <a href=""http://en.wikipedia.org/wiki/Kolmogorov_complexity#Chaitin.27s_incompleteness_theorem"">Chaitin's incompleteness theorem</a>.<br>
‎</p>

<p>Now consider the infinitary case. ‎In set theory ‎addition, ‎multiplication ‎and ‎exponentiation are defined for  ‎cardinal ‎numbers. ‎</p>

<blockquote>
  <p><strong>Question 1.</strong> What ‎about ‎‎$‎‎‎\kappa‎‎\uparrow‎‎\lambda‎$? ‎How should we define this? ‎
  ‎</p>
</blockquote>

<p>Intuitively, we expect to define ‎$‎‎\aleph_0‎\uparrow‎\aleph_0$ ‎to be  ‎‎$‎\aleph_0^{‎‎\aleph_0^{‎‎\aleph_0^{.^{.^{.}}}}}.$  </p>

<p>But this intuitive definition of tetration  has some counter-intuitive properties, as then ‎we ‎expect ‎to ‎have ‎‎$‎‎‎‎\aleph_0^{(‎‎\aleph_0‎\uparrow‎\aleph_0)}=‎‎\aleph_0‎\uparrow‎\aleph_0$ which is ‎impossible ‎by ‎Cantor's ‎theorem which says ‎$‎‎‎\forall ‎‎\kappa‎\geq\aleph_0\;\;\;\aleph_0^{‎\kappa‎}&gt;‎\kappa‎$.</p>

<p>Note that for the cases of addition, multiplication and exponentiation, we have quite natural operations $f_+, f_\times$ and $f_e$ such that given cardinals $\kappa, \lambda$, we have $f_+(\kappa,\lambda)=\kappa+\lambda, f_\times(\kappa, \lambda)=\kappa\times \lambda$ and $f_e(\kappa,\lambda)=\kappa^\lambda.$ </p>

<blockquote>
  <p><strong>Question 2.</strong> Is there a natural operation $f_t$ defined so that for all natural numbers $m,n$ we have $f_t(m,n)= ‎‎‎m\uparrow n$, and so that its definition is so natural that it also works for infinite cardinal numbers?</p>
</blockquote>

<p>The next question is taken from Noah's answer, where an answer to it may help in defining the tetration for higher infinite.</p>

<blockquote>
  <p><strong>Question 3.</strong> What is $m\uparrow n$ counting?</p>
</blockquote>

<p>See also <a href=""http://math.stackexchange.com/questions/1012260/what-combinatorial-quantity-the-tetration-of-two-natural-numbers-represents"">What combinatorial quantity the tetration of two natural numbers represents?</a>. But note that the answers given in the above question are so that they are not suitable for treating infinite cardinals.</p>
",logic
"<p>Inspired by this <a href=""http://math.stackexchange.com/q/390560/33495"">question</a> on MSE I tried to prove the following:</p>

<blockquote>
  <p>Let $T$ be a complete theory in a first order language and $\kappa$ a cardinal. If $T$ is $\kappa$-stable, then there exists a $\kappa$-saturated model $\mathcal M$ of $T$ such that there is some sequence of indiscernibles $(a_i)_{i&lt;\gamma}$, with $\gamma$ an ordinal of size less than $\kappa$, such that $\langle (a_i)_{i&lt;\gamma}\rangle^{\mathcal M}=\mathcal M$, where $\langle (a_i)_{i&lt;\gamma}\rangle^{\mathcal M}$ is the Skolem hull of $(a_i)_{i&lt;\gamma}$.</p>
</blockquote>

<p>As the following argument shows this holds provided $\kappa$ is regular:</p>

<p>By induction on $\alpha$, let us construct for each $\alpha&lt;\kappa$ a model $\mathcal M_{\alpha}$ of $T$ of size $\kappa$ and a sequence of indiscernibles $I_{\alpha}\subseteq M_{\alpha}$ whose order-type is an ordinal less than $\kappa^+$, and for given $\alpha&lt;\beta$, $\mathcal M_{\alpha}\prec \mathcal M_{\beta}$, $I_{\alpha}\subseteq I_{\beta}$ and each element of $I_{\beta}\setminus I_{\alpha}$ greater than all elements of $I_{\alpha}$ (1).</p>

<p>Let $\mathcal M$ be a model of $T$, and consider $I_0=\{a_{\alpha}:\alpha&lt;\kappa\}$ an enumeration of $\mathcal M$, then using the compactness theorem and Ramsey's theorem we get $\mathcal M_0$ a model of $T$ of size $\kappa$ containing $\mathcal M$ with a sequence $I_0'$ of indiscernibles of order type $\kappa$ which realizes $EM(I_0)$, WLOG we may assume $I_0=I_0'$.</p>

<p>For $\alpha$ limit we simply put $\mathcal M_{\alpha}=\bigcup_{\beta&lt;\alpha}\mathcal M_{\beta}$ and let $I_{\alpha}$ be the concatenation of the $I_{\beta}'$s $(\beta&lt;\alpha)$.</p>

<p>Now suppose $\alpha$ is not limit. </p>

<p>If $\alpha$ is an even ordinal , let $I_{\alpha}=\{a_{\gamma}:\gamma&lt;\mu\}$, where $(a_{\gamma})_{\gamma&lt;\mu}$ is an enumeration of $\mathcal M_{\alpha-1}$ such that for any $\beta&lt;\alpha$ we have that $I_{\beta}$ is bounded in $I_{\alpha}$, $\mu&lt;\kappa^+$, let $\mathcal M_{\alpha}$ be an elementary extension of $\mathcal M_{\alpha-1}$ of size $\kappa$ that realizes $EM(I_{\alpha})$.</p>

<p>If $\alpha$ is an odd ordinal let $\mathcal M_{\alpha}$ be a model of $T$ of size $\kappa$ realizing all types over subsets of $I_{\alpha-1}$ of size less than $\kappa$ in $\mathcal M_{\alpha-1}$, then let $I_{\alpha}$ be the union of all the previous $I_{\beta}'$s and the set of all this realizations, with such a enumeration satisfying (1); $|I_{\alpha}|=\kappa$ as $T$ is $\kappa$-stable.</p>

<p>When we finish at step $\kappa$, let $I$ be the concatenation of all the $I_{\alpha}'$s and put $\mathcal N=\bigcup_{\alpha&lt;\kappa}\mathcal M_{\alpha}$, then by the construction we have that $I$ is a sequence of indiscernibles in $\mathcal N$ of order type less than $\kappa^+$, $\langle I\rangle^{\mathcal N}=\mathcal N$, and thus $\mathcal N$ is $\kappa$-saturated because of the construction.</p>

<p>This solves the MSE question for $\kappa$ regular, as elementary equivalent saturated structures of the same size are isomorphic, and the above model has $2^{\kappa}$ automorphisms.</p>

<p>My question is, can we construct such model for $\kappa$ singular, under the above hypothesis?</p>

<p>Thanks</p>
",logic
"<p>Let H be an infinite dimensional Hilbert space. Then there exist non-normal states on B(H) in ZFC (i.e. states that are not represented by a density operator).</p>

<p>Is this also true in the Solovay model ?</p>

<p>I don't think so but I couldn't find a reference.</p>
",logic
"<p>A function f is <em>diagonaly non-recursive</em> (DNR) if for every Turing index $e$, $f(e) \neq \Phi_e(e)$.</p>

<p>A set is <em>strongly hyperhyperimmune</em> if there is no r.e. set of disjoint r.e. set intersecting it.</p>

<p>In their paper ""A cohesive set which is not high"", the authors claim that the jumps of the strongly hyperhyperimmune degrees coincide with the degrees of functions which are DNR relative to 0'.</p>

<p>How could it be possible knowing that there exists a $low_2$ DNR relative to 0' and of course no jump can be $low_2$ ?</p>
",logic
"<p>The question is whether, when you add a Cohen subset to a cardinal
$\kappa$, that cardinal becomes a characteristic of the resulting forcing extension $V[G]$. Or can there be strange instances in which the very
same model is realized as a Cohen subset forcing extension over
different ground models with different cardinals?</p>

<p>To be precise, can it happen that $M[G]=N[H]$, where $M$ and $N$
are transitive models of ZFC and $G$ is $M$-generic for the
forcing to add a Cohen subset to some cardinal $\kappa$, that is, using $\text{Add}(\kappa,1)^M$, and $H$
is similarly $N$-generic to add a Cohen subset to some other cardinal
$\delta$, using $\text{Add}(\delta,1)^N$?</p>

<p>For a more concrete version of the question, imagine that we have added  a Cohen real $c$ and form
the extension $M[c]$; could it be that this model might also be
realized as $N[A]$ for some other ground model $N$, where $A$ is
an $N$-generic Cohen subset of $\omega_1^N$? Note that $M\neq N$
since it must be that $c\in N$ as the higher forcing does not add
reals. For my application, I need to understand the case where the two cardinals are both inaccessible cardinals (if not much more). Also, it is not difficult to identify general situations where this kind of thing is impossible. What I really want to know is if it can ever happen at all.</p>

<p>I conjecture that this situation is impossible, and that indeed, when you
add a Cohen subset to a cardinal, you have in particular made that
cardinal definable, as ""the cardinal for which the universe was
just obtained by adding a Cohen subset to it"".</p>

<p>The question is really a part of the subject known as
<a href=""http://jdh.hamkins.org/set-theoreticgeology/"">set-theoretic geology</a>, but it has recently arisen in another project of mine.</p>
",logic
"<p>Of all the constructions of the reals, the construction of the surreals seems the most elegant to me.</p>

<p>It seems to immediately capture the total ordering and precision of Dedekind cuts at a fundamental level since the definition of a number is based entirely on how things are ordered.  It avoids, or at least simplifies, the convergence question of Cauchy sequences.  And it naturally transcends finiteness without sacrificing awareness of it.</p>

<p>The one ""rumor"" I've consistently heard is that it is hard to naturally define integrals and derivatives in the surreals, although I have yet to see a solid technical justification of that.</p>

<p>Are there known results that suggest we should avoid further study of this construction, or that show limitations of it?</p>
",logic
"<p>Let $\phi$ be an acceptable programming system. For every recursive function $f$, let $(f)=\{x:\phi_x=\phi_{f(x)}\}$ the set of fixed points of $f$. Now, suppose that $f$ and $g$ are recursive functions such that $(f)$ and $(g)$ are disjoint sets. The question is: are there recursive functions $F$ and $G$ such that $(F)\subseteq(f)$, $(G)\subseteq(g)$ and $\phi_{F(x)}\neq\phi_{G(x)}$, for all $x$?</p>
",logic
"<p>Is it possible to prove $Con(ZFC) \rightarrow Con(ZFC + \neg CH)$ purely within ZFC? To prove this (using forcing) one seems to need a countable transitive model of ZFC. The texts I am reading avoid this by proving Con(T + CH) for all (suitable) finite fragments T of ZFC using the Reflection principle to prove the existence of a countable transitive model of T. But doesn't the Reflection principle operate outside of ZFC? From what I understand it just shows how, given a list of axioms of ZFC, one can write down a proof that constructs a model of these axioms.
Am I confused here or is there an other way to achieve this?</p>
",logic
"<p>Hi. I'll confess from the start to not being a logician. In fact this question came up not from research but during a discussion with a friend about whether the classical proof that $\sqrt{2}$ is irrational can be made acceptable to an intuitionist. (It can be.)</p>

<p>The question is: <em>Are there any ""natural"" statements which can be proven in <a href=""http://en.wikipedia.org/wiki/Peano_axioms"" rel=""nofollow"">Peano Arithmetic</a>, but not in <a href=""http://en.wikipedia.org/wiki/Heyting_arithmetic"" rel=""nofollow"">Heyting Arithmetic</a> (Peano Arithmetic but with a logic that does not admit the law of the excluded middle)?</em> </p>

<p>In fact, any statements -- even pathological ones -- that can be proven in one but not the other would be interesting to me, since I wasn't able to come up with any. (Even after doing a few web searches!) But of course, the closer to the surface the better.</p>
",logic
"<p>The following assertion is trivial in ZFC, or even in much weaker theories. Is it also true in ZF?</p>

<p>(I couldn't find it in the Consequences site so far.)</p>

<blockquote>
  <p>If $A$ is an infinite set such that $A$ can be mapped onto $A\times 2$ then $|A\times 2|=|A|$</p>
</blockquote>

<p>The problem is that we cannot necessarily choose from every fiber of $f$, so we cannot construct an injection from $A$ to $f^{-1}(A\times\lbrace 0\rbrace)$, which will prove the assertion.</p>

<p>While I'm on the topic, is it possible for a D-finite set to have such property? It is possible for a D-finite set to be surjected onto a larger set than itself, but what about <em>that</em> large?</p>
",logic
"<p>$\Sigma_{3}KP\omega$ be Kripke-Platek set theory with infinity and $\Sigma_{3}$-separation and $\Sigma_3$-collection. What strengthening of Barwise's <em>Definition by $\Sigma$ Recursion</em> (Theorem 6.4 on page 26 of Admissible Sets and Structures) is supported by $\Sigma_{3}KP\omega$?</p>
",logic
"<p>In his answer to my question <a href=""http://mathoverflow.net/questions/71432/ordered-fields-with-the-bounded-value-property"">ordered fields with the bounded value property</a>, Ali Enayat showed that if one assumes the countable axiom of choice, then there exists a non-Archimedean ordered field $F$ with the bounded value property, by which I mean: for all $a &lt; b$ in $F$ and for every continuous function $f$ from $[a,b]_F := ${$x \in F: a \leq x \leq b$} to $F$, there exists $B$ in $F$ such that $-B \leq f(x) \leq B$ for all $x$ in $[a,b]_F$.  (Here we say $f$ is continuous if it satisfies the usual $\epsilon,\delta$ definition of continuity, where all quantification is over $F$.)</p>

<p>In the absence of $AC_\omega$, what can one prove?  E.g., could we perhaps prove the assertion using an explicit subfield of the Field of surreal numbers, such as the set of surreal numbers created prior to day $\omega_1$?  (I'm not a logician, so it's possible that such notions as ""the set of surreal numbers created prior to day $\omega_1$"" intrinsically depend on $AC_\omega$ in ways I'm not seeing.)</p>
",logic
"<p>All the statements of the <a href=""http://en.wikipedia.org/wiki/Archimedean_property"" rel=""nofollow"">Archimedean property</a> with which I am acquainted fundamentally uses &#8469; -- more than as a totally ordered semi-group, really being the 'standard model' of the naturals.  It is a fundamental ingredient in showing that the reals are (up to isomorphism) the only complete totally ordered field.</p>

<p>In this particular result, there are two non ingredients which seem to be of a fundamentally different nature: Dedekind completeness (which is about subsets, while all the other axioms are about elements), and the Archimedean property, which pre-supposes the existence of the Naturals.  But because being 'Archimedean' already makes sense in (ordered) monoids, that is the one I am most interested in.</p>

<p>Crazy scenario: replace the 'naturals' in the Archimedean property with a non-standard model of the 'naturals' (call this N-Archimedean).  Now <a href=""http://planetmath.org/encyclopedia/ArchimedeanOrderedFieldsAreReal.html"" rel=""nofollow"">the reasoning for the argument that</a> all Archimedean totally ordered fields are sub-fields of &#8477; readily lifts, but no longer proves quite the same thing.</p>

<p>In other words, it seems that this <em>unique position</em> of &#8477; is in part due to &#8469; already being baked in to the question.  And thus my question: is there a proper generalization of the Archimedean property which is ``properly abstract''?</p>
",logic
"<p>Hi,</p>

<p>Does anyone know the difference between proving that</p>

<pre><code>|- phi
------------------
|- ( psi -&gt; phi )
</code></pre>

<p>and proving that</p>

<pre><code>|- phi -&gt; ( psi -&gt; phi)  ?
</code></pre>

<p>Thanks for any help!</p>

<p>All the best,
Surikator. </p>
",logic
"<p>I came accross the following </p>

<p>Theorem:
If $A$ is an $\aleph_0$- categorical structure, then the algebraically closed substructures of $A$ satisfy the strong amalgamation principle. (for definitions look at the end).</p>

<p>My questions are:</p>

<p>(1) If $T$ is an $\aleph_0$- categorical theory and $B$ is a model of $T$, not necessarily countable, do the algebraically closed substructures of $B$ satisfy strong amalgamation?</p>

<p>If $B_0,B_1,B_2$ are substructures of $B$ such that $B_0\subset B_1,B_2$, I am interested in particular in the case that $B_0,B_1$ (not $B_2$) are finitely generated.</p>

<p>(2) The terms disjoint and strong amalgamation, do they refer to the same property?</p>

<p>(3) Does anyone know a reference to the above theorem?</p>

<p>Definitions:
If $A$ is a structure and $A_0\subset A$, $A_0$ is $algebraically\;\; closed$ if every finite set $B$ that is definable with parameters from $A_0$ is a subset of $A_0$.</p>

<p>If $A_0\subset A_1,A_2$, the triple $(A_0,A_1,A_2)$ have the $strong\; amalgamation \; property$, if there is a structure $A_3$ and embeddings $f:A_1\rightarrow A_3$ and $g:A_2\rightarrow A_3$ such that $f[x]=g[x]$, for all $x\in A_0$ and $f[A_1]\cap g[A_2]=f[A_0]$. </p>
",logic
"<p>If we start with $V\models\lozenge$, it is not hard to force the failure of diamond. You can blow up the continuum, or destroy all the Suslin trees. You can blow up the continuum of $\aleph_1$, and then collapse $\aleph_1$ to be countable.</p>

<p>There are many ways of doing that, but all of them (that I could think of, with the help of a few people over the day) include one of the two:</p>

<ol>
<li>Blowing up the continuum,</li>
<li>Collapsing cardinals.</li>
</ol>

<blockquote>
  <p>Is it consistent that $V\models\lozenge$, and $r$ is a $V$-generic real such that $V[r]\models\lnot\lozenge+\sf CH$ and no cardinals were collapsed between $V$ and $V[r]$?</p>
</blockquote>

<p>If the answer is positive, can we strengthen the preservation of $\sf CH$ by requiring also that the continuum function remains the same (so no blowing up power sets of larger cardinals somehow)?</p>
",logic
"<p>Consider Higher order predicate logic over dependent type theory (DPL) as defined in Chapter 11 of B. Jacobs's book ""Categorical Logic and Type Theory"" (though I think this question applies to first-order predicate logic too).</p>

<p>In the category $\mathbb{P}$ of propositions-in-dependent-type-contexts, an object is a well formed proposition $\Gamma \vdash \varphi:Prop$ and a morphism $(\Gamma \vdash \varphi:Prop) \rightarrow (\Delta \vdash \psi : Prop)$ consists of a context morphism $\vec{M} : \Gamma \rightarrow \Delta$ such that $\Gamma | \varphi \vdash \phi(\vec{M})$ is derivable.  This category $\mathbb{P}$ is fibred over the category of dependent type contexts $\mathbb{C}$ via $(\Gamma \vdash \varphi:Prop) \mapsto \Gamma$.</p>

<p>Consider the ""contradictory proposition"" object, $A$, in $\mathbb{P}$ which I define as $\emptyset \vdash \perp : Prop$ and the ""inconsistent context"" object, $B$, which I define as $x : 0 \vdash \top:Prop$ (where $0$ is the empty type).</p>

<p>I would expect $A$ and $B$ to be isomorphic in $\mathbb{P}$ since both objects seems equally void to me in the sense that neither appear to have any models, i.e. there are no morphisms from the terminal object, $1 := \emptyset \vdash \top : Prop$, to either $A$ or $B$. But, of course, $A$ and $B$ cannot be isomorphic since a morphism from $A$ to $B$ entails the existence of a context morphism $M : \emptyset \rightarrow x : 0$ which would imply that the void type is inhabited.</p>

<p>Can someone assuage my concerns about $A$ and $B$ being equally void yet not isomorphic?</p>
",logic
"<p>According to Godel result, neither ZFC nor other particular theory is strong enough to resolve all questions about, say, Diophantine equations. But maybe we can hope that a sequence of theories will help? It is known that ZFC-1 theory (ZFC + Cons(ZFC) ) is much stronger than ZFC, in sense that now there are theorems with extremely shorter proofs, and many new theorem are now decidable. If we continue this to ZFC-2, .., ZFC-n, ... then ZFC-w which is union of all, ZFC-(w+1) and so on, we can continue to extremely large sets of theories, about all of them we have no doubts, and maybe now for every natural Diophantine equation we can choose a theory witch resolve it? Moreover, if we would be able to imagine non-enumerable set of such theories, may be we could hope that for EVERY Diophantine equation has a corresponding theory from this set in which it can be resolved? Or this is trivially incorrect “conjecture”? It seems that this does not contradict to Godel Theorem, which consider one theory, not a sequence of theories.</p>

<p>Another way of thinking about the same idea is to take only axioms from ZFC but add a new derivation rule, which would say that ""from any set of axioms A it follows that A is consistent"". With this derivation rule we would derive Cons(ZFC) in one step! So, for some reasons (by the way, I do not understand why) Godel theorem is not applicable here. May we hope that with ZFC extended with such a new derivation rule we can, say, solve all Diophantine equations? </p>
",logic
"<p>The standard examples of complete but not model-complete theories seem to be:<br>
- Dense linear orders with endpoints.<br>
- The full theory $\mathrm{Th}(\mathcal{M})$ of $\mathcal{M}$, where $\mathcal{M} = (\mathbb{N}, &gt;)$ is the structure of natural numbers equipped with the relation $&gt;$ (and nothing else, i.e. no addition etc).</p>

<p>Can anyone explain or give a reference to show why any of these two theories are not model-complete, or give another example altogether of a complete but not model complete theory (with explanation)?</p>
",logic
"<p>Tarski's Theorem on the undefinability of truth gives me a bit of a headache, and as a beginner I am still trying to grapple with its consequences. Here's a question.</p>

<p>Let $T$ be the set of Godel numbers of sentences $\sigma$ such that $V \models \sigma$. </p>

<p>Now, I know that by Tarski's theorem, there is no formula that defines $T$ - that is to say, there is no first order formula $\tau (x)$ such that for each $n$, $n \in T \leftrightarrow V \models \tau (n)$. </p>

<p>I can live with that, because obviously some sets are not definable. (Indeed, most are not definable.) But must $T$ exist somewhere in $V$, even if it not definable? The argument is not so obvious to me. Or will this depend on background assumptions? (Whether $V=L$, or whether this or that large cardinal exists, and so on ...) </p>
",logic
"<p>According to wikipedia, the statement ""every polynomial over a countable field that is not the zero polynomial has only finitely many roots"" is equivalent to RCA0 over RCA0* (which is called ERCA-0 in <a href=""http://mathoverflow.net/questions/30904/weakest-subsystems-of-second-order-arithmetic-for-mathematical-logic"">this answer</a>).  I've been interested in reverse math for 1-2 years, so when I got to working with polynomial rings, I got curious as to the strength of the equivalence of their representations as functions and formal polynomials.  Let izizp (identically zero implies zero polynomial) be the following statement:</p>

<p>For all (countably) infinite fields $F$, for all members $c_0,...,c_n$ of $F$, if $\; \displaystyle\sum_{m=0}^n \; \; c_m\cdot x^m \;$ is identically zero, then $c_0,...,c_n$ are all zero.</p>

<p><br></p>

<p>Is izizp a theorem of RCA0*?</p>

<p>Is izizp equivalent to RCA0 over RCA0*?</p>
",logic
"<p>I was wondering (and could not seem to prove or disprove) if epsilon-induction could be derived from the transitive closure operator for binary relations, if we do not have the Foundation Axiom.</p>

<p>The induction of the transitive closure operator is of the form:
If $R(x,y)\subseteq P(x,y)$ and P is a transitive relation, then $R^{+}(x,y)\subseteq P(x,y)$. </p>

<p>I have a hunch that this rule is strong enough to prove epsilon-induction even if we do not assume Foundation, but I may be wrong of course.(It is enought to prove the induction on N by itself). Perhaps some other weaker assumption is needed. 
I'd appreciate your help on this topic.</p>
",logic
"<p>Is there any meaningful sense in which we can talk about o-minimal sentences of $L_{\omega_1,\omega}$? I can give a first attempt, easily; given a countable fragment $F$ and a sentence $\Phi$ in that fragment (or a conjunction of elements of that fragment, so $\Phi$ is an $F$-theory), say $\Phi$ is <em>o-minimal</em> if:</p>

<ul>
<li>$\Phi$ makes $&lt;$ a linear order, and</li>
<li>For every $\phi(x,\overline y)$ in $F$ and every finite tuple $\overline a$, the set $\phi(x,\overline a)$ is a finite union of points and open intervals.</li>
</ul>

<p>Amusingly the conditions above are actually a single sentence (although not typically in $F$) so some questions about elementarity may become vacuous.</p>

<p>My real question is: has this every been studied?  Are the usual theorems (cell decomposition, etc.) stateable and proveable in this framework?  Are there any interesting examples?</p>

<p>If the answer to the first question is no, I'd really like to know why not.  Is there some reason we should expect this not to be interesting?  Or is it just the the o-minimal people and the infinitary logic people aren't the same people?</p>
",logic
"<p>The Completeness Theorem in first-order logic states that any mathematical validity is derivable from axioms. Hence, any informal mathematical proof (which is rigorous) can be translated into a formal proof in any reasonable proof system. However, this formal proof may be larger than the informal, natural-language proof.</p>

<p>Is there any proof system with the property that all known natural-language proofs have formal proofs with only a constant or polynomial blow-up in the proof length?</p>
",logic
"<p>A statement referring to an infinite set can sometimes be logically rephrased using only finite sets/objects.  For example, ""The set of primes is infinite"" &lt;-> ""There is no largest prime"".  Pleasantly, the proof of this statement does not seem to need infinity either (assume a largest prime, contradiction).  </p>

<p>What reason is there, other than convenience or curiosity, to adjoin infinite sets to our universe by axiomatically declaring that one exists?</p>

<p>Specifically:</p>

<blockquote>
  <p>What is an example of a theorem in ZF or ZFC which 1) Does not refer to infinite sets, but 2) Cannot be proven if the Axiom of Infinity is excluded?</p>
</blockquote>

<p>(See <a href=""http://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory#The_axioms"">Zermelo–Fraenkel set theory</a> for the Axiom of Infinity in context.)</p>
",logic
"<p>Let $BB(n)$ denote busy beaver function. It's well known that $BB(n)$ dominates all computable functions (I'm quite certain it includes partial computable functions too). However, I was wondering if we can show similar domination over functions computable from some fixed oracle $A$. In particular, I have been wondering, is it the case that:</p>

<blockquote>
  <p>If $A$ has low r.e. Turing degree (i.e. $A'\equiv_T 0'$), then $BB(n)$ dominates all functions computable from $A$?</p>
</blockquote>

<p>Best I was able to show is that no $A$-computable function can dominate $BB(n)$ (this is quite simple, because if we can bound $BB$, then we can solve halting problem and compute $0'$).</p>

<p>On the other extreme, I know that there exist uncomputable degrees for which the conclusion holds (e.g. hyperimmune-free degrees, because all functions computable from it are dominated by computable functions). However, if we restrict our degrees to be recursively enumerable, I don't know the answer, so a lot simpler version of my question is:</p>

<blockquote>
  <p>Is there an uncomputable r.e. Turing degree such that $BB(n)$ dominates all functions computable from $A$?</p>
</blockquote>

<p>I expect the answer to this last question to be ""yes"".</p>

<p>Thanks in advance.</p>
",logic
"<p>Can the well known <a href=""http://terrytao.wordpress.com/2008/02/05/the-blue-eyed-islanders-puzzle/"">blue eyed islanders puzzle</a> be extended to an infinite number of islanders?</p>

<p>In that puzzle, a set of $k$ islanders, each with either blue eyes or non-blue eyes, each knows the color of every other islander's eyes but not his own. At time $t=0,1,...$ an islander who knows the color of his eyes raises his hand. Each islander can see which other islanders raised their hands at earlier times and nothing else. At time $t=0$ a visitor tells the islanders that at least one of them has blue eyes. All of the above is common knowledge among the islanders.</p>

<p>Suppose $k$ is finite, as in the initial version of the puzzle. Then, if all the islanders have blue eyes, they will all raise their hands at time $t=k$. </p>

<p>If $k$ is infinite, will they ever raise their hands?</p>

<p>I think it is best to assume here $t$ is an ordinal, and that each islander knows who raised his hand at any lower ordinal. </p>

<p>Certainly, if initially only a finite number of islanders have blue eyes, then after a finite time everyone will know his color. Thus, if initially they all have blue eyes, then after time $t=\omega$, it will be common knowledge that there are an infinite number of islanders with blue eyes. Unfortunately, that gets us nothing because I think this fact was already common knowledge at time $t=0$. I also considered maybe having the islanders collaborate on a strategy somehow - so long as they all know the others are using the strategy, and so long as it is still the case each only raises his hand when he knows his own eye color - but made no headway. </p>

<p>More speculatively, is there some kind of variant of this puzzle that could usefully distinguish between knowledge at transfinite times? I played around with different kinds of finite knowledge - maybe each islander can only see a subset of his fellows - but got nowhere.</p>
",logic
"<p>In the answers to <a href=""http://mathoverflow.net/questions/44208/is-there-any-formal-foundation-to-ultrafinitism"">this question</a>, Timothy Gowers asks:</p>

<blockquote>
  <p>I've been interested in this question for some time. I haven't put any serious thought into it, so all I can offer is a further question rather than an answer. (I'm interested in the answers that have already been given though.) My question is this. Is there a system of logic that will allow us to prove only statements that have physical meaning?</p>
</blockquote>

<p>One answer to this question is given by <a href=""http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.155&amp;rep=rep1&amp;type=pdf"" rel=""nofollow"">Fredkin and Toffoli's conservative logic</a>, which is an attempt to give a system of digital logic consistent with various abstract physical principles such as conservation laws, reversibility, and one-to-one composition (ie, no unbounded fanout, since signal strength degrades when signals are split). However, to a proof theorist, the constraints they describe sound hauntingly similar to the language used to motivate linear logic. Furthemore, the circuit diagrams they draw look like string diagrams in monoidal categories, which are models of linear logic. </p>

<p>So my own question is, how is conservative logic related to linear logic?</p>
",logic
"<p>Let $\Sigma$ be a (classic, single-sorted) signature. Denote by $\mathit{Mod}\_H(\Sigma)$ the category of $H$-valued models over $\Sigma$, where $H$ is a complete Heyting algebra. Then for any first-order sentence $\phi$ over $\Sigma$ and any model $M \in \mathit{Mod}\_H(\Sigma)$ the satisfaction relation $M \models \phi$ in defined in the obvious way (i.e. the semantics of $\phi$ in $M$ is the top element of $H$). Denote by $\mathit{Log}\_H(\Sigma)$ the category of first-order sentences over $\Sigma$, and ""proofs"" induced by the relation $\models$, that is: $\phi \rightarrow \psi \Leftrightarrow \forall\_M M \models \phi \Rightarrow M \models \psi$. We shall call such a triple $\langle\mathit{Mod}\_H(\Sigma), \models, \mathit{Log}\_H(\Sigma)\rangle$ a logical system.<br>
A morphism from a logical system $\langle\mathit{Mod}\_H(\Sigma), \models, \mathit{Log}\_H(\Sigma)\rangle$ to a logical system $\langle \mathit{Mod}\_K(\Sigma), \models, \mathit{Log}\_K(\Sigma)\rangle$ consists of a pair of functors $F\_\mathit{mod} \colon \mathit{Mod}\_K(\Sigma) \rightarrow \mathit{Mod}\_H(\Sigma)$ and $F\_\mathit{log} \colon \mathit{Log}\_H(\Sigma) \rightarrow \mathit{Log}\_K(\Sigma)$ (note opposite directions) compatible with the satisfiability relation: $M \models F_\mathit{log}(\phi) \Leftrightarrow F_\mathit{mod}(M) \models \phi$.<br>
A morphism transformation $\alpha \colon F \rightarrow G$ consists of a pair of natural transformations $\langle \alpha\_\mathit{mod} \colon F\_\mathit{mod} \rightarrow G\_\mathit{mod}, \alpha\_\mathit{log} \colon F\_\mathit{log} \rightarrow G\_\mathit{log}\rangle$.<br><br></p>

<p>Is there any interesting adjunction between $\langle\mathit{Mod}_H(\Sigma), \models, \mathit{Log}_H(\Sigma)\rangle$ and $\langle\mathit{Mod}_2(\Sigma), \models, \mathit{Log}_2(\Sigma)\rangle$, where $2$ is the two-valued boolean algebra? Note that the Kolmogorov transformation does not work here.<br><br></p>

<p>Appendix<br>
The truth is that $\mathit{Mod}_H(-)$ are fibred and $\mathit{Log}_H(-)$ are op-fibred over the category of signatures. Such entities (i.e. a fibration, an opfibration and a collection of satisfaction relations) are called ""institutions"". What I am really looking for is an interesting adjunction between such institutions. But this (modulo the Beck-Chevalley condition, what, I guess, is not an issue here) reduces to the above case.</p>
",logic
"<p>I have come to the conclusion that there is often an implied axiom: There are no other axioms.  Failure to explicitly state this axiom and to consider its consequences can result in the misleading conclusion that some true statements are unprovable within a certain system.  For example ZFC with this axiom stated proves CH:</p>

<p>Let an axiom be any statement taken to be true and not proven by propositional logic from the other axioms.</p>

<p>Premise: CH is independent of ZFC (Cohen)</p>

<p>$\implies$ no counterexample to CH can be proven by propositional logic from the axioms of ZFC.</p>

<p>$\implies$ existence of any counterexample to CH would either require or constitute an additional axiom</p>

<p>But there are no other axioms $\implies$ no counterexample to CH exists.</p>

<p>$\implies$ CH.</p>

<p>Note: It is likely that this axiom/theorem negates Godel's incompleteness theorem at least in part.</p>
",logic
"<p>Let S be a propositional modal logic system (extension of K, or even E) with a single unary modal operator and defined by a single non-iterative axiom (i.e. of modal degree 1).  </p>

<p>Is it true that for such a system S, every theorem that is a non-iterative formula has a proof consisting only of non-iterative formulas?  </p>

<p>If yes, can anyone provide a reference where I can find this result?<br>
If no, can you provide a counterexample?</p>

<p>EDIT: Adding clarification of where this comes from.</p>

<p>Denote by P the property in question. A slightly stronger property P' requires all the formulas in the proof to also not exceed N propositional variables, where N is the maximum between the number of variables in the non-iterative axiom and the number of variables in the non-iterative theorem to prove. So basically we are trying to prove a theorem without increasing the modal degree nor the number of propositional variables during the proof (with a possible exception for PC formulas; for example one may use $p \rightarrow p \lor q$ to infer that $\square p \rightarrow \square p \lor \lozenge p$ and this would not count as an increase in the number of variables).</p>

<p>It looks like for a system defined by a combination of iterative and non-iterative axioms these properties do not hold (universally). For example, see Hughes and Cresswell pp 58, in order to prove $\square p\rightarrow \square \square p$ in S5, one must use formulas of modal degree 3 during the proof. The same thing appears to be the case when proving that T+B+S4 implies S5. I also suspect that increasing the number of variables does not help in avoiding the increase in modal degree in these cases, therefore the distinction between P and P'. </p>

<p>However, P and even P' seem to hold for non-iterative systems. Given that these systems are relatively simple (i.e. they have FMP and a number of other ""nice"" properties), I was thinking that P and/or P' may be known results, but I cannot find them.</p>

<p>An algebraic explanation would be interesting for me too. (But I do not see a tag for algebraic-logic.)</p>
",logic
"<p>The question is exactly that of the title: what are Moschovakis cardinals?</p>

<p><strong>Background</strong>. In a recent answer to the question, ""Are there examples of statements that have been proven whose consistency proofs came before their proofs?,"" user14111 posted (<a href=""http://mathoverflow.net/questions/71201/are-there-examples-of-statements-that-have-been-proven-whose-consistency-proofs/137218#137218"">Are there examples of statements that have been proven whose consistency proofs came before their proofs?</a>) an answer involving ""Moschovakis cardinals,"" a large cardinal notion which was shown to be inconsistent at some point in time. Now, googling for Moschovakis cardinals reveals nothing besides that answer and this (<a href=""http://mathforum.org/kb/thread.jspa?forumID=13&amp;threadID=22263&amp;messageID=59655#59655"">http://mathforum.org/kb/thread.jspa?forumID=13&amp;threadID=22263&amp;messageID=59655#59655</a>) Math Forum Discussion post, which seems(?) to be responding to a post which was then deleted.</p>

<p>According to user14111, the notion of a Moschovakis cardinal arose in an unpublished manuscript circulated around the late 60s; given the timing, my current guess is that ""Moschovakis cardinal"" is just a synonym for ""Reinhardt cardinal,"" but I'll admit there is no real basis for my guess.</p>

<p><strong>Why I'm interested</strong>. (Assuming these aren't just Reinhardts in disguise) I'm always interested in large cardinal axioms inconsistent with ZFC; in particular, can Moschovakis cardinals survive in ZF? Also, on a purely historical level, it would be interesting to know about.</p>

<p>Even if Moschovakis=Reinhardt, I'm still intrigued: why would that name be used? I've heard Reinhardt cardinals called Kunen cardinals before, since Kunen proved their inconsistency; but Moschovakis seems to have no relation to the subject that I'm aware of.</p>
",logic
"<p>Let there be an omega sequence of ordinals such that the first is the least $\Sigma_1$-admissible ordinal and the $n+1$st is the least $\Sigma_{n+1}$-admissible ordinal. What is the name, if any, of the union of all of these? Incidentally, $L$ at the level of this ordinal would be the minimal model of ZFC minus the power set axiom.</p>
",logic
"<p>Hamkins showed that his infinite time Turing machine has the power to decide some $\Delta_2^1$ sets. I wonder if some modifications of the machine could be made to reach level $\Sigma_1^2$ sets, or, if no modifications on sight, if the power of his machine plus infinitely iterated super jumps from super oracles (those consisting of uncountable sets of real numbers) could reach that level. </p>
",logic
"<p>I would like to know why the relation: R(x,y) iff x independent from y (i.e: tp(x/y) doesn't fork over the empty set) is type definable in stable theory?</p>

<p>Thanks to the helper.</p>
",logic
"<p>The reals are the unique complete ordered field. The hyperreals $\mathbb{R}^\*$ are not unique in ZFC, and many people seemed to think this was a serious objection to them. Abraham Robinson responded that this was because ZFC was tuned up to guarantee the uniqueness of the reals. Ehrlich wrote a long paper in 2012 (ref and link below), which I've only skimmed so far. It's mainly about the surreals $\textbf{No}$, not the hyperreals, but it seems to suggest that Robinson's idea has been carried forward successfully by people like Keisler and Ehrlich. Apparently NBG set theory has some properties that are better suited to this sort of thing than those of ZFC.</p>

<p>Section 9 of the Ehrlich paper discusses the relationship between $\mathbb{R}^\*$ and $\textbf{No}$ within NBG. He presents Keisler's axioms for the hyperreals, which basically say that they're a proper extension of the reals, the transfer principle holds, and they're saturated. At the end of the section, he states a theorem: ""In NBG there is ... a unique structure $\langle\mathbb{R},\mathbb{R}^\*,*\rangle$ such that [Keisler's axioms] are satisfied and for which $\mathbb{R}^\*$ is a proper class; moreover, in such a structure $\mathbb{R}^\*$ is isomorphic to $\textbf{No}$.""</p>

<p>My question is: Does this result indicate that Robinson's program has been completed successfully and in a way that would satisfy mathematicians in general that the nonuniqueness of the hyperreals is no longer an argument against NSA? It seems to me that this would depend on the consensus about NBG: whether NBG is expected to be consistent; whether it is a natural way of doing set theory with proper classes; and whether a result such as Ehrlich's theorem is likely to be true for any set theory with proper classes, or whether such results are likely to be true only because of some specific properties of NBG (in which case the nonuniqueness has only been made into a new kind of nonuniqueness). Since I know almost nothing about NBG, I don't know the answers to these questions.</p>

<p>One thing that confuses me here is that I thought the surreals lacked the transfer principle, so, e.g., where the hyperreals automatically inherit $\mathbb{Z}^\*$ from $\mathbb{Z}$ as an internal set, a specific effort has to be made to define the omnific integers $\textbf{Oz}$ as a subclass of $\textbf{No}$, and $\textbf{Oz}$ doesn't necessarily have the same properties as $\mathbb{Z}$ with respect to, e.g., induction and prime factorization (see <a href=""http://mathoverflow.net/questions/72691/can-we-axiomatize-omnific-integers-without-the-surreal-number-system"">Can we axiomatize Omnific Integers without the Surreal Number system?</a> ). Would the idea be that according to Ehrlich's result, $\mathbb{Z}^\*$ would be (isomorphic to) a subclass of $\textbf{Oz}$?</p>

<p>I'm a physicist, not a mathematician, and if this seems inappropriate for mathoverflow, please add a comment saying so, and I'll move it to math.SE. I posted here because it relates to current research, but I'm not a competent research-level mathematician.</p>

<p>Philip Ehrlich (2012). ""The absolute arithmetic continuum and the unification of all numbers great and small"". The Bulletin of Symbolic Logic 18 (1): 1–45, <a href=""http://www.math.ucla.edu/~asl/bsl/1801-toc.htm"">http://www.math.ucla.edu/~asl/bsl/1801-toc.htm</a></p>
",logic
"<p>I am going to teach the standard undergraduate Logic course for math and engineering majors. What are good (bad) text-books and why. I have not taught that course for a while and wonder if there are new good books. Also those who took/taught such a course recently, please let me know your opinion about the text you used. I do not need Computer Science applications (I can include them myself, if needed). Just a standard first course in Mathematical Logic. </p>
",logic
"<p>Does anyone have a good reference for the method of giving a topology to a distributive lattice as outlined in M.H. Stone's ""Topological representation of distributive lattices and Brouwerian logics""? The full reference for that paper is:</p>

<p>M.H. Stone, Topological representation of distributive lattices and Brouwerian logics, ˇCasopis Pešt. Mat. Fys. 67 (1937) 1–25.</p>

<p>But I cannot seem to find an actual copy of the paper. Perhaps there are more recent references that outline the process in more modern terms, or perhaps it is very simply and can simply be described in an answer here. I have heard that the construction involves choosing ultrafilters, but from what I can glean ABOUT Stone's paper (e.g. a 1938 review of it by Saunders MacLane, Stone seems to do things in terms of so-called ideals of the lattice). </p>

<p>Thanks for any help!</p>
",logic
"<p>In the paper, </p>

<ul>
<li><em>Aldo Antonelli and Robert May</em>, <a href=""http://dx.doi.org/10.1305/ndjfl/1038336844"" rel=""nofollow""><strong>Frege's new science</strong></a>, <em>Notre Dame J. Form. Log.</em> <strong>41</strong> (2000), no. 3, 242–-270, <a href=""http://ams.org/mathscinet-getitem?mr=1943495"" rel=""nofollow"">MR 1943495</a>.</li>
</ul>

<p>the authors give the following quote of Frege, from his paper ""&Uuml;ber die Grundlagen der Geometrie""<sup>*</sup>:</p>

<blockquote>
  <p>What I call a proposition <em>tout court</em> or a real proposition is a group of of signs that expresses a thought [has a sense&mdash;my comment]; however, whatever only has the grammatical form [i.e. being a well-formed formula&mdash;my comment] of a proposition I call a pseudo-proposition.<sup>&dagger;</sup></p>
</blockquote>

<p>Since it is well-known that $$R \notin R \Leftrightarrow R \in R$$ (this is actually true if both $R \notin R$ and $R \in R$ are false, but then this seems to contradict the Law of Excluded Middle), can one rightly attribute either a reference (since they are 'propositions', their reference must be, according to Frege, either The True, or The False) or a sense (what would that be, exactly) to ""$R \notin R$"" or ""$R \in R$""?  And if not, are ""$R \notin R$"", ""$R \in R$"" pseudo-propositions?</p>

<p>Furthermore, since $$R \notin R \Leftrightarrow R \in R$$ can be derived from Basic Law V, shouldn't Basic Law V be restricted to apply only to ""real propositions""?  And how might that be done in the context of the <em>Grundgesetze</em>?   </p>

<hr>

<p><sup>*</sup><sub>In <em>Jahresbericht der Deutschen Mathematiker Vereinigung</em>, vol. 15 (1906), pp. 293-309, 377-403, 423-30.</sub><br>
<sup>&dagger;</sup><sub>English translation by E-H. W. Kluge in <em>Gottlob Frege, On the Foundations of Geometry and Formal Theories of Arithmetic</em>, Yale University Press, 1971, p.69.</sub></p>
",logic
"<p>The <a href=""http://mathoverflow.net/questions/164694/are-all-functions-in-bishops-constructive-mathematics-continuous"">partial μ-recursive functions</a> which may or may not be provably total seem to have some direct relation to the initial motivations for intuitionistic mathematics. (Following Kronecker, one motivation might have been that mathematical statements should be reducible to statements about the natural numbers, or computable functions of the natural numbers.)</p>

<p>When Brouwer and Heyting did their initial work, the understanding of those partial functions was still evolving significantly. However, this excuse no longer applies to the time when Errett Bishop published his <em><a href=""http://mathoverflow.net/questions/164694/are-all-functions-in-bishops-constructive-mathematics-continuous"">Foundations of constructive analysis</a></em>. However, extramathematical observations like that ""<a href=""http://mathoverflow.net/questions/164694/are-all-functions-in-bishops-constructive-mathematics-continuous"">all functions in Bishop's constructive mathematics are continuous</a>"" indicate that <em>function</em> always meant <em>provably total function</em>, because otherwise a formulation like ""no discontinuous function can be proved to be total in Bishop's constructive mathematics"" would seem to be less misleading and better capture what is really going on.</p>

<p>So did Bishop, Heyting or Brouwer (or any other prominent ""early"" proponent of intuitionism) explicitly discussed this relationship, and clearly indicated to role (and treatment) of such partial functions in intuitionistic mathematics?</p>
",logic
"<p>Call two axioms equivalent if they imply the same set of theorems. I am interested in decidability of so defined equivalence. In this generality the problem is obviously undecidable since it can be used to decide Entscheidungsproblem. So I am interested in cases where Entscheidungsproblem is decidable, particularly in case of monadic axioms (i.e. axioms containing only monadic functional and predicate symbols).</p>

<p>Any information about this would be appreciated.</p>

<p>Thank you for your time,
Levon</p>
",logic
"<p>Let $K$ be a field and $K\{X\}$ be the free non-associative algebra, freely generated by the countably infinite set $X$. We consider elements of $K\{X\}$ as (non-associative) polynomials in the variables of $X$.</p>

<p>Given $\mathfrak{F}\subseteq K\{X\}$, one can consider the variety of algebras defined by $\mathfrak{F}$. This is the class of all algebras which satisfy all identities of $\mathfrak{F}$, i.e., an algebra $A$ is an algebra in such variety if given $p\in \mathfrak{F}$, for any $a_i\in A$, we have $p(a_1,\dots,a_n)=0$.</p>

<p>For example, if one consider the polynomial $p=x(yz)-(xy)z$, the variety of algebras defined by $\{p\}$ is the variety of associative algebras. </p>

<p>My question is the following:</p>

<blockquote>
  <p>Is the variety of algebras defined by some $\mathfrak{F}\subseteq K\{X\}$, a set?</p>
</blockquote>

<p>A simpler question:
Is a variety of associative algebras a set?</p>
",logic
"<p>Suppose 0# exists.</p>

<p>It is clear that every order preserving map from the indiscernibles to the indiscernibles gives an elementary embedding from $L$ to $L$. Furthermore, following lemmas 18.7 and 18.8 of Jech, if $\alpha$ is an <i> <strike>infinite </strike> infinite limit</i> ordinal, an increasing map from alpha to beta gives an elementary embedding from $L_{i_\alpha}$ to $L_{i_\beta}$, where $i_\alpha$ is the $\alpha$-th indiscernible. This is because $L_{i_\alpha}$ equals the Skolem hull in itself of the first $\alpha$ indiscernibles. However, I am not clear on the following points.</p>

<p>1) Is it the case that for a <i><strike>finite</strike> successor</i> ordinal, n, $L_{i_n}$ is necessarily equal to the Skolem hull in $L_{i_n}$ of the first n indiscernibles? Jech only proves this result for infinite ordinals. </p>

<p>2) Is it possible that there could be an elementary embedding from $L$ to $L$, or from $L_{i_\alpha}$ to $L_{i_\beta}$ ($\alpha, \beta$ may be finite or infinite), that does not always map indiscernibles to indiscernibles? 
This sounds weird, but I'm not convinced it's impossible. As far as I know, there's no formula in $L$ that defines ""$\alpha$ is a Silver indiscernible."" (In fact there is no such formula -- see Andreas Blass's comment below.)</p>
",logic
"<p>Assume that $(P,\le)$ is a notion of forcing. There are several ways to define what it means for $P$ being proper and I would like to know: What is the complexity (in terms of the Levy-Hierarchy) of the statement 'P is proper'?</p>
",logic
"<p>Let $\bar{\mathbb{R}}$ be the structure of the real field, that is $(\mathbb{R},0,1,+,-,*,&lt;)$ . We say that a function $f$ is of growth higher than exponential if for all $N\in \mathbb{N}$ there $f(x)$ is ultimately greater than $\exp^N(x)$. That is there is we can find $r\in \mathbb{R}$ such that for all $x&gt;k$ we have $\exp^N(x) &lt; f(x)$ where  $\exp^N(x)$ stands for $\exp(\exp(\cdots \exp(x)\cdots))$ $N$ times. </p>

<p>Is it possible to find an o-minimal expansion (in the model theoretic sense) of $\bar{\mathbb{R}}$ where an $f$ as above is definable?</p>
",logic
"<p>For many years I had the idea that if a well-founded tree is both very tall and very narrow, then it must have a cofinal branch.  For example, it is a fun exercise to show that any $\omega_1$-tree with all levels finite has a cofinal branch. A similar fact holds also for much taller trees with all levels finite. I used to think that such a phenomenon might hold even more generally, for trees that are much taller than they are wide, although not necessarily finite. But after a conversation this evening with some other set theorists, I am less sure. And so I ask for a counter-example:</p>

<p><strong>Question.</strong> Is it (relatively) consistent with ZFC that there is a tree of height $\omega_2$ with all levels countable, with no cofinal branches? </p>

<p>More generally, under what circumstances can we have very tall trees with very small levels, but no cofinal branch? What general theorems about this are available? In what cases are there provable instances where there is a cofinal branch for tall narrow trees? </p>

<p>(Incidentally, I think it would be fine as a warm-up if someone were to post a solution to the fun exercise I mention, that is, that every tree of height $\omega_1$ and all levels finite has a cofinal branch; or some generalization of this. What is the best way to see it?)</p>
",logic
"<p>Additionally, is there any intuitive way to visualize the cardinalities that result?</p>
",logic
"<p>Suppose 1st-order arithmetic is inconsistent along with Voevodsky <a href=""http://video.ias.edu/voevodsky-80th"" rel=""nofollow"">http://video.ias.edu/voevodsky-80th</a>. </p>

<p>It nevertheless remains true that when you have 2 apples and 2 apples, you have 4 apples. Preforming an experiment gives you the result of an experiment, which cannot be inconsistent. So there is a subset of arithmetic that is ""necessarily"" consistent, given the notion (maps) that arithmetic models reality. The question is, what is this ""physically consistent"" proper subset of arithmetic? </p>

<p>The second question is, what happens if the physical theory is quantum field theory, where quanta loose their individual identity or ""primitive thisness""?</p>
",logic
"<p>Terminology:</p>

<p>Cohesive sets: $A\subset \omega$, for each recursively enumerable set $W_e$, either $A\cap W_e$ is finite or $A\cap(\omega\setminus W_e)$ is finite.</p>

<p>Non-high degrees: Degree $a$ such that $a'\not\geq 0''$.</p>

<p>I'm wondering if it is possible to construct a cohesive set using some non-high 1-generic degree as an oracle? i.e. are there $A$ cohesive, and $B$ non-high 1-generic such that $A\leq_T B$? Thanks in advance!</p>
",logic
"<p>Consider an elementary chain of models of some first-order theory $T$:
 $$ (M_\alpha)_{\alpha &lt; \kappa}, M_\alpha \prec M_\beta  \; {\rm for} \; \alpha &lt; \beta .$$
Let also $(N_\alpha)$ be another elementary chain of models of the same theory.
Assume, that for every $\alpha &lt; \kappa$ ($\kappa$ a cardinal) we have an isomorphism $f_\alpha: M_\alpha \to N_\alpha$. Is there a way to extend these isomorphisms to an isomorphism<br>
$f: M \to N$, $M:= \bigcup_{\alpha &lt; \kappa} M_\alpha$, $N:= \bigcup_{\alpha &lt; \kappa} N_\alpha$, even if we don't assume that the restriction of $f_\beta$ to $M_\alpha$ for $\alpha &lt; \beta$ is equal to $f_\alpha$?</p>
",logic
"<p>Theorem 2.65 in Woodin's <a href=""http://www.ams.org/mathscinet-getitem?mr=2723878"">book</a> shows that a saturated ideal on $\omega_1$ exists after Levy-collapsing a Woodin cardinal $\delta$ to $\omega_2$.  I am confused about the part of the argument where he shows that ideal he defines is a proper ideal.</p>

<p>Claim (2.2) on page 50 says we can find a countable structure $X \prec H_{\delta^+}$ and an $X$-generic condition $p$ such that for all inaccessible $\gamma \in X \cap \delta$ and $Col(\omega_1,&lt;\gamma)$-names $\tau \in X$ for a semi-proper subset of $\mathcal P(\omega_1)/NS$, there is a $\sigma \in X$ such that $p \Vdash \sigma \in \tau$ and $p \Vdash X \cap \omega_1 \in \sigma$.  He says we construct this pair $(X,p)$ by an elementary chain.</p>

<p>Suppose $X_0 \prec H_{\delta^+}$ and $p_0 \restriction \gamma \in X_0$.  By definition of semi-proper, if $\tau \in X_0$ is as above, then $p_0 \Vdash_\gamma (\exists y \in \tau) Sk(X_0[G_\gamma] \cup \{ y \}) \cap \omega_1 = X_0[G_\gamma] \cap \omega_1$ and $X_0[G_\gamma] \cap \omega_1 \in y$.  The problem I have is: How do we choose a <em>name</em> for $y$ with a similar property?  There is a name $\sigma$ such that $p_0$ forces $\sigma^G$ witnesses the above property of $y$ in $V[G_\gamma]$, but could it be that $Sk(X_0 \cup \{ \sigma \}) \cap \omega_1 \not= X_0 \cap \omega_1$?</p>

<p>Or perhaps there is a quite different strategy for building the elementary chain.  Thanks for your help!</p>
",logic
"<p>Was ""arithmetical translation"" (that is, coding in the Goedel sense) ever a part of Hilbert's Program?  I ask this question for several reasons:</p>

<p>i) it gives the numerals |, ||, |||,.... an ersatz 'meaning' in themselves  and Hilbert (at least in his paper ""On the Infinite"") states that ""These numerals, which are the object of our consideration, have no meaning at all in themselves.""</p>

<p>ii) inasmuch as a formal first-order theory $T$ (containing enough arithmetic for Goedel numbering) was to be treated as a 'formula game' of 'meaningless symbols' for the purpose obtaining a finitary consistency proof of $T$, ""arithmetical translation"" of $T$ into itself gives these 'meaningless formulae' meaning, which produces self-reference (assuming $T$ proves multiplication to be total, following Dan Willard's results regarding self-verifying formal theories) which, assuming $T$ proves multiplication to be total, derives the incompleteness theorems.  But then, what was the purpose of Hilbert requiring the formulae of $T$ to be 'meaningless'?  Wasn't it the purpose of actually having a finitary proof of the consistency of $T$ (meaning that treating the formulae of $T$ as meaningless strings of symbols may allow one to avoid, say, the use of primitive recursive functionals of finite type to prove the consistency of $T$, as Goedel does for $PA$)?</p>

<p>iii) Consider also the following statement of Bernays from his survey article from 1935, ""Hilbert's investigations on the foundations of arithmetic"" (Bernays project:  Text no. 14, translation by Dirk Schlimm, which can be found under title <a href=""http://www.phil.cmu.edu/projects/bernays/Pdf/untersuchungen.pdf"" rel=""nofollow"">on the web</a>) regarding Goedel's incompleteness theorems:</p>

<p>""The theorem mentioned [that is, the one that decides ""whether it is possible to provide a proof for the consistency of number the theoretic formalism with elementary combinatorial methods in the sense of the 'finite standpoint' ""]  is one of the different important results of Goedels' paper [""On Formally Undecidable propositions of Principia Mathematica and Related Systems I], which has brought fundamental enlightenment with regards to the relation between contentfulness and formalism--whose investigation has been mentioned by Hilbert in ""Axiomatisches Denken"" as one of the aims of proof theory.</p>

<p>The basic message of the theorem is that a proof for the consistency of a consistent formalism, which encompasses the usual logical calculus and number theory, cannot be represented in this formalism itself, more precisely:  it is not possible to deduce the elementary arithmetical theorem which represents the claim of the consistency of the formalism--based on a certain kind of enumeration of the symbols and variables and an enumeration of the formulas and of the finite series of formulas derivated from it--in the formalism itself.      </p>

<p>To be sure, nothing is said hereby directly about the possibility of finite consistency proofs; but a criterion follows, which every proof of the consistency for a formalism of number theory or a more comprehensive formalism has to meet:  a consideration must occur in the proof which can not be represented--based on the arithmetical translation--in the formalism mentioned.""</p>

<p>If anyone can provide a cite from any of Hilbert's writings, letters, etc. stating that arithmetization (or any other form of coding) of some first-order theory $T$ in itself was a part of his program, I would be very grateful.  Thanks in advance for your help. </p>
",logic
"<p>What is known about the failure of $\Diamond_{\kappa}$ (diamond at $\kappa$) for $\kappa$ (the least) inaccessible, (the least) Mahlo and (the least) weakly compact. </p>

<p><strong>Remark.</strong> The problem of forcing the failure of diamond at a weakly compact cardinal is solved recently by Gitik's student Omer Ben-Neria (see  <a href=""http://settheory.mathtalks.org/omer-ben-neria-the-failure-of-diamond-at-large-cardinals-and-gch/"" rel=""nofollow"">The failure of diamond at large cardinals and GCH</a>). This solves a longstanding open problem.</p>

<p>Does anyone know the main ideas of the proof?</p>
",logic
"<p>Apparently, the closest thing I've found would be normal number <a href=""http://mathworld.wolfram.com/NormalNumber.html"">http://mathworld.wolfram.com/NormalNumber.html</a> </p>

<p>But requiring that every finite words occurs is weaker than this property. So I'm wondering if there are any study on this topic.</p>

<p>My original goal is to find a criterion for a Büchi automaton not to recognize some infinite word like this. There's been a post here <a href=""http://mathoverflow.net/questions/145375/proof-that-the-omega-language-consisting-of-all-words-containing-every-finite"">Proof that the $\omega$-language consisting of all words containing every finite word as a factor is not rational/regular</a> , but there were no references to such a class of words.</p>

<p>Maybe all this is obvious to specialists, but I couldn't find anything with our universal friend google :)</p>

<p>Thank you!</p>
",logic
"<p>A poset $\mathbb{P}$ is called <em>well-met</em> iff every pair of compatible conditions in $\mathbb{P}$ has a greatest lower bound.  </p>

<p>Question:  Suppose $\mathbb{P}$ is a separative partial order which is $\lambda$-directed closed (for some regular infinite cardinal $\lambda$).  Can we always view $\mathbb{P}$ as a dense suborder of a well-met poset which is still $\lambda$-directed closed?</p>

<p>I'm vaguely aware that Boolean completions can screw up properties like directed closure, but I'm only asking for finite infima, not arbitrary infima.  It's not clear to me that the obvious ""well-met closure"" of $\mathbb{P}$ is still $\lambda$-directed closed, but I also don't have a counterexample.</p>
",logic
"<p>Suppose that $V$ is a model of $\sf ZFC$, and fix some regular $\kappa$, say $\omega_1$ for practical purposes.</p>

<p>Let $\cal U$ be an ultrafilter on $\omega_1$ in $V$ which is non-principal and even uniform. Let $\Bbb P$ be a forcing such that:</p>

<ol>
<li>$\Bbb P$ does not add bounded subsets to $\kappa$, but its generic defines a canonical unbounded subset of $\kappa$, say $G$.</li>
<li>$\Bbb P$ satisfies $\kappa^+$-c.c.</li>
<li>$\Bbb P$ is homogeneous.</li>
</ol>

<p>Of course that $\cal U$ is not an ultrafilter in $V[G]$ since it is no longer closed under supersets. But we can ask whether or not $\mathcal U\cup\{G\}$ is an ultrafilter base.</p>

<blockquote>
  <p>Is there a condition on $\cal U$ (or an additional condition on $\Bbb P$ or $G$) which guarantee that $\mathcal U\cup\{G\}$ is an ultrafilter base in $V[G]$?</p>
</blockquote>
",logic
"<p>In Kechris's book ""Classical Descriputive set theory"" Chapter 23 (Exercise 23.4), it claim that there is a $\Sigma^0_\xi$-complete ideal on $\omega$ for each $\xi\geq 3$. </p>

<p>There is a candidate construction as follows: give a $\Sigma^0_\xi$-complete $A$ subset of $2^\omega$, define an ideal $\mathcal I_A$ on ${}^{&lt;\omega}2$ generated by $\{\{x|n:n\in\omega\}:x\in A\}$. I don't underatand why the Borel hierarchy of $\mathcal I_A$ isn't bigger than $\xi$?</p>

<p>Is there a different construction?  </p>
",logic
"<p>I want to see if it is possible to force the existence of a function 
$F:\aleph_2 \times \aleph_2\rightarrow \aleph_1$ such that:</p>

<p>a) $F(a,b)=F(b,a)$, for all $a,b\in \aleph_2$ and </p>

<p>b) for all distinct $a,b$, the set $\{x|F(a,x)=F(b,x)\}$ is finite.</p>

<p>What is known:</p>

<p>1) Under CH, there is no such function. </p>

<p>2) If such a function exists, let A be a subset of $\aleph_2$ of size $\aleph_1$. Consider the functions $F(a,\cdot)$ restricted to A. We have a family of $\aleph_2$ many such functions from $\aleph_1$ to $\aleph_1$ and any two of them agree only on a finite set. That's a strongly almost disjoint family of size $\aleph_2$. Baumgartner call this $A(\aleph_1,\aleph_2,\aleph_1,\aleph_0)$. It is consistent together with the negation of CH that either $A(\aleph_1,\aleph_2,\aleph_1,\aleph_0)$ or its negation hold. In particular, 
$\neg CH$ + ""there is no such function"" is consistent.</p>

<p>I want to see if anyone knows any result on the positive side.</p>
",logic
"<p>Consider $\phi(A)$ a formula of second-order arithmetic with one free variable $A$ of type ""set"". Suppose $\exists A : \phi(A)$ is a true sentence. Does it follow (not in second order arithmetic itself, but in a stronger theory of your choice, e.g. ZFC) that there is a formula of second-order arithmetic $\psi(n)$ with one free variable $n$ of type ""number"", such that $\phi(\lbrace n | \psi(n)\rbrace)$ is a true sentence?</p>
",logic
"<p>Hello,</p>

<p>The proofs in logic often use the notion of truth.</p>

<p>Can we ignore the notion of truth, if we add axioms to the Peano's axioms ?</p>

<p>Is it possible to prove Gödel's first incompleteness theorem without the notion of truth ?</p>

<p>The proof of the Gödel's first incompleteness theorem, that I know is:
Gödel numbers by $n$ the statements $E_n(i)$ with one argument $i$.
""$E_i(i)$ is not provable"" is a statement $A(i)$. There is an $n$ such that $A$ is $E_n$. The proof of the theorem says: if $A(n)$ is not $\mathit{true}$, $E_n(n)$ is provable. So $A(n)$ is provable, and $A(n)$ is $\mathit{true}$, contradiction. So $A(n)$ is $\mathit{true}$, and not provable.</p>

<p>If $n$ is the Gödel's number of a statement $Q_n$ (without argument), and if $P(n)$ is the statement saying that $Q_n$ is provable in the formal system of Peano's axioms, we add, for every $n$, the axiom: ""$P(n) \implies Q_n$"".</p>

<p>So the step ""$A(n)$ is provable, implies $A(n)$"" in the previous proof, is an axiom.</p>

<p>So we don't use the notion of truth. Do you have references about this subject ?</p>

<p>Thanks in advance.</p>
",logic
"<p>Simpson's <em>Subsystems of Second Order Arithmetic</em> (pp. 134ff.) uses RCA$_0$ to prove various theorems of analysis for  all continuous functions with a suitable modulus of uniform continuity.  And he notes that RCA$_0$ itself proves ""any continuous function which arises in practice"" does have such a modulus.  Is there a place I can go to see many examples of the functions this covers?  I am especially interested in various complex analytic functions arising in analytic number theory. </p>
",logic
"<p>This question comes from the <a href=""http://en.wikipedia.org/wiki/Kleene%27s_O#Properties_of_Paths_in"" rel=""nofollow"">
Wikipedia article on Kleene's O</a> and a <a href=""http://mathoverflow.net/questions/71584/hyperarithmetic-statements-decidable-by-induction-up-to-a-recursive-ordinal"">previous Math Overflow question</a>.
The claim in Wikipedia that I have a question about is the second sentence in the following quote.
""There exist $\aleph_0$ paths through $\mathcal{O}$ which are $\Pi^1_1$. Given a progression of recursively enumerable theories based on iterating Uniform Reflection, each such path is incomplete with respect to the set of true $\Pi^0_1$ sentences.""
I do not understand the informal proof in the second sentence I would appreciate a more complete explanation and/or a reference.</p>
",logic
"<p>Given a finite set of statements known to be true, I need to derive all the ""non-redundant"" statements in disjunctive form using only literals that can be derived from this set of statements, i e all statements on the form (a &or; b &or; c &or; ...) where a, b ... are literals. By non-redundant I mean that I do not wish to include a statement if one of the literals could be removed and it would still always be true (given the initial set of statements).</p>

<p>Another way of looking at this would be that I want a statements in conjunctive normal form, but that includes all non-redundant statements as the inner groups, not just the minimal set equivalent to the initial set of statements.</p>

<p>A naive algorithm for this would be to test all assignments of truth values to literals, keeping only the ones that 1) are true given the initial set of statements 2) are non-redundant (tested by assigning false to each of the literals in the statement, checking if it still remains slow). However, the number of literals I'll be working with will be so large that this naive approach is not feasible.</p>

<p><strong>Edit:</strong></p>

<p>What I'm looking for is an algorithm that will efficiently produce the set of statements as described above, such as the strategies that can be used to convert to a conjunctive normal form.</p>
",logic
"<p>I am trying to understand bits and pieces of Lawvere's article <a href=""https://www.dropbox.com/s/p8739l5bk01dpdc/Lawvere%20F.W%20-%20Continuously%20Variable%20Sets%3B%20Algebraic%20Geometry%20%3D%20Geometric%20Logic.pdf?dl=0"" rel=""nofollow""><em>Continuously Variable Sets; Algebraic Geometry = Geometric Logic</em></a>. I'm not doing very well.</p>

<p>I know this is a lot to ask, but basically, I would like for someone to explain in more detail the whole construction described at the end of the paper. I was told the idea is to get a ""free local ring"", which is free simply because of the internal language of the corresponding sheaf topos which makes any ring locally free, but I really don't know what that means and I still don't understand the idea and details of the construction in the paper. I stress that I'm looking for a detailed explanation; I realize that the idea may be encapsulated in a short elegant statement, but I won't be able to decode it..</p>

<p>So... What the hell is going on there? :D</p>
",logic
"<p>Let $w$ be a group word with variables $\bar x, \bar y$, where
$\bar x=(x_1,\dots ,x_m)$ and
$\bar y=(y_1,\dots ,y_n).$ 
I am interested in the following questions.</p>

<p>(1) Is the sentence $(\forall\bar x)(\exists\bar y)w=1$
true in every group if it is true in every finite group? </p>

<p>(2) Is the sentence $(\exists\bar x)(\forall\bar y)w=1$  true in every group if it is true in every finite group? </p>

<p>For $m=2$ and $n=4$ the answer to (1)
is negative, in general, as shown in <a href=""http://www.ams.org/journals/proc/1999-127-04/S0002-9939-99-04747-4/S0002-9939-99-04747-4.pdf"">T. Coulbois, A. Khelif,
Proc. AMS 127 (1999), No. 4, 963--965</a>.</p>

<p>In  <a href=""http://mathoverflow.net/questions/207438/on-sentences-true-in-all-finite-groups"">On sentences true in all finite groups</a>
I asked the questions (1) and (2) for $m=n=1$.</p>

<p>Bjørn Kjos-Hanssen gave positive answers to these questions.
In fact, his answers can be generalized: 
an answer is positive for (1) if $m=1$, and for (2) if $n=1$.
The open questions I want to ask:</p>

<blockquote>
  <p>(a) Is  $(\forall xy)(\exists z)w(x,y,z)=1$
  true in every group if it is true in every finite group? </p>
  
  <p>(b) Is  $(\exists x)(\forall yz)w(x,y,z)=1$  true in every group if it is true in every finite group? </p>
</blockquote>
",logic
"<p>Let $\mathcal{A}$ be an uncountable almost disjoint family (not necessarily maximal) of infinite subsets of $\mathbb{N}$. Denote by $\mathcal{A}_{\subseteq}=\{ B\subseteq\mathbb{N}:|B|=\omega \wedge \exists A\in\mathcal{A}(B\subseteq A) \}$.</p>

<p>Question 1: Must there exist a $B\in\mathcal{A}_{\subseteq}$ such that for any $n$, $\{C\in\mathcal{A}:|C\cap B|\geq n\}$ is uncountable?</p>

<p>If this is true, then:</p>

<p>Question 1':  Must there exist a $B\in\mathcal{A}_{\subseteq}$ such that for any $n$, $\{C\in\mathcal{A}:B\upharpoonright n\subset C\}$ is uncountable? (By $B\upharpoonright n$, I mean the first $n$ elements of $B$ listed in increasing order.)</p>

<p>I don't have an intuition as to whether this should be true or false, but the question stems from the observation that for any uncountable family $\mathcal{A}$ of subsets of $\mathbb{N}$, there is an $n\in\mathbb{N}$ such that $\{A\in\mathcal{A}:n\in A\}$ is uncountable.</p>

<p>EDIT: As seen in the solutions below, the passage to $\mathcal{A}_{\subseteq}$ is unnecessary.</p>

<p>EDIT: In light of the positive answer to the questions above, I'll add an additional question that I am interested in.</p>

<p>Question 2: Must there be a <em>sequence</em> $(A_n)_{n\in\omega}$ of distinct elements of $\mathcal{A}$ (or elements of $\mathcal{A}_{\subseteq}$ which are below pairwise distinct elements of $\mathcal{A}$) such that for any $n$, $\{B\in\mathcal{A}:\forall i\leq n(A_i\upharpoonright n\subset B)\}$ (or $\{B\in\mathcal{A}:\forall i\leq n(A_i\upharpoonright n-i\subset B)\}$) is uncountable. (Again, $A \upharpoonright n$ means the first $n$ elements of $A$ listed in increasing order, it does <em>not</em> mean the elements of $A$ below $n$ here.)</p>
",logic
"<p>One obvious strategy for proving P not equal to NP would be to show that there is some problem in NP which is hard for a time class strictly containing P (the origin of this question is the recent result that graph isomorphism is in quasipolynomial time-- so for example one could imagine proving graph isomorphism hard for some quasipolynomial time class). An obvious obstruction to this would be if there are no time classes strictly containing P and contained in NP. So this leads to the following question: under standard complexity theoretic assumptions (whatever you like, but please be clear what you are assuming in your answer) is it known whether there are or are not time classes strictly containing P and contained in NP? What are the consequences of assuming there are or are not such classes?</p>
",logic
"<p>Let $G$ be a fully residually free group with a finitely generated profinite completion. Is $G$ necessarily finitely generated?</p>
",logic
"<p>intuitionistic logic ~ programming</p>

<p>natural deduction ~ lambda-calculus</p>

<p>Hilbert system ~ combinatory logic {S, K}</p>

<p>Gentzen system=sequent calculus ~ ?</p>

<p>What would you write in place of the question mark?</p>

<p>Update 0: Common mathematical tree notation for proofs is too cumbersome and redundant. I need a language as compact as e.g.:</p>

<p><code>
data Proof = Apply Proof Proof | S | K {- Haskell, combinatory logic -}
</code></p>

<p>Update 1: After following the links suggested by commentators I found this perfectly concrete and accessible article: ""Hugo Herbelin. A Lambda-calculus Structure Isomorphic to Gentzen-style Sequent Calculus Structure."" There, ""?"" language is named ""the usual interpretation of LJ cut-free proofs by normal lambda-terms"", i.e. is made out of lambda-calculus.</p>
",logic
"<p>Let's work in a set theory without assuming AC (for instance, but not necessarily, ZF). Fix a set $k$ satisfying $k\times k \simeq k$, and consider its powerset $X = 2^k$. I have a technical condition that is satisfied whenever $X$ is well-orderable, but I can't tell what other examples there might be. Excuse the peculiar phrasing: I'm aiming for the most constructive means possible (by ""well-orderable"" I mean classically so: a total order such that every inhabited subset has a least element. This is equivalent to $X$ being a <a href=""http://ncatlab.org/nlab/show/choice+object"" rel=""nofollow"">choice object</a>). </p>

<p>Let $p\colon X \to I$ be a partition of $X$ into subsets $X_i=p^{-1}(i)\lt X$, $i\in I$ such that the images of all functions $f_i\colon X_i \to X$ have inhabited complement $\forall i \in I$. Assume I is minimal in the $\lt$-ordering of sets by cardinality (if $X$ is well-orderable, then $I$ is unique and $I\simeq cf(X)$). The condition is as follows:</p>

<blockquote>
  <p>For all partitions as just described, and all families of functions $(f_i\colon X_i \to X\mid i \in I)$, the surjection
  $$
  \coprod_{i\in I} X_i \setminus f_i(X_i) \to I
$$
  has a section.</p>
</blockquote>

<p>The consequence of this that I want is that I can choose a point in the complement of every map $X \to X^I$, namely $X &lt; X^I$. For well-orderable $X$ this is a corollary of a restriction of König's theorem to powers of well-orderable sets in place of arbitrary products of families.</p>

<p>I would like to know if there are examples that aren't well-orderable, or otherwise how close to be able to well-order $X$ this gets. Note in particular, that we could take every function $f_i$ to be constant at a fixed point $x\in X$, and so this case implies that we should be able to take a section of $X\setminus\lbrace x\rbrace \to I$ and hence of $p$, for $p$ and $I$ as above.</p>

<p>Note that I don't quite have the result that $X$ is a choice object (equivalently, classically well-orderable). I'm not demanding the existence of sections for arbitrary surjections, or more generally for total relation into $X$ (a fine distinction, I'm sure). </p>

<p><strong>Edit:</strong> $X$ being a choice object is equivalent to saying that there is a choice function from the set $P_+X$ of inhabited subsets to $X$. I am only asking for a choice function on the subset of $P_+X$ given by those subsets of $X$ of strictly smaller cardinality, call it $P^{\lt X}_+X$.</p>
",logic
"<p>I'm looking for a proof assistant in order to write formal proofs about basic facts of set theory, such as:</p>

<ul>
<li>$a\subseteq a$</li>
<li>$(a,b)=(c,d)\leftrightarrow a=c\land b=d$</li>
</ul>

<p>Natural deduction for first-order logic is the only set of rules of inference I'd like to use. Easy to install and easy to use software is preferred over more complicated one. Also, open-source software is preferred over closed-source one. No matter if the software comes with an archive of proofs that have been already formalized: I'd like to start from scratch.</p>

<p>Thanks.</p>
",logic
"<p>Over at <a href=""http://www.scottaaronson.com/blog/?p=2725#comment-1089004"">http://www.scottaaronson.com/blog/?p=2725#comment-1089004</a> we had a discussion of intermediate Turing degrees.</p>

<p>The following function came up:</p>

<blockquote>
  <p>Take Chaitin’s constant, and rearrange its binary digits as follows: for each of the sets {1st digit} {2-3rd digits} {4-7th digits} {2^n-(2^n+1)-1}, order the digits within in ascending order, i.e. zeros then ones.</p>
</blockquote>

<p>(This is a number, the function is just {n->nth digit of the number} for natural numbers n)</p>

<p>A <a href=""http://www.scottaaronson.com/blog/?p=2725#comment-1089344"">later comment</a> says it's non-computable:</p>

<blockquote>
  <p>because it has unbounded information about omega.</p>
  
  <p>We know that K(Omega_n) >= n + O(1), but knowing how many 0s and 1s are in the second half of n/2 bits would allow you to save about (log n)/2 bits. This gives a contradiction for large enough n of the form n=2^i</p>
</blockquote>

<p>It's clearly either of degree 0′ or lower. Which is it? In other words, does an oracle for this function let you solve the halting problem?</p>
",logic
"<p>Following the <a href=""http://mathoverflow.net/questions/15685/is-it-necessary-that-model-of-theory-is-a-set"">blow</a>.  I will try to ask question in order to check if I well understand what was pointed. I decide to ask another question, because mathoverflow is not projected to be good environment for discussion, so it would be better to ask another question than to modify previous one.</p>

<p>From wikipedia, we have definition of <strong><a href=""http://en.wikipedia.org/wiki/Magma_%2528algebra%2529"" rel=""nofollow"">magma</a></strong>:</p>

<blockquote>
  <p>""In abstract algebra, a magma (or
  groupoid; not to be confused with
  groupoids  in category theory) is a
  basic kind of algebraic structure.
  Specifically, a magma consists of a
  set M equipped with a single binary
  operation M × M → M. A binary
  operation is closed by definition, but
  no other axioms are imposed on the
  operation.""</p>
</blockquote>

<p>Axioms of magma structure are <a href=""http://en.wikipedia.org/wiki/First-order_logic"" rel=""nofollow"">first order theory</a>. So lets drop words ""set"" and ""closed"" from the definition, and try playing with theory T for which we have:</p>

<ol>
<li><p>predefined single object E</p></li>
<li><p>objects which may be whatever You<br>
like to name by letters from
finite alphabet ( not necessary elements of defined set)</p></li>
<li><p>binary operation defined that for
every pair of objects it sends it into predefined element E. </p></li>
</ol>

<p>It has interpretation on the ground of ZFC and then it has finite or infinite models which are sets - in fact it may be considered as trivial magma if we assume that objects are from set $M U \{E\}$.   Whilst considered without set background it should also work, and do not be cursed by any obvious paradoxes ( because it has set-models). Then we have an example of theory which, when interpreted in domain of sets, is first order theory and is consistent / has models. </p>

<p>Suppose we <strong>formally</strong> drop requirement that domain of discourse for this theory is set interpretation. So then several questions arises:</p>

<ol>
<li><p><strong>Is theory T first order theory?</strong> When interpreted on set domain, it is. But if not in set domain?</p></li>
<li><p>Is it  necessary to interpret it in
set universum, by means of any other arguments than arising from question 1*?</p></li>
<li><p>Can we say that T is consistent in domain of set theory ( whilst we do not know in other domains)?</p></li>
<li><p><strong>If we drop requirements that universum of objects is in set, will
this theory becomes inconsistent?</strong></p></li>
<li><p>Is for any theory obligatory to point
its domain of discourse  in  a formal
meaning, that is for pure
syntactical definition? Is interpretation necessary?</p></li>
</ol>

<p><strong>By consistent I presume definition that """"Consistent"" means that a contradiction cannot be deduced from it.""</strong> </p>

<p>Suppose that answer on 4th question is NO, we may say that theory is still consistent even if we drop requirement that it is interpreted on domain of sets. Then we will end with theory which has set-model. From completeness theorem when interpreted on domain of set is consistent, and even if we drop certain domain interpretation we will still have consistent theory of first order with model from sets universum, but also with models outside of it. Suppose that we get our objects from some big category. I believe that it does not changes nothing, does it? Then there are theories for which we have models which are not sets ( whilst to be consistent it still have to have models which are sets!). </p>

<p>Is there any obvious mistake in this hand-waving of mine? </p>

<p>From Wikipedia article about <a href=""http://en.wikipedia.org/wiki/First-order_logic"" rel=""nofollow"">First Order Logic</a> I know that ""<em>he definition above requires that the domain of discourse of any interpretation must be a nonempty set.</em>"" but it is a remark pointing to ""<a href=""http://en.wikipedia.org/wiki/Empty_domain"" rel=""nofollow"">empty domains</a>"" and ""<a href=""http://en.wikipedia.org/wiki/Free_logic"" rel=""nofollow"">free logic</a>"" which obviously are not in case here. The only interesting link is this: <a href=""http://en.wikipedia.org/wiki/Interpretation_%2528model_theory%2529"" rel=""nofollow"">Interpretation_(model theory)</a> but it still is related to set or empty domain interpretations. But from category theory it seems to be possible to have theories which are interpreted in larger domains that sets in consistent way. </p>

<p>I would like to mention other questions in this or similar area here on mathoverflow, but I would like to say that I am not interested in category theory by other means than just an example of theory which is has other domain of interpretation than set.:
<a href=""http://mathoverflow.net/questions/11974/is-there-a-relationship-between-model-theory-and-category-theory"">Is there a relationship between model theory and category theory?</a>
<a href=""http://mathoverflow.net/questions/8731/categorical-foundations-without-set-theory"">Categorical foundations without set theory</a></p>
",logic
"<p>Could you tell if the positive existential theory of $\mathbb{C}[e^{\mu x} \mid \mu \in \mathbb{C}]$ is undecidable in the language $\{+, \cdot , \frac{d}{dx} , 0, 1, e^x\}$ ? </p>

<p>How can we prove the (un)decidability?</p>
",logic
"<p>Harvey Friedman posted several manuscripts [1] proposing a program for ""strict"" reverse mathematics, in the sense that the base theory should be mathematically natural and coding-free.</p>

<p>In them he describes a number of two-sorted systems (with sorts for integers and finite sets or sequences of integers) weaker than the base theory RCA$_0$ of reverse mathematics.</p>

<p>I wonder if it is known whether any of Friedman's systems are essentially equivalent to the two-sorted system called V$^0$ in Cook-Nguyen [2] (which if I understand correctly was introduced by Zambella [3]).</p>

<p>[1] <a href=""http://people.math.osu.edu/friedman.8/pdf/InevLogStr082907.pdf"" rel=""nofollow"">http://people.math.osu.edu/friedman.8/pdf/InevLogStr082907.pdf</a> among others</p>

<p>[2] Stephen Cook, Phuong Nguyen. Logical foundations of proof complexity, 2010.</p>

<p>[3] Domenico Zambella. Notes on polynomially bounded arithmetic, JSL, Sep. 1996.</p>
",logic
"<blockquote>
  <p><strong>Motivation</strong></p>
  
  <p>Consider the situation: You know that
  every $x$ that has property $P$ must have property $Q$. $Q$ is a
  rather strong condition but not strong
  enough to fulfill $P$. What is <em>missing</em>?</p>
</blockquote>

<p>Consider the formulas of a first-order language, a distinguished set of axioms $S$, and the formulas with exactly one free variable, factored out by provable equivalence $P(x) \sim_S Q(x)$ iff $S \vdash P(x) \leftrightarrow Q(x)$&nbsp;&ndash;&nbsp;for short: <em>properties</em>.</p>

<p>There is a partial order on the set of properties by $[P(x)] \Rightarrow_S [Q(x)]$ iff $S\vdash P(x) \rightarrow Q(x)$&nbsp;&ndash;&nbsp;for short: $P \Rightarrow Q$.</p>

<p>Let $P \Rightarrow Q$, but $Q \not\Rightarrow P$, read: $Q$ <em>is a proper necessary condition of</em> $P$.</p>

<blockquote>
  <p><strong>Definition</strong></p>
  
  <p>A property $D(x)$ may be
  called a <em>defect</em> of $Q(x)$ with
  respect to $P(x)$ if </p>
  
  <ul>
  <li>$D \not\Rightarrow P$</li>
  <li>$Q \wedge D \Rightarrow P$</li>
  </ul>
  
  <p>A defect $D(x)$ may be called <em>minimal</em>
  if there is no other
  defect $D'(x)$ with $D(x) \Rightarrow D'(x)$.</p>
</blockquote>

<hr>

<blockquote>
  <p><strong>Question #1:</strong> Is the search for <em>(minimal) defects</em>
  so manifest &ndash; in the working mathematician's life &ndash; that it is performed every  day without needing a proper name? And is the notion ´&ndash; thus &ndash; of no (meta-)mathematical importance?</p>
</blockquote>

<hr>

<blockquote>
  <p><strong>Question #2:</strong> ... or is there already a proper &ndash;
  and more common &ndash; name?</p>
</blockquote>

<hr>

<blockquote>
  <p><strong>Question #3:</strong> ... or is the definition above and its presuppositions flawed?</p>
</blockquote>

<hr>

<p><strong>Addendum</strong></p>

<p>The common divisor graph on the natural numbers shares one strong property $Q$ with the <a href=""http://en.wikipedia.org/wiki/Rado_graph"" rel=""nofollow"">Rado (= random) graph</a>: it contains any finite graph as an induced subgraph (which I guess is a quite general necessary condition for randomness). But it's not isomorphic to the Rado graph, i.e. does not fulfill its defining property $P$. I am now interested in the ""defect"" of the common divisor graph: which property $D$ - as minimal as possible -  prevents the common divisor graph from being truly random?</p>
",logic
"<p>Recall that with the internal language of 1-toposes, we have the nice, basic, and useful result that geometric sequents are stable under base change along geometric morphisms: If $\varphi$ and $\psi$ are geometric formulas (formulas not containing $\forall$ and $\Rightarrow$), and if $\mathcal{E} \models \forall x:X. (\varphi(x) \Rightarrow \psi(x))$, then also $\mathcal{F} \models \forall x:f^*X. (f^*\varphi(x) \Rightarrow f^*\psi(x))$, where $f : \mathcal{F} \to \mathcal{E}$ is a geometric morphism.</p>

<p>This is useful for lots of things, for instance for comparing validity on a space with validity at all points and for using classical reasoning in proving geometric sequents.</p>

<p>I have two naive questions relating the $(\infty,1)$-categorical generalization of this.</p>

<p><strong>Question 1.</strong> Is there a similar preservation statement for the internal language of $(\infty,1)$-toposes, at least in those cases where it's known that homotopy type theory serves as the internal language? (Note that, in light of propositions as types, one should probably formulate the preservation statement in slightly different terms.)</p>

<p><strong>Question 2.</strong> If yes, is it useful? Or are, with the prevalent use Pi types and universes (which are probably not preserved by the inverse image parts of arbitrary geometric morphisms), few formulas of the required form?</p>
",logic
"<p>Could a function in FOL take functions as arguments? FOL only limits on the order of the individuals being quantified, but if an expression does not involve quantifying over second-order or higher terms, would it still be valid in FOL? Say, $f(g)$ where  $f : (A \to B) \to C$ and $g : A \to B$.</p>

<p>So another way to put my question is that does the rule of formation in FOL say that $f(g)$ is valid as long as $g$ is in the domain of $f$, despite the type of $f$? Could $f$ be a 4th order function and would still be valid in FOL?</p>
",logic
"<p>What is the ""strongest"" core model to this day? In particular, how far are we from a core model for supercompact cardinals? There are rumors of some notes from a workshop in 2004:
<a href=""http://www.math.cmu.edu/~eschimme/AIM/LongDescription.html"">http://www.math.cmu.edu/~eschimme/AIM/LongDescription.html</a></p>

<p>But I couldn't find any more details with respect to a new core model.</p>

<p>Also, could someone recommend the clearest and most rigorous exposition of the ""strongest"" core model so far? </p>
",logic
"<p>I thought I had heard or read somewhere that the existence of a non-principal ultrafilter on $\omega$ was equivalent to some common weakening of AC. As I searched around, I read that this is not the case: neither countable choice nor dependent choice are strong enough.</p>

<p>This leads me to two questions:</p>

<p>Where would I find a proof that DC is not strong enough to prove the existence of a non-principal ultrafilter on $\omega$?</p>

<p>Is the assumption that there exists a non-principal ultrafilter on $\omega$ strong enough to show DC or countable choice? I.e. is ""there exists a non-principal ultrafilter on $\omega$"" stronger than either of countable or dependent choice?</p>
",logic
"<p>The following notion is introduced by Mohammad Golshani. Let $V$ be a model of set theory and let $\mathcal{P}$ be a class consisting of non-trivial forcing notions in $V$. Let</p>

<blockquote>
  <p>$$Th(V, \mathcal{P})=\{\phi: \phi\text{ is a sentence in }\mathcal{L}_\in\text{ and for all }\mathbb{P} \in \mathcal{P}, V^{\mathbb{P}}\models \phi\}.$$</p>
</blockquote>

<p>Now it is natural to ask the following questions:</p>

<p><strong>(A)</strong> What is $Th(L, \mathcal{P}),$ where $\mathcal{P}$ is the class of all forcing notions which introduce a new real$?$ Clearly $Th(L, \mathcal{P}) \supseteq ZFC+V \neq L.$</p>

<p><strong>(B)</strong> Suppose $V_1 \subset V_2$. What can we say about the relation between 
$Th(V_1, \mathcal{P}_1)$ and $Th(V_2, \mathcal{P}_2)$,
where $\mathcal{P}_i,$ for $i=1,2,$ consists of all non-trivial forcing notions $\mathbb{P}\in V_i$ which add a new real over $V_i?$</p>

<p>Remarks)</p>

<p><strong>(1)</strong> One can represent <a href=""http://mathoverflow.net/questions/196619/a-specific-model-of-zfc"">Hamkins and Lowe question</a> based on this notion that is: Is there any model of $ZFC$, $V$ such that $TH(V,\in)=Th(V,\mathcal{C})$, where $\mathcal{C}$ is the class of all forcing notions that collapse a cardinal onto $\omega$?
Note that $Th(V,\in)$ is just the theory of $(V,\in)$.</p>

<p><strong>(2)</strong> Also we can define an accessibility relation over model of $ZFC$ by $V ~\mathcal{R} ~W$ iff there exists a class of forcing notions $\mathcal{P}$ such that $Th(V,\mathcal{P})=Th(W,\in)$.Now we can consider this accessibility and investigate the modal logic, in fact similar to <a href=""http://jdh.hamkins.org/themodallogicofforcing/"" rel=""nofollow"">what Hamkins and Lowe did</a>.</p>

<p><strong>(3)</strong> We say two classes $\mathcal{P}$ and $\mathcal{Q}$ of forcing notions are equivalent over $V$ respect to theorems, if $Th(V,\mathcal{P})=Th(V,\mathcal{Q})$. This gives us a mean to compare forcing notions.</p>
",logic
"<p>I'm sure this is well-known, but: suppose I have a non-constructible real $r\in V-L$. Under what conditions is there a poset $\mathbb{P}\in L$ and a $G$ which is $\mathbb{P}$-generic over $L$, such that $r\in L[G]$? (Note: $G$ is not necessarily a real.)</p>

<p>Obviously it is consistent (e.g., with $V=L$) that the answer is ""always;"" for a non-trivial example of this, the result holds if $V$ is gotten from $L$ by adding a minimal degree of constructibility. It seems unlikely that the answer would be ""always"" in general, but I can't come up with a counterexample.</p>
",logic
"<p>One can prove Elimination of Quantifiers of ACVF finding an extension of any partial embedding of a model $K$ into a $|K|^+$ Saturated one using the language $\mathcal{L} = ( 0,1,+,*, U, \mid )$. In this Language $U$ is the unary predicate standing for the Valuation Ring of the model, and $\mid $ is a binary relation such that $x\mid y \leftrightarrow \exists z\in U \ x*z=y$.  How do you prove the completeness of this theory in that language?</p>
",logic
"<p>It is well-known that both Presburger arithmetic (by contrast with Peano arithmetic) and Tarski geometry are decidable. I was in the shower this morning and wondered whether there exists an elegant mutual generalisation of these theories that is also decidable. In particular, I settled on the following system:</p>

<ul>
<li>The objects are the finite-dimensional affine subspaces of your favourite infinite-dimensional real Hilbert space (let's say $L^2$ for concreteness).</li>
<li>We have a binary predicate, $x \subseteq y$, which inherits its usual meaning.</li>
<li>We have a ternary predicate, $I(x, y; z)$, which means there is an isometry of the ambient space which fixes $z$ and maps $x$ bijectively onto $y$.</li>
</ul>

<p>I'll show that this does indeed generalise both Presburger arithmetic and Tarski geometry.</p>

<hr>

<p>Firstly, note that we can encode the concept of a point:</p>

<p>$$ x \textrm{ is a point } \iff \forall y . (y \subseteq x) \implies (y = x) $$</p>

<p>(It's rather cute that this is precisely how Euclid described a point, namely 'a point is that which has no part'.)</p>

<p>Similarly for lines:</p>

<p>$$ x \textrm{ is a line } \iff x \textrm{ is not a point and } \forall y . (y \subseteq x) \implies ((y = x) \textrm{ or } y \textrm{ is a point}) $$</p>

<p>We can continue inductively to define planes and so on.</p>

<p>We describe two lines $x, y$ as <em>parallel</em> if there is a plane which contains both $x$ and $y$, and there is no $z$ such that $z \subseteq x$ and $z \subseteq y$. This allows one to define \emph{parallelogram}, and emulate vector addition with respect to some origin $o$. That allows one to take Minkowski sums of affine subspaces with respect to $o$.</p>

<hr>

<p>So far we haven't touched the ternary predicate $I(x, y; z)$. One rudimentary application is to equate distances between points:</p>

<p>$$ |a - b| = |d - c| \iff \exists e . (b + c = a + e) \textrm{ and } I(d, e; c) $$</p>

<p>Here we're using $(b + c = a + e)$ as shorthand for $e$ being a point and satisfying the vector addition property mentioned earlier. We can also compare distances: $|x - y| \geq |a - b|$ if and only if we can find points $c, d$ such that $b + b = c + d$ and $|x - y| = |a - c| = |a - d|$. Together with collinearity, this allows us to define Tarski's 'betweenness' predicate, so we can encode all of Tarskian geometry.</p>

<hr>

<p>Another application of this predicate is to equate dimension:</p>

<p>$$ \dim(x) = \dim(y) \iff \exists z . I(x, y; z) $$</p>

<p>We can also add dimensions. Specifically, $\dim(x) + \dim(y) = \dim(z)$ if and only if we can find a point $o$ and spaces $a, b$ such that $\dim(a) = \dim(x)$, $\dim(b) = \dim(y)$, the intersection of $a$ and $b$ is $o$, and every point in $z$ can be expressed uniquely as a sum (as vectors relative to $o$) of a point in $a$ and a point in $b$.</p>

<p>This endows us with the ability to perform Presburger arithmetic on the dimensions of spaces.</p>

<hr>

<p>Anyway, this prompts the question: is this theory (together with a suitable finite set of axioms) decidable? With 'bounded quantifiers' (i.e. bounded dimension), this reduces to $n$-dimensional Tarski geometry (and therefore is decidable). However, I feel this theory is much stronger since you can make first-order statements about arbitrary finite-dimensional vector spaces.</p>
",logic
"<p>What properties of tropical geometry (Starting from a valued Field) can be proven to be true using their analogue in algebraic geometry? For example, using the valuation on the Puiseux series $\mathbb{C}((t))$ what can be said about $\Gamma ^n$ where $\Gamma$ is the valuation group.</p>

<p>That is what pairs of properties $(X,X')$ such that $X$ is valid on an algebraic variety then $X'$ is valid on the tropicalization, and $X$ is a first order property in the language $L=\{ 0,1,+,*,U,|\}$ where $U$ stands for the valuation ring, and $x|y \leftrightarrow \exists z U(z) _\wedge xz=y$ </p>

<p>A silly example would be the following: One can prove that when the support (the set of exponents corresponding to non zero coefficients) of a polynomial $f$ in two variables is equal to {$(i,j)\in \mathbb{N}^2 | i+j \leq d$} for some $d\in \mathbb{Z}^+$ and the support of another polynomial $g$ is {$(i,j)\in \mathbb{N}^2 | i+j \leq c$} for another $c\in \mathbb{Z}^+$ then the tropical curves generated by those polynomials intersects in exactly $cd$ points or in infinitely many(Bézout). </p>
",logic
"<p>Suppose $S_3$ is the symmetric group of order 6. Which elements of the variety $Var(S_3)$ are relatively free? </p>

<p>This question is related to my previous question
<a href=""http://mathoverflow.net/questions/153743/relatively-free-algebras-in-a-variety-generated-by-a-single-algebra"">Relatively free algebras in a variety generated by a single algebra</a></p>
",logic
"<p>Suppose f is a computable function from a recursively enumerable set U to the natural numbers and that L,K are r.e. subsets of U. Is f(L-K) a difference of r.e. subsets? The motivation comes from</p>

<p><a href=""http://mathoverflow.net/questions/121178/primes-occurring-as-orders-of-elements-of-a-finitely-presented-group"">Primes occurring as orders of elements of a finitely presented group</a></p>

<p>A positive answer would mean that the theorem proposed in HW's nice answer is 100% correct. Otherwise the $\epsilon$-clarification in my answer is actually needed. </p>
",logic
"<p>$$y(t)=y_0+\int_0^t b(y(s))ds$$ $b\in C(R^d)\cap L^\infty(R^d)$</p>

<p>The classical proof for Peano's existence theorem in ODE need use the Ascoli's theorem, so it's not constructive. When $d=1$, in the paper of Walter ""There is an Elementary Proof of Peano's Existence Theorem"" the author showed there is an constructive proof for Peano's theorem. But the method can't transformed to $d&gt;1$. I found some literature say there is no constructive proof for this theorem. </p>

<p>I am not a logician and really confused about this. Can one give a rigorous meaning to ""there is no constructive proof to the Peano's theorem""?</p>
",logic
"<p>I've seen many different notion of $\infty$-categories, actual I've seen the operadic-globular ones of Batanin and Leinster and the opetopic too and eventually I'll see the simplicial ones too. Although there are so many notion of $\infty$-category so far I've only seen the following examples:</p>

<ul>
<li><p>$\infty$-grupoids as fundamental groupoids topological spaces;</p></li>
<li><p>$(\infty,1)$-categories, mostly via topological example and application in algebraic geometry (in particular in derived algebraic geometry);</p></li>
<li><p>strict $(\infty,\infty)$-categories, and their $n$-dimensional versions, for instance the various categories of strict-$n$-categories (here I intend $n \in \omega+\{\infty\}$).</p></li>
</ul>

<blockquote>
  <p>There are other example of $\infty$-categories, especially from algebraic topology or algebraic geometry, but also mathematical physics and computer science and logic?
  In particular I wondering if there's a concrete example, well known, weak $(\infty,\infty)$-category.</p>
</blockquote>

<p>(Edit:) after the a discussion with Mr.Porter I think adding some specifications may help: </p>

<blockquote>
  <p>I'm looking for models/presentations of $\infty$-weak-categories for which is possible to give a combinatorial description, in which is possible to make manipulations and explicit calculations, but also $\infty$-categories arising in practice in various mathematical context. </p>
</blockquote>
",logic
"<p>I am looking at FOL with no equality, no constant, no function symbol and the unique binary predicate $\in$ with variables in arbitrary sets $V$ or $W$. Specifically we define ${\bf P}(V)$ as the free algebra of type $\{\bot,\to\}\cup\{\forall x:x\in V\}$ (with the obvious arity for each symbol) generated by the ordered pairs $(x,y)$, denoted $(x\in y)$, for $x,y\in V$. We consider the Hilbert-style axiomatization on ${\bf P}(V)$:</p>

<blockquote>
  <p><strong>Axioms:</strong></p>
  
  <p>(i) $\phi_{1}\to(\phi_{2}\to\phi_{1})$ </p>
  
  <p>(ii) $\phi_{1}\to(\phi_{2}\to\phi_{3})\to[(\phi_{1}\to\phi_{2})\to(\phi_{1}\to\phi_{3})]$</p>
  
  <p>(iii) $[(\phi_{1}\to\bot)\to\bot]\to\phi_{1}$</p>
  
  <p>(iv) $\forall x(\phi_{1}\to\phi_{2})\to(\phi_{1}\to\forall x\phi_{2})\ ,\ x\not\in\mathtt{Fr}(\phi_{1})$</p>
  
  <p>(v) $\forall x\phi_{1}\to\phi_{1}[y/x]\ \ ,\ \ \mbox{$[y/x]:{\bf P}(V)\to{\bf P}(V)$ essential substitution of $y$ in place of $x$}$</p>
  
  <p><strong>Rules of inference :</strong></p>
  
  <p>(i) Modus ponens</p>
  
  <p>(ii) Generalization w.r. to $x\in V$ which do not appear free in any hypothesis</p>
</blockquote>

<p>An essential substitution $\sigma^{*}:{\bf P}(V)\to{\bf P}(W)$ associated with a map $\sigma:V\to W$ is a map which satisfies the property ${\cal M}\circ\sigma^{*}=\bar{\sigma}\circ{\cal M}$ where $\bar{\sigma}:V\oplus\mathtt{N}\to W\oplus\mathtt{N}$ is the extension defined by $\bar{\sigma}(n)=n$ for all $n\in\mathtt{N}$ and ${\cal M}:{\bf P}(V)\to{\bf P}(V\oplus\mathtt{N})$ is the operation replacing all bound variables of a formula by elements of the copy of $\mathtt{N}$ disjoint from $V$, as specified by the following recursion:</p>

<blockquote>
  <p>$(i)\ {\cal M}(x\in y)=(x\in y)$
  $(ii)\ {\cal M}(\bot)=\bot$
  $(iii)\ {\cal M}(\phi_{1}\to\phi_{2})={\cal M}(\phi_{1})\to{\cal M}(\phi_{2})$</p>
  
  <p>$(iv)\ {\cal M}(\forall x\phi_{1})=\forall n{\cal M}(\phi_{1})[n/x]$</p>
  
  <p>where $\ n=\min\{k\in\mathtt{N}:[k/x]\mbox{ avoids capture in }{\cal M}(\phi_{1})\}$</p>
</blockquote>

<p>I have an injective map $i:V\to W$ which induces a corresponding embedding $i:{\bf P}(V)\to{\bf P}(W)$ between formulas. My question is:</p>

<blockquote>
  <p><strong>Question:</strong> is it true that $\Gamma$ consistent $\ \Rightarrow\ $ $i(\Gamma)$ consistent</p>
</blockquote>

<p>When $V$ is an infinite set I know what to do: I can carry back any proof underlying the sequent $i(\Gamma)\vdash\bot$ into a proof of $\Gamma\vdash\bot$ by substituting variables from $W$ to $V$ while avoiding capture. The problem arises when $V$ is a finite set. I can no longer be sure I can carry back proofs while avoiding capture. I am looking for a reference where this question may have been dealt with, or any hints on how to approach the problem. More generally, this question can be phrased as follows: given $\phi\in{\bf P}(V)$ with $V$ finite, I want to show the implication $\vdash i(\phi)\ \Rightarrow\ \vdash\phi$. Heuristically, if $\phi\in{\bf P}(V)$ can be proved with variables in $W\supseteq V$, then it can also be proved with variables in $V$. This question is motivated by Gödel's completeness theorem which I am attempting to prove on ${\bf P}(V)$ for $V$ finite, following a Henkin type proof: as I add new variables to the language, I need to make sure consistency is preserved, i.e. that I have a conservative extension.</p>

<p><strong>EDIT</strong>: Following Andreas' and Noah's answer, I have hopefully made the question clearer.</p>

<p><strong>LAST EDIT</strong>: I have been stuck on this for a few weeks now. However, I am very hopeful the following strategy will work: first, spell out the details of an <strong>LK</strong> Gentzen type system in this particular setting ($V$ possibly finite, $[y/x]$ essential rather than just avoiding capture) which is equivalent to the Hilbert system. Then for all $i:V\to W$ injective, show the implication $i(\Gamma)\vdash i(\Delta)$ provable without cut $\Rightarrow$ $\Gamma\vdash\Delta$ provable without cut. Finally show that cut elimination holds in this setting. Proofs of the cut elimination theorem (e.g. Takeuti) seem to rely on an infinite supply of variables. However, if I am right about the implication $\Rightarrow$, I can always embed a sequent in a larger space to eliminate cut and bring it back to the smaller space. Comments and suggestions are very welcome.   </p>
",logic
"<p>Thank everybody for answering my previous questions: <a href=""http://mathoverflow.net/questions/15685/is-it-necessary-that-model-of-theory-is-a-set"">first</a>, and <a href=""http://mathoverflow.net/questions/15812/theory-interpreted-in-non-set-domain-of-discourse-may-be-consistent"">second</a>.</p>

<p>Here I would like to ask about some important thing which I do not understand clearly. </p>

<ol>
<li><strong>Is it necessary for theory to have given interpretation in some
universe by definition or not, it is not necessary for set of axiom to be a theory?</strong></li>
</ol>

<p>The meaning of question above is: is this a <strong>correct</strong> way of defining theory if we do not give domain of interpretation for it? What obstacles may arise from that? <strong>For example</strong>: As far as I know standard category theory do not qualify clearly which is its domain of interpretation, then, may we say that it is ""defined theory"" from a formal point of view? I have heard that there are some efforts to define category theory by means of metacategories which probably has as one of its aims to give clear definition of domain of interpretation. </p>

<p>So there another question arises for which I will try to give some introduction by example.</p>

<p>I may think about theory which when interpreted in set universe defined by some formulas, relations whatever may be consistent and have models, whilst in other universes do not. Is this a case? For example in answer about possible definition of domain of discourse for first order theories <a href=""http://mathoverflow.net/questions/15812/theory-interpreted-in-non-set-domain-of-discourse-may-be-consistent/15813#15813"">here</a> Joel David Hamkins wrote: ""If V is the universe of all sets, we can define certain classes in V, such as { x | φ(x) }, where φ is any property."" </p>

<p>What if $\phi(x)$ is not property from first order logic? </p>

<p>For example we may consider sentence $S= \{x | \phi (x) \}$ as meaning:""for every theory x when schema of axioms of induction is present in axiom set"". It is clearly not first order sequence, so maybe model which is interpreted in such universe is not first order model even if axiom of theory forms first order set? The only difference here is in a way we introduce a domain of interpretation so maybe this level of freedom is too much? </p>

<p>Usual definition of domain of interpretation which I have found in wikipedia <a href=""http://en.wikipedia.org/wiki/Theory_%2528mathematical_logic%2529"" rel=""nofollow"">here</a> uses set ""structure"" but not state clearly that domain of discourse has to be first order set from the beginning! It is something which is not clear for me here. Should I believe that some ""interpretations"" of theory may be inconsistent whilst other may be consistent when we drop interpretation part as a definition and we leave it free?</p>

<ol>
<li><strong>If we construct theory in first order logic ( for example as in my <a href=""http://mathoverflow.net/questions/15812/theory-interpreted-in-non-set-domain-of-discourse-may-be-consistent"">second question</a>), and then we will try to use it on domain of objects defined by means of higher order logic, do we end with higher order theory, or rather first order theory which is saying something about second order logic objects?</strong> Or maybe the answer is"" ""it depends"" and there should be stated additional requirements?</li>
</ol>

<p>I have hope it is no obviously wrong question...</p>

<hr>

<p><strong>Note 1.</strong>  As I do not want to be found very speculative, I will point to blog of Terence Tao <a href=""http://terrytao.wordpress.com/2007/08/27/printer-friendly-css-and-nonfirstorderizability/"" rel=""nofollow"">here</a> where You may find some information about nonfirstorderisability and specially this sentence:</p>

<blockquote>
  <p>which is part of the fundamental
  theorem of linear algebra, does not
  seem to be expressible as stated in
  first order set theory</p>
</blockquote>

<p>So there are pretty useful practical statement, not very abstract, in normal mathematics which cannot be expressed in first order theory language.</p>

<hr>

<p><strong>Note 2.</strong> In wikipedia <a href=""http://en.wikipedia.org/wiki/Morse-Kelley_set_theory"" rel=""nofollow"">here</a> I found the following remark:</p>

<blockquote>
  <p>""MK can be confused with second-order
  ZFC, ZFC with second-order logic
  (representing second-order objects in
  set rather than predicate language) as
  its background logic. The language of
  second-order ZFC is similar to that of
  MK (although a set and a class having
  the same extension can no longer be
  identified), and their syntactical
  resources for practical proof are
  almost identical (and are identical if
  MK includes the strong form of
  Limitation of Size). But the semantics
  of second-order ZFC are quite
  different from those of MK. For
  example, if MK is consistent then it
  has a countable first-order model,
  while second-order ZFC has no
  countable models.""</p>
</blockquote>
",logic
"<p>In set theory, the axiom of specification says that $\forall x_0\exists x_1\forall x_2\left(x_2\in x_1\leftrightarrow x_2\in x_0\land\theta\left[x_2\right]\right)$, where $\theta\left[x_2\right]$ is any formula that has $x_2$ as the only free variable.</p>

<p>In first order logic, the rule of universal introduction says that if $\Sigma\vdash\phi\left[t\right]$ then $\Sigma\vdash\forall x\phi\left[x/t\right]$, where $\Sigma$ is a set of axioms, $\phi$ is any formula that has $x$ as the only free variable and $t$ is any term. There is one restriction: $t$ cannot appear in $\Sigma$.</p>

<p>The problem is that, in set theory, every instance of the axiom of specification belong to $\Sigma$; in particular, instances of the axiom of specification in which a term appears belong to $\Sigma$. So every term appears in $\Sigma$, and you cannot use the rule of universal introduction at all. Without that rule, no relevant proof can be written down as far as I know.</p>

<p>I'm not sure if the question is clear enough; please let me know if it isn't.</p>

<p>Thanks.</p>
",logic
"<p>This issue is for logicians and operator algebraists (but also for anyone who is interested).</p>

<p>Let's start by short reminders on <a href=""https://en.wikipedia.org/wiki/Von_Neumann_algebra"">von Neumann algebra</a> (for more details, see <a href=""http://www.math.berkeley.edu/~vfr/MATH20909/VonNeumann2009.pdf"">[J]</a>, <a href=""http://www.springer.com/mathematics/analysis/book/978-3-540-42248-8"">[T]</a>, <a href=""http://iml.univ-mrs.fr/~wasserm/OHS.ps"">[W]</a>):   </p>

<p>Let $H$ be a separable Hilbert space and $B(H)$ the algebra of bounded operators.  </p>

<p><strong>Definition</strong>: A von Neumann algebra is a *-subalgebra $M \subset B(H)$ stable under bicommutant:<br>
$M^{*} = M$ and $M'' = M$.   </p>

<p><strong>Theorem</strong>: The <a href=""http://en.wikipedia.org/wiki/Abelian_von_Neumann_algebra"">abelian von Neumann algebras</a> are exactly the algebras $L^{\infty}(X)$ with $(X, \mu)$ a standard measure space. They are isomorphic to one of the following: </p>

<ul>
<li>$l^{\infty}(\{1,2,...,n \})$, $n \geq 1$</li>
<li>$l^{\infty}(\mathbb{N})$ </li>
<li>$L^{\infty}([0,1])$</li>
<li>$L^{\infty}([0,1]\cup \{1,2,...,n \})$</li>
<li>$L^{\infty}([0,1]\cup \mathbb{N})$  </li>
</ul>

<p><strong>Noncommutative philosophy</strong>: There are various <em>schools</em> of noncommutative philosophy, here is the <em>school</em> close to operator algebras. This issue is not about philosophy, so I will explain it quickly (for more details see <em>for example</em> the introduction of this <a href=""http://www.alainconnes.org/docs/book94bigpdf.pdf"">book</a>). First an intuitive idea : in the same way as there are <em>classical physics</em> and  <em>quantum physics</em>, there are <em>classical mathematics</em> and <em>quantum mathematics</em>. What does it mean in practice ? It means the following : in the <em>classical mathematics</em> there are many different structures, <em>for example</em>, the measurable, topological or Riemannian spaces. The point is to encode each structure by using the framework of commutative operator algebras. For the previous examples, it's the commutative von Neumann algebras, C$^{*}$-algebras and spectral triples. Now if we take these operator algebraic structures and if we remove the <em>commutativity</em>, we obtain what we call <em>noncommutative analogues</em> : <strong>noncommutative measurable, topological or Riemannian spaces</strong>.<br>
<em>This school</em> explores noncommutative analogues of more and more structured objects, it goes in one direction. My point is to question about the other direction (back to the <em>Source</em>) :<br>
What's the noncommutative analogue of a set (called a <strong>noncommutative set</strong>) ?    </p>

<blockquote>
  <p>What is a <em>noncommutative set</em>? </p>
</blockquote>

<p>The von Neumann algebras of the standard measure space $[0,1]$, $[0,1]\cup \{1,2,...,n \}$ and $[0,1]\cup \mathbb{N}$ are not isomorphic, but as sets, these spaces are isomorphic (i.e., same cardinal).  </p>

<p>Is there a natural equivalence relation $\sim$ on the von Neumann algebras, forgetting the <em>measure space</em> but remembering the <em>set space</em>, on abelian von Neumann algebras?  </p>

<p><strong>Remark</strong>: If $M \sim N$, we could say that they are isomorphic as <strong>noncommutative sets</strong>.<br>
The equivalence class could be called the <strong>quantum cardinal</strong> (a link with <a href=""http://mathoverflow.net/questions/133050/the-cyclic-subfactors-theory-a-quantum-arithmetic"">cyclic subfactor</a> theory?).</p>

<p>Are there <em>noncommutative analogues</em> of the ZFC axioms ?</p>

<p>What I'm looking for seems different of what is called <em>quantum set</em> in the literature...</p>
",logic
"<p>Given a cardinal $\kappa,$ recall that $X \subset \kappa$ is called fresh (over $V$), if $X \notin V,$ but $X \cap \alpha \in V$ for all 
$\alpha &lt; \kappa.$</p>

<p><strong>Question.</strong> Is it consistent that there exists a generic extension $V[G]$
of $V$ (for some suitable $V$), such that:</p>

<p><strong>(A)</strong> $V$ and $V[G]$ have the same cardinals and cofinalities,</p>

<p><strong>(B)</strong> $V$ and $V[G]$ have the same bounded subsets of $\aleph_\omega,$</p>

<p><strong>(C)</strong> There exists a fresh subset $X \in V[G]$ of $\aleph_\omega$ (over $V$), such that $V[G]=V[X],$ and $V[G]$ is a minimal generic extension of $V?$</p>

<p><strong>Remark.</strong> See <a href=""http://projecteuclid.org/euclid.jsl/1358951101"">A minimal Prikry-type forcing for singularizing a measurable cardinal</a> and <a href=""http://arxiv.org/abs/1310.0891"">Prikry-type forcing and minimal $α$-degree</a>, where some 
similar results for a large singular cardinal are proved.</p>
",logic
"<p>I am currently going through Philip Walder's <a href=""http://homepages.inf.ed.ac.uk/wadler/papers/propositions-as-types/propositions-as-types.pdf"">""Proposition as Types""</a> and a passage of the introduction has struck me:</p>

<blockquote>
  <p>for each way to simplify a proof
  there is a corresponding way to evaluate a program</p>
</blockquote>

<p>What does <em>simplify a proof</em> means here? I have searched in my logic textbook and on the Internet but surprisingly enough I could not find any direct, informal explanation.</p>
",logic
"<p>[I have updated the question after initial comments in the hope of clarifying it.]</p>

<p>I do quite a bit of reasoning, typically about topology and metric spaces, in ""non-standard"" foundations, such as inside of a particular topos, in type theory, or a predicative constructive setting. These typically do not have anything corresponding to unbounded separation or replacement (the constructive set theory CZF does have collection, though).</p>

<p>I have a pretty good feel when restricted forms of excluded middle and choice are needed, and what things powersets give us over predicative math, etc. But I never ever wish I had unbounded separation and replacement. Why is that? Is it just because of the kind of math I do, or are these two really not needed very much in ordinary math?</p>

<p>To make the question more specific: <em>what are some well-known definitions and theorems in ""ordinary"" mathematics which require unbounded separation or replacement?</em></p>

<p>The obvious uses of replacement and unbounded separation come from set theory, so we should avoid listing those. Ideally, I am looking for theorems and definitions in algebra, topology, and analysis.</p>

<p>Here is a non example from order theory, which was suggested in the comments. Under the usual encoding of ordinals as hereditarily transitive transitive sets, the rank of the function $n \mapsto \omega + n$ is $\omega + \omega$ and so we need replacement to show its existence. However, even PA can speak about this sort of small countable ordinals, so we are seeing here an artifact of a particular encoding. A different encoding of countable ordinals would make this function easy to define (for example we could view the countable ordinals as orders of subsets of $\mathbb{N}$).</p>

<p>The only example of unbounded separation I can think of right now comes from category theory. In a large category $C$ the definition of epi is unbounded, as it requires quantification over all objects of $C$. I am looking for something that is not so directly linked to a question of size.</p>
",logic
"<p>Given a class $C$ of arithmetical sentences, 
an arithmetical theory $T$ is said to be $C$-sound if 
all the theorems of $T$ which are in $C$ are true. 
For instance, $T$ is $\Sigma_1$-sound if all the $\Sigma_1$ theorems of $T$ are true.  </p>

<p>Now, for some classes $C$, like the class of $\Sigma_1$ sentences, 
the statement ""$T$ is $C$-sound"" is expressible in the language of arithmetic.
For other classes, like the class of all arithmetical sentences, $C$-soundness 
(which is just soundness) can't be definable in the language of arithmetic.
But there are some classes, like the class of $\Pi_1$ sentences, 
which have a rarer property: 
not only is $C$-soundness definable in the language of arithmetic, it can be defined within $C$ itself.  </p>

<p>However, I'm looking for an even rarer property:</p>

<blockquote>
  <p>does there exist a class $C$ for which 
  $C$-soundness is definable within $C$, <em>and</em> 
  which is also closed under negation?</p>
</blockquote>

<p>Or, failing that:</p>

<blockquote>
  <p>does there exist a class $C$ for which 
  ""$T$ is <strong>not</strong> $C$-sound"" is expressible within $C$?</p>
</blockquote>
",logic
"<p>I have been reading Wolfram's A New Kind of Science, and as I was reading the section on systems of logic and axioms, I came across this axiom, for which all of the normal axioms of Boolean logic can be proved: ((a.b).c).(a.((a.c).a))=c, where . is the Nand (not and) operator. I believe it is true, but I would like to see a proof of some of the axioms of boolean logic from it.</p>

<p>I have tried to prove some of them myself, but I couldn't figure out how to prove lemmas from that axiom that are (even remotely) helpful.</p>
",logic
"<p>Given a conflict graph $G = (V, E)$, a man has to transport a set $V$ of items/vertices across the river. Two items are connected by an edge in $E$, if they are conflicting and thus cannot be left alone together without human supervision. The available boat has capacity $b\geq 1$, and thus can carry the man together with any subset of at most $b$ items. A feasible schedule is a finite sequence of triples $(L_1, B_1, R_1),\dots, (L_s, B_s, R_s)$ of subsets of the item set V that satisfies the following conditions (FS1)–(FS3). The odd integer $s$ is called the length of the schedule.</p>

<p>(FS1) For every $k$, the sets $L_k, B_k, R_k$ form a partition of V . The sets $L_k$ and $R_k$ form stable sets in $G$. The set $B_k$ contains at most $b$ elements.</p>

<p>(FS2) The sequence starts with $L_1 \cup B_1 = V$ and $R_1 = \emptyset$, and the sequence ends with $L_s = \emptyset$ and $B_s\cup R_s = V$.</p>

<p>(FS3) For even $k \geq 2$, we have $B_k\cup R_k = B_{k-1} \cup R_{k-1}$ and $L_k = L_{k-1}$. For odd $k \geq3$, we have $L_k\cup B_k= L_{k-1}\cup B_{k-1}$ and $R_k = R_{k-1}$.</p>

<p>Known Result: $VertexCover(G) \geq b \geq VertexCover(G)+1$.</p>

<p>Please help formulate this problem in MSO. </p>
",logic
"<p>I've been reading up a bit on the fundamentals of formal logic, and have accumulated a few questions along the way. I am pretty much a complete beginner to the field, so I would very much appreciate if anyone could clarify some of these points.</p>

<ol>
<li><p>A complete (and consitent) propositional logic can be defined in a number of ways, as I understand, which are all equivalent. I have heard it can be defined with one axiom and multiple rules of inferences or multiple axioms and a single rule of inference (e.g. Modus Ponens) - or somewhere inbetween. Are there any advantage/disvantages to either? Which is more conventional?</p></li>
<li><p>Propositional (zeroth-order) logic is simply capable of making and verifying logical statements. First-order (and higher order) logics can represent proofs (or increasing hierarchial complexity) - true/false, and why?</p></li>
<li><p>What exactly is the relationship between an nth-order logic and an (n+1)th-order logic, in general. An explanation mathematical notation would be desirable here, as long as it's not <em>too</em> advanced.</p></li>
<li><p>Any formal logic above (or perhaps including?) first-order is sufficiently powerful to be rendered inconsistent or incomplete by Godel's Incompleteness Theorem - true/false? What are the advantages/disadvantages of using lower/higher-order formal logics? Is there a lower bound on the order of logic required to prove all known mathematics today, or would you in theory have to use an arbitrarily high-order logic?</p></li>
<li><p>What is the role type theory plays in formal logic? Is it simply a way of describing nth-order logic in a consolidated theory (but orthogonal to formal logic itself), or is it some generalisation of formal logic that explains everything by itself?</p></li>
</ol>

<p>Hopefully I've phrased these questions in some vaguely meaningful/understandable way, but apologies if not! If anyone could provide me with some details on the various points without assuming too much prior knowledge of the fields, that would be great. (I am an undergraduate Physics student, with a background largely in mathematical methods and the fundamentals of mathematical analysis, if that helps.)</p>
",logic
"<p><strong>Definition:</strong> Let $\kappa$ be an $\aleph$ cardinal, we say that $\langle f_\alpha\colon\alpha\to\kappa\mid\alpha&lt;\kappa^+\rangle$ is a <em>ladder</em> if every $f_\alpha$ is injective.</p>

<p>Equivalently this is the range of a choice function from every injection of $\alpha$ into $|\alpha|$ (for $\alpha&lt;\kappa$ we can always assume the identity is taken). Such ladder implies automatically that $\kappa^+$ is regular, since the union of $\kappa$ enumerated sets of size $\kappa$ is at most of size $\kappa$. (Recall that for well ordered sets $\kappa\times\kappa=\kappa$ even without the axiom of choice)</p>

<p>For example, then, if $\omega_1$ is singular then there is no such ladder of countable ordinals, since this would imply that $\aleph_1=\aleph_0^+$ is regular, therefore the existence of ladders for every successor ordinal is not provable in ZF alone.</p>

<p>However if we assume the existence of an inaccessible cardinal we can have the situation where $\aleph_1$ is indeed regular but there is no ladder avail. Indeed this is a necessary requirement since in such situation $\omega_1$ is inaccessible in $L$.</p>

<p>Both the forcing which makes $\aleph_1$ singular and the one which makes it regular without a ladder are essentially the same: collapse a limit cardinal to $\aleph_1$ and take symmetry model which ensures that no ladder exists, while setting $\aleph_1$ to have the cofinality of collapsed cardinal, i.e. singular or regular (if it was inaccessible).</p>

<p><strong>Question I:</strong> Can we do this trick by replacing $\aleph_1$ by $\aleph_\alpha$ for any non-limit ordinal? So for example, $\aleph_5$ would be singular or regular without a ladder.</p>

<p><strong>Question II:</strong> We do not need an inaccessible cardinal to have $\omega_1$ singular, nor $\omega_2$ singular. However if we want them <em>both</em> to be singular it already implies $0^\\#$ exists, and requires Woodin cardinals.</p>

<p>Suppose $\aleph_1$ and $\aleph_2$ are both regular, and neither has a ladder. Can we do that ""just"" from the existence of two inaccessible cardinals, or would such phenomenon imply that some very large cardinals are playing in the background?</p>
",logic
"<p>We say that a group <em>G</em> is in the class <em>F<sub>q</sub></em> if there is a CW-complex which is a <em>BG</em> (that is, which has fundamental group <em>G</em> and contractible universal cover) and which has finite <em>q</em>-skeleton.  Thus <em>F<sub>0</sub></em> contains all groups, <em>F<sub>1</sub></em> contains exactly the finitely generated groups, <em>F<sub>2</sub></em> the finitely presented groups, and so forth.</p>

<p>My question:  For a fixed <em>q</em> ≥ 3, is it possible to decide, from a finite presentation of a group <em>G</em>, whether <em>G</em> is in <em>F<sub>q</sub></em> or not?  I would assume not, but am not having much luck proving it.</p>

<p><strike>One approach would be to prove that, if <em>G</em> is a group in <em>F<sub>q</sub></em> and <em>H</em> is a finitely presented subgroup, then <em>H</em> &isin; <em>F<sub>q</sub></em> as well.  This would make being in <em>F<sub>q</sub></em> a Markov property, or at least close enough to make it undecidable.</strike></p>

<p>Henry Wilton's comment below makes it clear that being <em>F<sub>q</sub></em> is not even quasi-Markov, so the above idea won't work.  I still suspect that ""<em>G</em> &isin; <em>F<sub>q</sub></em>"" is not decidable, but now my intuition is from Rice's theorem:</p>

<blockquote>
  <p>If $\mathcal{B}$ is a nonempty set of computable functions with nonempty complement, then no algorithm accepts an input <em>n</em> and decides whether <em>&phi;<sub>n</sub></em> is an element of $\mathcal{B}$.</p>
</blockquote>

<p><strike>It seems likely to me that something similar is true of finite presentations and the groups they define.</strike></p>

<p>John Stillwell notes below that this can't be true for a number of questions involving the abelianization of G.  This wouldn't affect the Rips construction/1-2-3 theorem discussion below if the homology-sphere idea works, since those groups are all perfect.</p>

<p>Any thoughts?</p>
",logic
"<p>Let $C$ be the Cohen algebra, the boolean completion of the partial order of finite partial functions from $\omega$ to 2, ordered by reverse inclusion.  Does there exist an ideal $I$ on $C$ such that $C/I \cong \mathcal P(\omega)/ \mathrm{fin}$?</p>
",logic
"<p>Suppose $M$ is a model of ZFC, and $\mu^M$ is the Lebesgue measure on $\mathbb R^M$ such that $\mu^M(\mathbb R^M)=1$. It is known that if $r$ is a Cohen real over $M$ and $N=M[r]$ then $\mu^N(\mathbb R^M)=0$.</p>

<p>This is a very strong transition from having sets with a full measure being annihilated into nullity. Is it possible that for some[every?] $x\in(0,1)$ there exists $N=M[G]$ a generic extension of $M$ such that $\mu^N(\mathbb R^M)=x$?</p>

<p>If the answer is negative in its full generality ($M$ is just any model of ZFC) can we add some assumptions for a positive answer? (e.g. $M\models CH$)</p>

<p><em>This is really just idle curiosity which could not be satisfied via Google, references to a possible answer would be just as welcomed as a complete answer</em></p>
",logic
"<p>I am interested in a more specific reference or explanation of ""the categorical view"" explained in the article <a href=""http://ncatlab.org/nlab/show/theory#CategoricalView"" rel=""nofollow"">http://ncatlab.org/nlab/show/theory#CategoricalView.</a> In particular, I am interested in trying to prove full completeness for a geometric model of multiplicative linear logic and I want to use a category theoretic approach in order to do so. So, when it is mentioned that</p>

<blockquote>
  <p>Models of a theory $\mathcal{T}$ are identified with functors $$C_{\mathcal{T}} \rightarrow \textbf{Set}$$ that preserve some (typically property-like) structures on $C_{\mathcal{T}}$, such as certain classes of colimits or limits, pertinent to the logic at hand, where $C_{\mathcal{T}}$ is the syntactic category of terms for the theory $\mathcal{T}$.</p>
</blockquote>

<p>I interpret that as being that for a particular model of a theory, I want to define a functor which can be identified with that theory (in my case, the geometric model of multiplicative linear logic). Yet, I am unsure as to how I would know what properties I want it to preserve on $C_{\mathcal{T}}$.</p>

<p>Furthermore, the article mentions that a completeness theorem would be the statement that</p>

<blockquote>
  <p>the canonical map $$C_{\mathcal{T}} \rightarrow \prod_{\text{models in $\textbf{Set}$}} \textbf{Set}$$ is a full faithful embedding.</p>
</blockquote>

<p>In this context, how would I prove completeness for one model of the theory, or does only refer to completeness of a theory in all possible models of that theory? In particular, a proof of the full completeness of multiplicative linear logic was given by Samson Abramsky and Radha Jagadeesan in ""Games and Full Completeness for Multiplicative Linear Logic (1994)"" Does this mean that completeness is proved for multiplicative linear logic in general, or just for the game-theoretic model defined in the paper?</p>

<p>To summarize, my questions are as follows:</p>

<blockquote>
  <p>1) Given a language for a signature (in the syntactic view of a theory), how do I define a functor $C_{\mathcal{T}} \rightarrow \textbf{Set}$ which can be identified with this theory?</p>
  
  <p>2) In the categorical view, is completeness of a theory defined over all models for that theory, or can we prove completeness for a specific model of that theory. If the later holds, what exactly do I need to prove is a full faithful embedding?</p>
</blockquote>
",logic
"<p>So I'm not much of a math guy but I've really enjoyed programming in Lisp and have become interested in the ideas of lambda calculus which it is based.</p>

<p>I was wondering if anyone had a suggestion where I should go from here if I'm interested in learning about similar fields. If would be nice if I could relate it back to programming, but not necessarily a prerequisite.</p>

<p>Thanks.</p>
",logic
"<p>Let $\mathbf{G} = \langle G,\cdot,\mathcal{T}\;\rangle$ be a topological group. Let $\mathbf{e}$ be the identity element of $\langle G,\cdot \rangle$.
Assume $\{\mathbf{e}\}$ is closed in $\langle G,\cal{T}\;\rangle$. Then, I have managed to convince myself that:</p>

<ol>
<li>ZF proves that $\langle G,\cal{T}\;\rangle$ is regular Haudorff.</li>
<li>ZF + (Dependent Choice) proves that $\langle G,\cal{T}\;\rangle$ is completely regular.</li>
</ol>

<p>My questions are:</p>

<ol>
<li>Are those right?</li>
<li>Does ZF prove that $\langle G,\cal{T}\;\rangle$ is completely regular?</li>
<li>If no to question 2, does assuming one or more of following suffice for ZF to conclude that $\langle G,\cal{T}\,\rangle$ is completely regular?
<ol>
<li>$\mathbf{G}$ is <a href=""http://en.wikipedia.org/wiki/Uniform_space#Examples"">two-sided complete</a></li>
<li>$\langle G,\cdot \rangle$ is abelian</li>
<li>Countable Choice</li>
</ol></li>
</ol>
",logic
"<p>From wikipedia <a href=""http://en.wikipedia.org/wiki/Quantification"" rel=""nofollow"">quantification</a> has meaning:</p>

<blockquote>
  <p>In logic, quantification is the
  binding of a variable ranging over a
  domain of discourse</p>
</blockquote>

<p><strong>Is there any formal ""definition"" of universal quantifier for example using definition of domain of discourse?</strong> </p>

<p>I mean a formula build without universal quantifier, and existential one which has the same meaning if referenced to defined domain of discourse?</p>

<p>For example:
Suppose we use domain of discourse (DoD) given by sentence $ U = \{ x|\phi(x) \}$ for some $\phi(x)$. Then naively we may wrote:</p>

<p>($\forall (x \in U)   \Phi(x) ) \equiv  ( \{ x|\phi(x) \} =&gt; \Phi(x) )$</p>

<p>In words: to say that some property follows for every x in DoD is the same as to say that if x is chosen from DoD then has this property.</p>

<p>We may try also the folowing one:
($\forall (x \in U)   \Phi(x) ) \equiv (( \{ x|\phi(x) \} =&gt; \Phi(x) ) =&gt; (\phi(x) &lt;=&gt; \Phi(x) ))$</p>

<p>In words: to say that some property follows for every x in DoD is the same as to say that $\phi$ and $\Phi$ are evenly spanned. </p>

<p>Do  You know any reference for such matter?</p>

<hr>

<p>Gabriel: Yes, I agree that from formal point of view in mathematical practice DoD is a set and to extend it to bigger universe usual is done by pure formal way and may be changed to some additional axioms etc. But this is some kind of mathematical practice: ""near every decent theory as far as we know is defined for DoD to be set or smaller but as it works also for proper classes we are trying to write it in a way"". But then we omit important statement: <strong>every time DoD has to be defined and additional axioms about it existence, definition,properties has to be added to the theory.</strong> I am only a hobbyist but I do not know any theorem which states: structure to be DoD for formal theory over countable language has to have ""this and this"" property. Of course for example as in formula $\{ x|\phi(x)\}$ we may require that $\phi(x)$ has some property. For example we may require that it is in first order language. Or in second order. Or in finite order language etc. For me is rather clear that it cannot be whatever I like. As far as I know we do not have any theory for that. But maybe I am wrong? </p>

<p>So my question is: what is that mean ""for all"" in a context of different definition of DoD ( as well as ""there exists""). Do we have clear meaning what it means for very big universes? We use some operator here named ""for all"" but have we possibility to define its meaning in syntactical way? If not, may we be sure that meaning of sentence ""for all"" is clearly defined? </p>

<p>I suggest this is example of <strong>Incomplete Inductive reasoning</strong> about possible ways of using general quantifier in mathematics. Moreover I suppose, even after reading something about Hilbert epsilon calculus that quantifiers has usual only intuitive meaning, that is its definition is far from such level of formality as for binary operation $\in$ for ZFC for example, where it may be anything (for example in <a href=""http://en.wikipedia.org/wiki/Cumulative_hierarchy"" rel=""nofollow"">von Neumann hierarchy of sets</a> ""model"" of ZFC it is order). When we try to define formal theory we want to abstract from the ""meaning"" of the symbols and give only pure syntactical rules for them. As far as I know ( but I know not much) I do not know such definition for quantifiers, even in epsilon Hilbert calculus for example, because it <strong>omits the area of possible, acceptable or correct definitions of  domain of discourse.</strong></p>
",logic
"<p>In</p>

<blockquote>
  <p>David Pincus, <em>Zermelo-Fraenkel Consistency Results by Fraenkel-Mostowski Methods</em>,
  The Journal of Symbolic Logic, Vol. 37, No. 4 (Dec., 1972), pp. 721-743</p>
</blockquote>

<p>Pincus introduces the notion of <em>injectively bounded statements</em>, which he proves are sentences which can be transferred from a (permutation) model of ZFA to a (symmetric) model of ZF. I have no intuition for what these statements are, and he only gives a couple of examples (allow me to ignore the special case of projectively bounded statements, I am after generality here).</p>

<p>I would like, if possible, a more structural explanation of what it means for a statement to be injectively bounded, rather that something that looks like a mess of codings via ordinals.</p>
",logic
"<p>I am interested in different contexts in which Gödel's incompleteness theorems arise. Besides traditional  Gödelian proof via arithmetization and formalization of liar paradox it may also be obtained from undecidability results of Turing and Church. In the context of complexity theory, it is not hard to see that Gödel's theorem (as well as Turing's result) follows from the following Chaitin's result: there exists some natural number N such that for any program P of size more than N it is impossible to prove (say, in ZFC) that it is the smallest (in the sense of size, i. e. number of bits) of those programs which have the same inputs-outputs as P has. The number N depends on particular axiomatic system (say, ZFC) and is not very large so that it actually can be calculated.</p>

<p>If You know other ways towards Gödel's incompleteness theorems, please, present them. Particularly, can Goedel's theorem be obtained without use of self-referential ideas? </p>
",logic
"<p>Bayesian probabilities are usually justified by the Cox theorems, that can be written this way:</p>

<p><em>Under some technical assumptions (continuity, etc, etc...), given a set $P$ of objects $A, B, C, \ldots$, with a boolean algebra defined over it with operations $A \wedge B$ (and) and $A | B$ (or) such that</em>:</p>

<p>1) $A \wedge B = B \wedge A$  </p>

<p>2) $A \wedge (B \wedge C) = (A \wedge B) \wedge C$</p>

<p>3) $A | (B \wedge C) = (A|B) \wedge (A|C)$</p>

<p><em>and a ""valuation"":</em></p>

<p>$f : P \rightarrow \mathcal{R}$</p>

<p><em>there is a strictly monotonic ""regraduation function""</em> $R : \mathcal{R} \rightarrow \mathcal{R}$ <em>such that, for</em>:</p>

<p>$R(f(A\wedge B)) = R(f(A)) + R(f(B))$ (sum rule) </p>

<p>and</p>

<p>$R(f(A|B)) = R(f(A) ) R(f(B))$ (product rule)</p>

<p>This theorem allows one to show that any system designed to ""evaluate"" boolean expressions consistently with a single real number redunds in the laws of classical probability (this can be seen shortly here: arxiv:physics/0403089 and more thoroughly here: arxiv:abs/0808.0012)</p>

<p>Recently this has been extended for valuations of the type $f : P \rightarrow \mathcal{R}^2$ in <a href=""http://arxiv.org/abs/0907.0909"" rel=""nofollow"">http://arxiv.org/abs/0907.0909</a> and they proved that there are just 5 canonical valuations compatible with the underlying Boolean algebra (one of them giving a complex field structure to the ""valuation"" field). </p>

<p>My question/proposal is: is it possible/interesting/feasible to classify at least a class of valuations of the type:</p>

<p>$f : P \rightarrow W$ </p>

<p>where W is a continuous manifold? If we retrict our attention to $\mathcal{R}^n$ for example, is there, for each n, a set of canonical valuations to which all others can be reduced after a regraduation?</p>

<p>If this can be done, are those nice rules for inference in some sense? Are they useful as inference tools in specific situations? </p>
",logic
"<p>Hi,</p>

<p>Many thanks in advance if you could help answering the
following questions:</p>

<p>Q1 - Is M(e) > M(pi) true in the real numbers?</p>

<p>Q2 - Is the first order formal system T = ZFC + { M(e) > M(pi) } consistent?</p>

<p>(Where e and pi are the 2 familiar transcendental real numbers). </p>

<p>=========================> Definitions.</p>

<p>Let a real number x be generally expressed as:</p>

<p>I.d1d2d3...dn...</p>

<p>Where 'I' is the integral part and each 'dn' is a decimal expansion
digit. Consider the sequence Sn defined as:</p>

<p>S1 = .d1d2d3...dn...</p>

<p>S2 = .d2d3...dn...</p>

<p>...</p>

<p>Sn = .dn(dn+1)(dn+2)...</p>

<p>...</p>

<p>Let's define M(x) [""Major number"" of x] and m(x) [""minor"" number of x]
as:</p>

<p>M(x) = l.u.b (Sn)</p>

<p>m(x) = g.l.b (Sn)</p>

<p>Thanks,</p>

<p>-Nam Nguyen</p>
",logic
"<p>Let ${\bf N}^\omega = \bigcup_{m=1}^\infty {\bf N}^m$ denote the space of all finite sequences $(N_1,\ldots,N_m)$ of natural numbers.  For want of a better name, let me call a family ${\mathcal T} \subset {\bf N}^\omega$ a <em>blocking set</em> if every infinite sequence $N_1,N_2,N_3,N_4,\ldots$ of natural numbers must necessarily contain a blocking set $(N_1,\ldots,N_m)$ as an initial segment.  (For the application I have in mind, one might also require that no element of a blocking set is an initial segment of any other element, but this is not the most essential property of these sets.)</p>

<p>One can think of a blocking set as describing a machine that takes a sequence of natural number inputs, but always halts in finite time; one can also think of a blocking set as defining a subtree of the rooted tree ${\bf N}^\omega$ in which there are no infinite paths.  Examples of blocking sets include</p>

<ol>
<li>All sequences $N_1,\ldots,N_m$ of length $m=10$.</li>
<li>All sequences $N_1,\ldots,N_m$ in which $m = N_1 + 1$.</li>
<li>All sequences $N_1,\ldots,N_m$ in which $m = N_{N_1+1}+1$.</li>
</ol>

<p>The reason I happened across this concept is that such sets can be used to pseudo-finitise a certain class of infinitary statements.  Indeed, given any sequence $P_m(N_1,\ldots,N_m)$ of $m$-ary properties, it is easy to see that the assertion</p>

<blockquote>
  <p>There exists an infinite sequence $N_1, N_2, \ldots$ of natural numbers such that $P_m(N_1,\ldots,N_m)$ is true for all $m$.</p>
</blockquote>

<p>is equivalent to</p>

<blockquote>
  <p>For every blocking set ${\mathcal T}$, there exists a finite sequence $(N_1,\ldots,N_m)$ in ${\mathcal T}$ such that $P_m(N_1,\ldots,N_m)$ holds.</p>
</blockquote>

<p>(Indeed, the former statement trivially implies the latter, and if the former statement fails, then a counterexample to the latter can be constructed by setting the blocking set ${\mathcal T}$ to be those finite sequences $(N_1,\ldots,N_m)$ for which $P_m(N_1,\ldots,N_m)$ fails.)</p>

<p>Anyway, this concept seems like one that must have been studied before, and with a standard name.  (I only used ""blocking set"" because I didn't know the existing name in the literature.)  So my question is: what is the correct name for this concept, and are there some references regarding the structure of such families of finite sequences?  (For instance, if we replace the natural numbers ${\bf N}$ here by a finite set, then by Konig's lemma, a family is blocking if and only if there are only finitely many finite sequences that don't contain a blocking initial segment; but I was unable to find a similar characterisation in the countable case.)</p>
",logic
"<p>Is there any web-based course or materials about logic / automatic theorem proving? (I checked MIT's OpenCourseWare and I only found a vaguely related AI course)</p>
",logic
"<p>It is well-known that the modal logic S4 is complete with respect to the class of all finite quasi-trees (where we interpret the $\Box$ modality as topological interior, and topologize a quasi-tree with the up-set topology). It is also well-known that p-morphisms (open, continuous surjections) preserve modal validity. Thus, for any space $X$, the existence of p-morphisms from $X$ onto every finite quasi-tree is a sufficient condition for $X$ to be S4-complete. This technique can be used to establish, for example, McKinsey and Tarski's famous result that S4 is the logic of any dense-in-itself, metrizable space.</p>

<p>My question is:</p>

<blockquote>
  <p>Is this condition also necessary? Said differently: is there a space $X$ and a finite quasi-tree $Q$ such that $X$ is S4-complete but there exists no p-morphism $\rho: X \to Q$?</p>
</blockquote>

<p>This seems like a natural question to ask, but I haven't had much luck in finding any discussion about it. Even just a pointer to the right body of literature would be very much appreciated.</p>

<hr>

<p><strong>Addendum</strong></p>

<p>Here I'll define my terms a little more carefully, and spell out the translation of my question in terms of the more standard Kripke semantics.</p>

<p>Recall that quasi-orders are sets equipped with reflexive, transitive binary relations, which is precisely the class of Kripke frames corresponding to S4. A quasi-order $Q = (Q,\leq)$ is called a quasi-tree if $Q/\sim$ is a tree, where $\sim$ is the equivalence relation on $Q$ defined by</p>

<p>$$x \sim y \iff x \leq y \textrm{ and } y \leq x.$$</p>

<p>As mentioned in the comments, there is a correspondence between quasi-orders and Alexandrov spaces, one direction of which is given by topologizing quasi-orders with the up-set topology. There is also a notion of a p-morphism between quasi-orders, nicely outlined <a href=""http://en.wikipedia.org/wiki/Kripke_semantics#Model_constructions"" rel=""nofollow"">by Wikipedia</a>. A p-morphism between quasi-order corresponds to an open, continuous map between the corresponding Alexandrov spaces.</p>

<p>I use the phrase ""$X$ is S4-complete"" (perhaps somewhat idiosyncratically?) to mean that every formula validated by $X$ is provable in S4; equivalently, $X$ refutes all non-theorems of S4. It is known that if $Q$ is any quasi-order and for each <em>finite</em> quasi-tree $Q_{t}$ there exists a surjective p-morphism $\rho_{t}: Q \to Q_{t}$, then $Q$ is S4-complete. One can then ask:</p>

<blockquote>
  <p>Is the converse true? Does every S4-complete quasi-order Q admit maps $\rho_{t}$ as above?</p>
</blockquote>

<p>If not, then a counter-example can be ""lifted"" into the topological setting, thus answering my original question. However, a positive answer to this question does not immediately resolve the topological version since the quantification in the topological version is over <em>all</em> spaces, rather than just the Alexandrov spaces. Nonetheless, I would be interested in an answer (or even a hint at an answer) to either question.</p>
",logic
"<p>If  $\text{ZF}$ is consistent, then it is not finitely axiomatizable. For if $\Gamma$ is a finite axiomatization, then $\text{ZF}$ proves by reflection that $\Gamma$ has a set model, and hence (since $\Gamma$ axiomatizes $\text{ZF}$) so does $\Gamma$. By the Second Incompleteness Theorem, $\Gamma$ is inconsistent. This is absurd, since it axiomatizes $\text{ZF}$.</p>

<p>The following therefore intrigues.</p>

<p><strong>Theorem.</strong> There is a finite $\Gamma \subseteq \text{ZF}$ such that every transitive proper class model of $\Gamma$ verifies $\text{ZF}$.</p>

<p><em>I wish to know whether any obstacle prevents formalizing this in $\text{ZF}$. If not, how does that bear on the aforementioned theorem about finite axiomatizability?</em></p>

<p>For instance, if formalization is possible, it seems to follow that $\text{ZF}$ proves that, if $\text{ZF}$ is consistent, then $\Gamma$ has a model refuting $\text{ZF}$. Else ""every model of $\Gamma$ verifies $\text{ZF}$"" is consistent with $\text{ZF + Con(ZF)}$, which is absurd since the joint theory proves that $\text{ZF}$ both is and isn't finitely axiomatizable. But that's not very interesting. Perhaps the theorem implies something about nonfirstorderizability of transitivity? Do tell!</p>

<p>Here is a proof, the length of which merits apology. Seems formalizable to me!</p>

<p><strong>Proof.</strong> We specify $\Gamma$ in stages. First let it contain all axioms of $\text{ZF}$ besides Comprehension and Replacement. Next let $\Gamma$ contain the finitely many instances of Comprehension and Replacement needed, in addition to the above, to prove the facts invoked below about absoluteness and the cumulative hierarchy. Following Kunen, let $\text{En}(i,X,j)$ be the set of $j$-tuples from $X$ satisfying the $i$th formula in $j$ variables, relativized to $X$. Where $\ast$ denotes concatenation, write $\eta(m,n,s,t,A,B)$ for</p>

<blockquote>
  <p>$m, n \in \omega \wedge t \in B \wedge A \in B \wedge s \in B^n \wedge s\ast\langle t, A \rangle \in \text{En}(m, B, n+2)$</p>
</blockquote>

<p>and $\mu(m,n,s,t,A,B,y)$ for</p>

<blockquote>
  <p>$m, n \in \omega \wedge t \in B \wedge A \in B \wedge s \in B^n \wedge y \in B \wedge s\ast\langle t, y, A \rangle \in \text{En}(m, B, n+3).$</p>
</blockquote>

<p>Finally, let $\Gamma$ contain the instance (+)</p>

<blockquote>
  <p>$\forall m,n,s,A,B\ \exists y\ \forall t\ [t \in y \leftrightarrow t \in A \wedge \eta(m,n,s,t,A,B)].$</p>
</blockquote>

<p>of Comprehension, and the instance (++)</p>

<blockquote>
  <p>$\forall m,n,s,A,B[\forall t \in A\ \exists!y\ \mu(m,n,s,t,A,B,y) \rightarrow \exists Y\ \forall t \in A\ \exists y \in Y\ \mu(m,n,s,t,A,B,y)]$</p>
</blockquote>

<p>of Replacement. Let nothing else be in $\Gamma$.</p>

<p>Now suppose $M$ is a transitive proper class model of $\Gamma$. To prove that $M$ verifies $\text{ZF}$, it suffices to check that it verifies arbitrary instances of Comprehension and Replacement. We do the former; the latter is similar, using (++) in place of (+). Let $\theta(w_1, \dots, w_n, t, A)$ be a formula, and take sets $w_1, \dots, w_n, A$ in $M$. By Comprehension in $V$, let $a$ be the set of all $t \in A$ such that $\theta^M(w_1, \dots, w_n, t, A)$. We aim to show that $a$ is an element of $M$.</p>

<p>Since $M$ is transitive and contains $A$, $a$ is a subset of $M$. And since $M$ verifies $\Gamma$, the tuple $s = \langle w_1, \dots, w_n \rangle$ is in $M$. Define a cumulative hierarchy on $M$ by setting $M_\alpha = M \cap V_\alpha$. By the reflection theorem, take $\beta &gt; \text{max rank}(a, A, s, \omega)$ such that $\theta$ and $\Gamma$ are absolute for $M_\beta$, $M$. Now $M_\beta$ is a transitive model of $\Gamma$ containing $w_1, \dots, w_n, A, s, \omega$, and each element of $a$. Moreover, $M_\beta \in M$, since $M$ thinks $V_\beta$ exists.</p>

<p>By definition of $\text{En}$ there is an integer $q$, the Gödel number of $\theta$, such that $\text{En}(q, M_\beta, n+2)$ is the set of (n+2)-tuple from $M_\beta$ satisfying $\theta^{M_\beta}$. Using (+) in $M$ with $m = q$ and $B = M_\beta$, and computing relativizations and absoluteness with the aid of $\Gamma$, there is $y \in M$ containing precisely the $t \in M$ such that $t \in A \wedge \theta^{M_\beta}(w_1, \dots, w_n, t, A)$. Since $a$ is a subset of $M_\beta$ and $\theta$ is absolute for $M_\beta$, $M$, this $y$ is just $a$. So $a$ is in $M$, as desired.</p>

<p>QED</p>

<p>By the way, the theorem is Exercise 7 in Chapter V of Kunen.</p>
",logic
"<p>Every formal theory is a collection of alphabet, axioms and derivation rules. My question is - what kind of ""derivation rules"" are acceptable here. For example, ""from A B it follows $A \cup B$"" is a valid derivation rule. But what about, say, D: ""from K it follows Cons (T(K))"" where K is any collection of axioms, T(K) is the theory with axioms K and some prespecified alphabet and derivation rules? If alphabet of T(K) is reach enough to express the statement ""Cons (T(K))"", I see no reason why D is not a valid derivation rule.</p>

<p>But if it is, let us add this derivation rule D to ZFC, and denote the resulting theory ZFC+. Now, sets of axioms in ZFC and ZFC+ coincide, so it is recognizable. Next, if we believe that all axioms in ZFC are sound, all theorems in ZFC+ are also sound, and hence ZFC+ is consistent. Finally, if we apply D with K = ""all axioms in ZFC+"" we derive Cons (ZFC+) in one step. This is a contradiction with Godel Theorem. So, D is not a valid derivation rule? If so, why?    </p>
",logic
"<p>We know that existence of a Lebesgue non-measurable set is consistent with the Axiom Of Choice.  Is the converse true?  That is, does the existence of a Lebesgue non-measurable set imply the Axiom Of Choice?</p>
",logic
"<p>Is the following statement consistent in $\mathsf{ZFC}$?</p>

<blockquote>
  <blockquote>
    <p>For every ordinal $\beta$ there is an ordinal $\lambda_0$ such that for all ordinals $\lambda\geq\lambda_0$ we have $2^{\aleph_{\lambda}}\geq \aleph_{\lambda+\beta}.$</p>
  </blockquote>
</blockquote>
",logic
"<p>Just a random thought here: Can cohomology theories (e.g. sheaf cohomology) on the Stone space $S_n(T)$ (the space of complete n-types) of a first-order theory $T$ tell us anything interesting (e.g. the classification of theories)? Is there any result in model theory that is obtained (probably most easily) by this kind of application of cohomology theories? Thanks!</p>
",logic
"<p>Suppose we have a first order theory $T$ in a language which contains the identity symbol $=$, constants $a_1$, $a_2$, $a_3$, ... $b_1$, $b_2$, $b_3$, ... and no relation or function symbols. For natural numbers $i \neq j$, suppose that $a_i \neq a_j$ is contained in $T$, and let us suppose that $T$ has no models whose domain consists only of $a_1, a_2, a_3, ...$ - that is to say, let us suppose that in every model of $T$, at least one of the $b$s is distinct from all of the $a$s. </p>

<p>Must there be some number $n$ such that in every model of $T$, one of $b_1$, $b_2$, ... , $b_n$ is distinct from all the $a$s? </p>
",logic
"<p>Is there an algebra $A$ (for example a group) such that $Th(A)$ is logically equivalent to $id(A)$? In other words, is there an algebra $A$ such that
$$
Mod(Th(A))=Var(A)?
$$
Clearly finite algebras do not have this property. It seems that such an algebra should be relatively free.</p>

<p>This question is related to my previous two questions </p>

<ol>
<li><p><a href=""http://mathoverflow.net/questions/153743/relatively-free-algebras-in-a-variety-generated-by-a-single-algebra"">Relatively free algebras in a variety generated by a single algebra</a></p></li>
<li><p><a href=""http://mathoverflow.net/questions/153883/relatively-free-groups-in-vars-3"">relatively free groups in $Var(S_3)$</a></p></li>
</ol>

<p>Edition: Only trivial algebra has this property by the comment of Gerhard Paseman. So I ask again the question by $\pm id(A)$ instead of $id(A)$. Is there any algebra A (especially a group) such that $Th(A)$ is logically equivalent to $\pm id(A)$? Here $\pm id(A)$ means the set of identities and negated identities. </p>

<p>P.S. By negated identity  I mean a sentence of the form
$$
\forall x_1\ldots \forall x_n:  p(x_1, \ldots, x_n)\neq q(x_1, \ldots, x_n),
$$
where $p$ and $q$ are terms. Is there any negated identity in a non-trivial algebra? Clearly there are no negated identities in groups but if we add constants to the language of groups there will be many negated identities.</p>
",logic
"<p>Can one define some measure of progress towards a proof of a statement? I'm not sure if it's even possible for general first order logic statements so let's restrict ourselves to propositional statements. Assume for simplicity that we know if the statement in question is true or false beforehand.</p>

<p>Then if one is using the DPLL system for proving a propositional statement false (or true after taking the negation of the statement and trying to prove the unsatisfiability of that), then one can easily define a measure of progress towards the proof - if the statement has $n$ variables and we encounter failure after branching on $k$ variables, then we have made $2^{-k}$ fraction progress towards a proof of unsatisfiability.</p>

<p>If one works with the resolution proof system, then I can't think of a polynomial-time computable measure. For an exponential-time measure, one could examine all clauses derived so far and calculate what fraction of the search space they prune.</p>

<p>For more general proof systems which allow introducing new variables however (like the Extended Frege system, for instance), I can't think of any measure. (Edit: except in a very limited sense in which we explore the space of all possible proofs and then decide whether a particular step counted as progress towards a proof of unsat)</p>

<p>So my question is whether there exist better measures of progress towards a proof of unsatisfiability (or tautology) of a propositional formula than the ones above.</p>

<p>A relevant link might be <a href=""https://rjlipton.wordpress.com/2009/02/12/bait-and-switch-why-lower-bounds-are-so-hard/"" rel=""nofollow"">this</a> which talks about defining a measure of progress in terms of computing a function in terms of proving lower bounds. If we take the function to output 0 if the input formula is unsat and 1 if it is not, then it could be relevant to the measure in question above.</p>
",logic
"<p>Fagin's 0-1 law for first-order properties of random graphs states that, for every first-order sentence in the logic of graphs, the probability that a uniformly random $n$-vertex graph models the sentence tends to either 0 or 1 as $n$ goes to infinity. It is known that testing, for a given sentence, whether the limit is 0 or whether it is 1 is PSPACE-complete (Grandjean, ""Complexity of the first-order theory of almost all finite structures"", <em>Information and Control</em> 1983). One possible approach to performing this sort of test would be to sample random graphs of sufficiently large size and test whether they model the sentence; but this would be limited both by the difficulty of testing whether a graph models a given sentence and also by the convergence rate of the 0-1 law, as that would control the size of the graphs needed in this sampling scheme.</p>

<p>What if anything is known and published about more explicit upper or lower bounds on the convergence rate of $P_S$, for the worst-case sentence $S$ of a given length, as a function of $S$? Or to put it another way, if one wishes to get the correct limit with probability bounded away from $1/2$, how large a graph should one sample?</p>

<p>One simple example of a sentence that converges slowly is given by the Ramsey property: does this graph contain either a clique of size $k$ or an independent set of size $k$? The sentence for this has length $O(k^2)$ but one needs to sample graphs of size at least exponential in $k$ to discover that the limit probability is one. But maybe there are other sentences that converge even more slowly?</p>
",logic
"<p>As I understand it, a proof that P=NP or P≠NP would need to be non-relativizable (as in recursion theory oracles).</p>

<p>Virtually all proofs seem to be relativizable, though.</p>

<p>What are good examples of <em>non</em> relativizable proofs, of the sort that a P=NP/P≠NP proof would need to be, that are not trivial or contrived?</p>

<p>(I am not a recursion theorist, so please pardon the lack of citations.)</p>

<p>[xposted to <a href=""http://cstheory.stackexchange.com/questions/20511/what-are-natural-examples-of-non-relativizable-proofs"">cstheory</a> as suggested]</p>
",logic
"<p>In the paper ""Complete topoi representing models of set theory"" by Blass and Scedrov, they consider a general notion of Boolean-valued model of set theory, and one of the conditions they impose is that the model contain ""no extra ordinals after those of V"", i.e. that for all z in the model we have</p>

<p>$$\Vert z \text{ is an ordinal} \Vert = \bigvee_{\alpha \text{ is an ordinal of } V} \Vert z=\check{\alpha}\Vert $$</p>

<p>where $\Vert-\Vert$ denotes the truth function of the model valued in some complete Boolean algebra.</p>

<p>My question is: do there exist models which <em>do</em> contain ""extra ordinals"" in this sense?  I presume so, or they wouldn't have needed to impose this condition.  What do such models look like?</p>

<p>(By way of clarification, certainly if the starting model V is a set model in some larger universe, then one can find other set models in that larger universe which contain more ordinals.  But I'm interested in just starting with a single model V and building models from it, which can be sets or proper classes.)</p>
",logic
"<p>In mathematical logic and model theory, one considers <em>interpretations</em> of syntactic expressions: terms without free variables are interpreted as elements of some structure, formulas without free variables have truth values, formulas with free variables can be interpreted as relations.</p>

<p>Multiple expressions may have identical interpretations.  For example, $\ulcorner 1 + 1\urcorner$ and $\ulcorner 2\urcorner$ are both interpreted as $2$.</p>

<p><strong>Question:</strong> does anyone ever consider formal languages where terms can have multiple interpretations?  Is there some standard approach or framework?</p>

<p>I am thinking about this because i am trying to understand the $\omicron$ and $O$ notation in analysis, like in
$$
  \ln(x) =\omicron(x),\quad x\to +\infty.
$$
Also, when calculating an indefinite integral, on often writes
$$
  \int 2x\,dx = x^2 + C.
$$</p>

<p><strong>Update.</strong>
I understand that when the equality sign is used with $\omicron$/$O$ notation, it does not represent an equivalence relation.
I also know that $\omicron(g(x))$ can be viewed as a set of functions.
However, this interpretation does not fit my intuition well.
When i write $\sin x = x + \omicron(x^2)$, $x→0$, i do not think about sets of functions, i think that i am replacing an anonymous implicitly understood function with a placeholder.
In other words, the designated object does not change (it is still a function or a number, not a set of functions or set of numbers), only the notation is abbreviated and made less explicit, a bit like when i write ""$1 + 2 + 3$"" instead of ""$((1 + 2) + 3)$"".</p>
",logic
"<p>Although I think I know the answers to these, I'd just like to collect them all in one place.</p>

<p>What is the quantum PCP theorem, what implications does its proof have for simulation of Hamiltonians and is following Irit Dinur's reproof of the classical version the best/only current mode of attack (and if so why?) What is the sort of math/physics/theoretical CS background needed to approach this problem?</p>
",logic
"<p>In representation theory, there is a well-known notion of a wild classification problem (such problems have been discussed often on this forum, for example, <a href=""http://mathoverflow.net/questions/10481/when-is-a-classification-problem-wild/10484#10484"">here</a>). In logic, there is a notion of an <a href=""http://en.wikipedia.org/wiki/Undecidable_problem"">undecidable problem</a>.</p>

<blockquote>
  <p>Is there a theorem which says that there is something undecidable about a wild classification problem?</p>
</blockquote>

<p>A reference where such issues are discussed would be very helpful.</p>
",logic
"<p><strong>Update:</strong> Perhaps the question is too difficult. I would appreciate, thus, even just comments or related observations.</p>

<p>This question assumes familiarity with combinatorial cardinal characteristics of the continnum. It is the essence of an earlier question.</p>

<p>Let $[\mathbb{N}]^\infty$ be the family of infinite subsets of $\mathbb{N}$,
partially ordered by $\subseteq^*$, where $a\subseteq^* b$ means $a\setminus b$ is finite.</p>

<p>Let $\kappa$ be a cardinal number.
A <em>tower of height $\kappa$</em> is a $\kappa$-sequence 
$\langle\, s_\alpha : \alpha&lt;\kappa\,\rangle$ in $[\mathbb{N}]^\infty$ such that</p>

<ol>
<li>This $\kappa$-sequence is $\subset^*$-decreasing as the ordinal number $\alpha$ increases.</li>
<li>The set $\{\,s_\alpha : \alpha&lt;\kappa\,\}$ has no pseudointersection.
(That is, there is no infinite set $s$ such that $s\subseteq^* s_\alpha$ for
all $\alpha&lt;\kappa$).</li>
</ol>

<p>An element $a\in [\mathbb{N}]^\infty$ is identified with its increasing enumeration. This way, the set $[\mathbb{N}]^\infty$ 
becomes the family of increasing functions in $\mathbb{N}^\mathbb{N}$,
and the standard relation $\le^*$ is defined on 
$[\mathbb{N}]^\infty$.
A set $X\subseteq [\mathbb{N}]^\infty$ is <em>bounded</em> if it is bounded (from above) with respect to $\le^*$.</p>

<p>The general goal is to understand when is there an <em>unbounded</em> tower of height $\mathfrak{b}$. Let us call this axiom BT.</p>

<p>It is <a href=""http://dx.doi.org/10.1090/S0002-9939-10-10407-9"" rel=""nofollow"">known</a> or easy to see that:</p>

<ol>
<li>An unbounded set has no pseudointersection. So we may remove the need for no pseudointersection from the definition of <em>tower</em> without altering BT.</li>
<li>If there is an unbounded tower of any cardinality, then BT holds.</li>
<li>If $\mathfrak{t}=\mathfrak{b}$ or $\mathfrak{b}&lt;\mathfrak{d}$, then BT holds.</li>
</ol>

<p><strong>Open-ended question.</strong> Can the axiom BT be expressed using (standard) 
cardinal characteristics of the continuum?</p>

<p><a href=""http://mathoverflow.net/questions/238500/when-is-there-an-unbounded-tower-in-mathbbn-infty"">Ashutosh</a> proved that BT is consistent with ""$\aleph_1=\mathfrak{t}&lt;\mathfrak{b}=\mathfrak{c}=\aleph_2$"".</p>

<p><a href=""http://mathoverflow.net/questions/238424/what-is-the-height-or-depth-of-mathbbn-infty"">Will Brian</a> points out that that BT fails in the Hechler model. BT also fails in the Laver model, indirectly by the main result of the <a href=""http://dx.doi.org/10.1090/S0002-9939-10-10407-9"" rel=""nofollow"">linked paper</a>. I suspect that BT also fails in the Mathias model.</p>

<p><strong>Question 1.</strong> Does any additional inequality or inequality among cardinals of the continuum (one not following from 
$\mathfrak{t}=\mathfrak{b}$ or $\mathfrak{b}&lt;\mathfrak{d}$) imply BT? </p>

<p><strong>Question 2.</strong> Does BT imply any equality among cardinals of the continuum? </p>

<p>Since BT follows from CH, the hypotheisis BT does not imply any <em>in</em>equality.</p>

<p><strong>Motivation.</strong> BT implies that, even in the realm of real sets, the selective covering property $\operatorname{S}_1(\Gamma,\Gamma)$ (which is <a href=""http://dx.doi.org/10.1090/S0002-9939-10-10407-9"" rel=""nofollow"">consistently trivial</a>) is nontrivial.</p>
",logic
"<p>(This is based on <a href=""http://mathoverflow.net/questions/73815/does-zf-prove-that-topological-groups-are-completely-regular"">my earlier question</a>, but I think this one would be easier to answer.)
<br><br><br>
Let $\langle X,\mathbf{\delta} \hspace{.01 in} \rangle$ be a <a href=""http://en.wikipedia.org/wiki/Proximity_space"" rel=""nofollow"">separated proximity space</a>, and let $\cal{T}\hspace{.04 in}$ be the induced topology on $X$.
<br>
Then, ZF proves that $\langle X,\cal{T}\hspace{.06 in} \rangle$ is regular Hausdorff, and
<br>
ZF + (Dependent Choice) $\;$proves that $\langle X,\cal{T}\hspace{.06 in} \rangle$ is completely regular.</p>

<p>Does ZF prove that $\langle X,\cal{T}\hspace{.06 in} \rangle$ is completely regular?
<br><br></p>
",logic
"<p>Regarding the internalization of mathematics to a particular category as in the nLab article: <a href=""http://ncatlab.org/nlab/show/internal+logic"" rel=""nofollow"">Internal Logic</a>, there is a peculiar table mentioned in the section on <a href=""http://ncatlab.org/nlab/show/internal+logic#CategoricalSemantics"" rel=""nofollow"">Categorical Semantics</a> in which there is a corresponding category-theoretic construction to the regular logical operators in a theory. In particular, $\wedge$ corresponds to a pullback of a cospan, $\top$ corresponds to the top element (A itself), $\wedge$ corresponds to union, $\bot$ corresponds to the bottom element (strict initial object), $\Rightarrow$ corresponds to the Heyting implication, $\exists$ corresponds to the left adjoint to a pullback (I'm not sure which pullback in particular?), and $\forall$ corresponds to the right adjoint to a pullback (what pullback is this also?).</p>

<p>Would it be possible to define the modal operators of $\Box$ and $\Diamond$ as the right adjoint of a pushout (similarly to how $\forall$ is the right adjoint to a pullback) and the left adjoint of a pushout (similarly to how $\exists$ is the left adjoint to a pullback), respectively? Or, if this does not work, could it be possible to define modal operators in internal logic using some other category theoretic construction?</p>
",logic
"<p>Let $I$ be a set and $\mathcal{U}$ an ultrafilter on $I$.  Let $(X_i)_{i \in I}$ be an $I$-indexed family of sets.  The ultraproduct of the family $(X_i)$ with respect to $\mathcal{U}$ is, everyone agrees, another set.  But which set is it?  There are two different definitions, and they sometimes give different results.  </p>

<p>For the sake of discussion, I'll call them ""Type 1"" and ""Type 2"" ultraproducts.</p>

<p><strong>Type 1</strong> $\ $ The <strong>type 1 ultraproduct</strong> of $(X_i)_{i \in I}$ with respect to $\mathcal{U}$ is
$$
\Bigl( \prod_{i \in I} X_i \Bigr) \Bigl/ \sim
$$
where 
$$
(x_i)_{i \in I} \sim (x'_i)_{i \in I} \iff \{ i \in I: x_i = x'_i \} \in \mathcal{U}.
$$</p>

<p><strong>Type 2</strong> $\ $ View the poset $(\mathcal{U}, \subseteq)$ as a category.  The <strong>type 2 ultraproduct</strong> of $(X_i)_{i \in I}$ with respect to $\mathcal{U}$ is the colimit of the functor $(\mathcal{U}, \subseteq)^{\text{op}} \to \mathbf{Set}$ defined on objects by 
$$
J \mapsto \prod_{j \in J} X_j
$$
and on maps by projection.  Explicitly, then, the Type 2 ultraproduct is
$$
\Bigl( \coprod_{J \in \mathcal{U}} \prod_{j \in J} X_j \Bigr) \Bigl/ \approx
$$
where 
$$
(x_j)_{j \in J} \approx (x'_k)_{k \in K} \iff \{ i \in J \cap K: x_i = x'_i \} \in \mathcal{U}.
$$</p>

<p><strong>The difference</strong> $\ $ The two types of ultraproduct are the same if either none of the sets $X_i$ are empty or almost all of them are empty.  But in the remaining case, where at least one $X_i$ is empty but the set of such $i$ is not large enough to belong to $\mathcal{U}$, they're different: the Type 1 ultraproduct is empty but the Type 2 ultraproduct is not. </p>

<p><strong>The question</strong> $\ $ I've read in a couple of texts (both coming from the point of view of categorical logic) that the Type 2 ultraproduct is really the right one.  But why?  On what criteria is Type 2 judged to be better than Type 1?</p>

<p><strong>A vague guess at an answer</strong> $\ $ I think I can guess <em>very</em> roughly what's going on.  There's been a tradition in logic &mdash; maybe dying out now? &mdash; of taking all structures to be nonempty by definition.  But when you move to the more general setting of categorical logic, that's no longer a satisfactory approach.  Although in the category of sets, there's just a single object with no elements, in many other categories, there are lots of interesting objects with no (global) elements: e.g. there are lots of interesting sheaves with no global sections.  </p>

<p>So categorical logic sometimes involves a recasting of classical, set-based logic, in order to handle empty sets/types satisfactorily.  I imagine that something of the sort is going on here.  (I only defined ultraproducts of sets, but you could of course define ultraproducts of objects of any other sufficiently complete category.)  But still, I don't see clearly why Type 2 is the right choice.  </p>

<p><strong>See also</strong> <a href=""http://mathoverflow.net/questions/11261/"">This question</a> of Joel David Hamkins, and its responses.</p>
",logic
"<p>Say we have a model $M$ of a theory $T$ of some core fuzzy logic.</p>

<p>When dealing with compactness, we run in to a situation where the new model being built (by the use of compactness over $M$), will necessarily need a newer BL-algebra for the truth in it to be evaluated (for example, see here: <a href=""http://mathoverflow.net/questions/160112/compactness-and-completeness-in-g%C3%B6del-logic"">Compactness and completeness in G&#246;del logic</a>).</p>

<p>It is known that certain logics do not have this problem (the easiest being standard first order logic).</p>

<p>My question is, is there a classification on BL-algebras that says the BL-algebras having this property will allow for compactness (in the classical sense) to go through? </p>

<p>Edit: Also I know that there are studies of this question from the viewpoint; Which logics have (classical) compactness. I would be very thankful if someone could point me in the direction of a comprehensive survey of these results.</p>
",logic
"<p>Hey Everyone!
In nearly all (if not all) projective geometry texts I have bumped into the following theorem:</p>

<p>""Principle of duality: If in a theorem in $\mathfrak{P}$ one switches the word point for the word line and the corresponding incidence relations once again one obtains a theorem of $\mathfrak{P}$.""</p>

<p>So far so good. Then I found this awesome list by G. Eric Moorhouse:
<a href=""http://www.uwyo.edu/moorhouse/pub/planes/"" rel=""nofollow"">http://www.uwyo.edu/moorhouse/pub/planes/</a></p>

<p>I noted the distinction between a Hall Plane and its dual. So looking a bit into the matter I kept running into the claim ""Hall Planes are non-Desarguian and non-self-dual"" and the modified version of the principle of duality, which claims the dualized theorem is true <em>on the dual plane</em> (this makes much more sense in my mind). </p>

<p>My question is twofold:</p>

<ol>
<li>How does one prove that Hall Planes are not self dual? I haven't managed to find a proof of this fact!</li>
<li>What would be the true duality principle? If duality holds in the dual plane it should not hold in Hall Planes (as they're not self dual), yet all texts I've read claim that duality holds in any projective plane.</li>
</ol>

<p>Thanks in advance!</p>

<p>P.S.
Any good references on the concept of duality in projective geometry from a geometrical point of view would be much appreciated!</p>
",logic
"<p>There are various open problems in the subject of logical number theory concerning the possibility of proving this or that well-known standard results over this or that weak theory of arithmetic, usually weakened by restricting the quantifier complexity of the formulas for which one has an induction axiom.  It particular, the question of proving the infinitude of the primes in Bounded Arithmetic has received attention.</p>

<p>Does this question make known contact with ""workaday number theory"" - number theory not informed by concepts from logic and model theory?  I understand that proof of the infinitude of the primes in bounded arithmetic could not use any functions that grow exponentially (since the theory doesn't have the power to prove the totality of any such function).  So especially I mean to ask:</p>

<p>1) If one had such a proof, would it have consequences about the primes or anything else in the standard model of arithmetic?
2) If one proves that no such proof exists, would that have consequences...
3) Do any purely number theoretic conjectures if settled in the right way, settle this question of its kin? </p>

<hr>

<p>As a side question, I'd be interested to know the history of this question.  I first heard about it from Angus Macintyre and that must have been 25 years ago.</p>
",logic
"<p>Goguen has popularized the initial algebra view of semantics via his ""no junk, no confusion"" slogan.  By ""no junk"", he means that models of a theory presentation should not have unnecessary elements, and ""no confusion"" that terms should not be mapped to equal values unless they are provably equal.  Sometimes, ""no junk"" is also interpreted as every element in the model is a denotation of a term, while ""no confusion"" as two different terms denote different elements in the model.  [These are classically equivalent statements, but they are not intuinistically equivalent, so I mention both].</p>

<p>My questions are:</p>

<ol>
<li><p>What is a 'good' formalization of this slogan?  By this I mean an explicit statement of ""no junk, no confusion"" in the meta-logic (since we're talking about models), where the logical strength of the corresponding statement is well understood.</p></li>
<li><p>Are there logics in which these requirements can be internalized?</p></li>
<li><p>What would be the corresponding slogan to ""no junk, no confusion"" for final coalgebras?</p></li>
</ol>
",logic
"<p>The surreal numbers are sometimes introduced as a place where crazy expressions like  $(\omega^2+5\omega-13)^{1/3-2/\omega}+\pi$ (to use the nLab's example) make sense.  The problem is, there seem to be varying definitions of the exponential in the surreal numbers and since I can't find any recent reference that covers them all I have little idea whether they're actually the same or not.  (When I say ""exponential"", I mean either $e^x$ or the general $a^x$ for $a&gt;0$; obviously one can go back and forth between these so long as $e^x$ is indeed a bijection from surreals to positive surreals.)</p>

<p>To wit:</p>

<ol>
<li>Harry Gonshor gives one definition in his ""An Introduction to the Theory of Surreal Numbers"".</li>
<li>Gonshor mentions an earlier unpublished definition due to Martin Kruskal; so does Conway in the 2nd edition of ""On Numbers and Games"". Neither actually state this definition, but it is strictly speaking possible for someone who's never seen it to verify equivalence with it, because Conway mentions that it is inverse to a particular definition of the logarithm, which he does not explicitly state but gives enough information to deduce.  Gonshor seems to suggest in his text that his definition is equivalent to Kruskal's unpublished one, but on the other hand never seems to explicitly state so.</li>
<li>Norman Alling's ""Foundations of Analysis over Surreal Number Fields"" looks like it might contain another definition?  I'm not too clear on what he's doing, honestly, though it looks like it's restricted to non-infinite surreals...</li>
<li><a href=""https://en.wikipedia.org/w/index.php?title=Surreal_number&amp;oldid=476475571#.22..._and_Beyond..22"" rel=""nofollow"">Wikipedia's page</a> [old version, this definition was removed from Wikipedia soon after asking this question] gives a totally uncited definition for $2^x$.  I have no idea where this might be originally from.  I suppose one could substitute in other surreals for 2 to generalize this?</li>
<li>Or else one could take Wikipedia's definition and generalize it in the way one usually does when starting from $e^x$? (I should hope this agrees with definition 4!).</li>
</ol>

<p>Note that the operation $x\mapsto \omega^x$ commonly used in the surreals is not related; though it's exponential in some sense, it's not surjective onto the positive surreals, and so definitions of a general exponential shouldn't attempt to agree with it. And of course definitions 1, 2, and 4/5 above are surjective onto the positive surreals.  (Or Wikipedia claims #4/5 is, anyway.)</p>

<p><strong>Edit</strong>: To avoid confusion, in what follows, I'll write $\exp_\omega x$ instead of the usual $\omega^x$, and reserve the notation $\omega^x$ for whatever that happens to be in the notion of exponentiation under discussion.</p>

<p>So, does anyone know to what extent these are actually equivalent?  If they're not equivalent, is there agreement on which ones are the ""right"" definitions?  (It seems like <em>all</em> of them have the right properties!  And while it seems to be agreed that the idea behind Kruskal's definition is bad, that doesn't mean necessarily the definition itself is.)  Or could anyone point me to any recent book which might clear all this up, or at least the source of Wikipedia's definition?</p>

<p>(I had originally intended to ask other questions about surreal exponentiation before finding that I wasn't sure what it actually was.  I am hoping that whatever references people can point me to will answer my other questions as well.)</p>

<p><strong>Slight update</strong>: Definitions 4 doesn't seem to agree with definition 5 (nor definition 1, see below); it would seem that definition 4 would imply $3^\omega=\omega$, while definition 5 would imply $3^\omega&gt;\omega$.  This raises the problem in that one could make more definitions by using definition 4 to define $a^x$ for some fixed $a$, and then generalizing it to $b^x$ for all $b$ via definition 5, and depending on your choice of starting $a$ -- whether $e$, 2, or something else -- you'd get different definitions of $b^x$ out.  An entire proper class of distinct ""exponentiation"" operations!  Well, perhaps not, perhaps not all starting values of $a&gt;1$ yield an onto function -- perhaps 2 is special and it's the only one that does, though that seems pretty unlikely, and barring that, this is pretty bad regardless.  Also, definition 4 seems pretty suspect as the ""right"" definition for another reason: If we plug in two ordinals, it looks like it will agree with ordinary ordinal exponentiation.  This both disagees with Gonshor's definition (which would imply $\omega^\omega&gt;\exp_\omega \omega$) and is suspect on its own, because we shouldn't expect to get one of the <em>ordinary</em> ordinal operations out of this (we use natural addition and multiplication in the surreals, not ordinary addition and multiplication).  If indeed we get an ordinal operation out of this at all -- it would appear that by Gonshor's definition, $\omega^\omega$ would not even be an ordinal, instead being equal to $\exp_\omega \exp_\omega (1+1/\omega)$.</p>

<p><strong>Oops</strong>: Sorry, that shouldn't be ordinary exponentiation, but rather the analogue of it based on natural multiplication.  Regardless, still disagrees, still smells bad.</p>
",logic
"<p>This is problem 15.3 in Arnie Miller's <a href=""http://www.math.wisc.edu/~miller/res/problems.pdf"" rel=""nofollow"">problem list</a>: </p>

<p>(Juhasz) Suppose there exists $\langle A_{\alpha} : \alpha \in L \rangle$, where $L$ is the set of limit ordinals below $\omega_1$ and for each $\alpha \in L$, $A_{\alpha}$ is an unbounded subset of $\alpha$, satisfying: For every unbounded $A \subseteq \omega_1$, there exists $\alpha \in L$, $A_{\alpha} \subseteq A$. Must there exists a Suslin tree?</p>

<p>What is the current status of this problem? Thanks!</p>
",logic
"<p><strong>Definitions:</strong></p>

<p>A set $X$ is <em>of PA degree relative to a set $Y$</em> if every infinite $Y$-computable binary tree has an infinite $X$-computable path.
A set $X$ is <em>low</em> if $X'$ is computable from $\emptyset'$.</p>

<p><strong>Easy facts:</strong></p>

<p>By the relativized Low basis theorem and using the fact that a low relative to a low is still low, $\emptyset'$ is of PA degree relative to every low set.
Of course, if $\emptyset'$ is of PA degree relative to a set $X$, then $X$ is $\emptyset'$-computable.</p>

<p><strong>Question:</strong></p>

<blockquote>
  <p>Are there non-low set $Y$ such that $0'$ is of PA degree relative to $Y$ ?</p>
</blockquote>
",logic
"<p>Define a <em>growth function</em> to be a monotone increasing function $F: {\bf N} \to {\bf N}$, thus for instance $n \mapsto n^2$, $n \mapsto 2^n$, $n \mapsto 2^{2^n}$ are examples of growth functions.  Let's say that one growth function $F$ <em>dominates</em> another $G$ if one has $F(n) \geq G(n)$ for all $n$.  (One could instead ask for <em>eventual domination</em>, in which one works with sufficiently large $n$ only, or <em>asymptotic domination</em>, in which one allows a multiplicative constant $C$, but it seems the answers to the questions below are basically the same in both cases, so I'll stick with the simpler formulation.)  </p>

<p>Let's call a collection ${\mathcal F}$ of growth functions <strike>complete</strike> <em>cofinal</em> if every growth function is dominated by at least one growth function in ${\mathcal F}$.  </p>

<p>Cantor's diagonalisation argument tells us that a cofinal set of growth functions cannot be countable.  On the other hand, the set of all growth functions has the cardinality of the continuum.  So, on the continuum hypothesis, a cofinal set of growth functions must necessarily have the cardinality of the continuum.</p>

<p>My first question is: what happens without the continuum hypothesis?  Is it possible to have a cofinal set of growth functions of intermediate cardinality?</p>

<p>My second question is more vague: is there some simpler way to view the poset of growth functions under domination (or asymptotic domination) that makes it easier to answer questions like this?  Ideally I would like to ""control"" this poset in some sense by some other, better understood object (e.g. the first uncountable ordinal, the nonstandard natural numbers, or the Stone-Cech compactification of the natural numbers).</p>

<p>EDIT: notation updated in view of responses.</p>
",logic
"<p>In Bonn, we've been have a discussion on the topic in the title: </p>

<blockquote>
  <p>Suppose that A and B is are classes and that there are injections from A to B and fom B to A. Does it follow that there is a bijection between A and B?</p>
</blockquote>

<p>Example: Let A the class of sets of cardinality one and let B be the class of sets of cardinality two. There is an injection </p>

<p>A -> B sending a to {a, emptyset},</p>

<p>B-> A sending b to {{b}}.</p>

<p>Does it follow that there is a bijection between A and B?</p>
",logic
"<p>During the past days, I asked some questions in order to gain a clear understanding of the notion of ""free algebras"".  I suppose that the question below is the most clear image of the   concept I have in my mind:</p>

<p>Let $\mathcal{L}$ be an algebraic language. A negated identity in $\mathcal{L}$ is a formula of the form
$$
\forall x_1 \ldots \forall x_n: p(x_1, \ldots, x_n)\neq q(x_1, \ldots, x_n),
$$
where $p$ and $q$ are terms in $\mathcal{L}$. For an algebra $A$ of type $\mathcal{L}$ assume that $id^+(A)$ and $id^-(A)$ are the set of all identities and negated identities valied in $A$, respectively. 
As we know 
$$
Var(A)=Mod(id^+(A))
$$
is the variety generated by $A$ and during the questions</p>

<ol>
<li><p><a href=""http://mathoverflow.net/questions/153743/relatively-free-algebras-in-a-variety-generated-by-a-single-algebra"">Relatively free algebras in a variety generated by a single algebra</a></p></li>
<li><p><a href=""http://mathoverflow.net/questions/153883/relatively-free-groups-in-vars-3"">relatively free groups in $Var(S_3)$</a></p></li>
</ol>

<p>we tried to understand the relative free algebras in $Var(A)$. Now, suppose 
$$
Var^-(A)=Mod(id^-(A)).
$$
It is easy to see that $Var^-(A)$ is $\{ S, P\}$-closed and so it is a pre-variety. Hence, for any set $X$, there exists a free algebra $F_{Var^-(A)}(X)$ in this pre-variety. Now, we ask: </p>

<ol>
<li><p>How we can determine the structure of $F_{Var^-(A)}(X)$? I mean an answer like polynomial functions given by Anton Klaychko or the extendblity  criterion given by Benjamin Steinberg in my previous question.</p></li>
<li><p>Can we characterize $Var^-(A)$ using class operators? I mean some thing like HSP. </p></li>
</ol>

<p>P.S. To answer the question $F_{Var^-(A)}(X)=$?, one should determine the set of all identities with variables from $X$ which are logical consequence of the set $id^-(A)$. More precisely, suppose 
$$
R(X)=\{ (p, q):\ id^-(A)\vDash p=q\}.
$$
Then we have $F_{Var^-(A)}(X)=T_{\mathcal{L}}(X)/R(X)$, where $T_{\mathcal{L}}(X)$ is the term algebra. So, to answer the first question, one should say that: which identities are logical consequences of  given negated identities. For example, suppose $\mathcal{L}=(0,1, +, -, \times)$. Is it possible to determine all non-trivial identities which can be deduce from the negated identity
$$
\forall x \forall y: x^2+y^2\neq-1?
$$
Honestly, I have no even one example of non-trivial identity deducible from the above negated identity.</p>
",logic
"<p>Let $B$ be a complete Boolean algebra. Jech defines a Boolean-valued model $\mathfrak{A}$ of the language of set theory to consist of a Boolean universe $A$ and functions of two variables with values in $B$,
$\qquad \qquad \| x=y \|, \qquad \| x \in y \|$</p>

<p>that safisfy the following:</p>

<p>$ (i)\  \ \ \| x=x \| = 1 \\
(ii) \ \ \| x=y \| = \|y = x \| \\
(iii)\  \| x=y \| \cdot \| y=z \| \leq \| x=z \| \\
(iv) \ \ \| x\in y \| \cdot \|v=x \| \cdot \|w=y \| \leq \|v \in w \|  $</p>

<p>For every formula $\phi(a_1,\ldots,a_n)$, we define the Boolean value $\| \phi(a_1,\ldots,a_n) \|$ of $\phi$ as follows: </p>

<p>$(a)$ For atomic formulas, we have the functions $\| x=y \|, \| x \in y \| $</p>

<p>$(b)$ If $\phi$ is negation, disjunction, $\exists x \, \psi$,</p>

<p>$\qquad \| \lnot \phi(a_1,\ldots,a_n) \| = - \| \phi(a_1,\ldots,a_n) \| $</p>

<p>$\qquad \| (\phi \vee \psi)(a_1,\ldots,a_n) \| = \| \phi(a_1,\ldots,a_n) \| + \| \psi (a_1,\ldots,a_n) \|$</p>

<p>$\qquad \| \exists x \, \psi(x,a_1,\ldots,a_n) \| = \underset{a\in A}{\sum} \| \psi (a,a_1,\ldots,a_n)\|$</p>

<p>Next, Jech says that it's easy to prove </p>

<p>$\qquad \qquad \qquad \| x=y \| \cdot \|\phi(x)\| \leq \|\phi(y)\|$</p>

<p>However, I'm not seeing it. It seems clear that it should be a proof by induction on the complexity of $\phi$, and the inductive step is easy in the case of disjunction and existential, but why does it hold for negation? That is, why is it that if $ \| x=y \| \cdot \|\phi(x)\| \leq \|\phi(y)\|$, then $\| x=y \| \cdot \|\lnot \phi(x)\| \leq \| \lnot \phi(y)\|$?</p>

<p>Thank you!</p>
",logic
"<p>A very soft question, but I hope not out of order here.</p>

<p>In the first edition of Elliott Mendelson's classic <em>Introduction to Mathematical Logic</em> (1964) there is an appendix, giving a version of Schütte's (1951) variation on Gentzen's proof of the consistency of PA. This is intriguing stuff, crisply and quite accessibly presented. The appendix is, however, suppressed in later editions (in fact, from the second onwards), even though there is plenty of room given to other materials and a new appendix</p>

<p>Now, a number of people have said that the appendix is one of the most interesting things about the book. I agree. I too remember being quite excited by it when I first came across it a long time ago!</p>

<p>So: has anyone heard a folkloric story about why Mendelson suppressed the appendix? I've never heard it suggested that there is a problem with the consistency proof as given.</p>

<p>Context, if you are interested: I asked this a couple of weeks ago on math.SE (without getting an answer) when starting to write up a survey of some of the Big Books on Mathematical Logic that will become part of my Teach-Yourself-Logic Guide (mostly for philosophers, though others might be interested), and I'd got to Mendelson. You can get the current version of the Guide by going to <a href=""http://www.logicmatters.net/students/tyl/"">http://www.logicmatters.net/students/tyl/</a></p>
",logic
"<p>If $G\subseteq\omega^{&lt;\omega}$ is a computable clopen game, then $G$ has a winning strategy which is hyperarithmetic $(\Delta^1_1)$, by an inductive ranking process. The key observation here is that the length of this induction is bounded above by the length of the Kleene-Brouwer ordering $G_{KB}$, which is a computable ordinal and hence $&lt;\omega_1^{CK}$, and that each successive stage of the induction can be achieved by one application of the jump operator, so there is a winning strategy with complexity at most $0^{(\vert G_{KB}\vert)}$.</p>

<p>(An annoying subtlety here is that the theory $\Delta^1_1-CA_0$, which amounts to closure under hyperarithmeticity, does <em>not</em> prove determinacy of clopen games, since there are games which are not actually clopen but have no hyperarithmetic witnesses to their ill-foundedness.)</p>

<p>My question is whether a version of this result is also true for open games. Specifically, let $T\subseteq\omega^{&lt;\omega}$ be an open game in which the ""Open"" player (i.e., the player trying to fall off the tree) has a winning strategy; do they necessarily have a winning strategy hyperarithmetic in $T$?</p>

<p>I'm asking this question because I was looking through my notes from a previous class, and I ran across the assertion that ""a similar ranking argument"" shows that the answer is 'yes;' however, I can't reconstruct this argument, and I'm wondering whether I (or the lecturer) was simply incorrect; or whether there's a basic argument I'm not seeing.</p>
",logic
"<p>It is well known that ZFC + ""There is a measurable cardinal"" is equiconsistent with ZFC + ""There is a precipitous ideal on $\omega_1$.""  Is ZFC + ""There is a measurable $\kappa$ such that $2^\kappa &gt; \kappa^+$"" equiconsistent with ZFC + ""There is a precipitous ideal on $\omega_1$"" + CH + $2^{\omega_1}&gt;\omega_2$? </p>
",logic
"<p>Consider a first-order language $L$ and the infinitary language $L(\omega_1,\omega)$ obtained from $L$ by allowing infinite conjonctions and disjonctions. Let $X$ be an infinite set of sentences, including (possibly infinitely many) infinitary formulae and infinitely many finite formulae (let $\Delta$ be an infinite set of finite formulas, $\Delta \subset X$). Let $\mathcal{A}$ be the least admissible set containing $X$ ($X \subset \mathcal{A}$). Is it possible that $\mathcal{A}$ does not contain $\Delta$ as an element? ($\Delta \notin \mathcal{A}$). </p>
",logic
"<p>Let $\mathcal L$ be an <i>infinite</i> signature and $\mathcal A$, $\mathcal B$ two <i>finite</i> $\mathcal L$-structures such that
for each first-order $\mathcal L$-sentence $\varphi$, $$\mathcal A\models\varphi\iff\mathcal B\models\varphi.$$</p>

<blockquote>
  <p>Does it follow that $\mathcal A$ and $\mathcal B$ are isomorphic?</p>
</blockquote>

<p>Clearly, for finite signatures $\mathcal L$ the answer would be ""yes"".</p>
",logic
"<p>A celebrated theorem of Milnor and Kervaire asserts that any finite dimensional division algebra over the real numbers has dimension 1,2,4 or 8. This result is established using methods from algebraic topology, such as K-Theory.</p>

<p>Now  for any given natural number $n$ the existence of such an algebra of dimension $n$ is expressible as an  assertion $\phi_n$ in the first-order language of field theory. Since the theory $RCF$ of real closed fields is complete, it follows from the theorem  above that  $RCF \vdash   \neg \phi_n$ for all $n\not\in$ {1,2,4,8}. Here the universal quantifier on $n$ is in the meta-theory: we might  say that for  each $n$ there is an elementary  proof of $\phi_n$. </p>

<p>Given such a theorem  scheme, one might wonder whether there might be a  uniform elementary proof. Informally this could mean a proof  by induction on the relevant complexity parameter: for example,  $$RCF \vdash  \mbox{ any degree } d  \mbox{  polynomial has at most  }  d  \mbox{ roots}.$$
I would like to imagine that  there  is some first  order-theory  which suitably contains both  RCF and Peano Arithmetic (in particular,  so  as to enable  discussion of  finite sequences of field elements) in which the assertion $$\forall n \;\phi_n\leftrightarrow(n=1 \vee n=2  \vee n=4 \vee  n=8)$$ can  be  legfitimately formalized. Are there standard  constructions for  supporting finite sequences? If so, it should follow from completeness of RCF  that this  assertion  is  equivalent (within such  a larger theory)  to  a sentence $\Phi$ in the language of arithmetic. As noted  above, via difficult results from topology, $\Phi$ is true in the standard model  of  Peano Arithmetic. Consequently, it makes sense to ask whether $\Phi$ is provable within Peano Arithmetic. </p>

<p>Some questions:</p>

<p>(1) Can such a recipe be formalized, and does it reasonably capture the notion of  ""uniform elementary proof"" or  ""purely algebraic"" proof for such theorem schemes? Here I am not necessarily claiming that these conjectural notions are the same.</p>

<p>(2) In the given example of the 1,2,4,8 theorem, do we expect $\Phi$ to be provable in Peano Arithmetic? </p>

<p>Perhaps I have been looking in the wrong places, but all I have managed  to find are a few comments by Kreisel about ""unwinding"", on pages 67-68 of this note: <a href=""http://elib.mi.sanu.ac.rs/files/journals/zr/10/n010p063.pdf"">http://elib.mi.sanu.ac.rs/files/journals/zr/10/n010p063.pdf</a></p>

<p>The situation could be compared with what is known in the special cases of commutative division
algebras (dimensions 1,2) and associative division algebras (dimensions 1,2,4). Hopf's proof of the (1,2) theorem also uses some topology, namely that the $n$-dimensional sphere and $n$-dimensional projective space are not homeomorphic when $n&gt;1$; in fact it suffices to show that a specific map   between these spaces is not a homeomorphism.  Perhaps there is an elementary way to formulate
this consideration?  On the other hand,  there is a different and
""purely algebraic"" proof, via Bezout's Theorem. I don't have the reference at hand,  but it there is a citation  (froom the 1950s, as I recall) in the Springer-Verlag  book Numbers (Ebbinghaus et. al.). I've seen this proof dismissed as unreadable or unenlightening,
but when I examined it years ago it seemed like it might qualify.
The Frobenius proof of the (1,2,4) theorem is quite evidently purely
algebraic, as is the later extension (1,2,4,8) to alternative division
algebras.</p>
",logic
"<p>Hi,</p>

<p>I was wondering how much (if anything) $\mathcal{L}_{PA}$ can express about individual nonstandard elements in a nonstandard model of PA. For instance, presumably it can say that each has $k$-many predecessors, for each $k\in\mathbb{N}$. But:</p>

<p>(a) I can't see that there is any way that the type of one element in a $\mathbb{Z}$-chain differs from the type of any other in that same chain. Is this correct?</p>

<p>(b) Are the types of  elements in separate $\mathbb{Z}$-chains also identical? I mean, clearly they won't be the same as those of elements in the initial segment $\mathbb{N}$ - these will have a finite number of predecessors - but in two of the additional chains?</p>

<p>To me, it looks like these questions are straightforwardly true but I could be wrong. Many thanks,</p>

<p>Kate</p>
",logic
"<p>I've always been curious about the seeming compulsion to found mathematics upon sets, be it ZF(C) or some other system. Of course, there are other approaches these days like category theory and type theory (themselves inextricably linked by the Curry–Howard–Lambek correspondence), but these rather seek an entirely different approach. What I'm really getting at is: why can't we simply deal with (improper) classes? That is, throw away sets as reified mathematical objects and just deal with the classes implicitly defined by predicates in some logical system. Does this indeed make certain areas of mathematics inaccessible? Are there other problems I might not have considered? I would appreciate if someone could enlighten me here in a general way, albeit perhaps also with some specific cases within mathematical subfields.</p>
",logic
"<p>According to the article <i><a href=""http://plato.stanford.edu/entries/logic-higher-order/"" rel=""nofollow"">Second-order and Higher-order Logic
</a></i> from the <a href=""http://plato.stanford.edu/"" rel=""nofollow"">Stanford Encyclopedia of Philosophy</a>,</p>

<blockquote>
  <p>there is no need to stop at second-order logic; one can keep going. [...] we can allow quantification over super-predicate symbols. And then we can keep going further.</p>
  
  <p>We reach the level of type theory after ω steps.</p>
</blockquote>

<p>I wonder what the expressive power of ""$\omega$-order logic"" is:</p>

<blockquote>
  <p>Can you give an example of two structures $\mathcal A$, $\mathcal B$ that satisfy the same $\omega$-order sentences but are not isomorphic?</p>
</blockquote>
",logic
"<p>Is the following statement consistent:</p>

<blockquote>
  <p>``<strong>There is no non-trivial c.c.c forcing notion adding a minimal generic real</strong>''?</p>
</blockquote>

<p>The question is related to Prikry's question:  Is it consistent that any non-trivial c.c.c forcing notion adds a Cohen real or a Random real?</p>

<p>See also <a href=""http://mathoverflow.net/questions/149316/a-special-c-c-c-forcing-notion-and-adding-minimal-generic-reals"">A special c.c.c forcing notion and adding minimal generic reals</a> where it is shown that the answer to the above question is no, if we assume $CH$ or $MA+\neg CH$ (this follows from the results of Judah-Shelah in <a href=""http://projecteuclid.org/euclid.jsl/1183743725"" rel=""nofollow"">Forcing Minimal Degree of Constructibility</a>) Also it is clear that, a model for Prikry's question is also a model for the above mentioned question.</p>

<p><strong>Remark.</strong> By a theorem of Shelah, a modified version of Prikry’s conjecture holds in the
context of Souslin c.c.c forcing: i.e. every Souslin c.c.c forcing either adds a
Cohen real or is a Maharam algebra. Indeed, Shelah showed that any Souslin
c.c.c forcing which is not $ω^ω$-bounding adds a Cohen real. See</p>

<p>S. Shelah, How special are Cohen and random forcing. Israel Journal
of Math. 88 (1-3), pp. 159-174, (1994).</p>
",logic
"<p>My question is about terminology:</p>

<p>Do you know why stationary sets were named such?</p>

<p>Going over the <a href=""http://mathoverflow.net/questions/37502/what-is-the-idea-behind-stationary-sets"">following MO question</a> about the intuition behind stationary sets, the only compelling argument I can think of is Fodor's lemma. </p>

<p>Is this the reason?</p>
",logic
"<p>Is it consistent that there is no $\omega_2$-saturated ideal on $\omega_1$, but one is introduced by an $\omega_2$-closed forcing?</p>

<p><strong>Some motivation:</strong></p>

<p>If $\delta$ is a Woodin cardinal, then it remains so after any $\delta$-closed forcing.  It is a theorem of Woodin and Shelah that if $\delta$ is Woodin and $G \subseteq Col(\omega_1,&lt;\delta)$ is generic, then in $V[G]$ there is a saturated ideal on $\omega_1$.</p>

<p>Jech and Prikry showed that if CH holds and there is a saturated ideal on $\omega_1$, then $2^{\omega_1} = \omega_2$.  Thus if $\delta$ is inaccessible and $G \times H \subseteq Col(\omega_1,&lt;\delta) \times Add(\omega_1,\delta^+)$ is generic, then $V[G][H]$ has no saturated ideals on $\omega_1$.</p>

<p>But if $K \subseteq Col(\delta,\delta^+)$ is generic, then $V[K] \models Col(\omega_1,&lt;\delta) \times Add(\omega_1,(\delta^+)^V) \cong Col(\omega_1,&lt;\delta)$.  Thus if $G,H,K$ are mutually generic, then $V[G][H][K]$ has a saturated ideal on $\omega_1$.</p>

<p>By the $\delta$-c.c., $Col(\delta,\delta^+)^V$ remains $\delta$-distributive in $V[G][H]$.  So we can force over $V[G][H]$ to add a saturated ideal on $\omega_1$ without adding subsets of $\omega_1$.  But the question was whether we can do this with a $\delta$-closed forcing.</p>
",logic
"<p>Is it conceivable that <a href=""http://en.wikipedia.org/wiki/Union-closed_sets_conjecture"">Frankl's union closed sets conjecture</a> is undecidable in $\mathsf{ZFC}$, or is this quite implausible, perhaps due to the ""finitistic"" nature of the statement, or for some other reason?</p>
",logic
"<p>For a poset $P$ there exists an embedding $y$ into a complete and cocomplet poset $\hat{P}$ of downward closed subsets of $P$. It is easy to verify that the embedding preserves all existing limits and no non-trivial colimits --- i.e. colimits are freely generated. $\hat{P}$ may be equally described as the poset of all monotonic functions from $P^{op}$ to $2$, where $2$ is the two-valued boolean algebra. Then we see, that $P$ is nothing more than a $2$-enriched category, $2^{P^{op}}$ the $2$-enriched category of presheaves over $P$ and that $y$ is just the Yoneda functor for $2$-enriched categories.</p>

<p>However, for a poset $P$ there is also a completion that preserves both limits and colimits --- namely --- Dedekind-MacNeille completion <a href=""http://planetmath.org/macneillecompletion"">link text</a>, embedding $P$ into the poset of up-down-subsets of $P$.</p>

<p>Is it possible to carry the later construction to the categorical setting and reach something like a limit and colimit preserving embedding for any category $\mathbb{C}$ into a complete and cocomplete category? </p>
",logic
"<p>I'm going to define an exponential polynomial of degree $k$ as a function $f$ of the form</p>

<p>$f(x) = \sum_{i=1}^k c_ie^{\alpha_ix}$ ($\alpha_i$s real).</p>

<p>My first question is: is there an algorithm for counting the number of real roots of such an expression, with complexity depending only on the degree $k$?</p>

<p>I strongly suspect that the answer to this question is yes, and that the answer is known (seeing as Tarski's exponential function problem is all but solved), but I can't find it described anywhere.</p>

<p>My second question is: can somebody tell me what this algorithm is? Or give me a hint?</p>

<p>I vaguely remember reading somewhere that there was a known method analogous to the method of Sturm chains for polynomials... But I haven't been able to figure out what it should be, nor have I been able to find where I read that claim. My best guess is that we can get rid of terms of such an expression by first dividing $f$ by an exponential $e^{\alpha x}$ to make a term constant, differentiating, and then multiplying by that same exponential. If we call this operation $D_{\alpha}$, we get
$D_{\alpha}f(x) = \sum_{i=1}^k c_i(\alpha_i-\alpha)e^{\alpha_ix}$.
The nice thing is that $D_{\alpha}f$ acts analogously to the derivative of $f$, i.e. between any consecutive zeroes of $f$ there is a zero of $D_{\alpha}f$. The problem is that I can't think of a good analogue to the division algorithm for exponential polynomials (maybe we don't need one?).</p>

<p><strong>Edit:</strong> When I say that Tarski's exponential function problem is ""all but solved,"" I mean that all that is missing from the full solution is a proof of Schanuel's conjecture. I'm not saying that Schanuel's conjecture is easy, but given this result it seems to me that we should be able to describe some sort of explicit algorithm for deciding problems like this one, although the proof of correctness of such an algorithm might require us to assume Schanuel's conjecture holds.</p>
",logic
"<p>A set $X$ is called <em>cohesive for $(R_i)_{i\in \mathbb{N}}$</em> if it is infinite and for each $i$ we have $X\subseteq^* R_i$ or $X\subseteq^* \overline{R_i}$. (Where $X\subseteq^*Y$ means that $X$ is contained in $Y$ up to finitely many exceptions.)</p>

<p>A set $X$ is called <em>cohesive</em> if it is cohesive for all computable enumerable sets.</p>

<p>Further, a set $X$ is called <em>1-generic</em> if for each computably enumerable set $S\subseteq 2^{&lt;\mathbb{N}}$ of strings there is an initial segment of $\sigma$ of $X$ such that either $\sigma \in S$ or $\sigma \not\subseteq \tau$ for all $\tau \in \sigma$.</p>

<p>Both notions are well studies in computability theory. However, I was not able to find a answer to the following question in the literature:</p>

<p>Is (Turing) below each cohesive set a 1-generic set?</p>

<hr>

<p>To give some background on the question:
The reverse of the above question is known to be false. That is there is a 1-generic which has no cohesive set below it.
For the proof one has to note that there are low 1-generic sets but no low cohesive sets. (See <a href=""http://onlinelibrary.wiley.com/doi/10.1002/malq.19930390153/abstract"" rel=""nofollow"">Jockush, Stephan: A cohesive set which is not high</a>).</p>

<p>Moreover it is known that below each cohesive set is a <strong>weakly</strong> 1-generic. (A set $X$ is weakly 1-generic if for each dense c.e. set $S$ there is an inital segment $\sigma$ of $X$ with $\sigma\in S$.)</p>
",logic
"<p>Consider Grzegorczyk's concatenation theory $\operatorname{TC}$, a ""weak theory of words over the two letter alphabet $\Sigma=\{a,b\}$"" (this from Grzegorczyk and Zdanowski's paper <em>Undecidability and Concatenation</em>, pp.72-91 in <em>Andrzej Mostowski and Foundational Studies</em>, A. Ehrenfeucht, V.W. Marek, M. Srebrny (eds.)).</p>

<ul>
<li><strong>TC1:</strong> $x{\frown}(y\frown z)=(x\frown y)\frown z$</li>
<li><strong>TC2:</strong> $x{\frown}y=z{\frown}w \Rightarrow \\ ((x=z \land y=w) \lor \exists u((x{\frown}u=z \land y=u{\frown}w) \lor (x=z{\frown}u \land u{\frown}y=w))$</li>
<li><strong>TC3:</strong> $\lnot (\alpha =x \frown y)$</li>
<li><p><strong>TC4:</strong> $\lnot (\beta =x \frown y)$</p></li>
<li><p><strong>TC5:</strong> $\lnot (\alpha = \beta )$, </p></li>
</ul>

<p>(where in TC3-5 $\alpha$ and $\beta$ denote the one letter words $a$ and $b$ respectively).</p>

<p>It should be noted that in the aforementioned paper Grzegorczyk and Zdanowski prove $\operatorname{TC}$ essentially undecidable, however, they also note that $\operatorname{TC}$ without $\operatorname{TC5}$ has a decidable extension, e.g., from p.85 of the article:</p>

<blockquote>
  <p>Indeed, if we drop TC5 then we can interpret all axioms in the model for arithmetic without zero $(\omega \setminus \{0\}, +, 1,1)$.  By Presburger['s] theorem this model has a decidable theory.</p>
</blockquote>

<p>Suppose now that one drops TC5 and adds the following axiom introducing the notion of <em>subtext</em> $x \lt y$,  i.e. '$x$ is a subtext of $y$':</p>

<ul>
<li><strong>TC5a:</strong>  $x \lt y \Longleftrightarrow y=x \lor (\exists z,w )(x=y \frown z  \lor x=z \frown y \lor x=z \frown y \frown w)$</li>
</ul>

<hr>

<ul>
<li><p><strong>Question 1:</strong>  Is this new theory also decidable?</p></li>
<li><p><strong>Question 2:</strong>  Is this theory also consistent?</p></li>
<li><p><strong>Question 3:</strong>  If this theory is consistent, can the primitive recursive functions (appropriately recast in the language of concatenation) be consistently added? Can the first-order predicate calculus with only bounded numerical quantification be consistently added as well?</p></li>
<li><p><strong>Question 4.</strong> How much of 'contentual number theory' does the resulting theory capture?</p></li>
</ul>

<p>(It should be noted that semantical (i.e. model theoretic) methods can be used here, much as Hilbert and Bernays did in the <em>Grundlagen</em>, vol I,ch. 2, ""Elementary Number Theory--Finitistic Inference and its Limits.) </p>
",logic
"<p>It's well known that the numbers of the form $n!\pm1$ are not always prime. Indeed, <a href=""http://en.wikipedia.org/wiki/Wilson%27s_theorem"">Wilson's Theorem</a> guarantees that $(p-2)!-1$ and $(p-1)!+1$ are composite for every prime number $p &gt; 5$. </p>

<blockquote>
  <p>Is there a proof, preferably an elementary proof, that there are infinitely many composite <em>pairs</em> of the form $n!\pm1$?</p>
</blockquote>

<p>The motivation for this question comes from my answer to <a href=""http://mathoverflow.net/questions/30064/are-the-types-of-nonstandard-natural-numbers-within-a-z-chain-identical"">this recent question</a>. There, I show that every nonstandard model of Peano Arithmetic has a $\mathbb{Z}$-chain consisting entirely of composite numbers. The example I gave is that of a $\mathbb{Z}$-chain contained in the infinite interval $[N!+2,N!+N]$, where $N$ is any nonstandard natural number. I wonder if I could have picked some $\mathbb{Z}$-chain centered at $N!$ instead. A positive answer to the above question would mean that this is indeed possible. Note that it is important in this context that the proof is elementary, but I will also accept beautiful analytic arguments.</p>

<p>Andrey Rekalo pointed out that $(N!)^3 \pm 1$ are both composite. This means that, if $N$ is a nonstandard integer, then the $\mathbb{Z}$-chain centered at $(N!)^3$ has only composite numbers all but two have standard factors. I don't know if it's possible to find a $\mathbb{Z}$-chain all of whose elements have a standard factor.</p>
",logic
"<p>In the literature, one sometimes sees the claim that finitely presented quandles (in particular, knot quandles) are ""hard to deal with"". Hence, a great deal of effort has gone into studying finite quandles and counting homomorphisms onto them, and so on. However, I have not yet come across any theorems that state formal undecidability results for finitely presented quandles similar to those for finitely presented groups. In fact, I have yet to see any formulation of such problems. (For instance, a theorem stating that the isomorphism problem is undecidable for finitely presented quandles.)</p>

<p>Do such results exist in the literature and, if so, could someone please provide references?</p>

<p>(Asked previously <a href=""http://math.stackexchange.com/questions/59285/formally-undecidable-problems-on-finitely-presented-quandles"">here</a> on math.stackexchange, without response.)</p>
",logic
"<p>Consider two ultrafilters, $U$ and $V$, on the same cardinal $\kappa$. Let $D(U, V)=\lbrace X\subseteq \kappa: X\in U-V\rbrace$; clearly $D(U, V)$ is a lattice under $\subseteq, \cap, \cup $ since the intersection of two $U$- or $V$-large sets is $U$- or $V$-large, and the union of two $U$- or $V$-small sets is $U$- or $V$-small; by the same reasoning, $D(U, V)$ is a $\lambda$-complete lattice, where $\lambda$ is the minimum of the completeness of $U$ and the completeness of $V$. </p>

<p>My general question is, does this lattice have any interesting properties?</p>

<p>In particular, I'm interested in the following: let $M\models ZFC^-$, let $U\in M$ be a countably complete ultrafilter on some $M$-measurable cardinal $\kappa$, and let $j: M\rightarrow \prod M/U$ be the elementary embedding of $M$ into the ultrapower via $U$. Let $V=\lbrace X\in\wp^M(\kappa): \kappa\in j(X)\rbrace$; then $V\in M$ and $V$ is a normal ultrafilter on $\kappa$. In particular, if $U$ is not normal, then $U\not=V$. Intuitively, however, the difference between $U$ and $V$ is ""small"" (to be fair, this ""intuition"" may just be a figment of my not understanding inner model theory); is this somehow reflected by the lattice $D(U, V)$? In general, can anything about the relationship between $U$ and $V$ be read off of the lattice $D(U, V)$?</p>

<p>(Also, is this notion studied somewhere? I've googled around, unsuccessfully.)</p>

<p>EDIT: to clarify, I'm most interested in properties which can be determined from the isomorphism type of the lattice $D(U, V)$ alone.</p>

<p>Thanks in advance; hopefully this isn't too open-ended.</p>
",logic
"<p>First, a rather broad question: has there been any work on what, given a model $M$ of set theory, we can say about those models of set theory $N$ and posets $\mathbb{P}$ such that $\mathbb{P}\in N$ and $M=N[G]$ for some $G$ $\mathbb{P}$-generic over $N$?</p>

<p>Second, a more specific question. Let a poset $\mathbb{P}$ be $detectable$ if there is some sentence $\phi_\mathbb{P}$ in the language of set theory + a constant denoting $\mathbb{P}$ such that for all $M$ with $\mathbb{P}\in M$, we have $(M, \mathbb{P})\models\phi\iff M=N[G]$ for some model $N$ with $\mathbb{P}\in N$ and $G$ $\mathbb{P}$-generic over $N$. What posets are detectable? [Answered in the comments by Amit Kumar Gupta.]</p>

<p>Finally, an incredibly general question. Let $M$ be a model of $ZFC$, $\mathcal{C}$ a class of posets in $M$. Say $\mathcal{C}$ is $consistent$ if there is some elementary extension $N$ of $M$ such that, for all $\mathbb{P}\in \mathcal{C}$, there is some $N_\mathbb{P}\models ZFC$ with $\mathbb{P}\in N_\mathbb{P}$ and some $G$ $\mathbb{P}$-generic over $N_\mathbb{P}$ such that $N=N_\mathbb{P}[G]$. What are the consistent classes like? Can we say anything interesting about them?</p>

<p>I'm not sure if these questions are meaningful, or - even assuming they are - if they are interesting. Basically, what I'm interested in is the notion of inverse forcing - similar in an aesthetic sense, at least to me, to inverse Galois theory - and I haven't run into anything along these lines yet.</p>
",logic
"<p>I'm sure this is just my google-fu failing me, but: what are sufficient, non-overkill large cardinal axioms which guarantee ""Every (boldface) $\Pi^1_n$ set of (real codes for) countable ordinals contains or is disjoint from a club subset of $\omega_1$""? (I asked this question on math.stackexchange a couple weeks ago <a href=""http://math.stackexchange.com/questions/1539202/clubbiness-of-pi1-n-sets"">http://math.stackexchange.com/questions/1539202/clubbiness-of-pi1-n-sets</a>, and received some attention but no answer.)</p>

<p>To clarify, I'm asking about the strength <em>over ZFC</em>.</p>

<p>Here's a very silly upper bound: suppose $L(\mathbb{R})$ is a model of AD, and moreover every $\Pi^1_n$-sentence with real parameters is absolute between $L(\mathbb{R})$ and $V$ (actually, I think this is already a consequence of ""$L(\mathbb{R})\models AD$,"" but I'm not sure). Then let $A\in V$ be a $\Pi^1_n$-set of countable ordinals, via the formula (with real parameters) $\varphi$. By the absoluteness assumption, $\varphi^{L(\mathbb{R})}=A$, so $A\in L(\mathbb{R})$. And since $L(\mathbb{R})\models AD$, $L(\mathbb{R})$ thinks $A$ contains or is disjoint from a club. But inner models compute club-ness correctly, so we're done.</p>

<p>This seems massively overkill to me, though - what is the <em>right</em> bound?</p>
",logic
"<p>Frequently it is useful do deal with countable transitive models M of ZFC, for example in forcing constructions.  </p>

<p>The notion of being an ordinal is absolute for any transitive model, so certainly if ($\alpha$ is an ordinal)<sup>M</sup> then also $\alpha$ is an ordinal.  For the same reason, M will contain successors of every ordinal in it. </p>

<p>On the other hand, if M is countable then M cannot contain every countable ordinal; there must be a least (countable) ordinal not in M. </p>

<p>Can anything be said about this ordinal? Does it have any special significance?</p>
",logic
"<p>As I understand it, there is a program in set theory to produce an ultimate, canonical model of set theory which, among other things, positively answers the Continuum Hypothesis and various questions about large cardinals.  My question is about the motivation of such a program.  I'll present some of the thoughts that motivate my question and then state my question more precisely at the end.</p>

<p>Naively, one would think that a good first order theory for some subject ought to be able to decide any first-order expressible question about that subject.  Given certain reasonable restrictions on what ""good"" must entail, this is impossible, due to Godel.  Still, there is a sense that even though a good theory cannot answer every first order question, it should answer a reasonable subset of them.  Further still, there is a sense that for any given subject, there are certain first order propositions that a good theory should not only decide, but decide to be true.</p>

<p>What I just said may sound vague, so in the next two paragraphs I'll add examples of things I personally ought to be true or decidable in a good theory.  The point of these examples is simply to provide background and motivation to the question, and clarify any vagueness, the actual content of those paragraphs is just my opinion and not the real point of the question I'm asking here.</p>

<p><b>Things that ought to be true</b><br>
<a href=""http://en.wikipedia.org/wiki/Robinson_arithmetic"">Robinson Arithmetic</a> doesn't decide induction, but induction ought to hold in any good theory of numbers.  Replacement and Foundation aren't decided by Zermelo set theory, but they ought to hold in any decent theory of sets, even if it took decades for these axioms to join the rest of Zermelo's axioms.  Now there may be interesting theories extending Robinson Arithmetic in which induction fails, and interesting theories extending Zermelo set theory in which Replacement or Foundation fail, but these aren't good theories of numbers or sets, respectively.  Now I cannot prove induction or Replacement, and I may not be able to convince the extreme skeptic that my beliefs are nothing more than the result of cultural bias and upbringing.  Nonetheless, I can confidently assert that induction is true amd Replacement holds.  And even if I were tempted to prove these claims based on some more fundamental assumptions, the skeptic could just as well question those assumptions, and this leads to infinite regress.</p>

<p><b>Things that ought to be decidable</b><br>
A good theory of numbers ought to decide Goldbach's Conjecture.  A good theory of sets probably ought to decide CH and the existence of various large cardinals.  Again, I can't prove these claims, I'm simply making normative claims about what ought to be true of a theory if it is to be regarded as good.  On the other hand, a good theory need not decide its own consistency.  Excessively contrived formulas need not be decidable by a good theory either (e.g. formulas constructed simply to prove a certain theory is incomplete).</p>

<p><b>Main Question</b><br>
I feel that CH and the existence or non-existence of large cardinals should be decidable in a good set theory, or in the same vein, if there are to be some canonical models of set theory, they should all decide these questions the same way.  </p>

<p><i>But various prominent set theorists${}^{\dagger}$ believe further that CH should be true and large cardinals should exist in the ""true $V$.""  What are some of the motivations for these beliefs?</i></p>

<p>[EDIT]<br>
Although I feel this question is different from ones that have already been asked here, let me further distinguish my question by adding that I've heard the usual responses such as:  </p>

<ul>
<li>There are models with very nice structural properties in which large cardinals exist</li>
<li>Large cardinal axioms form a surprisingly linear hierarchy</li>
<li>They decide many natural questions</li>
<li>They fit together in a way that gives a nice, coherent picture of the universe</li>
<li>Why not add them?</li>
</ul>

<p>These responses implicitly appear to justify large cardinal axioms on some non-classical, non-platonist notion of truth - some combination of an aesthetic/pragmatic/coherentist theory of truth.  So perhaps I should refine my question to be:</p>

<p><i>What motivates many set theorists to evaluate new axioms by these non-classical standards (or am I way off base)?</i></p>

<p>I should emphasize that I'm not only interested in the justification of these new axioms, but the motivation behind justifying these axioms the way that set theorists appear to justify them, as these axioms seem to be justified in a categorically different way from how Peano's axioms or Zermelo's axioms are justified.
[/EDIT]</p>

<p>${}^{\dagger}$This <a href=""http://en.wikipedia.org/wiki/Large_cardinal#Motivations_and_epistemic_status"">Wikipedia article on Large Cardinals</a> mentions <a href=""http://en.wikipedia.org/wiki/Cabal_%28set_theory%29"">the Cabal</a> for instance.</p>

<p><b>Secondary Question</b><br>
I've made some specific claims about specific statements in specific theories that I feel ought to be true or ought to at least be decidable.  Admittedly I haven't given any general explanations for what sort of things ought to be true, false, decidable, or neither, I've just stated my opinion on a few specific sentences.  I doubt one could give a totally general account distinguishing the class of problems that ought to be decidable from the class of problems that needn't be (e.g. make a categorical distinction between statements ""like"" CH versus statements ""like"" Godel's self-referential sentence).  I don't think it's the type of question amenable to total generalization or formalization.  Nonetheless:</p>

<p><i>Can anyone shed some light on the apparent distinction between questions that a good theory ought to decide and those a good theory needn't decide?</i></p>
",logic
"<p>Background of my question is Martin Gardner's ""unexpected hanging"" paradoxon, which has once again be the subject of an article in a popular-scientific magazin (this time because this year it has been 5 years since Martin Gardner passed away on May 22nd).</p>

<p>The essence of the paradox is whether it is possible to predict that an event will come unexpectedly, despite an inductive proof that that isn't possible.  </p>

<p>What I would like to know is, what the mathematical interpretation of ""expected/unexpected"" is in the context of the paradoxon; specifically whether it is related to probability measures.  </p>
",logic
"<p>Consider the Peano axioms. There exists a model for them (namely, the natural numbers with a ordering relation $&lt;$, binary function $+$, and constant term $0$). Therefore, by the model existence theorem, shouldn't this suffice to prove the consistency of first order arithmetic? Why is Gentzen's proof necessary?</p>
",logic
"<p>Consider the distribution of all formulas of length less then n which define an integer in PA.<br>
So for instance f(7,n)=number of formulas of length less then n which output 7.</p>

<p>Or the number of steps for all halting turing machines with some natural enumeration.<br>
Or consider the cardinality of all finite definable sets in ZFC, with definition of n characters or less.<br>
Or take any turing complete programming language of your choice and enumerate all programs by length and plot the distribution of which number it outputs.</p>

<p>I want to know if anything is known about the character of such types of distributions, f(.,n) as n approaches infinity. Surely some experiments must have been done.
Are there reasons to expect that it will or will not be a Gaussian?  </p>
",logic
"<p>A classical theorem in Integer Programming by Lenstra says that any integer system
$$A x \le b$$ 
can be solved in polynomial time, where $A \in \mathbb{Z}^{m \times n}, x \in \mathbb{Z}^n, b \in \mathbb{Z}^m$. Here we fix the dimension $n$ of the variables to be solved over (it would be NP-complete to solve for $n$ arbitrary).</p>

<p>Viewed under the the lense of logic/computational complexity, this theorem says that any <em>existential</em> statement
$$ \exists x \in \mathbb{Z}^n : \Phi(x)$$
can be decided in polynomial time, where $\Phi$ is a formula in Presburger arithmetic.</p>

<p>By the work of Semenov, we also know that Presburger arithmetic with added precidates, such as ""x is a power of 2"", or ""x is a Fibonacci number"" is <em>decidable</em>.</p>

<p><strong>Question</strong>: For $n$ fixed, can we decide in polynomial time sentences of the form
$$\exists x \in \mathbb{Z}^n : \Psi(x)$$
where $\Psi(x)$ is a Presburger formula, augmented with some the Fibonacci (or Power of 2) predicates?</p>

<p><strong>Example</strong>: Does the following system have a solution?</p>

<p>$$ \begin{cases} 3x_1 + 2x_2 \le 1000 \\ 17x_2 - x_1 \le 5 \\ 2x_1 + 5x_2 \quad \text{is a power of 2} \end{cases} $$</p>
",logic
"<p>consider the following theorem, when $R$ is a commutative ring with a non-zero identity: </p>

<p><strong>A ring $R$ is zero-dimensional if and only if $\mbox{Spec(R)}$ is Hausdorff.</strong></p>

<p>The proof uses the Axiom of Choice. So, I am wondering if this theorem is equivalent to the Axiom of choice or not. </p>
",logic
"<p>When I was reading the paper:
Wang, Hao. ""Notes on a class of tiling problems."" Fundamenta Mathematicae 82.4 (1975): 295-305.
from <a href=""http://matwbn.icm.edu.pl/ksiazki/fm/fm82/fm82119.pdf"" rel=""nofollow"">http://matwbn.icm.edu.pl/ksiazki/fm/fm82/fm82119.pdf</a></p>

<p>I could not reproduce theorem 5.7:</p>

<p>Every solvable set (tilable) has a solution S such that every finite block occurring in S also occurs infinitely often in S:</p>

<p>Proof in the text: 
Given a solution T and the set K of all finite blocks occurring in T, consider the set L of all subsets of K such that a subset A of K belongs to the L if there is a solution covered by A, i.e., in that solution  all occurring finite blocks belong A. The set L is not empty because K belongs to it and it has minimal members. ...</p>

<p>Here's my problem: I could not see why the minimal member exists. There might be a sequence of A1>=A2>=A3>= ... belonging to L but their intersection does not belong to it ... I lacked a proof here... Any idea?</p>
",logic
"<p>[Metastuff: I asked this question in a slightly different way on mathSE last week, and it didn't go anywhere, which is why I am asking here. I added the DST tag because it's basically a problem about Borel equivalence relations stripped of all the Borelness constraints. I do need help, so helpful redirection is appreciated.]</p>

<p>I am trying to give a somewhat constructive definition of a function. It's somewhat constructive because I'll freely assume that I can well-order any set. Aside from that, I want to say what the function looks like.</p>

<p>I have two equivalence relations $E$ and $F$ on spaces $X$ and $Y$, respectively. There are no restrictions on the sizes of anything. I want to define a function $f : X \to Y$ such that
$$ x E y \Leftrightarrow f(x) F f(y)\;\;\;\text{ and }\;\;\;f(x) = f(y) \Rightarrow x = y $$
for all $x,y \in X$. This makes $f$ send all points in an $E$-class to the same $F$-class and also be injective on equivalence classes (i.e., injective as $X/E \to Y/F$) and on the underlying space.</p>

<p>Let $I$ be the class of nonzero cardinals. For every $i \in I$, the number of $F$-classes of size at least $i$ is greater than or equal to the number of $E$-classes of size at least $i$. I want to give a mostly-constructive proof that this is sufficient for there to be a function as described above (from $E$ to $F$), i.e., I want to describe the function.</p>

<p>I have been struggling with this on and off for several weeks. Below are some possible time-savers for you guys. If you already have a solution, you can skip it.</p>

<hr>

<p>The problem is extremely easy in the slightly nicer situation where, for every $i \in I$, the number of $F$-classes of size <strong>exactly</strong> $i$ is greater than or equal to the number of $E$-classes of size <strong>exactly</strong> $i$. Just partition the set of $E$-classes by size and put a well-order on each set in the partition. Do the same for $F$-classes. Then send the $n$th $E$-class of size $i$ to the $n$th $F$-class of size $i$.</p>

<p>The complication for the original case is that you might have to send an $E$-class of size $i$ to an $F$-class of size $j$ with $i &lt; j$. Two problems arise this way.</p>

<p>First, you can't use the larger classes wastefully by sending relatively small classes to them. E.g., if $E$ has solely two classes, one of size $2$ and one of size $5$, and $F$ has solely two classes, one of size $4$ and one of size $6$, you cannot send the class of size $2$ to the class of size $6$. The only way that I can think to avoid this problem is inductively: (i) well-order the classes in some way, (ii) send the least $E$-class to the least $F$-class that is big enough, (iii) remove these, and (iv) repeat from step (ii).</p>

<p>This creates the second problem: how to choose the well-order for step (i). If you try, e.g., to order the classes by increasing size with an arbitrary order among classes of the same size, you run into the following problem (as Brian Scott pointed out to me on mathSE a week ago). Suppose $E$ has $\omega$ many classes of size $1$ and one class of size $2$. Suppose $F$ has one class each of every finite size. Then the above won't work because $F$ has order-type $\omega$, but $E$ has order-type $\omega+1$.</p>

<p>You can fix this case with the same trick that you use to well-order the rationals. Put the $E$-classes of size $i$ into a column and well-order each column. <a href=""http://mathlesstraveled.files.wordpress.com/2007/12/rational-grid-diag-enum.png"" rel=""nofollow"">Then move along the diagonals like so.</a> But it's not clear to me what this looks like when you have any number of columns and rows rather than just countably many. </p>

<hr>

<p><strong>Edit to explain potential solution:</strong> It sounds plausible to me that sending an $E$-class to an $F$-class of the smallest available size that is large enough will avoid fatally wasteful assignments regardless of the order in which you make assignments. E.g., given an $E$-class of size $5$, if $F$-classes of sizes $4,7,$ and $9$ are available, choose one of size $7$.</p>

<p>The problem then is just how to iterate through the $E$-classes. This sounds problematic generally, but my knowledge of ordinals is weak. E.g., is there always some sense in which you can iterate through all the members of an initial ordinal?</p>

<p>Put the $E$-classes into <a href=""http://mathlesstraveled.files.wordpress.com/2007/12/rational-grid-diag-enum.png"" rel=""nofollow"">an array like this one</a> so that an $E$-class has an index <strong>(column,row)</strong>. Let the index $(s,p)$ mean that $s$ is the size of the $E$-class and $p$ is its arbitrarily-assigned position in the column. </p>

<p>Consider the case where you have at most countably many $E$-classes of each size and only countably many possible infinite sizes. That is, $p \in \omega$ and $s \in \omega \times \lbrace 0,1\rbrace$. That is, you have countably many finite sizes (tagged with $0$) and countably many infinite sizes (tagged with $1$). Then you just have two copies of the above array; one for finite sizes and one for infinite sizes. </p>

<p>Separately snake through each of them in the way depicted in the linked picture. For the array of finite sizes, this hits indices in this order: $((1,0),1), ((1,0),2), ((2,0),1), ((1,0),3), \ldots$, where the $0$ indicates that you're in the ""finite"" array. For the array of infinite sizes, this hits the indices in this (analogous) order: $((1,1),1), ((1,1),2), ((2,1),1), ((1,1),3), \ldots$. Here, $(1,1)$ denotes some infinite size such as $\omega$; $(2,1)$ might be $2^\omega$, and so on.</p>

<p>Finally, interleave the two orders that you got from snaking through each array. Most simply, you can take one member from each order at a time. This gives:
$$((1,0),1), ((1,1),1), ((1,0),2), ((1,1),2), ((2,0),1), ((2,1),1), ((1,0),3), \ldots$$</p>

<p>I apologize for the somewhat cumbersome notation, but I hope that the pattern becomes clear.</p>

<p>Incidentally, you won't necessarily have an $E$-class for all of the points in the above arrays. E.g., you might not have any $E$-classes of size $2$. I am assuming the fullest possible case for simplicity, as it still defines a well-order when you remove some of the points.</p>
",logic
"<p>If $_DV_D$ is a $D$-$D$-bimodule, and we have a $D$-basis for $V_D$, do we still need AC to get a $D$-basis for $_DV$?</p>

<p>(The original question appears below.  But this shorter question gets at the heart of my question, and makes it clear it has more logical foundations.)</p>

<hr>

<p>Let $D$ be a division ring and let $_D V_D$ be a $D$-$D$-bimodule.  If we temporarily forget the left module structure, and just look at the right $D$-module structure, we have $V_D= \bigoplus_{i\in I}e_iD$ for some basis $\{e_i\}_{i\in I}$.</p>

<p>It is a well-known fact that $E:={\rm End}(V_D)\cong {\rm CFM}_I(D)$ where ${\rm CFM}_I(D)$ is the ring of $I\times I$ <em>column finite matrices</em>.  These are the matrices where each column has only finitely many nonzero entries.  If we think of the elements of $V_D$ as columns of size $I\times 1$ with only finitely many nonzero entries, then ${\rm CFM}_I(D)$ acts on the left of $V_D$ simply by matrix multiplication.  (Of course, when $|I|=n$ is finite, then ${\rm CFM}_I(D)=\mathbb{M}_n(D)$ is just the usual ring of $n\times n$ matrices.)</p>

<p>So we have a natural bimodule structure on $V$, namely $_{E}V_D$.  Our original bimodule structure $_DV_D$ gives rise to a homomorphism $\varphi:D\to E\cong {\rm CFM}_I(D)$.  Conversely, given any such homomorphism (and a fixed basis for $V_D$ indexed by $I$) we get a $D$-$D$-module structure on $V$.</p>

<p>We could do all of this over again on the other side.  From the <em>left</em> $D$-module structure $_DV$, we can fix a basis $\{f_j\}_{j\in J}$ and corresponding decomposition $_DV=\bigoplus_{j\in J}Df_j$.  The right $D$-module structure then corresponds to a homomorphism $\psi:D\to {\rm RFM}_J(D)$.  (The ring ${\rm RFM}_J(D)$ is the ring of $J\times J$ row finite matrices.)</p>

<p>So given an index set $I$ and a homomorphism $\varphi:D\to {\rm CFM}_I(D)$, there is a corresponding index set $J$ and a homomorphism $\psi:D\to {\rm RFM}_J(D)$.  My question is whether there is a canonical way to describe the correspondence $(I,\varphi)\leftrightarrow(J,\psi)$.  If not a canonical way, given the information $I$ and $\varphi$, can we at least describe $|J|$ and $\psi$ explicitly from that data, after a choice of basis?</p>
",logic
"<p>Let $K$ be a kripke model and $k$ be one of its node, then $\mathcal{M}_k$ is classical structure of $k$.</p>

<blockquote>
  <p>What is the strongest theory of arithmetic like $T$ such that for
  every kripke  model $K\Vdash HA$ and for every nodes of it like $k$,
  $\mathcal{M}_k\models T$?.</p>
</blockquote>

<p>It is not hard to see that $T\vdash I\Delta_0$, because $HA$ proves least number principle for $\Delta_0$ formulas. </p>

<p>I found two paper that partially answered this question:</p>

<p><a href=""http://projecteuclid.org/euclid.ndjfl/1093636765"">Finite Kripke models of HA are locally PA</a></p>

<p><a href=""http://onlinelibrary.wiley.com/doi/10.1002/1521-3870(200204)48:3%3C391::AID-MALQ391%3E3.0.CO;2-T/abstract"">Every Rooted Narrow Tree Kripke Model of HA is Locally PA</a></p>

<p>I want to know is there any other results on this question?
Also can $T$ be a stronger theory than $I\Delta_0$ like $I\Sigma_1$?</p>
",logic
"<p>For each prime $p$, we have the algebraically closed field $\bar{\mathbb F}_p$ with the Frobenius automorphism.</p>

<p>Given any first-order statement with no free variables using the symbols $0,1, +, \times, -, /, \sigma(),=$, we can interpret it in $\bar{\mathbb F}_p$, interpreting the field operations to mean themselves and $\sigma$ to mean Frobenius.</p>

<p>For each prime, it is either true of false. This gives us a set of primes.</p>

<blockquote>
  <p>What sets of primes can be described this way?</p>
</blockquote>

<p>It is easy to pick out the primes whose Frobenius elements have a certain conjugacy class in in a Galois extension of $\mathbb Q$, and to pick out finite sets of primes.</p>

<p>Are there any sets of this type not generated by conjugacy classes in Galois groups and finite sets under the logical operations?</p>
",logic
"<p>Let $L \subseteq A^\star$ be a formal language over $A$ generated by a context-free grammar, and $L' = A^\star - L$ be the relative complement in $A^\star$.</p>

<p>If $L$ and $L'$ are both context-free, are they necessarily deterministic context-free?</p>
",logic
"<p>For Genzen's sequent calculus with PA axioms, why is the proof-theoretic ordinal $\epsilon_0$? This seems to hinge on what exactly it means for the level of a cut or CJ inference figure to be higher than that of a lower sequent, because it is when we encounter such a situation that the complexity represented by the ordinal $\alpha$ is used to denote the new complexity: $\omega^\alpha$ (or $\omega^{\omega^{\omega^\alpha}}$, if the level of the lower line is three lower rather than just one). According to my current understanding, a proof theoretic ordinal of $\omega$ means there are potentially $\omega$ lines in the proof. What is it about eliminating cuts that might lead to proofs with more than $\omega$ lines?</p>
",logic
"<p>I would like a reference and/or a simple proof using well-known results of the following, which I think is true.  (If it's false, I'd like to know that as well of course -- and ideally a way to modify the statement to make it true.)</p>

<hr>

<p>Let $X$ be a compact, connected, semi-algebraic set of dimension $n+1$ inside $\mathbb{R} \times \mathbb{R}^n$, and assume that $X$ contains an open $(n+1)$-dimensional ball centered at the origin.  Define
$$V(t) = \operatorname{Vol}\left(X \cap (\{t\} \times \mathbb{R}^n)\right),$$
where $\operatorname{Vol}$ just means $n$-dimensional Lebesgue measure.  Then $V$ admits a power series expansion
$$V(t) = a_0+a_1t+a_2t^2+\cdots$$
in an open neighborhood of $t=0$.</p>

<p>EDIT: To avoid counterexamples like the one in MattF's comment, let's assume that no line contained in the subspace $\{t=0\}$ is tangent to the boundary of $X$.  This is probably not the best way of phrasing this condition -- I welcome advice here.</p>

<hr>

<p>I'm aware of results of Lion and Rolin which has a similar flavor to this, for subanalytic sets (and with some logs I don't want in the result...).  Based on my very limited knowledge of the subject, I would imagine that a proof would work by induction, and use strongly the cell decomposition of $X$.  In the inductive step, I guess one is integrating the lengths of some line segments, and these are given in terms of roots of polynomials, so you use some results about analyticity of roots of polynomials as a function of the coefficients...  I think I could eventually give a rigorous proof, but this seems like the kind of thing that must be well-known (again, if it's true!) to the right people.  After all, the semi-algebraic category should be easier than the subanalytic one.  The logic tag is because maybe this follows from a general result for o-minimal structures.</p>
",logic
"<p>Recently I'm thinking about question below, but I can not prove or disprove it.</p>

<blockquote>
  <p>Is it true that for every model $M\models I\Delta_0$ there exists a
  model $M'\models PA$ such that $M'$ is end extension of $M$?</p>
</blockquote>

<p>How can this statement be proved or disproved?</p>

<p>Thanks.</p>
",logic
"<p>We consider the ring $\mathbb{C}[e^{\lambda x} \mid \lambda \in \mathbb{C}]$ and the language $L=\{+, \cdot , \frac{d}{dx} , 0, 1\}$. </p>

<p>The ring consists of elements of the form $$\sum_{i=0}^N \alpha_i e^{\lambda_i x}$$ where $\alpha_i , \lambda_i \in \mathbb{C}$. </p>

<p>In the language there is no symbol $e^x$. </p>

<p>When we want to write a formula in the structure $$\left (\mathbb{C}[e^{\lambda x} \mid \lambda \in \mathbb{C}] ; +, \cdot , \frac{d}{dx} , 0, 1\right )$$ can we use the symbol $e^x$ because it is an element of the ring? </p>

<p>Or do we have to define it somehow using the operations of the language? </p>
",logic
"<p>The Kadison-Singer problem is the following statement:
for any $\epsilon &gt;0$, there exists $r\in \mathbb N$ such that
for any bounded operator $A$ on $\ell^2(\mathbb Z)$, there exists a partition $(\mathcal P_s)_{1\le s\le r}$ of $\mathbb Z$, with
$$
\max_{1\le s\le r}\Vert P_s(A-\text{diag}A)P_s\Vert_{\mathcal B(\ell^2(\mathbb Z))}\le \epsilon \Vert A-\text{diag}A\Vert_{\mathcal B(\ell^2(\mathbb Z))}\quad\tag {PC}
$$
where $P_s=\sum_{j\in \mathcal P_s} p_j$ and $p_j$ is the orthogonal projection onto
$e_j=(\delta_{j,k})_{k\in \mathbb Z}$; the point is that $r$ depends only on $\epsilon$. This problem is sometimes quoted as the Kadison-Singer conjecture, a rather inaccurate denomination since these authors were inclined to think that the answer should be negative. We have given here the formulation of the Paving Conjecture, known to be equivalent to KS.
Since (PC) seems to be now solved, I will read the paper and I withdraw my question.</p>
",logic
"<p><strong>Question.</strong> Suppose that $X$ is a Lindelof space such
that every point of $X$ is a $G_{\delta}$-point. Then is it true that $|X| ≤ 2^{\omega}$?</p>
",logic
"<p>Is there a natural, non-trivial example of a TCA (total combinatory algebra, cf. pca) with a natural notion of an oracle? </p>
",logic
"<p>Let $k$ be a commutative ring.  Feel free to assume it's a field.</p>

<p>Let $X$ be a set.  This question is only interesting when $X$ is infinite.</p>

<p>Write $k^X$ for the $k$-algebra of functions $X \to k$, with the algebra operations defined pointwise.</p>

<blockquote>
  <p>What are the $k$-algebra homomorphisms $k^X \to k$?  </p>
</blockquote>

<p>Trivially, for each $x \in X$ there is a projection/evaluation map $k^X \to k$.  </p>

<blockquote>
  <p>Under what circumstances are there any $k$-algebra homomorphisms $k^X \to k$ apart from the projections?</p>
</blockquote>

<p>Here are some observations.  Observation 2 shows that the question is not entirely trivial, in the sense that there <em>are</em> sometimes nontrivial homomorphisms $k^X \to k$.</p>

<ol>
<li><p>When $k$ an integral domain, any homomorphism $\Phi: k^X \to k$ gives rise to an ultrafilter $\mathcal{U}_\Phi$ on $X$.  To see this, write $\chi_S \in k^X$ for the characteristic function of a subset $S \subseteq X$.  Since $\chi_S$ is idempotent, $\Phi(\chi_S)$ is also idempotent, and is therefore either $0$ or $1$.  Write
$$
\mathcal{U}_\Phi
=
\{ S \subseteq X : \Phi(\chi_S) = 1 \}.
$$
It's easy to check that $\mathcal{U}_\Phi$ is an ultrafilter on $X$ &mdash;  <a href=""https://mathoverflow.net/questions/69467/an-ultrafilter-is-a-set-of-subsets-containing-exactly-one-element-of-each-finite/129930"">in other words</a>, that whenever we write $X = X_1 \amalg \cdots \amalg X_n$, there is precisely one $i$ for which $\Phi(\chi_{X_i}) = 1$.</p></li>
<li><p>When $k$ is a <em>finite</em> integral domain &mdash; that is, a finite field &mdash; the $k$-algebra homomorphisms $k^X \to k$ are in bijection with the ultrafilters on $X$.  One direction of this correspondence is given as in (1).  </p>

<p>For the other, start with an ultrafilter $\mathcal{U}$ on $X$.  We want to define a homomorphism $\Phi_{\mathcal{U}}: k^X \to k$, so take $\phi \in k^X$.  Since $k$ is finite, the fibres $(\phi^{-1}(c))_{c \in k}$ form a finite partition of $X$.  So there is precisely one element $c \in k$ such that $\phi^{-1}(c) \in \mathcal{U}$, and we put $\Phi_{\mathcal{U}}(\phi) = c$.  It's straightforward to check that $\Phi_{\mathcal{U}}$ is a homomorphism and that the processes $\mathcal{U} \mapsto \Phi_{\mathcal{U}}$ and $\Phi \mapsto \mathcal{U}_\Phi$ are mutually inverse.</p></li>
<li><p>When $k$ is an integral domain and $X$ (rather than $k$) is finite, the only homomorphisms $k^X \to k$ are the projections.  This follows e.g. from (1) and the fact that ultrafilters on a finite set are principal.</p></li>
<li><p>Denote by $X \cdot k$ the $k$-vector space with basis $X$.  Then $k^X$, as a $k$-vector space, is isomorphic to the space of linear maps $X \cdot k \to k$.  Now any $k$-algebra homomorphism $\Phi: k^X \to k$ is, in particular, a $k$-linear map, so $\Phi$ is an element of the double dual of $X \cdot k$.  Hence there can only be nontrivial homomorphisms $k^X \to k$ if there are nontrivial elements of the double dual of $X \cdot k$.  </p>

<p>So my question seems to be closely related to one that's come up <a href=""https://mathoverflow.net/questions/49388"">a few times</a> <a href=""https://mathoverflow.net/questions/49351"">here before</a>: how much Choice do we need in order to construct nontrivial elements of the double dual of an infinite-dimensional vector space?</p></li>
</ol>
",logic
"<p>It is a somewhat curious phenomenon that, in forcing arguments, one usually doesn't care about any particular properties of the generic filter being used (this isn't strictly true; there are cases where we force below some sort of master condition, for example, but this basically amounts to asking my question for the cone below the condition). This position might possibly be preferred by mathematicians who interpret talking about generic filters as ""semantic sugar"" for purely syntactic arguments about Boolean truth values, but if we are prepared to talk about generics as real objects, it seems weird that we don't pay very much attention to the structure of the objects which generate our extensions.</p>

<p>But perhaps we needn't always care about the particular generic. Let $M$ be a transitive model of set theory. Call a notion of forcing $\mathbb{P}\in M$ <em>forcing agnostic</em> (over $M$) if for any two $M$-generic filters $G,H\subseteq \mathbb{P}$ the two extensions $M[G]$ and $M[H]$ are elementarily equivalent.</p>

<p>There is an obvious reformulation of forcing agnosticism: $\mathbb{P}$ is forcing agnostic iff the Boolean value, with respect to the Boolean algebra associated to $\mathbb{P}$, of any sentence (without parameters in the forcing language) is either 0 or 1. This immediately implies that any almost homogeneous forcing is forcing agnostic; in fact, any two extensions by almost homogeneous forcing are elementarily equivalent in the language augmented with constants for elements of the ground model.</p>

<p>Is there a characterization of forcing agnostic posets? Is this a purely structural property of the poset or does the ambient model matter, i.e. can  a poset be forcing agnostic over some models but not over others?</p>

<p>I would also welcome any examples of forcing arguments where some care is needed in choosing the generic (in addition to ensuring a particular condition gets in).</p>
",logic
"<p>The cardinal equation $\kappa^{\aleph_0}=2^\kappa$ is satisfied by $\kappa=\aleph_0$. </p>

<p>It is also satisfied by any $\kappa$ for which $MA(\kappa)$ holds. </p>

<p>Under $GCH$, the equation is satisfied by $\kappa$ if and only if $cof(\kappa)=\aleph_0$.</p>

<p>So my question is:</p>

<blockquote>
  <p>Is it consistent with $ZFC$ that the
  only solution to
  $\kappa^{\aleph_0}=2^\kappa$ is
  $\kappa=\aleph_0$?</p>
</blockquote>

<p>I´m sorry if this is too basic, but I just don´t see it.</p>
",logic
"<p>Work in the first order language of number theory, consisting of the symbols $\mathbf{0}$, $\mathbf{S}$, $\boldsymbol{+}$, and $\boldsymbol{\cdot}$, and let $Q$ denote Robinson's arithmetic.</p>

<p>By a <em>diophantine formula</em> we mean a formula in this language having the form $\exists y_1 \dots \exists y_m(f(x_1, \dots, x_n, y_1,\dots, y_m) = g(x_1, \dots, x_n, y_1,\dots, y_m))$, where each of $f(x_1, \dots, x_n, y_1,\dots, y_m)$ and $g(x_1, \dots, x_n, y_1,\dots, y_m)$ is a term in this language having the form of a polynomial whose variables are among $x_1, \dots, x_n, y_1, \dots, y_m$, and whose coefficients are terms of the form $\mathbf{S}\mathbf{S} \dots \mathbf{S}\mathbf{0}$.</p>

<p>We of course know (Rosser-Kleene-Mostowski) that there is a $\Sigma_1$-formula $\phi(x)$ with one free variable $x$ such that for every consistent recursively axiomatizable theory $T$ extending $Q$, there is some $n$ such that the sentence $\phi(\mathbf{S}^n\mathbf{0})$ is undecidable in $T$.</p>

<p>Question:  Is there a diophantine formula $\phi(x)$ for which the above will be true (i.e. for every consistent recursively axiomatizable theory $T$ extending $Q$, there is some $n$ such that the sentence $\phi(\mathbf{S}^n\mathbf{0})$ is undecidable in $T$)?</p>

<p>Note that we are only requiring that $T$ be a consistent recursively axiomatizable theory extending $Q$, and so are allowing $T$ to be $\omega$-inconsistent.</p>

<p>An alternative way of asking the same question:  Can some recursively inseparable pair of r.e. sets $A$ and $B$ be ""represented"" in $Q$ by some diophantine formula $\phi(x)$ (so that if $n \in A$ then $Q \vdash \phi(\mathbf{S}^n\mathbf{0})$ and if $n \in B$ then $Q \vdash \neg\phi(\mathbf{S}^n\mathbf{0})$)?</p>
",logic
"<p>I have seen Troelstra's Uniformity Principle stated as:
$\forall x \exists n R(x,n) \rightarrow \exists n \forall x R(x,n)$
where $x$ ranges over $\mathbb{P(N)}$ and $n$ ranges over $\mathbb{N}$.</p>

<p>Unless I'm misunderstanding something, this is obviously false in classical mathematics. For example, take $R$ to be the relation $R(x,n)$ iff $n$ is the smallest element of $x$, or $x$ is the empty set and $n=0$.</p>

<p>What is it about constructive mathematics that makes this counterexample invalid there?</p>

<p>Would the principle be classically valid if $x$ was restricted to recursive sets?</p>

<p>Or am I misunderstanding something?</p>
",logic
"<p>Standard textbooks in mathematical logic will assume an infinite supply of variables. Their axiomatization of first order logic will typically contain an axiom of the form $\forall x\phi_{1}\to\phi_{1}[y/x]$ with varying qualifications on what the term $y$ is allowed to be, along the lines of '$y$ is free for $x$ in $\phi_{1}$'. When the set of variables $V$ is finite, the standard textbook approach creates a problem: the formula $\forall x\forall y(x\in y)\to\forall x(y\in x)$ with $x\neq y$ is not an axiom. In general, this is hardly a problem as the set of variable $V$ will have a spare variable $z\not\in\{x,y\}$ allowing us to show that $\forall x\forall y(x\in y)\to\forall x(y\in x)$ is in fact a theorem. However, when $V=\{x,y\}$ there doesn't seem to be any way to prove the formula and we are left with a valid formula which cannot be proven. So whenever $V$ is a finite set, we can easily believe that excluding the axiom $\forall x\phi_{1}\to\phi_{1}[y/x]$ simply because $y$ is not free for $x$ in $\phi_{1}$ (without any substitute), will create a situation where a perfectly reasonable formula such as $\forall x\forall y(x\in y)\to\forall x(y\in x)$ which should have been an axiom, will fail to be included while not being a theorem, thereby leading to an incomplete axiomatization. Somehow we need a way to specify all axioms $\forall x\phi_{1}\to\phi_{1}[y/x]$ without leaving anyone out. Because $V$ is a finite set, we cannot hope to define a substitution of variable mapping $[y/x]:{\bf P}(V)\to{\bf P}(V)$ simply by using fresh variables which haven't yet been used. We fundamentally need to re-use variables, while avoiding capture. This I believe is the key issue which needs to be resolved so as to offer a sensible axiomatization of FOL with finitely many variables (but I could be wrong about this). So my question is: </p>

<blockquote>
  <p><strong>Question 1</strong>: Can anyone suggest an axiomatization of FOL with $V$ finite which is known to be sound, complete and in which the deduction theorem holds without qualification on closed formulas?</p>
  
  <p><strong>Question 2</strong>: Is there a known reference which deals with this question? (answered by Andres and Francois)</p>
</blockquote>

<p>One may assume no constant or function symbol, and a unique binary predicate $\in$ for the purpose of this post. </p>

<p>My personal approach to defining an <em>essential</em> substitution $[y/x]:{\bf P}(V)\to{\bf P}(V)$ is to create a mapping ${\cal M}:{\bf P}(V)\to{\bf P}(V\oplus\mathbb{N})$ which effectively replaces every bound variable of its argument by an element of a copy of $\mathbb{N}$ which is disjoint from $V$, while avoiding capture. So for example ${\cal M}(\forall x(x\in y))=\forall\,0(0\in y)$ and ${\cal M}(\forall y\forall x(x\in y))=\forall\,1\forall\,0(0\in 1)$ (the '$y$' has been replaced by $1$ instead of $0$ to avoid capture):</p>

<blockquote>
  <p><strong>Minimal Transform of formula:</strong></p>
  
  <p>${\cal M}(\forall x\phi_{1})=\forall n{\cal M}(\phi_{1})[n/x]$</p>
  
  <p>where $n=\min\{\ k\in\mathbb{N} : [k/x]\ \mbox{avoids capture for}\ {\cal M}(\phi_{1})\ \}$.</p>
</blockquote>

<p>Given a map $\sigma:V\to W$, its natural extension $\bar{\sigma}:V\oplus\mathbb{N}\to W\oplus\mathbb{N}$ (defined by $\bar{\sigma}(x)=\sigma(x)$ and $\bar{\sigma}(n)=n$) can act on the formula ${\cal M}(\phi)$ while avoiding capture. So $\bar{\sigma}\circ{\cal M}(\phi)$ is a meaningful formula which is our intended meaning for '$\sigma(\phi)$'. The problem is $\bar{\sigma}\circ{\cal M}(\phi)$ is a formula in ${\bf P}(W\oplus\mathbb{N})$ and not ${\bf P}(W)$. The trick is to show that provided $W$ is an infinite set or has cardinality no less than that of $V$, it is always possible to find a $\psi\in{\bf P}(W)$ such that $\bar{\sigma}\circ{\cal M}(\phi)={\cal M}(\psi)$. This formula $\psi$ is unique modulo $\alpha$-equivalence and is our candidate for $\sigma(\phi)$. I am not claiming to prove anything here, just sketching the ideas of what can be done to define a notion of: </p>

<blockquote>
  <p><strong>Essential substitution</strong> $\sigma:{\bf P}(V)\to{\bf P}(W)$ associated with $\sigma:V\to W$, which is a map satisfying the key equality $\bar{\sigma}\circ{\cal M}={\cal M}\circ\sigma$ and behaves for all intent and purposes as a variable substitution mapping, while avoiding capture at all times. This map is essentially unique and can be re-defined modulo $\alpha$-equivalence while preserving its intended properties.</p>
</blockquote>

<p>In the case when $W=V$ and $\sigma=[y/x]$ the existence of an essential substitution $[y/x]:{\bf P}(V)\to{\bf P}(V)$ is guaranteed and we seemingly have the object we need to finally write down specialization axioms:</p>

<blockquote>
  <p><strong>Specialization scheme:</strong></p>
  
  <p>$\forall x\phi_{1}\to\phi_{1}[y/x]$</p>
  
  <p>where $[y/x]:{\bf P}(V)\to{\bf P}(V)$ is  an essential substitution of $y$ in place of $x$.</p>
</blockquote>

<p>Going back to the case when $V=\{x,y\}$, $x\neq y$ and $\phi_{1}=\forall y(x\in y)$, taking $\sigma=[y/x]$ we see that $\bar{\sigma}\circ{\cal M}(\phi_{1})=\forall\,0(y\in 0)$ and consequently the only possible value for $\sigma(\phi_{1})$ is $\forall x(y\in x)$ and we can rejoice at the fact that $\forall x\forall y(x\in y)\to\forall x(y\in x)$ has now become an axiom. So:</p>

<blockquote>
  <p><strong>Question 3</strong>: Is anyone familiar with any alternative approach to this question of constructing <em>essential</em> substitution mapping $\sigma:{\bf P}(V)\to{\bf P}(W)$ associated with $\sigma:V\to W$ making a complete axiomatization possible?  </p>
</blockquote>

<p>This being said, despite having what I think are the right axioms, I still do not know if it can lead to a complete system (but this is already the object of another post <a href=""http://mathoverflow.net/questions/137485/embedding-of-consistent-subset-still-consistent-in-fol-finitely-many-variables"">Embedding of consistent subset in first order logic (finitely many variables)</a></p>

<p><strong>EDIT:</strong> some of the comments suggest that there is little point in considering finite variable fragments of FOL. After all, a closed formula (which is what we care most about) has only bound variables which are dummy names and do not matter modulo $\alpha$-equivalence. So whether we restrict these dummy names to be part of a finite set, or allow them to be chosen fresh at will, should not make any difference and is purely cosmetic. I completely agree with this of course and I am not suggesting there is anything interesting to be gained by seeing distinctions between dummy names. I perfectly accept that the interesting entities are congruence classes modulo $\alpha$-equivalence. but the fact remains: every formula of FOL needs a minimal number of variables to be expressed modulo $\alpha$-equivalence. The free algebra ${\bf P}(3)$ is the set of set theory statements which can be expressed with $3$ variables or less. There is a fundamental difference between ${\bf P}(0)$, ${\bf P}(1)$, ${\bf P}(2)$, ${\bf P}(3)$ and ${\bf P}(\mathbb{N})$. These are subsets of all statements of set theory which may be interesting in their own rights. In fact, there seems to be results about the classical decision problem being decidable in ${\bf P}(2)$ but not in ${\bf P}(3)$ (I may be saying something silly here, as I haven't yet checked the research, so please forgive me if my claim is inaccurate). Imagine we could code the Riemann Hypothesis in ${\bf P}(157)$ and the decision problem was decidable in ${\bf P}(n)$ for all $n\leq 160$. No one would question the pertinence of ${\bf P}(157)$. Unfortunately, this won't happen it seems...</p>

<p><strong>Monk (1971)</strong> : <a href=""http://www.ams.org/journals/proc/1971-027-02/S0002-9939-1971-0276063-5/S0002-9939-1971-0276063-5.pdf"" rel=""nofollow"">Provability with finitely many variables</a> seems to indicate that no finite scheme of axioms can achieve an axiomatization of FOL which is sound and complete. However, we have to be careful about the signatures involved. Monk assumes a language with equality, and a sequence of predicates with identical arity $n\geq 3$. He also crucially assumes that the number of variables is exactly equal to this common arity $n$. Thus, the question outlined in this post falls outside the scope of Monk's paper (since we have no equality, a single binary predicate and an arbitrary number of variables). So there is still hope that completeness can be achieved with the above specialization scheme (see <a href=""http://mathoverflow.net/questions/137485/embedding-of-consistent-subset-still-consistent-in-fol-finitely-many-variables"">Embedding of consistent subset in first order logic (finitely many variables)</a> for a full description of a possible deductive system involving that scheme). As recommended by Andres and Francois, I will still carefully review the paper and its associated literature.           </p>
",logic
"<p>Consider some arbitrary language $S$ written over a given (propositional) <a href=""https://en.wikipedia.org/wiki/Signature_(logic)"" rel=""nofollow"">signature</a> with a finite collection of <a href=""https://en.wikipedia.org/wiki/Finitary"" rel=""nofollow"">finitary</a> constructors, and consider a procedure that receives as input an arbitrary finite <a href=""https://en.wikipedia.org/wiki/Hilbert_system"" rel=""nofollow"">Hilbert system</a> $H$, that is, a finite number of axioms and inference rules over $S$.  Let $L_H$ be the <strong>logic</strong> inductively defined by $H$ as usual. Let $P_H$ be the <a href=""https://en.wikipedia.org/wiki/Decision_problem"" rel=""nofollow"">problem</a> of ascertaining whether $L_H$ is a decidable logic, that is, deciding about the derivability from $H$ of formulas of $S$.</p>

<p>Is $P_H$ decidable?</p>

<p>(I suspect the answer is negative, and that one could somehow codify the Halting Problem in $P_H$.  Before further investigating the matter, I would be happy though to learn if some literature already exists on this subject.)</p>
",logic
"<p><em>This is a fairly broad question. In particular, I specify 5 questions (Q1, Q2.1, Q2.2, Q3, Q4) which for me all fall under one umbrella. Since this is unreasonably broad, I'm really interested in an answer to any of them; I mention all of them largely to wave around what I think is an interesting umbrella.</em></p>

<hr>

<p>EDIT: I've replaced every instance of the predicate ""$Con$"" (consistency) with ""$Sat$"" (satisfiability); these are of course not equivalent over $RCA_0$, even though they are classically equivalent.</p>

<hr>

<p>Reverse mathematics studies the relative strength of theorems (in the language of second-order arithmetic) over the base theory $RCA_0$ which roughly corresponds to ""computable"" mathematics. A <em>separation</em> in reverse mathematics is a result of the form $$ RCA_0+A\not\models B, $$ where usually $ RCA_0+B\models A$; or equivalently $$Sat(RCA_0+A+\neg B).$$ In light of this latter form, it's easy to find true statements $A$ and $B$ such that $RCA_0+B\models A$ but $Sat(RCA_0+A+\neg B)$ cannot be proven from $RCA_0+Sat(RCA_0 + B)$; that is, the separation result is much harder to prove than the two statements being separated. This is what I mean by a ""hard"" separation.</p>

<p>However, I know of no natural examples of this phenomenon. So my first question is:</p>

<blockquote>
  <p>(Q1) Are there natural theorems $A, B$ such that $Sat(RCA_0+A+\neg B)$ is not known to be provable in the weakest natural (from the point of view of reverse mathematics) axiom system which proves $A+B+Sat(RCA_0+B)$?</p>
</blockquote>

<p>A non-example: the result $WKL_0\not\models RT^2_2$ <em>can</em> be proved in $ACA_0$, which is the weakest natural system above $WKL_0$ which proves the satisfiability of both $WKL_0$ and $RT^2_2$.</p>

<p>The only candidate for a positive answer to (Q1) that I know of is the result (due to Francois Dorais and Jared Corduan; see <a href=""http://arxiv.org/abs/1111.1367"" rel=""nofollow"">http://arxiv.org/abs/1111.1367</a> and <a href=""http://dorais.org/archives/827"" rel=""nofollow"">http://dorais.org/archives/827</a>) separating Weak Ramsey's Theorem and Hyper-Weak Ramsey's Theorem for pairs. The result uses a technique, ""envelope forcing,"" which seems technically complicated enough to require a strong system; however, although I have only glanced at this paper, it seems probable that the proof does in fact go through (perhaps modified) in $ACA_0$ and that $ACA_0$ is the weakest natural system proving Weak Ramsey's Theorem for Pairs and the satisfiability of Weak Ramsey's Theorem for Pairs. (Maybe Francois will weigh in on this?)</p>

<hr>

<p>A similar question exists for $\omega$-models:</p>

<blockquote>
  <p>(Q2.1) Are there natural theorems $A, B$ such that ""$RCA_0+A+\neg B$ has an $\omega$-model"" is not known to be provable in the weakest natural (from the point of view of reverse mathematics) axiom system which proves $A+B+Sat(RCA_0+B)$?</p>
</blockquote>

<p>And a slightly stronger version:</p>

<blockquote>
  <p>(Q2.2) Are there natural theorems $A, B$ such that ""$RCA_0+A+\neg B$ has an $\omega$-model"" is not known to be satisfied in every $\omega$-model of the weakest natural axiom system which proves $A+B$?</p>
</blockquote>

<p>In natural cases, I suspect these are not really different from (Q1), but one never knows.</p>

<hr>

<p>We can also switch all the way from proofs to ""nice"" models. From a computability-theoretic perspective, the fact corresponding to the non-example of $WKL_0$ and $RT^2_2$ is that there is an $\omega$-model of $WKL_0+\neg RT^2_2$ consisting of $\Delta_2^0$ sets. The ""relativized"" version of this observation is that for any set $X\subseteq\omega$, there is an $\omega$-model of $WKL_0+\neg RT^2_2$ containing $X$ and consisting of sets which are all $\Delta^0_2$ in $X$; that is, bounded in any $\omega$-model of $ACA_0$ containing $X$. (Note that this does <em>not</em> automatically imply that every $\omega$-model of $ACA_0$ satisfies ""$WKL_0+\neg RT^2_2$ has an $\omega$-model, although this is true; the obstacle is that in principle these bounded models could be very complicated to describe.) From this perspective, it is natural to ask:</p>

<blockquote>
  <p>(Q3) Are there natural theorems $A, B$, and a natural theory $T$ such that it is not known to be the case that for every $X\subseteq\omega$ and every $\omega$-model $\mathcal{M}$ of $T$ containing $X$, there is a set $Y\in \mathcal{M}$ and an $\omega$-model $\mathcal{N}$ of $A+\neg B$ with each set in $\mathcal{N}$ Turing below $Y$?</p>
</blockquote>

<p>Personally, I think it is this question which is most compelling, but I am biased.</p>

<hr>

<p>Finally, note that there's nothing special about $RCA_0$ here; the same sorts of questions can be asked over any base theory. Some natural base theories (at least for me) include:</p>

<ul>
<li><p>$ZFC$ (or $ZF$), or $ZFC$ ($ZF$) without Replacement, or without Powerset, etc.;</p></li>
<li><p>$KP$ or $KPU$, the theories of admissible sets;</p></li>
<li><p>Any of the theories in Buss' constellation of bounded arithmetic (e.g., $S_2^2$);</p></li>
<li><p>Alternative set theories, such as $NF$.</p></li>
</ul>

<p>So:</p>

<blockquote>
  <p>(Q4) Are there natural separation results over one of these (or some other) base theory which are not known to be provable just using the base theory and the consistency and truth of both statements involved? (And similarly for the analogues of Q2.1, Q2.2, and Q3.)</p>
</blockquote>
",logic
"<p>Any recommendations on the best texts for introducing Model Theory?</p>
",logic
"<p>Weakening the axiom of naive comprehension has not been a popular way of escaping from the set-theoretic paradoxes because no consistent weakenings seem to be particularly well motivated or even to lead to understandable models.  At any rate, that is so of the most famous consistent (well, <i>probably</i> consistent) weakening, New Foundations.  Nonetheless, it could be illuminating to understand the partial order of consistent subtheories of naive set theory.  My question would be: what is known about it?  Unfortunately, however, that question seems ill-posed in that an arbitrary axiom $\psi$ can be coded as comprehension for $(\psi \land x\neq x)\lor (\lnot\psi \land x\notin x)$.  But can anything interesting be said?</p>

<p>Besides NF, I am aware of just one type of set theory that is (almost) naturally thought of as arrived at by admitting only a subset of all possible instances of naive comprehension.  These are the so-called <a href=""http://en.wikipedia.org/wiki/Positive_set_theory"" rel=""nofollow"">positive set theories</a>.  Unfortunately, I know nothing about them except that they admit a universal set (like NF), and they apparently do require some extra axioms that are not naturally expressed as instances of comprehension.  In particular, according to Wikipedia, the theory known as $GPK^{+}_{\infty}$ requires the axiom of infinity, the empty set axiom (!), and an axiom scheme of ""closure"" giving, for each formula $\phi$ with one free variable, the intersection of all the sets that contain every $x$ such that $\phi(x)$.  This seems to me arguably in the spirit of restricting naive comprehension because comprehension is still the main set construction principle, and in particular there is no need for powerset or replacement.  Are there other ""natural"" examples of set theories that can be thought of as arrived at by weakening naive comprehension?  Perhaps ones that <i>don't</i> admit a universal set?</p>

<p>Even non-effective examples (examples where the set of instances of comprehension that is admitted is not computably enumerable) might be interesting.  Also, there might be interesting ways of weakening naive comprehension that are different from simply restricting the allowed instances of the schema.  For instance, maybe some set of disjunctions of instances of naive comprehension is interesting, or maybe it is interesting to consider an axiom that would only guarantee the existence of a set that is in some sense ""close"" to the class of objects satisfying $\phi$.</p>

<p>The context in which this question came up is that I was trying to explain Russell's paradox to someone, and their reaction was, well you should just throw out the instance of the comprehension axiom that leads to paradox.  Of course, throwing out literally that one instance won't restore consistency.  But pointing out a flaw in any particular proposal someone with this attitude toward the paradoxes might propose wouldn't show that some more sophisticated proposal might succeed.  I was hoping for some sort of general argument that, say, proceeding in this way inevitably leads to a system that is either like NF or like positive set theory (if it is not inconsistent or extremely weak).  (What else could be wrong with $x\notin x$ except that it is unstratified or that it involves negation?)  Or at least an argument that you won't get an extension of ZF by any natural weakening procedure would be nice!  Both NF and positive set theory, if I understand the situation aright, could serve as a foundation for mathematics, but both are less intuitive and convenient than ZFC, and it is sort of an article of faith for set theorists that any alternative to ZFC we might ever find is either somehow worse than ZFC or not deeply different from it, yes?</p>
",logic
"<p>What feature(s) must a (non 1st-order) language with proper-class-many formulas have in order to guarantee that:</p>

<p>There is a proper class P of formulas such that both</p>

<p>(a) every set-sized sub-collection of P is satisfiable, and</p>

<p>(b) no proper-class-sized sub-collection of P is satisifable?</p>
",logic
"<p>1-In his article written in German ""Über unerreichbare Kardinalzahlen"" (On inaccessible cardinals), inside Fund. Math. 1938 (pages 68-89), Alfred Tarski states his axioms A and A' as follows.
Axiom A: ""For every set x, there exists a set y satisfying the four following conditions:</p>

<ul>
<li>A1: x is a member element of y;</li>
<li>A2: If z is a member element of y and t is included inside z, then t is a member element of y;</li>
<li>A3: If z is a member element of y and t is  the set having as member elements exactly all sets u included inside z, then t is a member element of y;</li>
<li>A4: If z is included inside y and if the sets z and y are equipotent, then z is a member element of y.""</li>
</ul>

<p>Axiom A':""For every set x, there exists a set y satisfying the four following conditions:</p>

<ul>
<li>A'1: x is included inside y;</li>
<li>A'2: If z is a member element of y and t is a member element of z, then t is a member element of y;</li>
<li>A'3: If z is a member element of y, there exists a set w that is a member element of y such that every set t that is included inside z is a member element of w;</li>
<li>A'4: If z is included inside y and if no set included inside z is equipotent with y, then z is a member element of y.""</li>
</ul>

<p>Tarski asserts, without giving a proof, that axioms A and A' are equivalent.</p>

<blockquote>
  <p>QUESTION 1: Does anyone know about an explicit proof of the equivalance of A and A' ? </p>
</blockquote>
",logic
"<p>The following question is motivated by a result of Magidor that it is consistent that the least strongly compact cardinal is the least measurable cardinal. </p>

<blockquote>
  <p><strong>Question.</strong> Assume $\kappa$ is a strongly compact cardinal. Is there an inner model $M$ of the universe such that  $M \models$``$\kappa$
  is  strongly compact and the set of measurable cardinals below $\kappa$
  is unbounded in $\kappa$'' $?$</p>
</blockquote>
",logic
"<p>Does there exist any rubric where <em>provably</em> transcendental real numbers emerge, in a meaningful way, as rare among <em>all</em> the transcendental numbers?</p>

<p>Here are some of the things I'm worried about:</p>

<p>1) To talk about provably transcendental numbers, it seems only fair to consider them as a subset of some sort of set of definable real numbers (relative to some appropriate language).  If the language is countable, that means comparing two countable sets, so measure-theoretic language doesn't seem to help.</p>

<p>2) Some transcendentality proofs naturally apply to all the numbers in a definable uncountable set (which of course contains many undefinable numbers).  Small variations of Liouville's famous original construction yield uncountable sets of transcendentals.  So a countable language that can only encode a countable number of proofs can still establish the transcendentality of more than countably many numbers.</p>

<p>Perhaps something like this: relative to a fixed language one can define a complexity for definable transcendental reals by the length of their shortest defining formula.  Among those of a given complexity, some fraction admit transcendentality proofs.  Perhaps this
fraction must go to 0 with the complexity for any reasonable theory?  (This seems to me a meaningful question despite that attendant undecibilities concerning whether a formula defines a numbers, whether two formulas define the same number, etc.)</p>
",logic
"<p>2-By A'2, every set y satisfying axiom A' must be a transitive set. But it is not true that every set y satisfying axiom A must be transitive. So, it seems natural to ask the following.
Question 2: (i)  If a set y satisfies axiom A, is it necessary that the transitive closure of y is a set satisfying axiom A?
(ii)  If x is a transitive set, does any set y satisfying the axiom A and having x as a member set be a transitive set ?</p>
",logic
"<p>Much of the research taking place in set theory, is related to the classification of sentences according to their consistency strength relative to ZF. In order to be more specific, we say that for all sentences $\sigma,\tau\in Sent$, $\sigma$ has less consistency strength than $\tau$ (or $\sigma\leq_{cons}\tau$) iff $cons(ZF+\tau)\rightarrow cons(ZF+\sigma)$. My main question (which I believe should have a negative answer) is the following:
$$\mbox{ Is } \leq_{cons}\mbox{ linear? If not is there a natural counterexample?}$$
In fact I have several similar questions concerning $\leq_{cons}$ and I would be glad if someone could provide me with some references. Thanks! </p>
",logic
"<p>I asked this question on math stack exchange, but I didn't get any responses. So, now I am motivated to ask it here. Is the class of free monoids first order axiomatizable? And what about the class of full transformation monoids, in other words monoids that are isomorphic to a monoids of all functions over a set S to itself under composition?</p>
",logic
"<p>3-On the same page (84) he states axioms A and A',  Tarski also considers the 16 following axioms variants for A and A' and asserts witout giving a proof that they are all equivalent.
Axiom C: ""For every set x, there exists a set y satisfying the four following conditions C1, C2, C3 and C4, where for every i=1,2,3,4 Ci is choosen to be Ai or A'i.""
QUESTION 3: Does anyone know about an explicit proof of the equivalence of the 16 variants of axioms A and A' ?</p>

<p>4-As an example, let us consider the Tarski-Grothendieck axiom (TG) used by Mizar and Metamath, that is the variant C obtained by choosing C1=A1, C2=A2, C3=A'3 and C4=A4.
As A'3 is ane asy consequence of A3 (take w of A'3 to be t of A3), TG is a consequence of axiom A. So, to prove that TG is equivalent with A, it is sufficient to prove that A3 from TG.
from A1 and A2, we have that the power-set of x, P(x) is included inside y, and from A'3 that there exists a set w that is a member element of y such that P(x) is included inside w. And also, we have that P(w) is included inside y by A2. In view of A4, suppose that the set P(x) is equipotent with y. We then have an injection i from y into P(x), and as P(x) is included inside w we also have an injection j from y into w, and as P(w) is included inside y, the restriction k of j to the subset P(w) of y is an injection from P(w) to w.
But by Cantor's theorem, such an injection k does not exist, so a bijection between P(x) and y is impossible, and by A4, P(x) must be a member element of y, and A3 is proved from TG.</p>
",logic
"<p><strong>Weak Version</strong>:
Is there a 1st order language $L$ (with only countably-many formulas) such that for each recursive coding $C$ of the formulas of $L$, there is a theory $T$ of $L$ where</p>

<ol>
<li><p>$T$ is not satisfiable,</p></li>
<li><p>every $C$-recursive proper subtheory of $T$ (meaning the set of $C$-codes of the sentences in the subtheory is not recursive) is satisfiable, and</p></li>
<li><p>every proper subtheory of $T$ that isn’t $C$-recursive is unsatisfiable?</p></li>
</ol>

<p><strong>Strong Version</strong>:
Is there a 1st order language $L$ (with only countably-many formulas) such that there is a theory $T$ of $L$ where</p>

<ol start=""4"">
<li><p>$T$ is not satisfiable,</p></li>
<li><p>every recursively axiomatizable proper subtheory of $T$ is satisfiable, and</p></li>
<li><p>every proper subtheory of $T$ that isn’t recursively axiomatizable is unsatisfiable?</p></li>
</ol>

<p>Restricting to languages with only countably-many formulas excludes uncountable theories (which trivially fail to be recursively axiomatizable), but this restriction could be relaxed if we require that the theory T also be countable.</p>
",logic
"<p>I read about two different versions of the disjunction elimination rule.</p>

<p>The first version (<a href=""http://www.fecundity.com/logic/"" rel=""nofollow"">http://www.fecundity.com/logic/</a>) says that:</p>

<ul>
<li>if $\Sigma\vdash\phi_0\lor\phi_1$ and $\Sigma\vdash\lnot\phi_0$, then $\Sigma\vdash\phi_1$</li>
<li>if $\Sigma\vdash\phi_0\lor\phi_1$ and $\Sigma\vdash\lnot\phi_1$, then $\Sigma\vdash\phi_0$</li>
</ul>

<p>The second version (S. Hedman - A First Course in Logic) says that:</p>

<ul>
<li>if $\Sigma\models\phi_0\lor\phi_1$, $\Sigma\cup\left\{\phi_0\right\}\vdash\phi_2$ and $\Sigma\cup\left\{\phi_1\right\}\vdash\phi_2$, then $\Sigma\vdash\phi_2$</li>
</ul>

<p>Using the first version of the rule, I can't even demonstrate that if $\Sigma\vdash\phi\lor\phi$ then $\Sigma\vdash\phi$. Perhaps the entire system presented by the first source is not complete, in the sense that you can't prove certain true statements. Of course, it may be my fault, instead.</p>

<p>Thanks.</p>
",logic
"<p><b>Definitions. </b> Given a sentence $\varphi$ of $n$th-order logic, we define the spectrum of $\varphi$ to be the set of cardinalities of finite structures that satisfy $\varphi$. A set $X\subseteq\mathbb N$ is said to be an $n$th-order spectrum if there is an $n$th-order sentence whose spectrum is $X$. Given any positive integer $n$, let $S_n$ be the set of all $n$th-order spectra. An $\omega$-order spectrum is an element of the set $S_{\omega}:=\bigcup_{n\in\mathbb Z_+}S_n$.</p>

<p><b>Questions.</b></p>

<ol>
<li><p>Clearly, $S_n\subseteq S_{n+1}$ for each positive integer $n$. One knows that $S_1\subsetneq S_2$ (J. H. Bennett, <i>On spectra</i>, 1962).</p>

<blockquote>
  <p>Do we have $S_n\subsetneq S_{n+1}$ for each positive integer $n$?</p>
</blockquote></li>
<li><p>One does not know if the complement of a first-order spectrum is also a first-order spectrum. That is why I wonder:</p>

<blockquote>
  <p>Is the complement of a second-order spectrum always a second-order spectrum? Is the complement of a third-order spectrum always a third-order spectrum? ...</p>
</blockquote></li>
<li><p>For each positive integer $n$, every element of $S_n$ is decidable. But we can always construct a decidable set $D_n$ which is not in $S_n$: We simply construct the diagonal set $D_n$ such that $m \in D_n$ if and only if $m$ is not in the $m$th $n$th-order spectrum. (<a href=""http://researcher.watson.ibm.com/researcher/files/us-fagin/genspec.pdf"" rel=""nofollow"">source</a>, page 2)</p>

<blockquote>
  <p>Is $D_n$ always an element of $S_{n+1}$? Is $D_n$ always an element of some $S_p$, where $p&gt;n$?</p>
</blockquote></li>
<li><blockquote>
  <p>Is the complement of an $\omega$-order spectrum always an $\omega$-order spectrum?</p>
</blockquote></li>
</ol>
",logic
"<p>In order to respond to concerns of impredicativity, Bertrand Russell developed a system of ramified second-order logic, which is like regular second-order logic except the comprehension schema is divided into levels.  The comprehension schema for level $0$ sets does not allow any formulas with second-order quantifiers.  For any natural number $n$, the comprehension schema for level $n+1$ sets allows quantification over sets of level $n$ and below.  This ensures that no set is defined using quantification over itself.  The resulting system, however, proved too weak to do much mathematics.  (Although it turns out it can do more than Russell assumed; see <a href=""http://mathoverflow.net/questions/150454/can-the-burgess-hazen-analysis-of-predicative-arithmetic-be-extended-to-transfin"">here</a>.)  So Russell adopted his controversial axiom of reducibility, actually an axiom schema which for each natural number $n$, states that for any set $X$ of level $n$, there exists a set $Y$ of level $0$ such that $X$ and $Y$ contain the same elements.</p>

<p>Now, it is commonly asserted that the axiom of reducibility is equivalent to simply eliminating the ramified hierarchy and just working in standard second-order logic.  But I don't see why.  At first glance, it seems to me that saying that every set, period, is coextensional with a level $0$ set, is a stronger statement than saying that every set of any given level is coextensional with a level $0$ set.  Aren't there sets that aren't coextensional with sets of any level?</p>

<p>Any help would be greatly appreciated.</p>

<p>Thank You in Advance.</p>

<p>EDIT:  Here's another way to phrase my question.  Consider the following two possible axiom schemata:</p>

<ol>
<li>For any formula $\phi(x)$ in the language of second-order arithmetic, there exists a set of level $0$ whose elements are the ones that satisfy $\phi(x)$</li>
<li>For any formula $\phi(x)$ with only graded quantifiers (i.e. quantifiers of the form ""for all sets of level..."" or ""there exists a set of level...""), there exists a set of level $0$ whose elements are the ones that satisfy $\phi(x)$.</li>
</ol>

<p>Is the first axiom schema stronger than the second, or are they equivalent?</p>
",logic
"<p>I'd like to write down a proof of the following (simple) fact: $\forall x\left(\bigcup\left\{x\right\}=x\right)$. I'd like to use the rules of inference of natural deduction. One could show that if $y\in\bigcup\left\{x\right\}$ then $y\in x$ and vice versa. I managed to show the former implication, but I cannot show the latter.</p>

<p>Let me show you what I accomplished, as an example. You suppose that $t_1\in\bigcup\left\{t_0\right\}$. Then it follows that $\exists x_2\left(x_2\in\left\{t_0\right\}\land t_1\in x_2\right)$. Now you also suppose that $t_2\in\left\{t_0\right\}\land t_1\in t_2$. So $t_2\in\left\{t_0\right\}$, $t_1\in t_2$, $t_2\in\left\{t_0,t_0\right\}$, $t_2=t_0\lor t_2=t_0$, $t_2=t_0$, $t_1\in t_2\leftrightarrow t_1\in t_0$, $t_1\in t_0$. That's the easy part. The problem now is that if I suppose that $t_1\in t_0$ I can't show that $t_1\in\bigcup\left\{t_0\right\}$.</p>

<p>What can I do? Thanks.</p>
",logic
"<p>Please forgive any unorthodox notation or obvious errors here...  I'm trying to get an intuition for dependently typed languages, so I'm starting out by seeing which analogies I can take from the simply typed world.  In an ML-like language we can encode existential types in terms of universal types:</p>

<p>$\exists a.T(a) \equiv \forall x.(\forall a.T(a) \rightarrow x) \rightarrow x$</p>

<p>Similarly, we could also define sum types in terms of universal types and product types:</p>

<p>$ a + b \equiv \forall x.(a \rightarrow x)\times(b \rightarrow x) \rightarrow x $</p>

<p>This correspondence makes sense to me, since existential types are like infinite sums and universal types are like infinite products.</p>

<p>In a dependently typed language, would it also be possible to define dependent sums in terms of dependent products?  This seems close:</p>

<p>$\Sigma(b:B).T(b) \equiv \forall x.(\Pi(b:B).T(b) \rightarrow x) \rightarrow x$</p>

<p>$(a,t) : \Sigma(b:B).T(b) \equiv \lambda f. f\ a\ t$</p>

<p>$\text{fst}\ p \equiv p_B\ (\lambda(b:B).\lambda(\_:T(b)).b)$</p>

<p>$\text{snd}\ p \equiv p_{T (\text{fst}\ p)}\ (\lambda(b:B).\lambda(t:T(b)).t)$</p>

<p>However, I can't convince myself that the definition for <code>snd</code> is well-typed because I can't show that $t : T (\text{fst}\ p)$.  Is there some way to make this work?</p>
",logic
"<p>Let define procedure for converting second order theory to first order:</p>

<ol>
<li>Take any second order theory with equality</li>
<li>Invent sort Bool' and new fresh constants F' and T', of sort Bool'</li>
<li>Create fresh sort CC</li>
<li>Replace each proposition P(x) (where x : XX) except equality to P'(x) == T' where P' : XX -> Bool'</li>
<li>Replace each connective to respective function to Bool'</li>
<li>For each first order function f : XX -> YY define fresh constant c : CC. We call it the key of function f.</li>
<li>For each sort XX and YY, if source theory contained any functions XX -> YY, define new function applyXXYY : CC -> XX -> YY such that if c is key for f then applyXXYY(c,x) = f(x)</li>
<li>For each first order function f applied to second order function g replace f by its key:
g(f) replace to g(c) where c is a key for f</li>
<li>Each expression with variable containing first order function applied to argument replace application to variable by application to applyXXYY(variable)
(where XX and YY are respective to sort of f).
So, definition g(x,f,y) := x*f(y)+1-q(f) become g(x,c,y) := x*apply(c,y)+1-q(c)</li>
</ol>

<p>Items 6..9 is well known amongst functional programmers as defunctionalization process (roughly).</p>

<p>So, SOL is more expressive than FOL (in strict Felleisen/VanRoy sense) but strictly equal in power.
Is it correct?</p>

<p>Questions:</p>

<ul>
<li>Are Second Order Logic really equivalent to First Order Logic?</li>
<li>Are really any logic of some order can be lowered to FOL?</li>
<li>Can any higher order Logic be converted to equivalent first order logic?</li>
</ul>
",logic
"<p>Is the $\Sigma_{n}$-recursion supported by $\Sigma_{n}KP=KP+\Sigma_{n}$-separation + $\Sigma_{n}$-collection equivalent with $\Sigma_{n}$ transfinite recursion? If not, how do these notions differ?</p>
",logic
"<p>This question is about an issue left unresolved by <a href=""http://mathoverflow.net/questions/15957"">Chad
Groft's excellent
question</a> and
<a href=""http://mathoverflow.net/questions/15957#16122"">John Stillwell's excellent
answer</a> of
it. Since I find the possibility of an affirmative answer
so tantalizing, I would like to pursue it further here.</p>

<p>For background, Rice's Theorem
asserts essentially that no nontrivial question about computably enumerable sets is decidable. If W<sub>e</sub> is the set enumerated by program e, then the theorem states:</p>

<p><b>Rice's Theorem. </b> If A is a collection of computably
enumerable sets and { e |
W<sub>e</sub> &isin; A } is decidable, then either A is 
empty or A contains all computably enumerable sets.</p>

<p>In short, one can decide 
essentially nothing about a program e, if the answer is to
depend only on what the program computes rather than how it
computes it. </p>

<p>The question here is about the extent to which a similar
phenomenon holds for finitely presented groups, using the
analogy between programs and finite group presentations:</p>

<ul>
<li>a program e  is like a finite group presentation p</li>
<li>the set W<sub>e</sub> enumerated by e is like the group
&lang;p&rang; presented by p.</li>
</ul>

<p>According to this analogy, the analogue of Rice's theorem
would state that any decidable collection of finitely
presented groups (closed under isomorphism) should be either trivial or everything.
John Stillwell pointed out in answer to Chad Groft's
question that this is not true, because from a presentation
p we can easily find a presentation of the abelianization of
&lang;p&rang;, by insisting that all generators commute, 
and many nontrivial questions are decidable about finitely
presented abelian groups. Indeed, since the theory of
abelian groups is a decidable theory, there will be many
interesting questions about finitely presented abelian
groups that are decidable from their presentations. </p>

<p>My question is whether this is the only obstacle.</p>

<p><b>Question.</b> Does Rice's theorem hold for finitely
presented groups modulo abelianization? </p>

<p>In other words, if
A is a set of finitely presented groups (closed under
isomorphism) and the corresponding set of presentations { p | &lang;p&rang; &isin; A } is
decidable, then does A completely reduce to a question
about the abelianizations of the groups, in the sense that there is a set B of abelian groups such that G &isin; A iff Ab(G) &isin; B? </p>

<p>Of course, in this case B consists exactly of the abelian groups in A. The question is equivalently asking whether A respects the equivalence of groups having isomorphic abelianizations. In other words, must it be that G &isin; A iff Ab(G) &isin; A? 
The question is asking whether every decidable set of finitely presented groups amounts actually
to a decidable set of abelian groups, extended to all
finitely presented groups just by saturating with respect to abelianization. </p>

<p>In particular, the set A should contain either none or all perfect groups. </p>

<p>An affirmative answer would seem to provide a thorough
explanation of the pervasive undecidability phenomenon in
group presentations. But perhaps this may simply be too much to hope for...</p>

<p>In any event, I suppose that there is an equivalence relation on finite group presentations, saying that p &equiv; q just in case &lang;p&rang; and &lang;q&rang; have the same answer with repsect to any decidable question about finitely presented groups. The question above asks whether this equivalence relation is just Ab(&lang;p&rang;) = Ab(&lang;q&rang;). If this turns out not to be true, then what can be said about &equiv;?</p>
",logic
"<p>Suppose we have integer matrices $A_1,\ldots,A_n\in\operatorname{GL}(n,\mathbb Z)$.  Define $\varphi:F_n\to\operatorname{GL}(n,\mathbb Z)$ by $x_i\mapsto A_i$.  Is there an algorithm to decide whether or not $\varphi$ is injective?</p>
",logic
"<p>I am searching for a constructive proof of the following fact: If $X$ is an infinite set, there exists an uncountable family $(X_\alpha)_{\alpha \in A}$ of infinite subsets of $X$ such that $X_\alpha \cap X_\beta$ is finite whenever $\alpha \neq \beta$.  The way I know how to prove this statement is as follows.</p>

<p>First, it suffices to prove the case when $X$ is countable.  Thus we can choose a bijection between $X$ and $\mathbb{Q} \cap [0,1]$.  To save notation we can tacitly assume that $X = \mathbb{Q} \cap [0,1]$.  </p>

<p>Let the index set be $A = [0,1] \setminus X$, i.e. all the irrationals in $[0,1]$.  For each $\alpha \in A$, choose a sequence  $(x_{\alpha 1},x_{\alpha 2},\dots)$ of elements of $X$ such that $x_{\alpha n} \to \alpha$ as $n \to \infty$, and let $X_\alpha = \{ x_{\alpha_n} \mid n \in \mathbb{N} \}$.</p>

<p>Since $\alpha$ is irrational, the sequence $(x_{\alpha n})$ cannot be eventually constant, so $X_\alpha$ is infinite.  And if $\alpha \neq \beta$ then the sequences $(x_{\alpha n})$ and $(x_{\beta n})$ can have only finitely many terms in common since they have different limits, so $X_\alpha \cap X_\beta$ is finite.</p>

<p>Is it possible to do this in a more constructive way?  I know very little about set theory and logic, so I apologize if this question is too elementary.  Also, I wasn't sure about any relevant tags other than set-theory, so please feel free to add appropriate tags.</p>

<p>Edit: to clarify, I didn't have a clear notion of what I meant by ""constructive"" here.  What I didn't like about the proof I gave above was that it required a choice of sequence of rationals converging to each irrational.  The answers so far all address this concern adequately.</p>
",logic
"<p>If $\kappa$ is an inaccessible cardinal and $G \subset \operatorname{Col}(\omega,\mathord{&lt;}\kappa)$ is a $V$-generic filter, then in $V[G]$ the Chang model $L(\text{Ord}^\omega)$ satisfies ""every set of reals has the classical regularity properties"" by Solovay's theorem.  (By the classical regularity properties I mean Lebesgue measurability, the Baire property, and the perfect set property.)</p>

<p>If instead $\kappa$ is a limit of Woodin cardinals (not necessarily inaccessible, possibly singular,) $G \subset \operatorname{Col}(\omega,\mathord{&lt;}\kappa)$ is a $V$-generic filter, and we define $\mathbb{R}^*_G = \bigcup_{\alpha &lt; \kappa} \mathbb{R}^{V[G\restriction \alpha]}$, then the model $L(\mathbb{R}^*_G)$ satisfies the Axiom of Determinacy (and hence also the weaker statement that every set of reals has the classical regularity properties) by a theorem of Woodin.</p>

<p>Now let's assume that $\kappa$ is inaccessible <em>and</em> is a limit of Woodin cardinals. Again let $G \subset \operatorname{Col}(\omega,\mathord{&lt;}\kappa)$ be a $V$-generic filter.  Because $\kappa$ is inaccessible we have $\mathbb{R}^*_G = \mathbb{R}^{V[G]}$. In this case it is possible to obtain a mutual strengthening of the two results mentioned above:</p>

<blockquote>
  <p>In $V[G]$, does the Chang model $L(\text{Ord}^\omega)$ satisfy $\mathsf{AD}$?</p>
</blockquote>

<p>(I am aware that Woodin has proved that the much stronger hypothesis of the existence of a proper class of Woodin limits of Woodin cardinals implies that the Chang model of $V$ satisfies $\mathsf{AD}$.)</p>
",logic
"<p>I read some time ago some papers about proof formalization. Typically, I began whith <a href=""http://research.microsoft.com/en-us/um/people/lamport/pubs/lamport-how-to-write.pdf"" rel=""nofollow"">this one</a>, from Lamport.</p>

<p>Are there more recent works in this field ?</p>
",logic
"<p>One form of Vopenka's principle (a large cardinal axiom) states that no locally presentable category contains a full subcategory which is large (= a proper class) and discrete (= contains no nonidentity morphisms).  In terms of this definition, my question is:</p>

<blockquote>
  <p>Can one define a particular locally presentable category C and write down an explicit formula $\phi(x)$ in the first-order language of set theory such that <em>if</em> Vopenka's principle fails, then $\{ x | \phi(x) \}$ is a large discrete full subcategory of C?</p>
</blockquote>

<p>But feel free to use any equivalent statement of Vopenka's principle and answer a suitably equivalent version of the question.</p>
",logic
"<p>4-(suite): axiom A (or equivalently axiom TG) have powerfull consequences.
(i) It is easy to see that A1 and A2 prove the power-set axiom, by separation, because P(x is included inside the set y;
(ii)from A1 and iterations of A2, we also can derive the axiom of infinity. In fact all sets P(n,x), with P(0)=x, P(1,x)=P(x) and P(n+1, x)=P(P(n,x)) must be member elements of the set y and so are forming a set z by separation. But, by iteration of the Cantor's theorem, no injection from P(n+m,x) into P(n,x) is possible for m>0; so that all sets P(n,x) are distinct sets. We then have an injection from z into the class of finite ordinals, and by replacement this class must be a set, so that we prove the axiom of infinity.
(iii) It is also possible, but this is much more difficult and uses essentially the regularity axiom, to prove thecaxiom of choice from axiom A.
The three preceding proofs can be built so that we can prove that  the theory ""ZFC + Axiom A"" (or equivalently the theory ""ZFC + ""There exists a proper class of inaccessible cardinals"""")  is equivalent to the theory having as axioms: Replacement, Extensionality, Pair, Union and Regularity [and the axiom asserting the existence of some set , if this is not considered as a logical truth].
So, it seems that the price to be paid for deleting power-set, infinity and choice is to add the axiom of the Pair, but Tarski asserts that the Pair axiom can be derived from axiom A and replacement.
QUESTION 4 ""Is it possible to dispense with the addition of the axiom of the Pair and to preserve the equivalence with ""ZFC + axiom A ?""</p>
",logic
"<p>Let $X$ be a nonvoid set of cardinal $\alpha$. Let $\cong$ be an equivalence relation on $X$. Let $\beta$ be the cardinal of the set</p>

<p>(1)&nbsp;&nbsp;&nbsp;&nbsp; $ D = \{ \, ( x, y ) \in X \times X ~|~ x \ncong y \, \} $</p>

<p>Let any family $( x_i )_{i \in I}$, with $I$ a nonvoid index set, and $x_i \in X$, for $i \in I$. We call such a family a <em>chain</em>, iff</p>

<p>(2)&nbsp;&nbsp;&nbsp;&nbsp; $ x_i \ncong x_j,~~ i, j \in I,~ i \neq j $</p>

<p>We denote by</p>

<p>(3)&nbsp;&nbsp;&nbsp;&nbsp; $ \kappa $</p>

<p>the smallest cardinal which is at least as large as the cardinal of any index set $I$ of a chain (2).</p>

<p>Clearly, we shall have</p>

<p>(4)&nbsp;&nbsp;&nbsp;&nbsp; $ car ( X / {\cong} ) = \kappa $</p>

<p><strong>Problem 1</strong></p>

<p>Find, in terms of the cardinals $\alpha, \beta$, the cardinal $\kappa$.</p>

<p><strong>Problem 2</strong></p>

<p>Given the cardinal $\alpha$, and given an upper bound</p>

<p>(5)&nbsp;&nbsp;&nbsp;&nbsp; $ \beta \leq \gamma $</p>

<p>find, in terms of the cardinals $\alpha, \beta, \gamma$, an upper bound for the cardinal $\kappa$.</p>

<p><strong>Problem 3</strong></p>

<p>Given the cardinal $\alpha$, and given a lower bound </p>

<p>(6)&nbsp;&nbsp;&nbsp;&nbsp; $ \beta \geq \gamma $</p>

<p>find, in terms of the cardinals $\alpha, \beta, \gamma$, a lower bound for the cardinal $\kappa$. </p>
",logic
"<p>Let $V^{H}$ be a Heyting valued model of intuitionistic set theory. What conditions does $H$ have to satisfy in order for the following claim to hold? (where $\| \phi(u) \| \in H$ is the truth value of the sentence $\phi(u)$ of the language of IZF + the names of the elements of $V^{H}$ and for any $x \in V$, $\hat{x}$ is the canonical representative of $x$ in $V^{H}$)</p>

<p>Claim: For any $u, v \in V^{H}$, if </p>

<p>(a) $V^{H} \models u$ and $v$ are Dedekind real numbers,</p>

<p>and </p>

<p>(b)$\| u = v \| \neq 1 $,</p>

<p>then there exists a rational number $q \in \mathbb{Q}$ such that $\|\hat{q} \in u \| = 1 \neq \| \hat{q} \in v \|$ (or vice versa, i.e. $\|\hat{q} \in v \| = 1 \neq \| \hat{q} \in u \|$). </p>

<p>Note that it is always the case that if $u$ and $v$ satisfy (a) and (b), then there will exist $q \in \mathbb{Q}$ such that $\|\hat{q} \in u\| \neq \| \hat{q} \in v \|$. The quesiton is when we can use such a $q$ to build a rational that satisfies the claim.</p>

<p>The notion of Dedekind real I'm working with here is given by the formula</p>

<p>$r \subseteq \mathbb{Q} \wedge \exists x \in \mathbb{Q} (x \in r) \wedge \exists x \in \mathbb{Q} (x \notin r) \wedge \forall x \in \mathbb{Q} ( x \in r \leftrightarrow \forall y \in \mathbb{Q} (x \lneq y \rightarrow y \in r ))$ </p>

<p>Call this formula $\phi(r)$. If $\| \phi(u) \| = 1$, then assuming that $H$ is uncountable, it is easy to show that there exists $q \in \mathbb{Q}$ such that $\|\hat{q} \in u \| = 1$. What other conditions does $H$ need to satisfy?</p>
",logic
"<p>Assume $\kappa$ is uncountable and $\phi$ is an $L_{\infty,\kappa}$ sentence. Let $K$ be the collection of models of $\phi$ partially ordered by $\prec_{\infty,\kappa}$. It is well-known that $K$ is closed under unions of increasing chains of length $\kappa^+$, but the argument fails for increasing chains of length $&lt;\kappa$. </p>

<p>Do you have an easy counterexample, either for $\kappa=\aleph_1$ or $\kappa=\aleph_\omega$?</p>
",logic
"<p>Search problem $MIN^P$ is, given a polynomial-time computable predicate that is a partial order, to find its minimum (any will do).</p>

<p>Search problem $MIN^L$ is, given a polynomial-time computable predicate that is a linear order, to find its minimum.</p>

<p>Search problems can be interpreted as computational models (complexity classes), namely as polynomial time bounded computations plus an oracle solving instances of the search problem.</p>

<p>More formally, for example for linear orders:  Enhance a polynomial time bounded Turing machine $S$ with an oracle.  The oracle input always consists of a number $n$ and a code of another Turing machine $T$.  Machine $T$ (accepts pairs of integers and) computes an order relation $&lt;^L$ on integers from $0$ to $n$ and is constructed to guarantee termination in polynomial time.
The oracle then outputs a minimum number $m$ (that is, $0 \le m \le n$, and $(\forall x) 0 \le x \le n \implies  m &lt;^L x \vee m = x$).  In case the machine $T$ supplied to the oracle is invalid (not a Turing machine code, or defining a relation which is not a linear order up to $n$), the oracle is free to output any value.  Note that the size of $n$ is by definition polynomial in the size of the input to the Turing machine $S$, but its value may be exponential, and therefore the oracle may add computational power beyond polynomial time computable functions.</p>

<p>My question is: can this computation model (call it, $MIN^L$) solve $MIN^P$?</p>

<p>To further clarify, here is a trivial proof of the converse.   $S$ will get some $n$ and a code of a Turing machine.  It will simply feed both as $n$ and $T$ to its oracle, and output the oracle answer which is the desired minimum.</p>

<p>This question is bugging me for some time.  A negative answer would entail some quite interesting consequences for fragments of bounded arithmetic.</p>
",logic
"<p>If $\mathcal{I}$ is an ideal (proper and containing the finite sets) on $\omega$, call a family of subsets $\mathcal{A}\subseteq[\omega]^\omega$ <em>$\mathcal{I}$-almost disjoint</em> if for all distinct $A,B\in\mathcal{A}$, $A\cap B\in\mathcal{I}$. Such a family is <em>$\mathcal{I}$-mad</em> if it is maximal with respect to this property.</p>

<p>A well-known theorem of Mathias says that, for $\mathcal{I}=[\omega]^{&lt;\omega}$, there are no infinite analytic $\mathcal{I}$-mad families. At the extreme opposite end of the spectrum, if $$\mathcal{I}=\left\{A\subseteq\omega:\lim_{n\to\infty}\frac{|A\cap n|}{n}=0\right\},$$ the densitiy zero ideal, then there are countably infinite (and thus analytic) $\mathcal{I}$-mad families.</p>

<p>My question: Are there examples of analytic ideals $\mathcal{I}$ for which there are no countable $\mathcal{I}$-mad families, but there are <em>analytic</em> $\mathcal{I}$-mad families? If $\mathcal{I}$ is a $P$-ideal, I gather that a result of Farah requires $\mathcal{I}$ to be $F_\sigma$ for the former clause to occur.</p>
",logic
"<p>I have seen various references in the literature to such a connection but they tend to assume that the reader is familiar with the connection, and limit themselves to providing additional detail.  So in broad terms, what is the precise connection between o-minimal models and Grothendieck's programme?</p>
",logic
"<p>In his ASL Godel lecture (Las Vegas, Nevada, 2002), Harvey Friedman asked the following question:</p>

<p>Are there fundamental principles of a general philosophical nature which can be used to give consistency proofs of set theory, including the so called large cardinal axioms?</p>

<p>Recently, he is able to isolate the following two fundamental philosophical principles and use them to prove the interpretability of various common sense thinking and set theory (with large cardinals).</p>

<p>(i) Plenitude Principle (PP): Anything that can happen will.</p>

<p>(ii) Indiscernibility Principle (IP): Any two horizons are indiscernible to observers on the basis of their extent.</p>

<p>(See his Concept Calculus article, e.g. <a href=""http://www.math.ohio-state.edu/~friedman/pdf/ConceptCalc102506,pdf.pdf"">link text</a>)</p>

<p><strong>My main questions are: How confident are we that PP and IP are “true” ? More specifically, is it possible to “prove” or justify PP and IP rigorously? If yes, how? If not, why not?</strong></p>

<p>In my view, the ultimate justification of PP and IP would be to construct a (meta) system S based on PP and IP, and then prove its consistency and completeness. In the light of Godel’s incompleteness theorem, I’m not sure that this can be done. But perhaps S is not recursively axiomatizable, and so Godel’s incompleteness theorem would not apply to S.</p>

<p>My secondary question is: are there any logician (beside Friedman) who are working on this kind of research?</p>

<p><strong>Update: July 2011</strong></p>

<p>Here is a rephrasing of the question by Timothy Chow that makes it closer to mathematical logic: </p>

<h2>Is there some precise mathematical statement, that has the flavor of IP or PP, which proves the consistency of all (or most) set-theoretic axioms that are generally accepted today (e.g., large cardinal axioms)?</h2>

<p><strong>Update:</strong> The question has now been open. It is now time for people who can relate to the problem to answer it.</p>
",logic
"<p>ZFC-, which is ZFC minus power set, is modelled by $ L_{\delta}$ where $\delta$ is an admissible ordinal larger than
any least $\Sigma_{n}$-admissible ordinal for n a natural number. Can some provide more information? Does it have a name? What is its most natural omega sequence?</p>
",logic
"<p>A few years ago, a number of examples were given of Fraisse structures without the SAP in answer to the question raised in <a href=""http://mathoverflow.net/questions/127284/a-fra%C3%AFss%C3%A9-class-without-the-strong-amalgamation-property/127294#127294"">A Fra&#239;ss&#233; class without the strong amalgamation property.</a> 
It is well known that any closed subgroup of the full permutation group of the integers is the automorphism group of some Fraisse limit, which may or may not have the SAP, but this limit is far from unique.</p>

<p>For example, if one partitions the integers into pairs and considers the group of all permutations that send pairs to pairs and respect the natural ordering on each pair then one gets a group of permutations isomorphic to the full permutation group. The age of the original structure does not have the SAP because it has non-trivial algebraicity (if you know where the bottom element of a pair goes, you know where the top element goes too). However, the full permutation group is the automorphism group of the empty structure which, of course, has the SAP.</p>

<p>My question is: Is every non-locally-compact, closed subgroup of the full permutation group isomorphic to the group of automorphisms of the limit of some Fraisse structure with the SAP?</p>

<p>Since the SAP allows the construction of very many automorphisms, one cannot expect all closed groups to have this property. I suspect that a counterexample can be found in which the group has a locally compact factor, but do not know this either. But if this does turn out to be the case, then the next question is: Is every group that is not the homomorphic preimage of a locally-compact, closed subgroup of the full permutation group isomorphic to the group of automorphisms of the limit of some Fraisse structure with the SAP?</p>
",logic
"<p>Let $A$ be an abstract C*-algebra, and let $\varphi\colon A \rightarrow \mathbb C$ be a bounded linear function. Assuming the axiom of choice, there exist unique positive bounded linear functions $\varphi_+$ and $\varphi_-$ such that $\varphi = \varphi_+ - \varphi_-$ and $\|\varphi\| = \|\varphi_+\| + \|\varphi_-\|$ (see section 3.2 of Pedersen's <em>C*-algebras and their Automorphism Groups</em>). Is the <a href=""http://en.wikipedia.org/wiki/Axiom_of_dependent_choice"" rel=""nofollow"">axiom of dependent choices</a> sufficient to prove this result?</p>

<p>I believe that the axiom of dependent choices is sufficient to establish the result if $A$ is separable or commutative. If $A$ is separable, then the usual proof still works. If $A$ is commutative, then the decomposition can be obtained by lattice-theoretic methods, such as those in Schechter's <em>Handbook of Analysis and its Foundations</em>. In general, the self-adjoint operators of a noncommutative C*-algebra do not form a lattice (see examples II.3.3.3 in <a href=""http://wolfweb.unr.edu/homepage/bruceb/Cycr.pdf"" rel=""nofollow"">Blackadar's book</a>).</p>
",logic
"<p>How many field automorphisms does $\mathbf{C}$ have?  If you assume the axiom of choice, there are tons of them -- $2^{2^{\aleph_0}}$ I believe.  And what if you don't -- how essential is the axiom of choice to constructing ""wild"" automorphisms of $\mathbf{C}$?  Specifically, if you assume that ZF admits a model, does that imply that ZF admits a model where $\mathbf{C}$ has no wild automorphisms: $\mathop{Aut}\mathbf{C}=\mathbf{Z}/2\mathbf{Z}$?</p>

<p>I suppose if that's true, then the next logical question is to construct models of ZF where $\mathop{Aut}\mathbf{C}$ has cardinality strictly between 2 and $2^{2^{\aleph_0}}$--pretty disturbing if you ask me.  Which finite groups can you hit?</p>
",logic
"<p>The standard proof of the Hahn-Banach theorem makes use of Zorn's lemma. I hear that, however, Hahn-Banach is strictly weaker than Choice. A quick search leads to many sources stating that Hahn-Banach can be proven using the ultrafilter theorem, but I cannot seem to find an actual proof. So...</p>

<ol>
<li>What is the ultrafilter theorem; and</li>
<li>How does the said theorem imply the Hahn-Banach theorem?</li>
</ol>

<p>Any easily-accessible reference would be quite enough; thanks in advance!</p>
",logic
"<p>Jeremy Avigad and Erich Reck in their remarkable historical paper ""Clarifying the nature of the infinite: the development of metamathematics and proof theory"" claim that one of the factors of becoming of abstract mathematics in the late 19 century (as opposed to concrete mathematics or hard analysis) was the fact, that using more abstract notions we can avoid a lot of calculations to obtain the same result. Let me quote them:</p>

<blockquote>
  <p>The gradual rise of the opposing viewpoint, with its emphasis on conceptual
  reasoning and abstract characterization, is elegantly chronicled by Stein[110],
  as part and parcel of what he refers to as the “second birth” of mathematics.
  The following quote, from Dedekind, makes the diﬀerence of opinion very clear:</p>
  
  <blockquote>
    <p>A theory based upon calculation would, as it seems to me, not oﬀer
    the highest degree of perfection; it is preferable, as in the modern
    theory of functions, to seek to draw the demonstrations no longer
    from calculations, but directly from the characteristic fundamental
    concepts, and to construct the theory in such a way that it will, on
    the contrary, be in a position to predict the results of the calculation
    (for example, the decomposable forms of a degree).</p>
  </blockquote>
  
  <p>In other words, from the Cantor-Dedekind point of view, abstract conceptual
  investigation is to be preferred over calculation.</p>
</blockquote>

<p>So, my question is: do you know some concrete examples from concrete fields of avoiding calculation mass by the use of abstract notions? (term ""calculation"" here means any type of routine technicality). I can't remember where I read it but some examples one can find in category theory and topoi (not sure).</p>

<p>Thanks in advance</p>
",logic
"<p>Hello. This may not count as a research question, but I guess it's too much for math.stackexchange.</p>

<p>Could we define ZF (Zermelo-Fraenkel Set theory) in classical first-order predicate calculus, then define classical HOLs(Higher order logics) so that ZF can interpret it (via ""inhabits"" relation (sets)) and would we get that HOLs are interpretable in FOL?</p>

<p>Does that mean that HOLs do not have more expressive power than FOL in principle?</p>

<p>Thank you in advance.</p>
",logic
"<p>Absoluteness is a wonderful thing, but expensive consistency-strength wise. My question is, when can we get large amounts of absoluteness in specific situations for much cheaper?</p>

<p>Specifically, fix a definable forcing notion $\mathbb{P}$ - it is reasonable to ask how hard it would be to find a model where, say, $\Pi^1_3$ statements aren't changed by forcing with $\mathbb{P}$. For example, take $\mathbb{P}$ to be Cohen forcing. Then $L$ is certainly not such a model, but any forcing extension of $L$ by $\mathbb{P}$ is. On the other hand, there are certainly definable forcing notions such that the statement ""Forcing with $\mathbb{P}$ doesn't change the truth value of $\Pi^1_3$ sentences"" requires consistency strength beyond ZFC.</p>

<p>My question is when we can make ""local absoluteness assumptions"" without additional consistency strength. For a specific instance of this question:</p>

<blockquote>
  <p>Are there reasonable hypotheses on definable forcings $\mathbb{P}$ which imply that the statement $$\text{$PA(\mathbb{P})$ = ""Projective sentences are absolute under forcing with $\mathbb{P}$""}$$ has no additional consistency strength?</p>
</blockquote>

<p>I would ask for sufficient <em>and necessary</em> conditions, but I think that's demanding far too much.</p>

<hr>

<p><em>I've added the ""descriptive set theory"" tag because I think it may be relevant; feel free to delete if you think that's bonkers.</em></p>
",logic
"<p>The question <a href=""http://mathoverflow.net/questions/108726/getting-a-bound-on-the-coefficients-of-the-factor-polynomial?rq=1"">Getting a bound on the coefficients of the factor polynomial</a> got very nice answers on Gelfond's theorem. But for work on proof theory of arithmetic I want a proof in arithmetic.  The published proofs use Mahler measure defined in complex analysis. Are there published proofs of Gelfond's theorem in arithmetic in the first place.  I should say, proofs published in English or some Western European language.  I cannot read Gelfond's paper in Russian.</p>

<p>In fact Mahler uses the sort of complex analysis which is probably conservative over Peano arithmetic along the lines of Takeuti's ""A Conservative Extension of Peano Arithmetic.""  But I am not skilled at that yet.  Can anyone here tell me if that will work for Mahler measure? or won't?  Or point me to a better source?</p>

<p>Emil Jeřábek asks reasonably if I need Gelfond's theorem.  In fact I do need something close to it.  I want polynomial factorization over algebraic number fields. This is probably best approached in terms of two-variable integer polynomials where the first variable is really to be taken modulo an irreducible polynomial over $\mathbb{Z}$.  This would be a pretty special case of Gelfond's theorem, but not obviously reducible to one-variable polynomials over $\mathbb{Z}$.</p>

<p>To be clear I am asking to know a proof, so I can check if it works in EFA.  The project is to establish that EFA suffices for the classical Galois theory of number fields inclduing the Artin-Schreier theorem -- which is not obvious, since results in Reverse Math show even PRA does not suffice for the more general theory of algebraic extensions of $\mathbb{Q}$.</p>
",logic
"<p>I've read somewhere (probably in the nlab) that higher category theory has application in logic.
By the way since now the only applications of higher category theory I've seen are in homotopy theory and mathematical physics, so I was wondering if anyone could give me some example of applications of higher categorical methods in logic (any reference would be appreciated).</p>
",logic
"<p>Hi all,
I am interested in proofs without using Goedel's completeness theorem.</p>

<ul>
<li>Does anyone have a reference to a proof of this theorem that uses Skolem Functions?</li>
<li>How come Enderton's (Introduction to Logic) has a half a page proof (which looks OK to me) and Boolos (Computability And Logic) has a full chapter of it?</li>
</ul>

<p>Thanks.</p>
",logic
"<p>Recall that for sets $A, B \in 2^\omega$ that we say $A \leq_{tt} B$ if there is a total Turing functional $F \colon 2^\omega \to 2^\omega$ such that $F(B)=A$.  This is called <em>truth-table reducibility</em>.  The equivalence classes are called the <em>truth-table degrees</em>.  (The name ""truth-table"" has to do with another definition of this reducibility.)</p>

<p>It is easy to extend this definition to $\omega^\omega$.  Namely $f \leq g$ if there is a total Turing functional $F \colon \omega^\omega \to \omega^\omega$ such that $F(g)=f$.  It is fairly easy to see that (unlike Turing reducibility), this Baire space version gives a strictly larger set of degrees.  (Just take a function $f \in \omega^\omega$ which grows faster than any computable function.)</p>

<p><strong>Does the Baire space version of truth-table reducibility have a standard name?</strong>  (""Truth-table"" no longer seems appropriate here.)</p>

<p><strong>Are there any standard references on it?</strong>  (There are a number of papers and books exploring the truth-table degrees.  I wonder if there are any looking into this version.)</p>

<hr>

<p>Andrej Bauer asked for clarification on what I meant by total Turing functional.  There are a large number of equivalent definitions of what it means for a function $F \colon 2^\omega \to 2^\omega$ or $F \colon \omega^\omega \to \omega^\omega$ to be computable.  For example, $F$ is given by an oracle machine $M$ where $F(g)=f$ means that for all $n$, $M^g(n){\downarrow} = g(n)$.  Here the machine $M$ can query the oracle $g$ for the value of $g(n)$.  (One can also use monotone machines, type 2-machines, etc.  One can also use computable analysis, but that is overkill since we are just working with the spaces $2^\omega$ and $\omega^\omega$ which can be found in any computability theory textbook.) </p>

<p><em>Total</em> just means that $M^g(n)$ halts for all $g \in \omega^\omega$ and $n \in \omega$.  (To be clear, I want $g \in dom(F)$ for all $g$, not just the computable ones---else the degree structure would be trivial.)  </p>

<p><em>Total turing functional</em> means a total computable function $F \colon \omega^\omega \to \omega^\omega$.</p>
",logic
"<p>In the <em>Grundgesetze der Arithmetik</em>, Frege used a number of strange characters for notation. I would be most interested to know anything about the <em>typography</em> (origin, usage and so on) of the strange U with a flourish which occurs in the following.</p>

<p>I am no logician, but I am given to understand that the symbol (U in the following) is used as ""a function-name ‘Ux’ in such a way that if y is the extension of a relation, then Uy is the extension of its inverse"".</p>

<p><a href=""http://i.stack.imgur.com/84YfK.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/84YfK.jpg"" alt=""In context""></a>
<a href=""http://i.stack.imgur.com/F2a5t.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/F2a5t.jpg"" alt=""detail""></a></p>

<p>Thanks in advance!</p>

<p>[edit]</p>

<p>In response to some of the comments as to the relevance of this question to mathematics, I add my motivation for it.  I have heard it said (by a rather famous Frege scholar) that Frege chose his notation by taking whatever was available in the [type] box.  I have come to the view that this is not the case, and that Frege often chose his notation rather carefully. This rather obscure issue leads me to seek the typographic origins of these symbols. I know the origins of most of those in the <em>Grundgesetze</em> (which are surprisingly  diverse: phonetics, commerce, German, Greek, ...) but a few remain unidentified, hence the question.  </p>
",logic
"<p>Every now and then, somebody will tell me about a question. When I start thinking about it, they say, ""actually, it's undecidable in ZFC.""</p>

<p>For example, suppose A is an abelian group such that every short exact sequence of abelian groups 0&rarr;&#8484;&rarr;B&rarr;A&rarr;0 splits. Does it follow that A is free? This is known as <a href=""http://en.wikipedia.org/wiki/Whitehead_problem"">Whitehead's Problem</a>, and it's undecidable in ZFC.</p>

<p>What are some other statements that aren't directly set-theoretic, and you'd think that playing with them for a week would produce a proof or counterexample, but they turn out to be undecidable? One answer per post, please, and include a reference if possible.</p>
",logic
"<p>Let $\mathbf{SBM}$ be the normal modal logic system defined as $\mathbf{T}$ plus the following two axioms:</p>

<p>$$\mathrm{SB}: \Box(\Diamond p \rightarrow p)\rightarrow (p \rightarrow \Box p)$$</p>

<p>$$\mathrm{M}: \Box\Diamond p \rightarrow \Diamond\Box p $$</p>

<p>If I am not mistaken, the frames for $\mathbf{SBM}$ are the same as the frames for $\mathbf{Triv}$ ($\mathbf{T}$ plus $p \leftrightarrow \Box p$), namely the frames where every world sees precisely itself. The argument (sketch) goes like this:</p>

<p>1) $\mathrm{SB}$ corresponds to the following frame condition: if $w$ sees $w'$ then there exists a path back from $w'$ to $w$ (i.e. $w'$ sees $w$ in a finite number of steps) such that $w$ sees all the worlds along the path, including $w$ if the reflexivity condition from $\mathbf{T}$ is added. Let's call this the <em>visible back-path</em> (VBP) condition. It can be proved using induction on the length of the path.</p>

<p>2) $\mathrm{M}$ corresponds to the <em>McKinsey</em> (McK) frame condition: for every partitioning of the set of worlds into two disjoint subsets, every world sees a world whose direct (immediate) successors lie all within the same partition. It can be proved by writing $\mathrm{M}$ as $\Diamond(\Box p \lor \Box \lnot p)$.</p>

<p>3) Consider a reflexive VBP frame that is not a frame for $\mathbf{Triv}$, i.e. there is a world $w$ that sees at least one world $w'$ distinct form itself. For every such world $w'$ define $L_w(w')$ to be the length of the shortest VBP from $w'$ to $w$. Define a partitioning of the set of worlds into two subsets such that the first one includes $w$ and all the worlds $w'$ seen by $w$ for which $L_w(w')$ is even, the second one includes all the remaining worlds. Then the McK frame condition is not satisfied at $w$.</p>

<p>At this point there are two possibilities, but I cannot prove either of them:</p>

<p>a) $p \leftrightarrow \Box p$ is a theorem of $\mathbf{SBM}$, i.e. the system $\mathbf{SBM}$ is the same as $\mathbf{Triv}$.</p>

<p>b) $p \leftrightarrow \Box p$ is not a theorem of $\mathbf{SBM}$, in which case $\mathbf{SBM}$ is distinct from $\mathbf{Triv}$ and therefore incomplete.</p>
",logic
"<p>Hilbert's axioms from Grundlagen der Geometrie involve notions of incidence, between-ness, segment congruence and angle congruence.  </p>

<p>Consider the sub-theories of either Euclidean or hyperbolic geometry involving only the notions of incidence and between-ness.  Of course, a priori, notions of congruence may occur in <em>proofs</em>  (though not statements) of theorems solely about incidence and between-ness.  </p>

<p>As a matter of fact, consider any 2-dimensional compact convex body $B$, with every boundary point extreme, say, but $B$ not affinely equivalent to a round disk.  One can associate to $B$ an incidence geometry after the manner of Beltrami-Klein (with ""lines"" equal to interiors of chords).  Such a geometry will <em>not</em> have an isomorphism to hyperbolic or Euclidean incidence geometries even though Hilbert's axioms about incidence and between-ness will hold!  Indeed the incidence theory of such a quasi-Beltrami-Klein model actually determines $B$ up to an affine transformation.  (<strong>Has this fact been recorded in the literature?</strong>)</p>

<p><strong>Main Question:  Can one formulate a finite, or at least an elegant set of incidence and between-ness axioms, extending Hilbert's, so as to capture the theory of Euclidean and/or hyperbolic incidence?</strong></p>

<p>Added later: In light of Will Jagy's comment I'll sketch very briefly why I think the incidence geometry determines $B$ as much as it does, in case I'm obviously wrong.  Given $B$, one can decorate it in many way with three families of evenly spaced parallel chords with triple intersections wherever intersections occur.  The infinite of maximal configurations of this sort constitute approximations sufficient to recover $B$ up to affine. </p>
",logic
"<p>If $j : V \rightarrow M$ is an elementary embedding, what can we learn in $M$ from $j''ORD$?  That is, what is $M[j''ORD]$?  </p>

<p>In particular, </p>

<blockquote>Is it $M[j''ORD]$ equal to all of $V$?</blockquote>  

<p>If not, do we get a model intermediate between $M$ and $V$?  If $\kappa$ is the critical point of $j$, is $\kappa$ still a large cardinal in $M[j''ORD]$?  I am thinking of $j$ arising from a measure on $\kappa$, but I'm also interested in the more general situation.</p>

<p>My thinking goes like this:  If we have the image of all of $V$, we can reconstruct $V$ itself by taking the Mostowski collapse of $j''V$  (and $j$ is the inverse of the Mostowski collapse).  In $M[j''ORD]$, let's consider the class $W$ of sets with rank in $j''ORD$.  Does the Mostowski collapse of $W$ yield all of $V$, and if not, what's missing?  </p>

<p>EDIT: formatting, clarification of question.</p>
",logic
"<p>I have twice heard it attributed to Dana Scott that he said something to the effect that the consistency of the lambda-calculus was an accident.</p>

<p>Does anyone have a reasonable-sounding source for this?  I find it hard to believe that Scott would talk about the Church-Rosser theorem in this way; I guess that this a mangling of something else he said, or some context is hidden.</p>
",logic
"<p>In this <a href=""http://link.springer.com/chapter/10.1007/978-94-007-0214-1_7"" rel=""nofollow"">Paper</a> of D. Isaacson, it is proved that the true arithmetic($Th(\mathbb{N}$)) is the only $\omega$-consistent and complete extension of $Q$ (Robinson's arithmetic). This, together with the fact that $Th(\mathbb{N})$ is not definable, immediately implies the following result:</p>

<blockquote>
  <p><strong>Proposition</strong>. If $T\supseteq Q$ is a $\omega$-consistent theory such that the set of (Godel numbers of ) axioms of $T$ is definable by a $\Sigma_n$ (or $\Pi_n$) formula (for some $n\in \mathbb{N}$), then $T$ is incomplete.</p>
</blockquote>

<p>It can be proved that this incompleteness phenomenon is <em>essentially non-constructive</em>, which means that there is no computable function $f$ such that for every formula $\sigma(x)$ which defines the set of (Godel numbers of) axioms of an $\omega$-consistent theory $T$, then $f(\ulcorner\sigma(x)\urcorner)\downarrow=\theta$ and $\theta$ is a sentece independent from $T$. It is the case even when we restrict the problem to $\Sigma_4$ formulas. The idea of the proof is as follows:</p>

<blockquote>
  <p>$\omega$-consistency of a r.e. theory can be written as a $\Pi_3$ formula.
  By using the parametric version of the diagonal lemma, we can construct a formula $\psi(x)$ such that :
  $Q\vdash \psi(x)\equiv [f(\ulcorner \psi \urcorner)\downarrow \wedge \omega\text{-}con(Q+f(\ulcorner \psi \urcorner)) \wedge (x=q \vee x=f(\ulcorner \psi \urcorner))] \vee$
  $[f(\ulcorner \psi \urcorner)\downarrow \wedge \omega\text{-}con(Q+\neg f(\ulcorner \psi \urcorner)) \wedge (x=q \vee x=\neg f(\ulcorner \psi \urcorner))]\vee$ 
  $[x=q]$</p>
  
  <p>Where $q$ is the Godel number of conjunction of all axioms of $Q$. Now it is not hard to check that $\psi(x)$ is a $\Pi_3$ and then $\Sigma_4$ formula which defines a $\omega$-consistent theory $T_\psi$, but $f(\psi)$ is not independent from $T_\psi$ (see this <a href=""https://arxiv.org/abs/1506.02790"" rel=""nofollow"">preprint</a> for more details).</p>
</blockquote>

<p>So there is no computable $f$ with the desired property, even when we restrict the problem to $\Sigma_4$-definable theories. My question is about Turing degree of a function like $f$. Obviously one can enumerate the graph $f$ by oracle $0^{(4)}$ (because for a given $\Sigma_4$-definable theory, the problem of provability or refutability of a given sentence can be decided by oracle $0^{(4)}$). Hence it is a $0^{(4)}$-r.e. set, so its Turing degree is less that (or equal to) $0^{(5)}$. </p>

<p><strong>Question:</strong> Is this Turing degree (necessarily) $0^{(5)}$ or it can be strictly less than $0^{(5)}$?</p>
",logic
"<p>It is well-known that the category of local rings and <em>ring</em> homomorphisms admits an axiomatisation in coherent logic. Explicitly, it is the coherent theory over the signature $0, 1, -, +, \times$ with the usual axioms for rings, plus the axioms
$$0 = 1 \vdash \bot$$
$$\top \vdash (\exists b . \; a \times b = 1) \lor (\exists b . \; (1 - a) \times b = 1)$$
See, for example, [<em>Sheaves in Geometry and Logic</em>, Ch. VIII, §6]. Unfortunately, because homomorphisms are only required to commute with the various things in the signature, the homomorphisms here are just ring homomorphisms and need not be local. It appears to me that the neatest way to fix this is to introduce a unary relation symbol $(\quad) \in \mathfrak{m}$, with the intention that $\mathfrak{m}$ is interpreted as the unique maximal ideal of the local ring. Then, by the usual rules for homomorphisms of models, a homomorphism $R \to R'$ must map elements of $\mathfrak{m}$ to elements of $\mathfrak{m}'$. But is there a way to axiomatise the theory so that</p>

<ol>
<li><p>we get a coherent, or at least geometric theory, and</p></li>
<li><p>the category of models in $\textbf{Set}$ is indeed the category of local rings and local ring homomorphisms, and</p></li>
<li><p>the structure sheaf homomorphism $f^\ast \mathscr{O}_{Y} \to \mathscr{O}_{X}$ of morphism of locally ringed spaces $X \to Y$ is a homomorphism in the category of models for this theory?</p></li>
</ol>

<p>Ideally, we'd like to define $\mathfrak{m}$ to be the subsheaf of nowhere invertible sections defined by
$$\{ s \in \mathscr{O} : \nexists t . \; s \times t = 1 \}$$
but unfortunately $\nexists t . \; s \times t = 1$ is not a geometric formula. (The formula $\forall t . \; s \times t \ne 1$ is equivalent to the previous one but has the same defect.) We can salvage one half of the biimplication as the geometric sequent
$$(a \in \mathfrak{m}) \land (\exists b . \; a \times b = 1) \vdash \bot$$
which merely expresses the requirement that ""$a$ is not in $\mathfrak{m}$ if $a$ is invertible"", but we also need to express the requirement that ""$a$ <em>is</em> in $\mathfrak{m}$ if $a$ is <em>not</em> invertible"". One possibility is the following:
$$\top \vdash (\exists b . \; a \times b = 1) \lor (a \in \mathfrak{m})$$
These two axioms appear to give the correct characterisation of $\mathfrak{m}$ in intuitionistic first order logic: it is easy to derive from these axioms that
$$a \in \mathfrak{m} \dashv \vdash \nexists b . \; a \times b = 1$$
so the interpretation of $\mathfrak{m}$ is completely determined by the axioms, at least in a topos. </p>

<p>But does every local ring object (in the sense of the first paragraph) admit an $\mathfrak{m}$ satisfying these axioms? The answer appears to be no, for the reason that these axioms assert that a every section of a sheaf of a local ring admits an open cover of the space by open sets on which the restriction is either invertible or nowhere invertible – and this is certainly not true in the contexts of interest. Can this idea be rescued with a more clever approach?</p>
",logic
"<p>Let me start with Helly's theorem: Let $A_1$, $A_2$, ..., $A_{n+2}$ be $n+2$ convex subsets of $\mathbb R^n$. If any $n+1$ of these subsets intersect (this means: have nonempty intersection), the so do all $n+2$.</p>

<p>This assertion is, logically speaking, a definite clause: All conditions are of the form ""some subsets intersect"", and so is the assertion. Generally, a definite clause about intersection of convex sets looks like this: Given some sets $S_1$, $S_2$, ..., $S_k$ and $T$ and a family $\left(F_a\right)_{a\in S_1\cup S_2\cup ...\cup S_k\cup T}$ of convex subsets of $\mathbb R^n$ indexed by the elements of $S_1\cup S_2\cup ...\cup S_k\cup T$, we claim that if every $i\in\left\lbrace 1,2,...,k\right\rbrace$ satisfies $\bigcap\limits_{a\in S_i}F_a\neq\emptyset$, then $\bigcap\limits_{a\in T}F_a\neq\emptyset$.</p>

<p>Now it is an easy exercise to see that every tautological (= true for every choice of convex subsets) definite clause about intersection of convex sets is derivable using trivial properties of intersection (such as $A\cap A=A$, $A\cap B=B\cap A$ and $A\cap \left(B\cap C\right)=\left(A\cap B\right)\cap C$) and Helly's theorem only. (Note that we consider $n$ as given a priori and fixed during our proof, so we can't project on a subspace and use Helly for a smaller $n$, for example. We really only can manipulate intersections and use Helly for various intersection of convex subsets. I could write up what we can do as a natural deduction system, but it is pretty obvious.)</p>

<p>Now, what if we allow indefinite clauses? These are statements of the form: Given some sets $S_1$, $S_2$, ..., $S_k$ and $T_1$, $T_2$, ..., $T_l$ and a family $\left(F_a\right)_{a\in S_1\cup S_2\cup ...\cup S_k\cup T_1\cup T_2\cup ...\cup T_l}$ of convex subsets of $\mathbb R^n$ indexed by the elements of $S_1\cup S_2\cup ...\cup S_k\cup T_1\cup T_2\cup ...\cup T_l$, we claim that if every $i\in\left\lbrace 1,2,...,k\right\rbrace$ satisfies $\bigcap\limits_{a\in S_i}F_a\neq\emptyset$, then at least SOME $j\in\left\lbrace 1,2,...,l\right\rbrace$ satisfies $\bigcap\limits_{a\in T_j}F_a\neq\emptyset$.</p>

<p>What set of ""axioms"" (such as Helly's theorem) do we need in order to prove such indefinite clauses, if they are tautological? By ""prove"" I mean prove without using the convexity of the sets or that the sets are set at all (a pointfree approach, so to speak) - only using formal properties of $\cap$, logic (let's say constructive) and these axioms. Obviously Helly alone is not enough anymore; for example, for $n=1$ we have this here: If $A$, $B$, $C$, $D$ are four convex subsets of $\mathbb R^n$ such that $A\cap B$, $B\cap C$, $C\cap D$ and $D\cap A$ are nonempty, then at least one of the sets $A\cap C$ and $B\cap D$ are nonempty.</p>

<p>A connection to temporal logic is possible, but to be honest I have no idea about temporal logic; if somebody could point me to a reference that is of help here this might change...</p>
",logic
"<p>This question is not precise, but I believe has a precise formulation. </p>

<p>Consider a mathematical theorem which gives an equivalency between two conditions. As an extreme example:</p>

<p>\begin{theorem}
A compact 3-manifold is simply-connected if and only if it is homeomorphic to the 3-sphere.
\end{theorem}
The if direction is an exercise in a first course in algebraic topology, and the only if direction is a celebrated result of Perelman.</p>

<p>The question is, are there results which have been shown that one direction of a proof is ""harder"" than the other? </p>

<p>Certain equivalence proofs seem to have the same complexity in both directions, when all the steps of the proof are reversible. </p>

<p>I think this can be formulated as a precise way, by asking for the length of a proof in a standard proof system. One might also be able to give a precise formulation in terms of the Kolmogorov complexity of a proof. </p>

<p>On the other hand, I can imagine results of the sort that say that for any equivalency, there is a proof system for which one direction is shorter than the other, and another proof system where the reverse holds. So I'm not certain that this question is well-defined. But I think it is well-defined for certain proof systems. </p>

<p>So a more precise question: <strong>Is there an equivalence theorem and a proof system, for which it has been shown that one direction of a proof must have a longer proof than the other direction?</strong> </p>
",logic
"<p>In practice (say, in computer science), collections with many ""labels"" (""identities""), or collections which occur in many copies, are more frequently used than sets. Such collections do not satisfy the extensionality axiom, i.e. two different such collections A and B can have same elements (I would then say that A and B are ""extensionally equivalent""). I am aware that extensionality axiom is independent of other axioms in ZF and possibly in other axiomatic set theories. </p>

<p>Is there any (systematic) research of a set theory without extensionality axiom? Say, how a model of such a theory can be obtained in ZF, or whether the model of such a theory ratio the ""extensionality equivalence"" is a model of a set theory with extensionality axiom? It sounds probable that such collections have to do with multisets, i.e. sets, the elements of which can occur in many copies - the atoms must be allowed to occur in many copies, once such collections can have many copies). By the way, is there an axiomatized multiset theory? </p>
",logic
"<p><strong>Question 1:</strong> Suppose that $V[G]$ is a set generic extension of $V$ by some forcing notion $P\in V,$ and suppose that $W$ is a model of $ZFC, V \subset W \subset V[G].$ Can we find a forcing notion $Q\in V$ and a map $\pi: P\to Q$ such that:</p>

<p>1) $|Q|\leq |P|,$</p>

<p>2) $\pi$ and $G$ generate a filter $H$ which is $Q-$generic over $V$ (for example if $\pi$ is a projection, then we can take $H$ to be the filter generated by $\pi''[G]$),</p>

<p>3) $W=V[H].$</p>

<p><strong>Remark.</strong> Let $B=r.o(P).$ Then for some $\bar{G}, B-$generic over $V$, we have $V[G]=V[\bar{G}].$ Also for some complete subalgebra $C$ of $B, W=V[\bar{G}\cap C].$ If $P$ satisfies the $\kappa-c.c.$, then $|C|\leq |B| \leq |P|^{&lt;\kappa},$ so clearly the answer is yes if $|P|=|P|^{&lt;\kappa}.$ </p>

<p><strong>Question 2:</strong> Suppose that $P, Q\in V$ are two forcing notions such that for any $G$ which is $P-$generic over $V$, there is $H\in V[G]$ which is $Q-$generic over $V$. Is there a map $\pi: P\to Q$ such that for any $G$ as above, we can choose $H$ to be the filter generated by $\pi[G]$?</p>
",logic
"<p>This is a question which I suspect has an absurdly easy answer, but I'm not seeing it.</p>

<p>Let $\langle\cdot,\cdot\rangle:\omega^2\rightarrow\omega$ be your favorite pairing map (for me, this is the Cantor pairing function $(x, y)\mapsto{(x+y)(x+y+1)\over 2}+y$). Then, for $\mathcal{U}$ any ultrafilter on $\omega$, we can define a map $$m_\mathcal{U}: \mathcal{P}(\omega)\rightarrow\mathcal{P}(\omega): X\mapsto\lbrace j: \lbrace i: \langle i, j\rangle\in X\rbrace\in \mathcal{U}\rbrace.$$ The intuition behind this, for me, is that we take $X$, decompose it into rows, and treat each row as a guess at a mysterious set $\hat{X}$. The actual set $\hat{X}$ is the set of all natural numbers $j$ such that ""most"" of the rows of $X$ guess that $j$ is in $\hat{X}$. Topologically speaking, these maps are very badly behaved (unless $\mathcal{U}$ is principal of course); I don't know of any good picture of them besides this guessing idea.</p>

<p>This lets $\mathcal{U}$ act on collections of sets of natural numbers: for $\mathcal{C}\subseteq\mathcal{P}(\omega)$, let $$\mathcal{U}(\mathcal{C})=\lbrace m_\mathcal{U}(X): X\in\mathcal{C}\rbrace.$$ Mild closure properties of $\mathcal{C}$ imply that for all ultrafilters $\mathcal{U}$, we have $\mathcal{U}(\mathcal{C})\supseteq\mathcal{C}$; in the other direction, it is easy to construct, for any ultrafilter $\mathcal{U}$ and any $\mathcal{D}\subseteq\mathcal{P}(\omega)$, a $\mathcal{C}\subseteq\mathcal{P}(\omega)$ such that $\mathcal{D}\subseteq\mathcal{C}$ and $\mathcal{U}(\mathcal{C})=\mathcal{C}$. </p>

<p>I'm playing around with these maps for the heck of it; I don't know of any mathematical significance they have (although I'd be very interested if someone could point me towards a source where they're already studied). While fooling around, I ran into the following question:</p>

<p>Let $\mathcal{C}\subseteq\mathcal{P}(\omega)$. Say that an ultrafilter $\mathcal{U}$ on $\omega$ is <em>definable in $\mathcal{C}$</em> if $\mathcal{U}(\mathcal{C})=\mathcal{C}$ and there is some formula $\phi$ with parameters from $\mathcal{C}\cup\omega$ and two free set variables $\phi(X, Y)$ in the language of second-order arithmetic such that $$\forall A, B\in\mathcal{C}, m_\mathcal{U}(A)=B\iff (\omega,\mathcal{C})\models\phi(A, B).$$ (In this case, say $\mathcal{U}$ is definable in $\mathcal{C}$ via $\phi$) My question is this:</p>

<p>(*) What are the $\mathcal{C}$, $\mathcal{U}$ such that $\mathcal{U}$ is definable in $\mathcal{C}$?</p>

<p>Principal ultrafilters are definable in reasonable $\mathcal{C}$, but I can't ""construct"" an example of any non-principal ultrafilter being definable in any $\mathcal{C}$ that isn't stupid (say, $\mathcal{C}=\lbrace A\rbrace$, $m_\mathcal{U}(A)=A$, so $\phi(X, Y)\equiv X=Y$); on the other hand, I have no reason to believe that nontrivial examples don't exist.</p>

<p>There is also the stronger notion of <em>extendible definability</em>: An ultrafilter $\mathcal{U}$ is <em>extendibly definable in $\mathcal{C}$</em> if for some formula $\phi$, $\mathcal{U}$ is definable in $\mathcal{C}$ via $\phi$ and for all $\mathcal{D}\supseteq\mathcal{C}$, there is some $\mathcal{E}\supseteq \mathcal{D}$ such that $\mathcal{U}$ is definable in $\mathcal{E}$ via $\phi$. For instance, every principal ultrafilter is extendibly definable in any sufficiently closed $\mathcal{C}$.</p>

<p>(**) Are there any examples of non-principal ultrafilters being extendibly definable?</p>

<p>A negative answer to this question is plausible to me, I just have no idea how to approach this.</p>

<p>Thanks!</p>
",logic
"<p>Are there examples of independence results over subsystems of true second order arithmetic that cannot be established using omega-models? To rule out trivial examples, let us assume that the base theory extends true first order arithemtic. A non example of such a statement would be Ramsey theorem for pairs since there is a computable coloring of pairs of integers into two colors without a computable (even from the halting problem, Jockusch) infinite homogeneous set.</p>

<p>An example of a use of non-omega models appears <a href=""http://math.berkeley.edu/~slaman/papers/SRT22.pdf"" rel=""nofollow"">here</a> - Also, see the introduction and question 6.1 in this paper.</p>

<p>I am not an expert in reverse mathematics so please feel free to offer any interesting known facts known to you here.</p>
",logic
"<p>A result commonly, and <a href=""http://mathoverflow.net/a/223245/16537"">probably erroneously</a>, attributed to W. Sierpiński is that every non-atomic, countably additive, nonnegative measure $\mu: \Sigma \to \bf R$, where $\Sigma$ is a sigma-algebra on a set $S$, has the weak, and hence the strong, Darboux property, which means that for every $X \in \Sigma$ and $a \in [0, \mu(X)]$ there exists $Y \in \Sigma$ such that $Y \subseteq X$ and $\mu(Y) = a$.</p>

<p>The theorem is provable in ZFC, and I'm just curious to know if it is actually equivalent to the axiom of choice.</p>

<p>In either case, I would very much appreciate a reference where the question is answered: Before asking, I browsed through Howard and Rubin's <em>Consequences of the Axiom of Choice</em>, but couldn't find anything close to what I'm looking for.</p>
",logic
"<p>I am researching a system that was designed by myself and what I call PCA (Primitive Closure Arithmetic), because it looks like PRA.</p>

<p>The differences are:
- PRA uses recursive definition with a descending parameter. While PCA uses closures.
- PRA has functions that have always exactly one result. In PCA there are relations, that may have no results (for instance in case of an endless loop) or multiple.
- In PRA every theory consists of the equality of two primitive recursive functions (e.g. F(x) = G(x)). In PCA it consists of an inequality of two relations (e.g. F(x,y) => G(x,y)).</p>

<p>The similarities are that you always compare two functions/relations and that it is logic free. No logical symbols, no quantifiers, no 'and', no 'or' etc. The boolean operators must first be defined.</p>

<p>PCA is more expressive than PRA. For instance, you can not express that there are infinite prime numbers in PRA, but you can in PCA. Still PCA is finitistic, because it has only potential infinite, but no actual infinite (it doesn't have a infinite set).</p>

<p>PCA might be interested for proving correctness of programs. Loops without a descending variable can easily be translated to a closure, but not to PRA. 
But of course, you need to have some sort of love for weak systems.</p>

<p>My question is, for my further research, does something like the system I described already exists? Before I continue with this, I want to be sure that I don't re-inventing something. In my search I already did, I couldn't find something in this direction.</p>

<p>Thanks in advance.</p>

<p>Edit, a more formal description of the language.</p>

<p>Value-expressions consists of 0 or variables, $x$, $x_1$, $x_2$, $y$, etc.</p>

<p>There are two pre-defined predicate, the equality:</p>

<p>$$
x = y
$$</p>

<p>And the successor operator $y = x + 1$:</p>

<p>$$
s(y, x)
$$</p>

<p>A new predicate can be defined, by the conjunction of predicates already defined. For instance, a relation that adds two can be defined as follows:</p>

<p>$$
AddTwo(y, x) := s(y, z), s(z, x)
$$</p>

<p>Any variable that appears on the right side, but not on the left side, is existential automatically (in the example above the variable $z$).</p>

<p>You can take transitive reflexive closure of any predicate with an even number of parameters. In this way, the natural numbers can be given in a ""potential infinite"" way:</p>

<p>$$
N(x) := s^*(x, 0)
$$</p>

<p>Closures can also be used in defining new predicates. If the predicate contains more than 2 variables, then the closure is over multiple variables at once. The even variables are connected to the odd ones. In this way the addition relation can be defined ($z = x + y$):</p>

<p>$$
PlusMinus(y, x, w, v) := s(y, x), s(v, w)
$$
$$
Add(z, x, y) := PlusMinus^*(z, x, y, 0), N(x)
$$</p>

<p>A theorem is a comparison of two predicates:
$$
Even(x) := AddTwo^*(x, 0)
$$
$$
N(x) \Leftarrow Even(x)
$$
Which says that the even numbers are a subset of the natural numbers. The $\Leftarrow$ is preferred over $\Rightarrow$ because it is more convenient when making proofs.</p>

<p>The main axiom scheme is of replacement. The right side of a theorem can be made stronger (more restrictive). </p>

<p>There are more axioms, but the most interesting is the inductive scheme. The scheme is not on numbers, but on the closure:</p>

<p>$$
H(x, y) := F(x, z), G(z, y)
$$
$$
H'(x, y) := F(x, z), G^*(z, y)
$$
If:
$$
F(x, y) \Leftarrow H(x, y)
$$
Then:
$$
F(x, y) \Leftarrow H'(x, y)
$$</p>

<p>Where $x$, $y$ and $z$ can also be multiple variables. In plain English it says, that if applying a certain relation does not alter a property, then the property is also not altered if applied multiple times (the closure).</p>

<p>I hope this outlines the system in it most basic form. The complete axioms and schemes are of course more elaborate. </p>
",logic
"<p>Nature just published a paper by Cubitt, Perez-Garcia and Wolf titled <a href=""http://www.nature.com/nature/journal/v528/n7581/full/nature16059.html"">Undecidability of the Spectral Gap</a>, there is an <a href=""http://arxiv.org/pdf/1502.04573v2.pdf"">extended version</a> on arxiv which is 146 pages long. Here is from the abstract:""<em>Many challenging open problems, such as the Haldane conjecture, the question of the existence of gapped topological spin liquid phases, and the Yang–Mills gap conjecture, concern spectral gaps. These and other problems are particular cases of the general spectral gap problem: given the Hamiltonian of a quantum many-body system, is it gapped or gapless? Here we prove that this is an undecidable problem. Specifically, we construct families of quantum spin systems on a two-dimensional lattice with translationally invariant, nearest-neighbour interactions, for which the spectral gap problem is undecidable</em>"".</p>

<p>I am curious about the undecidable part. The abstract says ""<em>our result implies that there exists no algorithm to determine whether an arbitrary model is gapped or gapless, and that there exist models for which the presence or absence of a spectral gap is independent of the axioms of mathematics</em>"". ""Axioms of mathematics"" is kind of vague, so in the extended version they phrase it in a Gödelian manner:""<em>Our results imply that for any consistent, recursive axiomatisation of mathematics, there exist specific Hamiltonians for which the presence or absence of a spectral gap is independent of the axioms</em>"". But still, axiomatization of which mathematics, how much mathematics do they need to construct their Hamiltonians. Is it real analysis? ZF? ZFC? I can't figure it out even from their theorem statements.</p>

<blockquote>
  <p>Is this a mathematical proof or something at the ""physical level of rigor""? If so, does it produce ""concrete"" undecidable statements, or are these Hamiltonians as obscure as ""I am unprovable""? Does it represent a new way of proving independence results compared to forcing, etc.? In other words, is it an advance on Gödel sentences and the continuum hypothesis? </p>
</blockquote>

<p>EDIT: <a href=""http://m.phys.org/news/2015-12-quantum-physics-problem-unsolvable-godel.html#"">Cubitt gave an interview</a> where he commented on the nature of the result informally:""<em>It's possible for particular cases of a problem to be solvable even when the general problem is undecidable, so someone may yet win the coveted $1m prize... The reason this problem is impossible to solve in general is because models at this level exhibit extremely bizarre behaviour that essentially defeats any attempt to analyse them... For example, our results show that adding even a single particle to a lump of matter, however large, could in principle dramatically change its properties</em>"".</p>
",logic
"<p>The set theory <a href=""http://ncatlab.org/nlab/show/ETCS"">ETCS</a> famously comes without the Replacement axiom schema (or an equivalent) that is part of ZFC. One (to me, not apparently useful) set that one cannot build in ETCS is $\coprod_{n\in \mathbb{N}} P^n(\mathbb{N})$. <a href=""https://mathematicswithoutapologies.wordpress.com/2015/06/04/does-mathematics-without-apologies-have-a-real-author/comment-page-1/#comment-410"">Jacob Lurie pointed out</a> on Michael Harris' blog<sup>1</sup> the example of taking a Banach space $V$ and considering the colimit of the sequence $V \to V^{**}\to V^{*4} \to \cdots$. <a href=""https://mathematicswithoutapologies.wordpress.com/2015/06/04/does-mathematics-without-apologies-have-a-real-author/comment-page-1/#comment-424"">Yemon Choi responded</a> to a foolish suggestion of mine that this sequence (or rather, the related cosimplicial object) is in fact of use.</p>

<p>This got me to thinking that from a category-theoretic point of view, we are used to not having enough colimits (say in geometric settings, like schemes, manifolds, and so on) or limits (for instance in settings like finite groups etc), and this is deftly sidestepped by using a colimit completion. One can consider ind-schemes, or differentiable stacks, etc etc. Why should ETCS be any different, apart from intending to be the primordial category?</p>

<p>What stops me from working, when I need to, in a slightly larger category that is in a sense a colimit-completion of an ETCS category, with the understanding that most of the time I'm interested in objects in my original category, but sometimes constructions I'm interested in sit outside it? The original example above is perfectly well represented as the sequence $k\mapsto \coprod_{0\leq n\leq  k} P^n(\mathbb{N})$, with the obvious inclusions between them.</p>

<p>Note that I'm not asking that arbitrary objects in the completed category are necessarily the stuff of ordinary mathematics, or that the completed category is a topos, or a model of ETCS. But what can go wrong with this approach? What are the usual uses of Replacement in ""ordinary mathematics"" (almost anything that's not ZFC-and-friends) that could/couldn't be sorted by the method proposed above?</p>

<hr>

<p><sup>1</sup> The context of the discussion was the effect on ordinary mathematics the discovery that ZFC was inconsistent. Tom Leinster argues (and I agree) that the most likely culprit would be Replacement, since the rest of ZFC is essentially equivalent to ETCS, and the axioms of ETCS encode the operations on sets that underly day-to-day practice of people who aren't set theorists.</p>

<p>[EDIT: On reflection, I'm putting words into Tom's mouth a little here. The actual point he has made is that <em>if</em> a contradiction were found with using Replacement, it wouldn't affect most mathematicians, but it a contradiction were found in ETCS (equivalently, BZC) then we could start to worry. If we assume that 'ordinary' mathematics is consistent, as it seems to be, then one might make the---justified or not---leap that a little-used axiom is the place a contradiction might be found, if one existed. As others have pointed out in the comments below, Comprehension is also a contender for a 'risky' axiom.]</p>
",logic
"<p>Suppose that $\langle\mathbb{P_\alpha,\dot Q_\beta}\mid \beta&lt;\delta,\alpha\leq\delta\rangle$ is a system of iterated forcing.</p>

<p>Let $\dot a$ be a name in $\mathbb P_\delta$, and let $G_\alpha$ be a generic for $\mathbb P_\alpha$ for $\alpha&lt;\delta$. Is there a reasonable sense in which we can interpret $\dot a$ using $G_\alpha$?</p>

<p>If so, is the result of this partial interpretation a $\mathbb P_{\alpha\delta}$-name (i.e. the quotient forcing) for $\dot a$?</p>

<p>(If it matters, we can assume that the iteration is finite support, but a general answer would be great.)</p>
",logic
"<p>Is it consistent intuitionistically (in the sense of topos theory) for there to be a surjection from the natural numbers to the (Dedekind, let us say) real numbers? [I've managed to convince myself this happens in the effective topos, but not so convincingly as I'd like; I suspect others will be able to answer more confidently and cleanly...]</p>
",logic
"<p><strong>Short version</strong>: what can we say about the place of idempotent ultrafilters in the Rudin-Keisler ordering?</p>

<p><strong>Longer version</strong>:</p>

<p>If $U$, $V$ are (nonprincipal) ultrafilters on $\omega$, then we write $U\ge_{RK}V$ in case there is some function $f:\omega\rightarrow\omega$ such that $$ \forall X\subseteq\omega,\quad f^{-1}(X)\in U\iff X\in V.$$</p>

<p>An ultrafilter $U$ is <em>Ramsey</em> if given any two-coloring of pairs $c: [\omega]^2\rightarrow 2$, there is a homogeneous set for $c$ in $U$. Equivalently, $U$ is Ramsey if whenever $\lbrace C_n\rbrace_{n\in\omega}$ is a partition of $\omega$ with each $C_n\not\in U$, there is some $H\in U$ such that for all $n\in\omega$, $$\vert H\cap C_n\vert=1.$$ An ultrafilter $U$ is <em>idempotent</em> if $U\oplus U=U$, where $$ V\oplus W=\lbrace X: \lbrace x: \lbrace y: x+y\in X \rbrace \in W \rbrace \in V\rbrace.$$ Idempotent ultrafilters can be proved to exist in $ZFC$: this amounts to showing that $\oplus$ is left-continuous and associative on the compact space $\beta\mathbb{N}$, and then applying Ellis' theorem that every left-continuous semigroup on a compact space has an idempotent element. By contrast, Ramsey ultrafilters cannot be shown to exist in $ZFC$, although their existence is equiconsistent with $ZFC$ (in particular, if the Continuum Hypothesis - or weaker statements - holds, then there are Ramsey ultrafilters).</p>

<p>Now, an easy argument shows that no Ramsey ultrafilter is idempotent. On the other hand, the Ramsey ultrafilters enjoy a special property with respect to the RK-ordering: they are precisely the RK-minimal ultrafilters. So combining these facts shows that no idempotent ultrafilter can be RK-minimal.</p>

<p>My question is, what else can be said about the idempotent ultrafilters in terms of RK-reducibility? For example, can we have an idempotent ultrafilter U with exactly one RK-class of (necessarily, Ramsey) ultrafilters strictly RK-below U? This seems clearly impossible, but I don't see how to prove it.</p>

<hr>

<p>Motivation: a few weeks ago, I taught a one-week course on the proof of Hindman's theorem from additive combinatorics using idempotent ultrafilters. On the last day, I talked a bit about other types of ultrafilters, and spent a bit of time defining Ramsey ultrafilters and explaining (not proving) their place in the RK-ordering. One of my students asked whether anything similar could be said about idempotent ultrafilters; besides the obvious, I couldn't come up with anything, so I'm asking here.</p>
",logic
"<p>Are there existential theorems of ZFC, or PA say, with no witnesses?</p>

<p>Ie does there exist a formula $\phi$ such that ZFC $\vdash\exists x \phi(x)$, but for all numerals $\underline{n}$, ZFC $\nvdash \phi(\underline{n})$?</p>

<p>Can you give an example of such a formula?</p>
",logic
"<p>Could you please give examples of fundamental questions in mathematics (let us say, pure mathematics) which were resolved <em>fundamentally</em> by the use of computers? More precisely, are there examples that you can compare to the accomplishments that Gauss, Ramanujan, Riemann, Grothendieck, Deligne, Wiles, Perelman, etc. obtained? Let me make precise that my question does not mean that I do not advocate the use computers as a powerful tool.    </p>
",logic
"<p>Kripke Platek set theory has collection instead of replacement, and it is a weakening of KP if one has replacement instead of collection. Call KP minus collection plus replacement KF for <em>Kripke Fraenkel</em>. Is KF weaker than KP in that some transfinite recursion can be done by KP which cannot be done by KF? If so, is that a difference inherited by strengthened theories as $\Sigma _{n} KP$ and $\Sigma _{n} KF$ for $n&gt;1$?</p>
",logic
"<p>If ZF has a standard model there is a least ordinal $\sigma$ such that $L_{\sigma}$ is a model of ZFC. What is $\sigma$ called?</p>
",logic
"<p>It is well known that every partial order on a set can be extended
to a linear order on that set. That is, for every partial order
$\lhd$ on a set $X$, there is a linear order $\prec$ on $X$ such
that ${\lhd}\subseteq\prec$, meaning $a\lhd b\implies a\prec b$. In the
most general case, with uncountable $X$, one appeals to Zorn's
lemma. For relations on $\mathbb{N}$, however, the linearization
process is effective. My question concerns the relative complexity
of such linearizations $\prec$ in comparison with the original
order $\lhd$. (See also Jirka Hanika's
related question on <a href=""http://mathoverflow.net/questions/89527/is-minp-search-problem-partial-order-reducible-to-minl-linear-order-sea"">reducing minimal element search for partial orders to that of linear orders</a> in the
case of finite orders.)</p>

<p><b>Question.</b> Does every polynomial time decidable partial order
relation $\lhd$ on $\mathbb{N}$ extend to a polynomial time
decidable linear order relation on $\mathbb{N}$?</p>

<p>I expect not. I think there will be a polynomial time decidable
partial order relation on $\mathbb{N}$ that does not extend to any
polynomial time linear order. The reason I believe so is that the
natural method of constructing a linear order extending a given
partial order seems to proceed fundamentally in series rather than
parallel, in the sense that one gradually linearizes increasing
portions of the partial order, but one must keep track of what one
did earlier, in order not to conflict with later decisions. But
with a polynomial time construction, one cannot afford to inspect
the earlier parts of the linearization.</p>

<p>Meanwhile, every computable partial order $\lhd$ on $\mathbb{N}$
does extend to a computable linear order $\prec$ on $\mathbb{N}$, and this is what I meant when I said that linearizaton is effective, by
the following procedure: at stage $n$, we know how the numbers up
to $n$ relate with respect to $\lhd$ and we have built the desired
relation $\prec$ on the numbers below $n$. The new number $n$
divides this linear order into those that are $\lhd$-below $n$,
incomparable to $n$, and $\lhd$-above $n$. We may now proceed to
linearize $n$ into the order by placing $n$ as high as possible,
say, above all the nodes so far to which it is incomparable, if
any. This recursive procedure produces a linear order extending
$\lhd$.</p>

<p>The point for the question is that this algorithm seems to require
an exponential increase in the time complexity, since on a given
input one must construct the relation on all nodes up to that node
before knowing what to do, and this takes exponential time. Indeed,
it isn't even clear whether one should be able to find a
linearization in the class NP.</p>

<p><b>Question.</b> Does every polynomial time partial order extend to
an NP linear order?</p>

<p>I expect not, since even a polynomial size certificate seems
insufficient in general to track the linearization construction,
which has exponential size.</p>

<p>Finally, let me point out that the analogue at the level of c.e.
orders attains the negative result.</p>

<p><b>Theorem.</b> There is a c.e. partial order $\lhd$ on
$\mathbb{N}$ that does not extend to any c.e. linear order on
$\mathbb{N}$.</p>

<p>Proof. Part of the point is that every c.e. linear order is
actually decidable. Let $A,B\subset\mathbb{N}$ be computable
inseparable c.e. sets, meaning that they are disjoint c.e. sets and
there is no decidable set containing $A$ and disjoint from $B$.
Define the partial order $\lhd$ by placing every element of $A$
below $0$ and $0$ below every element of $B$, but otherwise
elements are incomparable. This is a c.e. relation, since given two
numbers $a$ and $b$, we can say how they are related once they are
enumerated into $A$ or $B$, and otherwise they are unrelated. But
if the relation extends to a linear order $\prec$ on $\mathbb{N}$,
then the set of $\prec$-predecessors of $0$ will be a computable
separation of $A$ and $B$, a contradiction. QED</p>

<p>Can one similarly employ a polytime version of inseparability to
answer the main question?</p>

<p>There are similarly many analogues of the main question in terms of other complexity classes. Please answer if you have interesting positive or negative results for any of them.</p>
",logic
"<p>Assume a metatheory that supports lambda-abstraction, and an object language that is merely first-order. Now let $\varphi$ denote a formula in the object language with one free variable $x$. Then we can write $\lambda x. \varphi$ in order to mean the function that accepts an expression $E$ in the object language and returns the formula $\varphi[x/E].$ Hence $\lambda x. \varphi$ works just like a predicate symbol. For example, if $P$ is a predicate symbol in the object language and we let $Q$ equal $\lambda x.\varphi$, then $\forall y(Py \rightarrow Qy)$ is a well-formed formula, despite that $Q$ is not a predicate symbol.</p>

<blockquote>
  <p><strong>Question.</strong> What do we call functions (like $\lambda x. \varphi$) that behave like predicate symbols?</p>
</blockquote>

<p>For example, in the following sentence, what word should go in place of [///]?</p>

<blockquote>
  <p>Let $Q$ denote the [///] $\lambda x.\varphi.$</p>
</blockquote>

<p>Obviously, the word ""function,"" but its not really a good fit, being far too general.</p>
",logic
"<p>I have a basic working knowledge of category thoery since I do research in programming languages and typed lambda-calculus.  Indeed, I have refereed many papers in my area based on category theory.</p>

<p>But, in doing this refereeing, and in reading many important categorial papers in my area, I simply find the terminology and presentation style extremely opaque compared to style that I prefer which instead emphasizes logic inference rules and extensions of the lambda calculus.</p>

<p>Given the (extended) Curry-Howard Isomorphism between programming languages, logics, and categories, it's clear that I can understand the concepts I need by mapping category theory into the other two.  But, am I missing something in the process, or are the papers I'm refereeing just making things more difficult than they need to be? </p>
",logic
"<p>It is a trivial fact that forcing can not produce finite sets of ground model objects. However there are situations, 
where we can use forcing to prove the existence of finite objects with some properties. For example consider the following 
result of Shelah (I learned this example from the answer given by Prof. Komjath in <a href=""http://mathoverflow.net/questions/29945/forcing-as-a-tool-to-prove-theorems"">Forcing as a tool to prove theorems</a>):</p>

<blockquote>
  <p><strong>Theorem (Shelah)</strong> There exists  a finite $K_4$-free graph which, when the edges colored by $2$ colors, always contains a 
  monocolored triangle.</p>
</blockquote>

<p>Shelah's proof of the theorem is simply as follows: 
He constructs a forcing extension which adds a graph $X$ with the same property but 
with $\aleph_0$ colors. Then $X$ has the edge-coloring property for $2$ colors, 
as well. Then using compactness theorem, $X$ must contain a finite subgraph $Y$ with the same property.
 As forcing cannot create new finite graphs, $Y$ is already present 
in the ground model.  By Godel, $ZFC$ proves that there is such a graph. </p>

<p>Now my question is that if there are more examples of the above kind. To be more precise:</p>

<blockquote>
  <p><strong>Question 1.</strong> Are there any other examples for producing some finite object $Y$ (with some properties)
  in the following way:</p>
  
  <p>1) We provide a suitable generic extension in which there is an infinite object $X$ with the required properties,</p>
  
  <p>2) By compactness (or other devices), we can conclude that there must be a finite subset $Y$ of $X$ with the same properties,</p>
  
  <p>3) So we can conclude that the object must exist in the ground model.</p>
</blockquote>

<p><strong>Remark 1.</strong> I am mostly interested in examples where it is not known (or it is difficult) to produce such finite object directly</p>

<p><strong>Remark 2.</strong> It seems that some partition type theorems are of this type: It is possible to derive some kind of 
finite partition theorems (like finite Ramsey theorem) using infinite versions of them. So if we can prove 
the infinite version of these partition theorems, then we have produced examples of the required type 
(there are cases where we can prove infinite partition theorems using forcing). </p>

<blockquote>
  <p><strong>Question 2.</strong> Is Shelah's result the first non-trivial example of an answer to question 1? Are there othe non-trivial constructions of the above kind before him?</p>
</blockquote>

<p><strong>Remark 3.</strong> Here by non-trivial I mean the above strategy is, in some sense, the only method for producing the required finite object.</p>

<p>--</p>

<blockquote>
  <p><strong>Question 3.</strong> Are there any results of the above type proved in other parts of mathematics other than logic?</p>
</blockquote>

<p>Of course Shelah's result is of this type, but the example given by Hamkins is in mathematical logic.</p>
",logic
"<p>It has been known for some time that one can define a topos as a model of a (finitary) essentially algebraic theory (or in other words, can be defined internal to any category with finite limits). In particular, given a topos $E$ (for instance the topos of sets) one can define an internal topos in $E$ (e.g. a small topos). One can ask for stronger (and in fact is easier to define) in an internal <em>universe</em>: this is a category theoretic analogue of a Grothendieck universe. Such a thing gives rise to an internal topos $M$ in $E$ that is in addition a <em>locally full subcategory</em>. The nontechnical definition is that there is an $E$-object $e(x)$ of $M$-elements of any $M$-object $x$ (recall that elements are functions $1 \to x$, here taken in $M$), and (the $E$-object of) functions <em>in $E$</em> between $e(x)$ and $e(y)$ correspond to the $E$-object of functions <em>in $M$</em> between $x$ and $y$.</p>

<p>There are toposes, given a metatheory of $ZFC$, that have no universes in this sense, namely the topos of sets in $V_{\omega+\omega}$, much like one cannot prove the existence of Grothendieck universes in vanilla ZFC. </p>

<p>What I'm curious about is the existence of internal toposes that <em>aren't</em> locally full (equivalently, arise from universes). Shouldn't we get the <em>free internal topos</em> in a topos? If we have NNOs, can we get the free internal topos with NNO? Are there good descriptions of these?</p>

<p>Given the topos of ZFC sets, the models of ZC give internal toposes, but I'm interesting in when we can say something about internal toposes without any material meta-theory. In essence: what can be said about ""inner models"" in topos theory? When we build inner models in ZFC (say), we leverage the extra structure that material sets have, for instance the cumulative hierarchy, which is not a priori available to the topos theorist.</p>

<hr>

<p>Postscript: Joyal defined (in work decades old by not yet published) a special sort of category called an <em>arithmetic universe</em>, which is much weaker than a topos, yet has enough structure to define the free internal arithmetic universe in it. I guess the free internal topos should be exist in a topos, but otherwise I can't be sure it's possible. I worry about erroneously ""proving the existence of a model"" out of nothing.</p>
",logic
"<p>What are current trends/questions in algebraic logic? I mean the research developed by Paul Halmos.</p>

<p>Could anyone give some references for the overview of its history? Any overview of its application to computer science and computability theory is welcome.</p>
",logic
"<p><a href=""http://cs.nyu.edu/pipermail/fom/2004-August/008394.html"" rel=""nofollow"">Conway</a> postulated that the Steiner-Lehmus theorem is unprovable using direct methods of proof. Can this be proven directly, that the Steiner-Lehmus theorem cannot be proven directly over Euclidean postulates?</p>
",logic
"<p>The following is stated without proof in Shelah's book ""Cardinal arithmetic"" (page 276), and is attributed to Uri Abraham:</p>

<blockquote>
  <p>Suppose that $L[A], L[B]$ have no non-constructible reals and that $\aleph_1^{L[A,B]}=\aleph_1^L.$ Then $L[A,B]$ has no non-constructible reals.</p>
</blockquote>

<p>How can we prove this result.</p>
",logic
"<p>Assuming the axiom DC($\omega_1$), is there a definition of the rank of a group ?</p>

<p>Another related question: assuming DC($\omega_1$), if we have two groups $A$ and $B$ of the same infinite rank, is there necessarily a surjective homomorphism from $A$ onto $B$? </p>

<p>Edit: in the second question , we assume $A$ and $B$ both free abelian.</p>
",logic
"<p>Hey. I have a few off the wall questions about topos theory and algebraic geometry.</p>

<ol>
<li>Do the following few sentences make sense? </li>
</ol>

<p>Every scheme X is pinned down by its Hom functor Hom(-,X) by the yoneda lemma, but since schemes are locally affine varieties, it is actually just enough to look at the case where ""-"" is an affine scheme.  So you could define schemes as particular functors from CommRing^op to Sets.  In this setting schemes are thought of as sheaves on the ""big zariski site"".</p>

<p>If that doesn't make sense my next questions probably do not either.</p>

<p>2 The category of sheaves on the big zariski site forms a topos T, the category of schemes being a subcategory. It is convenient to reason about toposes in their own ""internal logic"". Has there been much thought done about the internal logic of T, or would the logic of T require too much commutative algebra to feel like logic?  Along these lines, have there been attempts to write down an elementary list of axioms which capture the essense of this topos?  I am thinking of how Anders Kock has some really nice ways to think of differential geometry with his SDG.</p>

<p>3 What is it about the category of commutative rings which makes it possible to put such a nice site structure on it, but not other algebraic categories? Gluing rings together lead to huge advancements in algebraic geometry. What about gluing groups?  Is there a nice Grothendieck topology you could put on Groups^op, and then you could start studying sheaves on this site? If not, why not - what about rings makes them so special?</p>

<p>4 Why do people work with the category of schemes instead of the topos of sheaves on CommRing^op - toposes have every nice categorical property you could possibly ask for.</p>

<p>About me:  I am a 1st year grad student who is taking a first course on schemes, and I just have a lot of crazy ideas floating around.  I don't feel comfortable engaging in such wild speculation with my professors.  Could you offer any insight into these ideas?</p>
",logic
"<p>In their paper ""A barren extension"", Henle, Mathias, and Woodin considered the forcing whose conditions are the sets of natural numbers ordered by inclusion up to finite error.
If we force over $L(\mathbb{R})$ and assume that this is a model of determinacy, they show that this will add a free ultrafilter U on the natural numbers, and moreover in the 
extension there are no new (ordinal-indexed) sequences of elements of the ground model. </p>

<p>Let us order the functions $f\colon\omega\rightarrow\omega$ in $L(\mathbb{R})[U]$ by domination mod $U$. We obtain a linear order $(L,\leq)$. </p>

<p>(1) Is there a strictly increasing $\omega_1$-sequence in $(L,\leq)$? </p>

<p>(2) Is there a strictly increasing $\omega_1$-sequence of gaps in $(L,\leq)$? </p>
",logic
"<p>I've been trying to do some forcing arguments in intuitionistic ZF using Heyting valued models where the Heyting algebra I'm using is actually a bi-Heyting algebra (both a Heyting algebra and a co-Heyting algebra) and I've found that some interesting questions arise if I use the co-Heyting negations as well as/instead of the Heyting negation. I'm just wondering if anyone knows if any work has been done in constructing some kind of co-Heyting valued models of any kind of set theory? I guess such a theory would have to be paraconsistent. If this hasn't been done, could anybody give me some info/references about the current situation with respect to paraconsistent set theory and its model theory. Is there a dominant axiomatization? </p>
",logic
"<p>As I currently understand it, induction on formulas containing $N+1$ first-order quantifiers is required to prove the well-ordering of the ordinal $(\omega \uparrow\uparrow N) &lt; \epsilon_0$, that is, $\omega^{\omega^\cdots}$ for $N$ layers of $\omega$.  See e.g. the second answer to <a href=""http://mathoverflow.net/questions/138875/why-do-stacked-quantifiers-in-pa-correspond-to-ordinals-up-to-epsilon-0"">Why do stacked quantifiers in PA correspond to ordinals up to $\epsilon_0$?</a>.</p>

<p>If this is so then by Godel's Completeness Theorem there must be models of (if I have this right) $PRA+I(\Pi^0_{N+1})$ within which $\omega \uparrow\uparrow N$ is well-ordered, but $\omega \uparrow\uparrow (N+1)$ is not well-ordered.</p>

<p>What would these nonstandard models look like?  Is there any intuitive way to describe them via ultrapowers or something similar?  Or can we say something about their structure, the way that $\mathbb{N} + \mathbb{Z}\cdot\mathbb{Q}$ is the structure for countable nonstandard models of full first-order arithmetic?</p>

<p>For concreteness:  Is there any more specific way to describe a nonstandard model of PRA in which the Ackermann function is not complete, beyond ""The Ackermann function is not complete""?  Hopefully via some construction which will extend to ""Kirby-Paris hydras of height $N+2$(?) always terminate, but some of height $N+3$(?) don't""?  Obviously every primitive recursive function $f_n$ with $n \in \mathbb{N}$ is complete for every standard and nonstandard input, while the Ackermann function is incomplete for some input $\varpi$ which is a nonstandard number ($\varpi &gt; 0, \varpi &gt; 1, \dots$), likewise with non-terminating hydras where at least one branch has nonstandard width, but beyond this I cannot visualize anything about what the nonstandard model looks like.</p>

<p>(Understanding this would provide a direct, non-Godelian argument for why induction on $N+1$ quantifiers is <em>necessary</em> as well as <em>sufficient</em> to prove well-ordering of $\omega \uparrow\uparrow N$.  It would also show in a direct, non-Godelian way that $PA$ cannot prove the well-ordering of $\epsilon_0$, since this would require induction on infinite quantifiers.)</p>
",logic
"<p>Hello,
Can anybody explain to me how, in model theory, a type $p$ in a theory $T$ and language $L$ implies a type $p'$ in theory $T'$ and language $L'$, with $T \subset T'$ and $L \subset L'$. \
Also in the same context, how strong orthogonality of two definable sets $D$ and $D'$ is equivalent to the condition: If $A'$ is generated by elements of $D'$, then any type of elements of $D$ generates a complete type over $A'$.
Thanks.</p>
",logic
"<p>The axiom of replacement is usually used to prove the existence of large sets, to provide a reflection principle, for transfinite recursion… However, I am wondering how it affects finite sets. Let me give two concrete questions (let S be ZF without replacement and without infinity, SF=S+replacement, Z=S+infinity):</p>

<ul>
<li>Are there theorems in SF+“every set is finite” which cannot be proved in S+“every set is finite”? In an alternative formulation: Does S+“every set is finite” imply the axiom of replacement? If not: Is there some instructive construction which fails?</li>
<li>Assume we are working in Z or ZF and consider the set $HF$ of all hereditarily finite sets: Are there “natural” statements about $HF$ which can be proved in $ZF$ but not in $Z$? (of course there are such statements, namely in $ZF$ we can prove that $HF$ is a model of some first-order statements expressing that $Z$ plus any given finite fragment of $ZF$ is consistent (and some similar statements), but I am looking for different properties)</li>
</ul>

<p>“Finite” should be defined using natural numbers, which are Dedekind finite ordinals. Feel free to use strong versions of foundation for the first question. If something interesting happens with the negation of such an axiom, it would be interesting, too.</p>

<p>Regards</p>
",logic
"<p>I will accept an answer in the form of references to the literature about my question as well as any other information.  I am quite ignorant of the area and that will be clear from my question.</p>

<p>I take it that interpreting a system (e.g., PA) in some structure without the use of parameters is harder than doing the same with the use of parameters.  I would like to understand the difference of the consequences of the two tasks (interpreting with parameters vs. interpreting without).  What does it have to say about the structure in which the interpretation takes place?</p>
",logic
"<p>Countable models of PA fall into two categories: the standard one $(\omega, S)$ and the nonstandard ones (all the rest).  The only way I've seen to construct a nonstandard model is through taking an ultraproduct or, equivalently, using the compactness theorem.  My question is wether or not these are all the models there are?  There are continuum many ultrafilters and continuum many nonstandard, countable models, but I don't know if there's a surjective correspondence.</p>
",logic
"<p>In first approximation, modal logic (I'm using the term loosely)
   can be understood as an interesting fragment of first-order logic
   (for simplicity I ignore e.g. how modal logic relates to
   second-order logics) with bounded/local quantifiers: modal
   operators can be thought of as abbreviations that encode
   quantification over relationally-accessible states in a convenient,
   variable-free notation. The <a href=""https://en.wikipedia.org/wiki/Standard_translation"" rel=""nofollow"">standard translation of modal logic into
   first-order logic</a> gives rise to interesting fragments like the
   finite variable fragments, the fragments closed under bisimulation,
   guarded fragments that have been investigated heavily, etc.
   The standard translation also allow us to push techniques, constructions and
   results between logics.  </p>

<p>Modal logic is used because formulae and
   proofs in modal logic are more succinct, sometimes substantially
   so, than the corresponding first-order fragments.</p>

<p>In a similar sense, <a href=""https://en.wikipedia.org/wiki/Many-sorted_logic"" rel=""nofollow"">many-sorted</a> first-order logic can be seen as a
   fragment of first-order logic by translating sorts
   into appropriate first-order predicates. Here I assume that we have more than one sort. Now my question: are there
   non-trivial results about fragments of first-order logic obtained by
   translating away sorts? I'm particularly interested in questions
   about the complexity of decision problems.</p>

<p>PS: I'm not sure if this question is suitable for mathoverflow. If not, please
feel free to close or move to a more appropriate venue.</p>
",logic
"<p>In his answer to the following mathoverflow question, <a href=""http://mathoverflow.net/q/177047/1946"">The (un)decidability of Robinson Arithmetic without multiplication</a>, Emil Jerabek proved that the following fragment:</p>

<ol>
<li><p>$\forall$x(Sx$\neq$0)</p></li>
<li><p>$\forall$x$\forall$y(Sx=Sy $\Rightarrow$ x=y)</p></li>
<li><p>$\forall$x(x$\neq$0 $\Rightarrow$ ($\exists$y)(x=Sy)</p></li>
<li><p>$\forall$x(x+0=x)</p></li>
<li><p>$\forall$x$\forall$y (x+Sy)=S(x+y)</p></li>
</ol>

<p>""with '0' as the sole constant and 'S' [successor] and '+' as the built-in function signs...and whose deductive system is your favourite classical first-order logic with identity."" (Quote from Peter Smith, the OP in question.)</p>

<p>is undecidable, and in fact hereditarily undecidable.</p>

<p>Question:  What would be an example of a true but undecidable well-formed formula definable in the language of this fragment?         </p>
",logic
"<p>If $P$ is a notion of forcing in $M$, then $G$ is a $P$-generic filter over $M$ if $G\subseteq P$ is a filter, and for every $D\in M$ which is a dense subset of $P$, $G\cap D\neq\varnothing$.</p>

<p>Equivalently we can replace $D$ being dense by being pre-dense, open dense, or a maximal antichain.</p>

<p>Given such a generic filter, and $\dot x$ which is a $P$-name, we can define the interpretation of $\dot x$ by the filter $G$ by recursion, $$\dot x^G=\{\dot y^G\mid\exists p\in G:\langle p,\dot y\rangle\in\dot x\}.$$</p>

<p>Clearly, we don't <em>need</em> genericity in order to interpret names. We can talk about interpretation using arbitrary filters.</p>

<blockquote>
  <p><strong>Question.</strong> Given a filter $G$, is there some reasonable condition stating that $G$ is generic if and only if it interprets certain names (e.g. names which are forced to be ordinals) ""properly""?</p>
</blockquote>
",logic
"<h2>Background</h2>

<p>An ordinal $\alpha$ is called a <em>recursive ordinal</em> if there is a recursive well-order $R$ on $\mathbb{N}$ such that ordertype($\mathbb{N},R) = \alpha$.  For example, $\omega\cdot 2$ is a recursive ordinal because the ordering of $\mathbb{N}$ as 0, 2, 4, 6, 8,  ... 1, 3, 5, 7, ... is computable and has order type $\omega\cdot 2$.</p>

<p>Kleene encoded the recursive ordinals in the natural numbers in a nifty way which is described at <a href=""http://en.wikipedia.org/wiki/Kleene%27s_O"" rel=""nofollow"">the Wikipedia page on Kleene's O</a>.  Now Kleene's $\mathcal{O}$ is a fairly powerful set -- given a Turing machine index for a linear order, $\mathcal{O}$ can decide whether that ordering is a well-ordering or not.</p>

<p>Using Kleene's $\mathcal{O}$, it is possible to describe how to iterate the Turing jump through the recursive ordinals.  For each natural number $a\in\mathcal{O}$, we can define a set $H_a$ recursively as follows:</p>

<ol>
<li>$H_a = \emptyset$ if $a=0$</li>
<li>$H_a = {H_b}'$ if $a=2^b$</li>
<li>$H_a = \{\langle n, x \rangle | x \in H_{\phi_e(n)} \}$ if $a = {3\cdot 5^e}$</li>
</ol>

<p>For each $a\in \mathcal{O}$, we have $H_a$ &lt;$_T \ \mathcal{O}$ (strict inequality), and no $H_a$ is powerful enough to decide which recursive orders are well-orders.</p>

<h2>Question</h2>

<p>Among recursive non-well-orders, some hide their descending chains better than others do.  </p>

<p>For example, if we only wanted to flag the non-well-orders sporting a <em>recursive</em> descending chain, the full power of $\mathcal{O}$ would not be necessary -- $\emptyset'''$ would do $(\exists e [ \phi_e$ is total and $\forall n [\ \phi_e(n+1)$ &lt;$_R\ \phi_e(n)\ ]]$?).  Thus there is a recursive linear non-well-order with no recursive descending chain.  </p>

<p>In fact (by similar reasoning), for each $a \in \mathcal{O}$ there must be a recursive linear non-well-order with no recursive-in-$H_a$ descending chain.</p>

<p>I wonder whether we could effectively construct these sneaky recursive non-well-orders.</p>

<blockquote>
  <p>Is there a recursive function $f$ such that whenever $a\in\mathcal{O}$, $f(a)$ is a Turing index for a linear non-well-order with no $H_a$ -computable descending chain?</p>
</blockquote>
",logic
"<p>I am curious what braid groups (strings in $\mathbb{R}^3$) are <a href=""https://en.wikipedia.org/wiki/NIP_(model_theory)"" rel=""nofollow"">NIP</a>. Consider the following: </p>

<p>Let $B_\mathbb{N}$ be braid group with ""braids"" indexed by the natural numbers (alternatively, the direct limit of braid groups on finitely many braids with inclusion maps between them). This structure (in the language of groups) is not NIP. </p>

<p><strong>Proof:</strong> There is a formula which shatters arbitrarily large (finite) subsets of $B_\mathbb{N}$. Consider the formula $\varphi(x;y) \equiv xy \neq yx$</p>

<p>Let $\{\sigma_i : i \in \mathbb{N}\}$ generate $B_\mathbb{N}$. Let $A_n = \{\sigma_0, \sigma_3,...,\sigma_{3m},..., \sigma_{3n}\}$. Let $I \subseteq A_n$. Suppose that $I = \{\sigma_{j_1},...,\sigma_{j_k}\}$. Then, let $b_I = \sigma_{j_1 +1} \circ ... \circ \sigma_{j_k +1}$. If $I = \emptyset$, let $I = \sigma_t$ where $t&gt;3n+1$.   Then, we have that $$B_\mathbb{N}\models \varphi(x, b_I)\iff \sigma_j\in I;\forall \sigma \in A_n $$</p>

<p>Since we can shatter arbitrarily large finite sets $\implies$ $B_{\mathbb{N}}$ is not NIP. </p>

<p>$\boxdot$</p>

<p><strong>Remarks:</strong> The proof that $B_{\mathbb{N}}$ is not NIP relies on the fact that there are infinitely many generators. While I find this interesting, it is not helpful in understanding whether braid groups with finitely many generators are NIP. I am curious to know whether $B_n$ is NIP for $n \in \mathbb{N}$. Futhermore, I should remark that $B_1,B_2$ are NIP since $B_1$ is finite and $B_2 \cong \mathbb{Z}$ (in the group language) and since $\mathbb{Z}$ is stable, $B_2$ is NIP. But, more specifically, I am asking the following question: </p>

<p><strong>Question:</strong> Is $B_3$ NIP?</p>
",logic
"<p>Hi there,</p>

<p>Assuming X and Y are modal formulae and diamond X is satisfiable and diamond Y is satisfiable, how would one show that they X AND Y is satisfiable?</p>

<p>I don't think it requires much effort?</p>

<p>I think you need to choose one world and one model where X AND Y is true and that would mean it is satisfiable?</p>

<p>So assuming I'm going about it correctly, any ideas what model and world I should select to show this X AND Y is satisfiable?</p>

<p>Any advice would be great,</p>

<p>Thank you.</p>

<p>P.S. NO appropriate tags for this type of most, maybe someone should create a modal logic one (I can't as I'm a new user)</p>
",logic
"<p><strong>Background.</strong> The <a href=""http://en.wikipedia.org/wiki/Church-Turing_thesis"">Church-Turing thesis</a>, in one of its many equivalent formulations, states that the intuitively computable arithmetical functions are exactly those computed by Turing machines.</p>

<p>According to Alan Turing’s classic paper <a href=""http://plms.oxfordjournals.org/cgi/pdf_extract/s2-42/1/230"">On computable numbers, with an application to the Entscheidungsproblem</a>, “intuitively computable” refers to a human computer having access to enough scratch paper to hold the intermediate results.</p>

<p>This thesis has been extremely successful among logicians first (including <a href=""http://books.google.com/books?id=qW8x7sQ4JXgC&amp;pg=PA72"">Kurt Gödel</a>), and computer scientists later; some authors even extended it to include all functions that can be computed by any <a href=""http://bjps.oxfordjournals.org/cgi/content/abstract/54/2/181"">effectively realizable physical system</a>.</p>

<p>Nonetheless, the Church-Turing thesis is, at least in principle, falsifiable: it is enough to describe a non Turing-computable function admitting another kind of computation procedure, executable by the above-mentioned human computer. Of course, no such function is known to exist; however, consider the following “weaker computability thesis” for the sake of argument:</p>

<blockquote>
  <p>Every intuitively computable arithmetical function is <a href=""http://en.wikipedia.org/wiki/Primitive_recursive_function"">primitive recursive</a>.</p>
</blockquote>

<p>This is falsified by <a href=""http://en.wikipedia.org/wiki/Ackermann_function"">Ackermann's function</a>, which is clearly computable (both intuitively and by a Turing machine) although not primitive recursive.</p>

<p><strong>Question.</strong> Has a similar, provably weaker “computability thesis” ever been proposed before Church’s and Turing’s? As an alternative, can we reasonably argue that no such statement was ever made?</p>
",logic
"<p>Just a curiosity:</p>

<blockquote>
  <p>Is there an assertion of which a proof (formalizable, say, in ZFC) is not known but a proof that it's <em>not</em> undecidable (in ZFC) <em>is</em> known?</p>
</blockquote>

<p>Edit: after the comments, I think the actual question was </p>

<blockquote>
  <p>Is there an (""interesting"") assertion of which neither a proof (formalizable, say, in ZFC) of it or its negation is known but a proof that it's <em>not</em> undecidable (in ZFC) <em>is</em> known?</p>
</blockquote>
",logic
"<p><strong>See moderator's note in the comments.</strong></p>

<p>I just came across the following. In intuitionistic logic<br>
and classical logic we have the following consequences:</p>

<pre><code>∃x¬φ → ¬∀xφ  
∀x¬φ → ¬∃xφ  
¬∃xφ → ∀x¬φ
</code></pre>

<p>But the following consequence is only generally valid<br>
in classical logic but not in intuitionistic logic:</p>

<pre><code>¬∀xφ → ∃x¬φ                         (Q)
</code></pre>

<p>Are there intermediate logics where the last consequence<br>
doesn't fail? I mean a logic where φ v ¬φ doesn't hold<br>
in general but (Q) does.</p>

<p>Bye</p>
",logic
"<p>Invariant Subspace Conjecture: A bounded operator on a separable Hilbert space has a non-trivial closed invariant subspace. </p>

<p>Can this conjecture be reformulated as an arithmetic statement, that is, $\Pi^0_n$ statement for some n? (I tried to figure it out, but failed.)</p>

<p>EDIT: For what I understand from answers, it appears to be an open problem. As 
Emil Jerabek and others mentioned, the intrinsic complexity of the conjecture (considered 
as a statement in second-order arithmetic) is $\Pi^1_2$. Apparently, no reduction to lesser 
complexity is known. One may speculate about how much of a solution would be a reduction 
to $\Pi^1_1$ or $\Pi^0_n$, but I would rather not. </p>

<p>Carl Mummert pointed out an interesting possibility: whether the conjecture itself 
is true or not, its interpretation in computable analysis may be false. 
In this case, if I got it right, the only way to reduce its complexity is to disprove it. 
However, this obstacle would disappear if we are allowed to use set 
theory to prove equivalence, because computable analysis doesn't work there.</p>

<p>Thanks to everyone. </p>
",logic
"<p>first,I think we can avoid set theory to bulid the first order logic ,  by the operation of the finite string.but I have  The following questions:</p>

<p>How does ""meta-logic"" work. I don't really know this stuff yet, but from what I can see right now, meta-logic proves things about formal languages and logics in general. But does it use some logic to do so? Like if I want to prove that two formal languages are equivalent in some respect, aren't I presupposing a ""background"" formal language? And won't my choice of a ""background"" (meta) language affect what I can and can't demonstrate? For example,  what logic was Godel using when he proved his famous theorems? Was it a bivalent one? A three valued logic? etc</p>

<p>In short,I'm still not sure how reasoning about all possible formal languages work. For example, suppose I say something of the form ""for all formal theories, F, if F has property X, then F must have property Y"". If I wanted to prove something like that, how does such very general reasoning work? What I mean is that in such a proof, what kind of logic would be employed (for example, would it be a two valued logic?), and does the choice of logic affect the outcome? Do logicians agree on some kind of meta-meta logic, which they use to reason about absolutely everything? Or do they just choose their favorite one?</p>

<p>if metalogic is just predicate logic,It seems circular to me! we build the theory of predicate logic by using predicate logic?For example, in proving some theorem in the object language we seem to assume that it is already correct (in the metalanguage). Or defining some connective in the object language, we use that connective in the metalanguage to do so. It's like they're saying ""Alright guys! We are going to prove a bunch of stuff about logic! Oh, by the way, you have to take all this stuff we are about to prove for granted, but don't worry, that's just the ""metalanguage""."" Something about this seems wrong to me. Maybe I have misunderstood?</p>
",logic
"<p>I want to understand the idea of the proof of the artihmetic fixed point theorem. The theorem is crucial in the proof of Gödel's first Incompletness theorem.</p>

<p>First some notation: We work in $NT$, the usual number theory, it has implemented all primitve recursive functions. Every term or formula $F$ has a unique Gödel number $[F]$, which encodes $F$. If $n$ is a natural number, the corresponding term in $NT$ is denoted by $\underline{n}$. The function $num(n):=[\underline{n}]$ is primitive recursive. Also, there is a primitive recursive function $sub$ of two variables, such that $sub([F],[t])=[F_v(t)]$, where $v$ is a free variable of $F$ which is replaced by a term $t$.</p>

<p>Now the theorem assertions the following:</p>

<blockquote>
  <p>Let $F$ be a formula with only one free variable $v$. Then there is a sentence $A$ such that $NT$ proves $A \Leftrightarrow F_v(\underline{[A]})$.</p>
</blockquote>

<p>This may be interpreted as a self-referential definition of $A$, which is, as I said, crucial in Gödel's work. I understand the proof, I just repeat it, but I don't get the idea behind it:</p>

<p>Let $H(v)=F_v(sub(v,num(v)))$ and $A = H_v(\underline{[H]})$. Then we have</p>

<p>$A \Leftrightarrow H_v(\underline{[H]})$
$\Leftrightarrow F_v(sub(v,num(v)))_v(\underline{[H]})$
$\Leftrightarrow F_v(sub_1(\underline{[H]},num(\underline{[H]})))$
$\Leftrightarrow F_v(sub_1(\underline{[H]},\underline{[\underline{[H]}]}))$
$\Leftrightarrow F_v(\underline{[H_v(\underline{[H]})]})$
$\Leftrightarrow F_v(\underline{[A]}), qed.$</p>

<p>But why did we choose $H$ and $A$ like above?</p>
",logic
"<p>This question does <em>not</em> concern the comparative merits of standard (SA) and nonstandard (NSA) analysis but rather a comparison of different approaches to NSA. What are the concrete advantages of the abstract approaches to NSA (e.g., via the compactness theorem), as compared to the more concrete approach using ultrapowers? One can name generic reasons such as naturality, functoriality, categoricity, etc., but I am hoping for a concrete illustration of why a more abstract approach may be advantageous for understanding NSA concepts and/or proving theorems.</p>

<p>Note 1. One of the existing answers provided a bit of information about advantages of the more abstract approach in terms of saturation. I would appreciate an elaboration of this if possible, in terms of a concrete application of saturation.</p>
",logic
"<p>Skolemization is often used for eliminating existential quantifiers, which is often useful for proving theorems, especially in automated resolution theorem proving. Skolemization in first order predicate calculus is often based on a second order identity:</p>

<p>$\forall$x$\exists$y $\phi$(x,y) $\iff$ $\exists$f$\forall$x $\phi$(x, f(x))</p>

<p>I asked on the math.stackexchange site how to perform this operation in higher order <a href=""https://math.stackexchange.com/questions/1060183/how-is-quantifier-elimination-accomplished-in-second-and-higher-order-logic"">logic</a>, with a reasonably satisfactory answer, with one rather large caveat.</p>

<p>Apparently, at higher levels of logic, exploiting this identity to use an operation like Skolemization to eliminate existential quantifiers requires the axiom of choice. Is this always the case? This seems like a fairly heavy assumption for using a proof calculus, so are there any restricted forms of higher order Skolemization or existential quantifier elimination that don't require the axiom of choice, or require weaker versions of choice like countable choice or dependent choice?</p>
",logic
"<p>The statement A = ""There exists a well-ordering of the reals"" is independent of ZF.  My understanding is that the statement B = ""There exists an explicit well-ordering of the reals"" is also independent of ZF, yet this seems counterinutitive to me, because of the following line of reasoning:  If B were true, then A would be provable in ZF, which is impossible since A is independent of ZF, so B must be false.  This line of reasoning seems perfectly clear to me, and I see no reason why it cannot be carried out in ZF itself.  But if the line of reasoning could be carried out in ZF, then that would mean that ZF implies that not B, contradicting the claim that B is independent of ZF.</p>

<p>So can anyone clarify how exactly ZF+B is consistent?</p>

<p>Any help would be greatly appreciated.</p>

<p>Thank You in Advance.</p>
",logic
"<p>I am attempting to write an expository paper on non-standard models of PA that is accesible to students taking an introductory graduate course in mathematical logic (covering Godel's incompleteness theorems, the diagonalization lemma, models, etc.). In this paper I want to give an explanation of some results such as Tennanbaum's Theorem (there does not exist a countable recursive model of PA that is not isomorphic to the standard model). By, ""give an explanation of"", I mean to actually work through an explanation of the proof, some of the techniques involved, and the general overlap between techniques used in the proofs of Tennanbaum's theorem, some theorems proven by Rosser on extensions of PA, Robinson's overspill lemma, etc. (Note: I want to avoid digressing into an explanation of forcing if possible).</p>

<p>My question is, what books or online resources do you know of that would be useful for me? That is, do you happen to know of surveys of these topics that are around on arXiv or JSTOR? I have been digging through the mathematical logic section of arXiv for papers and I found a few that are useful, but I thought that some mathematicians/logicians on MO might know of some papers that give a just survey of the introductory results regarding non-standard models of PA.</p>

<p>Thank you!</p>
",logic
"<p>I recently looked at <a href=""http://arxiv.org/abs/1405.4297"" rel=""nofollow"">Permutations on the random permutation</a> which seems to talk about the notion of random permutuation as a notion from logic rather than probability.</p>

<blockquote>
  <p>The <strong>random permutation</strong> is the Fraïssé limit of the class of ﬁnite structures with two linear orders.</p>
</blockquote>

<p>The intro also mentions that finite permutations are ""two linear orders on a ﬁnite set"".</p>

<p>I am not a logician, so I don't know what Fraïssé limit could be, but I got something about <strong><a href=""https://en.wikipedia.org/wiki/Age_%28model_theory%29"" rel=""nofollow"">age</a></strong> in model theory.</p>

<p>There a sense in which a random permutation is a ""universal"" construction?</p>

<ul>
<li><a href=""http://math.stackexchange.com/questions/63150/what-is-a-universal-property"">http://math.stackexchange.com/questions/63150/what-is-a-universal-property</a></li>
</ul>

<p>Is there a sense in which a ""random"" object can be a logical construction?</p>

<ul>
<li>Ed Nelson's <a href=""http://web.math.princeton.edu/~nelson/books/rept.pdf"" rel=""nofollow"">Radically Elementary Probability Theory</a> is a fascinating non-standard construction of law of large numbers and stochastic proceses, but I could not find an explanation of the random permutation.</li>
</ul>
",logic
"<p>In homotopy type theory, homotopy types can be viewed as logical types and it is possible to prove some theorems about them without using any underlying space (no simplicial set, no topological space). It is a kind of synthetic algebraic topology. Is it just a coincidence that the word ""type"" may have these two meanings ? What I mean is: what had in mind the one who invented this terminology of ""homotopy types"" ? And do we even know where that terminology of ""homotopy types"" comes from. I guess that the answer will be that it is a coincidence but since it is written nowhere in the book, I ask the question in order to be sure.</p>
",logic
"<p>In <a href=""http://mathoverflow.net/questions/74941/is-there-an-undecided-assertion-of-which-a-proof-that-its-not-undecidable-is-k"">this MO question</a>, the OP asked for an example of a statement which was known not to be independent of ZFC, but for which the truth value was unknown. I immediately thought of <a href=""http://math.stackexchange.com/questions/13054/how-to-show-eee79-is-not-an-integer"">a question I asked on math.SE</a>: is $e^{e^{e^{79}}}$ an integer? This is apparently an open question, but I realized after some thought that I don't know how to prove it is decidable in ZFC.</p>

<p>If the number is not an integer, this can be proved in ZFC, because that fact could be expressed by an arithmetical sentence saying there is an integer $n$ such that the sum of a certain definable series is greater than $n$ and less than $n+1$. This sentence can be seen to be $\Sigma^0_1$ by standard techniques, and any true $\Sigma^0_1$ sentence is provable in ZFC. </p>

<p>But if the sum is an integer, it does not seem obvious that this must be provable in ZFC. In general, only $\Sigma^0_1$ statements have to be provable if they are true, and the claim that a certain definable series sums to an integer is $\Sigma^0_2$ rather than $\Sigma^0_1$. </p>

<p>Moreover, it's not hard to see that there are definitions of sequences $(a_n)$ in ZFC such that ZFC proves that $\sum a_n$ converges but ZFC doesn't prove this sum is an integer and ZFC doesn't prove it is not an integer. These sequences can be constructed using the incompleteness theorem in the usual way. In fact, we can make $0 \leq a_n \leq 2^{-n}$ for all $n$, so there is no issue with the rate of convergence. </p>

<p>But there must be something special about $e^{e^{e^{79}}}$ that means either ZFC can prove it's an integer, or can prove it's not an integer - right? </p>
",logic
"<p>Let $S$ be the set of all finite permutations of $\mathbb{N}$, i.e. they fix all but a finite set, and $A\subset S$ the set of all even permutations. </p>

<p><strong>Theorem</strong> The normal subgroups of $S_\infty$ are exactly the following four (in increasing order): $\{id\}$, $A$, $S$, $S_\infty$.</p>

<p>Now, consider a model $M$ with domain $\mathbb{N}$ and let $Aut(M)$ be the group of  automorphisms of $M$. $Aut(M)$ is a closed subgroup of $S_\infty$ and every closed subgroup of $S_\infty$ equals $Aut(M)$, for some model $M$.</p>

<p><strong>My question</strong>: Are there any (partial?) results generalizing the above  theorem to $Aut(M)$? I.e. what are the normal subgroups of $Aut(M)$, for various $M$? Equivalently, if $A$ is a closed subgroup of $S_\infty$, what are the normal subgroups of $A$?</p>
",logic
"<p>Hi,</p>

<p>In Chang &amp; Keisler ""Model Theory"" it is claimed that the theory of a one-to-one function of A onto A with no finite cycles is $\omega_1$- categorical (page 140). Why is that, and is there a reference for this?</p>
",logic
"<p>I wonder if it is possible to specialize the question:
(a) <em>What is the probability that a random Turing Machine program
will halt?</em>, to: (b) <em>What is the probability that a random Turing Machine 
program that halts, when, given&mdash;say&mdash;the integer
coordinates of three vertices of a planar triangle on its tape,
will halt with the triangle area on the tape as an answer?</em></p>

<p>The answer to (a) is
<a href=""http://en.wikipedia.org/wiki/Chaitin%27s_constant"" rel=""nofollow"">Chaitin's $\Omega$</a>.
What I am asking is whether ""halting"" can be narrowed to ""useful""
in any meaningful way, with any positive probability attached. It seems
it should be possible, perhaps not to compute a specific probability, but
to guarantee that it is positive...?</p>

<p>This is well beyond my ken, so I'd especially welcome tutorial pointers.
Thanks!</p>
",logic
"<p><a href=""https://www.quantamagazine.org/20160524-mathematicians-bridge-finite-infinite-divide/"">This popular article</a> reports a recent result in reverse mathematics, showing that a certain theorem in Ramsey theory is provable from RCA$_0$, the base theory in SOSOA.  Then there are a bunch of surprised remarks, since (according to the article) the theorem itself is infinitary.  Does that just mean that it uses unbounded quantifiers, or maybe that it refers to infinite sets?  Isn't that the whole point of second-order arithmetic?  And aren't there tons of theorems of the same sort?  I don't know much about the subject, but I thought one of the basic discoveries in RM was that lots of the familiar results of calculus and analysis can be reached from RCA$_0$.</p>

<p>I get that $RT^2_2$ has a Friedman-like flavour that sounds like it might need strong axioms to prove, and I get that proving its strength (that was lower than expected) was difficult, but I'm having trouble understanding why there is such excitement over this, or what far-reaching consequences it's supposed to have.  I'd appreciate any enlightenment.</p>
",logic
"<p>Disjoint sets $A$ and $B$ are <a href=""http://en.wikipedia.org/wiki/Recursively_inseparable_sets"">computably inseparable</a>, if there
is no computable separating set, a computable set $C$ containing $A$ and disjoint from $B$. The
existence of c.e. computably inseparable sets is a fundamental
phenomenon explaining and unifing many arguments in computability theory.</p>

<p>Perhaps the easiest example of a c.e. computably inseparable pair of sets is the following, 
where $\varphi_e$ is the function computed by program $e$.
$$A=\{e\mid
\varphi_e(0)\downarrow =0\},\qquad B=\{e\mid
\varphi_e(0)\downarrow=1\}.$$
To see this, suppose $C$ is decidable, $A\subset C$ and $B\cap
C=\emptyset$. Since $C$ is computable, we may design via the recursion theorem a program $e$ such that
$\varphi_e(0)\downarrow=1$ just in case $e\in C$, and otherwise
$\varphi_e(0)=0$, and this gives an immediate contradiction. Another computably inseparable pair is the set of theorems versus the set of negations of theorems of PA, or your favorite consistent theory containing arithmetic. </p>

<p><b>Question.</b> What is the computational-complexity-theoretic
analogue of computable inseparability?</p>

<p>Specifically, if $P\neq NP$, then are there disjoint NP sets with
no separating set in $P$? </p>

<p>This plainly fails if $P=NP$. </p>

<p><b>Edit.</b> Mark Sapir points out that if we assume $\text{P}\neq\text{NP}\cap\text{Co-NP}$, then there is are some easy examples, namely, any set $L\in\text{NP}\cap\text{Co-NP}\setminus P$ together with its complement. In light of this (since this particular example won't help me with my intended purpose), let me modify the particular question to:</p>

<p><b>Question.</b> Under some standard complexity theory hypothesis, such as $\text{P}\neq \text{NP}\cap\text{Co-NP}$, are there disjoint sets in NP with no separation in $\text{NP}\cap\text{Co-NP}$? </p>

<p>And are there other analogues of the phenomenon with other complexity classes?</p>
",logic
"<p>We are talking about ordinary reals in constructive mathematics.</p>

<ol>
<li><p>Let represent each real number by infinite converging series:
$$r = [\;(a_0,b_0),(a_1,b_1),...,(a_i,b_i),...\;]$$
$$where\quad a_i \leq b_i\quad and \quad a_i \leq a_{i+1} \; and \; b_{i+1} \leq b_i$$</p>

<p>And interval $(a_i,b_i)$ converges: for any given rational $e &gt; 0$ there is index $j$ such that $b_k - a_k &lt; e$ for all $k \geq j$.</p></li>
<li><p>There are only one way to construct such a number: to build an algorithm that produces $ (a_{i+1},b_{i+1}) $ from (a,b) (or some nearly equivalent).</p></li>
<li><p>Let model algorithms by lambda terms (we are able to do so because lambda calculus is Turing complete).</p></li>
<li><p>It is easy to show that each lambda term may be represented by unique natural number (this is simple serialization/deserialization process, well known for every programmer).</p></li>
<li><p>So there is a one-to-one correspondence between real numbers and subset of natural numbers.</p></li>
<li><p>This imply that constructive reals and naturals are equipotent sets.</p></li>
</ol>

<p>What are not ok with this reasoning and why?</p>
",logic
"<p>I have in mind something like the following:</p>

<hr>

<p>Start with some suitable version of ""finite"" mathematics. Some possibilities might be maybe ZFC with a suitable anti-infinity axiom, the topos $\mathbf{FinSet}$, Peano arithmetic, Turing machines... something whose objects are suitably ""finite"".</p>

<p>Then, posit the existence of both a standard and a non-standard model.</p>

<p>Now, in this setting, where we have access both to a standard model and a non-standard extension, use the non-standard objects as proxies for infinite objects (e.g. maybe some sort of set theory that has a set of natural numbers), and develop ordinary mathematics this way.</p>

<hr>

<p>Has anybody worked on such a thing? Does anyone know of references of it being done? Or suggestions that it can't work out?</p>

<p>(P.S. I wasn't sure how to tag this....)</p>

<hr>

<p>Edit: After more thought and reviewing the answers thus far, I think I can state an example of the sort of thing i was imagining. Define a first-order theory with two types $T_1$ and $T_2$, two binary relation symbols $\in_1, \in_2$ (one for each sort), and a map $\tau : T_1 \to T_2$ satisfying:</p>

<ul>
<li>$(T_1, \in_1)$ satisfies the axioms of finite set theory</li>
<li>$(T_2, \in_2)$ satisfies the axioms of finite set theory</li>
<li>$\tau$ is injective</li>
<li>$\tau$ is not surjective</li>
<li>$\tau$ satisfies an axiom schema that says it's an elementary embedding</li>
</ul>

<p>and the question is to what extent we can develop infinite set theory in this theory.</p>
",logic
"<p>In Calculus we teach that if the $a_n$ are positive and decreasing with limit equal to zero, then the alternating series $\sum_n (-1)^na_n$ converges. One can in general not leave out the assumption that the $a_n$ (eventually) decrease, as the example $a_{2n}:=1/n$ and $a_{2n+1}:=1/2^n$ shows. However, most examples are series where the $a_n$ are given by some function $a_n=f(n)$ (for $n\gg 0$). </p>

<p>So my question is, for which class of functions $\mathcal F$ do we have the property  that if $f$ is a positive function in $\mathcal F$ and $\lim_{x\to \infty}f(x)=0$, then the alternating series $\sum_n (-1)^nf(n)$ converges. For instance, any o-minimal class will work, since any $f$ with limit zero at infinity must eventually be decreasing. But I think if we add the sine function to this class and close under addition, multiplication and composition, this is still true. In fact, I would almost dare to postulate that the class of elementary functions (i.e., the ones our students work with), have this property, and so we do not need to ``bug'' them with this extra condition.</p>
",logic
"<p>Assuming the axiom of choice we have that successor cardinals are regular. However as one of the first examples of uses of forcing show, it is consistent relative to $\sf ZF$ that $\omega_1$ is singular. On the other hand, Schindler proved that if there are two consecutive singular cardinals, then there is an inner model with a Woodin cardinal.</p>

<p>There has been quite some recent research into all sort of patterns of singular successor cardinals from large cardinal assumptions.</p>

<p>But how much can we do without any large cardinal assumption? E.g. can we have two singular successors, perhaps with infinitely many cardinals between them, without large cardinals? Can we have a proper class of singular successors?</p>

<p>I don't expect the exact line of ""there be large cardinals"" to be known, but do we know anything except the Feferman-Levy model (or the Truss model, where he mimics the classic Solovay model construction, and shows that if we start with a singular then $\omega_1$ is singular)?</p>
",logic
"<p>I included this footnote in a paper in which I mentioned that the number of partitions of the empty set is 1 (every member of any partition is a non-empty set, and of course every member of the empty set is a non-empty set):</p>

<p>""Perhaps as a result of studying set theory, I was surprised when I learned that some respectable combinatorialists consider such things as this to be mere convention.  One of them even said a case could be made for setting the number of partitions to 0 when $n=0$.  By stark contrast, Gian-Carlo Rota wrote in \cite{Rota2}, p.~15, that 'the kind of mathematical reasoning that physicists find unbearably pedantic' leads not only to the conclusion that the elementary symmetric function in no variables is 1, but straight from there to the theory of the Euler characteristic, so that 'such reasoning does pay off.'  The only other really sexy example I know is from applied statistics: the non-central chi-square distribution with zero degrees of freedom, unlike its 'central' counterpart, is non-trivial.""</p>

<p>The cited paper was: G-C.~Rota, Geometric Probability, <em>Mathematical Intelligencer</em>, 20 (4), 1998, pp. 11--16.  The paper in which my footnote appears is the first one you see <a href=""http://www.combinatorics.org/Volume_13/v13i1toc.html"">here</a>.</p>

<p><b>Question:</b> What other really gaudy examples are there?</p>

<p>Some remarks:</p>

<ul>
<li><p>From one point of view, the whole concept of vacuous truth is silly.  It is a counterintuitive but true proposition that Minneapolis is at a higher latitude than Toronto.  ""Ex falso quodlibet"" (or whatever the Latin phrase is) and so if you believe Toronto is a more northerly locale than Minneapolis, it will lead you into all sorts of mistakes like 2 + 2 = 5, etc.  But that is nonsense.</p></li>
<li><p>From another point of view, in its proper mathematical context, it makes perfect sense.</p></li>
<li><p>People use examples like propositions about all volcanoes made of pure gold, etc.  That's bad pedagogy and bad in other ways.  What if I ask whether all cell phones in the classroom have been shut off?  If there are no cell phones in the room (that <em>is</em> more realistic than volcanoes made of gold, isn't it??) then the correct answer is ""yes"".  That's a good example, showing, if only in a small way, the utility of the concept when used properly.</p></li>
<li><p>I don't think it's mere convention that the number of partitions of the empty set is 1; it follows logically from some basic things in logic.  Those don't make sense in some contexts (see ""Minneapolis"", ""Toronto"", etc., above) but in fact the <em>only</em> truth value that can be assigned to ""F--->F"" or ""F--->T"" that makes it possible to fill in the truth table without knowing the content of the false proposition (and satisfies the other desiderata?) is T.  That's a fact whose truth doesn't depend on conventions.</p></li>
</ul>
",logic
"<p>It is known from a result of Sierpinski that the generalized continuum hypothesis (GCH) implies the axiom of choice (AC).  It is also known from the celebrated results of Cohen that AC is independent of ZF and that GCH is independent of ZFC.  But suppose we start with the axioms of ZF and assume they are consistent, and then add both the negation of the axiom of choice and the continuum hypothesis (i.e., CH but not GCH).  </p>

<p>Is it known whether the resulting system is consistent or inconsistent?</p>
",logic
"<p>I am thankful of Anton Klyachko who introduced axiomatic rank to me: the axiomatic rank of a variety is the minimum number of variables which we need to define that variety by identities. 
It seems clear that the axiomatic rank of the variety of groups is equal to three. But why?</p>
",logic
"<p>It is known that to prove completeness of first-order logic for countable languages WKL<sub>0</sub> is enough. But, is it the weakest subsystem where one can prove it?</p>

<p>What about the incompleteness theorems? Is it known which are the weakest subsystems of second order arithmetic where one would be able to prove each of them?</p>
",logic
"<p>The notion of an $\infty$-Borel set of reals is useful in the study of AD.  Under ZFC it becomes trivial: every set of reals is $\infty$-Borel.  However, the notion of an $\infty$-Borel <em>code</em> is still interesting.  For example, an $\infty$-Borel code $S$ gives us an absolute way to define a set of reals $(A_S)^{V[g]}$ in a generic extension $V[g]$, albeit without some of the nice properties of uB-codes.  So I have two related questions:</p>

<p>(1) What are some applications of $\infty$-Borel codes in ZFC?</p>

<p>(2) What are some applications where an $\infty$-Borel code is used to define a set of reals in a generic extension?</p>

<p>I am discounting the special case of $\omega$-Borel codes, that is, ordinary codes for Borel sets.</p>
",logic
"<p>(For simplicity, the background theory for this post is NBG, a set theory directly treating proper classes which is a conservative extension of ZFC.)</p>

<p>Vopenka's Principle ($VP$) states that, given any proper class $\mathcal{C}$ of structures in the same (set-sized, relational) signature $\Sigma$, there are some distinct $A, B\in\mathcal{C}$ such that $A$ is isomorphic to an elementary substructure of $B$. In terms of consistency, we have the following rough upper and lower bounds: $$\text{proper class of extendibles $\le$ Vopenka's Principle $\le$ almost huge.} $$ (I don't know if this is state-of-the-art; more precise bounds, if known, would be welcome!) Thus, even though on the face of it $VP$ does not directly talk about cardinals, it is generally thought of as a large cardinal axiom.</p>

<p>Now, abstract model theory appears to give a framework for generalizing VP. Let $\mathcal{L}$ be any regular logic$^*$; then we can study ""Vopenka's Principle for $\mathcal{L}$,"" $VP(\mathcal{L})\equiv$ ""For any proper class $\mathcal{C}$ of $\Sigma$-structures ($\Sigma$ a set-sized relational signature), there are distinct $A, B\in\mathcal{C}$ with $A$ $\mathcal{L}$-elementarily embeddable into $B$."" So, for example, taking $\mathcal{L}_I$ to denote first-order logic, $VP$ is just $VP(\mathcal{L}_I)$.</p>

<p>In principle, the resulting principles could have wildly varying large cardinal strengths. In practice, however, this seems to be extremely false.</p>

<p><strong>Weaker Versions:</strong> Harvey Freidman has proved (see <a href=""http://www.cs.nyu.edu/pipermail/fom/2005-August/009023.html"">http://www.cs.nyu.edu/pipermail/fom/2005-August/009023.html</a>) that $VP(\mathcal{L}_I)$ is equivalent to the statement that given any appropriate proper class $\mathcal{C}$ of structures, there are distinct $A$, $B\in\mathcal{C}$ such that $A$ is embeddable (NOT elementarily) into $B$. So $VP(\mathcal{L}_I)$ is equivalent to VP for the quantifier-free fragment of first-order logic.</p>

<p><strong>Stronger Versions:</strong> Two reasonable logics to look at for stronger versions of $VP$ are $\mathcal{L}_{II}$ and $\mathcal{L}_{\omega_1\omega}$, second-order and (the smallest standard) infinitary logic respectively. However, the corresponding Vopenka principles are still just as strong as $VP(\mathcal{L}_I)$.$^{**}$ In general, $VP(\mathcal{L}_I)$ seems to be an upper bound for Vopenka's Principles for locally set-sized, definable logics. Since non-definable logics are of limited interest, it's reasonable to look at class-sized logics. The tamest class-sized logic I know of is $\mathcal{L}_{\infty\omega}$, the infinitary logic allowing arbitrary set-sized Boolean combinations but no infinite strings of quantifiers. However, $VP(\mathcal{L}_{\infty\omega})$ is inconsistent: by a famous theorem of Carol Karp, two structures are $\mathcal{L}_{\infty\omega}$-equivalent if and only if they are back-and-forth equivalent, so the class $\mathcal{O}$ of all ordinals (regarded as linear orderings) is a counterexample in any model of $ZFC$.</p>

<p>This all suggests that there are probably no interesting versions of Vopenka's Principle stronger than the usual one, and that any weaker form of Vopenka has to come from a horribly weak - to the point of being probably uninteresting - logic. I find this kind of disappointing. So, my question is:</p>

<blockquote>
  <p>Are there any interesting logics $\mathcal{L}$ for which $VP(\mathcal{L})$ is different from the usual Vopenka's Principle?</p>
</blockquote>

<hr>

<p>$^*$ The definition of ""regular logic"" is long and tedious, but it can be found in Ebbinghaus and Flum's book ""Mathematical Logic"" (Definitions 12.1.2 and 12.1.3). For this post, the details don't really matter; the key points are that the structures considered are the same as for first-order logic, and that everything is classical (i.e., two truth values).</p>

<p>$^{**}$ The proof for $\mathcal{L}_{II}$ goes as follows. Suppose $V\models VP(\mathcal{L}_I)$, and let $\mathcal{C}\in V$ be a proper class of structures in a set-sized relational signature $\Sigma$. Let $\Sigma'$ be the signature consisting of $\Sigma$ together with a new unary relation symbol $S$ and a new binary relation symbol $E$. In $V$, we can construct the class $\mathcal{C}'$ of structures of the form $$ A':= A\sqcup (\mathcal{P}(A)\times\lbrace A\rbrace), \quad  S^{A'}=\mathcal{P}(A)\times\lbrace A\rbrace, \quad E^{A'}=\lbrace (a, b): a\in A, b=(X, A), a\in X\rbrace  $$ for $A\in\mathcal{C}$. Now second-order quantification over a structure in $\mathcal{C}$ can be replaced with first-order quantification over the $S$-part of the corresponding structure in $\mathcal{C}'$. So if $A'$ is first-order elementarily embeddable into $B'$, $A$ must be second-order elementarily embeddable into $B$, so since $V\models VP(\mathcal{L}_I)$ we're done. The proof for $\mathcal{L}_{\omega_1\omega}$ follows similar lines.</p>
",logic
"<p>I am trying to understand why induction up to exactly $\epsilon_0$ is necessary to prove the cut-elimination theorem for first-order Peano Arithmetic; or, as I understand, equivalently, why the length of a PA-proof with all cuts eliminated grows (in the worst case) as fast as $f_{\epsilon_0}$ in the fast-growing hierarchy.</p>

<p>I can understand why use of an induction axiom corresponds to ordinal multiplication by $\omega$.  As induction axioms are written in the sequent calculus, as a premise we have a proof of $\phi(x)\vdash\phi(Sx)$ for a free variable $x$, and as a conclusion we get $\phi(0)\vdash\phi(y)$ for any term $y$.</p>

<p>Then if the proof of $\phi(x)\vdash\phi(Sx)$ has the ordinal $\omega^\alpha$, the proof with the conclusion $\phi(0)\vdash\phi(y)$ is assigned the ordinal $\omega^{\alpha+1}$.  E.g. if the proof of the induction step had ordinal $\omega^0 = 1$, then the conclusion $\phi(y)$ has the ordinal $\omega^1 = \omega$.</p>

<p>This part makes perfect sense to me, because if I wanted to eliminate the use of an induction rule (CJ sequent) I might just start with $\phi(0)$ and repeatedly go through the part of the proof that I used to prove $\phi(x)\vdash\phi(Sx)$.  Say, I'd repeat the sub-proof of the induction step 17 times, e.g. with $\phi(14)\vdash\phi(15)$ and so on, until I got to $\phi(17)$, or whichever number I wanted to prove $\phi$ about.</p>

<p>I don't quite understand how this corresponds to eliminating <i>cuts</i>, per se (it seems to create a host of new cuts, in fact).  But it is still very <i>intuitive</i> to me that Peano Arithmetic's power to invoke the induction axiom would correspond to multiplication by $\omega$.  If we take a proof in PA that ends with a single use of the induction axiom to get $\phi(y)$, and we want to translate it into a proof in an arithmetic theory that doesn't have induction, then we might have to multiply the PA-proof-length by any finite number (e.g. multiply it by 17) to get the proof length in the inductionless theory.</p>

<p>Repeated multiplication by $\omega$ only takes us up to $\omega^\omega$ as a proof-theoretic ordinal, though.</p>

<p>According to Gentzen, when we use cuts on formulas involving quantifiers, e.g. $\forall p:\exists q:\psi(p,q)$, this corresponds to ordinal exponentiation.  If the proof above the cut has ordinal $\alpha$ and we cut a formula with one quantifier, then the proof below the cut has ordinal $\omega^\alpha$.  If we cut on two quantifiers, the proof below the cut has ordinal $\omega^{\omega^\alpha}$.  This fits with other things I've heard about how PA using formulas with only N quantifiers can be proven consistent by PA using only N+1 quantifiers.  (As a side issue I'd be interested in knowing how you use N quantifiers to prove wellfoundedness of an ordinal notation for a stack of $\omega$s N layers high.)</p>

<p>What I don't understand is why the ability to use quantifiers corresponds to ordinal exponentiation.  I can guess in a vague sense that if we have a proof using $\forall p:\phi(p)\vdash\phi(17)$, and we want to eliminate the use of $\forall p:\phi(p)$, then we need to repeat that part of the proof each time we want to prove $\phi(17)$, $\phi(q)$, and so on.  But this would again just imply that we needed to repeat that part of a proof a finite number of times, and iterating this takes us up to only $\omega^\omega$, not the desired $\epsilon_0$, so I must be missing something.</p>

<p>I asked a friend to help with this and she's read through Gentzen's relevant papers, and she's shown me the relevant parts, and I'd previously checked several standard texts on proof theory and Googled around, and she's also shopped the question around the logic department of a major university, and we still don't know any answer to this except ""because Gentzen says to use ordinal exponentiation"".</p>

<p>We also can't find any examples of cut-elimination being carried out on a proof with cut on a quantified formula, which shows how the size of the resulting cut-free proof could grow faster than $f_{\omega^\omega}$.  An example like this for some particular proof would be <i>very</i> helpful, even if, of necessity, the repeated steps for eliminating the cut are sketched more than shown.  I can understand why the length of a Kirby-Paris hydra game grows at the same rate as the Goodstein sequence, and visualize both processes insofar as a human being possibly can.  I cannot visualize why the length of a PA-proof heading for cut-freeness would grow at that same rate as cuts were repeatedly eliminated.  (Mapping the process onto a Kirby-Paris hydra game of starting height at least 3 would answer the question!)</p>
",logic
"<p>I first quote a definition from Clone theory in Universal Algebra: A binary relation $\rho$ on a set U is strongly rigid if every universal algebra on U such that $\rho$ is a subuniverse of its square is trivial, i.e., the clone preserving ρ has only projections. It is known that there are only two strongly rigid relations on a 3-element domain. I found that</p>

<p>1) On a 4-element domain {0,1,2,3}, the following binary relation is possibly a strongly rigid relation:
{(0,1), (0,2), (0,3), (1,0), (1,2), (2,0), (2,1), (2,3), (3,1), (3,2)}</p>

<p>2) On a 5-element domain {0,1,2,3,4}, the following relation is possibly a strongly rigid relation:
{(0,2), (0,3), (0,4), (1,0), (1,3), (1,4), (2,0), (2,1), (2,4), (3,0), (3,1), (3,2), (3,4), (4,0), (4,1), (4,2), (4,3)}.</p>

<pre><code> Could you let me know if there is an easy way to prove the above statements?
</code></pre>

<p>This could be an algebraic proof, or by using a computer program.</p>
",logic
"<p>If I'm not mistaken, it was in his seminal paper “An Essentially Undecidable Axiom System”, published in </p>

<p>Proceedings of the International Congress of Mathematics (1950), 729–730,</p>

<p>where R.M. Robinson proved that Gödel Incompleteness Theorem still applies to Peano Axioms if we drop the induction schema (hence showing that infinite axiomatization is not necessary for essential undecidability), in what we now call Robinson Arithmetic.</p>

<p>I would like to know:</p>

<ul>
<li>Is actually this paper what I should be looking for?</li>
<li>Can it be found anywhere on the net? (I already tried on MathSciNet, SpringerLink, JSTOR and Google Scholar, without success)</li>
<li>Can anyone pinpoint to closely related, or at least similar, accessible papers?</li>
</ul>

<p>(Note: I already have the book ""Undecidable theories"", which he published in collaboration with Tarski, but I'd prefer to locate papers about 'Robinson theory', specifically).</p>
",logic
"<p>Assume DC($\aleph_1$).</p>

<p>Can we define the following: </p>

<ol>
<li>Basis for a vector space $V$ over a field $K$ such that $\operatorname{card}(K) \leq \aleph_1$ and we happen to find a generating set of $V$ of cardinality $\leq \aleph_1$. </li>
<li>Linear dimension making the same assumption as above.</li>
<li>Transcendence degree of a field $K$ over $\mathbb{Q}$ if we happen to know that $K$ is of cardinality $\leq \aleph_1$.
etc...</li>
</ol>
",logic
"<p>Question <a href=""http://mathoverflow.net/questions/138790/is-there-any-forcing-free-proof-for-hard-independence-results#comment358616_138790"">Is there any forcing free proof for hard independence results?</a>  talks about the use of forcing for independence results such as: $Con(ZFC)\longrightarrow Con (ZFC+\neg CH) $.  For that case (and its companions $V=L$ and $AC$)  constructibility is used for the other half of the independence: $Con(ZFC)\longrightarrow Con (ZFC+ CH) $.</p>

<p>Is this typical?  Do later independence results still tend to use forcing one way, and $V=L$ the other?  Are there independence results where forcing is used in both directions?  </p>

<p>Are there statements $S$ where forcing is used for both $Con(ZF+S)$ and $Con(ZF+\neg S)$?</p>

<p>Question <a href=""http://mathoverflow.net/questions/118477/is-every-class-that-does-not-add-sets-necessarily-added-by-forcing"">Is every class that does not add sets necessarily added by forcing? </a> mentions use of forcing over a model of $NBG$ to add a universal choice function.  But I do not know for whether you would also use forcing to eliminate that version of global choice in that context.</p>
",logic
"<p>Let's start with some family of algebraic structures of the same type indexed by the natural numbers, say the symmetric group $S_n$.  Suppose that the axioms of this algebraic structure (in this case, groups) can be stated within the framework of first-order logic.  In this way, we can consider a structure $M$ defined as follows: it contains $\mathbb{N}$, as well as all the $S_n$.  Consider the complete theory $Th(M)$ in first-order logic (i.e. containing all the symbols of $M$ and a symbol for each relation on $M$ of any arity).</p>

<p>In this theory, there are relations $m, e, i$ that correspond to the relations of multiplication, identity, and inverse, and a relation $P$ such that $P(a,b)$ iff $a \in S_n$ and $b = n$.  There are a bunch of axioms that are satisfied, e.g. if $P(a,b)$ then $P( i(a), b)$ and $m( a, i(a)) = e(b)$, etc., that correspond to the group laws.  There is also a relation $isParameter$ that tells you whether the object in question is a parameter (i.e. a natural number).</p>

<p>So, in this way (am I misunderstanding this?) one can use an ultraproduct construction (or the compactness theorem applied to $Th(M)$ together with the collection of sentences $isParameter(c) \wedge c&gt; 1 + \dots + 1$ where $c$ is some new constant symbol) to embed $M$ in a bigger structure $M'$ where there are parameters greater than all the standard elements of $\mathbb{N}$, i.e. where the parameters are (some version of) the hypernatural numbers.  Since the group $S_n$ is nonempty for each standard $n$, it should follow by transfer that $S_n$ is also defined for infinite $n$.  It must be a group by transfer.</p>

<blockquote>
  <p><strong>Question:</strong> Is $S_{n}$ for infinite $n$ in any way related to the set of
  permutations of the interval from $1$
  to $n$?  If not, what can we say about it?</p>
</blockquote>

<p>My hunch is that this probably isn't the case, because ""every permutation is contained in $S_n$"" sounds like a second-order statement and this is first-order logic we're dealing with.  Nevertheless, I'm curious about what we can say about $S_{n}$ for infinite $n$, and whether we can deduce additional properties about $S_n$ for infinite $n$ from the known theory for finite $n$.</p>
",logic
"<p>By the Kirby–Paris theorem, Goodstein's theorem is independent of Peano arithmetic (PA). Therefore there are non-standard models in which every Goodstein sequence terminates. However, Tennenbaum's theorem states that there is no countable recursive non-standard model of PA. So in what sense do Goodstein sequences in non-standard models terminate? Do they terminate after a non-standard number of steps?</p>
",logic
"<p>Here, $E_1$ denotes the set of arithmetic formulas starting with a bounded existential quantifier, followed by a quantifier-free formula. Is there an $E_1$-formula $\phi$ such that $\phi(n)$ holds
iff $n$ is prime? If yes, it is likely to be rather complicated to obtain, as this apparently implies that PRIMES is in P.
Clearly, there is such a $U_1$-formula (i.e. one starting with a bounded universal quantifier instead). And of course there's this famous prime polynomial, but this gives a $\Sigma_1$-statement where the variables correspond to exponentiations and factorials, so certainly there can be no polynomial bounds for them.</p>
",logic
"<p>Trying to figure out the logic in which the following formula is expressible:
$\forall i\in N: (x_i &gt; y_i)$, which is equivalent to the ""infinite"" conjunction $\bigwedge_{i\in N} (x_i &gt; y_i)$.</p>

<p>Now a 1st order logic allows arbitrary number of variables $\{x_i,y_i\mid i\in N\}$, but only a finite number of atomic formulas can be composed. (Here $x_i &gt; y_i$ is an atomic formula based on binary predicate ""$&gt;$"", and so the above formula is a composition of infinite number of atomic formulas.) Thus in the form written, the above doesn't seem to be a formula of 1st-order logic. Also, it's not clear how to rewrite this formula in 1st-order logic if indeed it belongs there.</p>

<p>Next in 2nd-order logic, that allows quantification over predicates (as well as functions), again it is not clear whether the above can be written as formula in 2nd-order logic.</p>

<p>Any insights? Thanks.</p>
",logic
"<p>Are Lascar strong types (definition below) in models of fragments of arithmetic always type definable? (They trivially are, in models of full induction.)</p>

<p><strong>Definition</strong> Given a saturated model ${\cal M}$ and a set $A\subseteq{\cal M}$ the Lascar graph over $A$ has an arc between $a,b\in{\cal M}$ if $a\equiv_Mb$ for some $A\subseteq M\preceq{\cal M}$. The Lascar strong type of $a$ is the set of the $c\in{\cal M}$ that are in the same connected component of $a$.</p>
",logic
"<p>If $\phi$ is any formula of set theory with just one free variable $x$, the abstraction term $A_{\phi}=\lbrace x | \phi(x) \rbrace$ is either a set or a proper class. Assume that ZFC is consistent, or any large cardinal axiom you like. Then my question is, are there two formulas 
$\phi$ and $\psi$ such that ZFC+($A_{\phi}$ is a set) is consistent, ZFC+($A_{\psi}$ is a set) is consistent also, but ZFC+($A_{\phi}$ and $A_{\psi}$ are both sets) is not?</p>

<p>UPDATE 09/15/2011 : to avoid  ""cheating"" as in François Dorais' answer, we may introduce the following additional constraint : if $T$ is any theory extending $ZFC$, say that the abstraction term $A_{\phi}=\lbrace x | \phi(x) \rbrace$ is small in $T$ if $T$ proves that $A_{\neg \phi}$ is not a set ; for example, if $\phi(x)$ is  ""x is an accessible ordinal"" or ""all cardinals below the ordinal $x$ are not measurable"" or ""all cardinals below the ordinal $x$ are not Mahlo"" then $A_{\phi}$ will be small, but this will not be the case if $\phi$ is an undecidable statement independent of $x$ as in Francois Dorais' answer.</p>

<p>The question then becomes, are there two formulas $\phi$ and $\psi$ such that 
$A_{\phi}$ and $A_{\psi}$ are both small in $ZFC$, ZFC+($A_{\phi}$ is a set) is consistent, ZFC+($A_{\psi}$ is a set) is consistent also, but ZFC+($A_{\phi}$ and $A_{\psi}$ are both sets) is not?</p>
",logic
"<p>Let $M$ be a model of $\sf ZFC$ in which $\kappa$ is a measurable cardinal, and $\cal U$ is a normal measure on $\kappa$. We can define the Prikry forcing (the most simple one) as the poset: $$\Bbb P=\left\{(p,A)\mid p\in[\kappa]^{&lt;\omega}, A\in\mathcal U, \max p&lt;\min A\right\}.$$
We also define the order, $(q,B)$ is stronger than $(p,A)$ if $q$ is an end-extension of $p$, $B\subseteq A$ and $q\setminus p\subseteq A$. The generic $G$ adds an $\omega$-sequence, $x_G=\bigcup\{q\mid\exists A:(q,A)\in G\}$ which we call a <em>Prikry sequence</em>. We can show that $x\subseteq^* A$, for all $A\in\cal U$, that is $x\setminus A$ is finite.</p>

<p>In the other direction, if $M$ is a model of $\sf ZFC$ in which $\kappa$ is measurable, and $M\subseteq V$, such that in $V$ we have some $x\in[\kappa]^\omega$ such that for some $\cal U$ in $M$ which is a normal measure on $\kappa$, $x\subseteq^*A$ for all $A\in\cal U$, then $x=x_G$ for some generic filter $G$ over the Prikry forcing defined from $\cal U$.</p>

<p>One conclusion from this last statement is that if $x$ is a Prirky sequence for $\kappa$, and $y\subseteq x$ is infinite then $y$ is also a Prikry sequence. This raises the following question.</p>

<blockquote>
  <p>Suppose that $x$ is a Prikry sequence for $\kappa$, and $y\subseteq x$ is infinite. Is $x$ generic over $y$? More generally, if $y,w\subseteq x$ are disjoint infinite subsets, are they pairwise generic? What about the weaker condition $y\cap w$ being finite?</p>
</blockquote>
",logic
"<p>I am wondering what is the accepted version of the strong order property in continuous logic.</p>

<p>The definition for classical logic is as follows:
$T$ has SOP$_n$ (for $n\geq 3$) if there is a formula $\varphi(x,y)$ (where $x$ and $y$ are tuples of the same length) and a sequence $(a_i)_{i&lt;\omega}$ (in some large model of $T$) such that</p>

<ol>
<li>$\varphi(a_i,a_j)$ holds for all $i&lt;j$;</li>
<li>$\neg\exists x_1\ldots x_n(\varphi(x_1,x_2)\wedge\ldots\wedge\varphi(x_{n-1},x_n)\wedge\varphi(x_n,x_1))$.</li>
</ol>

<p><br/><br/></p>

<p>The most direct guess for continuous logic would be to just replace ""$\varphi(x,y)$ holds"" with ""$\varphi(x,y)=0$"".</p>

<p>$T$ has SOP$_n$ (for $n\geq 3$) if there is a formula $\varphi(x,y)$ (where $x$ and $y$ are tuples of the same length) and a sequence $(a_i)_{i&lt;\omega}$ (in some large model of $T$) such that</p>

<ol>
<li>$\varphi(a_i,a_j)=0$ for all $i&lt;j$;</li>
<li>$\inf_{x_1,\ldots,x_n}\max\{\varphi(x_1,x_2),\ldots,\varphi(x_{n-1},x_n),\varphi(x_n,x_1)\}&gt;0$.</li>
</ol>

<p><br/></p>

<p>I am concerned that is translation is too direct and not ""approximate"" enough. Although it does admit the same characterization as in classical logic of being able to make directed cycles out of the 2-type of an indiscernible sequence:</p>

<p>The following are equivalent.</p>

<ol>
<li>$T$ has SOP$_n$.</li>
<li>There is an indiscernible sequence $(a_i)_{i&lt;\omega}$ such that if $p(x,y)=\textrm{tp}(a_0,a_1)$ then
$$
p(x_1,x_2)\cup\ldots\cup p(x_{n-1},x_n)\cup p(x_n,x_1)
$$
is unsatisfiable.</li>
</ol>

<p>This statement works equally well in the classical or continuous setting (with the definitions above).</p>

<p><br/><br/></p>

<p>If this continuous definition for SOP$_n$ is acceptable, then it seems like the most reasonable way to define the strong order property is just to say:</p>

<p>$T$ has the <b>strong order property</b> if there is a formula $\varphi(x,y)$ (where $x$ and $y$ are tuples of the same length) and a sequence $(a_i)_{i&lt;\omega}$ (in some large model of $T$) such that</p>

<ol>
<li>$\varphi(a_i,a_j)=0$ for all $i&lt;j$;</li>
<li>for all $n\geq 3$, $\inf_{x_1,\ldots,x_n}\max\{\varphi(x_1,x_2),\ldots,\varphi(x_{n-1},x_n),\varphi(x_n,x_1)\}&gt;0$.</li>
</ol>

<p><br/><br/></p>

<p>So my questions are:</p>

<ol>
<li>Are these definitions for the strong order property good?</li>
<li>If not, what is the right definition and why don't the ones above work?</li>
</ol>
",logic
"<p>In the last part of Kanamori's excellent ""The Higher Infinite"" there is a small diagram about the strength and consistency strength of some major large cardinal axioms.</p>

<p>Below supercompact cardinals there are two then-incomparable cardinals. Superstrong cardinals and strongly compact cardinals, both are stronger than Woodin cardinals </p>

<p>Has there been any progress on this problem since then? If yes, is there some reference? If not, can someone give basic outline as to why this problem is difficult? (I am somewhat familiar with the problem of extender models for very large cardinals, so an concise similarities if they exist would suffice).</p>
",logic
"<p>My function is $f:\mathbb{N} \rightarrow \mathbb{N},\ f(n)=2\uparrow ^n 3$ , the Ackermann(-Péter) function, with the second argument fixed to 3 (and ""$\uparrow$"" the Knuth up-arrow), which I believe is not primitive recursive, but which I could not prove - and that is what this question is about. Any ideas for the proof are very welcome.</p>

<p>Explanation: </p>

<p><strong>Idea 1</strong>
I have tried to prove that it is not primitive recursive in the lines of the proof that the Ackermann function is not primitive recursive - meaning I tried to prove, that my function $f$ bounds in some way all the other primitive recursive functions, so that I arrive at a contradiction, if I assume, that $f$ would be primitive recursive, because than it would bound itself.
The way in which I tried to prove, that $f$ should bound all the other functions was: If $g$ is an arbitrary primitive recursive $k$-ary function $g:\mathbb{N}^k \rightarrow \mathbb{N}$, than there exists an natural number $N$, such that for all $n_1 , ..., n_k &gt; N$ we get $  g(n_1, ... ,n_k) &lt; f(n_1 + ... +n_k)$.</p>

<p>I thought I could try to prove this by trying to prove, that the set of all primitive recursive functions, which are bounded by f like described above, fulfills the properties which the primitive functions have to fulfill (the ""standart"" functions belong to this set, the set is closed under composition, the set is closed under primitive recursion). Since the primitive recursive functions are the smallest set, that fulfills these properties, I would obtain that this set has to equal the set of all the primitive recursive functions, which would the give me my contradiction.
But this proof failed as well, because I can't show, that this set is closed under composition - that is, I can't show that given functions $h:\mathbb{N}^l \rightarrow \mathbb{N}$ and $g:\mathbb{N}^k \rightarrow \mathbb{N}$, which have the property, that:</p>

<p>$\exists N_1 \ \forall n_1,\ldots,n_{l}&gt;N_1$ such that $h(n_1 ,\ldots ,n_{l})&lt;2 \uparrow^{n_1 + \ldots + n_{l}} 3$ </p>

<p>and </p>

<p>$\forall i \in $ {$ 1,\ldots,l $}$ \ \exists N_{i+1} \ \forall n_1,\ldots, n_{k} &gt; N_{i+1} $ such that $g_i(n_1, \ldots ,n_{k})&lt;2 \uparrow^{n_1 + \ldots + n_{k}} 3$ </p>

<p>then there should exists an $N$ such that $\forall n_1,\ldots,n_{k}&gt;N$ we should also have, that $t(n_1,\ldots,n_k):=f(g_1(n_1,\ldots ,n_k),\ldots ,g_l(n_1,\ldots,n_k))&lt;2 \uparrow^{n_1 + \ldots + n_{k}} 3$.</p>

<p>In trying to prove the this, I somehow have to make use of the above properties of the functions $g_i$ and $h$. But I can't use the ""boundedness"" of $h$ because I can't control how much the functions $g_i$ grow - if there aren't values $n_1,\ldots ,n_k$ such that each of the $g_i$'s grow above $N_1$, then I can't make use of $h$'s properties.
Maybe there is some other way to prove the closedness under composition, but I can't see it. </p>

<p><strong>Idea 2</strong></p>

<p>I have tried, to proceed indirectly and to assume, that my $f$ would be primitive recursive - the idea was to construct out of this now primitive recursive $f$ another primitive recursive function, that would violate the ""Ackermann""-bound - in the sense of the original proof, where one proves that the Ackermann function is not primitive recursive, by first establishing this ""Ackermann"" bound which all primitive recursive functions have to obey and then showing, that if the Ackermann function is assumend to be primitive recursive one obatains a contradiction.</p>

<p>Could anyone please give me an idea how to finish one of this proof ?</p>
",logic
"<p>The Gandy-Harrington topology on $\omega^\omega$ is the topology generated by all lightface $\Sigma^1_1$ sets; that is, all sets which are continuous-in-the-usual-sense images of $\omega^\omega$.</p>

<p>Although this topology is definitely less nice than the standard one - for example, it is non-metrizable - it satisfies the <em>strong Choquet property</em>: this is the statement that player I has a winning strategy in a certain topological game. From the strong Choquet property we can deduce many results whose proof would follow easily from metrizability, so in some sense the Gandy-Harrington topology is ""close enough"" to metrizable. One particularly nice result we can show is: if $A$ is a nonempty lightface $\Sigma^1_1$ subset of $\omega^\omega$, then $A$ has an element $x$ such that $\mathcal{O}^x\equiv_T\mathcal{O}\oplus x$.</p>

<p>A natural question now is to ask about topologies generated by lightface sets further up the projective hierarchy; e.g., let $\tau_k$ be the topology on $\omega^\omega$ generated by lightface $\Sigma^1_k$ sets. And similarly, we can define $\tau_\Gamma$ for any pointclass $\Gamma$ (although we're probably only interested in, say, Spector pointclasses). Unfortunately, for $k&gt;1$ the strong Choquet property fails badly in $\tau_k$!</p>

<p>My question is:</p>

<blockquote>
  <p>Is there a weakening of the strong Choquet property that holds for $\tau_2$? (Or more generally for $\tau_\Gamma$ for nice enough pointclass $\Gamma$.)</p>
</blockquote>

<p>Relatedly, for a real $x$ let $\mathcal{O}_2^x$ be the set of $x$-computable codes for nonempty $\Sigma^1_2$ sets, and let $\mathcal{O}_2=\mathcal{O}_2^\emptyset$.</p>

<blockquote>
  <p>Is it the case that every lightface $\Sigma^1_2$ subset of $\omega^\omega$ contains an $x$ with $\mathcal{O}_2^x\equiv_T\mathcal{O}_2\oplus x$?</p>
</blockquote>

<p><em>I've tagged ""set-theory"" and ""inner-model-theory"" because it seems reasonable to me that answers might depend on structural hypotheses about the universe; feel free to remove either tag if this seems bonkers.</em></p>
",logic
"<p>I seem to remember having read that the proof-theoretic ordinal (sup of ordinals the theory can prove well-ordered) of $\mathsf{PA} + \mathsf{Con}(\mathsf{PA})$ is the same as that of $\mathsf{PA}$, namely $\epsilon_0$. However, the one particular source where I remember reading something like this is <a href=""https://www1.maths.leeds.ac.uk/~rathjen/realm.pdf"">The Realm of Ordinal Analysis</a> by Michael Rathjen (bottom of p.9), but this is less unambiguous than I thought. Is this statement true? If so, do $\mathsf{PA} + \mathsf{Con}(\mathsf{PA} + \mathsf{Con}(\mathsf{PA}))$ etc. have the same proof-theoretic ordinal as well? What's a good reference for this?</p>
",logic
"<p>We're interested in recursive predicates $P(n)$ with RE range $R$ and non-RE complement $R^\prime$.  For various $n \in R^\prime$ we may be able to prove that $n \in R^\prime$.  For instance, if $P$ is the halting problem, then we can build a non-halting algorithm, figure out its index $n$, and we then know that $n \in R^\prime$.  Another example is provability: if $P(n)$ is ""the statement [with G&ouml;del number] $n$ is provable"", then we can prove that if $n$ is [the G&ouml;del number of] the G&ouml;del Sentence, then $n \in R^\prime$.</p>

<p>What I'm asking is whether there is any such recursive predicate $P(n)$ for which no member of $R^\prime$ is provably in $R^\prime$?</p>
",logic
"<p>We take an ordered ring to be a structure of type $(+ - \times &lt; 0\,\, 1)$ satisfying the usual axioms. If $A$ is an ordered ring then we say that an element $a$ of $A$ is infinitesimal if for all integers $n$ it holds that $-1&lt;na&lt;1$.</p>

<p>Let $T$ be the set of sentences that hold in every ordered ring that has no infinitesimal elements other than 0. </p>

<p>Question: Is $T$ effectively enumerable? Is the set of universal sentences of $T$ effectively enumerable? </p>
",logic
"<p>This question continues the line of inquiry
of <a href=""http://mathoverflow.net/questions/15957"">these</a>
<a href=""http://mathoverflow.net/questions/16532"">three</a>
<a href=""http://mathoverflow.net/questions/16565"">questions</a>.</p>

<p><b>Question.</b> Which finitely presented groups can be
distinguished by decidable properties?</p>

<p>To be precise, let us say that &phi; is a <em>decidable</em> property of finitely
presented groups, if there is a class A of finitely
presented groups, closed under group isomorphisms, such that
{ p | &lang;p&rang; &isin; A } is decidable, where &lang;p&rang; denotes the group presented by p. That is, we insist that the decision procedure give the same answer for presentations leading to the same group up to isomorphism.</p>

<p>One extreme case, perhaps unlikely, would be that any two non-isomorphic
finitely presented groups can be distinguished by decidable
properties, so that for any two finitely presented
non-isomorphic groups &lang;p&rang; and &lang;q&rang;,
there is a decidable property &phi; where &phi;(p) holds
and &phi;(q) fails. That would be quite remarkable. </p>

<p>If this is not the case, then there would be two finite group
presentations p and q, such that the groups presented
&lang;p&rang; and &lang;q&rang; are not isomorphic, but
they have all the same decidable properties. This also
would be remarkable. </p>

<p>Which is the case?</p>

<p>Another way to describe the question is in terms of the
equivalence relation &equiv;, which I introduced in <a href=""http://mathoverflow.net/questions/16532"">my
previous question</a>, where p
&equiv; q if &phi;(p) and &phi;(q) have the same answer for
any decidable property &phi; of finitely presented groups. This
is precisely the equivalence relation of ""having all the
same decidable properties"". Of course, this includes the
group-isomorphism relation, and the current question is
asking: What is this relation &equiv;? In particular, is
&equiv; the same as the group isomorphism relation?
If it is, then any two non-isomorphic finitely presented
groups can be distinguished by decidable properties; if
not, then there are two finitely presented non-isomorphic
groups &lang;p&rang;, &lang;q&rang; having all the same
decidable properties.</p>

<p>Henry Wilton has emphasized several times that there are
relatively few truly interesting decidable properties of
finitely presented groups. This may very well be true.
Nevertheless, the answers to the previous MO questions on
this topic have provided at least <em>some</em> decidable
properties, and my question here is asking the extent to
which these properties are able to distinguish any two
finitely presented groups.</p>

<p>In particular, in these previous MO questions, <a href=""http://mathoverflow.net/questions/15957"">Chad Groft</a>
inquired whether there were
any nontrivial decidable properties of finitely presented
groups. <a href=""http://mathoverflow.net/questions/15957#16122"">John Stillwell's 
answer</a> was
that one could decide many questions about the
abelianization of the group. In a <a href=""http://mathoverflow.net/questions/16532"">subsequent question</a>, I
inquired whether all decidable properties were really about
the abelianization, and <a href=""http://mathoverflow.net/questions/15957#16122"">David Speyer's
answer</a> was
that no, there were questions about other quotients, such
as whether the group had a nontrivial homomorphism into a
particular finite group, such as A<sub>5</sub>. In a <a href=""http://mathoverflow.net/questions/16565"">third question</a>, David generalized further and inquired
whether all decidable properties depended on the
profinitization, and the answer again was no (provided by David and Henry). So at least
in these cases we have been increasingly able to separate
groups by decidable properties.</p>

<p>A generalization of the question would move beyond the
decidable properties. For example, if we consider the
computably enumerable (c.e.) properties, then we have quite
a lot more ability to distinguish groups. A property is
c.e. if there is a computable algorithm to determine the
positive instances of &phi;(p), but without requiring the
negative instances to ever converge on an answer. For
example, the word problem for any finitely presented group,
or indeed, for any computably presented group, is
computably enumerable, since if a word is indeed trivial, we will eventually discover this. Using the same idea as David's answer to my question, it follows that the question of
whether a finitely presented group &lang;p&rang; admits a
nontrivial homomorphism into the integers Z, say,  or many other
groups, is computably enumerable. One may simply try out all possible maps of the generators. A generalization of
this establishes:</p>

<p><b>Theorem.</b> The question of whether one finitely
presented group &lang;p&rang; maps homomorphically onto (or into) another &lang;q&rang; is computably enumerable.</p>

<p>The proof is that given p and q, one can look for a map of
the generators of p to the words of q, such that all
relations of p are obeyed by the image in q, and such that
all the generators of q are in the range of the resulting
map. This is a c.e.
property, since one can look for all possible candidates
for the map of the generators of p into words of q, and
check whether the relations are obeyed and the generators
of q are in the range of the map and so on. If they are,
eventually this will be observed, and at the point one can
be confident that &lang;p&rang; maps onto &lang;q&rang;. More generally, is the isomorphism relation itself c.e.? It is surely computable from the halting problem 0', since we could ask 0' whether the kernel of the proposed map was trivial or not, and it would know the answer. </p>

<ul>
<li>Where does the isomorphism relation on finitely
presented groups fit into the hierarchy of Turing
degrees? Is it c.e.? Is it Turing equivalent to the Halting problem?</li>
</ul>

<p>Once one moves to the c.e. properties, it is similarly
natural to move beyond the finitely presented groups to the
computably presented groups (those having a computable
presentation, not necessarily finitely generated). In this
context, the proof above no longer works, and the natural
generalization of the question asks:</p>

<ul>
<li>Which computably presented groups are distinguished by
c.e. properties?</li>
</ul>

<p>The isomorphism relation on finitely generated computably
presented groups (given the presentations) seems to be
computable from the halting problem for the same reason as
in the proof above, but now one doesn't know at a finite
stage that the proposed map of the generators will
definitely work, since one must still check all the
relations-yet-to-be-enumerated. But 0' knows the answer, so
we get it computably in 0'. In the infinitely generated case,
however, things are more complicated.</p>
",logic
"<p>Y. Sergeyev developed a positional system for representing infinite numbers using a basic unit called a ""grossone"", as well as what he calls an ""infinity computer"".  The mathematical value of this seems dubious but numerous articles have already appeared in refereed <em>research</em> journals.  Thus, there are 19 such articles in <a href=""http://www.ams.org/mathscinet/search/publications.html?pg4=AUCN&amp;s4=sergeyev&amp;co4=AND&amp;pg5=TI&amp;s5=&amp;co5=AND&amp;pg6=JOUR&amp;s6=&amp;co6=AND&amp;pg7=ALLF&amp;s7=infinit*&amp;co7=AND&amp;dr=all&amp;yrop=eq&amp;arg3=&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;pg8=ET&amp;s8=All&amp;review_format=html&amp;Submit=Search"" rel=""nofollow"">mathscinet</a> not to speak of numerous lectures in conferences.  </p>

<p>What I find most puzzling is a piece by G. Lolli <a href=""http://www.sciencedirect.com/science/article/pii/S0096300314005116"" rel=""nofollow"">here</a> that seems to analyze this as a serious phenomenon in logic/foundations. I would appreciate a reasoned technical view from experts in the field.</p>

<p>Note 1. Since the response by user ""none"" cites Lou Kauffman's ""grossone"" article in category theory, I added the appropriate tag.</p>

<p>Note 2. ""none"" mentioned similarity to the <em>sur</em>reals but Sergeyev himself compares his theory to the <em>hyper</em>reals, hence the tag.</p>

<p>Note 3. In a comment accessible <a href=""http://link.springer.com/article/10.1007/s00283-015-9600-7"" rel=""nofollow"">here</a> Sergeyev asserts that ""Levi-Civita numbers are built using a generic infinitesimal $\varepsilon$ ... whereas our numerical computations with finite quantities are concrete and not generic.""  Here apparently ""finite"" is a misprint and should be ""infinite"". How is this comment on the difference between Sergeyev's grossone one the one hand, and the Levi-Civita unit on the other, to be understood?</p>

<p>Note 4. In a 2013 article, Sergeyev compares his grossone to Levi-Civita in the following terms in footnote 5: <em>5 At the first glance the numerals (7) can remind numbers from the Levi-Civita field (see [20]) that is a very interesting and important precedent of algebraic manipulations with infinities and infinitesimals. However, the two mathematical objects have several crucial differences. They have been introduced for different purposes by using two mathematical languages having different accuracies and on the basis of different methodological foundations. In fact, Levi-Civita does not discuss the distinction between numbers and numerals. His numbers have neither cardinal nor ordinal properties; they are build using a generic infinitesimal and only its rational powers are allowed; he uses symbol 1 in his construction; there is no any numeral system that would allow one to assign numerical values to these numbers; it is not explained how it would be possible to pass from d a generic infinitesimal h to a concrete one (see also the discussion above on the distinction between numbers and numerals). In no way the said above should be considered as a criticism with respect to results of Levi-Civita. The above discussion has been introduced in this text just to underline that we are in front of two different mathematical tools that should be used in different mathematical contexts.</em> It would be interesting to have a specialist in numerical analysis comment on Sergeyev's use of the term ""numerical"" to explain the difference between his grossone and an infinite element of the Levi-Civita field.</p>

<p>Note 5. The latest installment of grossone numerals appeared in <em>The Mathematical Intelligencer</em> <a href=""http://link.springer.com/article/10.1007/s00283-014-9511-z"" rel=""nofollow"">here</a> (<em>Olympic Medals</em>). I would be interested in an evaluation by the experts.</p>

<p>Note 6. At a different venue (see comment by Daniel Moskovich), Charles Stewart pointed out that ""As it happens, the Grossone numbers considered as polynomials seem to be a generalisation of these REXes [rational exponential expressions], allowing subtraction in addition to the operations I described above. If that's right, then Sergeyev claims to have such a decision procedure."" The question is whether Sergeyeyev has such a decision procedure.</p>

<p>Note 7. My understanding of Gabriele Lolli's <em>answer</em> is that he sees Sergeyev as developing a <em>conservative</em> extension of the intended model of PA, allegedly contrary to previous models; and of Daniel Moskovich's <em>answer</em>, that Sergeyev is adopting standards of rigor of an <em>applied</em> mathematician and therefore should not be judged by the standards of rigor of <em>pure</em> mathematicians. Editors are invited to comment.</p>

<p>Note 8.  Why has <a href=""http://www.spacephys.ru/kompyuter-beskonechnykh-vychislenii"" rel=""nofollow"">this website</a> been shut down? See the related <em>answer</em> below for some context.</p>

<p>Note 9.  Sergeyev claims that his <em>grossone</em> has the properties of both ordinal and cardinal numbers. Does he give a definition that would ensure such properties, or is this claim merely a declarative pronouncement?</p>

<p>Note 10.  <em>Foundations of Science</em> just published <a href=""http://link.springer.com/article/10.1007/s10699-016-9485-8"" rel=""nofollow"">our rebuttal of Sergeyev's pseudoscience aided and abetted by the chief editor of TMI</a>.  </p>
",logic
"<p>I was reading this paper    <a href=""http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.2911&amp;rep=rep1&amp;type=pdf"" rel=""nofollow"">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.2911&amp;rep=rep1&amp;type=pdf</a>    in which the author describes an algorithm, based on Groebner  basis,    whose input is a proposition in Peano arithmetic that satisfies a    specific quantifier structure, and the output is True or False.
       If the output is true, then the proposition must be true. However,    sometimes the output is false but the proposition is true, so the    algorithm is not a decision procedure for Peano arithmetic -I already    know that such an algorithm cannot exist, by Matiyasevich theorem-.</p>

<p>I have two questions:</p>

<p>1: Are there any similar results to this, i.e. an efficient pseudo-decision    procedure such that if the output is true, then the proposition must    be true, but we cannot say anything in the other case?</p>

<p>2: Is there a chance to use similar ideas to the ones in the paper so    that we can overcome the limitations on the quantifier structure of    the input propositions, and ask things like ""There are many    infinitely many prime numbers""?</p>
",logic
"<p>I am trying to pin down: who first proved that <a href=""http://en.wikipedia.org/wiki/Reverse_mathematics#Weak_K.C3.B6nig.27s_lemma_WKL0"" rel=""nofollow"">$\mathsf{WKL}_0$</a> has an $\omega$-model in which every set is of <a href=""http://en.wikipedia.org/wiki/Low_%28computability%29"" rel=""nofollow"">low degree</a>? As shown in Simpson's <em>Subsystems of Second Order Arithmetic</em> (Theorem IX.2.17), one doesn't have to travel too far to get to this result when starting from the <a href=""http://en.wikipedia.org/wiki/Low_basis_theorem"" rel=""nofollow"">low basis theorem</a> of Jockusch and Soare. But Simpson's typically extensive bibliographic remarks on the section in which this result is proved offer no indication of when this fact about $\mathsf{WKL}_0$ was first noted. Thanks.</p>
",logic
"<p>In the paper ""Generic Absoluteness"" by Bagaria and Friedman (<a href=""http://www.logic.univie.ac.at/~sdf/papers/bagfried.pdf"">http://www.logic.univie.ac.at/~sdf/papers/bagfried.pdf</a>) it is shown that in ZFC generic $\mathbf{\Sigma_3^1}$-absoluteness is false for class forcing. The proof uses Jensen Coding. Is this still true in ZFC${^-}$? I am particularly interested whether generic $\mathbf{\Sigma_3^1}$-absoluteness might be consistent for class forcings over models of Second Order Arithmetic (resp. ZFC$^-+$V=HC).</p>
",logic
"<p><sup>Sorry, but I do not know another place to post this question.</sup></p>

<p><a href=""http://scholar.google.de/scholar?hl=de&amp;q=%22conditions+of+possibility%22"" rel=""nofollow"">Condition of possibility</a> is an important philosophical concept. Naively, this concept could be formally defined this way: </p>

<blockquote>
  <p>$q$ <em>is a condition of possibility of</em>
  $p$ <strong>iff</strong> $\neg q$ <em>implies</em> $\neg
&gt; p$ </p>
</blockquote>

<p>the latter being equivalent with $p$ <em>implies</em> $q$.  When we write $\hookrightarrow$ for <em>is a condition of possibility of</em> and $\rightarrow$ for <em>implies</em> we get</p>

<blockquote>
  <p>$q \hookrightarrow p$ iff $p
&gt; \rightarrow q$.</p>
</blockquote>

<p>So, <em>condition of possibility</em> is something like <em>co-implication</em>.</p>

<p>My question is: While in category theory many concepts and co-concepts are treated as strongly related (= inter-definable) but each in its own right, and while in logic many concepts are treated as strongly related (= inter-definable) but each in its own right: </p>

<blockquote>
  <p>Why wasn't the - philosophically important - concept of <em>condition
  of possibility</em> found worthy of being
  named and treated in its own right in (formal) logic?</p>
</blockquote>
",logic
"<p>We know $PFA$ implies $2^{\aleph_0}=\aleph_2$. </p>

<p><strong>Q1.</strong> What does $PFA$ say about other values of continuum function? Does proper forcing axiom carry any further information about values of continuum function in other cardinals greater than $\aleph_{0}$? In the other words, is there any other known non-trivial result in the form ""$ZFC+PFA\vdash 2^{\aleph_{\alpha}}=\aleph_{\beta}$"" for some ordinals $\alpha , \beta$, or all other situations are consistent with $PFA$ like Easton's theorem in presence of some large cardinal?</p>

<hr>

<p>In the direction of my <a href=""http://mathoverflow.net/questions/155428/very-large-cardinal-axioms-and-continuum-hypothesis"">previous question</a> on Godel's program for deciding $CH$ and $GCH$ using adding large cardinal axioms to $ZFC$ and based on the impact of $PFA$ on $CH$ which is compatible with Godel's conjecture on refuting $CH$ and $GCH$ using large cardinal axioms. One can consider existence of another large cardinal tree in the <strong>shadow</strong> of the current standard tree of large cardinal assumptions including $PFA$ in a rank near supercompacts. (The equiconsistency of PFA and supercompacts is not proved yet but we assume it for straightforwardness of the below diagram.)</p>

<p>Maybe Godel's conjecture and program are true if we replace the standard tree of large cardinals with another tree with equiconsistent steps. Please note the following imaginary <strong>large cardinal ladder</strong> which includes <strong>two parallel trees</strong> of ""large cardinal"" assumptions: </p>

<p><strong>Q2.</strong> Can we complete the middle part of the following ladder by some axioms like $A$, $B$, $C$, ..., $X$ which are equiconsistent with usual large cardinal axioms and also refute $CH$, $GCH$ and $V=L$ in direction of Godel's program? </p>

<p><img src=""http://i.stack.imgur.com/MuIcq.png"" alt=""enter image description here""></p>

<p><strong>Update.</strong> Using above approach to large cardinal axioms (inspired by success of $PFA$ in deciding $CH$ and its possible equiconsistency with existence of supercompact cardinals) we can restate Godel's program in deciding independent statements of set theory as follows:</p>

<p><strong>For every independent statement $\sigma$ from $ZFC$ there is a (standard) large cardinal axiom $I$ and a statement $J$ (a non-standard large cardinal axiom) such that:</strong></p>

<p><strong>(a) Consistency of $ZFC+I$ implies consistency of $ZFC+J$.</strong></p>

<p><strong>(b) $ZFC+J$ decides $\sigma$ (i.e. $ZFC+J\vdash \sigma$ or $ZFC+J\vdash \neg\sigma$)</strong></p>

<p>In the other words one can decide any independent statement of mathematics using some standard/non-standard large cardinal axiom.</p>

<p><strong>Q3.</strong> Is the above thesis true? </p>

<hr>

<p>I would like to thank Asaf Karagila for his comment in my  <a href=""http://mathoverflow.net/questions/155428/very-large-cardinal-axioms-and-continuum-hypothesis"">previous question</a> that was the main guide for this question.  </p>
",logic
"<p>Hi guys,</p>

<p>In modal logic i.e. propositional logic with box and diamond, are then any laws to get a box or a diamond from outside a bracket to inside?</p>

<p>I.e. $\Box (x \rightarrow \Box x)$</p>

<p>I want the box inside the brackets :).</p>
",logic
"<p>Suppose I enlarge the first-order logic with an ""almost all"" quantifier, let's denote it by G, ie.:</p>

<p>$G_x P(x) \iff$ <em>for all but finitely many x, P(x)</em></p>

<p>Syntax for G is the same as for other quantifiers. </p>

<p>Suppose I am working over the first-order theory of natural numbers. For every sentence $T$ using $G$, does there exist a sentence $S$ over ""standard"" first-order logic, such that $S \iff T$ in every countable model of natural numbers? </p>
",logic
"<p>Is there an explicit construction of a Hamel basis of the  vector space of real numbers $\mathbb R $ over the field of rational numbers $\mathbb Q $?</p>
",logic
"<p>Is it consistent that there is a countable group $G$ such that the cardinality of the set of subgroups of $G$ is uncountable, but strictly less than $2^{\aleph_0}$?</p>
",logic
"<p>This isn't really a research question, but at least it's research-level mathematics.  I'm talking with some other people about the first uncountable ordinal, and I want some facts to inform this discussion.  Specifically, what useful or interesting foundations of mathematics do or don't allow one to prove the existence of an uncountable ordinal?</p>

<p>If you don't have a better interpretation, then for ""useful"", you can probably take ""capable of encoding most if not all rigorous applied mathematics""; for ""interesting"", you can probably take ""popular for study by researchers in foundations"".  For ""existence of an uncountable ordinal"", you could take ""existence of a well-ordered uncountable set"", ""existence of a set whose elements are precisely the countable ordinals"", etc.</p>

<p>Hopefully there is a body of known results or obvious corollaries of such, since it could be a matter of some work to apply this question to foundational system X, and I don't expect anybody to do that.</p>
",logic
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://mathoverflow.net/questions/72047/lebesgue-measurability-and-weak-ch"">Lebesgue Measurability and Weak CH</a>  </p>
</blockquote>

<p>I have studied a little set theory and I found that Solovay constructed a model of ZF+DC+""All set of reals are Lebesgue measurable"" and I found that the same model satisfies the ""perfect set property"" which implies that every uncountable subset of $\mathbb{R}$ is bijectable with $\mathbb{R}$. In other words, the Continuum Hypothesis (CH) is true in that model. I also found that the Axiom of Determinacy (AD) implies that every set of reals is Lebesgue measurable and it also implies the perfect set property.</p>

<p>Therefore, I have a question: Does ZF+DC+""All set of reals are Lebesgue measurable"" always imply CH?</p>
",logic
"<p>If $r, s\in\mathbb{R}$, we say $r$ is <em>constructible relative to</em> $s$ - and write $r\le_cs$ - if $r\in L[s]$. Modding out by the induced equivalence relation $\equiv_c$, we get a partial order, the <em>degrees of constructibility</em> $\mathcal{C}$. This poset is extremely dependent on the ambient set theory. If $V=L$, the poset is trivial, whereas the existence of a Cohen real automatically leads to a very complicated structure (see, e.g., the paper ""The degrees of constructibility of Cohen reals"" by Abraham and Shore). </p>

<p>My question is basically, what is known about the possible posets which $\mathcal{C}$ could be? I am especially interested in properties of $\mathcal{C}$ which follow from large cardinals. For example, if $0^\sharp$ exists, then we can deduce that $\mathcal{C}$ has size $2^{\aleph_0}$, which is the maximum possible; presumably this actually gives us a lot more.</p>

<p>As a sub-question, what is a good source for learning about techniques for building a model of $ZFC$ in which $\mathcal{C}$ has some prescribed properties?</p>

<p>ADDED: I'm most interested in what can be said when the size of $\mathcal{C}$ is assumed to be $2^{\aleph_0}$. As a particular example, the paper ""Hinges and automorphisms of the degrees of non-constructibility"" by P. Farrington (<a href=""http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.96.3272"" rel=""nofollow"">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.96.3272</a>) has, as Lemma 2.5, the following (CAVEAT: Farrington's paper actually gives the wrong definition of ""hinge,"" which was corrected in Lubarsky's review in the JSL in 1989): </p>

<blockquote>
  <p>Suppose that $\omega_2^L&lt;\omega_1$. Then there is no nontrivial automorphism of $\mathcal{C}$.</p>
</blockquote>

<p>(Now $\omega_2^L&lt;\omega_1$ (and much more!) is a consequence of the existence of $0^\sharp$, so this is a very weak hypothesis.) Results like this are exactly what I'm looking for: properties $\mathcal{C}$ which follow from large cardinals, and in particular can hold under the assumption $\vert\mathcal{C}\vert=2^{\aleph_0}$.</p>
",logic
"<p>In <a href=""http://wwwmath.uni-muenster.de/u/weiermann/"" rel=""nofollow"">Old Home Page of Andreas Weiermann</a>  Andreas Weiermann has stated the following:</p>

<blockquote>
  <p>Quite recently I submitted a preprint about an application of the Riemann hypothesis and the ABC conjecture to independence results for publication.</p>
</blockquote>

<p><strong>Question 1.</strong> can someone give a short description of the stated work(s)?</p>

<p><strong>Question 2.</strong> Do such independence results say anything about the independence of Riemann hypothesis or ABC conjecture in $PA$ or some of its weaker sub-theories?</p>

<p>The paper <a href=""https://biblio.ugent.be/publication/861950"" rel=""nofollow"">Unprovability, phase transitions and the Riemann zeta-function</a> by Bovykin-Wiermann may  be related. 
Also as Jaso Rute has  suggested, the paper <a href=""http://cage.ugent.be/~weierman/MSJ.pdf"" rel=""nofollow"">Phase transitions in logic and combinatorics</a>  might be also helpful.</p>
",logic
"<p>In different books one can find different implicit definitions for a large cardinal axiom. </p>

<p>My question is that which one of these definitions are more popular or standard amongst set theorists?</p>

<p>Any reference for an explicit definition of a large cardinal axiom is welcome.</p>
",logic
"<p>Consider Basic Law $V$:</p>

<p>$\hat x$$F$($x$)=$\hat x$$G$($x$)$\equiv$($\forall$$x$)($F$$x$$\equiv$$G$$x$)</p>

<p>At first glance, it seems to have the same form as Leibniz's law</p>

<p>$x$=$y$$\equiv$($\forall$$F$)($F$$x$$\equiv$$F$$y$) (if one substitutes '$x$' for '$y$' and one assumes '$x$' satisfies both '$F$ ' and '$G$')</p>

<p>Since it is claimed that the logic of Frege's <em>Begriffsschrift</em> is second-order logic without comprehension principles, if, given second-order logic without comprehension principles with the extra axioms</p>

<p>$x$=$x$</p>

<p>$x$=$y$$\equiv$($\forall$$F$)($F$$x$$\equiv$$F$$y$)</p>

<p>and a 'course-of-values' operator '$\hat x$' that gives, when applied to $F$, $G$, the first-order objects that satisfy $F$, $G$; can one derive Basic Law $V$?  If not, what further assumptions must one make in order to derive Basic Law $V$ and are these further assumptions valid?  </p>
",logic
"<blockquote>
  <p>Does every model of $I\Delta_0$ has an end extension to a model of $I\Delta_0+\Omega_1$?</p>
</blockquote>

<p>In <a href=""http://www.sciencedirect.com/science/article/pii/S0168007297000262"" rel=""nofollow"">End extensions of models of linearly bounded arithmetic</a> paper the author said this problem is open. I want know is there any progress on this problem?</p>

<p>Thanks. </p>
",logic
"<p>Model theorists have a lot to say about so-called definable imaginary elements of a structure. One way to formulate imaginaries is the following: Suppose $\mathcal{M}$ is a structure with universe $M$, and let $G$ be the automorphism group of $\mathcal{M}$. 
Define
$$V_0(M) = M, \quad V_{\alpha+1}(M) = V_\alpha\cup P(V_\alpha(M)), \quad V_\lambda = \bigcup_{\alpha&lt;\lambda}V_\alpha(M)$$
when $\lambda$ is a limit ordinal. Let
$$V(M) = \bigcup_{\alpha&lt;\infty}V_\alpha(M).$$
Then $G$ has a natural action on $V(M)$ defined inductively by
$$g(x) = \{g(y):y\in x\}.$$
If $x\in V(M)$ and $S\subseteq M$, then $S$ supports $x$ if $G(S)\subseteq G(\{x\})$, where $G(S)$ is the pointwise stabilizer of $S$ and $G(\{x\})$ is the setwise stabilizer of $x$. The imaginaries are those $x\in V(M)$ which have finite support.</p>

<p>Now, for a finite structure $\mathcal{M}$, it makes sense to work with $HF(M)$ instead of $V(M)$ (stop the construction at the first countable infinite ordinal). </p>

<p>I would like to know if anyone has done any work regarding the action of a group of permutations of a finite set $X$ on the hereditarily finite sets above $X$. Ideally, I'd like to get results ""off the shelf"" if they're out there.</p>
",logic
"<p>Is there a version of the L&ouml;wenheim-Skolem theorem in intuitionistic logic?  I'm particularly interested in the ""downward"" form.  The standard proof I know uses the Tarski-Vaught test for elementary substructures, which in turn relies on the fact that ""forall"" is equivalent to ""not exists not"", and that fails intuitionistically.</p>
",logic
"<p>Where's the notion of interpretation (model) originally introduced?
I find it used in Skolem's paper ""Logico-combinatorial investigations in the satisfiability or provability of mathematical propositions"" (1920).
However, I do not find any explicit reference to semantical ideas in Frege's Begriffsschrift. Where did the formal idea of semantics come up? What's the relation of this to Tarski's theory of truth?
I really have a mess in my head.</p>
",logic
"<p>Among models of $\lambda$-calculus, some like the Bohm tree model have the property that every element is a directed sup of definable elements, whereas others like the $D_\infty$ and $P(\omega)$ models contain ""extra"" elements (e.g. step functions) that are not sups of sets of $\lambda$-definable elements.</p>

<p>Among models of the real numbers, standard models have the property that every element is a sup of a set of rational (0,1,+,-,*,/-definable) points, whereas nonstandard models can contain ""extra""  elements like infinitesimals.</p>

<p>Does this property have a common name? A model is ___ if every element is a sup of a set of definable elements, for a give notion of definability.</p>

<p>Related properties of similar grammatical form:</p>

<ul>
<li><em>separability</em> of a metric space</li>
<li><em>algebraicity</em> of a continuous lattice</li>
<li><em>completeness</em> of a partial order or semilattice</li>
<li><em>standardness</em> of a model of the reals</li>
<li><em>full-abstraction</em> of model of a programming language</li>
</ul>
",logic
"<p>As we can see,there are some conditions given in a proposition.
If there are 2 propositions having  approximate conclusions.Usually，we can name one propositions gives  stronger conditions than the other.
My question is that whether there is a good system to weigh the conditions given in a proposition.e.g. a condition ""uniform convergence""is stronger than a condition""convergence"".
Can we give each condition a value to show their sharpness?</p>
",logic
"<p>Assuming the axiom of choice the following argument is simple, for infinite $A$ it holds: $$2\lt A\leq2^A\implies 2^A\leq A^A\leq 2^{A\times A}=2^A.$$</p>

<p>However without the axiom of choice this doesn't have to be true anymore. For example if $A$ is an amorphous set (infinite set that cannot be written as a disjoint union of two infinite sets), then it is actually true that $2^A&lt;3^A&lt;4^A&lt;\ldots&lt; A^A$. The reason these inequalities hold is that $A^A$ is actually Dedekind-finite, so whenever we remove elements we strictly decrease in cardinality.</p>

<p>Of course there are still sets that obey the equation $A^A=2^A$, even if $A$ cannot be well-ordered. For example given any set $A$ it is not hard to verify that $A^\omega$ has the property $A^\omega\times A^\omega=A^\omega$. From this follows:</p>

<p>$$2\lt A^\omega\leq 2^{A^\omega}\implies 2^{A^\omega}\leq\left(A^\omega\right)^{A^\omega}\leq \left(2^{A^\omega}\right)^{A^\omega}=2^{A^\omega}$$
(In fact we can replace $\omega$ by any set $\tau$ such that $\tau+\tau=\tau$)</p>

<p>But I have a hard time to believe that these two things are equivalent: $$A^A=2^A\iff A\times A=A.$$</p>

<blockquote>
  <p><strong>Question I.</strong> Is there anything known on the properties of sets for which $A^A=2^A$? </p>
  
  <p><strong>Question II.</strong> If $2^A=A^A$ does not characterize the sets for which $A\times A=A$, does the axiom ""<em>For every infinite $A$, $2^A=A^A$</em>"", imply the axiom of choice?</p>
</blockquote>

<p>If the answer is unknown, does this question (or variants, or closely related questions) appeared in the literature?</p>

<p>It seems like a plausible question by Tarski or Sierpiński. I found several other questions I have asked before to be questions that have been asked in one a paper or another.</p>
",logic
"<p>In the early 20th century there was a lot of fuss over the axiom of choice implying that there are Lebesgue non-measurable sets of reals. In his book about The Axiom of Choice, Gregory Moore points to the following paper:</p>

<blockquote>
  <p>Sierpinski, W. <strong>""L’axiome de M. Zermelo et son rôle dans la théorie des ensembles et l’analyse.""</strong> <em>Bulletin de l’Académie des Sciences de Cracovie, Classe des Sciences Math., Sér. A (1918)</em> (1918): 97-152.</p>
</blockquote>

<p>(And even more specifically, to pages 124-125.)</p>

<p>Moore writes that Sierpinski proved that if $[\Bbb R]^\omega$ has cardinality $2^{\aleph_0}$, then there is a non-measurable set. Lebesgue argued that Sierpinski uses the axiom of choice, but Moore points out that while the assumption requires some amount of choice (as we full well know today), the implication does not.</p>

<p>Being a historical book about the axiom of choice, Moore doesn't provide a sketch of the proof. However, I've been unable to locate the paper. Which brings me to my question.</p>

<p><strong>Question.</strong> Is there any accessible (preferably English) reference to what the argument of Sierpinski was?</p>
",logic
"<p>Yesterday, Z. Sela published a  <a href=""http://arxiv.org/abs/1401.5711v1"" rel=""nofollow"">preprint</a> in arXiv which claims that the solution of Olga Kharlampovich and Alexi Miyasnikov for the Tarski problem on  decidablity of the first order theories of free groups and torsion free hyperbolic groups contains  mistakes and so, that problem which was announced to be solved in 2006, is still an open problem. At this time, I am interested to know, which important theorems of Group theory, Model theory and Algebraic geometry over groups discovered in the period of 2006-2013 applied  result of Kharlampovich-Miyasnikov.</p>

<p>Edit: An answer of Kharlampovich and Miyasnikov for the preprint of Sela is just published in arXiv. They explained briefly that there was no serious mistakes in their work, and many errors discovered by Sela are already have been corrected. See this link: <a href=""http://arxiv.org/abs/1402.0482"" rel=""nofollow"">http://arxiv.org/abs/1402.0482</a></p>
",logic
"<p>It is well known that primitive recursion is not powerful enough
to express all functions, Ackermann function being probably the best
known example.</p>

<p>Now, in the logic courses (that I have had look at) one always proceeded from primitive recursion to mu-recursion. In computer science terms this basicly means we are jumping from a formalism where programs are quaranteed to halt to a Turing-complete formalism where halting is a non-computable property i.e. we can't say for every program if it will eventually halt.</p>

<p>I got curious if there is any hierarchy between primitive recursion and
mu-recursion. After a while I found a programming language called Charity. In Charity (according to Wikipedia)
all programs are quaranteed to stop, thus its not Turing-complete, but,
on the other hand, it is expressive enough to implement Ackermann function.</p>

<p>This suggests there is at least one level between mu-recursion and primitive recursion. </p>

<p>My question is: does there exists any other halt-for-sure formalisms that are more expressive than primitive recursion? Or, even better, does there exist some known hierarchies between mu-recursive and primitive recursive functions? I'm curious about how ""much"" we can compute with a formalism that guarantees halting.</p>
",logic
"<p>This is a question related to ideas raised in <a href=""http://arxiv.org/abs/1410.1224"">http://arxiv.org/abs/1410.1224</a> and <a href=""http://arxiv.org/pdf/1405.7456.pdf"">http://arxiv.org/pdf/1405.7456.pdf</a>. Basically, the idea is the following:</p>

<blockquote>
  <p>Suppose I have a first-order theory $T$. Under what conditions are there ""few"" models of $T$ across all possible forcing extensions of the universe?</p>
</blockquote>

<p>Maybe ""few"" is the wrong word - what I really mean is, when does the collection of ""models of $T$ you can get by forcing"" have some nontrivial structure?</p>

<p>There are a bunch of aspects of this question; the one I'm interested in right now is the following:</p>

<blockquote>
  <p>Say that a theory $T$ is <em>generically embeddable</em> if - whenever $\mathbb{P}$ is a forcing notion and $\nu$ is a $\mathbb{P}$-name such that $\Vdash_\mathbb{P}``\nu\models T""$ - there is some forcing notion $\mathbb{Q}$ and $\mathbb{Q}$-name $\mu$ such that $$\Vdash_{\mathbb{P}\times\mathbb{Q}} ``\mbox{$(\mu[G_1]\models T)$ and there is a homomorphism $h\colon \nu[G_0]\rightarrow\mu[G_1]$}.""$$ (Note that this homomorphism of course exists in $V[G_0\times G_1]$.)</p>
</blockquote>

<p>To get a sense of what this means, let's look at a counterexample. Take $T$ to be the true theory of second-order arithmetic - that is, $T=Th(\omega\sqcup 2^\omega; +, \times, \in)$. Then models of $T$ code reals, and this is bad. Specifically, let $\mathbb{P}$ be Cohen forcing, and let $\nu$ be the $\mathbb{P}$-name picking out the ""true"" model $(\omega\sqcup 2^\omega; +, \times, \in)^{V[G]}$. Then if $G_0\times G_1$ is $\mathbb{P}\times\mathbb{Q}$ generic - for any $\mathbb{Q}$! - since the real $G_0$ won't be in $V[G_1]$, no model $N$ of $T$ in $V[G_1]$ will embed $\nu[G_0]$, since such a homomorphism would have to biject $\nu[G_0]$ with the well-founded segment of $N$, and from this we could recover $G_0$ in $V[G_1]$.</p>

<p>More generally, <em>theories which let you code sets are bad.</em></p>

<p>My question is: <strong>When is a theory generically embeddable?</strong> Specifically, are there model-theoretic niceness properties which guarantee this? For instance, I can't come up with a <em>stable</em> example of a non-generically embeddable theory $T$, but I also can't prove there isn't one. I can prove that if $T$ is totally categorical, then $T$ is generically embeddable, but this isn't very interesting (in fact, it's hard not to prove this).</p>

<hr>

<p>EDIT: Note that there are many natural strengthenings of this: e.g.</p>

<ul>
<li><p>We may demand that $\mathbb{Q}=\mathbb{P}$, or even $\mathbb{Q}=\mathbb{P}$ and $\mu=\nu$!</p></li>
<li><p>We may ask for the homomorphism $h$ to be an elementary embedding, or satisfy some other strong property (e.g. the papers linked above looked at <em>isomorphisms</em>, not homomorphisms).</p></li>
<li><p>We may restrict attention to certain classes of forcing notions, or certain names (e.g. the papers linked above looked only at $\nu$ such that $\Vdash_\mathbb{P}$``$\nu[G]$ is countable"").</p></li>
</ul>

<p>For now, though, I'm interested in the question as it stands.</p>
",logic
"<p>In a <a href=""http://arxiv.org/PS_cache/arxiv/pdf/1011/1011.3578v1.pdf"" rel=""nofollow"">paper placed on the arXiv today</a> Shelah references theorem 0.9 from <a href=""http://arxiv.org/PS_cache/math/pdf/0212/0212250v2.pdf"" rel=""nofollow"">this paper</a> (also Shelah) that uses $\aleph_{736}$ as an upper bound. This strikes me as analogous to Skewes' number. Are there any other examples where explicit mentions of 'large alephs' are used in proofs or theorems? Large in this instance is $\aleph_n$ for $n &gt; 3$, say.</p>

<p>Edit: The first version of this question asks for $n$ a natural number, because clearly there are uses of $\aleph_\omega$ that are not all that uncommon, I imagine. But if there are uses of alephs - in isolation, not as part of a general transfinite induction scheme - that have $n$ an infinite ordinal like $\omega^2\cdot 5 + 45$ or some specific polynomial in $\omega$ which is 'not boring' (e.g. $\omega, \omega+1$), then I'd like to hear those as well.</p>

<p>Bonus points, even though this is a separate question: where does the 736 come from? Is it due to some sort of Goedelian numbering scheme that encodes the statement “G is a free abelian group”, which is part of the theorem?</p>
",logic
"<p>Sometime around 1975, <a href=""http://math.berkeley.edu/~leo/"">Leo Harrington</a> wrote a set of notes, apparently 13 pages long, entitled <em>Kolmogorov's $R$-operator and the first nonprojectible ordinal</em>.  I do not know how widely they were circulated (or if they were ever available from the UCB library or anywhere).</p>

<p>From what I understand, these notes relate recursion on the first stable ordinal in the first nonprojectible to recursion in a certain explicitly defined type-3 functional.  A more precise statement is given in Thomas John's <a href=""http://www.jstor.org/stable/2273936"">paper</a> “Recursion in Kolmogorov's $R$-operator and the ordinal $\sigma_3$” (<em>J. Symbol. Logic</em> <strong>51</strong> (1986) 1–11), but the proof is not reproduced there.  A related but slightly different result of Harrington's, with a different type-3 operator, is quoted (as example 4.10) by Stephen Simpson's “Short course on Admissible Recursion Theory” (355–390 in: Fenstad &amp;al. eds., <em>Generalized Recursion Theory II</em> (Oslo 1977), North-Holland 1978).</p>

<p>I'd very much like to see a copy of these notes, or a proof of any closely related result (e.g., the one quoted by Simpson's paper mentioned above).</p>

<p>The author has been kind enough to see if he can find them, but he isn't too optimistic.  I've also written to a number of people who worked in the subject around that time (Sacks, Shore, Simpson and Soare), but without success.  So I now turn to MO in the hope that someone has heard of these notes or knows where a copy might be found.</p>

<p>[Xref: <a href=""http://tea.mathoverflow.net/discussion/1541/looking-for-a-copy-of-some-unpublished-notes-can-i-ask-on-mathoverflow/"">link to meta thread</a>]</p>

<p>PS: While I'm aware that offering prizes other than reputation points is frowned upon on MO, if someone should go through the (real-world!) trouble of copying, scanning or mailing these notes for me, I think it would be appropriate that I should respond with a small (real-world!) token of thanks, like an Amazon gift card or something. :-)</p>
",logic
"<p>When I work with various presheaf categories, and I need some lemma, I often am able to prove the lemma by proving the analogous lemma for sets. As a simple example, let $f_i :X_i\hookrightarrow Y$ be two monomorphisms for $i=1,2$. If $g:X_1 \rightarrow X_2$ be a map such that $f_2\circ g=f_1$ Then $g$ is also a monomorphism. Let us say that this is taking place in simplicial sets (or $\mathcal{A}$-sets). Well, to prove this for simplicial sets, we prove the lemma in sets, and apply pointwise. </p>

<p>What we were able to do is to prove a fact about simplicial sets by reducing to the case of sets. The question is, when can we do this in full generality.</p>
",logic
"<h2>Background</h2>

<p>The beth function is defined recursively by: $\beth_0 = \aleph_0$, $\beth_{\alpha + 1} = 2^{\beth_\alpha}$, and $\beth_\lambda = \bigcup_{\alpha &lt; \lambda} \beth_\alpha$. Since the beth function is strictly increasing and continuous, it is guaranteed to have arbitrarily large fixed points by the <a href=""http://en.wikipedia.org/wiki/Fixed-point_lemma_for_normal_functions"">fixed-point theorem on normal functions</a>. </p>

<p>The cofinality of an ordinal $\alpha$ is the smallest ordinal $\beta$ such that there are unbounded increasing functions $f : \beta \to \alpha$.</p>
",logic
"<p>If &#8477;<sup>#</sup> exists then why is cof(&theta;<sup>L(&#8477;)</sup>) = &omega;? Also I have the same question for the L(V<sub>&lambda;+1</sub>) generalization (if it's actually a different proof; I presume it isn't), i.e. if &theta; is defined as the sup of the surjections in L(V<sub>&lambda;+1</sub>) of V<sub>&lambda;+1</sub> onto an ordinal, then if V<sub>&lambda;+1</sub><sup>#</sup> exists why is cof(&theta;<sup>L(V<sub>&lambda;+1</sub>)</sup>) = &omega;? </p>
",logic
"<p>To show that $ZFC$ is not existentially closed, we can use the following forcing argument: Let the ground model can model $V=L$ and the forcing extension model $2^{{\aleph}_{0}}=\aleph_{2}$. (Maybe there is a simpler proof of this fact, but I can't see it right now).</p>

<p>However suppose that I were to refine my question. Suppose that $ZFC\subseteq{T}$ is complete and consistent. Is $T$ existentially closed? If I were to guess, I would guess no. However I'm having trouble proving this.</p>

<p>I would guess the same for a complete theory $Th({\mathbb{N}},+, \times, &lt;,0,1) \subseteq{T'}$, and I would like to have an argument that is applicable in both cases.</p>

<p>My original idea for both was to exploit the fact that for an infinite linear order where each element has a unique predecessor and a unique successor, I can show that a structure is not existentially closed by adding an element in between two elements to obtain an extension.
However this idea fails for $Th({\mathbb{N}},+, \times, &lt;,0,1)$ in the following sense: </p>

<p>Given $M\models{T'}$ and $a,b\in{M}$ such that $b=a+1$, I can't use compactness to add a new $c$ s.t. $a&lt;c&lt;b$ while also extending $T'\cup{\text{Diag}(M)}$ for the following reason; as $b=a+1$ will be in the diagram of $M$ that I'm trying to extend and $a&lt;c&lt;b$ would imply $b\neq{a+1}$ in the extension. So the option seems to be to construct models witnessing the failure of the criterion from scratch.</p>

<p>I'm not sure about $ZFC\subseteq{T}$. There will be a lot of linear orders (without any additional structure as in the above example) in a model of $T$ to play around with, but extending a model of set theory is not an easy task! </p>

<p>Edit: Or is my guess wrong and are models of the theories I'm interested in existentially closed (and hence model complete)?. I would be surprised by such a result as extensions of $ZFC$ tend to be badly behaved.</p>
",logic
"<p>Hi, I know that there are models in ZFC where don't exist p-points, but I can't find (neither on internet) a proof that I understand, some of you could help me please?</p>

<p>Another question: I know that assuming the continuum hypothesis then there exist Ramsey ultrafilters, but I don't know how to prove it. I found a proof that if we assume the continuum hypothesis then there exist p-points (<a href=""http://www.logic.univie.ac.at/~wolfgang/Diplomarbeit_Wolfgang_Wohofsky.pdf"" rel=""nofollow"">http://www.logic.univie.ac.at/~wolfgang/Diplomarbeit_Wolfgang_Wohofsky.pdf</a>).</p>
",logic
"<p>Let $\omega^\omega$ denote the set of all functions $f:\omega\to\omega$. We write $f &lt;^* g$ if there is $N\in\omega$ such that $f(n) &lt; g(n)$ for all $n&gt;N$. A set $D\subseteq \omega^\omega$ is said to be <em>dominating</em> if for all $f\in \omega^\omega$ there is $g\in D$ such that $f &lt;^* g$. Set $$\frak{d} = \textrm{min}\{|\mathrm{D}|: \mathrm{D}\subseteq \omega^\omega \textrm{ and } \mathrm{D} \textrm{ is dominating}\}.$$</p>

<p>Is it consistent that $\frak{d} &lt; 2^{\aleph_0}$?</p>
",logic
"<p>Say I start with some  a transitive model of a large fragment of ZFC (say enough to run Łoś' Theorem externally) and a specific set x&isin;M. Now let's say I'm going to pick some M-ultrafilter U on x. By M-ultrafilter, I mean that U measures the subsets of x which are in M.</p>

<p>My question is, by varying U, how much can I affect the ultrapower of M by U? Let's say I limit myself to a U which are countably complete, so that the ultrapower will be wellfounded.  If this question is too vague or broad, I'd welcome any interesting examples of things that are possible or impossible.</p>
",logic
"<p>My colleague Matthias Baaz is looking for a reference for the following question (or possibly theorem): </p>

<p>Let T be the ""theory of pairs of finite linear orders"".  That is, consider all finite structures $(X, R, S)$ where $R$ and $S$ are linear orders on $X$. Let T be the set of all first order formulas (in the language $=, R, S$) which are valid in all those (finite) models. </p>

<p>Clearly T is $\Pi^0_1$.  Is T undecidable (or even $\Pi^0_1$-complete, as in Trakhtenbrot's theorem)? This should be well known. </p>
",logic
"<p>Hello, I would like to ask you if there is a mathematical theory, that is complete (in the sense of Goedel's theorem) but practically applicable. I know about Robinson arithmetic that is very limited but incomplete already. So, I would like to know if there is some mathematics that could be practically used (expressiveness) and reduced to logics (completeness).</p>

<p>I'm very new to the site and to the maths as well, so please tell me if that's a silly question.</p>
",logic
"<p>This is basically a reference request, but the post is going to be relatively long (and a little bit verbose): I apologize in advance for that.</p>

<p><strong>Premise.</strong> There are several examples of ""ordered structures""  appearing in nature (at least for the moment, let me be vague with the actual meaning of various terms I'm using): <a href=""https://en.wikipedia.org/wiki/Partially_ordered_group"" rel=""nofollow"">ordered groups</a>, <a href=""https://en.wikipedia.org/wiki/Partially_ordered_ring"" rel=""nofollow"">ordered rings</a>, <a href=""https://en.wikipedia.org/wiki/Ordered_vector_space"" rel=""nofollow"">ordered vector spaces</a>, etc. All of these have something in common: They are algebraic structures, where each operation is compatible, in some sense and in some way, with a (partial) order. Thus, I find it reasonable to ask:</p>

<blockquote>
  <p>What about a fully formal definition of an ordered structure, in general?</p>
</blockquote>

<p>For simplicity, I'm <em>not</em> seeking a definition worded in the language of categories, and I'm looking at the case where ""structure"" means whatever can be understood as a (classical) model of a finitary, single-sorted, first-order <em>algebraic</em> theory in the frame of model theory (in principle, I'm also interested in possibly non-finitary or many-sorted structures, but the general case would probably make things look more complicated than they are and overshadow some relevant details).</p>

<p>The most basic, non-trivial example is provided by structures with <em>one</em> operation. For instance, an <em>ordered semigroup</em> is a triple $\mathbb A = (A, {\cdot}\,, \preceq)$, where $(A, \cdot)$ is a semigroup (written multiplicatively) and $\preceq$ an order on $A$ with the property that $xz \preceq yz$ and $zx \preceq zy$ for all $x,y,z \in A$ such that $x \preceq y$.</p>

<p>Of course, the axiom of associativity doesn't play any role in these definitions, so from a fundamental point of view it would have been morally better to replace ""semigroups"" with ""magmas"" in the previous paragraph, but on the other hand, that doesn't really matter, insofar as I'm just using ordered semigroups as a guiding example to forge a tentative answer to my question along the following lines.</p>

<p><strong>Naive (and ""wrong"") approach.</strong> Let $T$ be a finitary, single-sorted, first-order theory, which, to me, means a triple $(\sigma, \Xi, V)$, where:</p>

<ol>
<li>$V$ is an infinite countable set of (logical) variables from the formal language, $\mathcal L$, underlying the axiomatic theory used to lay out the foundations (say, Tarski-Grothendieck set theory, as oversized as it may appear);</li>
<li>$\sigma$ is a (single-sorted) signature, namely a triple $(\Sigma_{\rm f}, \Sigma_{\rm r}, \varrho)$ consisting of a set of function symbols $\Sigma_{\rm f}$, a set of relation symbols $\Sigma_{\rm r}$, and a function $\varrho: \Sigma_{\rm f} \cup \Sigma_{\rm r} \to \mathbf N^+$ such that $\Sigma_{\rm f}$, $\Sigma_{\rm r}$, and the set of (logical and non-logical) symbols of $\mathcal L$ are pairwise disjoints (the function $\varrho$ assigns to each function or relation symbol of $\sigma$ an ariety; in particular, an $n$-ary function symbol will correspond, in any model of the theory, to a function $A^{n-1} \to A$ (for some set $A$), and an $n$-ary relation symbol to a subset of $A^n$);</li>
<li>$\Xi$ is a (possibly empty) subset of $\langle V; \sigma \rangle$,  the set of all (well-formed) formulas generated by combining, according to the formation rules of first-order logic, the variables in $V$, the (function and relation) symbols of $\sigma$, and those of $\mathcal L$ which are not logical variables.</li>
</ol>

<p>(The role of $V$ is meaningless here, as we could assume that $V$ includes <em>all</em> the variables in $\mathcal L$; however, it starts being meaningful in the case of many-sorted theories, and that's why I beg your indulgence for being redundant in this respect.)</p>

<p>Now, $T$ is called an algebraic theory if $\Sigma_{\rm r}$ is empty (in which case $\sigma$ is referred to as an algebraic signature), and since we are interested in structures that are algebraic except for the fact of being endowed with an order, we may refer to $T$ as a quasi-algebraic theory if</p>

<ol>
<li>$\Sigma_{\rm r}$ consists of <em>one</em> relation symbol $R$, subjected to the axioms of reflexivity, antisymmetry, and transitivity (for binary relations), which are hence comprised among the formulas in $\Xi$ (so that $R$ is interpreted as a partial order in any possible model of $T$);</li>
<li>$\Xi$ includes basic formulas encoding the compatibility between each function symbol of $\sigma$ and the relation $R$, which can be phrased as follows: If $\varsigma$ is a function symbol in $\Sigma_{\rm f}$ of ariety $n := \varrho(\varsigma)$, then the formula
$$
\forall \vec{x}, \vec{y} \in V^{n-1}: R^{(2n-2)}(\vec{x}, \vec{y}) \implies R(\varsigma(\vec{x}), \varsigma(\vec{y}))\qquad\qquad(\star)
$$
belongs to $\Xi$. (The notation should be self-explanatory, but let me note that the formula in the case of constant symbols is redundant, in the sense that it is implied, in any model of theory, by the very fact that $R$ is reflexive; yet, having it there makes the approach look more ""uniform"" than otherwise, in the same spirit of Joel David Hamkins' comment below.)</li>
</ol>

<p>An ordered structure would then be any model of a quasi-algebraic theory.</p>

<p>Unfortunately, the above doesn't work even in the case of (the theory of) groups, where $\Sigma_{\rm f}$ consists, say, of the symbols $\cdot$ (binary symbol for ""multiplication""), ${}^{-1}$ (unary symbol for ""inversion""), and $1$ (constant symbol for ""identity""). In fact, the naive approach would suggest to assume one binary relation symbol, say $\preceq$, in $\Sigma_{\rm r}$ and the following axioms in $\Xi$:
$$
\begin{split}
(1)\ &amp; \forall x, y, z \in V: x \cdot (y \cdot z) = (x \cdot y) \cdot z \\
(2)\ &amp; \forall x \in V: x \cdot 1 = 1 \cdot x = x \\
(3)\ &amp; \forall x,y \in V: x \cdot x^{-1} = x^{-1} \cdot x = 1 \\
(4)\ &amp; \forall x,y,z \in V: (x \preceq x) \land (((x \preceq y) \land (y \preceq y) \implies (x=y))) \land (((x \preceq y) \land (y \preceq z) \implies (x \preceq z))) \\
(5)\ &amp; \forall x,y \in V: (x \preceq y) \implies (x^{-1} \preceq y^{-1}) \\
(6)\ &amp; \forall x,y,z \in V: (x \preceq y) \implies ((x \cdot z \preceq y \cdot z) \land (z \cdot x \preceq z \cdot y)) \\
\end{split}
$$
The problem is that the 5th axiom is essentially incompatible with the 6th, as the latter yields that, in every model $(A; +, \cdot\,,1;\preceq)$ of $T$, we have $x \preceq y$ iff $y^{-1} \preceq x^{-1}$.</p>

<p><strong>Remedies.</strong> One may argue that the ""mistake"" lies in the fact of including the function symbol ${}^{-1}$ in the signature of the theory, while an alternative could be to avoid it and replace the 3th axiom above with:</p>

<p>$$
\forall x \in V, \exists\, \tilde{x} \in V: x \cdot \tilde{x} = \tilde{x} \cdot x = 1.
$$
This is certainly a possibility (as long as $\mathcal L$ includes both $\forall$ and $\exists$ among the logical symbols), but I find it rather ""artificial"" (whatever it may mean), all the more that the same strategy fails if we try to use the naive approach outlined in the above to recover as a special case the common definition of an ordered ring, for which the compatibility between multiplication and order is ""restricted to nonnegative factors"", which has no hope to fit in the paradigm implied by condition $(\star)$.</p>

<p>So, putting it all together, my (second) question is:</p>

<blockquote>
  <p>Where should I look up for a sufficiently general definition of ""ordered structure"", which copes with the kind of issues that I've tried to point out in this post?</p>
</blockquote>

<p>I've my own ideas on what to do, but there may be a much better way on how to proceed, which is what I'm looking for. In particular, one solution could be as follows:</p>

<ol>
<li>Start with a finitary, single-sorted, first-order theory $T = (\sigma, \Xi, V)$, whose signature is of the form $((\varsigma_i)_{i \in I}, (R_i)_{i \in I \,\cup\, \{\infty\}}, \varrho)$ for some index set $I$ and $\infty \notin I$, so that each function symbol $\varsigma$ has one corresponding relation symbol of ariety $2\varrho(\varsigma)-2$, and we have an extra relation symbol $R_\infty$.</li>
<li>Make $\Xi$ include, for each relation symbol $R$ of $\sigma$, the axioms of reflexivity, antisymmetry, and transitivity (extended, as appropriate, from binary to $2n$-ary relations), so that, in particular, $R_\infty$ is interpreted as an
order in any possible model of the theory.</li>
<li>Rewrite condition ($\star$) so as to replace, for each
function symbol $\varsigma$ of $\sigma$, the symbol ""$R^{(2n-2)}$"" to the left of the connective ""$\implies$"" with the (unique) relation
corresponding to the function symbol $\varsigma$, and the symbol ""$R$"" to the right with ""$R_\infty$"".</li>
</ol>

<p>These conditions together describe a paradigm I will refer to as (P), the last condition encoding the naive idea that the relations $R_i$ must be glued together in a ""consistent way"" (and can't be ""completely independent"" from each other, which otherwise would result into something exceedingly general, I feel).</p>

<p><strong>An example.</strong> Assume the (algebraic) theory of unital rings is encoded by the (algebraic) signature whose set of function symbols is given by $\Sigma_{\rm ring} := \{+, \cdot\,, -\,, 0, 1\}$, where $+$ and $\cdot$ are, respectively, the binary symbols for ""addition"" and ""multiplication"", $-$ is the unary symbol for ""additive inverse"", and $0$ and $1$ are, respectively, the constant symbols for ""additive identity"" and ""multiplicative identity"". The axioms of the theory are the usual ones:
$$
\begin{split}
(1)\ &amp; \forall x, y, z \in V: (x+(y+z) = (x+y)+z) \land (x \cdot (y \cdot z) = (x \cdot y) \cdot z) \\
(2)\ &amp; \forall x \in V: (x+0 = 0 + x = x) \land (x \cdot 1 = 1 \cdot x = x) \\
(3)\ &amp; \forall x,y \in V: x + (-x) = (-x) + x = 0 \\
(4)\ &amp; \forall x,y,z \in V: (x \cdot (y+z) = (x \cdot y) + (x \cdot z)) \land ((y+z) \cdot x = (y \cdot x) + (z \cdot x)) \\
\end{split}
$$
Now, according to the paradigm (P), the theory of ordered rings would have a signature of the form $(\Sigma_{\rm ring}, \Sigma_{\rm r}, \varrho)$, where $\Sigma_{\rm r}$ is a set of relation symbols of the form $\{R_{(+)}, R_{(\cdot)}, R_{(-)}, R_{(0)}, R_{(1)}, \preceq\}$, with each relation symbol subjected to the axioms of reflexivity, antisymmetry, and transitivity, all the relation symbols glued together by the 4th condition of (P), and each function symbol $\varsigma$ in $\Sigma_{\rm ring}$ ""bound"" to the corresponding relation symbol $R_{(\varsigma)} \in \Sigma_{\rm r}$ by the formula:
$$
\forall (\vec{x}, \vec{y}) \in V^{n-1} \times V^{n-1}: R_{(\varsigma)}(\vec{x}, \vec{y}) \implies (\varsigma(\vec{x}) \preceq \varsigma(\vec{y})),
$$
where $n$ is the ariety of $\varsigma$.</p>

<p>In particular, this paradigm fits with the usual notion of an ordered ring, which is then a tuple $\mathbb A = (A; +, \cdot\,,-\,,0,1; R_{(+)}, R_{(\cdot)}, R_{(-)}, \preceq)$, where $\preceq$ is a partial order on $A$, $R_{(+)}$ the subset of $A^2 \times A^2$ consisting of those pairs $((x,y),(x,z))$ or $((y,x),(z,x))$ with $y \preceq z$, $R_{(\cdot)}$ the subset of $A^2 \times A^2$ consisting of those pairs $((x,y),(x,z))$ or $((y,x),(z,x))$ such that $0 \preceq x$ and $y \preceq z$, and $R_{(-)} = \{(x,x): x \in A\}$. (I'm intentionally omitting any explicit reference in models to the relations associated with constants, for they don't add any information, as a result of considerations already made in the above.)</p>
",logic
"<p>In Lambek and Scott's ""Introduction to higher order categorical logic"" (1988), they state that every Heyting Algebra can be understood as a bicartesian closed category.</p>

<p>On the other hand, fixing a bicartesian closed category, and using $A \cong B$ to denote that morphisms<sup>1</sup> exists between $A$ and $B$, we can see that every bicartesian closed category exhibits the <a href=""http://en.wikipedia.org/wiki/Heyting_algebra#Characterization_using_the_axioms_of_intuitionistic_logic"" rel=""nofollow"">intuitionistic equational axiomatization</a> of a Heyting algebra.  Specifically, we can observe that:</p>

<ol>
<li>If $X \to Y \cong 1$ and $Y \to X \cong 1$ then $X \cong Y$</li>
<li>If $1 \to X \cong 1$ then $X \cong 1$</li>
<li>$X \to (Y \to X) \cong 1$</li>
<li>$(X \to (Y \to Z)) \to (X \to Y) \to (X \to Z) \cong 1$</li>
<li>$X \times Y \to X \cong 1$</li>
<li>$X \times Y \to Y \cong 1$</li>
<li>$X \to Y \to X \times Y \cong 1$</li>
<li>$X \to X + Y \cong 1$</li>
<li>$Y \to X + Y \cong 1$</li>
<li>$(X \to Z) \to (Y \to Z) \to (X + Y \to Z) \cong 1$</li>
<li>$0 \to X \cong 1$</li>
</ol>

<p>Here $\to$ is an exponential, $\times$ is a product, and $+$ is a co-product, $1$ is a final object and $0$ is an initial object. </p>

<p>I cannot find the statement of this in Lambek &amp; Scott, however.  So I have two questions:</p>

<p>(A) Does this follow from some general theorem regarding bicartesian closed categories?<br/>
(B) Is this a folk theorem, or is there a place in the literature where this is established?</p>

<hr>

<p>I originally wrote isomorphism here, but as Andreas Blass notes this is not true (for instance, in the category of sets).  However, as noted below, this is true if we weaken the statement to <em>equimorphic</em>.</p>
",logic
"<p>I am interested in models of intuitionistic linear logic, that is, the logic that you get if you take classical linear logic and restrict the set of operators to $\otimes$, $1$, $\multimap$, $\times$, $\top$, $+$, $0$, and $!$. I know what categorical models of this logic are. However I am looking for something more concrete, something that reflects the interpretation that intuitionistic linear logic is about resources.</p>

<p>Intuitionistic linear logic corresponds to a variant of the λ-calculus that cannot only deal with values (which can be duplicated and destroyed at will), but also with resources (which can neither be duplicated nor destroyed by default). The ordinary simply typed λ-calculus can be given a semantics where the meaning of a type is the set of its inhabitants. Can something similar be done for the linear λ-calculus such that the idea of computing with resources is directly expressed?</p>
",logic
"<p>A well-known result of Kunen says that there is no non-trivial elementary embedding $j: V \rightarrow V.$ There are several proofs of this theorem (see Kanamori, The higher infinite). I wonder to know if the following argument works:</p>

<p>Assume on the contrary that such an embedding exists. Let $\Phi(\alpha)$ be the following statement:</p>

<p>'' $\alpha=crit(j)$ for some non-trivial $j: V \rightarrow V.$''</p>

<p>Let $\kappa$ be the least such that $\Phi(\kappa)$ and let $j: V \rightarrow V$ witness this. Using $j$ we can conclude that $j(\kappa)$ is also the least such that $\Phi(j(\kappa))$ and this is impossible.</p>
",logic
"<p>The existence and uniqueness of algebraic closures is generally proven using Zorn's lemma.  A quick Google search leads to a <a href=""http://www3.interscience.wiley.com/journal/113463992/articletext?DOI=10.1002%2Fmalq.19920380136"">1992 paper of Banaschewski</a>, which I don't have access to, asserting that the proof only requires the ultrafilter lemma.  Questions:</p>

<ul>
<li>Is it known whether the two are equivalent in ZF?</li>
<li>Would anyone like to give a quick sketch of the construction assuming the ultrafilter lemma?  I dislike the usual construction and am looking for others.</li>
</ul>
",logic
"<p>I have a question regarding the ""compilation"" of typed lambda calculus in untyped lambda calculus.</p>

<p>Take for example the inductive definition of lists, with introduction rules:
<img src=""http://i.stack.imgur.com/xfeJ5.png"" alt=""Nil introduction"">
and:
<img src=""http://i.stack.imgur.com/OpcO4.png"" alt=""Cons introduction""></p>

<p>We can automatically derive the elimination rule and the computation rules (here
omitted as they are well known), as well as an interpretation in untyped lambda
calculus:
$[\![Nil]\!] = \lambda x.\lambda y.x$
$[\![Cons(a,l)]\!] = \lambda x.\lambda y.y \&gt; [\![a]\!] \&gt; ([\![l]\!] \&gt; x \&gt; y)$
$[\![ListCata(l,n,c)]\!] = [\![l]\!] \&gt;[\![n]\!] \&gt; [\![c]\!]$</p>

<p>This ""automatic definition"" can be done, up to my knowledge, if we are
defining an inductive type $I$ such that the occurrences of $I$ in the premises
of the introduction rules are strictly positive.</p>

<p>It seems to me that the power of this method
lies in his generality: I only have to state my introduction rules and I automatically get a translation in a language I know how to execute, in this case untyped lambda calculus.</p>

<p>Now, I'm interested in a better understanding of this type of translation, in different directions:</p>

<ul>
<li>Where has this schema been first defined? Are there papers regarding this
translation?</li>
<li>What are the limits of this approach? For example, can I extend this
process to more inductive types, to co-inductive types, to a polymorphic
lambda calculus, to dependent types?</li>
<li>What if I'd like, given a definition of an inductive type, ""compile"" the
code in, for example, SKI calculus, or another system of symbolic computation?
Is there any work done in this direction?</li>
<li>Could one hope to give an inductive definition of the underlying ""computational machine"", and get automatically a translation?</li>
</ul>
",logic
"<p>epsilon-induction is the scheme: $\forall x(\forall y\in x\varphi (y)\rightarrow \varphi (x))\rightarrow \forall x\varphi (x)$.</p>

<p>Let ""bounded epsilon-induction"" be the above scheme, but only for bounded formulas. </p>

<p>It seems clear that the full epsilon induction is not derivable from the bounded one, but I haven't managed to find a model which satisfies the bounded but not the full. If anyone can help, or refer me to some book/paper, I would appreciate it. </p>
",logic
"<p>There are many proofs based on a ""tertium non datur""-approach (e.g. prove that there exist two irrational numbers a and b such that a^b is rational).</p>

<p>But according to Gödel's First Incompleteness Theorem, where he provides a constructive example of a contingent proposition, which is neither deductively (syntactically) true nor false, we know that there can be a tertium.</p>

<p><strong>My question:</strong> Are all proofs that are based on that principle useless since now we know that a tertium can exist?</p>
",logic
"<p>Given two regular expressions $R$ and $S$ on an alphabet $\Sigma$ it is possible to decide their equivalence as follows:</p>

<ol>
<li>build two finite automata $M_R$ and $M_S$ such that $L(R) = L(M_R)$ and $L(S) = L(M_S)$</li>
<li>build an automaton $M$ such that $L(M) = (L(M_R) - L(M_S)) \cup (L(M_S) - L(M_R))$</li>
<li>test emptyness of $L(M)$ using a reachability algorithm on $M$</li>
</ol>

<p>I was wondering if there is another way to decide equivalence. Suppose $M_R$ and $M_S$ are the minimal DFA (without epsilon-moves) such that $L(R) = L(M_R)$ and $L(S) = L(M_S)$. If they have a different number of states, then $R$ and $S$ are not equivalent. Otherwise let $m$ be the number of states of the two automata. Is it true that $L(M_R) = L(M_S)$ iff ${x \in L(M_R) : |x| \leq m +1 } = {x \in L(M_S) : |x| \leq m +1 }$?
How to prove that with the Myhill-Nerode theorem?</p>
",logic
"<p>It seems to me that for most of the twentieth century, axiomatic foundations for mathematical theories were constructed with the (mostly allied) goals of minimizing the number of primitive notions and minimizing the number of axioms.  But one could equally well be guided by the goal of minimizing the logical depth of the axioms, i.e., minimizing the use of quantifiers.</p>

<p>Consider group theory, for instance.  I have seen formalizations of group theory that say ""There exists an element $h \in G$ such that for all $g \in G$, $gh=hg=g$"" and then go on to prove that $h$ is unique and to name it $e$.  But I have also seen formalizations that say ""A group is a set $G$ equipped with an element $e$ such that..."" which eliminates the need for a quantifier in an axiom.  Likewise, if one includes the operation $g \mapsto g^{-1}$ as a primitive, one can avoid the axiom ""For all $g$ there exists $h$ such that $gh=hg=e$"" (or worse, ""For all $g$ there exists $h$ such that for all $h'$, $ ghh'=hgh'=h'gh=h'hg""$, which I haven't seen, but which I can imagine a certain sorts of purist preferring!).</p>

<p>I know that in constructive mathematics, the status of existential quantifiers is suspect to begin with, so I imagine that there's already quite a bit of writing in foundations and philosophy of mathematics (and maybe computable mathematics as well) that addresses this issue.  Some pointers to relevant literature would be appreciated.</p>
",logic
"<p>Let $\sf PA$ denote the theory of natural numbers with constants $(0, 1)$ and binary operators $(+,\times)$ based on the first-order predicate calculus with equality, having the following axioms, where the last one is the axiom schema of induction yielding an axiom for each wff $\Phi(a)$:</p>

<ul>
<li>$a+0=a$</li>
<li>$a\times1=a$</li>
<li>$a+(b+c)=(a+b)+c$</li>
<li>$a\times(b+c)=a\times b+a\times c$</li>
<li>$a+c=b+c\implies a=b$</li>
<li>$a+1\ne0$</li>
<li>$\forall a\,\left(\Phi(a)\implies\Phi(a+1)\right)\implies\left(\Phi(0)\implies\Phi(c)\right)$</li>
</ul>

<p>Note that $\sf PA$ is powerful enough to introduce Gödel numbering for its own formulae and define the predicate for their provability in $\sf PA$. </p>

<p>Let's use $\sf ZFC$ as a meta-theory to reason about $\sf PA$ and its extensions defined below, and furthermore assume $\sf ZFC$ is consistent.</p>

<hr>

<p>For any recursively axiomatizable theory $\sf T$, that contains $\sf PA$ as its fragment, define $\sf T^+$ to be a new theory obtained from $\sf T$ by adjoining the following axiom schema yielding an axiom for each wff $\Phi$:</p>

<ul>
<li>$\left(\Phi\ \text{is provable in}\ \sf T\right)\implies\Phi$</li>
</ul>

<p>Note that $\sf T^+$ can prove consistency of $\sf T$, thus, if $\sf T$ is consistent, $\sf T^+$ is stronger than $\sf T$.</p>

<hr>

<p>Let $\alpha$ range over recursive ordinals, i.e. $\alpha\in\omega_1^{CK}$. Define the countable transfinite sequence of theories $\sf PA_\alpha$ such that:</p>

<ul>
<li>$\sf PA_0$ is $\sf PA$</li>
<li>$\sf PA_{\alpha+1}$ is $\sf PA_\alpha^+$</li>
<li>for a limit ordinal $\alpha$, $\sf PA_\alpha$ is the theory whose set of axioms is the union of sets of axioms of all $\sf PA_\beta$, where $\beta&lt;\alpha$</li>
</ul>

<p>Apparently, each of $\sf PA_\alpha$ is recursively axiomatizable. I also believe each of them is consistent, but do not yet see how to prove it.</p>

<p><em>Question 1</em>: Can we prove it?</p>

<p><em>Question 2</em>: Does any of $\sf PA_\alpha$ contain a theorem that is not provable in $\sf ZFC$ (when properly translated to the language of set theory, with natural numbers represented as finite von Neumann ordinals, and operators $(+,\times)$ as ordinal addition and multiplication)? If so, what's the least $\alpha$ with this property?</p>

<hr>

<p><em>Update</em>: As pointed out in the comments below, my ""definition"" of the transfinite sequence $\sf PA_\alpha$ is not really a definition because we have some wiggle room in choosing a specific ordinal notation at limit points (I do not yet completely understand how exactly it can affect the strength of theories in the sequence, but I've started to read a book on this topic — Thanks!). But I believe we still can define the set $\mathcal T$ of all possible transfinite sequences constructed this way (although it is not a singleton set). So, each of my questions can be restated as <em>""Is it the case for at least one sequence in $\mathcal T?$ Is it the case for all sequences in $\mathcal T?$""</em></p>
",logic
"<p>Bodnarchuk, Kaluzhnin, Kotov, Romov’s paper [1]  is well-known. Anne Fearnley [2] infered from it the following theroem and used it to prove the inclusion of polymorphisms.</p>

<p>Theorem (Bodnarchuk, Kaluzhnin, Kotov, Romov). Let $A$ be a finite set. Let
$\rho \subseteq A^{h}$ , and let $\sigma \subseteq A^{l}$ be a relation without repetitions. Then $Pol \rho \subseteq Pol \sigma$ if and only if
there exist $m \geq l, n &lt; m^{h}$ and an $n \times h$ matrix $X = (x_{ij})$ with $x_{ij} \in  \{1, \dots, m\}$
such that $(a_1 ,\dots , a_l) \in \sigma$ iff there exist $a_{l+1} , \dots , a_{m}$ such that for all $i = 1, \dots , n$,
$(a_{x_{i,1}}, a_{x_{i,2}}, \dots , a_{x_{i,h}}) \in \rho$.</p>

<p>My questions are:</p>

<ol>
<li><p>I have read [1] several times and am unable to find the proof for necessity part. 
Could you tell me how is the matrix $X$ constructed for the necessity part? Or could you recommend another resource for a complete proof? </p></li>
<li><p>Anne Fearnley ([2], page 8) used the matrix $X$ =  $
\begin{pmatrix}
  3 &amp; 4 &amp; 1\\
  5 &amp; 3 &amp; 2\\
\end{pmatrix}
$ in the above theorem to prove the following</p></li>
</ol>

<p>$Pol\{(0, 0, 0), (1, 1, 1), (0, 1, 2)\} \subset Pol\{(0, 0), (1, 1), (1, 2), (2, 0)\}$,</p>

<p>but how was this matrix $X$ constructed? Is this just by trial? Or is there a general way to construct such a matrix given two relations? </p>

<p>[1] V. G. Bodnarchuk, L. A. Kaluzhnin, V. N. Kotov, and B. A. Romov. Galois theory for Post algebras I–II, Kibernetika, 3 (1969), pp. 1–10 
and 5 (1969), pp. 1–9 (in Russian); Cybernetics, (1969), pp. 243–252, 531–539 (English version), 1969.</p>

<p>[2] Anne Fearnley, The monoidal interval for the monoid generated by two constants, Journal of Multiple-Valued Logic and Soft Computing, 15(5–6), pp. 597–609, 2009, <a href=""http://www3.sympatico.ca/anathia/Anne_Fearnley/2-const.pdf"" rel=""nofollow"">http://www3.sympatico.ca/anathia/Anne_Fearnley/2-const.pdf</a>‎.</p>

<p>[3] David Geiger, Closed systems of functions and predicates, Pacific J. Math. Volume 27,
Number 1 (1968), 95–100.</p>
",logic
"<p>(I'm taking my definition of a cardinal characteristic from Blass' excellent article <a href=""http://www.math.lsa.umich.edu/~ablass/need.pdf"" rel=""nofollow"">http://www.math.lsa.umich.edu/~ablass/need.pdf</a>, which cites Vojtas/Fremlin/Miller; theirs is more general, but I'm already interested in this more restrictive context.) </p>

<p>Fix a binary relation $S$ on $\omega^\omega$. A set $X\subseteq \omega^\omega$ is <em>$S$-adequate</em> if for any $x\in \omega^\omega$ there is a $y\in X$ such that $xSy$. Assuming the reals are well-ordered, the cardinal characteristic associated to $S$ is then the minimum cardinality of any $S$-adequate set. For example, taking $S$ to be domination, $\le^*$, yields the dominating number $\mathfrak{d}$.</p>

<p>My question, roughly, is: to what extent is there a meaningful theory of cardinal characteristics in contexts where choice fails, perhaps very badly?</p>

<p>One approach that seems interesting to me is via ""theta-like"" cardinals. Recall that $\Theta$ is defined to be the smallest ordinal onto which $\mathbb{R}$ does not surject; see <a href=""http://mathoverflow.net/questions/47028/value-of-theta-in-zfad"">value of Theta in ZF+AD</a> for some facts about $\Theta$ in the context of $AD$, which is where it is usually studied. We can define analogues of $\Theta$ for cardinal characterstics, as follows: for $S$ a binary relation on $\omega^\omega$ (or similar) we define $\Theta_S$ as the supremum of the cardinals onto which every $S$-adequate set surjects. Assuming $\mathbb{R}$ is well-orderable this is of course equal to the standard cardinal associated with $S$; in the absence of such a fact, this is still a meaningful definition.</p>

<p>(Note that we could also define $\Theta_S$ as the supremum of the cardinalities which inject into every $S$-adequate set, but this seems less natural. For one thing, it is consistent that $\Theta_=\not=\Theta$, which is probably a bad sign.)</p>

<hr>

<p>On to the questions:</p>

<blockquote>
  <p>(Q1) Is there work done on cardinal characteristics in the absence of choice, at all?</p>
</blockquote>

<p>Note that there is work done - such as Blass' article, as well as Nicholas Rupprecht's thesis <a href=""http://deepblue.lib.umich.edu/bitstream/handle/2027.42/77915/furikuri_1.pdf?sequence=1"" rel=""nofollow"">http://deepblue.lib.umich.edu/bitstream/handle/2027.42/77915/furikuri_1.pdf?sequence=1</a> - on computability-theoretic aspects of cardinal characteristics. This is really interesting stuff, but I'm looking for something more on the set theory side, ideally actually assigning specific ordinals to relations in a nice way.</p>

<p>In particular,</p>

<blockquote>
  <p>(Q2) What can be said about the various $\Theta_S$s as defined above?</p>
</blockquote>
",logic
"<p>The Transfinite Induction says: Let $\mathbf{P}(x)$ is a property, assume that, for all ordinal numbers $\alpha $  : If $\mathbf{P}(\beta)$ holds for all $\beta &lt; \alpha$, then $\mathbf{P}(\alpha)$ holds. Then $\mathbf{P}(\alpha)$ holds for all ordinals $\alpha$.</p>

<p>My question is: What is the problem if I replace ordinals with cardinals？ I mean could I say that  If $\mathbf{P}(\kappa)$ holds for all cardinals $ \kappa&lt; \lambda$, then $\mathbf{P}(\lambda)$ holds. Then $\mathbf{P}(\lambda)$ holds for all cadinals $\lambda$.</p>
",logic
"<p>I have been able to find a lot of information on the <strong>category of contexts</strong> -- for example, the page on <a href=""http://ncatlab.org/nlab/show/syntactic+category"" rel=""nofollow"">syntactic categories</a> at the nLab is a good starting point.  However, when I try to find similar information on the <strong>category of judgements</strong>, I find a whole lot less.  My guess would be that I am simply not looking for the right term.</p>

<p>To be more specific, I am looking for a reference which defines the <strong>category of judgements</strong> with $\Gamma \vdash t:T$, i.e. term $t$ has type $T$ in context $\Gamma$ as objects, and ???? as arrows (i.e. that is one of the things I am looking for).  I am guessing that the morphisms are likely the same as in the category of contexts, namely the substitutions that respect the underlying type theory.<br>
<hr/>
Edit: on top of Andrej's answer, and Paul's book there is also relevant work by Garner such as the paper <a href=""http://www2.math.uu.se/research/pub/Garner5.pdf"" rel=""nofollow"">Two dimensional models of type theory</a>, and the slides <a href=""http://web.science.mq.edu.au/~rgarner/Talks/2LCCC.pdf"" rel=""nofollow"">Two dimensional locally cartesian closed categories</a> which are quite relevant.</p>

<p>As far as I understand, Seely's work (see links in Andrej's answer) uses explicit reduction paths (based on explicit generators such as $\beta$ reduction) as 2-cells, while the more recent work uses abstract identity types for the same idea.  If I understand well, these are essentially the same, just that Seely's work gave explicit generators for the 2-cells, while in homotopy type theory one allows generalizations to higher dimensions, and the simplest way to do this is to let the inhabitants be implicit.</p>

<p>Surprisingly, no one mentionned that the category of judgements is mostly easily seen as the slice category of the category of contexts over a single variable -- as <a href=""http://ncatlab.org/nlab/show/categorical+semantics#ContextsAndTypeJudgements"" rel=""nofollow"">explained over at the n-lab</a>.</p>
",logic
"<p>Let $\mathcal{T}_\kappa$ be the set of all linear order types of cardinality $\kappa$. Let $\prec$ denote a binary relation on $\mathcal{T}_\kappa$ representing embeddability of order types (note that $\prec$ is a quasi-order).</p>

<ul>
<li><p>What is the cardinality of a subset of $\mathcal{T}_\kappa$ of the largest size that can be equipped with a linear order $&lt;$ consistent with $\prec$ (such that $\tau&lt;\mu$ implies $\tau\prec\mu$)?</p></li>
<li><p>What is the cardinality of a subset of $\mathcal{T}_\kappa$ of the largest size such that all its elements are mutually embeddable?</p></li>
</ul>

<p>I am particularly interested in cases where $\kappa$ is $\aleph_0$, $\aleph_1$ and $\mathfrak{c}$.</p>
",logic
"<p>Let $\omega \leq \kappa &lt;2^{\omega}$ , $\omega \leq\lambda \leq  \kappa$ and $D(\kappa, \lambda)$ be the statement:</p>

<p>For all $ \mathfrak{B} \subseteq \mathbf{P}(\omega)$ with $|\mathfrak{B}|=\kappa$ that is an almost disjoint family, there exists an $\mathfrak{A}\subseteq\mathfrak{B}$ with $|\mathfrak{A}|=\lambda$, such that for some $d\subseteq \omega $ we have:</p>

<p>1) $\forall x \in \mathfrak{A} ~~~~~~~~~~ |x\cap d |&lt; \omega$</p>

<p>2) $\forall x \in \mathfrak{B} \smallsetminus\mathfrak{A} ~~ |x \smallsetminus d|&lt; \omega$.</p>

<p>Now I have three questions:</p>

<p><strong>Question 1)</strong> Does $MA(\kappa) \longrightarrow D(\kappa, \lambda) ?$</p>

<p>Or even:</p>

<p><strong>Question 2)</strong> Is it true that $$Con(ZFC+ \neg CH+MA(\kappa)) \longrightarrow Con(ZFC+ D(\kappa , \lambda)) ?$$</p>

<p><strong>Remarks:</strong> Clearly $ZFC \vdash D(\omega, \omega)$ and also $MA(\kappa) \longrightarrow D(\kappa, \omega) \wedge D(\kappa, \kappa).$
On the other hand what happens in the case $\lambda=\kappa$, when we add the condition $|\mathfrak{B} \smallsetminus \mathfrak{A}|=\kappa$ into the defination of $D(\kappa, \kappa)$? I mean, let $D^{+}(\kappa, \kappa)$ be $D(\kappa, \kappa)$ with this additional condition.</p>

<p><strong>Question 3)</strong> Does $MA(\kappa) \longrightarrow D^{+}(\kappa, \kappa) ?$</p>

<p>Thanks</p>
",logic
"<p>Since Boole it is known that probability theory is closely related to logic.   </p>

<p>According to the axioms of Kolmogorov, probability theory is formulated with a (normalized) 
probability measure $\mbox{Pr}\colon \Sigma \to [0,1]$ on a Boolean
$\sigma$-algebra $\Sigma$ (of events).</p>

<p>Realizing these data by a set $X$ (sample space of elementary events) and a corresponding $\sigma$-algebra $\Sigma(X)\subseteq P(X)$ of subsets of $X$, one obtains a probability space $(X,\Sigma(X),\mbox{Pr})$.   </p>

<p>The $\sigma$-homomorphisms  $f \colon {\cal B}({\mathbb R})\to \Sigma$ (real $\Sigma$-valued measures) are defined on the Borel $\sigma$-algebra 
${\cal B}({\mathbb R})$ of the real Borel sets. They can be realized by real-valued measurable functions $F\colon X\to {\mathbb R}$ (random variables). </p>

<p>I wonder how this theory extends from the classical to the intutionistic logic i.e. from the  Boolean to the Heyting ($\sigma$-)algebras and what  the major differences between the two theories are.</p>

<p>Where can I find precise descriptions of the following topics:</p>

<ol>
<li><p>Definition and properties of probability measures on a Heyting algebra ${\cal H}$.</p></li>
<li><p>Definition and properties of  real ${\cal H}$-valued measures $f \colon {\cal B}({\mathbb R})\to {\cal H}$.</p></li>
</ol>

<p>(Already the discrete case would be of interest.)</p>

<p>(BTW: Boole 1815–1864; Heyting 1898–1980; Kolmogorov 1903–1987) </p>
",logic
"<p>If ZFC (Zermelo-Fraenkel set theory with the Axiom of Choice) is consistent, does it remain consistent
when the following statement is added to it as a new axiom? </p>

<p>""There exists a denumerably infinite and ordinal definable set of real numbers, not all of whose elements
are ordinal definable""</p>

<p>If the answer to the above question is negative, then it must be provable in ZFC that every denumerably
infinite and ordinal definable set of real numbers is hereditarily ordinal definable. This is because
every real number can be regarded as a set of finite ordinal numbers and every finite ordinal number is
ordinal definable.
                                                                        Garabed Gulbenkian</p>
",logic
"<p>Main Question:</p>

<p>Does ZF (no axiom of choice) prove that every Principal Ideal Domain is a Unique Factorization Domain?</p>

<p>The proofs I've seen all use dependent choice.</p>

<p>Minor Questions:</p>

<p>Does ZF + Countable Choice prove all PIDs are UFDs?</p>

<p>Does ZF prove ""If all PIDs are UFDs, then [some choice principle]""?</p>

<p>(If anyone knows how I could force line breaks to put the questions on their own lines, please tell me.)</p>
",logic
"<p>When working over a model $V$ of $ZFC$, countably closed forcings are extremely nice:</p>

<blockquote>
  <p>If $\mathbb{P}$ is countably closed, then $V[G]$ has no new $\omega$-sequences of elements of $V$. In particular, countably closed forcing adds no new reals.</p>
</blockquote>

<p>This can fail miserably if $V\models ZF+\neg AC$. In particular, it is consistent with $ZF$ that there is an infinite, Dedekind-finite set $X$ of reals. Letting $\mathbb{P}$ be the poset of finite partial injective maps $\subseteq\omega\rightarrow X$, we have the peculiar result that $\mathbb{P}$ is countably closed inside $V$, since there are <em>no</em> countably infinite subsets of $X$! </p>

<p>The general question is: without $AC$, what are good ways to tell that forcing with a given poset adds no new reals?</p>

<p>A particular sub-question, that I am separately interested in: if $W\models ZF$, $W$ is an inner model of $V\models ZFC$ with $\mathbb{R}^V=\mathbb{R}^W$, and $\mathbb{P}\in W$ is countably closed in $V$, then forcing with $\mathbb{P}$ over $W$ adds no new reals. However, I don't actually know any ways of building pairs $(V, W)$ with these properties. So, my subquestion is:</p>

<p>How does one show (without extra consistency strength, so not $L(\mathbb{R})$) that there are models $V$ and $W$ of $ZFC$ and $ZF$ respectively, such that $W\models$ ""The reals are not well-ordered"" and $\mathbb{R}^V=\mathbb{R}^W$?</p>
",logic
"<p>This may be inappropriate for MO, but here goes: <strong>if</strong> I have understood the statement of the Erdős&ndash;Rado theorem correctly, then it contains as a special case the following result:</p>

<blockquote>
  <p>if $\mu$ is an infinite cardinal then $(2^\mu)^+ \to (\mu^+)_\mu^2$</p>
</blockquote>

<p>that is, every $\mu$-colouring of the $2$-elements subsets of a set $X$ of cardinality $&gt; 2^\mu$ has a monochromatic subset of cardinality $&gt;\mu$.</p>

<p>Looking online, the usual citation given for the ER-theorem is </p>

<p>P. Erdős, R. Rado, <em>A partition calculus in set theory</em>. 
<a href=""http://www.ams.org/journals/bull/1956-62-05/S0002-9904-1956-10036-0/home.html"" rel=""nofollow"">Bull. Amer. Math. Soc. 62 (1956), 427&ndash;489</a></p>

<p>I am trying to track down <strong>where</strong> in this paper one can find the statement of the E-R theorem, or at least the special case described above. Unfortunately, partition calculus lies <strong>well</strong> outside my usual routes for mathematical excursions, and some of the notation E&amp;R use seems slightly at odds with the notation I see in all the various online notes describing or proving the E-R theorem. I am hoping that the set theorists among the MO readership may be more familiar with the notation of the paper and hence be able to quickly locate the statement.</p>
",logic
"<p>I’d like to verify if my formula correctly expresses that a number is a power of $ 10 $, using the $ \sf{TNT} $ language provided by Hofstadter in his famous book <em>Gödel, Escher, Bach: An Eternal Golden Braid</em>. Although Hofstadter uses ‘$ b $’ to express the desired number, I’ll use ‘$ a $’ just for the sake of clarity. I’ll use common numerals for shortening the formula. Here we go:</p>

<p>$$\exists b: \exists c: \exists d: \exists e: (a = 1) \\
$$
$$\lor (((\neg (b = 0) \land (a = 10 \cdot b)) \supset ((b = 10 \cdot c) \lor (b = 1))) \\
$$
$$\land (((c = d \cdot e) \land  \neg \exists f:(d = 10 \cdot f)) \supset (d = 1)))
$$</p>
",logic
"<p>My questions concern the following quote from “The HOD Dichotomy”, page 8. </p>

<p>""… notice that $\ cof(\omega)\cap\lambda$ belongs to $HOD$ even though it might mean
something else there. Also, $\{S\subseteq\lambda\mid S\in HOD \text{ and S is stationary}\}$ belongs
to $HOD$ even though there might be sets which are stationary in $HOD$
but not actually stationary. In any case, $HOD$ can recognise when a given
$S\in HOD$ is stationary in $V$...”</p>

<p>My three (probably naive) questions are:</p>

<ol>
<li><p>Given an ordinal $\lambda$, what could $cof(\omega)\cap\lambda$ mean in $HOD$ that it doesn’t mean in $V$?</p></li>
<li><p>Perhaps a set $C$ could be club in a given ordinal $\kappa$ in $HOD$, and hence a set $S\in HOD$ could be stationary there, though $S$ is not stationary in $V$. Could there be a set $C$ club in some $\kappa$ which is not actually club in $\kappa$? </p></li>
<li><p>How can $HOD$ recognize when a particular set $S$ is stationary in $V$ if it isn't stationary in $HOD$?</p></li>
</ol>

<p>Is there some kind of absoluteness between $HOD$ and $V$ involving club and stationary sets that simply ""falls out of"" the notion ordinal or hereditarily ordinal definable that I have missed?</p>
",logic
"<p>Suppose that for all $\alpha&lt;\kappa$ we have that $A_\alpha\subseteq\kappa$. We define the diagonal intersection to be $$\bigtriangleup_{\alpha&lt;\kappa}A_\alpha = \left\lbrace\xi&lt;\kappa\ \middle|\ \xi\in\bigcap_{i&lt;\xi}A_i\right\rbrace$$</p>

<p>One of the most surprising theorems in basic set theory, I think, is that if $A_\alpha$ is closed and unbounded (and $\kappa$ is regular and uncountable) then this diagonal intersection is also a closed and unbounded set.</p>

<p>Looking at it from a measure theoretic point of view now, clubs correspond to sets of measure one. Is there any measure theoretic operation which corresponds to diagonal intersections?</p>

<p>Are there possibly other analogies in mathematics which can be used to describe this construction in a rather simple way that non-set theorists could relate to?</p>

<p>Furthermore, it is quite clear that changing the order of the $A_\alpha$ or taking a subsequence can completely change the resulting set. Is there some invariance? For example, up to order the result is unique modulo a non-stationary set?</p>
",logic
"<p>In universal algebra, a <a href=""http://en.wikipedia.org/wiki/Variety_%28universal_algebra%29"" rel=""nofollow"">variety</a> is axiomatized by identities $t \approx s$ between terms $t$ and $s$. More general are <a href=""http://en.wikipedia.org/wiki/Quasivariety"" rel=""nofollow"">quasi-varieties</a> that are axiomatized by quasi-identities of the form $$u_1 \approx v_1,\dots,u_n \approx v_n \Rightarrow t \approx s,$$ which is intended to mean $$(\forall \bar{x})[u_1 = v_1 \land \cdots \land u_n = v_n \to t = s].$$ These are universal Horn theories which are therefore exceptionally well behaved and worthy of a special name.</p>

<p>A natural next step in the hierarchy are theories axiomatized by gadgets of the form $$u_1 \approx v_1,\dots,u_n \approx v_n \Rightarrow t_1 \approx s_1,\dots,t_m \approx s_m,$$ which are intended to mean $$(\forall \bar{x})[u_1 = v_1 \land \cdots \land u_n = v_n \to t_1 = s_1 \lor \cdots \lor t_m = s_m].$$ (When $m = 0$ the right hand side is understood to be $\bot$.) Unfortunately, such theories are not as well behaved as the above so it is not clear they are worthy of a special name. However, if there is one name that has been in use for these theories, I would like to know!</p>
",logic
"<p>There is an extremely rich and well-understood analogy between ""recursively enumerable"" and ""$\Pi^1_1$"" - indeed, this is the starting point of metarecursion theory, and $\alpha$-recursion theory in general (see Sacks' wonderful book <a href=""http://projecteuclid.org/DPubS?verb=Display&amp;version=1.0&amp;service=UI&amp;handle=euclid.pl/1235422632&amp;page=record"">http://projecteuclid.org/DPubS?verb=Display&amp;version=1.0&amp;service=UI&amp;handle=euclid.pl/1235422632&amp;page=record</a>).</p>

<p>I'm interested in whether there is a straightforward reverse mathematical analogy to be made here, as well. Specifically, we usually think of $RCA_0$ and $ACA_0$ as ""recursive comprehension"" and ""recursively enumerable comprehension,"" respectively; I'm wondering if there is a theory $T$ such that we can - in a similar way - think of $T$ as ""metarecursive comprehension"" and $\Pi^1_1-CA_0$ as ""metarecursively enumerable comprehension."" </p>

<p>A natural candidate for that theory might be $\Delta^1_1-CA_0$, but that's not quite right: in the metarecursive context, $\Delta^1_1$ corresponds to finite (since intuitively everything is relative to Kleene's $\mathcal{O}$). I've been thinking that the right $T$ here is $ATR_0$, but I don't really have any serious reason to back that up.</p>

<p>My instinct is that this is not really the right question - metarecursion theory doesn't live on $\omega$, it lives on $\omega_1^{CK}$, so the right thing to do is formulate a version of reverse math on $\omega_1^{CK}$ (in fact, Richard Shore <a href=""http://www.math.cornell.edu/~shore/papers/pdf/RMComp7.pdf"">http://www.math.cornell.edu/~shore/papers/pdf/RMComp7.pdf</a> has already done this for cardinals, and I don't see anything preventing his work extending to arbitrary admissible ordinals - although his theorems might not, of course, since they may require more admissiblity than $\Sigma_1$). But I'm still holding out hope that there's something neat that can happen already on $\omega$.</p>

<p>(I've tagged ""descriptive-set-theory"" because of the deep connections between higher recursion theory and descriptive set theory, but if anyone feels that that's too much of a reach here, feel free to untag.)</p>
",logic
"<p>I'd like to ask a question on type theory:</p>

<p>Consider the usual type theoretical definition of the natural numbers. We could give an elimination rule in the form:
<img src=""http://i.stack.imgur.com/8fNOW.png"" alt=""enter image description here"">
or in the form:
<img src=""http://i.stack.imgur.com/Jxzuk.png"" alt=""enter image description here""></p>

<p>I called the costants in the elimination rules $NatCata$ and $NatPara$ for the
parallel with catamorphisms and paramorphisms recursion schemas. I also omitted
the computation rules, as they are well known.</p>

<p>Now, this two ways to introduce the elimination rules let us build the same
functions (in the sense in which a function is his graph), but other details are
different (for example, the length of the derivation in the computation of a
function; the pseudo-predecessor function expressed with the $NatCata$ version
has to recur on all the structure, while with $NatPara$ is always a single
step).</p>

<p>What I want to know is this: is there any reason why we insist on having a
unique elimination rule?</p>

<p>Examples of such reasons may be theorems which are easier to state/proof, or
other meta-theoretic properties.</p>

<p>Could we have different elimination rules, if they are automatically determined
by the introduction rules (as in this case?). Would a logician consider this
approach tasteful?</p>
",logic
"<p><a href=""https://en.wikipedia.org/wiki/Reverse_mathematics"">Reverse mathematics</a> (RM) is that area that tries to pin down exactly which axioms are necessary to prove theorems, given some weak base theory. Harvey Friedman has pointed out several times (on the <a href=""http://www.cs.nyu.edu/mailman/listinfo/fom"">FOM mailing list</a>) that $Con(PA)$ is equivalent to a variant of Bolzano-Weierstrass over the rationals between 0 and 1 inclusive (something like: every sequence has a subsequence $\{q_i\}$ which is Cauchy, in the that sense $\forall i,j \geq n, |q_i - q_j| &lt; 1/n$). Apparently a very similar result is given in <a href=""http://www.personal.psu.edu/t20/sosoa/"">Simpson's book</a> and ""it is clear to the experts"" how to get to Friedman's claim. (As an aside, I find this such an amazing result it should be written up for the average mathematician, and not buried in a vaguely equivalent form in a book that is hard to get one's hands on.)</p>

<p>The reason I bring up Bolzano-Weierstrass is that Todd Trimble, in a <a href=""http://mathoverflow.net/a/210337"">nice answer</a> on <a href=""http://mathoverflow.net/questions/10535/ways-to-prove-the-fundamental-theorem-of-algebra"">Ways to prove the fundamental theorem of algebra</a>, uses B-W to prove (as the key tool among other, elementary considerations) the fundamental theorem of algebra. Todd then had a look to see, at my behest, if the RM strength of FTA was known. He came up blank, so I ask here:</p>

<blockquote>
  <p>How close in reverse mathematical strength are the Bolzano-Weierstrass statement from Friedman's claim and the fundamental theorem of algebra?</p>
</blockquote>

<p>If they are the same, then we find ourselves in the amazing situation that the consistency of PA is equivalent to a theorem that we all would use with no qualms whatsoever. However, I have a vague feeling that FTA is strictly weaker than BW (as used here), but cannot make this precise.</p>
",logic
"<p>In the paper</p>

<blockquote>
  <p><a href=""http://link.springer.com/chapter/10.1007%2F978-3-0348-8599-7_22"" rel=""nofollow"">Eléments de la méthode de forcing dans quelques travaux de N. N. Lousin</a>. (French) [Elements of the method of forcing in some papers of N. N. Luzin] Amphora, 469–479, Birkhäuser, Basel, 1992. </p>
</blockquote>

<p>Fedor Medvedev has claimed the following:</p>

<blockquote>
  <p>P. Cohen, who proved the independence of the axiom of choice and of the generalized continuum hypothesis by the method of forcing, did not invent this method, but discovered it in the works of his predecessors. The aim of the paper is to indicate some elements of the method in the works of N. N. Luzin. </p>
</blockquote>

<p>I could find the paper, but it is in French, and so I  could not read it.</p>

<p><strong>Does anyone know how the work of Luzin is related to forcing?</strong> </p>

<p>The following papers of Luzin are mentioned in the above paper:</p>

<p>1) LOUZIN, N.: Sur un probleme de M. Baire. Comptes
rend. de l'Acad. sei. de Paris 158 (1914),1258-
1261. - LOUZIN, N. N.: Sur une theoreme de
Baire. ffiuvres completes. Moscou: Mit. Acad. des
Seiences de l'U.R.S.S., v. 11, 1958, pp. 683-685.</p>

<p>2) LOUZINE, N.: Sur l'existance d'un ensemble nondenombrable
qui est de premiere categorie sur tout
ensemble parfait. Fund. Math. 2 (1921), 155-157.
- LOUZINE, N. N.: Sur l'existance de l'ensemble
de premiere categorie dans tout ensemble parfait.
ffiuvres completes. Moscou: Mit. Acad. des Seiences
de l'U.R.S.S., v. 11, 1958, pp. 692-694.</p>

<p>3) LOUZINE, N.: Sur une question concemant la propriete
de Baire. Fund. Math. 9 (1927), 116-118.-LOUZINE, N. N.: Sur un point, concernant la propriete
de Baire. 

<p>4) LOUZINE, N.: Sur les ensembles toujours de premiere
categorie. Fund. Math. 21 (1933), 114-126.
- LOUZINE, N. N.: Sur les ensembles toujours de
la premiere categorie. 

<p>5) LOUZINE, N., SERPINSKI, W.: Sur un ensemble
non-denombrable qui est de premiere categorie sur
tout ensemble parfait. Atti della R. Acad. dei LinceL
Serie 6. 7 (1928), 214-215. - LOUZINE, N.
N., SERPINSKI, W.: Sur l'ensemble denombrable,
etant l'ensemble de premiere categorie sur tout ensemble
parfait. 

<p><strong>Are there any English translation of the above papers of Luzin?</strong></p>
",logic
"<p>Categorical models for linear logic with $\otimes$, $1$, $\&amp;$, $\top$, $\oplus$, $0$, and $\multimap$ are typically symmetric monoidal closed categories (for modeling $\otimes$, $1$, and $\multimap$) with products (for modeling $\&amp;$ and $\top$) and coproducts (for modeling $\oplus$ and $0$). Is it harmful to additionally require that such a category has exponentials? Exponentials would model a binary operator $\Rightarrow$ for which proofs of $A \vdash B \Rightarrow C$ correspond to proofs of $A \mathbin\&amp; B \vdash C$. Are there sensible categorical models for linear logic that have exponentials, or does the introduction of exponentials make the structure collapse?</p>
",logic
"<p>Say that a set $X\subseteq\omega$ is <strong>distinguishable</strong> if there is some Turing machine $\Phi_e$ which, when given two sets <em>exactly one of which is $X$</em>, can determine which set is $X$. Formally, $X$ is distinguishable if there is some Turing machine $\Phi_e$ such that for all $Y\not=X$, $$\Phi_e^{X\oplus Y}(0)=0,\quad \Phi_e^{Y\oplus X}(0)=1.$$ (Think of ""$0$"" and ""$1$"" as meaning ""Left"" and ""Right."")</p>

<p>Clearly every computable set is distinguishable; it is not hard to show (see my answer to <a href=""http://math.stackexchange.com/questions/1189370/is-there-a-turing-machine-that-can-distinguish-the-halting-problem-among-others"">http://math.stackexchange.com/questions/1189370/is-there-a-turing-machine-that-can-distinguish-the-halting-problem-among-others</a>) that the converse also holds. My question is about the <em>reverse mathematics</em> of the converse. Specifically, my proof used Weak Konig's Lemma, and I don't immediately see a way to do without it. So my question is:</p>

<blockquote>
  <p>Is it consistent with $RCA_0$ that there is a non-computable, distinguishable set?</p>
</blockquote>

<hr>

<p>Motivation: Over the last year or so I've developed an interest in ""alternate computability theories"" - e.g. see Visser's delightfully-named paper ""Oracle bites theory"" at <a href=""http://www.phil.uu.nl/preprints/lgps/authors/visser/oracle-bites-theory/pdf"">http://www.phil.uu.nl/preprints/lgps/authors/visser/oracle-bites-theory/pdf</a>. I'm especially interested in ""almost computable"" sets in such theories, and distinguishable sets might provide such an example. </p>
",logic
"<p>Is there a definition of what is a 'free monoid' which does not pre-suppose that the natural numbers has already been defined?  The definitions that I have been able to track down all use the natural numbers (since sequences/words need them).</p>

<p>In other words, I am trying to define the <em>theory</em> of free monoids (as a signature with sorts, operations and axioms), and I would like to know if I can do this without having the theory of the naturals already defined.  For exhibiting/constructing a free monoid, I do expect to need Nat.</p>

<p>Note that my ambient logic is higher-order, so I am fine with a second-order axiomatization.  If dependent-types are needed, that would also be acceptable.</p>
",logic
"<p>Let $\mathcal{C}$ and $\mathcal{D}$ be pretopoi, and let $f: \mathcal{C} \rightarrow \mathcal{D}$ be a pretopos functor (that is, a functor which preserves finite coproducts, finite limits, and epimorphisms).
Let $M( \mathcal{C} )$ be the category of models of $\mathcal{C}$ (that is, pretopos functors from $\mathcal{C}$ to the category of sets) and define $M( \mathcal{D} )$-similarly. </p>

<p>The conceptual completeness theorem of Makkai-Reyes asserts that if
$f$ induces an equivalence of categories $M(f): M( \mathcal{D} ) \rightarrow M( \mathcal{C} )$, then $f$ is itself an equivalence of categories.</p>

<p>I am wondering about the following more general situation. Suppose that the functor $M(f)$ is an op-fibration in sets (in other words, that the category $M( \mathcal{D} )$ can be obtained by applying the Grothendieck construction to a functor from $M( \mathcal{C} )$ to the category of sets). I would like to conclude that $\mathcal{D}$ can be obtained as a filtered colimit of pretopoi of the form $\mathcal{C}_{ / C}$ (in other words, that $\mathcal{D}$ is the pretopos associated to a Pro-object of $\mathcal{C}$).</p>

<p>Is something like this true, and/or available in the categorical logic literature?</p>
",logic
"<p>The question's in the title and is easily stated, but let me try to give some details and explain why I'm interested.  First, a disclaimer: if the answer's not already somewhere in the literature then it could be rather hard; I'm asking this question here because MO is lucky enough to have some of the foremost experts on lacunary hyperbolic groups as active participants.</p>

<p><strong>Definitions</strong></p>

<ol>
<li><p>A group $\Gamma$ is <em>non-Hopfian</em> if there is an epimorphism $\Gamma\to\Gamma$ with non-trivial kernel.</p></li>
<li><p>A group $\Gamma$ is <em>lacunary hyperbolic</em> if some asymptotic cone of $\Gamma$ is an $\mathbb{R}$-tree.</p></li>
</ol>

<p>To motivate this second definition, note that a group is word-hyperbolic if and only if <em>every</em> asymptotic cone is an $\mathbb{R}$-tree.</p>

<p>Lacunary hyperbolic groups were defined and investigated in a paper of <a href=""http://www.ams.org/mathscinet/search/publdoc.html?arg3=&amp;co4=AND&amp;co5=AND&amp;co6=AND&amp;co7=AND&amp;dr=all&amp;pg4=AUCN&amp;pg5=AUCN&amp;pg6=PC&amp;pg7=ALLF&amp;pg8=ET&amp;r=1&amp;review_format=html&amp;s4=sapir&amp;s5=osin&amp;s6=&amp;s7=&amp;s8=All&amp;vfpref=html&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;yrop=eq"">Ol'shanskii, Osin and Sapir</a> (although examples of lacunary hyperbolic groups that are not hyperbolic already existed---I believe the first one was constructed by Simon Thomas). They construct examples that exhibit very non-hyperbolic behaviour, including torsion groups and Tarski monsters.</p>

<p><strong>Question</strong></p>

<p>Once again:-</p>

<blockquote>
  <p>Is there a non-Hopfian lacunary hyperbolic group?</p>
</blockquote>

<p><strong>Motivation</strong></p>

<p>My motivation comes from logic, and the following fact.</p>

<p><strong>Proposition:</strong> A lacunary hyperbolic group is a direct limit of hyperbolic groups (satisfying a certain injectivity-radius condition).</p>

<p>That is to say, lacunary hyperbolic groups are limit groups over the class of all hyperbolic groups. (Note: the injectivity-radius condition means that there are other limit groups over hyperbolic groups which are not lacunary hyperbolic. I'm also interested in them.) Sela has shown that limit groups over a <em>fixed</em> hyperbolic group $\Gamma$ (and its subgroups) tell you a lot about the solutions to equations over $\Gamma$.  For instance, his result that a sequence of epimorphisms of $\Gamma$-limit groups eventually stabilises (which implies that all $\Gamma$-limit groups are Hopfian) has the following consequence.</p>

<p><strong>Theorem (Sela):</strong> Hyperbolic groups are equationally Noetherian.  That is, any infinite set of equations is equivalent to a finite subsystem.</p>

<p>In the wake of Sela's work we have a fairly detailed understanding of solutions to equations over a given word-hyperbolic group $\Gamma$.  But it's still a matter of great  interest to try to understand systems of equations over <em>all</em> hyperbolic groups.</p>

<p>Pathological behaviour in lacunary hyperbolic groups should translate into pathological results about systems of equations over hyperbolic groups.  A positive answer to my question would imply that the class of hyperbolic groups is not equationally Noetherian. And that would be quite interesting.</p>

<p><strong>Note:</strong>  <a href=""http://arxiv.org/abs/0903.3978"">This paper</a> of Denis Osin already makes a connection between equations over a single lacunary hyperbolic group and equations over the class of all hyperbolic groups.</p>

<hr>

<p>This question attracted great answers from Yves Cornulier and Mark Sapir, as well as some excellent comments from Denis Osin.  Let me quickly clarify my goals in answering the question, and try to summarise what the state of knowledge seems to be.  I hope someone will correct me if I make any unwarranted conjectures!</p>

<p>My motivation came from the theory of equations over the class of all (word-)hyperbolic groups.  For these purposes, it is not important to actually find a non-Hopfian lacunary hyperbolic group; merely a non-Hopfian limit of hyperbolic groups is enough.  (That is, the injectivity radius condition in the above proposition can be ignored.)  Yves Cornulier gave an example of a limit of virtually free (in particular, hyperbolic) groups which is non-Hopfian.  From this one can conclude that the class of word-hyperbolic groups is not equationally Noetherian, as I had hoped.</p>

<p>[Note: I chose to accept Yves's answer.  Mark's answer is equally worthy of acceptance.]</p>

<p>Clearly, the pathologies of Yves's groups derive from torsion---the class of free groups is equationally Noetherian---and there are some reasons to expect torsion to cause problems, so I asked in a comment for torsion-free examples.  These were provided by Denis Osin, who referred to a <a href=""http://www.ams.org/mathscinet/search/publdoc.html?arg3=&amp;co4=AND&amp;co5=AND&amp;co6=AND&amp;co7=AND&amp;dr=all&amp;pg4=AUCN&amp;pg5=AUCN&amp;pg6=TI&amp;pg7=ALLF&amp;pg8=ET&amp;review_format=html&amp;s4=ivanov&amp;s5=storozhev&amp;s6=&amp;s7=&amp;s8=All&amp;vfpref=html&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;yrop=eq&amp;r=1&amp;mx-pid=2174100"">paper</a> of Ivanov and Storozhev.  Thus, we also have that the class of all torsion-free hyperbolic groups is not equationally Noetherian.</p>

<p>Let us now turn to the question in the title---what if we require an actual lacunary hyperbolic group that is non-Hopfian.  First, it seems very likely that such a thing exists. As Mark says,  'A short answer is ""why not?""'.  More formally, Denis claims in a comment that the subspace of the space of marked groups consisting of lacunary hyperbolic groups is comeagre in the closure of the subspace of hyperbolic groups.  This formalises the idea that lacunary hyperbolic groups are not particularly special among limits of hyperbolic groups.</p>

<p>Mark also suggested two possible approaches to constructing a non-Hopfian lacunary hyperbolic group; however, in a comment, Denis questioned whether one of these approaches works.  In summary, I feel fairly confident in concluding that a construction of a non-Hopfian lacunary hyperbolic group is not currently known, although one should expect to be able to find one with a bit of work.</p>
",logic
"<p><em>I am not 100% certain this question is appropriate for MO; I may just be missing something obvious. Also, I vaguely recall a similar question being asked here a while ago, but I can't find it; if it turns out this is a duplicate, I'll delete this question. Anyways, apologies in advance if this is too easy or is a duplicate. Note that e.g. <a href=""http://mathoverflow.net/questions/110871/can-measures-be-added-by-forcing"">Can measures be added by forcing?</a> prevents the obvious nuke from working.</em></p>

<p><em>Also, the ""descriptive-set-theory"" tag is purely a guess on my part, based on the surprising ubiquity of descriptive set theory in similar-sounding questions.</em></p>

<hr>

<p>Suppose I have a transitive model $M$ of $ZFC$, and - in $M$ - $U$ is a measure on $\kappa$. Then the transitive collapse of the ultrapower of $M$ along $U$ is an inner model, $N\subset M$.</p>

<p>My question is:</p>

<blockquote>
  <p>Can we ever have $M$ be a generic extension of $N$ (either by set or class forcing in $M$)?</p>
</blockquote>

<p><strong>EDIT: As Douglas Ulrich points out below, the answer is no for set forcing, by an extension of the Kunen inconsistency. This barrier breaks down for class forcing, though (see Larson's book on stationary tower forcing), so the class version is still open.</strong></p>

<p>As mentioned above, I am almost certain the answer is ""no"", even if $M$ has loads of large cardinals, but I don't see how to prove this.</p>

<hr>

<p>A small observation:</p>

<p>Say (inside a model $W$) a cardinal $\mu$ is</p>

<ul>
<li><p><em>potentially measurable</em> if $\mu$ is measurable in some forcing extension; and</p></li>
<li><p><em>reversibly measurable</em> if $\mu$ is measurable, and $W$ is a forcing extension of the transitive collapse of the ultrapower of $W$ by a measure on $\mu$ (that is, if $\mu$ is as above).</p></li>
</ul>

<p>Then suppose we had such an $M, N, U, \kappa$, with $j$ the elementary embedding. Then $N$ satisfies ""There is a potential measurable below $j(\kappa)$,"" so - pulling back along $j$ - $M$ satisfies ""There is a potential measurable below $\kappa$."" This shows that - in $M$ - the least potentially measurable is strictly less than the least reversibly measurable (otherwise we get a descending chain of measurable cardinals).</p>

<p>Now, it feels plausible to me that there's a clever trick that can be done here to outright build a descending sequence of reversibly measurables from a single reversibly measurable; but I don't see it.</p>
",logic
"<p>Let &Sigma; be an axiom system. Can there be a formula &phi;, s.t. </p>

<ul>
<li>Con(&Sigma;) does not imply Con(&Sigma; + &phi;) AND</li>
<li>Con(&Sigma;) does not imply Con(&Sigma; + not &phi;)</li>
</ul>

<p>If yes, can you give me an example for ZFC?</p>
",logic
"<p>In this question, suppose $S$ is some popular real-world automated proof system that is stronger than or equivalent to Peano Arithmetic.  I would be happy with a positive answer to the following for any such $S$, so please feel free to cherry-pick $S$ to make that easier:</p>

<p><strong>Can the validity of an $S$-proof be verified in time polynomial in the
string-length of the proof?</strong></p>

<p>I've been able to find some work assessing progress in formal proof verification, such as </p>

<p><a href=""http://www.ams.org/journals/notices/200811/tx081101408p.pdf"">http://www.ams.org/journals/notices/200811/tx081101408p.pdf</a></p>

<p>but not much on the algorithmic complexity of verifying the outputs of various approaches, so I figure I must be looking in the wrong places / using the wrong search terms.  Please, help point me in the right direction!</p>
",logic
"<p>In the math.se question <a href=""http://math.stackexchange.com/q/59846/1778"">Proof of no prime-representing polynomial in 2 variables</a>, Alon Amit asks if Ribenboim's claim that a prime-representing polynomial (a Diophantine polynomial in which the positive values are precisely the primes) must have at least three variables has been proven.  Alon suggested that perhaps the number was a typo, that all that is known is that (trivially) no univariate polynomial is prime-representing.</p>

<p>As of Jones 1982 [1, p. 550] the question of the existence of a universal Diophantine equation in two variables was open, so certainly it was not known that the number of variables for the special case of the primes was more than 2 at that time.</p>

<p>[1] James P. Jones, ""Universal Diophantine equation"", <em>The Journal of Symbolic Logic</em> <strong>47</strong>:3 (1982), pp. 549-571.</p>
",logic
"<p>From <a href=""http://en.wikipedia.org/wiki/Lindenbaum_algebra"" rel=""nofollow"">Wikipedia</a> I learn: </p>

<blockquote>
  <p><em>The Lindenbaum algebra A of a theory T consists of the equivalence
  classes of sentences of T. The operations in A are inherited from those in T.</em></p>
</blockquote>

<p>If there are disjunction, conjunction and negation, <em>A</em> is a Boolean algebra and can be seen as a poset: </p>

<blockquote>
  <p>The objects of <em>A</em> are sentences $\phi$ modulo </p>
  
  <p>$$T \vdash \phi \leftrightarrow \phi'$$ </p>
  
  <p>There is a relation $\phi \leq \psi$ iff </p>
  
  <p>$$T \vdash \phi \rightarrow \psi$$</p>
</blockquote>

<p>Lindenbaum algebras are a bit boring since &mdash; for example &mdash; <a href=""http://mathoverflow.net/questions/65851/lindenbaum-algebras-and-models/65853#65853"">all complete theories <em>T</em> have the same two-element Lindenbaum algebra</a>.</p>

<p>They might be a bit more interesting when relaxing the conditions:</p>

<blockquote>
  <p>Objects $\phi$ modulo:</p>
  
  <p>$$ \vdash \phi \leftrightarrow \phi'$$ </p>
  
  <p>Relation  $\phi \leq \psi$: </p>
  
  <p>$$T \vdash \phi \rightarrow \psi$$</p>
</blockquote>

<p>I just want to know where I can learn more about this approach?</p>

<p><em><strong>EDIT</strong>: I made two corrections due to Joel's answer.</em></p>

<p><em><strong>EDIT</strong>: And a simplification.</em></p>
",logic
"<p>The axiom of Turing determinacy is a weakening of the full axiom of determinacy, $AD$, in which only games with payoff sets which are $\equiv_T$-invariant are demanded to be determined. </p>

<p>In ""Turing determinacy and the continuum hypothesis"" (published in 1989), Ramez Sami writes:</p>

<blockquote>
  <p>""The main question so far unsettled in this particular domain can be roughly put this way: is it true that for any ""reasonable"" pointclass $\Gamma$ we have: Turing-Det$(\Gamma)\implies$Det$(\Gamma)$? In particular is it the case that: [over $ZF+DC$, presumably] Turing $AD$ implies $AD$?"" </p>
  
  <ul>
  <li><a href=""http://link.springer.com/article/10.1007%2FBF01622874"">http://link.springer.com/article/10.1007%2FBF01622874</a>, page 153</li>
  </ul>
</blockquote>

<p>My question is, what is the status of this question currently? Do we know whether Turing $AD$ is strictly weaker than $AD$? The only recent work I know of around Turing determinacy is from the reverse mathematical side (<a href=""http://www.math.cornell.edu/~shore/papers/pdf/TDet21.pdf"">http://www.math.cornell.edu/~shore/papers/pdf/TDet21.pdf</a>); I'm not at all familiar with the set theory on the subject.</p>

<p>(I vaguely recall that Turing determinacy implies that every Suslin set is determined, but I can't remember where I supposedly learned this ""fact."")</p>
",logic
"<p>Define a number $n$ to be composite if it can be written as $a\cdot b$ for some $a,b$ where $a,b\neq 1$.</p>

<p>Define $p$ to be prime if $p=a\cdot b$ implies $a=1$ or $b=1$.</p>

<p>The theorem that every composite number has a prime factor seems to require a bit more induction than just everything is either 0 or a successor. So what is a model of Robinson Arithmetic where that theorem fails? </p>
",logic
"<p>My question is about a kind of relative constructibility in set theory.</p>

<p>Fix a countable transitive model $W\models ZFC$ which is much bigger than $L^W$. There is a natural way within $W$ to compare how non-constructible one set is relative to another: $A$ is <em>constructible relative to</em> $B$ - and write $A\le_L B$ - if $A\in L[B]$. This is the direct analogue of the relation ""<em>computable relative to</em>,"" $\le_T$.</p>

<p>There is another notion of relative constructibility that I haven't seen before, as follows. By a theorem of Barwise, given any set $A\in W$ there is an (ill-founded) end extension $W'$ of $W$ such that $W'\models A\in L$. In light of this, we can consider the following relation:</p>

<ul>
<li>Say $A$ is <em>as $L$-ish as</em> $B$ - and write $A\le_{L, end}B$ - if for every end extension $W'$ of $W$, ""$W'\models B\in L$"" implies ""$W'\models A\in L$.""</li>
</ul>

<p>My question is:</p>

<blockquote>
  <p>Is there a nice description of $\le_{L, end}$ - or an interesting subrelation, such as $\le_{L, end}$ restricted to $\mathbb{R}^W$ - without referring to end extensions?</p>
</blockquote>

<p>In general, what can we say about $\le_{L, end}$, or the induced degree structure (especially in relation to what large cardinal axioms are satisfied in $W$ or the ""real"" universe $V$ in which $W$ lives)?</p>

<p>In particular:</p>

<blockquote>
  <p>Is $\le_{L, end}$ the same as $\le_L$?</p>
</blockquote>
",logic
"<p>One can look at, say, Conway's Game of Life in at least two ways:</p>

<p>1) as a cellular automaton; and</p>

<p>2) as a discrete topological dynamical system (on an underlying Cantor set).</p>

<p>Famously, Conway showed how to build a register machine inside
the Game of Life, thus showing the Game of Life, viewed as a cellular automaton, 
Turing complete.</p>

<p>My question:  Suppose we have another discrete topological dynamical system S, on
a Cantor set C, connected to the Game of Life by a topological conjugacy.  Does
that guarantee that we can view S as a Turing complete automaton?</p>

<p>I'll assume that C comes in the form of the topological product of finite sets. 
If necessary, I'll also assume also that C has a computable update rule.</p>

<p>Certainly strong assumptions on the conjugacy (including at least computability) would allow for the translation of problems about the fate of Game of Life configuration into questions about the fate of C configurations.  But I don't see what would make all such conjugacies computable or any appropriate way to carry out Conway's argument in purely dynamical terms.</p>
",logic
"<p>This is a largely a question of pedagogy/references, though I may have overlooked some nuance of actual mathematics. </p>

<p>I am planning to introduce the concept of Turing machines and the halting problem to utter novices. </p>

<p>The proofs (or rather proof sketches) of undecidability for the halting problem that I have seen fix a universal Turing machine and vary a program and an input that both reside on the TM's tape. In effect an infinite 0-1 array is formed which is indexed by programs and inputs, with entries indicating whether or not the TM supposedly halts on the corresponding program/input pair. One then employs a diagonal argument.</p>

<p>But it seems more concrete to me to ditch the stored program idiom, let the TM vary instead, and use a TM/input pair for the diagonal argument. It is very easy to produce an explicit enumeration of (binary) TMs, and far less so to detail an encoding scheme for a universal TM's tape that allows one to sensibly distinguish the program from the input (of course I know this <em>can</em> be done, but an existence proof is not a great primary approach for very inexperienced students, I think). </p>

<p>So, are there any references that discuss a proof of the undecidability of the halting problem along these lines? (A little part of me actually wonders whether or not I have missed some trivia that obstruct such a proof, because I haven't seen one.)</p>
",logic
"<p>Suppose $\mathbb{P}$ is a notion of forcing in the ground model $V$, and $X$ is a set which is in $V[G]$ for every $\mathbb{P}$-generic filter $G$. Then $X\in V$ already, by a fairly simple (if tedious) argument.</p>

<p>I'm working on a paper in which this fact is mentioned, and I would like to cite it properly; however, I can't seem to find any citation for it, and I don't recall when I learned the argument. So my question is:</p>

<blockquote>
  <p>What is a citation for ""if $X$ is in every forcing extension by some poset $\mathbb{P}$, then $X$ is already in the ground model?""</p>
</blockquote>
",logic
"<p>A reliable source made the following claim:</p>

<blockquote>
  <p>Suppose CH there is an $\omega_2$-saturated ideal on $\omega_1$.  Then this is preserved by $\mathrm{Add}(\omega_1,\omega_2)$.</p>
</blockquote>

<p><strong>Question 1:</strong>  How do you show this?</p>

<p><strong>Question 2:</strong>  Is there an example where adding a Cohen subset of $\omega_1$ changes the truth-value of, ""There is a saturated ideal on $\omega_1$""?  Perhaps under MM?</p>
",logic
"<p>Related to the Union-closed sets conjecture.</p>

<p>Let $\phi$ be a <a href=""https://en.wikipedia.org/wiki/Horn-satisfiability"" rel=""nofollow"">co-HORNSAT</a>
on variables $x_1 \ldots x_n$ in CNF format.
This means in every close at most one literal is negative.</p>

<p>The solutions of $\phi$ are closed under disjunction,
which is related to set union.</p>

<p>Map the $j$-th solution $y_1 \ldots y_n$ to a set $S_j$,
$i \in S_j$ iff $y_i$ is True.</p>

<p>The inverse map is $y_i \iff (i \in S_j)$.</p>

<p>The sets $S_j$ corresponding to the solutions of $\phi$
are closed under union, so Frankl's conjectures implies
in $\phi$ there is variable $x_i$ which is True in 
at least half the solutions.</p>

<blockquote>
  <p>Is the converse true:  to every union-closed family of
  sets $S_i$ corresponds a co-HORNSAT formula whose solutions
  are the mapped $S_i$?</p>
</blockquote>

<p>From certain co-HORNSAT formulae got sets in which
all elements are in exactly half the sets.</p>

<p>The powerset might cause difficulty so either exclude it
or allow clauses of the form $x \lor \lnot x$.</p>
",logic
"<p>In the past, First order logic and its completeness and whether arithmetic is complete was a major unsolved issues in logic . All of these problems were solved by  Godel. Later on, independence of main controversial axioms were established by forcing method. </p>

<p>I wonder if there still exist some ""natural"" questions in mathematical logic that are still unsolved? Or is it the case that most of the major questions have been already answered? </p>

<p>I'd love to know about some important, but still unsolved problems that puzzle logicians and why would the young logician\mathematician care about those? (that is, Whey they are important?)</p>

<p>I'm not an expert in logic (nor in any other mathematical field, I'm undergraduate) but I'm interested in logic so I would like to know about the current problems that logicians face and what are the trends of research in the discipline nowdays and what type of problems people are trying to solve.</p>

<p>I know that logic is a vast term which includes many sub-disciplines: model theory, proof theory, set theory, recursion theory,  higher-order logics , non-classical logics, modal logics, algebraic logic and many others. So feel free to tell us about problems form whichever topic you would love to. </p>
",logic
"<p>I have been trying to understand ""The Hanf number of the first  order theory of Banach spaces"" by Shelah and Stern (Trans. AMS 244 (1978) 147-241). They construct a normed space $M$ from a Hilbert space $\cal H$ by taking the unit ball of $M$ to be the intersection of that of $\cal H$ with the halfspaces defined by $(x, \pm a) \le 1 - \delta_a$ for certain unit vectors $a$  and small $\delta_a &gt;0$. They then need to show that the $\cal H$-unit ball is definable in $M$ using a first order language with symbols for vector addition and membership of the $M$-unit ball. With this in view, in their Lemma 2.9, they claim certain of the vectors $a$ are definable, but they don't have what they need to apply the lemma they appeal to for this (they have an inequality $\|b\| \le (1 - \delta)^{-1}$ but their Lemma 2.3 needs the opposite inequality).</p>

<p>So this looks like a bug. I suspect it can be fixed, e.g., by taking the unit ball to be the convex hull of the proposed one and the vectors $\pm a$. But this would be quite disruptive to the rest of the argument, I suspect.</p>

<p>My questions are (1) have I missed something so that Shelah and Stern's proof does actually go through more or less as its stands, or (2) is there another reference that gives a correct proof of these results.</p>
",logic
"<p>Let $\mathcal{L}$ be a countable first order language. For a natural number n, can we find a complete $\mathcal{L}$-Theory $T$ which has exactly n non-isomorphic countable models ?</p>
",logic
"<p>Clearly I first need to formally define what I mean by ""junk"" theorem.  In the usual <a href=""http://en.wikipedia.org/wiki/Set-theoretic_definition_of_natural_numbers"">construction of natural numbers in set theory</a>, a side-effect of that construction is that we get such <em>theorems</em> as $2\in 3$, $4\subset 33$, $5 \cap 17 = 5$ and $1\in (1,3)$ but $3\notin (1,3)$ (as ordered pairs, in the usual presentation).  </p>

<p>Formally: Given an axiomatic theory T, and a model of the theory M in set theory, a true sentence $S$ in the language of set theory is a <em>junk theorem</em> if it does not express a true sentence in T.</p>

<p>Would it be correct to say that <a href=""http://ncatlab.org/nlab/show/structural+set+theory"">structural set theory</a> is an attempt to get rid of such junk theorems?</p>

<p>EDIT: as was pointed out $5 \cap 17 = 5$ could be correctly interpreted in lattice theory as not being a junk theorem.  The issue I have is that (from a computer science perspective) this is not modular: one is confusing the concrete implementation (in terms of sets) with the abstract signature of the ADT (of lattices).  Mathematics is otherwise highly modular (that's what Functors, for example, capture really well), why not set theory too?</p>
",logic
"<p>There is those one Q5 to Q7 in <a href=""https://en.wikipedia.org/wiki/Hilbert_system#Formal_deductions"" rel=""nofollow"">https://en.wikipedia.org/wiki/Hilbert_system#Formal_deductions</a></p>

<p>But I know the axioms of Boolean algebra were simplified to this <a href=""https://en.wikipedia.org/wiki/Wolfram_axiom"" rel=""nofollow"">https://en.wikipedia.org/wiki/Wolfram_axiom</a></p>

<p>I was wondering if similar researchs have been done on quantifiers?</p>
",logic
"<p>Apologies if my question seems overly naive, but I haven't seen/heard/read any good answers.  </p>

<p>What is modern computability theory ""really"" about? The study of feasible(even <em>remotely</em> feasible) algorithms falls under the domain of theoretical and non-theoretical computer science. There is, of course, the a posteriori fact that computability theory tells us a lot about the structure of the natural numbers(I'm thinking of Turing degrees, etc). But, from a certain perspective, this can be seen as a historical coincidence. (I'm not saying that this is necessarily a ""correct"" perspective). </p>

<p>So what is the motivation for the subject of modern computability theory?</p>
",logic
"<p>Does anybody know the exact number from the Goedel's Incompleteness Theorem? Is it written down somewhere? Is there a computer program to generate it?</p>
",logic
"<p>My question is basically, does there exist a statement X independent of ZF such that ZF + X implies a statement P of first-order arithmetic, but ZF + not X implies not P?  </p>

<p>Now X cannot be the axiom of constructibility due to Schoenfield's absoluteness theorem, which states that the axiom of constructibility, and thus its consequences like the axiom of choice and the continuum hypothesis, can't be used to prove any statement of first-order arithmetic that you couldn't already prove using ZF:
<a href=""http://en.wikipedia.org/wiki/Absoluteness#Shoenfield.27s_absoluteness_theorem"" rel=""nofollow"">http://en.wikipedia.org/wiki/Absoluteness#Shoenfield.27s_absoluteness_theorem</a></p>

<p>Also, there are examples like Con(ZF), but they're not really interesting, because obviously Con(ZF) is a true statement assuming that ZF is sound.  So I'm specifically looking for statements X whose truth value cannot be deduced from the assumption that ZF is sound.</p>

<p>So perhaps a preliminary question should be, does there exist any statement independent of ZF which can prove statements of first-order arithmetic that ZF can't prove, but whose truth value does not follow from the assumption that ZF is sound?</p>

<p>Any help would be greatly appreciated.</p>

<p>Thank You in Advance.</p>

<p>EDIT:  This is based on <a href=""http://math.stackexchange.com/questions/467017/do-the-axiom-of-choice-and-its-negation-have-contradictory-consequences-for-arit"">a question of mine</a> from Math.Stackexchange:</p>

<p>EDIT 2:  Just to clarify, when I said ""does not follow from the assumption that ZF is sound"", I was speaking metamathematically, I wasn't talking about reasoning within the language of ZF.  I meant that we shouldn't be obliged to believe either X or its negation just because we believe that the axioms of ZF are true.  The axiom of choice is an example of such a statement: if we accept that the axioms of ZF are true, that doesn't compel us to accept either the axiom of choice or its negation.  But unfortunately, the axiom of choice doesn't have any new consequences for first-order arithmetic, outside of what ZF already allows us to prove.  So I want a statement like that that does have consequences for first-order arithmetic.</p>

<p>Still, if people find it too informal to talk about metamathematical reasoning, we can make things more precise by defining the truth predicate of ZF within NBG set theory, as shown in theorem 1 of <a href=""http://matwbn.icm.edu.pl/ksiazki/fm/fm37/fm37110.pdf"" rel=""nofollow"">(Mostowski 1950)</a>.  Or, if @JoelDavidHamkins is right and we can't define a truth predicate within NBG, I'm happy to define the truth predicate within Morse-Kelley set theory instead.  But however we formalize it, I hope my intent is clear: I want a statement X such that mathematicians who agree that the axioms of ZF are true can still disagree about whether statement X is true.</p>

<p>EDIT 3:  I've come to realize that consistency statements Con(T) don't satisfy what I'm trying to ask, because the only warrant of their independence from ZF is that we assume that the underlying theory T is in fact consistent.  Because if the theory were inconsistent, then the falsehood of Con(T) could be proven in ZF and even in PA.  The reason for that is that consistency statements are all Pi_1 statements, and every false Pi_1 statement can be proven wrong in PA and thus ZF.  So I want the arithmetical statement P to be higher up in the arithmetical hierarchy than Pi_1.</p>

<p>Now, as @WillSawin has pointed out, it's easy to show that there are truths of first-order arithmetic that are independent of ZF + (All Pi_1 truths), because otherwise an oracle who could decide Pi_1 truths would be able to decide all truths of first-order arithmetic, which is obviously wrong.  So we know that such a statement exists.  But I would prefer to have a concrete statement, not just a proof that a statement exists.  </p>

<p>And more importantly, while I do want P to be a statement of first-order arithmetic, I would prefer that X not be a statement of arithmetic.  I want X to be a set-theoretic statement that's not an arithmetic statement, something like the axiom of choice, the continuum hypothesis, or a large cardinal axiom.  The fundamental intent of my question is, can there be an unfalsifiable disagreement about which set theory is correct, which leads to an unfalsifiable disagreement about which statements of first-order arithmetic are correct?  As noted above, Schoenfield's absolute theorem rules out the axiom of choice  and the continuum hypothesis, and <a href=""http://math.stackexchange.com/questions/467017/do-the-axiom-of-choice-and-its-negation-have-contradictory-consequences-for-arit/467024#467024"">this answer</a> to my Math.SE question suggests that large cardinals won't work either.  So does anyone know any non-arithmetical set-theoretic statement, independent of ZF, which implies a non-Pi_1 statement of first-order arithmetic that's independent of ZF?</p>
",logic
"<p>Hello,</p>

<p>I read the paper on groupoid interpretation of type theory by Hofmann and Streicher and I have a question. According to the authors $Tm([[\text{Set}\:[\Gamma]\: ]])$ is the same as $\text{Se}([[\Gamma]])$ but I don't understand because an element of  $Tm([[\text{Set}\,[\Gamma]\:]])$ is a pseudo-fonctor (from $[[\Gamma]]$ to GPD) as said page 10 while an element of $\text{Se}([[\Gamma]])$ is a true fonctor (from $[[\Gamma]]$ to Gpd). Have you an idea ?</p>

<p>Best</p>

<p>P.S: I precise that the paper I mention is entitled <em>The Groupoid Interpretation of Type Theory</em> by Martin Hofmann and Thomas Streicher. You can find this article here <a href=""http://www.mathematik.tu-darmstadt.de/~streicher/"" rel=""nofollow"">http://www.mathematik.tu-darmstadt.de/~streicher/</a>
Thanks </p>
",logic
"<p>Joel Hamkin's <a href=""http://arxiv.org/abs/1108.4223"">The set-theoretic multiverse</a> has featured in MO questions before, e.g., <a href=""http://mathoverflow.net/questions/25227/using-the-multiverse-approach-to-decide-the-law-of-the-exluded-middle"">here</a> and <a href=""http://mathoverflow.net/questions/39604/universe-view-vs-multiverse-view-of-set-theory"">here</a>. But I was wondering about the best category theoretic angle to take on it.</p>

<p>In the paper Joel writes, rather poetically,</p>

<blockquote>
  <p>Set theory appears to have discovered an entire cosmos of set-theoretic universes, revealing a category-theoretic nature for
  the subject, in which the universes are connected by the forcing relation or by large cardinal embeddings in complex commutative diagrams, like constellations filling a
  dark night sky. (p. 3)</p>
</blockquote>

<p>He has given us a couple of kinds of morphism here, but what is the best way to capture this multiverse category theoretically? Which morphisms should we allow? </p>

<p>Is it right to stay at the level of ordinary categories? Since each universe, a model of ZFC, is a category, one might expect the multiverse to be at least a bicategory, as suggested <a href=""http://golem.ph.utexas.edu/category/2011/08/the_settheoretic_multiverse.html#c039277"">here</a>. Do set theorists consider, say, arrows between two forcing relations between two models?</p>
",logic
"<p>If any recursively enumerable language can be reduced by a mapping reduction to a language $L$, then $L$ is called $RE$ complete. In that case, $L$ must be in $RE\setminus R$. But are there languages in $RE\setminus R$ which are not $RE$ complete? Can anyone give an example of such a language? I'm sure this is well known, but it's not well known to me, and google doesn't help.</p>
",logic
"<p>Is it possible to have a structure $T$ in some language which is rigid in $V$, but in a cardinal-preserving extension $T$ is homogeneous (in a suitable sense of the word)?</p>

<p>If this is not possible, is it at least consistent? If not, then what if we remove the requirement that cardinals are preserved?</p>
",logic
"<p>The pair of identities the sine and cosine of a sum of two terms as functions of the sines and cosines of the terms separately is not as <b>simple</b> as the identity that expresses the exponential of a sum as a product.  But in some senses the former says the same thing as the latter.</p>

<p>It seems there are also some identities that are simpler when stated in terms of sines and cosines than as equivalent identities involving exponential functions.  E.g. if $a+b+c=\pi$ then $\sin(2a)+\sin(2b)+\sin(2c)=4\sin a\sin b\sin c$.</p>

<p>Is there some sensible objective way of quantifying <em>simplicity</em> and stating things like this precisely, and proving results that say specified kinds of identities are simpler in one form than in the other?</p>
",logic
"<p>I am curious whether or not the following <em>axiom</em> is independent of Hamkins's axioms for the Set-Theoretic Multiverse. Hamkins's axioms can be found <a href=""http://arxiv.org/pdf/1104.4450.pdf"" rel=""nofollow"">here on pages 1-2</a> and <a href=""http://arxiv.org/pdf/1108.4223v1.pdf"" rel=""nofollow"">here on pages 24-26</a>. </p>

<p>Consider the following axiom: If $(M,\in_M)$ and $(N,\in_N)$ are set-theoretic universes, then there exists a universe $(W,\in_W)$ such that there exists injective functions $j:M\to W$ and $i:N\to W$ where $(W|_{j(M)}, \in_W) \cong (M,\in_M)$ and $(W|_{i(N)},\in_W) \cong (N,\in_N)$.  </p>

<p>Remark: Independence might not be the correct work I am looking for (since the Set-Theoretic Multiverse is a foundational structure). I am looking to see whether this axiom (as well as its negation) is <em>coherent</em> in the same sense that the Multiverse axioms are coherent (i.e. in the same way that the collection of countable computably-saturated models of ZFC satisfies the multiverse axioms). </p>
",logic
"<p>Jack Silver proved that if $x$ is a real so that every $x$-admissible ordinal is a cardinal in $L$, then $0^{\sharp}$ exists.</p>

<p>I wonder whether various weaker or stronger  versions of Silver's result have been considered in the literature. For example,</p>

<p>$\bf{Question \ 1.}$:
How strong is the statement that there is real $x$ so that every $x$-admissible ordinal is a recursively inaccessible?</p>

<p>$\bf{Question \ 2.}$:
How strong is the statement that there is real $x$ so that every $x$-admissible ordinal is inaccessible in L?</p>
",logic
"<p>Consider a non-trivial elementary embedding $j:V_\lambda\to V_\lambda$ and, for each $A\subset V_\lambda$, set $j(A)=\bigcup_{\delta&lt;\lambda}j(A\cap V_\delta)$.</p>

<p>In <em>Implications between strong large cardinals,</em> Annals of Pure and Applied Logic 90 (1997) 79-90, Laver says that $j:(V_\lambda, \in,A)\to (V_\lambda, \in, j(A))$ is an elementary embedding.</p>

<p>I think that this is equivalent to $j$ being $\Sigma_0^1$-elementary, i.e., it satisfies the definition of elementary embedding for formulas with second order variables but without second order quantifiers.</p>

<p>Could someone provide a hint or a reference for this fact? I think I could prove it from a particular case, namely, that $\forall x\in V_\lambda\exists y\in V_\lambda\ (x,y)\in A$ implies $\forall x\in V_\lambda\exists y\in V_\lambda\ (x,y)\in j(A)$.</p>

<p>Does this case follow easily from $j$ being elementary? I cannot see it.</p>

<p>Edited:</p>

<p>I have found a proof in chapter 2 of <a href=""http://www.logic.univie.ac.at/~dimonte/notes.htm"" rel=""nofollow"">these notes</a> (theorem 0.4), but I think that the proof has a gap, since it considers skolem functions $f_i$ and assumes tacitly that $j(f_i)$ are also total functions, but they could be just partial functions.</p>
",logic
"<p>Some background: Łukasiewicz many-valued logics were intended as modal logics, and Łukasiewicz gave an extensional definition of the modal operator: $\Diamond A =_{def} \neg A \to A$ (which he attributes to Tarski).</p>

<p>This gives a weird modal logic, with some paradoxical, if not seemingly absurd theorems, notably $(\Diamond A \land \Diamond B) \to \Diamond(A\land B)$. Substitute $\neg A$ for $B$ to see why it's been relegated to a footnote in the history of modal logic.</p>

<p>However, I've realised that it's less absurd when that definition of a possibility operator is applied to Linear Logic and other substructural logics. I have an informal talk about this earlier in the month. A link to the talk is at <a href=""http://www.cs.st-andrews.ac.uk/~rr/pubs/lablunch-20110308.pdf"" rel=""nofollow"">http://www.cs.st-andrews.ac.uk/~rr/pubs/lablunch-20110308.pdf</a></p>

<p>Anyhow, the only non-critical work that I found a reference to is a talk by A. Turquette, ""A generalization of Tarski's Möglichkeit"" at the Australasian Association for Logic 1997 Annual Conference. The abstract is in the BSL 4 (4), <a href=""http://www.math.ucla.edu/~asl/bsl/0404/0404-006.ps"" rel=""nofollow"">http://www.math.ucla.edu/~asl/bsl/0404/0404-006.ps</a> Basically Turquette suggested applications in m-valued logics for m-state systems. (I've not been able to obtain any notes, slides or other content of this talk, so I would appreciate hearing from anyone who has more information.)</p>

<p>I don't have any applications for it, but I find the properties to be interesting enough to merit a paper (in progress) on adding this operator to various substructural logics, and comparing those logics with themselves augmented by Lewsian modal operators.</p>

<p><strong>My question:</strong> Is anyone here aware of other articles or papers on Tarski's Möglichkeit or ""extensional"" modalities?</p>

<p>Note: This is a question from CS Theory @ Stack Overflow <a href=""http://cstheory.stackexchange.com/questions/5928/looking-for-papers-and-articles-on-the-tarskian-moglichkeit"">http://cstheory.stackexchange.com/questions/5928/looking-for-papers-and-articles-on-the-tarskian-moglichkeit</a> which a commentator suggested I post in Math Overflow.</p>
",logic
"<p>I'm looking for books that introduce the reader to mathematical logic assuming the perspective of a formalist. 
I've found that many books are more or less written for the platonist - like Kunen's <em>Foundations of Mathematics</em>, where he even implicitly says on pp. 191 that his book, if I understood it right, is primarily written for platonists, but also explains how a formalist would understand his book (in a whopping 3 pages compared to a couple of sentences for platonist view!).</p>

<p>I'm looking for a book that doesn't wait until page 191 to explain this to me, but <em>constantly</em> conveys the formalist viewpoint.<br>
It is important that the books clearly explains the distinction between theory and metatheory and where different theorems of the metatheory live in (e.g. the soundness theorem can be perceived to be a theorem of ZFC since the relevant parts of the metatheory can be coded in ZFC).</p>

<p>I looked at every book from the thread <a href=""http://mathoverflow.net/questions/61814/ask-for-recommendations-for-textbook-on-mathematical-logic"">Ask for recommendations for textbook on mathematical logic</a> and <em>none</em> was what I was looking for. Closest to my needs came Kunen - who at least mentions formalism and how his book should be read according to this perspective. This contrasts with other logic books who don't mention anything, and Cori and Lascar's book - for their excellent introduction concerning the vicious circle in what mathematical logic studies - and Goldrei's book on logic, which is not on the list.</p>

<p>To give an explanation for this, perhaps, unusual request: I find it that I understand mathematical theories best when the setting in which the theory ""lives"" in is clearly outlined so that working in that theory is just formal manipulations of symbols - of course I can attach meaning and intuition to these manipulations, but there has to be a ""fixed"" setting to work in. From what I've read this aligns understanding aligns best with the perspective of formalism. But sadly mathematical logic is always somewhat vague and in basic core always seems to be somewhat obscure (Kunen says in the above mentioned book for example on page 190 that </p>

<blockquote>
  <p>we cannot say exactly</p>
</blockquote>

<p>what metatheory is. Now I accept that we can't begin with formal setting based on nothing, because there has to be an informal description of the most basic formal elements of our setting, but I would hope that there are books that explain in more detail that in a single paragraph what metatheory really is. Additionally the lecturer at a course I'm taking also believes in some absolute mathematical objects - I assume he is a platonist - since he frequently says things like ""no, now we're not talking about a formalized version of the natural numbers, we're talking about the <em>real</em> natural numbers"", which totally annoys me because for me, there are no <em>real</em> natural numbers).</p>
",logic
"<p>Yesterday I was shocked to discover that <a href=""http://coq.inria.fr/library/Coq.Logic.FunctionalExtensionality.html"">function extensionality</a> (the statement that if two functions $f$ and $g$ on the same domain satisfy $f\left(x\right) = g\left(x\right)$ for all $x$ in the domain, then $f = g$) is not an axiom in the standard constructive logic of Coq. Of course, one can add it as an axiom in one's files, but it is not obviously available in any pre-defined tactics. I am left wondering...</p>

<p><strong>1.</strong> What is the thinking behind considering function extensionality as foreign to the calculus of constructions? I thought that from a computational perspective, a function really <em>is</em> there to be applied to things, and cannot carry any more information than what it does to them (and its type). For a moment I suspected that Coq avoids function extensionality in order to allow applying results to models like arbitrary enriched categories whose internal homomorphisms carry some more information than plain morphisms. But this is not the case: Coq (since version 8.4) has a implementation of eta-expansion (saying that any function $f$ equals the function sending every $x$ in its domain to $f\left(x\right)$, provided the types are right). In an enriched category, this would pour any additional structure of an internal Hom down the drain. (I must say the eta-expansion in Coq feels rather weird, too -- it is triggered by the <code>reflexivity</code> tactic. I expected it to be a tactic on its own...) Having eta-expansion but no extensionality is seriously confusing: one can have $f\left(x\right) = g\left(x\right)$ for all $x$, and yet one cannot rewrite the $f\left(x\right)$ in ""the function sending every $x$ to $f\left(x\right)$"" as a $g\left(x\right)$. And there I thought the bound variable in a lambda term would be like the bound variable in a forall quantification?</p>

<p><strong>2.</strong> On a more practical note (and more on-topic in MathOverflow), how much do the axiom of function extensionality and the (weaker) axiom of eta-expansion contribute to the strength of the logic? (At this point I have to admit that I don't really know the definition of the logic involved, so I'll just say I'm talking about the logic of Coq with no additional axioms assumed; it has so far been agreeing with my intuitive understanding of constructivism, until extensionality came along.) If I can define two terms $a$ and $b$ of type $\mathrm{nat}$ (natural numbers) and use function extensionality (resp. eta-reduction, both ways) to prove their equality, can I also do it without? If I can prove a (more complicated) statement using function extensionality, is there a way to transform it into a (possibly clumsier) statement which can be proven without function extensionality and which can be transformed into the former statement using some straightforward applications of function extensionality?</p>

<p>I'm sorry for logical naivety. The way I am posing the question, I fear it would qualify as soft; nevertheless I am pretty sure that there is some precise statements to be made here (or maybe just a reference to a textbook to be given).</p>
",logic
"<p>I have been looking around, unsuccessfully, for generalizations of universal algebra based on higher-order logic (rather than first order) and where the relations are not purely equational.  Motivation:  I need a ""theory of syntax"" for presentations of higher-order, non-equational theories.  Furthermore, I want to be able to specify 'combinators' over these presentations, rigorously.</p>

<p>I am aware of <a href=""http://en.wikipedia.org/wiki/Lawvere_theory"" rel=""nofollow"">Lawvere theories</a>, but these are still equational (and neither particularly higher-order, though the multi-sorted generalization seems straightforward enough).  There is a beginning of model theory done in a logical independent way, i.e. <a href=""http://en.wikipedia.org/wiki/Institutional_model_theory"" rel=""nofollow"">model theory over an institution</a>; but that seems to concentrate on the model-theoretic aspects, rather than the universal algebra aspects. Perhaps what I am looking for are <a href=""http://en.wikipedia.org/wiki/Sketch_%28mathematics%29"" rel=""nofollow"">sketches</a>?</p>

<p>[Edit:] From the various answer below, it seems I should be asking the question ""how can I view type theory as a theory of syntax""?  Somehow, that seems like an 'implementation' (as it requires a fair bit of 'encoding'); for example, to express the 'theory of categories' [i.e. (Obj, Mor, id, src, trg, $\circ$) and 5-6 axioms, I need a dependent record.  Plus what is a sort (and sort constructor for Mor), what is an operation, and what is in Prop?  Universal algebra cleanly separates these.</p>

<p>A good question was asked: what theorems do I want?  Well, whatever operations I make on theories, well-formedness of the results will require discharging some obligations -- these obligations should all be finitely expressible (and automatically well-formed).  Furthermore, the resulting syntactic objects and their morphisms should form a finitely co-complete category.  Note that I expect that deciding if a given (presentation of a ) theory has a model to be undecidable.</p>
",logic
"<p>I asked this on MSE yesterday ( <a href=""http://math.stackexchange.com/q/197873/39378"">http://math.stackexchange.com/q/197873/39378</a> ) but no one has answered it yet.  I hope it's not too soon to post it here.</p>

<p>Here are a few ways to formalize the question, so you can pick your favorite and answer it. Assume whatever large cardinals you like.</p>

<p>(1) Is it consistent with ZFC that there is an inaccessible cardinal $\delta$ and a nonempty finite set that is first-order definable without parameters over $(V_\delta,\in)$ but has no elements that are first-order definable without parameters over $(V_\delta,\in)$?</p>

<p>(2) Is there any model of ZFC that has a finite nonempty set, first-order definable without parameters over the model, with no element that is first-order definable without parameters over the model?</p>

<p>(3) Is it consistent with ZFC that there is an ordinal-definable finite nonempty set with no ordinal-definable member? (I am aware of the question <a href=""http://mathoverflow.net/questions/17608/a-question-about-ordinal-definable-real-numbers"">A question about ordinal definable real numbers</a>, but that question asks about sets of real numbers and I already know the answer to my question for sets of real numbers, or indeed for sets of subsets of any ordinal, because they are definably linearly ordered.)</p>

<p>(4) Any of the above formulations with ZFC replaced by ZF.</p>
",logic
"<p>hi I posted this question on mathematics stackexhange ( <a href=""http://math.stackexchange.com/questions/468855/what-are-the-rosser-turquette-axioms-of-lukasiewicz-3-valued-propositional-logic"">http://math.stackexchange.com/questions/468855/what-are-the-rosser-turquette-axioms-of-lukasiewicz-3-valued-propositional-logic</a> ) but did not get an helping answer  (but did get two down votes) hope on this site maybe somebody can help me.</p>

<p>I am trying to get my head around the Rosser-Turquette axiomatisation of Lukasiewicz n-valued logics, but cannot really follow it.</p>

<p>Maybe if somebody can give me the axioms for 3 and 4 valued logic then I can figure out the others by myself.</p>

<p>I try to get the axioms out of Gottwalds book ""A Treatise on Many-Valued logics""  but i fear it is wrong on where he describes them (page 109)<br>
$ AX_{RT} 5 : J_s(s) $  for each truth degree s and each truth degree constant s denoting it,</p>

<p>To me it makes no sense because it is an axiomatisation and then there is no truth degree constant s for an s that is not a designated truthvalue.</p>

<p>As far as I remember from another text there is an axiom  $ \bigvee_{s \epsilon W} J_s(p) $  to fix the number of truth degrees to n</p>

<p>I do know that examples of the J functions are  $ J_1(p) = NCpNp $ , $ J_{1/2}(p)  = NCCpNpNCNpp $ and $ J_0(p) = NCNpp $ but for the rest it is all greek to me.</p>

<p>hope somebody can help me here</p>
",logic
"<p>The following is taken from Borceux and Bourn's <em>Mal'cev, Protomodular, Homological, and Semi-Abelian Categories</em>.</p>

<blockquote>
  <p><strong>Metatheorem 0.1.3.</strong> Let $\mathcal P$ be a statement of the form $\varphi\implies \psi$, where $\varphi$ and $\psi$ can be expressed as conjunctions of properties in the following list:</p>
  
  <ol>
  <li>some finite diagram is commutative;</li>
  <li>some morphism is a monomorphism;</li>
  <li>some morphism is an isomorphism;</li>
  <li>some finite diagram is a limit diagram;</li>
  <li>an arrow $f:\rightarrow B$ factors (of course, uniquely) through some specified monomorphism $s:S\rightarrowtail B$.</li>
  </ol>
  
  <p>If this statement is valid in the category of sets, it is valid in every category.</p>
</blockquote>

<p>After the proof comes the following remark.</p>

<blockquote>
  <p>It is probably useful to make a comment. The list of properties in our metatheorem is not exhaustive. A better way to express the metatheorem would have been to state it for Horn sentences and the ""unique existential quantifier $\exists!$"", but we do not want to enter those considerations here.</p>
</blockquote>

<p>I tried googling 'Yoneda embedding horn sentence' but didn't find anything I thought was relevant. What is the ""better way to express the metatheorem"", and why is it true? I'm guessing some topos theory comes in, but I don't really know anything about (the logical aspect of) it.</p>
",logic
"<p>DISCLAIMER: All pointclasses considered here are boldface.</p>

<p>Most of the time, when doing descriptive set theory, we want the projective sets to ""behave well;"" for example, maybe we don't want there to be nonmeasurable projective sets, or projective well orderings of $\mathbb{R}$, etc. Generally, this means making some (fairly conservative) large cardinal assumption, or equivalent.</p>

<p>At the far opposite end of things is the axiom that all sets are constructible, $V=L$. This axiom implies that there is a projective - in fact, $\Delta^1_2$ - well-ordering of the reals, and so projective sets become bad very early in the hierarchy. </p>

<p>My question is about the state of affairs when $V=L$ holds. My motivation is simply that I don't feel I have a good grasp on basic concepts in descriptive set theory, and the following seemed like a good test problem to assign myself; but I have thought about it for a while without making progress, so I'm asking here:</p>

<p>Let $\oplus$ be one of the usual pairing operators on $\omega^\omega$. For the purposes of this question, we say that a pointclass $\Gamma\subseteq \mathcal{P}(\omega^\omega)$ has the uniformization property if whenever $A\in \Gamma$, there is some $B\in \Gamma$ such that:</p>

<ul>
<li><p>$B\subseteq A$, and</p></li>
<li><p>Whenever $x\oplus y\in A$, there is a unique $z$ such that $x\oplus z\in B$.</p></li>
</ul>

<p>That is, we view $A$ as coding a relation on $\omega^\omega\times \omega^\omega$, and $B$ is the graph of a function contained in $A$. (This is not usually how uniformization is presented, but it's equivalent for all intents and purposes.) My question is then:</p>

<blockquote>
  <p>Assume $V=L$. Let $D$ be the set of (boldface) $\Delta^1_2$ elements of $\omega^\omega$; does $D$ have the uniformization property?</p>
</blockquote>

<p>Now, it seems clear to me that $D$ should <strong>not</strong> have the uniformization property. [EDIT: As Joel's answer below shows, this is completely wrong.] The counterexample should be just the $\Delta^1_2$ well-ordering $\prec$ given by the assumption that $V=L$: uniformizing $\prec$ requires us to choose, for each real $r$, a real $s$ such that $r\prec s$; and although $\prec$ is $\Delta^1_2$, the usual way of doing this - choosing the immediate $\prec$-successor of $r$ - is no longer $\Delta^1_2$.</p>

<p>However, I don't know how to show that $\prec$ - or any other $\Delta^1_2$ set - cannot be uniformized in $\Delta^1_2$. I suspect I'm just missing something fairly simple.</p>

<hr>

<p>Note: it is known that the boldface pointclasses $\Pi^1_1$ and $\Sigma^1_2$ have the uniformization property, and assuming large cardinals, the uniformization property can be further propagated to every pointclass $\Pi^1_{2n+1}$, $\Sigma^1_{2n}$. On the other hand, the class $\Delta^1_1$ of Borel sets lacks the uniformization property, provably in $ZFC$.</p>
",logic
"<p><em>All structures are countable with countable signature.</em></p>

<p>Given a structure $\mathcal{A}$, the <em>age</em> of $\mathcal{A}$, $Age(\mathcal{A})$, is the set of structures isomorphic to finitely-generated substructures of $\mathcal{A}$ (see <a href=""http://en.wikipedia.org/wiki/Age_(model_theory)"">http://en.wikipedia.org/wiki/Age_(model_theory)</a>). (This isn't really a set, but we can restrict attention to those structures contained in $H_{\omega_{17}}$, say.) $Age(\mathcal{A})$ automatically satisfies the Joint Embedding and Hereditariness properties, but may lack the Amalgamation property: an example of this is the undirected graph $\mathcal{G}$ with integers as vertices, and an edge between ever pair $(z, z+1)$.</p>

<p>Given a collection $\mathbb{K}$ of finite structures closed under isomorphism with the Joint Embedding, Hereditariness, and Amalgamation properties, we can form the <em>Fraïssé limit</em> of $\mathbb{K}$, the unique homogeneous structure $F(\mathbb{K})$ with $Age(F(\mathbb{K}))=\mathbb{K}$. Specifically, let $\mathbb{P}(\mathbb{K})=\mathbb{P}$ be the poset whose elements are finite sequences $\emptyset\prec \mathcal{A}_0\prec . . . \prec\mathcal{A}_n$ of structures in $\mathbb{K}$, ordered by reverse extension; then forcing with $\mathbb{P}$ produces the Fraïssé limit. Formally, there is a countable collection $\mathcal{D}$ of dense sets in $\mathbb{P}$ such that the direct limit of the terms of any $\mathcal{D}$-generic filter through $\mathbb{P}$ is isomorphic to the Fraïssé limit.</p>

<p>Now if $\mathbb{K}$ lacks the Amalgamation property, there will be no homogeneous structure with age $\mathbb{K}$. The poset $\mathbb{P}(\mathbb{K})$, however, still makes sense, and we can consider the collection $Fil(\mathbb{K})$ of all structures formed by (taking direct limits of terms of) maximal filters through $\mathbb{P}(\mathbb{K})$.</p>

<p>Moreover, we can compare structures in $Fil(\mathbb{K})$ in terms of relative genericity. For $D\subseteq \mathbb{P}(\mathbb{K})$ dense, let $\mathcal{O}_D$ be the set of structures which can be built by filters hitting $D$. These sets $\mathcal{O}_D$ then generate a topology $\tau_\mathbb{K}$ on $Fil(\mathbb{K})$. This space is terrible, but seems reasonably natural if what we're interested in is how generic elements of $Fil(\mathbb{K})$ are. </p>

<p>As it turns out, elements of $Fil(\mathbb{K})$ can be extremely generic, even though the Fraïssé limit as such may not exist. Specifically, let $Gen(\mathbb{K})$ be the class of isomorphism classes of structures $\mathcal{A}$ such that in every open $\mathcal{O}_D$ there is a copy $\mathcal{B}\cong\mathcal{A}$. Then, for example, consider the graph $\mathcal{G}$ from the first paragraph and let $\mathbb{K}=Age(\mathcal{G})$. $Fil(\mathbb{K})$ is precisely the class of acyclic infinite graphs in which each vertex has degree at most 2. However, the graph $\mathcal{G}$ is special among these graphs, since there is a countable collection $\mathcal{D}$ of dense subsets of $\mathbb{P}(\mathbb{K})$ such that any $\mathcal{D}$-generic filter corresponds to $\mathcal{G}$. This means $Gen(\mathbb{K})=\{\mathcal{G}\}$, and so in some sense $\mathcal{G}$ is the closest thing to a Fraisse limit of $Age(\mathcal{G})$ as we might reasonably expect to exist.</p>

<p>In general, if $Gen(Age(\mathcal{A}))$ has precisely one element, denote that element by $G(\mathcal{A})$, and call it the <em>generalized Fraïssé limit</em> of $Age(\mathbb{A})$.</p>

<hr>

<p>My questions are as follows. First, the obvious:</p>

<blockquote>
  <p>What are some sources for learning about this construction? In particular, what's it <em>actually</em> called?</p>
</blockquote>

<p>Second, </p>

<blockquote>
  <p>When is $Gen(Age(\mathcal{A}))$ nonempty? When does it have exactly one element?</p>
</blockquote>

<p>Finally, the fact that $G(\mathcal{G})=\mathcal{G}$ motivates me to ask:</p>

<blockquote>
  <p>Suppose $Gen(Age(\mathcal{A}))$ has exactly one element. What can we say about $G(\mathcal{A})$ in relation to $\mathcal{A}$? For example, what structures $\mathcal{A}$ do we have $G(\mathcal{A})=\mathcal{A}$? </p>
</blockquote>

<p>A couple quick observations: any homogeneous structure $\mathcal{A}$ will certainly have $G(\mathcal{A})=\mathcal{A}$. On the other hand, consider the graph $\mathcal{G}_\omega$ consisting of the disjoint union of infinitely many copies of $\mathcal{G}$; then $G(\mathcal{G}_\omega)=\{\mathcal{G}\}$, so not every structure has this property even if it has singleton $Gen$. Finally, note that we will always have $G(G(\mathcal{A}))=G(\mathcal{A})$ if $G(\mathcal{A})$ exists.</p>
",logic
"<p>Let $\mathcal{M}$ and $\mathcal{N}$ be two $\mathcal{L}$-structures and suppose that for n-tupls $\bar{a}\in M^n$ and $\bar{b}\in N^n$, 
$tp^\mathcal{M}(\bar{a})=tp^\mathcal{N}(\bar{b})$ where $tp^\mathcal{M}(\bar{a})=\{\varphi: 
\mathcal{M}\models\varphi(\bar{a})\}$. </p>

<p>$\bf Question$: is there an $\mathcal{}L$-structure 
$\mathcal{A}$ and elementary embeddings $f:\mathcal{M}\hookrightarrow\mathcal{A}$ and 
$g:\mathcal{N}\hookrightarrow\mathcal{A}$ such that $f(a_i)=g(b_i)$ for $1\le i\le n$?</p>
",logic
"<p>Is there any general definition, for a class $C$ of languages, what is the relativized class $C^A$ for an oracle $A$?</p>

<p>Usually, these classes and their relativizations seem to be defined in an ad-hoc way. For example, $P$ is the class of languages decided by poly Turing machines, $P^A$ is the class of languages decided by poly Turing machines with access to $A$. There is not any logic, as far as I can see, to tell you how to add $A$ to the definition of $P$.</p>

<p>Obviously, the definition of a relativization of $C$ depends on more than simply the set of languages that comprise $C$. For example, $P = NP$ is unknown, but there exists an oracle $A$ such that $P^A \neq NP^A$. So, the definition of the relativization should somehow have access to the ""defining property"" of $C$. But, is there any rigorous way to do this?</p>
",logic
"<p>Ref to : Sara Negri &amp; Jan von Plato, <em>Structural Proof Theory</em> (2001).</p>

<p>In <em>Ch.6 : Structural Proof Analysis of Axiomatic Theories</em> [page 126-on], they</p>

<blockquote>
  <p>give a method of adding axioms to sequent calculus, in the form of nonlogical rules of inference.</p>
  
  <p><strong>Theorem 6.4.1</strong> [page 136] : If $\Gamma \implies \Delta$ is derivable in $G3im^*$ or $G3c^*$, [where the first is an extesion of $G3im$, the intuitionistic multisuccedent sequent calculus] the derivation are either subformulas of the endsequent or atomic formulas.</p>
  
  <p>Consider a theory having as axioms a finite set $D$ of regular formulas. Define $D$ to be
  <strong>inconsistent</strong> if $\implies \bot$ is derivable in the corresponding extension and consistent if it is not inconsistent. For a theory $D$, inconsistency surfaces with the axioms through regular decomposition, with no consideration of the logical rules:</p>
  
  <p><strong>Theorem 6.4.2</strong>: [...] </p>
  
  <p>It follows that if an axiom system is inconsistent, its formula traces contain negations and atoms or disjunctions. Therefore, if there are neither atoms nor disjunctions, the axiom system is consistent, and similarly if there are no negations. [page 137]</p>
</blockquote>

<p>Finally, they consider [page 147-148] <strong>Lattice theory</strong>, and conclude with :</p>

<blockquote>
  <p>All structural rules are admissible in the proof-theoretical formulation of lattice
  theory. The underivability of $\implies \bot$ follows, by Theorem 6.4.2, from the fact that no axiom of lattice theory is a negation.</p>
</blockquote>

<p>Consider now, for simplicity, one of the following systems [see Peter Smith, <em>An Introduction to Gödel's Theorems</em> (1st ed - 2007), page 51-on] :</p>

<blockquote>
  <p><em>BA, Baby Arithmetic</em></p>
  
  <p><em>Q, Robinson Arithmetic</em></p>
</blockquote>

<p>Both have the axiom : $\lnot 0 = S(x)$, that is (using standard ""unabbreviation"" for $\lnot$) : $0 = S(x) \rightarrow \bot$.</p>

<p>Using the fact established above, may we say that if we have systems whose axioms does not include the $\bot$ sign, they are <em>ipso facto</em> consistent ?</p>

<p>Are there “interesting fragments” of arithmetic, based on intuitionistic sequent calculus, that are “negation-free” ?</p>
",logic
"<p>From what I understand, Higher Order Logics cannot be reduced to lower ones -- for example, Second Order Logic cannot be reduced to FOPL. But, can't I use FOPL to reason about the behavior of a Turing Machine running a second order logic solver, and thus solve second order logic problems in FOPL?</p>

<p>Edit: I mean reducibility in the sense of <a href=""http://en.wikipedia.org/wiki/Second-order_logic#Non-reducibility_to_first-order_logic"" rel=""nofollow"">http://en.wikipedia.org/wiki/Second-order_logic#Non-reducibility_to_first-order_logic</a> that there are second order sentences that cannot be expressed in first order logic. I suppose solve was the wrong word to use. What I meant is that I don't see why one can't view application of the inference rules of second order logic as just string rewriting, and so come up with a way of representing such strings and the inference rules in FOPL, and thereby perform whatever inference I could in Second Order Logic using FOPL.</p>
",logic
"<p>Let $N$ be the standard full model of the simply typed lambda calculus with infinite base type $o$ and let $X$ be an infinite and coinfinite subset of $N(o)$. I want to know if there's a full functional submodel $M$ of $N$ such that $M\cap X=\emptyset$.</p>

<p>The union of any chain of functional submodels disjoint from $X$ is also a functional submodel disjoint from $X$, so by Zorn's lemma there's a maximal submodel with this property. My conjecture is that any such maximal functional submodel would be full, but I haven't been able to show this. Any pointers to relevant literature would also be welcome.</p>

<p><em>Note on terminology</em>. Given some infinite set $N(o)$, $N(\cdot)$ is defined on complex types by identifying $N(\sigma\to\tau)$ with the set of all functions from $N(\sigma)$ to $N(\tau)$. Write $N$ for the union $\bigcup_\tau N(\tau)$. A submodel of $N$, as I am using the term, is a subset $M\subseteq N$ that is closed under application and contains the $S$ and $K$ combinators of $N$ (note in particular that it is not enough that a submodel merely contain and be closed under elements that behave like $S$ and $K$ relative to the submodel). Write $M(\sigma)$ for $M\cap N(\sigma)$, and interpret the application function $*: M(\sigma\to\tau) \to (M(\sigma)\to M(\tau))$ in the obvious way as the restriction of ordinary function application to $M$. Say that a submodel is additionally <em>functional</em> if $*$ is injective, and <em>full</em> if it is surjective.</p>
",logic
"<p>I was happily surfing the arXiv, when I was jolted by the following paper:</p>

<p><a href=""http://arxiv.org/abs/1203.0494"">Inconsistency of the Zermelo-Fraenkel set theory with the axiom of choice and its effects on the computational complexity</a> by <em>M. Kim</em>, Mar. 2012.</p>

<blockquote>
  <p><strong>Abstract.</strong> This paper exposes a contradiction in the Zermelo-Fraenkel set theory with the axiom of choice (ZFC). While Godel's incompleteness theorems state that a consistent system cannot prove its consistency, they do not eliminate proofs using a stronger system or methods that are outside the scope of the system. The paper shows that the cardinalities of infinite sets are uncontrollable and contradictory. The paper then states that Peano arithmetic, or first-order arithmetic, is inconsistent if all of the axioms and axiom schema assumed in the ZFC system are taken as being true, showing that ZFC is inconsistent. The paper then exposes some consequences that are in the scope of the computational complexity theory.</p>
</blockquote>

<p>Now this seems to be a very major claim, and I lack the background to be able to judge if the claim is true, or there is some subtle or even obvious defect in the paper's arguments. But picking on this paper itself is <strong>not</strong> the purpose of my question.</p>

<p><strong>1.</strong> The paper, however, got me very curious about how ""disastrous"" would inconsistency of ZFC really be? </p>

<p><strong>2.</strong> A slightly more precise question is: what would be the major consequences of the kind of inconsistency claimed in the abstract cited above?</p>

<p>If you feel that my questions might not admit ""clearly right"" answers, I will be happy to make this post CW. </p>
",logic
"<p>Otherwise, if all the elements in a set can be represented by a at most n symbols (finite Kolmogorov complexity), I could count them by creating a n dimensional pairing function. Or atleast, that is my assumption.</p>

<p>Any thoughts?</p>

<p>Edit: as @Carl has pointed out the correct term for sequences that have no finite representation is Kolmogorov Random not infinite as I used in my title.</p>
",logic
"<p>First, let me say that I have no idea if such a post has its place here. However, I believe that the ideas I'm going to present are important. The goal of this thread is three fold:</p>

<p>1) trying to define morally what is a theory and its stratification process (like set theory) as a collection of higher categories,</p>

<p>2) asking for references about such ideas,</p>

<p>3) listening for constructive criticisms.</p>

<p>To begin, let us notice that the 1-category Sets of all sets cannot discriminate the ""deeper"" layers of sets: by this, I mean that two different sets of the same cardinalities will be isomorphic even though their elements are non isomorphic <strong>sets</strong>. This means that 1-category theory can only see the first layer of structure of an object, but fails to see its construction process (which can, however, be quite important when one is looking at some ""higher level"" concepts).</p>

<p>Yet, if one was following the philosophy that arrows are probing the inner structure of an object, one should instantly conclude that in order to discriminate the elements of a set, and their elements, and so on, infinite category theory is needed. However, how to put such higher categorical structure on Sets? Quite simply, by thinking upside down:
we have to consider that a set is an object, while an element of a set is probed by an 1-cell, while an elements of an element is probed by a 2-cells, and so on up to some $n$ (we call the height of a set the length of the maximum chain of membership of its elements).
With such vocabulary, one needs $n$-category theory in order to probe up to length $n$ sets.</p>

<p>To begin, let us think of a strict $n$-category as something built recursively from $n-1$ categories. An $n$-category has $n+1$ collection of cells such that:
Its ""collection"" of $0$-cell are $n-1$-categories,</p>

<p>Its ""collection"" of $1$-cells are $(n-1)$-$0$-transfor (that is, $(n-1)$-functors),</p>

<p>Its ""collection"" of $2$-cells are $(n-1)$-$1$-transfor (that is, $(n-1)$-natural transformation),
...</p>

<p>Its ""collection"" of $k$-cells are $(n-1)$-$(k-1)$-transfor (for $k \leq n-1$),
...</p>

<p>Its collection of $n$-cells are $(n-1)$-$(n-1)$-transfor.</p>

<p>We also impose that the domain and codomain of an $n$-$k$-transfor is an $n$-$(k-1)$ transfor, and adds all the relevant compositions.</p>

<p>Now, for any $1$-category $\mathcal{C}$, let us define $Pow(\mathcal{C})$ to be the $2$-category whose $0$-cells are the full subcategories of $\mathcal{C}$, $1$-cells are functors between them, and $2$-cells are natural transformations between such functors.</p>

<p>Notice that at this point, with our previous interpretation of $n$-category, taking such ""powercat"" operation doesn't allow us to see deeper inside the inner structure of sets inside Sets (that it, it doesn't see that the elements of a set are sets). Yet, $Pow(Sets)$ clearly contains a terminal category whose object is $1 = \{*\}$ and unique arrow is $Id_*$. In particular, any $1$-cell from $1$ to $A$ is a way to pickup an element in $A$ (say, a set $S$), while any natural transformation between $S_1, S_2: 1 \rightarrow A$ is like picking up an arrow $S_1 \rightarrow S_2$ ""inside"" $A$, without having to know what are the constituting elements of $A$.</p>

<p>Also, say that a map $term: 1 \rightarrow A$ is terminal if it is a terminal object in $Hom(1,A)$ (that is, it picks up the terminal object inside $A$). Any natural transformation from $term$ to $S_1$ is a way to look at the elements of $S_1$ inside $A$ from the outside of $A$. Hence, such natural transformation is nothing else than an element of $A$ in the usual sense : an element of some set that is itself a set, but the latter structure seems to be totally inaccessible from the outside.</p>

<p>Here comes the idea: suppose that we are able to take for all $n$ the $Pow^n(X)$ category where $X$ is some syntactic category, hence is ""at most"" a category representing some sets of height $1$ : the ""formal"" elements of a syntactic object $A$ in $X$ are arrows $1 \rightarrow A$. Yet, these formal elements have no arrows between them because there is no 2-cells ($X$ is a $1$-cat). As a result, $X$ represents a category of sets where elements are structureless (like, urelements?). Now, let us fix some big enough $n$. Clearly, $Pow^n(Sets)$ is a $n+1$-category in the previous sense (arrows are $n$-$k$-transfors, etc). We interpret such category as a category of sets of height at most $n$, where elements are sets of height at most $n-1$, and so on. In particular, what happens if we restrict such category to a $1$-category by forgetting all $n$-$k$-transfors but the $k = 0$th one ? We are forming a $1$-category whose objects are $n$-categories and arrows are $n$-$0$-transfors representing sets of height at least $n$. However, by doing so, we just forgot that our ""elements"" of our categories are actually categories too, and this is exactly what happens when one is looking at Sets as a $1$-category: we forgot that the elements of our elements are sets!</p>

<p>Therefore, one can be tempted to say that the ""real"" category Sets is actually an $\infty$-category built under some operations on categories over a syntactic one $X$. Also, given two $0$-cells $1$ and $A$ of such $\infty$-category interpreted as some sets of some height (1 being the terminal cell), the maximum $n$ such that the $\infty$-$m$-transfors are trivials for $m &gt; n$ is simply the height of the set $A$ for the membership relation. </p>

<p>Following this line of thoughts, it becomes natural to say that a formal theory (like set theory) is a ""collection"" of higher categories ($1$-cat, $2$-cat, $\ldots$, $n$-cat, $\ldots$) that are ""closed"" under the following primitive operations: </p>

<ul>
<li><p>Powercat operations takes some $n$-category $\mathcal{C}_n$  and send it to the full $(n+1)$-category of all full subcategories of $\mathcal{C}_n$. We write it $Pow(\mathcal{C}_n)$.</p></li>
<li><p>Transfor operations takes two $n$-categories $\mathcal{C}_n$, $\mathcal{D}_n$, and sends them to the full $n$-category of $(n-1)$-transfors $Trans(\mathcal{C}_n, \mathcal{D}_n)$, </p></li>
<li><p>$Downshift_k$ operation for all positive integers $k$: if $\mathcal{C}_n$ is an $n$-category, then for any $0 \leq k &lt; n$, $Downshift_k(\mathcal{C}_n)$ is the $(n-k)$-category whose $m$-cells for $0 \leq m &lt; (n-k)$ are the $k+m$-cells of $\mathcal{C}_n$, </p></li>
<li><p>$Upshift_k$ operation for all positive integers $k$: if $\mathcal{C}_n$ is an $n$-category, then for any $0 \leq k &lt; n$, $Upshift_k(\mathcal{C}_n)$ is the $(n-k)$-category whose $m$-cells for $0 \leq m  &lt; (n-k)$ are the $m$-cells of $\mathcal{C}_n$.</p></li>
<li><p>Lifting operation: if $\mathcal{C}_n$ is an $n$-category, then $Lift(\mathcal{C}_n)$ is formally a $n+1$-category where the $(n+1)$-$n$-transfors are all identities and other cells are left unchanged.</p></li>
<li><p>Restriction by subcategories</p></li>
<li><p>Closed under limits inside any $n$-categories containing the previous ones.</p></li>
</ul>

<p>Question: Did some people already looked at this kind of things and paradigm? Moreover, can we find a syntactic $1$-category $X$ generating the category nSets, of all sets of height at most $n$ for the membership relation?</p>

<p>edit: Maybe an easier way to ""see"" the whole structure of Sets is as follow: for any set $A$, we define the small category $\mathcal{A}$ generated by the syntactic objects with the same name as the ones of $A$ (say, $a$, $b$, $c$, $\ldots$), plus a terminal element $1$. Now, the arrows of $\mathcal{A}$ are, for any objects $a$, $! : a \rightarrow 1$, and $a: 1 \rightarrow a$ with $! \circ a = Id_{1}$ and no other relations. That is, the arrow $a \circ !$ is an endoarrow that is not equals to the identity.</p>

<p>Call $1Sets$ the $1$-category whose objects are all such categories, and arrows are the functors preserving limits (that is the terminal element) between them. Note that here, the terminal category is initial, while the arrow category $(1 \rightarrow *)$ with one non trivial endoarrow at $*$ is terminal. This category is obviously equivalent to Sets. Now, if one is taking the powercat operation taking as $0$-cells all (non necessarily full actually) subcategories of $1Sets$, as $1$-cells the functors between such subcategories, and as 2-cells the natural transformations, we obtain $2Sets$: the category of all sets of height $2$. In particular, one can easily iterate such constructions by taking $Pow(nSets)$ to obtain $(n+1)$Sets as the $(n+1)$-category of all sets of height $n+1$.</p>

<p>Now, what I tried to express yesterday is that the ""true"" set theory is the ""collection"" of all $n$-categories $nSets$, which can be put together by lifting all nSets categories to infinite-categories where all $m$-cells are trivials for $m &gt; n$.</p>

<p>I hope that it's now clearer.</p>
",logic
"<p>Let $A$ and $B$ be objects in a topos $\mathcal{E}$ with natural numbers object $\mathbb{N}$.  If there is a monomorphism $m: \mathbb{N}\rightarrow A\times B$, is it necessarily the case that there is either a monomorphism from $\mathbb{N}$ to $A$ or a monomorphism from $\mathbb{N}$ to $B$?</p>

<p>This is clearly true when $\mathcal{E}$ is Boolean, although the proof I've seen is more involved than one might expect.  It freely uses the Boolean assumption in several places.</p>
",logic
"<p>In forcing, we take a collection of forcing conditions and impose a partial order on them. The convention is that if $p$ is stronger than $q$, then we say $p &lt; q$. This is perfectly fine, but it seems intuitively backwards to me. If I were designing the notation for forcing, I would want the stronger condition to be larger. (Something I read says, I think, that Shelah uses the opposite convention that I find more intuitive. Is this so?)</p>

<p>Further, if we are forcing with a collection of partial functions (as we often do), we want the stronger condition to be the partial function with the larger domain. This leads us to a definition of the poset order whereby $f &lt; g$ iff $f \supset g$. This seems notationally awkward.</p>

<p>Nonetheless, Cohen must have had some good reasons choosing the order that he did. What is/was the rational for Cohen's notational convention? Does it have benefits today, or is it just an artifact of a older approach to forcing?</p>
",logic
"<blockquote>
  <p>1) Can the Riemann Hypothesis (RH) be expressed as a $\Pi_1$ sentence?</p>
</blockquote>

<p>More formally,</p>

<blockquote>
  <p>2) Is there a $\Pi_1$ sentence which is provably equivalent to RH in PA?</p>
</blockquote>

<hr>

<h3>Update (July 2010):</h3>

<p>So we have two proofs that the RH is equivalent to a $\Pi_1$ sentence. </p>

<ol>
<li>Martin Davis, Yuri Matijasevic, and Julia Robinson,
""Hilbert's Tenth Problem. Diophantine Equations: Positive Aspects of a Negative Solution"", 1974.<br>
Published in ""<a href=""http://books.google.ca/books?id=4lT3M6F745sC&amp;pg=PA335"">Mathematical developments arising from Hilbert problems</a>"", Proceedings of Symposium of Pure Mathematics"", XXVIII:323-378 AMS.<br>
Page 335
$$\forall n &gt;0 \ . \ \left(\sum_{k \leq \delta(n)}\frac{1}{k} - \frac{n^2}{2} \right)^2 &lt; 36 n^3 $$</li>
</ol>

<p>2.
Jeffrey C. Lagarias, ""<a href=""http://www.math.lsa.umich.edu/~lagarias/doc/elementaryrh.pdf"">An Elementary Problem Equivalent to the Riemann Hypothesis</a>"", 2001
$$\forall n&gt;60 \ .\  \sigma(n) &lt; \exp(H_n)\log(H_n)$$</p>

<p>But both use theorems from literature that make it difficult to judge if they can be formalized in PA. The reason that I mentioned PA is that, for Kreisel's purpose, the proof should be formalized in a reasonably weak theory. So a new question would be:</p>

<blockquote>
  <p>3) Can these two proofs of ""RH is equivalent to a $\Pi_1$ sentence"" be formalized in PA?</p>
</blockquote>

<hr>

<h3>Motivation:</h3>

<p>This is mentioned in P. Odifreddi, ""<a href=""https://books.google.ca/books?id=xuvuAAAAMAAJ"">Kreiseliana: about and around George Kreisel</a>"", 1996, page 257. Feferman mentions that when Kreisel was trying to ""unwind"" the non-constructive proof of Littlewood's theorem, he needed to deal with RH. Littlewood's proof considers two cases: there is a proof if RH is true and there is another one if RH is false. But it seems that in the end, Kreisel used a $\Pi_1$ sentence weaker than RH which was sufficient for his purpose.</p>

<h3>Why is this interesting?</h3>

<p>Here I will try to explain why this question was interesting from Kreisel's viewpoint only.</p>

<p>Kreisel was trying to extract an upperbound out of the non-constructive proof of Littlewood. His ""unwinding"" method works for theorems like Littlewood's theorem if they are proven in a suitable theory. The problem with this proof was that it was actually two proofs: </p>

<ol>
<li>If the RH is false then the theorem holds.</li>
<li>If the RH is true then the theorem holds.</li>
</ol>

<p>If I remember correctly, the first one already gives an upperbound. But the second one does not give an upperbound. Kreisel argues that the second part can be formalized in an arithmetic theory (similar to PA) and his method can extract a bound out of it assuming that the RH is provably equivalent to a $\Pi_1$ sentence. (Generally adding $\Pi_1$ sentences does not allow you to prove existence of more functions.) This is the part that he needs to replace the usual statement of the RH with a $\Pi_1$ statement. It seems that at the end, in place of proving that the RH is $\Pi_1$, he shows that a weaker $\Pi_1$ statement suffices to carry out the second part of the proof, i.e. he avoids the problem in this case.</p>

<p>A simple application of proving that the RH is equivalent to a $\Pi_1$ sentences in PA is the following: If we prove a theorem in PA+RH (even when the proof seems completely non-constructive), then we can extract an upperbound for the theorem out of the proof. Note that for this purpose, we don't need to know whether the RH is true or is false.</p>

<p>Note: 
Feferman's article mentioned above contains more details and reflections on ""Kreisel's Program"" of ""unwinding"" classical proofs to extract constructive bounds. My own interest was mainly out of curiosity. I read in Feferman's paper that Kreisel mentioned this problem and then avoided it, so I wanted to know if anyone has dealt with it.</p>
",logic
"<p>Consider sets of Vitali's type in models of $\mathsf{ZF}+\mathsf{GCH}$ where $V \neq L$.  Are there sets of Vitali's type in both $L$ and $V \backslash L$?  If so, is there any way one can distinguish the constructible sets of Vitali's type from the nonconstructible sets of Vitali's type?</p>

<p>By a <em>set of Vitali's type</em> it is meant a subset of $\mathbb{R}$ containing exactly one element of every equivalence class of the relation $x - y \in G$, where $G$ is some fixed countable subgroup of $( \mathbb{R} , + )$.</p>
",logic
"<p>$1-ab$ invertible $\implies$ $1-ba$ invertible has a slick power series ""proof"" as below, where Halmos asks for an explanation of why this tantalizing derivation succeeds. Do you know one?</p>

<hr>

<p><em>Geometric series.</em> In a not necessarily commutative ring with
unit (e.g., in the set of all $3 \times 3$ square matrices with real
entries), if $1 - ab$ is invertible, then $1 - ba$ is invertible. However
plausible this may seem, few people can see their way
to a proof immediately; the most revealing approach belongs
to a different and distant subject.</p>

<p>Every student knows that
$1 - x^2 = (1 + x) (1 - x),$
and some even know that
$1 - x^3 =(1+x +x^2) (1 - x).$
The generalization
$1 - x^{n+1} = (1 + x + \cdots + x^n) (1 - x)$
is not far away. Divide by $1 - x$ and let $n$ tend to infinity;
if $|x| &lt; 1$, then $x^{n+1}$ tends to $0$, and the conclusion is
that
$\frac{1}{1 - x} = 1 + x + x^2 + \cdots$.
This simple classical argument begins with easy algebra,
but the meat of the matter is analysis: numbers, absolute
values, inequalities, and convergence are needed not only
for the proof but even for the final equation to make
sense.</p>

<p>In the general ring theory question there are no numbers,
no absolute values, no inequalities, and no limits -
those concepts are totally inappropriate and cannot be
brought to bear. Nevertheless an impressive-sounding
classical phrase, ""the principle of permanence of functional
form"", comes to the rescue and yields an analytically
inspired proof in pure algebra. The idea is to pretend
that $\frac{1}{1 - ba}$ can be expanded in a geometric series (which
is utter nonsense), so that
$(1 - ba)^{-1} = 1 + ba + baba + bababa + \cdots$
It follows (it doesn't really, but it's fun to keep pretending) that
$(1 - ba)^{-1} = 1 + b (1 + ab + abab + ababab + \cdots) a.$
and, after one more application of the geometric series
pretense, this yields
$(1 -ba)^{-1} = 1 + b (1 - ab)^{-1} a.$</p>

<p>Now stop the pretense and verify that, despite its unlawful
derivation, the formula works. If, that is, $ c = (1 - ab)^{-1}$, 
so that $(1 - ab)c = c(1 - ab) = 1,$ then $1 + bca$ is the inverse
of $1 - ba.$ Once the statement is put this way, its
proof becomes a matter of (perfectly legal) mechanical
computation.</p>

<p>Why does it all this work? What goes on here? Why
does it seem that the formula for the sum of an infinite
geometric series is true even for an abstract ring in which
convergence is meaningless? What general truth does
the formula embody? I don't know the answer, but I
note that the formula is applicable in other situations
where it ought not to be, and I wonder whether it deserves
to be called one of the (computational) elements
of mathematics. -- P. R. Halmos [1]</p>

<p>[1] Halmos, P.R. Does mathematics have elements?<br>
Math. Intelligencer 3 (1980/81), no. 4, 147-153<br>
<a href=""http://dx.doi.org/10.1007/BF03022973"" rel=""nofollow"">http://dx.doi.org/10.1007/BF03022973</a></p>
",logic
"<p>Hi everyone,</p>

<p>This is a question I have been asking from long, but none of my colleagues could ever answer me:</p>

<p>It is a well-known fact that the axiom of choice (AC) allows one to prove the existence of some set with some property $P$, though we cannot <em>exhibit</em> such a set: for instance, one knows that there exists a well-ordering on $\mathbb{R}$, but cannot define any though.</p>

<p>In formal terms, this means the following: working is the ZFC system, one can find a (first-order) logical property $P(x)$ (with one free variable) such that
$$\vdash (\exists x) (P(x)),$$
yet there is no logical property $Q(x)$ such that
$$\vdash (\exists! x) (P(x) \wedge Q(x))$$</p>

<p>Apparently that is the very phenomenon why many people are dubious about the relevance of AC. Yet I have seen nowhere the statement (and even less the proof) that such a phenomenon would <em>not</em> occur in ZF...</p>

<p><strong>So, is it true that, whenever ZF proves the existence of a set having some property, it is also possible to define some non-ambiguous such set?</strong></p>

<p>Regards,</p>
",logic
"<p>Call a higher-order logic fully monadic if and only if all of its predicate constants (at any order) and higher-order variables (at any order) are monadic (and it has no function symbols). In /Solvable cases of the decision problem/, Ackermann proves that fully monadic second-order logic is decidable, and so complete. My question: has this result been, or can it be, extended to fully monadic logics of even higher order?</p>

<p>(My gut tells me it should be so extensible; failures of decidability stem, even in FOL, from having relational predicates, and so you'd expect so long as you keep away from them as you go up the hierarchy you'd be in the clear. But I'd like something more solid than my gut on this one.)</p>
",logic
"<p>Is every noncountable field of characteristic zero the ultraproduct (using a non principal ultrafilter over the set of prime numbers) of fields of positive characteristic? </p>
",logic
"<p>In Paul Cohen's 
 <em>Set Theory and the Continuum Hypothesis</em>
(Page 71) there is a lemma with the assumption that 
$\exists x\, P(x)$.
The ''proof'' there, uses the following argument:</p>

<blockquote>
  <p>Intuitively the lemma is obvious, since if $F$ is valid it holds for
  every set $S$ in which relations and constants corresponding to the
  formal language are defined and hence for the   subset
    $$\{x|\,x \in S \land P(x)\}.$$
  Thus $F_P$ is true in every model and hence is
  valid.</p>
</blockquote>

<p>Where </p>

<blockquote>
  <p>If $F$ is a formula, then $F_P$ denotes the formula obtained from $F$
  by adjoining to every variable $x$ the condition $P(x)$. That is in
  building $F_P$, each $\exists x\, B$   becomes
  $$\exists x\,[P(x) \land B]$$ 
  and each $\forall x\, B$ becomes<br>
  $$\forall x\,[P(x) \rightarrow B].$$
  We say $F_P$  is $F$ <em>relativized</em> to the condition
  $P(x)$.</p>
</blockquote>

<p>Obviously, I must be missing something.
But say that $F$ is the following statement 
  $$\exists x\, \lnot P(x)$$
and it holds in some model $M$.
That is $P(x)$ is true for some $x\in M$
and is false for some $x\in M$.
Now for the subset 
  $$B = \{x|\,x \in M \land P(x)\}$$
$F$ clearly fails and $F_P$ cannot be true.</p>

<p>What am I missing? Must $F$ be restricted to certain types of statements?</p>

<hr>

<p>Christian Remling and Noah S.
Explained that $F$ as defined above is not valid.</p>

<p>Still, I would like to get a better intuition of
the lemma mentioned in Paul Cohen's book.
So let's look at another example.</p>

<p>Assuming Peano axioms, say $F$ is
 $$\forall x \exists y\, x &lt; y $$
is it considered valid?</p>

<p>If $F$ is valid, then if $P(x)$ is some property like
  $$x &lt; 5$$
then $F_p$ becomes
  $$\forall x\, [x &lt; 5 \rightarrow \exists y\, (y &lt; 5 \land x &lt; y)].$$
Which is clearly invalid considering $x=4$.</p>

<p>If $F$ is <em>not</em> valid, can someone give
a ''non trivial'' example of a valid statement
that includes $\forall$?</p>
",logic
"<p>An important feature of the Cantor-Schroeder-Bernstein theorem is that it does not rely on the axiom of choice. However, its various proofs are non-constructive, as they depend on the law of excluded middle.</p>

<p>There are several well-known proof strategies. For example, there is a simple proof which uses Tarski's fixed point theorem.</p>

<p>My question pertains to the well known proof attributed to Julius Konig, and given here: <a href=""http://en.wikipedia.org/wiki/Cantor-Bernstein-Schroeder_theorem#Proof"">Proof by Konig</a>. 
What I have not been able to grasp is,  how this is not a constructive proof? Given functions $f$ and $g$, isn't it possible to actually arrive at the bijection by forming biinfinite sequences as given in the proof?</p>
",logic
"<p>By ""formal analogies"" between the metamathematics of $\mathsf{ZFC}$/set theory and $\mathsf{PA}$(=Peano Arithmetic)/first order arithmetic, I mean facts such as the following:</p>

<ul>
<li><p>We are considering a first-order theory ($\mathsf{ZFC}$ or $\mathsf{PA}$) motivated as a first-order approximation to a second-order theory (second-order $\mathsf{ZFC}^2$ or $\mathsf{PA}^2$) which is ""more or less"" categorical; because of this, some axioms (the separation and replacement axioms on the one hand, the induction axiom on the other) have to be stated as axiom schemes in the first-order theory.</p></li>
<li><p>There is an interesting hierarchy of formulæ, $\Sigma_n$ or $\Pi_n$, based on alternations of quantifiers (viz.: the arithmetic hierarchy vs. the Lévy hierarchy); at the lowest ($\Delta_0$) level of this hierarchy are formulæ with only ""bounded"" quantifiers.</p></li>
<li><p>There is a uniform truth predicate for any (concrete) given level of the hierarchy, which is built upon some kind of absoluteness of $\Delta_0$ formulæ.  As a related fact, the infinite axiom schemes are naturally stratified along the hierarchy (they can be cut off at the $\Sigma_n$ level and stated as a single formula for each concrete $n$).</p></li>
<li><p>There is a reflection theorem which ensures that any finite set of true statements (or one bounded in the hierarchy of formulæ) is consistent.  In particular, the full theory proves the consistency of the subtheory with the axiom schemes cut off at the $\Sigma_n$ level: that is, the theory ($\mathsf{ZFC}$ or $\mathsf{PA}$) is reflexive.  In fact, it is even <em>essentially</em> reflexive (every consistent extension is reflexive).</p></li>
<li><p>There is a conservative two-kinded extension (Gödel-Bernays on the set theoretical side, $\mathsf{ACA}_0$ on the arithmetical side) which is obtained by allowing formation of classes but only with a comprehension scheme for such classes that does not involve quantifying over classes; remarkably, this conservative two-kinded extension is finitely axiomatizable.  There is also a standard strictly stronger two-kinded extension (Morse-Kelley on the set-theoretical side, second-order arithmetic $\mathsf{Z}_2$ seen as a first-order theory on the arithmetical side).</p></li>
</ul>

<p>(I hope I didn't mess things up too much, but all of these facts are standard and can be found in standard textbooks such as Jech's <em>Set Theory</em> for the set-theoretical side and Hájek and Pudlák's <em>Metamathematics of First-Order Arithmetic</em> plus Simpson's <em>Subsystems of Second-Order Arithmetic</em> for the arithmetical side.)</p>

<p>I'm sure many more examples can be found.  Maybe I should also nod to the similarity between proof theory of extensions of $\mathsf{PA}$ by analysing ordinal notations made by collapsing recursively large ordinals, and large cardinal extensions of $\mathsf{ZFC}$ — or maybe not.</p>

<p>Yet as striking as this analogy seems, nobody seems to comment upon it as far as I know.  (At the very least, this seems pedagogically regrettable: I'm sure all of the above statements would be more memorable to students if the analogous statements were made explicit.)</p>

<p>So: is there some deeper truth to be found behind this parallelism?  (Or are all my sample facts just aspects of a single phenomenon?  Or is this just a red herring?)  Might it make sense to bring $\mathsf{ZFC}$ and $\mathsf{PA}$ under an umbrella metatheory so that the above facts can be proved in a common formalism?  At the very least, is there a textbook I missed where the analogy is played out in some detail?</p>

<p>And perhaps more thought provokingly: can one give an example of a completely different kind of theory that is just as similar to $\mathsf{ZFC}$ and $\mathsf{PA}$ as they are to each other?</p>

<p>(I'm of course aware that are also huge differences between $\mathsf{ZFC}$ and $\mathsf{PA}$; but I would tend to say that they make the similarities all the more striking.)</p>
",logic
"<p>In §1.12 of the <a href=""http://homotopytypetheory.org/book/"">Homotopy type theory book</a>, it is mentioned that indiscernibility of identicals is a consequence of path induction. More precisely, for each type $C$ dependent over a type $A$, there is a term
$$\mathsf{transport} : \prod_{a_0, a_1 : A} \prod_{p : a_0 =_A a_1} C (a_0) \to C (a_1)$$
such that $\mathsf{transport} (a, a, \mathsf{refl}) \equiv \mathsf{id}_{C (a)}$, which is manifestly an instance of the general path induction principle, which constructs for each type $B$ dependent over $\sum_{a_0, a_1 : A} a_0 =_A a_1$ and each $s : \prod_{a : A} B (a, a, \mathsf{refl})$ a term
$$\mathsf{ind}(s) : \prod_{a_0, a_1 : A} \prod_{p : a_0 =_A a_1} B (a_0, a_1, p)$$
such that $\mathsf{ind}(s, a, a, \mathsf{refl}) \equiv s (a)$.</p>

<p><strong>Question.</strong> Is path induction strictly stronger than indiscernibility of identicals? (Or, does there exist a model of intensional type theory where the propositional equality satisfies indiscernibility of identicals but not path induction?)</p>

<p>I ask because the built-in <code>eq</code> type in Coq is defined as an inductive type whose induction principle is indiscernibility of identicals, rather than path induction. Coq is sufficiently rich to allow the path induction principle as well; however, it doesn't seem to be derived from the indiscernibility of identicals but rather by using pattern matching directly.</p>
",logic
"<p>I work at a four-year teaching school, where we pride ourselves on teaching pure math, proof, and a rather obsessive carefulness of work.  Recently I have been criticized for saying that ""Let $x \in A$"" is often a good way to begin a proof of a statement about all elements of $A$.  The criticism is based on the objection that $A$ could be empty, in which case there is no $x$ to be in $A$.  The issue affects quite a lot of mathematical content, because more than half of our proofs are proofs of universal statements, and most of them begin this way. </p>

<p>I have objected that if $A$ is empty, then any universal statement $\forall x \in A ...$ is vacuously true, but people are telling me that this needs to be dealt with as a special case, or else the proof is technically incorrect, etc. </p>

<p>I have appealed to normal mathematical conventions, without success.  Our department prides itself on being more careful than normal working mathematicians.  Convention can do what it will, but we intend to be right! </p>

<p>I have appealed to serious logic, by talking about the underlying meaning of ""Let $x \in A$.""  In my reading it plays a dual role of symbol introduction (""Use $x$ to represent a single thing"") and assumption (""Assume $x \in A$"").  But these arguments have no traction -- ""our students can't be expected to understand clever subtleties of metalogic.""</p>

<p>I fear the only option remaining is to appeal to authority -- some specific authority who says this act of ""Let $x \in A$"" has some sort of seal of approval.  Maybe such an authority is here?</p>

<p>From this question you might thing I work with fools, but they're really very wonderful and intelligent people, and the sense of family here is unusually strong.  Like family, they drive me out of my head sometimes.  Probably it's mutual.</p>

<p>So I suppose I have two questions:  1.  Am I right?   2.  Is there any hope for me to persuade my colleagues that I'm right?  </p>

<p>(3.  But social advice would be welcome too.)</p>

<p>Thank you,</p>

<p>Anonymous Coward</p>
",logic
"<p>Background/motivation: I'm investigating the construction of models for a first-order modal system (S5) as products of classical models. Since ultraproducts are all classical models and I need non-classical ones as well, I need to look at reduced products where the filter is not an ultrafilter. This leads me to ask about filters in general:</p>

<p>J.L. Bell &amp; A.B. Slomson, in <em>Models and Ultraproducts</em> (p. 116), state and prove:</p>

<blockquote>
  <p>Lemma 1.17. Let I be a countable set.
  Then the collections of non-principal,
  $\omega$-incomplete, uniform, and
  regular ultrafilters on I all
  coincide.</p>
</blockquote>

<p>Suppose I alter their definitions slightly so the above properties are all defined for filters in general, then modify the lemma to assert that it holds for filters in general. Would that be true? Can anyone supply a reference to a proof or disproof? Thanks.</p>
",logic
"<p>It is said that the kernel of a isogeny is finite because it is discrete and complex tori are compact.</p>

<p>I have some questions about this.</p>

<p>1.</p>

<p>Following is my reason for the kernel is discrete.</p>

<p>Suppose
$$
\varphi:\mathbb{C}/\Lambda\rightarrow\mathbb{C}/\Lambda'
$$</p>

<p>is an isogeny. Then there exists $m\in \mathbb{C}$ such that $m\Lambda=\Lambda'$. So the kernel of $\varphi$ is $\left(\frac{1}{m}\Lambda'\right)/\Lambda$. Intuitively, it is discrete, I think. But I don't know how to reason it. </p>

<p>There is a hint in the book I'm reading saying that if the kernel is not discrete, complex analysis shows that the map is zero.</p>

<p>Can anyone tell me why?</p>

<p>2.</p>

<p>Why can we deduce finiteness from discreteness and compactness?</p>
",number_theory
"<p>Ok,this problem might appear a bit trivial but I have some doubts..If it's not a burden take a look and comment!</p>

<p>Let $F$ be a finite field of characteristic equal to $p$ and $ƒ(x)=x^p-α$ $∊F[x]$.Show that $ƒ(x)$ either has one root of multiplicity equal to $p$ or that $ƒ(x)$ is irreducible over $F$.</p>

<p>My answer:</p>

<p>Let $x₁$ and $x₂$ be two different roots of $ƒ(x)$.
Then it follows: $x₁^p-α=x₂^p-α=0$ ⇒$x₁^p-x₂^p=0$ 
But since the characteristic of the field is $p$,it derives from Euler's theorem that in general: $(b-c)^p=b^p-c^p$ for any $b,c∊F$</p>

<p>Thus:$(x₁-x₂)^p=0⇒x₁=x₂$.
So $ƒ(x)$ can have no distinct roots.
If $α$ is a root,then indeed $(x-α)^p=0$ and $α$ is a root of multiplicity equal to $p$.
Since no other factorization of $ƒ(x)$ exists-that is one that does not include the $(x-α)$ factor,it follows that if $α$ is not a root,then $ƒ(x)$ is irreducible.</p>
",number_theory
"<p>I have 2 numerical series like this:</p>

<p>$$
144 + 25 + 27 + 29 + 31 + \cdots
$$</p>

<p>$$
133 + 3 + 5 + 7 +9 +11+13+\cdots
$$</p>

<p>Is there a efficient way to find the common sum of these patterns?</p>

<p>solution for this case:
$$
144 + 25 + 27 = 133 +3+5+\cdots+15$$</p>
",number_theory
"<p>I am <a href=""https://github.com/gazman-sdk/quadratic-sieve"" rel=""nofollow"">developing</a> the <a href=""https://en.wikipedia.org/wiki/Quadratic_sieve"" rel=""nofollow"">quadratic sieve</a> algorithm and I reached a new bottle neck: The matrix processing.</p>

<p>I been reading quit a lot about this topic and I found many solutions</p>

<ul>
<li><a href=""https://en.wikipedia.org/wiki/Gaussian_elimination"" rel=""nofollow"">Gaussian elimination</a>: This perhaps the most common approach for this problem. It's running time is $O(N^3)$ above GF (2)</li>
<li><a href=""https://en.wikipedia.org/wiki/Method_of_Four_Russians"" rel=""nofollow"">Method of Four Russians</a>: It optimize the classic <strong>Gaussian elimination</strong> to $O(\frac{N^3}{\log{N}})$ by partition the matrix into small square blocks of size $\log N$. You can read more about it <a href=""https://martinralbrecht.files.wordpress.com/2011/11/ple.pdf"" rel=""nofollow"">here</a>(section 3.2). </li>
<li><a href=""https://en.wikipedia.org/wiki/Block_Wiedemann_algorithm"" rel=""nofollow"">Block Wiedemann algorithm</a> is used to parallelize the matrix of several machines in order to speed up the process. Here is a good example of such <a href=""https://www.cs.umd.edu/~gasarch/TOPICS/factoring/fastgauss.pdf"" rel=""nofollow"">implementation over GAPP</a>, they use a little bit different algorithm for that.</li>
</ul>

<p>But non of the above was good enough for me, so I created my own <a href=""https://github.com/gazman-sdk/quadratic-sieve/blob/master/src/com/gazman/factor/matrix/HashMatrix.java"" rel=""nofollow"">algorithm</a>.</p>

<p>It's based on <strong>Gaussian elimination</strong>, but instead of searching for pivot in each column I represent the columns with <a href=""https://en.wikipedia.org/wiki/Hash_table"" rel=""nofollow"">hash table</a> and <a href=""https://en.wikipedia.org/wiki/Linked_list"" rel=""nofollow"">linked list</a>(This is how HashMap in java is implemented) where each node of the list is stored in <strong>hash table</strong> and contain the pivot index of the original matrix. So I can iterate over all the pivots of column. </p>

<p>When I start to perform <strong>Gaussian elimination</strong> it only takes $O(1)$ to find the first pivot of a column, once I find such pivot I store it in another <strong>hash  table</strong>, so I want pick it for the next column I will operate. Next I iterate over the reset of the pivot of the first column and xor the rows to eliminate all the reset of the pivot of the first column. I do the same trick with the rows, so I got duplicate representation of the matrix, by hash-table rows and columns. This allows me to speed up the row xoring process as I only iterate over the row pivot. The xor operation itself of each node is $O(1)$ but it evolves 2 hash operations and it's by it self quite expensive. And so this is the part where this algorithm fails. Even so that I estimate it's performance as sub-quadratic on average. </p>

<p>I ended up <a href=""https://github.com/gazman-sdk/quadratic-sieve/blob/master/src/com/gazman/factor/matrix/BitMatrix.java"" rel=""nofollow"">implementing</a> classic <strong>Gaussian elimination</strong> using bit operators and it allows me to process square matrices with up to $10,000$ lines in minutes time. But it's not fast enough for me, my goal is factoring 100 digits number, this require around 1M square matrix size, and this impossible with my current approach. </p>

<p>Is there any other methods that I missed? What is the best non parallel method to solve this problem?</p>
",number_theory
"<p>Let $M$ be a finitely generated $\mathbb Z_ \ell$-module, where $\ell$ is a prime number and $\mathbb Z_\ell$ is the ring of $\ell$-adic integers. Let $T$ be its torsion submodule. Is $T$ finite?</p>

<p>In other words, let $f$ be a non-zero element of $\mathbb Z_ \ell$. Is the quotient module $\mathbb Z_ \ell/ (f)$ finite?</p>

<p>My guess is that we can assume $f= \ell^n$ for some non-negative $n$ (as units don't change the quotient). Then the quotient module $\mathbb Z_ \ell/ (f)$ should just be $\mathbb Z/(\ell^n)$. Is that correct? What triviality am I missing?</p>
",number_theory
"<p>Problem: Find all $n\in \mathbb{N}$ such that $f(x)=x^n+4$ is reducible in $\mathbb{Z}[x]$.</p>

<p>It seems $n=4k$ is the only one (the factorization follows easily from Sophie Germain's identity in this case), but I can't prove it. I can prove, however, that if $f(x)=g(x)h(x)$ for non-constant integer polynomials $g(x),h(x)$, then their constant terms, say $a_0,b_0$, must satisfy $a_0=b_0=\pm 2$.</p>

<p>EDIT: I am still looking for an elementary solution which only uses olympiad tools. It will be viewed in higher regard than one which uses linear/abstract algebra. Thanks!</p>
",number_theory
"<p>What is an efficient algorithm to find the first number $n$ such that $n^2 \equiv -1 \mod p$ for a prime $p$, if such an $n$ exists?</p>

<p>Is there anything better than the brute-force approach up to $p-1 \over 2$?</p>

<p>I know this is simple to find for primes of the form $n^2+1$ because $n^2 \equiv -1 \mod (n^2+1)$, resulting in $n$, but is there a fast way for a generic case $n$?</p>

<p>Ex:</p>

<ul>
<li>$p = 29, n = \pm 12$ </li>
<li>$p = 37, n = \pm 6$ </li>
<li>$p = 41, n = \pm 9$</li>
<li>$p = 53,
   n = \pm 23$</li>
</ul>
",number_theory
"<p>I don't know whether the books metioned in <a href=""http://math.stackexchange.com/questions/329/best-ever-book-on-number-theory"">Best ever book on Number Theory</a> are beyond undergraduate/high-school-olympiad level.</p>

<p>Please recommend your favourite.</p>
",number_theory
"<blockquote>
  <p>Let $e(x)$ be the number of $1$'s in the ternary representation of $x$. Let $A(n)$ be the number of integers $x$ with $0 \leq x \leq 3^n$ such that $3 \mid e(x)$. Prove that $A(n)$ can be expressed in the form $$A(n) = \sum_{\mu \geq 0} c_n^{3 \mu} 2^{n-3\mu}.$$</p>
</blockquote>

<p>I thought that $A(n) = 2^n+\binom{n}{3}2^{n-3}+\cdots$ by a counting argument. Where does the $c_n^{3 \mu}$ come from?</p>
",number_theory
"<p>How can I prove that $ 10200300040000100004000300201$ is not a perfect square ? This number is divisible with $3$ only one time. Is it a good reason and it is enough ? </p>

<p>thanks :)</p>
",number_theory
"<p>Whether a Prime number greater than can be written as sum of a Prime number and $2^n$?</p>

<p>$P_2 = P_1 +  2^N$</p>

<p>Some Examples of this
<Br/>
$3=2+2^0$<br/><br/>
$5=3+2^1$<br/>
<Br/>$1021=509+2^9$</p>
",number_theory
"<p>I just read this paragraph: (written by G. H. Hardy, on Ramanujan)</p>

<blockquote>
  <p>I remember once going to see him when he was lying ill at Putney. I
  had ridden in taxi cab number 1729 and remarked that the number seemed
  to me rather a dull one, and that I hoped it was not an unfavorable
  omen. ‘No,’ he replied, ‘it is a very interesting number; it is the
  smallest number expressible as the sum of two cubes in two different
  ways.’</p>
</blockquote>

<p><em>Was Ramanujan right?</em></p>

<p><em>What are other numbers having such property (expressible as the sum of two cubes in two different ways)?</em></p>

<p><em>Are there infinite number of them?</em></p>

<p>And, on the other hand:</p>

<p><em>What if the word ""cubes"" is replaced by ""5-degree power""? Would such numbers exist? If yes, what would be the smallest?</em></p>

<hr>

<p>Another SO question related to 1729: <a href=""http://math.stackexchange.com/questions/487537/proof-that-1729-is-the-smallest-taxicab-number"">Proof that 1729 is the smallest taxicab number</a></p>
",number_theory
"<p>Prove that a natural number with at least 2 digits cannot be written like a sum with the the power of digits equal $2$. </p>

<p>What I want to say: $$\overline{ab}\neq a^2+b^2.$$</p>

<p>What I have done: </p>

<p>$$10a+b=a^2+b^2 $$ or 
$$a(a-10)=b(1-b).$$
$b(1-b)=2k$ so $a(a-10)=2k$ and this is possible only when $a=2q.$ </p>

<p>so: $2 \cdot 8 =b(b-1)$ or $4\cdot 6=b(b-1)$ and this is not possible. 
final conclusion for the number $\overline{ab}$ is ok, but what can I do for number formatted with $3,4, \ldots$ digits ? </p>

<p>thanks :) </p>
",number_theory
"<p>Bertrand's postulate states that for any integer $n&gt;3$, there's always a prime $p$ between $n$ and $2n-2$.
That result sets a reasonable 'lower bound' on how often we can expect primes to show up, and there are even better estimates (such as the Prime Number Theorem, although that one is an asymptote, and doesn't prove any result for a specific $n$).</p>

<p>However, the proofs of the results above aren't obvious; I'm looking for elementary claims, ones that follow straight from the definition of a prime number (and perhaps some algebraic manipulation).</p>

<p>For example, the following can be deduced using Euclid's method for the infinitude of primes:</p>

<p><strong>Claim:</strong> Let $M_n$ Denote the product of all primes smaller than or equal to $n$. Then, if $n \geq 2$, there's at least one prime $p$ such that $n&lt;p\leq M_n+1$.</p>

<p><strong>Proof:</strong> If $M_n+1$ is prime, we're done.</p>

<p>Otherwise, $M_n+1$ is divisible by a smaller prime $p$. Then $p$ can't divide $M_n$. but $M_n$ is divisible by all numbers smaller than or equal to $n$, so we get $n&lt;p&lt;M_n+1$, just as we wanted. $\square$</p>

<p>In particular, this shows that there's always a prime number between $n$ and $n!$.</p>

<p>Now, how can we lower this bound? Is there any elementary proof for how there's always a prime between $n$ and $n^2$? What about, say,  $n$ and $1000^n$?</p>
",number_theory
"<p>I was given that $\sum_{p\le x} \frac{1}{p}$ = $\log\log x$+O(1). </p>

<p>I need to show that $\sum_{pq\le x} \frac{1}{pq} = (\log \log x)^2 + O(\log \log x)$.</p>

<p>Here we go:</p>

<p>Break the sum into two sums: $\sum_{p\le x} \frac{1}{p}\sum_{q\le \frac{x}{p}} \frac{1}{q}$</p>

<p>Using what I was given: $(\log \log x +O(1))(\log \log \frac{x}{p} +O(1))$</p>

<p>Log Rules: $(\log \log x +O(1))(\log( \log x - \log p) +O(1))$</p>

<p>Algebra: $\log \log x \cdot \log(\log x - \log p) + O(\log \log x)$ </p>

<p>From here I am lost. Any ideas?</p>
",number_theory
"<p>I know there exist (even) residues that do not appear in the sequence <a href=""http://oeis.org/A005277"" rel=""nofollow"">(A005277)</a>, but of those that do, do any appear only once?</p>
",number_theory
"<p>Show that $\displaystyle\sum_{d|n}\mu(d)\phi(d)=0$ using only Dirichlet Convolution propertys (without multiplicative function concepts).</p>

<p>I suspect you have to use that  $1\ast \mu=I$ and $f\ast 1=id$ where $1(n)=1$, $id(n)=n$ for all $n$ and $I$ is the unity in the set of arithmetic function.
but not how to use this.</p>

<p>Note: $\phi$ and $\mu$ are Euler and Mobiüs function respectly.</p>
",number_theory
"<p>Let $K$ be a non-archimedean field of characteristic zero and $||.||:K\to \mathbb{R}_{\geq 0}$ be its absolute value.</p>

<p>Define the Washnitzer Algebra as: $$W_n=\{\sum_{u\in \mathbb{Z}_{\geq 0}^n} \in K[[X]]: \text{ there exists some } \rho&gt;1 \text{ such that } ||a_u||\rho^{|u|}\to 0 \text{ as } |u|\to \infty\}$$ where $|u|=u_1+u_2+\ldots+u_n$ for $u=(u_1,\ldots,u_n)$ and $\rho\in\mathbb{R}$.</p>

<p>Now, set $n=1$, so $$W_1=\{\sum_{n\in\mathbb{Z_{\geq 0}}}\in K[[X]]: \text{ there exists some } \rho&gt;1 \text{ such that } ||a_n||\rho^{n}\to 0 \text{ as } n\to \infty\} $$</p>

<p>The question is the derivation map on $W_1$ defined as $$\partial: W_1\to W_1, \qquad \sum_{n\in\mathbb{Z_{\geq 0}}} a_n X^n \to \sum_{n\in\mathbb{Z_{&gt; 0}}} na_nX^{n-1}$$ is a surjection or not?</p>

<p>Essentially, one needs to show that if $\sum_{n\in\mathbb{Z_{\geq 0}}}a_nX^n$ is in $W_1$ then we also have $\sum_{n\in\mathbb{Z_{&gt; 0}}} \frac{a_{n-1}}{n}X^n $ (which is the formal integration of the initial series) is also in $W_1$.</p>

<p>More spesifically, if there exists some $\rho&gt;1$ such that $$\lim_{n\to\infty} ||a_n|| \rho^n=0$$ then is there a $\rho_1$ such that  $$\lim_{n\to\infty} ||{\frac{a_{n-1}}{n}}||{\rho_1}^n=0$$ ??</p>
",number_theory
"<p>I'm a little stuck with the proof of a theorem I'm trying to understand. The theorem is as follows:</p>

<p>""For odd prime $p$, suppose for $\alpha \in Q_{p}$ (the p-adic rationals) that $|\alpha|_p=1$. Then $\exists\beta\in Q_p$ such that $\alpha=\beta^2\iff \exists\gamma\in Z/pZ$ such that $|\alpha-\gamma^2|_p&lt;1$.""</p>

<p>The proof is:</p>

<p>Suppose $\exists\gamma\in Q_p$ such that $|\alpha -\gamma^2|_p&lt;1$, (i.e. $\beta^2\equiv\alpha(modp)$ is soluble).
Now we construct a sequence $(\beta_n)$ by letting $\beta_1=\gamma$ and defining $\beta_n$ to satisfy:</p>

<p>$|\beta_n^2-\alpha|_p&lt;\frac{1}{p^n}$ and $|\beta_{n+1}-\beta_n|&lt;\frac{1}{p^n}$</p>

<p>If we take $\beta_n$ as given, then we take $\beta_{n+1}=\beta_n+\delta_n$, so that $\beta_{n+1}^2=\beta_n^2+2\beta_n\delta_n+\delta_n^2$, and it is sufficient to take $\delta_n=\frac{\alpha-\beta_n^2}{2\beta_n}$.</p>

<p>Conversely, the necessity is obvious if we choose $\gamma=\beta^2$. $\square$</p>

<p>I feel that I'm missing something which is stopping me from understand this. $|\beta_{n+1}-\beta_n|_p&lt;\frac{1}{p^n}\implies p^n$ divides $(\beta_{n+1} - \beta_n)$, and if $\beta_{n+1}=\beta_n+\delta_n$ then this must mean $\delta_n$ is divisible by $p^n$.</p>

<p>If we take $\delta_n$ as $\delta_n=\frac{\alpha-\beta_n^2}{2\beta_n}$, then this gives us $\beta_{n+1}^2=\alpha+\delta_n^2 \implies \beta_{n+1}^2-\alpha=\delta_n^2$. Then we have shown that $\beta_{n+1}-\alpha$ is divisible by $p^{n+1}$, i.e. that $|\beta_{n+1}^2-\alpha|_p&lt;\frac{1}{p^{n+1}}$.</p>

<p>Was this the aim of the proof? An inductive argument on the terms of $(\beta_n)$? If not what is it that I have misunderstood in this theorem? Many thanks in advance for any replies, I would love to understand this.</p>
",number_theory
"<p>Let $k$ be the completion of an algebraic number field at a prime divisor $\mathfrak{p}$. We note that $k$ is locally compact. Let $k^{+}$ be the additive group of $k$ which is a locally compact commutative group.</p>

<p>Tate's Thesis Lemma 2.2.1 states that</p>

<blockquote>
  <p>If $\xi \rightarrow \chi(\xi)$ is one non-trivial character of $k^{+}$, then for each $\eta \in k^{+}$, $\xi \rightarrow \chi(\eta\xi)$ is also a character. The correspondence $\eta \leftrightarrow \chi(\eta\xi)$ is an isomorphism, both topological and algebraic, between $k^{+}$ and its character group.</p>
</blockquote>

<p>The proof of this lemma is divided up into 6 steps, one step is to show that the characters $\chi(\eta\xi)$ are everywhere dense in the character group. Tate writes</p>

<blockquote>
  <p>$\chi(\eta\xi) = 1$, all $\eta \implies k^{+}\xi \neq k^{+} \implies \xi = 0$. Therefore the characters of the form $\chi(\eta\xi)$ are everywhere dense in the character group.</p>
</blockquote>

<p>My question is: How does he get from showing that the $\xi = 0$ to the the result that the $\chi(\eta\xi)$ are everywhere dense?</p>
",number_theory
"<p>META: I wrote the explanation for this problem assuming a monospace font... it might be easier to read if you copy and paste it into a text file and view it separately.
Or, if you know how, feel free to edit it to have a monospace font with automatic line breaks because I don't know how.</p>

<p>Let 4 variables $a,b,c,d$ be rationals in $[0,1]$ which, when multiplied by $255$, become integers. (That is, $a,b,c,d\in \{\frac{x}{255}\mid 0\leq x\leq 255,\ x\in\mathbb{Z}\}$.  Examples of valid values are $1/255$, $2/255$, $3/255$, etc.</p>

<p>The variables are related in one equation. I want to prove that there are no solutions to this equation, by which I mean there are no valid values for the 4 variables that will satisfy the equation.
$$\frac{ac + (1-a)bd}{a+(1-a)b} = \frac{1}{2}$$</p>

<p>Now I'm going to redefine $a,b,c,d$ to be non-negative integers in the domain $[0,255]$. The equation will still hold if I add the denominator $255$ to the variables.
$$\begin{align*}
\frac{\frac{a}{255}\;\frac{c}{255} + \left(1-\frac{a}{255}\right)\frac{b}{255}\;\frac{d}{255}}{\frac{a}{255} + \left(1 - \frac{a}{255}\right)\frac{b}{255}} &amp;= \frac{1}{2}\\
\frac{\frac{ac}{255^2} + \frac{(255-a)bd}{255^3}}{\frac{a}{255}+\frac{(255-a)b}{255^2}} &amp;= \frac{1}{2}\\
\frac{\quad\frac{255ac + (255-a)bd}{255^3}\quad}{\frac{255a + (255-a)b}{255^2}}&amp;=\frac{1}{2}\\
\frac{255 ac + (255-a)bd}{255^3}\;\frac{255^2}{255a+(255-a)b} &amp;= \frac{1}{2}\\
\frac{255ac + (255-a)bd}{255(255a + (255-a)b)}&amp;=\frac{1}{2}\\
\frac{255 ac + (255-a)bd}{255^2a + 255(255-a)b}&amp;=\frac{1}{2}.
\end{align*}$$</p>

<p>$a,b,c,d$ are non-negative integers in the domain $[0,255]$.  Is it possible to prove that there are no solutions to this equation?</p>

<p>One way to determine this is to test all ($255^4=4228250625$) possible combinations, however I'm looking for a more compelling proof.</p>

<p>Both the numerator and denominator will each evaluate to a non-negative integer value. That being said, a part of the set of possible evaluated fractions will look like this:
$$\frac{1}{2}, \frac{2}{4}, \frac{3}{6},\frac{4}{8},\frac{5}{10},\frac{6}{12},\frac{7}{14},\frac{8}{16},\frac{9}{18},\frac{10}{20},\ldots$$</p>

<p>The denominator must evaluate to an even number.</p>

<p>Here are some of the rules of parity (even or odd) arithmetic:</p>

<p>Addition/subtraction:</p>

<pre><code>      Even Odd
     __________
Even |Even Odd
Odd  |Odd  Even
</code></pre>

<p>Multiplication:</p>

<pre><code>      Even Odd
     __________
Even |Even Even
Odd  |Even Odd
</code></pre>

<p>The denominator has only two variables $a$ and $b$ that I need to worry about. Let's consider the possible cases of parity and see which combinations result in an even number.</p>

<p>$$255^2a + 255(255-a)b$$
$$(\mathrm{Odd})a + (\mathrm{Odd})((\mathrm{Odd})-a)b$$</p>

<pre><code>$a$: Even; $b$: Even
(Odd)(Even) + (Odd)((Odd)-(Even))(Even)
(Even) + (Odd)(Odd)(Even)
(Even) + (Odd)(Even)
(Even) + (Even)
(Even)

a: Odd; b: Even
(Odd)(Odd) + (Odd)((Odd)-(Odd))(Even)
(Odd) + (Odd)(Even)(Even)
(Odd) + (Even)(Even)
(Odd) + (Even)
(Odd)

a: Even; b: Odd
(Odd)(Even) + (Odd)((Odd)-(Even))(Odd)
(Even) + (Odd)(Odd)(Odd)
(Even) + (Odd)(Odd)
(Even) + (Odd)
(Odd)

a: Odd; b: Odd
(Odd)(Odd) + (Odd)((Odd)-(Odd))(Odd)
(Odd) + (Odd)(Even)(Odd)
(Odd) + (Even)(Odd)
(Odd) + (Even)
(Odd)
</code></pre>

<p>Therefore, the denominator is only even when both $a$ and $b$ are even. Let's see the parity of the numerator with $a$ and $b$ both being even.</p>

<p>$$255ac + (255-a)bd$$</p>

<pre><code>(Odd)(Even)c + ((Odd)-(Even))(Even)d
(Even)c + (Odd)(Even)d
(Even)c + (Even)d
(Even) + (Even)
(Even)
</code></pre>

<p>Therefore, the numerator must be an even number as well, reducing the set of possible evaluated fractions to those with even numerators:
$$\frac{2}{4},\frac{4}{8},\frac{6}{12},\frac{8}{16},\frac{10}{20},\ldots$$</p>

<p>.. this is the furthest I could go with my insular analysis. Are there any other rules I could use to reduce the set of possible evaluated fractions down to 0?</p>
",number_theory
"<p>Prove that for any primitive Pythagorean triple (a, b, c), exactly one of a and b must be a multiple
of 3, and c cannot be a multiple of 3.</p>

<p><strong>My attempt:</strong></p>

<p>Let a and b be relatively prime positive integers.</p>

<p>If $a\equiv \pm1 \pmod{3}$ and $b\equiv \pm1 \pmod{3}$, </p>

<p>$c^2=a^2+b^2\equiv 1+1\equiv 2 \pmod{3}$</p>

<p>This is impossible as the only quadratic residues modulo 3 are 0 and 1.</p>

<p><em>So far, so good.</em></p>

<p>If one of a, b is $\equiv 0 \pmod{3}$ and the other is $\equiv \pm1 \pmod{3}$,</p>

<p>$c^2=a^2+b^2\equiv 0+1\equiv 1 \pmod{3}$</p>

<p><em>This is the part I don't understand. Just because $c^2\equiv 1\pmod{3}$ doesn't mean that $c^2$ must be a perfect square. For example, $a=12$ and $b=13$ satisfy the above conditions but $c^2=a^2+b^2=313$, which isn't a perfect square.</em></p>
",number_theory
"<p>I've been trying to figure this out and it's been getting on me myself.  I know that $3$ is not just a prime number, but also a triangular number.  I'll now add a sequence:</p>

<p>Prime numbers: $2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107$
Triangular numbers: $1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66, 78, 91, 105, 120, 136, 153, 171, 190, 210, 231, 253, 276, 300$</p>

<p>Anyway, let's cut to the chase.  Does this sequence help anything about which prime numbers are also triangular numbers?  Now I want to know from you, yeah, you.  How many prime numbers can also be triangular numbers?  I don't think it's probable.  If you have serious, stupendous answers, I would be glad to accept <em>one</em> of them.</p>
",number_theory
"<p>Given prime number $p\equiv 1 \pmod 4$. Prove  if $a∈F_p^×$ is a quadratic
residue then the congruence $$x^4 ≡ a \pmod p$$ has either no solutions or four solutions.
Give examples of each case.</p>
",number_theory
"<p>When is $f(k):=8k^2+8k+1$ a square for $k\in\mathbb Z_{\geq 0}$?</p>

<p>How do I begin on this? I see $f(k)$ is a square for $k=0,2$, but I do not know where to go from here.</p>
",number_theory
"<p>I'm writing a primality testing program and want to test numbers like $3^{3^{3^{100}}} + 4
\mod 7$.</p>

<p>I use Euler's theorem to do this, so that the exponents get smaller. Instead of calculating $a^{b^c} \mod n$, I calculate $a^{b^{c \mod n_2}\mod n_1} \mod n$, where $n_1 = \phi(n)$ and $n_2 = \phi(\phi(n))$. This works sometimes, however, sometimes the exponent and the modulo is not relativly prime and Euler's theorem can not be used. Like in the above example with $3^{3^{3^{100}}} + 4
\mod 7$, it works in the first step, but not in the second, because $\gcd(3,6)\neq 1$.</p>

<p>One mathematician told me many years ago that it doesnt matter, because if you calculate $a^{(b \mod n_1)+n_1} \mod n$, it will still equal $a^b \mod n$. Even in the cases where $\gcd(a, n)\neq 1 $. I have tested this and it seems to work.</p>

<p>My questions are:
Under what circumstances does this work? Are there any exceptions, like $a = 0$ or $1$ or anything?</p>

<p>What theorems does this trick rely upon? What is the formal proof that it works? I don't want to use math that I dont understand in my program and I dont really understand why this works.</p>

<p>The main idea is that the number that should be tested is large, and the modulo is small. However, if anybody could give any hints of how to do it when the modulo is large, like ($2^{300}+1$) it would also be appreciated. It might be good for further, more advanced testing. It is enough to know that $a^b \mod n = c $ with a certain probability, if $n$ is large. I feel that this should be possible to do in some way, but I don't know how.</p>

<p>Thanks for any help.</p>

<p>Note that I am looking for mathematical tricks, not programming, so please don't ask me to use Java's BigInteger package or anything like that.</p>

<p>Note 2: Before anybody complains that I am writing mod wrong. I am referring to the binary operation modulo, not modular congruence.</p>

<p><a href=""http://en.wikipedia.org/wiki/Modulo_operation"" rel=""nofollow"">http://en.wikipedia.org/wiki/Modulo_operation</a></p>

<p>They basically work the same, but the notation is a bit different.</p>
",number_theory
"<p>$$\varphi(n)=\sum_{d\mid n}d\cdot \mu\left(\frac{n}{d}\right)=n\sum_{d\mid n}\frac{\mu(d)}{d}$$</p>

<p>This describes the totient function in terms of the Möbius function. I understand what the Möbius function does but I don't understand this derivation at all. Is there an easy way to understand why this is so?</p>

<p>I'm not looking for some lengthy mathematical proof, but rather an intuitive understanding. I've seen plenty of papers showing the proof, but I just don't get what's happening.</p>
",number_theory
"<blockquote>
  <p>If $a$ and $b$ are positive integer then what is length of digits of $a^b$?</p>
</blockquote>

<p>I have worked so far and formula works fine.</p>

<p>To find the exact length of digits of $a^b$ where $a\gt 0, b\gt 0$:</p>

<p>Number of Digits are = $\lfloor 1+b\ log(a) \rfloor$</p>

<p>Either it is true of any positive integers $a$ and $b$ or it's accuracy is limited?</p>

<p>Tell me if is there any other method to find the number of digits of $a^b$?</p>
",number_theory
"<p>I came across this question while looking at powers of 2 and investigating number theory. I found it quite interesting, unfortunately I would say that my skills in number theory are far too primitive to solve this. My question is, is this true?
$$i \in \mathbb{N} \land \exists j \in \mathbb{N}, 2j = i \implies \exists x \in \mathbb{N}, 3x + 1 = 2^i$$</p>

<blockquote>
  <p>$\frac{2^i - 1}{3}$ is an integer only when $i$ is even</p>
</blockquote>

<p>I think it has something to due with the fact that $2^1 = 2$ is 1 away from $3$ and $2^2 = 4$ is $1$ away from 3 but in the other direction. I know this has to do with modular arithmetic (or at least I'm guessing) and the fact that I guess when you subtract $2^i$ by $1$ and $i$ is even, then you bring it down one mod cycle to become divisible by $3$, and then multiplying $2^i$ by $4$ doesn't affect the mod cycle of $2^i - 1$ against $3$ (i.e. its divisibility by $3$)</p>
",number_theory
"<p>Let $f: \mathbb{N}\rightarrow \mathbb{R}$ be a function potentially taking negative values. Suppose I knew that $$cN \leq \left|\sum_{n= 1}^{N}f(n)\right|$$ for some absolute constant $c$. Then by the Pigeonhole Principle, there is at least one integer $n_0 \in [1, N]$ such that $|f(n_0)| \geq c/2$. Can I say more? Do I know that a positive proportion of the integers $n \in [1, N]$ satisfy $|f(n)|\geq c/2$?</p>
",number_theory
"<p>In the extant books of Diophantus, are considered in the system of equations.  Of interest is the non-linear system of Diophantine equations.  Some simple systems from his book manages to solve it.</p>

<p>For example, from 3 books tasks 10, 11. 4 books   task 19. The solution presented in this.  <a href=""http://www.artofproblemsolving.com/community/c3046h1057324_the_system_is_almost_linear_diophantine_equations"" rel=""nofollow"">http://www.artofproblemsolving.com/community/c3046h1057324_the_system_is_almost_linear_diophantine_equations</a></p>

<p>But here's an example of a decision like almost linear system of 3 task book 6.  Gives another view of the representation of solutions.  <a href=""http://www.artofproblemsolving.com/community/c3046h1055253_the_system_of_equations_15"" rel=""nofollow"">http://www.artofproblemsolving.com/community/c3046h1055253_the_system_of_equations_15</a></p>

<p>But there is in the books such a group of tasks which are of the same type. The conditions are very similar.  It is conceivable that they can be solved one way.</p>

<p>For example with 2 books tasks 20, 21.  This system was considered Sierpinski. He found a private decision. And in the book of Diophantus referred to the decision according to his formulas don't work.  It turned out that the formulas of the solutions may be several.
<a href=""http://www.artofproblemsolving.com/community/c3046h1046718__4"" rel=""nofollow"">http://www.artofproblemsolving.com/community/c3046h1046718__4</a></p>

<p>Now interested in the question itself.</p>

<p>In the 2nd book is very much the same type of systems that can be described as follows. I wrote to look for solutions in integers.</p>

<p>$$\left\{\begin{aligned}&amp;X^2\pm{(X+Y)q}=Z^2\\&amp;Y^2\pm{(X+Y)q}=R^2\end{aligned}\right.$$</p>

<p>$$\left\{\begin{aligned}&amp;XY+(X+Y)q=Z^2\\&amp;XY-(X+Y)q=R^2\end{aligned}\right.$$</p>

<p>$$\left\{\begin{aligned}&amp;(X+Y)^2\pm{Xq}=Z^2\\&amp;(X+Y)^2\pm{Yq}=R^2\end{aligned}\right.$$</p>

<p>The system is very similar and right of common and more simple approach to their solution.  Because then there are systems with a large number of equations.</p>
",number_theory
"<p>We are interested in the following statement: </p>

<p>For each $n&gt;1$ and $x&gt;2$ there is at least one prime $p$ satisfying $x&lt;p&lt;n x$.</p>

<p>For $n=2$ we get precisely the Bertrand's postulate which is true. As corollaries, the statements for arbitrary $n\geqslant 2$ are true. However, I am interested maybe there exist independent proofs (prossibly short and elementary) for some of the cases $n&gt;2$.</p>

<p>Thanks for your help.  </p>
",number_theory
"<p>Is there a prime number $p$ that $p &gt; 2$, and in which $p$ is a never a factor of any Carmichael number $C_n$:</p>

<p>(p ∤ $C_n$)</p>

<p>Extended this to all numbers $m$, instead of just $p$, will prove the $p$ problem too. (m ∤ $C_n$)</p>

<p>After a quick glance at some Carmichael number factors, $p$ must be greater or equal to $53$.</p>
",number_theory
"<p>Working needs to be shown
$\sqrt{\sqrt{5}+3}+\sqrt{\sqrt{5}-2}$
My guess is to multiply by  $\sqrt{\sqrt{5}+3}-\sqrt{\sqrt{5}-2}$ then we have a rational number but is it enough to prove the rationality of a number?</p>
",number_theory
"<p>Prove that $(\mathbb Z/m\mathbb Z)^\times$ is cyclic <strong>if and only if</strong> there is a primitive root modulo $m$.</p>

<p>if $g$ is a primtive root modulo $m$ so indeed  $(\mathbb Z/m\mathbb Z)^\times$ is cyclic by definition , but I don't understand why the other direction is right:</p>

<p>if  $(\mathbb Z/m\mathbb Z)^\times$ is cyclic then it has a generator g, but how do we know that $\gcd (m,g)=1$ and that $g\in (\mathbb Z/m\mathbb Z)^\times$  ?</p>
",number_theory
"<p>Find all positive integers $a, b, c$ such that $a^2+1$ and $b^2+1$ are both primes and
$$(a^2+1)(b^2+1)=c^2+1$$</p>

<p>What I have done:</p>

<p>It is obvious that $a^2+1$ and $b^2+1$ cannot be both 2, so assume, WLOG, that $a^2+1=2$. Then, $a=1$
$$2(b^2+1)=c^2+1 \Rightarrow 2b^2+1=c^2 \Rightarrow b=2, c=3$$
Hence, we have 2 sets of solutions $(a, b, c)=(2, 1, 3); (1, 2, 3)$
If both $a^2+1$ and $b^2+1$ are odd primes, then $a, b, c$ are all even numbers.</p>

<p>I tried using Fermat's Infinite Descent by letting $a=2a_1, b=2b_1, c=2c_1$ but I seem to reach a dead end. Can anyone help me?</p>

<p>Thank you!</p>
",number_theory
"<p>I just wondered about the following question:</p>

<p>Suppose that we are given a homogeneous second-order recurrence relation, $x_{n+2}+ax_{n+1}+bx_n=0$ for all $n\in\mathbb{N}$. </p>

<p>Can we choose integers $a$, $b$, $x_0$ and $x_1$ in such a way that the resulting sequence $(x_n)$ will contain <em>infinitely many</em> primes?</p>

<p>Does anybody know anything about this? Or any ideas? I couldn't come up with much, having done some years of maths at uni.</p>
",number_theory
"<p>I would like to know whether or not a prime number $ p $ can be written in the form
$$
p = 3A + 2B,
$$
where $ A $ and $ B $ are positive integers.</p>
",number_theory
"<p>The Weyl equidistribution theorem states that the sequence of fractional parts ${n \xi}$, $n = 0, 1, 2, \dots$ is uniformly distributed for $\xi$ irrational. </p>

<p>This can be proved using a bit of ergodic theory, specifically the fact that an irrational rotation is uniquely ergodic with respect to Lebesgue measure. It can also be proved by simply playing with trigonometric polynomials (i.e., polynomials in $e^{2\pi i k x}$ for $k$ an integer) and using the fact they are dense in the space of all continuous functions with period 1.  In particular, one shows that if $f(x)$ is a continuous function with period 1, then for any $t$,  $\int_0^1 f(x) dx = \lim \frac{1}{N} \sum_{i=0}^{N-1} f(t+i \xi)$. One shows this by checking this (directly) for trigonometric polynomials via the geometric series.  This is a very elementary and nice proof.</p>

<p>The general form of Weyl's theorem states that if $p$ is a monic integer-valued polynomial, then the sequence ${p(n \xi)}$ for $\xi$ irrational is uniformly distributed modulo 1.  I believe this can be proved using extensions of these ergodic theory techniques -- it's an exercise in Katok and Hasselblatt.  I'd like to see an elementary proof.</p>

<p>Can the general form of Weyl's theorem be proved using the same elementary techniques as in the basic version?</p>
",number_theory
"<p>I am so excited to learn finding integer solutions of the equation $x^2 -y^5 = x-y$. I just found few solutions by plugging various integers in place of $x$ and $y$. But, I need a permanent method or approach to find all most all OR as much as we can ""integer"" solutions of the cited above equation.
Kindly help.
with regards
Pokwishi</p>
",number_theory
"<p>Below is a proof that the cyclotomic polynomial $\Phi_n(x)=\prod_{d|n}(x^d-1)^{\mu(n/d)}$ using Möbius inversion. However, it requires that we take the log of a polynomial, which (to my knowledge) is not necessarily well defined. Is there any way to fix this, or rigorously define a logarithm of a polynomial?</p>

<blockquote>
  <p>We have $x^n-1=\displaystyle\prod_{d|n}\Phi_d(x)$. Taking the log of
  both sides yields:
  $$\log\left(\prod_{d|n}\Phi_d(x)\right)=\sum_{d|n}\log(\Phi_d(x))=\log(x^n-1).$$
  By Möbius inversion we have \begin{align*}\log(\Phi_n(x)) &amp;=
\log(x^n-1)*\mu \\ &amp;=\sum_{d|n}\log(x^d-1)\mu\left(\frac{n}{d}\right)\\ &amp;=\sum_{d|n}\log\left[(x^d-1)^{\mu(n/d)}\right] \\ &amp;=\log\left(\prod_{d|n}(x^d-1)^{\mu(n/d)}\right), \end{align*} and
  exponentiating both sides gives the desired result.</p>
</blockquote>
",number_theory
"<p>I am supposed to have proved the following congruence identity:
$$
1^{n} + 2^{n} + \cdots + (p - 1)^{n} \equiv 0 ~ (\text{mod} ~ p).
$$
This is apparently meant to help me solve the problem stated in the title. I have noticed that
$$
y^{2} \equiv x^{2} - D ~ (\text{mod} ~ p)
$$
has solutions if and only if $ x^{2} - D $ is a quadratic residue modulo $ p $. I have applied the Legendre symbol to show that it is equivalent to $ (x^{2} - D)^{(p - 1) / 2} ~ (\text{mod} ~ p) $. I know that I have to apply the Binomial Theorem to this, but I am not sure how. Even if I were sure, I still would not know how to produce $ (p - 1) $ solutions.</p>

<p>I can get the number $ p - 1 $ based on the fact there are $ (p - 1) / 2 $ squares in the group $ (\Bbb{Z} / p \Bbb{Z})^{*} $ and that there are two solutions for each one, but that is not the point. :/</p>
",number_theory
"<p>How to prove$\forall n\ge5 $ </p>

<blockquote>
  <p>$$\phi(n)\ge \frac{n}{6\log \log (n)} $$ </p>
</blockquote>

<p>$\phi$ is Euler function</p>

<p>Thanks in advance </p>
",number_theory
"<p>I found this interesting conjecture, but maybe I'm not the first to state it. I have tested it for the first $10^4$ positive integers, but that is not a proof. Can anybody prove or disprove this conjecture?</p>

<blockquote>
  <p><strong>Every positive integer can be written as the sum of 1 square number, 1 pentagonal number, and 1 hexagonal number.</strong></p>
</blockquote>

<p><strong>Note</strong>:</p>

<p>Square numbers are generated by the formula, $S_{n}=n^{2}$.
The first ten square numbers are:</p>

<pre><code>0, 1, 4, 9, 16, 25, 36, 49, 64, 81,...
</code></pre>

<p>Pentagonal numbers are generated by the formula, $P_{n}=\frac{1}{2}n(3n-1)$.
The first ten pentagonal numbers are:</p>

<pre><code>0, 1, 5, 12, 22, 35, 51, 70, 92, 117,...
</code></pre>

<p>Hexagonal numbers are generated by the formula, $H_{n} = n(2n-1)$.
The first ten Hexagonal numbers are:</p>

<pre><code>0, 1, 6, 15, 28, 45, 66, 91, 120, 153,...
</code></pre>

<hr>

<p>Here are the solutions for the first 10 positive integers.</p>

<p>Numbers    =     Square + Pentagon + Hexagon </p>

<pre><code>1    =    0    +    1    +    0
2    =    1    +    1    +    0
3    =    1    +    1    +    1
4    =    4    +    0    +    0
5    =    0    +    5    +    0
6    =    1    +    5    +    0
7    =    1    +    5    +    1
8    =    1    +    1    +    6
9    =    4    +    5    +    0
10   =    9    +    1    +    0
</code></pre>
",number_theory
"<p>As is well-known, $Z[\sqrt{-5}]$ is not a ufd because $6$ has more than one prime factorization in this ring: $6=2\cdot 3$ and $6=(1+\sqrt{-5})(1-\sqrt{-5})$. But both of these prime factorizations have the same number $(2)$ of prime factors...Am I correct that in $Z[\sqrt{-29}], 30=2\cdot 3\cdot 5$ and $30=(1-\sqrt{-29})(1+\sqrt{-29})$ are prime factorizings of $30$ that have different numbers of factors? </p>

<p>Also would $Z[\sqrt{-2309}]$ give as distinct prime factorizations $2310=2\cdot 3 \cdot 5\cdot 7\cdot 11=(1+\sqrt{-2309})(1-\sqrt{-2309})$? ($2309$ is a prime number). </p>

<p>What about $Z[\sqrt{-30029}]$, would that give $30030=2\cdot 3\cdot 5\cdot 7\cdot 11\cdot 13=(1+\sqrt{-30029})(1-\sqrt{-30029})$ as distinct prime factorizations?($30029$ is prime)...Does this show the number of primes in distinct prime factorizings be different? I'm worried that the norms will cause some of my ""primes"" to be nonprimes. Thanks.</p>
",number_theory
"<p>For any prime $p &gt; 2 $ and any positive integer a with GCD$(a, p) = 1$ the
Legendre symbol for $a$ and $p$ is</p>

<p>$$\text{Leg}\Big[\dfrac{a}{p} \Big] = 1 \text{ if } a\text{ is a quadratic residue modulo }p,$$</p>

<p>$$\text{Leg}\Big[\dfrac{a}{p} \Big] = -1 \text{ if } a\text{ is a quadratic nonresidue modulo }p,$$</p>

<p><b>Jacobi Symbol</b></p>

<p>Let $n = p_1^{k_1}\cdot p_2^{k_2}\cdot ... \cdot p_l^{k_l}$ be the factorization of an odd integer $n \geq 3$. For all positive integers $a$ with GCD$(a, n) = 1$, the Jacobi symbol of $a$
and $n$ is</p>

<p>$$
	\text{Jac}\Big[\frac{a}{n}\Big] = \prod_{i=1}^{l}\Big(\text{Leg}\Big[\frac{a}{p_i}\Big]\Big)^{k_i} =   \prod_{i=1}^{l}\Big(\text a^{\tfrac{p_i-1}{2}} \text{ mod } p_i \Big)^{k_i}.
$$  </p>

<hr>

<p>It has been hours I am trying to prove the following equations but I failed:</p>

<p>(1) Jac $\Big[\dfrac{2}{n} \Big] = -1 \text{ forall } n \text{ mod } 8 \in \{3, 5\}$ AND Jac $\Big[\dfrac{2}{n} \Big] = 1 \text{ forall } n \text{ mod } 8 \in \{1, 8\}$</p>

<p>(2) Jac $\Big[\dfrac{a}{n} \Big] = (-1)^{\tfrac{a-1}{2}.\tfrac{n-1}{2}}.\text{ Jac } \Big[\dfrac{n}{a} \Big]$ for all odd $a$</p>
",number_theory
"<p>I need some help in solving the following problem:</p>

<p>Suppose $K$ is a number field and $K=\mathbb{Q}(\theta)$ where $\theta\in\mathfrak{O}_K$, the ring of integers of $K$. Now among the elements in $\mathfrak{O}_K$ of the form $$\frac{1}{d}(a_0+\cdots+a_i\theta^i)$$($0\ne a_i$; $a_0,\ldots a_i\in\mathbb{Z})$, where $d$ is the discriminant of $K$, pick one with the minimum value of $|a_i|$ and call it $x_i$. Do this for $i=1,\ldots ,n=\dim_{\mathbb{Q}}K$. I need to show that $\lbrace x_1,\ldots ,x_n\rbrace$ is an integral basis for $K$.</p>

<p>Here are my thoughts: If we can show that the discriminant of $\lbrace x_1,\ldots ,x_n\rbrace$, which can be shown to be a $\mathbb{Q}$-basis, is less than or equal to $d$ then we are done; I tried to show this but have not succeed. I have to somehow use the fact that $|a_i|$ is the minimum which I am unable to see how. Any help will be appreciated.</p>
",number_theory
"<p>I am wondering if there is a way to prove the following statement, which bears some resemblance to Zsigmondy's Theorem. I am not sure if the statement is true, but it seems as though it should be. </p>

<p>For any prime $p$, there is some positive integer $n$ such that $p^{2^n}-1$ is divisible by two distinct primes that do not divide $p^k-1$ for any $k\in\{1,2,\ldots,2^n-1\}$. </p>

<p>Indeed, Zsigmondy's Theorem guarantees that $p^{2^n}-1$ will be divisible by some prime that does not divide $p^k-1$ for any $k\in\{1,2,\ldots,2^n-1\}$ no matter the choice of $n$ (except, perhaps, if $n=1$ and $p$ is a Mersenne prime). 
One might also phrase the problem as follows: </p>

<p>Let $p$ be a prime. Show that there is some positive integer $n$ such that $ord_{q_1}(p)=ord_{q_2}(p)=2^n$ for distinct primes $q_1$ and $q_2$.  </p>
",number_theory
"<p>Prove that the prime factors of $510510^{510510} + 1$ are greater than or equal to 19.</p>

<p>Here is my (incomplete) proof that I need help with:<br>
1. The prime factors of 510510 are 2, 3, 5, 7, 11, 13 and 17.<br>
2. Since $510510^{510510}$ is a multiple of 510510, the prime factors of $510510^{510510}$ are also 2, 3, 5, 7, 11, 13 and 17.<br>
3. ...  </p>

<p>How can I show that none of these prime factors are factors of $510510^{510510} + 1$? In other words, how can I show that the smallest possible prime factor of $510510^{510510} + 1$ must be greater than the largest prime factor of $510510^{510510}$, which is 17?</p>
",number_theory
"<p>This question is inspired by the announcement of a proof that ""fake twin"" primes, i.e. pairs of consecutive primes differing by at most K, are -in infinite number- where K is a fixed integer which can be taken = 70,000,000.</p>

<p>It is not known OTOH whether the above would hold where K would be  = 2 instead (the twin prime conjecture).</p>

<p>Anyway, my question may be (hopefully is)  much simpler : it's been known after Viggo Brun that the sum of reciprocals of actual ""twin primes"" is finite (whether the number of terms in this sum is finite or infinite). Does the sum of reciprocals of the ""fake twins"" as defined above (for K=70 million) also converge ? Does it follow from an easy extension of Brun's method ?</p>

<p>I should make it clear I am no expert, just curious... I do not have accesss to a proof of Brun's original theorem, even a sketchy one.</p>
",number_theory
"<p>Prove (or disprove) the following statement:
For any positive integers $x,y,t$,</p>

<p>$\displaystyle\sum_{i=1}^{t(y+1)-1} \frac{1}{t(xy+x-1)-x+i}$</p>

<p>is an increasing function of $t$.</p>

<p>My attempts:
The statement appears to be true numerically.
Tried some obvious bounds to compare the sums for consecutive values of $t$ but didn't find one that was strong enough to prove the statement. </p>
",number_theory
"<p>It is quite well-known that,</p>

<p>$$1^2+2^2+\dots+24^2 = 70^2$$</p>

<p>Not so well-known is,</p>

<p>$$15^3+16^3+\dots+34^3 = 70^3$$</p>

<p>The formula for the sum of $m$ consecutive <em>squares</em> starting with $a^2$ is,</p>

<p>$$F(a,m) = (m/6)(6a^2-6a+6am+1-3m+2m^2)$$</p>

<p>while the sum of $n$ consecutive <em>cubes</em> starting with $b^3$ is,</p>

<p>$$F(b,n) = (n/4)(2b+n-1)(2b^2-2b+2bn-n+n^2)$$</p>

<p><strong><em>Question</em></strong>: Is the only solution in <em>positive integers</em> to the simultaneous equations,</p>

<p>$$F(a,m) = x^2$$</p>

<p>$$F(b,n) = x^3$$</p>

<p>given by $a,m;b,n;x = 1,\,24;\,15,\,20;\,70$? (I have searched within a relatively small range, but didn't find any new solution.)</p>
",number_theory
"<p>Consider a set of integers $Q$ such that the set of all positive integers $\mathbb{Z}$ is equivalent to the span of ever possible power tower</p>

<p>$$a_1^{a_2^{\ldots a_N}}$$ involving $a_i \in Q$.</p>

<p>In simpler terms. Take the integers, remove all square numbers, cube numbers, fourth powers, fifth powers, etc... And this remaining set is $Q$.</p>

<p>What is the density of $Q$ compared to positive $\mathbb{Z}$? Does it obey a theorem similar to the prime number theorem for primes? Are there infinity many numbers $x$, in $Q$ such that both $x$ and $2x$ are members of $Q$? Is there a formula for the elements of $Q$?</p>

<p>This is basically analogous to prime numbers except now it deals with exponents as opposed to multiplication.</p>
",number_theory
"<p>The Chebyshev functions are defined as $\psi(x) = \sum_{p^m \leq x} \log n$ and $\theta(x) = \sum_{p\leq x} \log p$, where $p$ is a prime, $m\geq 1$ is an integer and $n=p^m$ in $\psi(x)$. It is known that there exist positive constants $c_{1}$ and $c_2$ such that
                                                                                 $c_{1}x &lt; \psi(x) &lt; c_{2} x$ and $ \frac{1}{2}c_{1}x &lt; \theta(x) &lt; c_{2} x$.     By these bounds we find that
                                                                                  $  \dfrac{ \psi(x) - x}{\psi(x) - \theta(x)} &lt; \dfrac{(c_{2} -1)x}{(c_2 - c_1)x}  = \dfrac{c_{2} -1 }{c_2 - c_1} &lt;\infty $. </p>

<p>Hence invoking the well known result  $\mid \psi(x) - \theta(x) \mid = O(x^{\frac{1}{2}}\log x)$, it then follows that $\mid \psi(x) - x \mid = O(x^{\frac{1}{2}}\log x)$ ?</p>

<p>EDIT: It is also known that $\theta (x)$ tends to $x$ as $x$ tends to $\infty$. Surely, an impication of this is $\dfrac{ \psi(x) - x}{\psi(x) - \theta(x)}  &lt; \infty$ since $\psi(x) \neq \theta(x)$.</p>
",number_theory
"<p>Given large $n\in\Bbb N$ is there many $a,b\in(n,2n)$ with $\gcd(a,b)=1$ and $q,r\in(n^4,2n^4)$ with $\gcd(a,bq)=\gcd(ar,b)=1$ and $c,d\in(n^3,2n^3)$ with $-n&lt;-x=q\bmod c,-y=r\bmod d&lt;0$ with $\gcd(a,x)=1$ and $\gcd(b,y)=1$ such that if $u=ca^{-1}{b^2}\bmod q, v=db^{-1}{a^2}\bmod r$ then ${n}^{2+\beta}&lt;u,v&lt;{n}^{2+\beta'}$ at a fixed $0&lt;\beta&lt;\beta'\ll1$?</p>
",number_theory
"<p>I am looking for a fast pairing function which maps two integers (cartesian coordinates) to a single unique integer. In other words, 
$$
\mathbb{Z} \times \mathbb{Z} \rightarrow \mathbb{Z},
$$
thats has a one-to-one-correspondence (bijection). </p>

<p>I have found Cantor's pairing function, 
$$
f(x,y) = \frac{(x+y)\times(x+y+1)}{2}+y,
$$
which is,
$$
\mathbb{N} \times \mathbb{N} \rightarrow \mathbb{N},
$$
and a bijection, but since it is from $\mathbb{N} \times \mathbb{N}$ it only works for coordinates where x and y are both positive or zero.</p>

<p>Additionally I have found the 'elegant pairing function' written by <a href=""http://szudzik.com/ElegantPairing.pdf"" rel=""nofollow"">Matthew Szudzik</a> which suffers from the same issue.</p>

<p>There should be a way to modify Cantor's, or Szudzik's method so that it spirals around (0,0) as opposed to saw toothing through all of the positive integer pairs. </p>

<p>Is such a function already defined?</p>

<p>If not is there a good place to start in creating one?</p>

<p>What about,
$$
\mathbb{Z} \times \mathbb{Z} \rightarrow \mathbb{N}.
$$</p>
",number_theory
"<p>Is this a solution for the problem: $\ a^3 + b^3 = c^3\ $ has no nonzero integer solutions?    </p>

<p>Suppose $\ a^3 + b^3 = c^3,\ a,b,c \in \mathbb Z^*,\ $then:<br>
$c^3 - b ^ 3 = (c - b)((c - b) ^ 2 + 3cb) = a ^ 3 \quad (1)$<br>
<a href=""http://mathrefresher.blogspot.com/2005/05/coprime-numbers-xn-yn-zn.html"" rel=""nofollow"">We can assume that all variables are coprime</a>, because $\ c - b\ $ divides $\ 3cb,\ a\ $ and $\ c - b\ $ doesnt divides $\ c,\ b,\ $ so<br>
  $c - b = 3 \quad (2),$<br>
from $(1)\ $ and $\ (2)\ $   get $\ 3 (3 ^ 2 + 3 c(c - 3)) = 3^{3}x ^{3},\ c ^ 2 - 3c + 3 = 3x ^3$,<br>
here we see $3$ divides $\ c,\ $and we know $3$ divides $a$, this conflict by assuming.</p>

<p>Edit:</p>

<p>As Nishant commented: ""I don't see why $\ c−b\ $ divides $\ 3cb$...""<br>
Divide both side of  $(1)\ $ by $\   (c - b)\ $ get  $\ 3cb = (c - b)^{2}(x^{3} - 1)$    </p>

<p>Update:</p>

<p>If$~(c−b)~$ is a single prime or a product of distinct primes or $~(c−b)~\nmid~a~$ and $~(c−b)~$ isn't a cubic number, then $~(c−b)~$ contains factor$~m~$ of $~a,~$divide both side of  $(1)\ $ by $\ (c - b):$</p>

<p>$(c - b) ^ 2 + 3cb = (c-b)^{2}x^3 \quad (2),$ </p>

<p>from $~(2)~$ if $~m=3~$ or not, we can get $~c~$ or $~b~$ contains factor $~m,~$this conflict by assuming.  </p>

<p>If $~(c−b)=1~$ then $~3c^2-3c+1=a^3,~$</p>

<p>from  <a href=""http://www.wolframalpha.com/"" rel=""nofollow"">Wolframalpha</a> get:</p>

<p>$$
c = \dfrac{3- \sqrt{3}\sqrt{4a^{3}-1}}{6} \\
c = \dfrac{\sqrt{3}\sqrt{4a^{3}-1}+3}{6}
$$
There's no integer solution (As Steven Stadnicki commented,$~\sqrt{3}\sqrt{4a^{3}-1}~$ isn't an integer, lack of proof)(update: this solved by Jack D'Aurizio see: <a href=""http://math.stackexchange.com/questions/884565/how-to-prove-sqrt3-sqrt4a3-1-isnt-an-integer"">How to prove $~\sqrt{3}\sqrt{4a^{3}-1}~$ isn&#39;t an integer?</a>).</p>

<p>(If$~(c−b)~$ is a cubic number, the problem left: $~(c - b) ^ 2 + 3cb=x^3~$has no nonzero integer solutions for $~c,~b$)</p>
",number_theory
"<p>Find all integer solutions to $x^2=2y^4+1$.</p>

<hr>

<p><strong>What I tried</strong> </p>

<p>The only solutions I got are $(\pm 1 ,0)$, I rewrote the question as : is $a_{n}$ a perfect square for $n&gt;0$ were </p>

<p>$$a_0=0,\quad a_1=2, \quad a_{n+2}=6a_{n+1}-a_n.$$ 
I tried taking $\pmod{4}$ and $\pmod{12}$ but that lead me nowhere.</p>
",number_theory
"<p>let $P$ be a non-zero prime ideal of $O_K$, where $K$ is a number field(i.e. the degree $[K:\mathbb{Q}]$ is finite) then $O_K/P$ is finite. I'm working through a proof for this claim, however there is some group theory used in the proof which I don't understand.</p>

<p>Choose $\alpha\in P$, such that $\alpha\neq 0$, then $N=|Nm(\alpha)|=\alpha\Pi_{i=2}^d \phi_i(\alpha)$ where $\phi_i$ are the embeddings for $\alpha$, letting $\phi_1$ be the identity map. So $N=\alpha\beta$, where both $\alpha,\beta\in O_k$. Therefore $N\in P$, by definition of an ideal. So $\langle N\rangle\subseteq P$ and $(O_K/P)\subseteq (O_K/\langle N\rangle)$.</p>

<p>I understand everything up until this point, but now $O_K\cong \mathbb{Z}^d$, where $d$ is the degree of the minimal polynomial of $\alpha$. But I don't understand where this result comes from. Next the proof says that $(O_K/\langle N\rangle)\cong(\mathbb{Z}/N\mathbb{Z})^d$, which is finite, hence $(O_K/P)\subseteq (O_K/\langle N\rangle)$ must also be finite. Since $\langle N\rangle = NO_K$, does this mean that $\langle N\rangle\cong N\mathbb{Z}^d$, and then can we jump to the conclusion that $(O_K/\langle N\rangle)\cong(\mathbb{Z}/N\mathbb{Z})^d$.</p>
",number_theory
"<p>Consider an integer$L$ written in Base 2B which digits</p>

<p>$$a_n a_{n-1} a_{n-2} ... a_1 B$$</p>

<p>Where $a_i$ are arbitrary constants such that $9 \le a_i &lt; 2B$.</p>

<p>I am attempting to prove that the square of this integer $L$ will have ending digits equal to</p>

<p>$$\frac{B}{2}, 0$$
if B is even and:</p>

<p>$$\frac{B-1}{2}, B $$
when B is odd</p>

<p>and furthermore the leading chunk of digits will be equivalent to those of</p>

<p>$$\frac{L}{2m} \left(\frac{L}{2m} + 1\right)$$</p>

<p>Where the division is integer division (no remainders)</p>

<p>Naturally I opted to begin by considering $L^2$ modulo $(2B)^2$ to generate a solution to the initial clause involving even and odd $B$.</p>

<p>I proceeded by noting</p>

<p>$$L^2 = B^2 + 2Ba_1(2B)+ ... + a_n^2(2B)^{2n} $$</p>

<p>When expanding the multiplicands</p>

<p>Thus we can consider</p>

<p>$$B^2 + (2B)a_1 \mod 4B^2$$</p>

<p>So my first challenge is to absorb the $a_1$ and have it dissappear when considering this expression $\mod 4B^2$ No clue how to do this</p>

<p>Any suggestions where to take it from here?</p>
",number_theory
"<p>Something I have been struggling with!</p>

<blockquote>
  <p>Let $m$ be a squarefree odd integer, and let $(a, m) = 1$. Show that $x^2 ≡ a \pmod m$ has a solution if and only if the Jacobian Symbol $(a/p) = 1$, for all primes $p|m.$</p>
</blockquote>
",number_theory
"<p>I wrote this equation, that is a way to represent the Sieve of Eratosthenes:</p>

<p>$-1+\sum\limits_{i=2}^{\infty} ( 2 \left \lfloor \frac {x}{i} \right \rfloor - \left \lfloor \frac {2x}{i} \right \rfloor +1) (2 \left \lfloor \frac {i+2x-2}{2i} \right \rfloor - \left \lfloor \frac {i+2x-2}{i} \right \rfloor +1)=0$</p>

<p>The solutions are all the prime numbers, and only them.</p>

<p>The function</p>

<p>$y=-1+\sum\limits_{i=2}^{\infty} ( 2 \left \lfloor \frac {x}{i} \right \rfloor - \left \lfloor \frac {2x}{i} \right \rfloor +1) (2 \left \lfloor \frac {i+2x-2}{2i} \right \rfloor - \left \lfloor \frac {i+2x-2}{i} \right \rfloor +1)$</p>

<p>is also a divisor function, because its values represent the number of proper divisors for every integer $x&gt;1$.</p>

<p>Inside the sum, the first factor produces a square wave of period $i$ and amplitude of 1. The second factor reduces the duty cycle of the first wave to 1.</p>

<p>As for the Sieve of Eratosthenes, to calculate all the prime numbers not greater than a number n, the sum can be stopped at $i=\sqrt{n}$.</p>

<p>It seems to me an original function. Is it of some interest? Can it be simplified? Is there any way to evaluate the equation, that is to bring the x to the left, outside the floor functions and the sum?</p>

<p><strong>added images</strong></p>

<p>square waves: $i=4$</p>

<p><a href=""http://i.stack.imgur.com/ji1sb.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/ji1sb.jpg"" alt=""q4""></a></p>

<p>$i=9$</p>

<p><a href=""http://i.stack.imgur.com/U2zEb.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/U2zEb.jpg"" alt=""q9""></a></p>

<p>The complete value</p>

<p><a href=""http://i.stack.imgur.com/8U0LE.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/8U0LE.jpg"" alt=""ss""></a></p>

<p>See the primes: 2,3,5,7,11,13,17,19 where the value is zero.</p>
",number_theory
"<p>Let $d_1$, $d_2$, ..., $d_n$ be positive integers. Let $B$ be the $n \times n$ matrix
$$\begin{pmatrix}
d_1 &amp; 1 &amp; 1 &amp; \cdots &amp; 1 \\
1 &amp; d_2 &amp; 1 &amp; \cdots &amp; 1 \\
1 &amp; 1 &amp; d_3 &amp; \cdots &amp; 1 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; 1 &amp; 1 &amp; \cdots &amp; d_n \end{pmatrix}.$$
When does $B$ have a square root in $\mathrm{Mat}_n(\mathbb{Z})$?</p>

<p>Motivation: The <a href=""http://en.wikipedia.org/wiki/Friendship_graph"" rel=""nofollow"">Friendship Theorem</a> states that the only graph in which every pair of vertices is joined by a path of length $2$ is the ""Friendship Graph"", which you can see at the linked article. If $A$ is the adjacency matrix of such a graph, with degree sequence $(d_1, d_2, \ldots, d_n)$, then $A^2=B$. So this contributes the solution $(d_1, d_2, \ldots, d_n) = (2,2,2,\ldots,2,2m)$, with $n=2m+1$.</p>

<p>I was preparing notes on the friendship theorem and got distracted by trying to figure out when this matrix has an integer square root at all. It seemed like it might make a nice challenge for here.</p>
",number_theory
"<p>I'm having a problem with a section of Niven's book the Theory Of Numbers.  I am trying to show:</p>

<p>If an integer $\alpha \in \mathbb{Q}(\sqrt{m})$ is neither zero nor a unit, prove that $|N(\alpha)|&gt;1$.</p>

<p>An element of $\mathbb{Q}(\sqrt{m})$ would look like $a+b\sqrt{m}$ where $a,b$ are rational integers $0, \pm1, \pm2,...$  The norm is defined as $N(\alpha)=\alpha\bar{\alpha}$, where $\bar{\alpha}$ is defined as the conjugate of $\alpha$ ($\alpha=a+b\sqrt{m}, \bar{\alpha}=a-b\sqrt{m}$).</p>

<p>So since $\alpha$ can not be zero or a unit, we have the two cases where 1).  $a\neq 0, b\neq 0$.  2).  $a\neq \pm 1, b\neq 0$.  Therefore $a\ge 2, b\ge 1$.  Now</p>

<p>$N(\alpha)=\alpha\bar{\alpha}=(a+b\sqrt{m})(a-b\sqrt{m})=a^2 -b^2m$.  By our given conditions, we see that $N(\alpha)\neq 0$ or $1$  Now I have to show that $|N(\alpha)|&gt;1.$  I was thinking contradiction, so suppose that there exist an $a,b$ such that $|a+b\sqrt{m}|\le 1$.  Then
$$-1\le a^2+b^2m\le 1$$
However, with $m\ge 2$ this is impossible unless either $a=b=0$ or $a=1, b=0$.  But these cannot be since we have restricted these conditions in the initial problem.  Therefore
$|N(\alpha)|&gt;1$. </p>

<p>Is this the correct way of solving this particuluar problem?  ( I think I worked it out while I was typing, but any verification would be helpful....)</p>
",number_theory
"<p>Which is the smallest integer $n&gt;1$, such that $$n^{5000}+n^{2013}+1$$ is prime ?
 Since $x^{5000}+x^{2013}+1$ is irreducible over $\mathbb{Q}$ and has value $1$ for $x=0$,
 there should be infinitely many such $n$, if Bunyakovsky's conjecture is
 true.</p>
",number_theory
"<p>is there a short proof of the fact that there is a finite amount of consecutive smooth numbers (meaning Given a finite set B, there is a finite amount of pairs $n,n+1$ so that both can be expressed as the product of elements from B only.</p>

<p>I was told there is a proof via the Thue–Siegel–Roth theorem but the proof of the theorem is pretty long and I'd be happy if there was another proof.</p>
",number_theory
"<p>Let's say I have the following equalities</p>

<p>$a_1x_1 + a_2x_2 + a_3x_3 + a_4x_4 = b_1x_1 + b_2x_2 + b_3x_3 + b_4x_4 = c_1x_1 + c_2x_2 + c_3x_3 + c_4x_4$</p>

<p>Where the $a$'s, $b$'s, and $c$'s are known, non-negative integers.</p>

<p>Is there an efficient way to check if a solution exists (the $x$'s) such that they are non-negative real numbers (except for the trivial case of all $x$'s being 0)? I don't need to actually calculate them, just need some way to see if a solution even exists.</p>
",number_theory
"<p>Does anyone know how to find the m-th coefficient of</p>

<p>$-t=(3+2\sum_{k=1}^{\infty} \frac{t^{2k}}{(2k)!})(\sum_{n=0}^{\infty} D_n \frac{t^n}{n!})$?</p>

<p>The answer is:</p>

<p>$0=3 \frac{D_m}{m!}+2\sum_{k=1}^{m/2} \frac{1}{(2k)!} D_{m-2k} \frac{1}{(m-2k)!}$</p>

<p>but i don't understand it why this is the m-th coefficient. </p>

<p>This is an exercise trying to find a recursive formula for $D_m$. In this exercise the numbers $D_m$ are defined by the generating function:</p>

<p>$G(t)=\frac{-t}{e^t +1 + e^{-t}} = \sum_{m\geq 0 } D_m \frac{t^m}{m!}$</p>
",number_theory
"<p>Question:</p>

<blockquote>
  <p>Let $n = pq$ be a product of two distinct odd primes and put $d = \gcd(p − 1, q − 1)$.<br>
  (a) Prove that $n$ is a pseudoprime to the base $b$ if and only if $b^d\equiv  1 \pmod n$. 
  (b) Conclude (using part (a)) that $|Pn| = d^2.$</p>
</blockquote>

<p>I got part (a) on my own. I just don't see how I can conclude part (b) with it. Could someone guide me in the right direction?</p>
",number_theory
"<p>Let $a&gt;0$ be a real number, such that for all integers $n\geq 1$: $n^a \in \mathbb N$<br>
Show that $a$ must be an integer.</p>

<hr>

<p>It's not difficult to show this when $a$ is a rational number: $2^\frac{p}{q}$ is irrational when the fraction is in lowest terms and $q \neq 1$.</p>

<p>When $a$ is irrational, then for all $n\geq 1$, there exists $m_n\in \mathbb N^*$, such that:
$$a = \frac{\log m_n}{\log n}; \quad \text{$m_n$ is not a power of $n$}$$</p>

<p>I think considering $n=2,3$ is enough to show a contradiction, but I can't seem to find it. This is what I get:
$$a = \frac{\log p}{\log 2} = \frac{\log q}{\log 3}$$
$$p = 2^{\log q/\log 3} $$</p>

<p>I think the RHS is irrational when $q$ is not a power of $3$, but I can't prove it. The closest thing I have to a solution is <a href=""http://math.stackexchange.com/a/974590/120267"">this answer on a similar question</a>. But it uses an unproven conjecture, and I was hoping for a more elementary proof.</p>
",number_theory
"<p>Do primes become more or less frequent as you go further out on the number line?  That is, are there more or fewer primes between $1$ and $1,000,000$ than between $1,000,000$ and $2,000,000$?</p>

<p>A proof or pointer to a proof would be appreciated.</p>
",number_theory
"<p>Some $k$ prime numbers $n_1, n_2, ..., n_k$ are given. Then some natural number $x$ is provided. </p>

<p>Then we want to figure natural numbers (including zero) $m_1, m_2, ..., m_k$ so that $n_1m_1 + n_2m_2 + ... + n_km_k = x$.</p>

<p>1) Suppose that for given $k$ and given sequence $n_k$, $x$ can be linearly decomposed as above. Then what would be the general algorithm for doing this? Note that I want cases for all possible $k$ from 2 to any number less than infinity.</p>

<p>2) As $k$ increases, would the number of possible cases of sequence $m_k$ decrease?</p>
",number_theory
"<p>Prime numbers are numbers with no factors other than one and itself.</p>

<p>Factors of a number are always lower or equal to than a given number; so, the larger the number is, the larger the pool of ""possible factors"" that number might have.</p>

<p>So the larger the number, it seems like the less likely the number is to be a prime.</p>

<p>Surely there must be a number where, simply, every number above it has some other factors.  A ""critical point"" where every number larger than it simply will always have some factors other than one and itself.</p>

<p>Has there been any research as to finding this critical point, or has it been proven not to exist?  That for any <code>n</code> there is always guaranteed to be a number higher than <code>n</code> that has no factors other than one and itself?</p>
",number_theory
"<p>Let $n$ be a positive integer. Suppose $a$ and $b$ are randomly (and independently) chosen two $n$-digit positive integers which consist of digits 1, 2, 3, ..., 9. (So in particular neither $a$ nor $b$ contains digit 0; I am adding this condition so that division by $b$ will be possible, and that we don't get numbers of the form $0002$ and so on). Here ""randomly"" means each digit of $a$ and $b$ is equally likely to be one of the 9 digits from $\{1,2,3,..., 9\}$. </p>

<p>My question concerns the divisibility of these integers:</p>

<blockquote>
  <p>1) What is the probability that $b$ divides $a$ ?</p>
</blockquote>

<p>The answer, of course, will depend on $n$. Denote this probability by $p(n)$. I would be happy with rough estimates for $p(n)$ as well :)</p>

<blockquote>
  <p>2) Is it true that $p(n)\to 0$ as $n\to\infty$?</p>
</blockquote>

<p>I think answer to question 2) is yes (just by intuition). </p>
",number_theory
"<p>I know that there are some solutions in the reel numbers, but how can I prove that there are none in the rational ones?</p>
",number_theory
"<p>I am looking to evaluate the sum $$\sum_{1\leq k\leq mn}\left\{ \frac{k}{m}\right\} \left\{ \frac{k}{n}\right\} .$$</p>

<p>Using matlab, and experimenting around, it seems to be $\frac{(m-1)(n-1)}{4}$ when $m,n$ are relatively prime.  How can we prove this, and what about the case where they are not relatively prime?</p>

<p><strong>Conjecture:</strong>  Numerically, it seems that for any $m,n$ we have $$\sum_{1\leq k\leq mn}\left\{ \frac{k}{m}\right\} \left\{ \frac{k}{n}\right\} =\frac{(m-1)(n-1)}{4}+C(\gcd(m,n))$$
where $C(\gcd(m,n))$ is some constant depending only on the $\gcd(m,n)$.</p>

<p><strong>Additionally:</strong>  Can we sum this even when it is not a complete interval? Suppose that $0&lt;a&lt;b&lt;mn,$ do we have an exact form for $$\sum_{a\leq k\leq b}\left\{ \frac{k}{m}\right\} \left\{ \frac{k}{n}\right\}.$$ </p>

<p><strong>Remark:</strong> In the one variable case we have $$\sum_{1\leq k\leq n}\left\{ \frac{k}{n}\right\} =\frac{n-1}{2}$$ the sum over an interval $a,b$ has an explicit form.</p>
",number_theory
"<p>Find all polynomials $P$ with integer coefficients such that $P(n)$ divides $2^n-1$ for all positive integers $n$.</p>
",number_theory
"<p>Given a prime $q$, and another prime $p$ = 20q + 1, I am able to find generators in $\mathbb{Z}_p$. Does $-1$ have a square root in $\mathbb{Z}_p{}^*$? 
Thanks!</p>
",number_theory
"<p>what's up folks?</p>

<p>I'm solving the red book of math problems, problem 16 which is to solve the following recurrence relation:</p>

<p>$\sum_{k=1}^n {n \choose k} a(k) = \frac{n}{n+1}$</p>

<p>PS: ${n \choose k}  = \frac{n!}{k!(n-k)!}$ (it is not the Legendre symbol).</p>

<p>for every $n \in \mathbb{N}$</p>

<p>I'm wondering if it's possible to use Moebius Inversion formula with</p>

<p>$G(x) = \frac{x}{x+1}$ (one can define it to be zero if $0&lt;x&lt;1$)</p>

<p>and some $F$ I know one can use differential equations theory to solve this one, but I want to try to solve it by this way</p>

<p>spoiler alert: $a(k) = \frac{(-1)^{k+1}}{k+1}$</p>
",number_theory
"<p>What's with the definition of Bezout's Identity? As I understand it, it states that if $d = \gcd(a, b)$, then there exist integers $x,\ y$ such that $ax+by=d$. </p>

<p>Why the requirement that $d=\gcd(a,b)$ though? It seems to work even when this isn't the case. For example, let $a = 17$ and $b = 4$. Then $d = 1$, however setting $d = 2$ still generates an infinite number of solutions:
$$
x = -4n-2,\quad\quad y=17n+9\\
n\in\Bbb{Z}
$$
and for $(a,\ b,\ d) = (19,\ 17,\ 5)$ we get $x=-17n-6$ and $y=19n+7$. However for $(a,\ b,\ d) = (44,\ 55,\ 12)$ we <em>do</em> have no solutions.</p>

<p>So what's the fuss? Why require $d=\gcd(a,b)$? Is it like, you can't <em>guarantee</em> the existence of solutions to $ax+by=d$ unless $d=\gcd(a,b)$, and I just stumbled across a case where it happens to work? In that case can we classify <em>all</em> the cases where there are solutions $x,\ y$, more specifically than just $d=\gcd(a,b)$?</p>
",number_theory
"<p>So we choose two large primes p and q and multiply them together to get n.
We also pick an encryption exponent e and so for any message m, we can compute m^e (mod n) which is our ciphertext c.</p>

<p>So anyways, I understand (or rather, I'm familiar with) Fermat's little theorem that x^(p-1) is congruent to 1 mod p, as well as Euler's theorem, which seems to just tie together FLT and the notion that for any prime p, since there are p-1 numbers less than p that are coprime to p, $\phi(p) = p-1$</p>

<p>My question: since c is just m^e, then if we can find d, by solving de = 1 (mod p-1 * q-1), and then compute m by taking c^d = m^ed = m (mod n). What I don't understand is where the equation de = 1 (mod $\phi(n)$) comes from. Like why are we modding by (p-1)(q-1) instead of n? </p>

<p>There is a little section in my book that says the following: ""when we are working mod 11 we are essentially working with the exponents mod 10, not mod 11"" so I can see how that would relate to my question but I don't see the exact</p>
",number_theory
"<p>Assume that $P_n$ denotes the $n$'th prime for this entire question.</p>

<p><strong>Inspriation:</strong> I was dumbfounded by the fact that: $$\hat\prod_\limits{n=1}^\infty P_{n}=4\pi^2$$ 
After further investigation, I learned of many other properties of zeta-regulation, as well as their proofs (to a reasonable extent). I realized nothing had been done of this question: $$2*5*11\cdots=\hat\prod_\limits{n=1}^\infty P_{2n-1}=\kappa$$
and solve for $\kappa$. </p>

<p><strong>Issues:</strong> I am fairly competent in the usage of zeta-regularization, but am lost here, because it seems that zeta regularization doesn't work with $2n-1$ used instead of $n$. Unfortunately, I couldn't really figure out how to apply that on to this here. I was driven, from Resource 1, that a <em>potential</em> to use bounds was created, but my inability to logically understand this problem made it impossible to determine if $4\pi^2$ or $\sqrt{2\pi}$ would be upper or lower.</p>

<p><strong>Questions:</strong></p>

<p>a) Can $\kappa$ be zeta-regularized?</p>

<p>b) If it can, could you please assist me in a calculation of $\kappa$? </p>

<p><strong>Side notes:</strong> I have had this question on my mind almost forever, and would really love an answer. Although I would most appreciate a proof, really anything will help me here. I am also somewhat uncertain with my tag choices, so please consider editing before immediately downvoting. The following were helpful in the construction of this problem. </p>

<p>1) <a href=""http://math.stackexchange.com/questions/177946/when-is-an-infinite-product-of-natural-numbers-regularizable"">When is an infinite product of natural numbers regularizable?</a></p>

<p>2) <a href=""http://mathworld.wolfram.com/Zeta-RegularizedProduct.html"">http://mathworld.wolfram.com/Zeta-RegularizedProduct.html</a></p>

<p>(I realize the former has been unanswered, but the problem had helpful comments as well as the idea to find a bound. )</p>
",number_theory
"<p>It is relatively easy to show that if $p_1$, $p_2$ and $p_3$ are distinct primes then $\sqrt{p_1}+\sqrt{p_2}$ and $\sqrt{p_1}+\sqrt{p_2}+\sqrt{p_3}$ are irrational, but the only proof I can find that $\sqrt{p_1}+\sqrt{p_2}+...+\sqrt{p_n}$ is irrational for distinct primes $p_1$, $p_2$, ... , $p_n$ requires we consider finite field extensions of $\mathbb{Q}$.</p>

<p>Is there an elementary proof that $\sqrt{p_1}+\sqrt{p_2}+...+\sqrt{p_n}$ is irrational exist?</p>

<p>(By elementary, I mean only using arithmetic and the fact that $\sqrt{m}$ is irrational if $m$ is not a square number.)</p>

<p>The cases $n=1$, $n=2$, $n=3$ can be found at in the MSE question <a href=""http://math.stackexchange.com/questions/964729/sum-of-square-root-of-primes-2"">sum of square root of primes 2</a> and I am hoping for a similar proof for larger $n$.</p>
",number_theory
"<p>Given 3 diophantine equations:</p>

<p>$$x_1y_1+x_2y_2=x_3y_3+x_4y_4$$</p>

<p>and </p>

<p>$$x_1+x_2 = x_3+x_4$$ and</p>

<p>$$y_1+y_2 = y_3+y_4$$</p>

<p>We're interested in solutions to this system of equations when all variables are positive. I conjecture that any solutions have $x_1=x_3$ or $x_1=x_4$ and $y_1=y_3$ or $y_1=y_4$. Any tips on how to go about proving this? Thanks.</p>
",number_theory
"<p>The classical <a href=""http://en.wikipedia.org/wiki/M%C3%B6bius_function"" rel=""nofollow"">Möbius function</a> $\mu(n)$ fulfills the multiplicative inversion formula, e.g. <a href=""http://math.stackexchange.com/questions/83805/an-identity-involving-the-mobius-function"">see this thread</a>. Now I see in the theory of <a href=""http://en.wikipedia.org/wiki/Poset"" rel=""nofollow"">posets</a>, they generalize the concept of that function, see <a href=""http://en.wikipedia.org/wiki/Incidence_algebra#Special_elements"" rel=""nofollow"">incidence algebra</a> and from this point of view, the previous definition is the case for the natural numbers and its order induced by divisibility. </p>

<p>In the last link, they also define a ""zeta-function"" $\zeta(x,y)$ for elements $x,y$ of a poset - I think that's just the boolean version of ""$x\le y$"" telling me if two numbers $x,y$ are appropriately ordered. There is <a href=""http://en.wikipedia.org/wiki/M%C3%B6bius_inversion_formula"" rel=""nofollow"">a formula</a> of how to obtain the inverse of such a $\zeta$ using $\mu$, and this appears to be the source of the equal names.</p>

<p>But I fail to see if this new function is otherwise the analog of the Riemann zeta function $\zeta(z)$ (and other members of the <a href=""http://en.wikipedia.org/wiki/List_of_zeta_functions"" rel=""nofollow"">family</a> of continuous zeta functions). Does that analytic function also somehow represent a characteristic function for ordered intervals of numbers? How is the inversion formula a generalization of it, when the number theoretic $\zeta(z)$ doesn't even have two arguments?</p>

<p>Or can I maybe connect $\zeta(x,y)$ to the idea behind the Arithmetic and Dedekind zeta function, which know about the spaces (ideals..) which can be constructed from their domain?</p>
",number_theory
"<p>Is there any simple algorithm which can tell if a string is a repeat of its substring?
For example, $1212121212$ is a repeat of $12$, $135746135746$ is a repeat of $135746$.</p>
",number_theory
"<p>Show that for any $a \in \mathbb{Z}, 42 \mid (a^{7} − a)$.</p>

<p>I saw this question on Rosen textbook and it doesn't have answer key so I am wondering can you guide me how to do it? </p>

<p>What I have tried is that since I don't know the number a so I substitute a number for a.</p>
",number_theory
"<p>$\frac17 = 0.(142857)$...</p>

<p>with the digits in the parentheses repeating.</p>

<p>I understand that the reason it's a repeating fraction is because $7$ and $10$ are coprime.  But this...cyclical nature is something that is not observed by any other reciprocal of any natural number that I know of (besides multiples of $7$). (if I am wrong, I hope that I may find others through this question)</p>

<p>By ""cyclical,"" I mean:</p>

<pre>
1/7 = 0.(142857)...
2/7 = 0.(285714)...
3/7 = 0.(428571)...
4/7 = 0.(571428)...
5/7 = 0.(714285)...
6/7 = 0.(857142)...
</pre>

<p>Where all of the repeating digits are the same string of digits, but shifted.  Not just a simple ""they are all the same digits re-arranged"", but the same digits <strong>in the same order</strong>, but shifted.</p>

<p>Or perhaps more strikingly, from the <a href=""http://en.wikipedia.org/wiki/142857_(number)"">wikipedia article</a>:</p>

<pre>
1 × 142,857 = 142,857
2 × 142,857 = 285,714
3 × 142,857 = 428,571
4 × 142,857 = 571,428
5 × 142,857 = 714,285
6 × 142,857 = 857,142
</pre>

<p>What is it about the number $7$ in relation to the base $10$ (and its prime factorization $2\cdot 5$?) that allows its reciprocal to behave this way?  Is it (and its multiples) unique in having this property?</p>

<p><a href=""http://en.wikipedia.org/wiki/Cyclic_number"">Wikipedia</a> has an article on this subject, and gives a form for deriving them and constructing arbitrary ones, but does little to show the ""why"", and finding what numbers have cyclic inverses.</p>
",number_theory
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://math.stackexchange.com/questions/21351/upper-bound-exact-length-of-decimal-expansion-of-simple-fraction"">Upper bound/exact length of decimal expansion of simple fraction</a>  </p>
</blockquote>



<p>I noticed that <a href=""http://www.wolframalpha.com"" rel=""nofollow"">WolframAlpha</a> given an operation like $\frac{n}{m},\;n,m \in N$ that result in a periodic decimal number, computes really fast the length of the period.</p>

<p>E.g. $\frac{3923}{6173}$ has a period of 3086: <a href=""http://www.wolframalpha.com/input/?i=3923/6173"" rel=""nofollow"">here</a>.</p>

<p>I was wondering how this computation is done: is there some method to do this (except the trivial one of executing the division and looking for a sequence repetition) ?</p>
",number_theory
"<p>Let $\zeta_{p^n}$ be the primitive $p^n$-th root of unity where $p$ is a prime and $K_n=\mathbb Q(\zeta_{p^n})$ the $p^n$-th cyclotomic field. Let $K_\infty=\bigcup K_n$. </p>

<p>Could someone give a proof of the isomorphism $\text{Gal}(K_\infty/\mathbb Q)\cong \mathbb Z_p^{\times}$?</p>

<p>Many thanks in advance. </p>
",number_theory
"<p>Consider some binomial chain that looks like this:</p>

<p>$$\binom{N}{k_1}\binom{N-k_1}{k_2}\binom{N-k_1-k_2}{k_3}\binom{N-k_1-k_2-k_3}{k_4} \cdots \binom{N-k_1-k_2-\cdots -k_{t-1}}{k_t}$$</p>

<p>Where all variables $N$ and $k_1$ through $k_t$ are known positive integers.</p>

<p>Is there some simple way to compress this?</p>
",number_theory
"<p>Which is the single best book for Number Theory that everyone who loves Mathematics should read?</p>
",number_theory
"<p><strong>Question</strong>: When $p$ is an odd prime, show that the number of quadratic residues $a$ modulo $p$ with $1\leq a\leq p-1$ is $(p-1)/2$</p>

<p><strong>Answer</strong>: From Euler's criterion $\left(\frac{a}{p}\right)\equiv a^{(p-1)/2}\pmod{p}$</p>

<p>When we apply Lagrange's theorem, the congruence $a^{(p-1)/2}\equiv 1\pmod{p}$ has at most $(p-1)/2$ solutions</p>

<p>By Fermat's little theorem, we have $a^{p-1}\equiv 1\pmod{p}$, so</p>

<p>$a^{p-1}-1\equiv(a^{(p-1)/2}-1)(a^{(p-1)/2}+1)\equiv 0\pmod{p}$</p>

<p>The answer then says this ""has precisely $p-1$ solutions""</p>

<p>How do we deduce from this that this $a^{p-1}-1$ has precisely $p-1$ solutions?</p>
",number_theory
"<p>Greetings Mathematics Community.</p>

<p>I am having much difficulty in solving the following problem:</p>

<p>If $m\equiv 2$ (mod 4), show that $\mathbb{Q(\zeta_m)}=\mathbb{Q(\zeta_{\frac{m}{2}})}$ where $\zeta$ is a primitive root of unity. I know that $\zeta_m=e^{\frac{2\pi i}{m}}$ and by Euler's equation, we have $\cos(\frac{2 \pi }{m})+i\sin(\frac{2\pi }{m})$.</p>

<p>I have tried to compare $[\mathbb{Q(\zeta_{\frac{m}{2}})}:\mathbb{Q}]$ with $[\mathbb{Q(\zeta_m)}:\mathbb{Q}]$ by substituting $\frac{m}{2}$ in Euler's equation to get
$\cos(\frac{4 \pi }{m})+i\sin(\frac{4\pi }{m})$. My intuition is telling me that I should somehow use the given fact that $m\equiv 2$ (mod 4), but I am not sure how. </p>

<p>Furthermore, I do know that this extension degree can be found using Euler's $\phi-$function on $m$. But I am unsure about how to apply it in my situation.</p>

<p>As always, any help is greatly appreciated. Thanks in advance. </p>
",number_theory
"<p>Is there any general form to determine the number of non-congruent solutions to equations of the form $f(x) \equiv b \pmod m$?</p>

<p>I solved a few linear congruence equations ($ax \equiv b \pmod m$) and I know those have only one solution because we're basically finding $a^{-1}$ and all the inverses of $a$ are congruent.</p>

<p>What's the number of solutions for congruences of higher degree polynomials? (quadratic, qube, etc).</p>

<p>Thanks a lot.</p>
",number_theory
"<p>Let $\mathbb{F}_q$ be a finite field with $q$ elements, let $N$ be a positive divisor of $q-1$, and let $\xi_N$ be an element of $\mathbb{F}_q^*$ of order $N$. One can similarly define the Ramanujan sum for $\mathbb{F}_q$ as 
$$
c_N(k) = \sum_{\substack{i=1 \\ (i,N) = 1}}^N \xi_N^{ik}.
$$
That is, $c_N(k)$ is the sum of $k$-th powers of the primitive $N$-th roots of unity in $\mathbb{F}_q$. I'm wondering how many zeros does the sum have? What are its values? How about a lower bound for this? Thanks!</p>
",number_theory
"<p>My number theory is terrible so I don't know what ""class"" of problem this secretly is.  I'm looking for all positive integer solutions to the equation:</p>

<blockquote>
  <p>$M^2=5N^2+2N+1$</p>
</blockquote>

<p>That is, I want positive integer $M$ and $N$ to make the above true.  I've got the obvious solution ($N=0$, $M=1$) but I don't know how to go about getting more solutions.  It has been suggested to me that there should be infinitely many solutions, and I would like to find them all.</p>

<p>I could transform it to look like Pell's equation by completing the square on the right, but it won't have integer coefficients (or you could multiply it through by the denominators, but then it wouldn't look like Pell's equation), so I don't think that helps much.</p>

<p>I don't know enough number theory to guess at other things, but I'm happy to read something on this topic.</p>
",number_theory
"<p>For example:
say $n = 2$.
The numbers from $1$ to $2^2$ are $1, 2, 3, 4$.
i.e. $1, 10, 11, 100$ in binary.
So the result is $1$, because only one number i.e. $3$ is there such that it has <code>11</code> in it.</p>

<p>For $n = 3$,
$3, 6, 7$ have '11', so the result is $3$.</p>
",number_theory
"<p>Let $a_1,\ a_2,\ a_3,\ \ldots,\ a_n$ be distinct positive integers. 
Find $x_1,\ x_2,\ x_3,\ \ldots,\ x_n,\ y \in \mathbb{Z^+}$ 
such that: $$\left\{\begin{array}{rl}(x_1,x_2,\ldots,x_n)&amp;=1\\ a_2x_1+a_3x_2+\cdots+a_nx_{n-1}+a_1 x_n &amp; =y x_2\\ \cdots\cdots\cdots\cdots &amp; = \cdots\cdots \\ a_n x_1+a_1 x_2+ \cdots + a_{n-1} x_n&amp;=y x_n \end{array}\right.$$</p>

<p>How to solve this system equation ? </p>

<p>I am not good at diophantine equation and the problem above is so hard.</p>
",number_theory
"<p>Let $L/K$ be abelian.  There is a natural way to define the Artin reciprocity map on the ideles using the notion of an <strong>admissible cycle</strong>.  I don't want to go into the details of what that is right now, but essentially what I'm having trouble with is the following.  In order to show that the Artin map is well defined on the ideles $\mathbb I_K$, I must show:</p>

<blockquote>
  <p>Suppose $x \in K^{\ast}$ is a local norm at each ramified place.  Also suppose that for any real place $v$ of $K$ (and corresponding embedding $ \sigma: K \rightarrow \mathbb{R}$) which has a complex place $w$ lying over it, we have $\sigma(x) &gt; 0$.  Then $$\prod\limits_{v } (\mathfrak p_v, L/K)^{ord_v(x)}$$
  is the identity element of $Gal(L/K)$, where $(\mathfrak p, L/K)$ is the Frobenius element and $v$ runs through all the unramified places.  </p>
</blockquote>

<p>One way to do this would be to show that $x$ is a global norm, or at least a local norm at each place $v$ where $ord_v(x) \neq 0$.  But I don't know if this is true.  Any hints?</p>
",number_theory
"<p>In Intro Number Theory a key lemma is that if $a$ and $b$ are relatively prime integers, then there exist integers $x$ and $y$ such that $ax+by=1$.  In a more advanced course instead you would use the theorem that the integers are a PID, i.e. that all ideals are principal.  Then the old lemma can be used to prove that ""any ideal generated by two elements is actually principal.""  Induction then says that any finitely generated ideal is principal.  But, what if all finitely generated ideals are principal but there are some ideals that aren't finitely generated?  Can that happen?</p>
",number_theory
"<p>I have come to know of an elementary proof, by Chebyshev, that there exists a real $\alpha&lt;1$ such that $$ p_n &gt; \alpha n \log n, $$ where $p_n$ is the $n$-th prime. As I am failing to find it online, I hope someone can provide a link to it or reproduce it.</p>
",number_theory
"<p>This is a question from Frohlich's book 'Galois Module Structure of Algebraic Integers', Ch.1. </p>

<p>Let $K$ be a number field and $\Omega_K=\text{Gal}(K^c/K)$ where $K^c$ is the separable closure of $K$. Also let $\Gamma$be any finite group and $R_\Gamma$ ring of virtual characters of $\Gamma$. Next let $\mathfrak I(\mathbb Q^c)$ be the direct limit of the idele groups $\mathfrak I(E)$ as $E$ runs over the number fields in $\mathbb Q^c$. The values of the virtual characters of $\Gamma$ lie in some number field $F$ containing $K$.</p>

<p>The book states that $$\text{Hom}_{\Omega_K}(R_\Gamma,\mathfrak{I}(\mathbb Q^c))=\text{Hom}_{\Omega_K}(R_\Gamma,\mathfrak{I}(F))$$</p>

<p>How can we show this? For a start, how do we know that the LHS is a subgroup of the RHS? </p>

<p>Many thanks for your help.</p>
",number_theory
"<p>suppose I have a finite field $\mathbb{F}_q$, where $q = p^m$ and $p$ is 
prime. Let $0 \not = t \in \mathbb{F}_q$. I was wondering
if someone could tell me what the number of solution to
$$
x^2 + y^2 + z^2 = t
$$
would be (where $x,y,z \in \mathbb{F}_q$)? In particular is there always a solution?
I would appreciate any reference also.</p>

<p>Thanks!</p>
",number_theory
"<p>Let $f: N \to N$, $f(2) = 3$, and $f(ab) = f(a)f(b)$, that is, f is a multiplicative function. f is also strictly increasing. Show that no such function exists.</p>

<p>Progress: Apparently, this is proven by contradiction.  So I used $f(2) = f(2 * 1) = f(2) * f(1)$.  This gives me $3 = 3 * f(1)$, which means $f(1) = 1$.</p>

<p>I see no contradiction though.  f is strictly increasing, not decreasing, so it makes sense that $f(1) = 1$ but $f(2) = 3$.  Help please?</p>
",number_theory
"<p>Suppose that an infinite set $S= {0,1,2,4,8,...}$ of integers written in monotonically increasing order (that is, all other members are integers greater than 8) has the property that Euclidean division of any integer $a$ in $S$ by any integer $b\ne0$ in $S$ (regardless of whether $a&gt;b$) gives quotient $q$ and remainder $r$ also in $S$. That is, $S$ is closed under Euclidean division. Obviously, $S$ could then be ${0,1,2,4,8,16,...}$, but is it possible to prove that there are no other infinite sets $S=0,1,2,4,8,...$ satisfying the closure property?</p>
",number_theory
"<blockquote>
  <p>Prove that in every sequence of $79$ consecutive positive numbers written in decimal notation there is a number the sum of whose digits is divisible by $13$.</p>
</blockquote>

<p>I tried to take one by one sets of $79$ consecutive positive numbers. Then I tried to solve with sets,relation,function. But I am not getting any idea how to start solving the question.</p>
",number_theory
"<p>This result is used in the Erdos' Distance problem, in the Landau-Ramanujan constant, but I can't find a proof anywhere.</p>

<p><a href=""http://en.wikipedia.org/wiki/Erd%C5%91s_distinct_distances_problem"" rel=""nofollow"">http://en.wikipedia.org/wiki/Erd%C5%91s_distinct_distances_problem</a>
<a href=""http://en.wikipedia.org/wiki/Landau%E2%80%93Ramanujan_constant"" rel=""nofollow"">http://en.wikipedia.org/wiki/Landau%E2%80%93Ramanujan_constant</a></p>
",number_theory
"<p>[1] Number of ordered pair of unequal positive integer solution of $x+y+z = 10$</p>

<p>[2] Number of ordered pair of unequal positive integer solution of $x+y+z+w = 20$</p>

<p>$\bf{My\; Try}::$ For $(1)$ one:: Here $x,y,z&gt;0$ and $x,y,z\in \mathbb{Z^{+}}$</p>

<p>$\bullet $ If $x=1$, Then $y+z=9$, So $(y,z) = (2,7)\;,(3,6)\;,(4,5)\;(5,4)\;,(6,3)\;,(7,2)$</p>

<p>$\bullet $ If $x=2$ Then $y+z=8$, So $(y,z) = (1,7)\;,(3,5)\;,(5,3)\;(7,1)$</p>

<p>$\bullet $ If $x=3$ Then $y+z=7$, So $(y,z) = (1,6)\;,(2,5)\;,(5,2)\;(6,1)$</p>

<p>$\bullet $ If $x=4$ Then $y+z=6$, So $(y,z) = (1,5)\;,(5,1)$.</p>

<p>$\bullet $ If $x=5$ Then $y+z=5$, So $(y,z) = (1,4)\;,(2,3)\;,(3,2)\;(4,1)$</p>

<p>$\bullet $ If $x=6$ Then $y+z=4$, So $(y,z) = (1,3)\;,(3,1)$</p>

<p>$\bullet $ If $x=7$ Then $y+z=3$, So $(y,z) = (1,2)\;,(2,1)$</p>

<p>So Total unordered pair is $ = 24$</p>

<p>My Question is , is there is any other Method to calculate the ordered pair in less complex way</p>

<p>because above is very Lengthy method</p>

<p>Help Required</p>

<p>Thanks.</p>
",number_theory
"<blockquote>
  <p>Express $\mathbb{Q}(\sqrt{3},\sqrt[3]{5})$ in the form $\mathbb{Q}(\theta)$.</p>
  
  <p>Hint: Let $f,g$ be the minimal polynomials of $\sqrt{3}$ and $\sqrt[3]{5}$, respectively. Factor $f$ and $g$ in $\mathbb{C}$ to obtain expressions of the form $$f(x)=\prod\limits_{j=1}^n (x-\alpha_j),g(x)=\prod\limits_{k=1}^m (x-\beta_k)$$</p>
  
  <p>where $\alpha_1=\sqrt{3}$ and $\beta_1=\sqrt[3]{5}$. Choose $c \in \mathbb{Q}$\ $\lbrace 0 \rbrace$ so that $$\alpha+c\beta \notin \lbrace \alpha_j+c\beta_k|1\leq j \leq n, 2 \leq k \leq m \rbrace$$ It can then be shown that $\mathbb{Q}(\sqrt{3},\sqrt[3]{5})=\mathbb{Q}(\sqrt{3}+c\sqrt[3]{5})$</p>
</blockquote>

<p>Following the hint, I think $c=1$ works. Now I try to prove that $\mathbb{Q}(\sqrt{3},\sqrt[3]{5}) \subseteq \mathbb{Q}(\sqrt{3}+\sqrt[3]{5})$ (the other containment is easy), but I'm having trouble with this last step.</p>
",number_theory
"<p>Suppose: $ x_1 + x_2 + x_3 + x_4 + x_5 + x_6 = 1$ , and $x_1x_3x_5 + x_2x_4x_6 \ge \dfrac {1}{540} $ and $\dfrac{p}{q}$ is the maximum possible value of
$x_1x_2x_3 + x_2x_3x_4 + x_3x_4x_5 + x_4x_5x_6 + x_5x_6x_1 + x_6x_1x_2$</p>

<p>Find $p+q$</p>

<p><strong>Details and Assumptions</strong></p>

<p>$x_1, x_2, \dots, x_6$ are non-negative real numbers.</p>

<p>$p$ and $q$ are positive relatively prime integers.</p>
",number_theory
"<p>Prove that there are infinitely many prime numbers of the form $6n-1$. I proved that there are infinitely many prime numbers but I couldn't bring it in the form given in the question. While proving it, I was getting $6n+1$ not $6n-1$.</p>
",number_theory
"<p>It is a theorem in elementary number theory that if $p$ is a prime and congruent to 1 mod 4, then it is the sum of two squares. Apparently there is a trick involving arithmetic in the gaussian integers that lets you prove this quickly. Can anyone explain it?</p>
",number_theory
"<p>Find $a,b,c \in \mathbb {Q}$ such that:
$\left\{\begin{array}{rl} x^3&amp;\in \mathbb Q \\ x&amp;\notin \mathbb{Q}\\ ax^2+bx+c &amp;=0\end{array}\right.$</p>

<p>I tried Vieta's formulas, but seem like it didn't help.</p>

<p>I think $a=b=c=0$ is only solution.</p>
",number_theory
"<blockquote>
  <p>The least common multiple of $\{1,2,...,n\}$ is greater than $2^{n-1}$ for any $n \ge 3$.</p>
</blockquote>

<p>I found this in a MATHEMATICA book, but I don't know how to prove this. Can you help me?</p>
",number_theory
"<p>If i define $f(m,n)=$ $$\sum_{1\leq k\leq mn}\left\{ \frac{k}{m}\right\} \left\{ \frac{k}{n}\right\} .$$</p>

<p>Then prove $$f(m+n,n) - f(m,n) =\frac{n^2-n}{4}$$
for all $m$ and $n$.</p>

<p>This question came from part of answer from this question: <a href=""http://math.stackexchange.com/questions/140499/a-sum-of-fractional-parts/140517#140517"">A sum of fractional parts.</a></p>
",number_theory
"<p>Suppose we have a fixed (generally composite) $k$, and we want to find the largest power of $k$ that divides $n!$ for $n$ large.</p>

<p>If $k$ is square-free, we need only consider the behavior of the largest prime $p$ dividing $k$: if $p^i | n!$, then certainly $q^i|n!$ for any prime $q&lt;p$, and so $k^i|n!$.</p>

<p><em>Most of the time</em>, when $k$ is composite, a similar argument is possible and we need only consider a single prime factor of $k$. Legendre's formula for the prime factorization of $n!$ tells us that the highest power of $p$ dividing $n!$ is
$$
\sum_{j=1}^\infty \left\lfloor \frac{n}{p^j}\right\rfloor = \frac{n}{p-1} + O(\log n) \, .
$$
So, for a fixed prime power $p^a$, the largest power of $p^a$ that divides $n!$ is $\frac{n}{a(p-1)} + o(n)$.</p>

<p>It follows that, if $k=p_1^{a_1}\dots p_n^{a_n}$, then we need only consider those $p_i$ which minimize $a_i(p_i-1)$. Most of the time there will only be one such $p_i$, in which case our life is no harder than it was when $k$ was square-free.</p>

<p>For example, if $k=24$, then we are interested only in the divisibility of $n!$ by the prime powers $8$ and $3$. The above analysis tells us that the largest power of $8$ that divides $n!$ is roughly $\frac{n}{3(2-1)}=\frac{n}{3}$, while the largest power of $3$ that divides $n!$ is roughly $\frac{n}{3-1}=\frac{n}{2}$. So the largest power of $24$ that divides $n!$ is always the same as the largest power of $8$ that divides $n!$, for $n$ sufficiently large.</p>

<p>However, there are exceptions!</p>

<p>For example, if $k=12=2^2 \cdot 3$, then the largest power of both $4$ and $3$ that divides $n!$ will be roughly $\frac{n}{2}$. Numerical experimentation suggests that $n!$ <em>usually</em> has more than twice as many factors of $2$ as it has factors of $3$, but the number of exceptions is large (for $n&lt;10^7$, the factors of $2$ are the scarce ones about $17\%$ of the time, and that number seems to decrease only slowly as $n$ increases).</p>

<p><strong>Can anything be said about which prime factor of $k$ will be the most scarce, in cases where the basic asymptotic analysis given above isn't strong enough?</strong></p>
",number_theory
"<p>I have asked a <a href=""http://math.stackexchange.com/questions/1402613/find-the-smallest-number-which-leaves-remainder-1-2-and-3-when-divided-by-11-5"">similar question</a> before on Chinese Remainder Theorem. </p>

<p>Now  concepts are getting clear. Thinking of a possible case where there are no solutions. Suppose the question is</p>

<pre><code>x ≡ 2 (mod 88)      
x ≡ 3 (mod 99)   
</code></pre>

<p>Then there will not be any solutions, correct?</p>

<p>Since 88 and 99 can be written as co-prime products 8*11 and 9*11,</p>

<pre><code>x ≡ 2 (mod 8)      
x ≡ 2 (mod 11) 
x ≡ 3 (mod 9)   
x ≡ 3 (mod 11)  
</code></pre>

<p>x ≡ 2 (mod 11) and x ≡ 3 (mod 11) will not come together. hence there are no solutions.</p>

<p>Is this right? Your comments are really helpful for me</p>
",number_theory
"<p>Consider the equation below:</p>

<p>$$\cos\dfrac{\pi}{m}=2\cos\dfrac{\pi}{r}\cos\dfrac{\pi}{n},$$ where $m,n$ and $r$ are non-zero integers.</p>

<p>Equality holds when $m=2$ and $r=2$ (or $n=2$), and also when $m=n$  and $r=3$ (alternatively $m=r$ and  $n=3$).</p>

<p>I would like to know any general conditions (if there are) between $m,n$ and $r$ for equality to hold.</p>
",number_theory
"<p>Adopting the following notation:</p>

<p>$$ R(b/a) = \text{Remainder of b when divided by a} $$</p>

<p>So I was trying to prove the following:</p>

<p>There always exists an $n$ for two primes $a$ and $b$ such that:</p>

<p>$$ R(b/a) = R(2n/a) $$</p>

<p>and satisfies:</p>

<p>$$ 2n &gt; b &gt; n &gt; a &gt; 2$$ </p>
",number_theory
"<blockquote>
  <p>There is a row of 1000 integers. There is a second row below, which is constructed as follows. Under each number $a$ of the first row, there is a positive integer $f(a)$ such that $f (a)$ equals the number of occurrences of $a$ in the first row. In the same way, we get the 3rd row from the 2nd row, and so on. Prove that, finally, one of the rows is identical to the next row.</p>
</blockquote>

<p>Attempt:</p>

<p>I looked at some cases. Suppose all integers are the same then $f(a_k) = 1000, \forall k$. For the third row then, $f(f(a_k)) = 1000, \forall k$. Similarly, $f(f(....a_k)..) = 1000, \forall k$.</p>

<p>I need to find an invariant. Can someone give me hints?</p>
",number_theory
"<p>In my book it said ""For nonnegative integers $a,n,$ and $N$ we have that $$(1+Na^{n+1})^a = 1+a \cdot Na^{n+1}+\binom{a}{2}N^2a^{2n+2}+Ma^{3n+3}$$ for some integer $M$."" Shouldn't it be $$(1+Na^{n+1})^a = 1+\binom{a}{1} \cdot Na^{n+1}+\binom{a}{2}N^2a^{2n+2}+\cdots+\binom{n}{n}N^{a}a^{an+a}?$$</p>
",number_theory
"<blockquote>
  <p>Find the smallest positive integer $a$ such that $1971$ divides $50^{n}+a \cdot 23^n$ for all odd integers $n$.</p>
</blockquote>

<p>I would re-write under this form
$$1971m-50^n=a \cdot 23^n$$
But where to go next?</p>
",number_theory
"<p>This is a curiosity question:</p>

<blockquote>
  <p><strong>Question</strong> Given two positive integers $a$ and $b$ do we have the following equivalence:
  $$\sum_{n=0}^{\infty}\frac{1}{n^2+2an+b}\in \Bbb Q \iff \exists k\in \Bbb N^+\text{ such that } a^2-b=k^2\ ?$$</p>
</blockquote>

<p><strong>My attempt</strong></p>

<ul>
<li>$(\Leftarrow)$ Assume that $a^2-b=k^2$ ave $k&gt;0$ then :
$$\begin{align}\sum_{n=0}^{\infty}\frac{1}{n^2+2an+b}&amp;=\sum_{n=0}^{\infty}\frac{1}{(n+a)^2-k^2}\\ \\
&amp;=\frac{1}{2k}\sum_{n=0}^{\infty}\left(\frac{1}{n+a-k}-\frac{1}{n+a+k}\right)\\ \\
&amp;=\frac{1}{2k}\sum_{i=0}^{2k-1}\frac{1}{i+a-k} \end{align}$$</li>
<li>$(\Rightarrow)$ I don't know how to approach this implication, but I know for example that if $a^2-b=0$ then using the sum:
$$\sum_{n=0}^{\infty}\frac{1}{(n+a)^2}=\frac{\pi^2}{6}-\sum_{i=1}^{a-1}\frac{1}{i^2}\notin \Bbb Q $$</li>
</ul>

<p>How can I approach the second implication, I don't know even if it's true or not but it seems when $\sqrt{a^2-b}\in \Bbb N$ that the implication would be true, for instance I don't know what would be the value of:
$$\sum_{i=0}^\infty\frac{1}{(n-a)^2+3} \text{ or } \sum_{i=0}^\infty \frac{1}{(n-a)^2-3}.$$</p>
",number_theory
"<p>So I'm searching a certain $n\in \mathbb Z\,$ that satisfies $2^{n-1}\cdot n+1=y^2$.</p>

<p>How do I find the different solutions and how do I prove this? </p>

<p>I think that it would be possible to transform the equation to a sort of Pell equation: $$y^2-n \cdot 2^{n-1}= 1$$ </p>

<p>Only this is not a Pell's equation because $n-1$ would have to be $2$.</p>

<p>Does another form exist? </p>
",number_theory
"<p>I write the positive numbers starting at $1$ in a triangle:$$\mathbb{N}_\triangle = \begin{matrix}
    &amp;&amp;&amp;&amp;&amp;21&amp;\ldots         \\
    &amp;&amp;&amp;&amp;15&amp;20&amp;\ldots       \\
    &amp;&amp;&amp;10&amp;14&amp;19&amp;\ldots     \\
    &amp;&amp;6&amp;9&amp;13&amp;18&amp;\ldots   \\
    &amp;3&amp;5&amp;8&amp;12&amp;17&amp;\ldots \\
    1&amp;2&amp;4&amp;7&amp;11&amp;16&amp;\ldots 
    \end{matrix}$$</p>

<p>I write $[n]$ for the $n^{th}-odd-column$ of $\mathbb{N}_\triangle$ and label the elements of $[n]$ as $x_1,\ldots,x_n$ where $x_1 =1+ {n(n-1) \above 1.5pt 2}$ and $x_n ={n(n+1) \above 1.5pt 2}$. For example $$[1] =\{1\}$$ $$[2] =\{4,5,6\}$$ $$[3] =\{11,12,13,14,15\}$$ Denote the number of elements in $[n]$ by $|[n]|$. I construct the following finite alternating sum for $[n]$  $$\mathfrak{a(n)} =x_n+\sum_{i=1}^{n-1}(-1)^{|[n]|-i}x_{|[n]|-i}$$ where $x_i \in [n]$ for $1 \leq i \leq n$. I am asking if the following claim is true?</p>

<blockquote>
  <p>If $n&gt;1$ then $$\mathfrak{a(n)} =2n^2-1$$</p>
</blockquote>

<p>For example consider $[3]$. First note that $|[3]|=5$ then </p>

<p>$$15+(-1)^{5-1}14+(-1)^{5-2}13+(-1)^{5-3}12+(-1)^{5-4}11=15+14-13+12-11=17$$ and $2*3^2-1=17$. The partition of the Natural numbers into the sets $[1],[2],[3],\ldots$ is known as  Smarandache's Sequential Sieve - <a href=""https://oeis.org/A007606"" rel=""nofollow"">A007606</a>. </p>

<p><strong><em>Edit 1</em></strong>: I just noticed that $|[n]| =2n-1$ in which case we can actually write $$\mathfrak{a(n)} =x_n+\sum_{i=1}^{n-1}(-1)^{2n-1-i}x_{2n-1-i}$$</p>
",number_theory
"<p>Find all solutions to the Diophantine equation $n^p+3^p=k^2$, where $p\in \mathbb{P}$ and $n,k$ positive integers.</p>

<p>I have tried everything, from mods to bounding to LTE; nothing seems to work on this. I did find one solution: $(n,p,k)=(4,2,5)$, which was motivated by noticing the resemblance to Pythagorean triples.</p>

<p>I should note that I don't know any advanced number theory (I'm in high school), so I apologize if there is a very simple approach I'm not seeing.</p>
",number_theory
"<blockquote>
  <p>Please refer this <a href=""http://www.careerbless.com/maths/speedmaths/cuberoot1.php"" rel=""nofollow"">site</a>. A method is provided for finding cube
  roots of perfect cubes.</p>
  
  <p>As per the method explained, suppose we are finding cube root of
  $157464$</p>
  
  <p>First we write as  $157,\quad 464$</p>
  
  <p>Last digit of $464$ is $4.$ Hence RHS=$4$</p>
  
  <p>$157-5^3 \ge 0$ ($5$ is the maximum). So LHS$=5$</p>
  
  <p>Hence, $\sqrt[3]{157464}=54$</p>
</blockquote>

<p>How we can prove this mathematically? Please give directions on how to start towards writing a proof for this. Thanks.</p>
",number_theory
"<p>The question is: If $n$ is a square, can $n$ consist of only odd digits?</p>

<p>I have a feeling that the answer is no, with the only exceptions being $n=1,9$. I am not sure how to go about proving this though. Any help or hints would be appreciated.</p>
",number_theory
"<p>solve $x^4 + y^4 = x^3 + y^3 + 10$  for  $x,y \in \mathbb{Z}$.</p>

<p>I tried solving this by trying to find upper bounds for $|x|$ and $|y|$, therefor it is quite useful to write:</p>

<p>$x^4 + y^4 - x^3 - y^3 = .....$</p>

<p>where ... is in the form of a square.</p>

<p>I tried to write $x^4 - x^3 = x^2(x^2+x) = x^2((x+\frac{1}{2})^2 - \frac{1}{4})$, but the $'\frac{1}{4}'$ is kind of troublesome, any tips or hints on how to get a good square, so i can estimate my polynomial?</p>

<p>Kees</p>
",number_theory
"<p>Step 1, make x columns rows data A and data B:</p>

<pre><code>date A row 0 is 3*n^2 + 3*n - 1
date B row 0 is 3*n^2 + 3*n
date A columns extended by add 5 + 6 * i
date B columns extended by add 7 + 6 * i
(i is columns index starts from 0)

here's a 3 x 3 data for example:

        date A:     date B:   

         5 17 35     6 18 36
        10 28 52    13 31 55
        15 39 69    20 44 74
</code></pre>

<p>Step 2, get  all numbers related to date A and date B less than max(B) = 74</p>

<pre><code>        date A:               date B:   

         5 17 35  59           6 18 36  60
        10 28 52              13 31 55         
        15 39 69              20 44 74  

        20 50                 27 57
        25 61                 34 70
        30 72                 41
        35                    48
        40                    55
        45                    62             
        50                    69           
        55                     
        60                     
        65                     
        70
</code></pre>

<p>Step 3,  from 0 to max(B) get numbers that not in the full data:</p>

<pre><code> [0,  1,  2,  3,  4,  7,  8,  9, 11, 12, 14, 16, 19, 21,
 22, 23, 24, 26, 29, 32, 33, 37, 38, 42, 43, 46, 47, 49, 
 51, 53, 54, 56, 58, 63, 64, 66, 67, 68, 71, 73]
</code></pre>

<p>Step 4, multiply step 3 data  items by 12 then add 5 , get prime form 12 * i + 5.</p>

<p>It seems this sieve is correct,how to prove this?</p>
",number_theory
"<p>How to prove the following identity:</p>

<p>$$\sum_{n\ge0}\frac{2q^{n^{2}+n}}{(q)_{n}^{2}(1+q^{n})}=\sum_{n\ge0}\frac{q^{n^{2}+n}}{(q)_{n}^{2}(1-q^{2n+2})}$$</p>
",number_theory
"<p>Are  there any upper bound for $a_i$ in $\gamma =\{a_0,a_1,\dots,a_i,\dots\}$ the  simple continued fraction expansion of  real positive algebraic numbers? </p>
",number_theory
"<p>A quadratic form represents an integer $n$ if there exist $x,y\in \mathbb{Z}$ such that $f(x,y)=n$.  It is proper if $\gcd{(x,y)}=1$.  It is said that if $f(x,y)=n$ and $\gcd{(x,y)}=g$, then $g^2|n$.  My question in regards to the material is this; why is it necessary that $g^2|n$?</p>

<p>Knowing $\gcd{(x,y)}=g$, I know that there must exist $a,b\in\mathbb{Z}$ such that $ax+by=g$  Also $$a^2x^2+2abxy+b^2y^2=n=g^2  $$
This is clearly a quadratic form and it is such that $g^2=n$.  Is this the reason?</p>

<p>EDIT:  I made a mistake originally that stated $\gcd{(x,y)}=1$ when it was my intention to write $\gcd{(x,y)}=g$  This I hope clarifies what I was asking, but I believe that I understand why it is such that $g^2|n$.  (Since $\gcd{(x,y)}=g, x=gk_1, y=gk_2$.  If $ax^2+bxy+cy^2=n$, substituting for $x,y$ gives the desired result I believe..)</p>
",number_theory
"<p>Let, $\Gamma, \Gamma'$ be $lattices$ of $\mathbb C$, define $elliptic$ $curves$ by $\mathbb C/\Gamma , \mathbb C/\Gamma'$, then </p>

<blockquote>
  <p>$\mathbb C/\Gamma , \mathbb C/\Gamma'$ are isomorphic $\Leftrightarrow$ $\Gamma=\lambda\Gamma'.$</p>
</blockquote>

<p>The $\Leftarrow$ part is easy, but how to prove the $\Rightarrow$ part?</p>

<p>(Rmk:</p>

<p>I am reading Serre's $A$ $Course$ $In$ $Arithmetic$, it doesn't particular treat elliptic curves, and just writes:</p>

<p>""Let us associate to a lattice $\Gamma$ of $\mathbb C$ the elliptic curve $E_\Gamma =\mathbb C/ \Gamma$. It is easy to see that two lattices $\Gamma, \Gamma'$  define isomorphic elliptic curves if and only if they are homothety.""</p>

<p>That's all I know about elliptic curves now, so I am not sure what does ""isomorphic"" mean in original question. ... I thought it means group isomorphism, but I am not sure now. It is helpful that anyone clarifies what is the author talking about.)</p>
",number_theory
"<p>Find the remainder when ${45^{17^{17}}}$ is divided by 204</p>

<p>I tried using congruence modulo. But I am not able to express it in the form of $a\equiv b\pmod{204}$.</p>

<p>$204=2^2\cdot 3\cdot 17$</p>
",number_theory
"<p>Consider $2y^x-1$; for what $y$ does this function's range not contain a prime? Having $x&gt;0, y&gt;1$.</p>
",number_theory
"<p>$\forall l,m,n\in \Bbb{Z_+}$, let $A:=\{k: m+1\leq k\leq m+n\text{ and }l-k^2\text{ is a square number}\}$.</p>

<p>Please prove that the number of elements in $A$ is not more than $C\sqrt{n\log n}$, where $C$ is a positive constant that is independent of $l,m$ and $n$.</p>
",number_theory
"<p>Consider a regular n-gon with side length $A$.</p>

<p>Let $p$ be a point in the polygon.
Let the distances from $p$ to the corners of the n-gon be $x_1,x_2,...,x_n$</p>

<p>Are there solutions with $A,x_1,x_2,...x_n$ all positive integers and $gcd(A,x_1,x_2,...,x_n) = 1$.</p>

<p>For the triangle ( $n=3$) this question has been answered already here</p>

<p><a href=""http://math.stackexchange.com/questions/485755/do-there-exist-an-infinite-number-of-rational-points-in-the-equilateral-triang"">Do there exist an infinite number of &#39;rational&#39; points in the equilateral triangle $ABC$?</a></p>

<p><a href=""http://mathoverflow.net/questions/180191/rational-distance-from-vertices-of-an-equilateral-triangle"">http://mathoverflow.net/questions/180191/rational-distance-from-vertices-of-an-equilateral-triangle</a></p>

<p>--</p>

<p>I assume for sufficiently large $n$ there are no solutions ?</p>

<p>In particular im intrested in $n=4,5,6$.</p>
",number_theory
"<p>I need to get integer solutions for the next equation: $$x^{2}-y^{4}=336$$ I know equations that look like $x^{2}-y^{2}=n$ have solutions $x$ and $y$ where $x=\frac{a+b}{2}$ and $y=\frac{a-b}{2}$, $a$ and $b$ being both odd or even. But I can not figure out how to solve the equation.</p>
",number_theory
"<p>Given a positive integer n, we have to calculate the following sum in the most efficient way: 
$$ \sum_{i=1}^n\frac{n}{\gcd(i,n)}$$</p>

<p>I think it is equivalent to:</p>

<blockquote>
  <p>On the set {1,2,…,N}{1,2,…,N} iterate the NN-cycle (12⋯N)(12⋯N) MM
  times. In the resulting permutation, what is the length of the cycle
  that contains 11?</p>
</blockquote>

<p>which is  N/gcd(N,M)</p>
",number_theory
"<p>Notation: </p>

<ul>
<li>$p$ - a prime integer,  </li>
<li>$\Bbb{Z}_p$ - set of $p$-adic integers,</li>
<li>$\Bbb{Q}_p$ - set of $p$-adic rationals,</li>
<li>$\Bbb{Q}$ - set of rationals,</li>
<li>$\Bbb{R}$ - set of reals.</li>
</ul>

<p>While reading up on $p$-adic numbers I came to know that $\Bbb{Z}_p$ is both open and closed in $\Bbb{Q}_p$. Since $\Bbb{Z}_p$ is properly contained in $\Bbb{Q}_p$ and is also a clopen set in $\Bbb{Q}_p$ we observe that $\Bbb{Q}_p$ is not connected. This was a bit of a surprise to me as the completion of $\Bbb{Q}$ in the Archimedean metric is $\Bbb{R}$ which is connected. </p>

<p>This made me curious as to what are the connected components of $\Bbb{Q}_p$ and whether there is a characterization for the components in terms of the $p$-adic metric (or any characterization at all). But I couldn't find anything on doing a Google search. </p>

<p>Hence, I thought it best to ask this question here in the hope that others might also find it interesting and something might come up. </p>

<p>So finally my question is - What are the connected components of $\Bbb{Q}_p$ and what interesting information do they tell us? Further, how do we compare or contrast this situation with that of $\Bbb{R}$? </p>
",number_theory
"<p>We know that :
$( x.y )$ mod $m$ = ( ($x$ mod $m$) . ($y$ mod $m$) ) mod $m$</p>

<p>Is there any property for:
$\frac{x}{y}$ mod $m$ like  $\frac{x \mod m}{y \mod m}$ mod $m$ . I hope this fails.</p>

<p>I want to find an efficient way to solve:
$$\frac{x_1 .x_2.x_3 ... x_i }{y_1 . y_2 . y_3 . . .y_j} \mod \ m$$
where, $x_i, x_j, m \le 10 ^9 ; $
and $\frac{x_1 .x_2.x_3 ... x_i }{y_1 . y_2 . y_3 . . .y_j}$ results in an integer</p>

<p><strong>Edit: If $a \ mod \ m = \ x$ and $b \mod m =\ y$, then can we express $(\frac{a}{b} \ mod \ m)$ in terms of x, y and m ??</strong></p>

<p>Any help will be appreciated :) Thanks</p>
",number_theory
"<p>My question is whether (*) below can be shown using the Erdős-Kac theorem? I don't think the distinction between $\Omega$ and $\omega$ is important here.</p>

<p>For lack of better notation let $\lambda_{r,s}(i) := 1$ if $ \Omega(i)\equiv s~ \text{(mod r)}$ and zero otherwise.  For $ (0\leq s,\hat{s}&lt; r)$ and $s\neq \hat{s},$</p>

<blockquote>
  <p>$$(*)\hspace{15mm} \sum_{i\leq n} \lambda_{r,s}(i) \sim \sum_{i\leq n} \lambda_{r,\hat{s}}(i)  $$</p>
</blockquote>

<p>Briefly the E-K theorem says that </p>

<p>$$\frac{\omega(n)-\log\log n}{\sqrt{\log\log n}}$$</p>

<p>is normally distributed. So the idea would be that for large n the area under the gaussian curve can be divided into bands (mod $r$) and the sums of areas for each $s ~\text{(mod r)}$ are roughly equal, with the caveat that for $r &gt; 2$ the numbers have to be very large for this to work.    </p>

<p>For $r = 3,~ n = 2^{22}$ we already have for $s \equiv 0,2,1,$ </p>

<p>$\sum_i \lambda_{3,0}(i)/n = 0.3320,$ </p>

<p>$\sum_i \lambda_{3,2}(i)/n = 0.3505, $ </p>

<p>$\sum_i \lambda_{3,1}(i)/n = 0.3174,  $</p>

<p>Note also: $r$ is fixed as n grows.  </p>
",number_theory
"<p>For a quadratic character $ \chi \bmod m $, define $\displaystyle r_\chi(n)=\sum_{d\,\mid\, n}\chi(d) $. I would like to prove that</p>

<p>$$\sum_{n \leq m }\frac{r(n)}{n} \ll \frac{m}{\varphi(m)}\exp \Big( 2 \sum_{\substack{p \,\leq\, m \\ p \text{ prime} \\ \chi(p)\,=\,1}} \frac{1}{p} \Big) $$</p>

<p>I think I found a characterization of $ r_{\chi} $: </p>

<p>$$r_\chi(n)=\prod_{p^e\,\|\,n}(1+\chi(p)+\cdots+\chi(p)^e)$$</p>

<p>$$ r_\chi(n)=\begin{cases}0
&amp; \text{if } \exists \text{ prime } p\mid n \text{ such that }  e_p(n) \text{ is odd and } \chi(p)=-1 \\ 
\tau(n) &amp; \text{if  all the primes } p\mid n \text{ are residues} \\ 
\tau(\frac{n}{m}), &amp; \text{otherwise} 
\end{cases} $$</p>

<p>Here $\tau(n)$ represents as usual, the number of divisors of $n$ and $\displaystyle m= \!\!\! \prod_{\substack{p^e\,\|\,n \\  \ \chi(p)=1}}p^e $.</p>

<p>I apologize for my bad latex skills and would appreciate any comments, ideas and sugestions. Thank you very much!</p>
",number_theory
"<p>I have a conjecture which I cannot prove or disprove.</p>

<p>Denote the $i$'th digit of $x$ in binary expansion by $d_i(x)$, where for $i=1$ the MSB is taken. Example: $d_3(110.1)=0$ and $d_4(110.1)=1$ (so it just ignores the dot).</p>

<p>Denote by $p_i$ the $i$'th prime number, i.e. $p_1=2, p_2=3, p_3=5$ and so on.</p>

<p>Let $$h_i^j(x)=\frac {d_i(x)} {p_i^{p_{2j}}}$$ if the $i$'th digit of $x$ is left to the decimal point, and $$h_i^j(x)=\frac {d_i(x)} {p_i^{p_{2j+1}}}$$ otherwise.</p>

<p>Define $f(x):\mathbb R^n\rightarrow\mathbb R$ as: </p>

<p>$$f(x)=\sum_{j=1}^n \sum_{i=1}^\infty  h_i^{j+in}(x_j) $$</p>

<p>Conjecture: $f$ is injective and finitely integrable over any finite measure balls on $\mathbb R^n$.</p>

<p>Caution: some explanations might work well for rational numbers only.</p>

<p>Please, if you think if it's incorrect, try to see if you can slightly modify $f$ to make the conjecture correct.</p>

<p>Thanks!!!</p>
",number_theory
"<p>I learned quadratic congruence by myself and stuck in these problems:</p>

<ol>
<li><p>I know if quadratic congruence $X^2=a(\mod\mbox{ p} )$ with $p$ is an odd prime number and $\gcd(a,p)=1$, then it has no solution or has exactly two solutions. So,
what is Theorem/Lemma that guarantee a quadratic congruence has solutions?</p></li>
<li><p>For linear congruence, we can use the extended Euclidean algorithm to find solution of linear congruence. So my question, what is method to find solution of quadratic congruence?</p></li>
</ol>

<p>I would really appreciate if anyone could help me out here</p>
",number_theory
"<p>Prove that for any natural number a and prime number p, $a^{p^{p-1}}\equiv a$ mod p. </p>
",number_theory
"<p>The rule of Mersenne Prime says that $2^p - 1$ is prime if $p$ is prime.</p>

<p>$2^{11} - 1 = 2047$ satisfies the condition, but it's not a prime as it can be divided by two prime numbers $23$ and $89$. Then, why do we use Mersenne Prime thing at all?</p>

<p>Last I checked, the biggest known prime today is a Mersenne Prime. Can't it be wrong?</p>
",number_theory
"<p>Prove that if $\sigma(n)=2n+1$ then $n$ is an odd perfect square.</p>

<p>(Here, $\sigma(n)$ is the sum of the positive divisors of $n$
including 1 and $n$ itself.)</p>

<p>As I know, this $n$ is a quasiperfect number, and I just proved that $n$ is a perfect square or $\frac{n}{2}$ is a perfect square.</p>
",number_theory
"<p>I recall reading a proof that showed these two sets were equinumerous, but I'm having trouble finding it. Is there any intuitive method to show that they are in fact equinumerous? It seems like since $[0,1]$ is a subset of $\mathbb{R}$ that $\mathbb{R}$ should be larger.</p>
",number_theory
"<p>What I need to show is that</p>

<p>For $\gcd(ab,p)=1$ and p is a prime, </p>

<p>the number of solutions of the equation $ax^2+by^2\equiv 1\pmod{p}$ is exactly $p-(\frac{-ab}{p})$.</p>

<p>I got a hint that I have to use Legendre symbol from the answer.</p>

<p>I think that I may count a solution one by one.</p>

<p>What I did :</p>

<p>$$(ax)^2 \equiv a-aby^2 \pmod{p}$$
It suffices to count $y$ such that $(\frac{a-aby^2}{p})=1$.</p>

<p>I tried to use the complete residue system or a primitive root but it didn't work.</p>

<p>The factorization also didn't work.</p>

<p>I think that the pigeonhole principle may not work because it just says the existence.</p>

<p>Thanks in advance.</p>
",number_theory
"<p>Does a subset of $R$ contain equal number of rational and irrational numbers? How to prove?</p>
",number_theory
"<p>I have the following expression</p>

<p>$$\frac{gcd(a,b)}{\varphi(gcd(a,b))}$$</p>

<p>$a,b$ are known positive integers. Is there any way to rephrase this or simplify it?</p>
",number_theory
"<p>The question is what are the possible values of $x$ when we have</p>

<p>$$x^{x^3} = 3$$</p>

<p>(that is $x^3$ in the exponent itself and not $x*3$).</p>

<p>I solved one answer by guessing that $x = \sqrt[3]3$. My work is below however I was only able to solve it assuming $x = \sqrt[3]3$, can anyone solve it without the assumption. I suspect that logarithms are involved which I have to review. Also there are supposed to be more solutions to this than just the one mentioned. Thanks in advance and enjoy. It's a fun problem<img src=""http://i.stack.imgur.com/eU36P.jpg"" alt=""![enter image description here"">]<a href=""http://i.stack.imgur.com/eU36P.jpg"" rel=""nofollow"">1</a></p>
",number_theory
"<p>Given two integers $N$ and $M$ , How to find out number of arrays A of size N, such that : </p>

<ol>
<li>Each of the element in array, $1 ≤ A[i] ≤ M$</li>
<li><p>For each pair i, j ($1 ≤ i &lt; j ≤ N$) </p>

<p>$GCD(A[i], A[j]) = 1$</p></li>
</ol>

<p>$M$ can be at max $100$. But $N$ can be upto $100000$. Is there some direct mathematical formula for the same ?</p>

<p>Example to make question clear : Say $N=3$ and $M=3$ then answer is $13$.</p>
",number_theory
"<p>Find the sum of all even positive divisors of 1000.</p>

<p>I prime factorised 1000 but the answer was not coming.</p>
",number_theory
"<p>I learnt at this <a href=""http://googology.wikia.com/wiki/Fast-growing_hierarchy"" rel=""nofollow"">site</a> that</p>

<p>$$\large f_{\omega^\omega}(n)\approx \underbrace{[n,...,n]}_{n\ n's}$$</p>

<p>For a simular approximation</p>

<p>$$\large f_{\omega^2}(n)\approx \underbrace{n\rightarrow n\rightarrow...\rightarrow n\rightarrow n}_{n\ n's}\ =:\ g(n)$$</p>

<p>Wythagoras concreted this approximation to the inequality</p>

<p>$$\large g(n+1)&lt;f_{\omega^2}(n)&lt;g(n+2)\ \ for\ \ n\ge 2$$</p>

<p>Is there a similar inequality in this case ?</p>
",number_theory
"<p>If you know $\phi (n)$ how can you derive the prime factorization of $n$ from this? For example, $\phi(100) = 40$, but how does $40$ help us come to $2^25^2$?</p>
",number_theory
"<p>As we know $\sqrt{2},\sqrt{3}$ are irrational numbers. And I see some proofs on the net.</p>

<p>So I doubt that how $e,\pi$ or already known irrational numbers are proved to be irrational.</p>

<p>In fact, I got interested in Riemann zeta function
$$\zeta(s)=\sum_{n=0}^{\infty} \frac{1}{n^s},$$</p>

<p>we know $\zeta(2)=\pi^2/6$ from Euler, 1737.</p>

<p>One mathematician (sorry to forgot his name) proved $\zeta(3)$ to be also irrational 40 years before.</p>

<p>Can somebody explain how he could do with that? To understand Apéry's theorem, is it very hard?</p>

<p>An question raises that could one real number make up of two different irrationals (for example: $e,\pi$), $e\pi$, or others can be rational?</p>
",number_theory
"<p>Diophantine equation. $X^2+Y^2=qZ^3$</p>

<p>I wonder at what values ​​of the coefficient $q$ equation has a solution.</p>

<p>And of course I wonder how she looks like a formula describing their solutions.</p>

<p>For the special case when $X^2+Y^2=Z^3$ You can get a basic formula.</p>

<p>Has the solutions:</p>

<p>$X=2k^6+8tk^5+2(7t^2+8qt-9q^2)k^4+16(t^3+2qt^2-tq^2-2q^3)k^3+$</p>

<p>$+2(7t^4+12qt^3+6q^2t^2-28tq^3-9q^4)k^2+8(t^5+2qt^4-2q^3t^2-5tq^4)k+$</p>

<p>$+2(q^6-4tq^5-5q^4t^2-5q^2t^4+4qt^5+t^6)$</p>

<p>.................................................................................................................................................</p>

<p>$Y=2k^6+4(3q+t)k^5+2(9q^2+16qt+t^2)k^4+32qt(2q+t)k^3+$</p>

<p>$+2(-9q^4+20tq^3+30q^2t^2+12qt^3-t^4)k^2+4(-3q^5-tq^4+10q^3t^2+6q^2t^3+5qt^4-t^5)k-$</p>

<p>$-2(q^6+4tq^5-5q^4t^2-5q^2t^4-4qt^5+t^6)$</p>

<p>.................................................................................................................................................</p>

<p>$Z=2k^4+4(q+t)k^3+4(q+t)^2k^2+4(q^3+tq^2+qt^2+t^3)k+2(q^2+t^2)^2$</p>

<p>$q,t,k$ - What are some integers any sign.  After substituting the numbers and get a result it will be necessary to divide by the greatest common divisor. This is to obtain the primitive solutions.</p>
",number_theory
"<p>Let $p$ be an odd prime and $a, b \in \Bbb Z$ with $p$ doesn't divide $a$ and $a$ doesn't divide $b$. Prove that among the congruence's $x^2 \equiv a \mod p$, $\ x^2 \equiv b \mod p$, and $x^2 \equiv ab \mod p$, either all three are solvable or exactly one.</p>

<p>Please help I'm trying to study for final in number theory and I can't figure out this proof.</p>
",number_theory
"<p>If a positive integer $n$ is both a perfect square and a perfect cube , then is it true that $7$ divides $n(n-1)$ ?  </p>
",number_theory
"<p>I was reading some <a href=""http://www.math.uconn.edu/~kconrad/blurbs/gradnumthy/SL2classno.pdf"" rel=""nofollow"">notes</a> of Keith Conrad where he proves that the number of orbits of the $\text{SL}(2,\mathcal{O}_K)$-action on $\mathbb{P}^{1}(K)$ for a number field $K$ is precisely the class number of $K$.</p>

<p>I am wondering if there is any kind of ""higher-order"" arithmetic information found in looking at the number of orbits of the $\text{SL}(n,\mathcal{O}_K)$-action on $\mathbb{P}^{n-1}(K)$ for $n&gt;2$ (or even on higher Grassmannians $\text{Gr}(r,K^{n})$, but let's not get too crazy for now). As a first question, will these numbers even be finite for all $n$?</p>

<p>For $K=\mathbb{Q}$, I believe one can use a generalized Euclidean algorithm to show that the action above is transitive for all $n$, at least for the projective spaces $\mathbb{P}^{n-1}(\mathbb{Q})$, but I'm not sure if one can adapt this argument to work even for $\mathcal{O}_K$ that are UFDs but not Euclidean.</p>

<p>Does anyone know of any references on this question?</p>
",number_theory
"<p>How many odd primes $p$ are there such that both $ \dfrac {p+1}2$ and $\dfrac{p-1}4$ are primes ?</p>
",number_theory
"<p>Does an algebraic number field $\mathbb{Q}\bigl(\sqrt[3]{d}\bigr)$ with $d$ cube-free exist, which contains a non-integral element $\alpha$ with integer trace and integer norm?</p>
",number_theory
"<p>Let $x$ be a positive integer and $y = x^2 + 2$. Can $x$ and $y$ be both prime? The answer is yes,
since for $x = 3$ we get $y = 11$, and both numbers are prime. Prove that this is the only value of x for which both x and y are prime.</p>

<p>I have to somehow prove this is true, and the only hint we were given is that we should consider cases depending on the remainder of $x$ modulo $3$. Does anyone have any tips on how to start proving this is true?</p>
",number_theory
"<p>The <a href=""http://en.wikipedia.org/wiki/Van_der_Waerden%27s_theorem"">van der Waerden theorem</a> states that given any natural numbers $k$ and $r$, there exists a natural number $W=W(k,r)$ such that if the set $\{1,2\cdots W\}$ is divided into $r$ classes (also called colors) then there exists a $k$-term arithmetic progression in one class.</p>

<p>I am trying to prove the theorem according to the outline given <a href=""http://en.wikipedia.org/wiki/Van_der_Waerden%27s_theorem#Proof_of_Van_der_Waerden.27s_theorem_.28in_a_special_case.29"">here</a>. </p>

<p>I have understood the proofs for $W(3,2) \le 325$ and $W(3, 3) \le 7(2·3^7+1)(2·3^{7·(2·3^7+1)}+1)$ and on similar lines have worked out a proof for $W(3,4)\le 9(2.4^9+1)(2.4^{9(2.4^9+1)}+1)(2.4^{9(2.4^9+1)(2.4^{9(2.4^9+1)}+1)}+1)$. </p>

<p>What I want to do is to prove the theorem in general on similar lines. The main problem is for me as to what will be the upper bound to start off with and then how to deal with the cumbersome notation. </p>

<p>I understand asking someone to prove the full result is not appropriate here, but if you can give me any help I will greatly appreciate it.</p>

<p>Thanks.</p>
",number_theory
"<p>Let $c_1,c_2,\ldots,c_{\varphi(m)}$ be the reduced residue set modulo $m&gt;2$. Show that $$c_1+c_2+\cdots+c_{\varphi(m)} \equiv 0 \pmod{m}.$$</p>

<p>My solution looks something like this.</p>

<p>If $c_i \in {\mathbb{Z}_m}^*$, then $m-c_i \in {\mathbb{Z}_m}^*$. Hence, we may take the reduced residue system $$\{c_1,c_2,\ldots,c_{\varphi(m)/2},m-c_{\varphi(m)/2},\ldots,m-c_2,m-c_1\}.$$</p>

<p>Hence, 
\begin{align} 
c_1+c_2+\cdots+c_{\varphi(m)} &amp;= c_1+c_2+\cdots+c_{\varphi(m)/2}+m-c_{\varphi(m)/2}+\cdots+m-c_2+m-c_1 \\
&amp;=m \cdot \varphi(m)/2 \equiv 0 \pmod{m},
\end{align}</p>

<p>since $\varphi(m)$ is even for $m &gt;2$.</p>

<p>Is this on the right track?</p>
",number_theory
"<blockquote>
  <p>Find all positive integers $x,y,z$ that satisfy: </p>
  
  <p>$$3^x - 5^y = z^2.$$ </p>
</blockquote>

<p>I think that $(x,y,z)= (2,1,2)$ will be the only solution. But how to prove that?</p>
",number_theory
"<p>Let $\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}$. We have $\frac{\zeta'}{\zeta}(s) = \sum_{n=1}^\infty \frac{\Lambda(n)}{n^s}$ for $s&gt;1$, where $\Lambda$ stands for the von Mangoldt function (<a href=""http://en.wikipedia.org/wiki/Von_Mangoldt_function"" rel=""nofollow"">http://en.wikipedia.org/wiki/Von_Mangoldt_function</a>).
It is easy to prove that there exists a constant $A$ such that $-\frac{\zeta'}{\zeta}(s) \leq \frac{1}{s-1} + A$ for every $s&gt;1$. By plotting $-\frac{\zeta'}{\zeta}(s)-\frac{1}{s-1}$ or $-\frac{\zeta'}{\zeta}(s)\cdot(s-1)$ on any computation program, it seems fair to conjecture that we can choose $A=0$. Unfortunately, I am unable to prove this. Is it a well-known inequality? Does anyone know how to prove this, if true?</p>

<p>I tried to use the formula $-\frac{\zeta'}{\zeta}(s) = \frac{1}{s-1} + 1 + s \int_1^\infty \frac{\psi(t)-t}{t^{s+1}} \mathrm{d}t$, where $\psi(x) = \sum_{n \leq x} \Lambda(n)$, but the erractic behavior of $\psi$ makes it useless (and any Chebyshev-type inequality does give $A&gt;0$).</p>

<p>Thanks in advance.</p>
",number_theory
"<p>I am trying solve this form, but it appears not easy problem, and also I can't find references about it. </p>

<p>I suppose some constrains should be stated, like ""$b,y &gt; 1$"" and ""$\gcd(a,b) \gcd(x/y) = 1$"" .</p>

<p>Here some examples
$$
\left( \frac{17}{21} \right)^{3} + \left(\frac{37}{21} \right)^{3} = 6
$$
$$
\left(\frac{73}{38} \right)^{3} - \left( \frac{17}{38}\right)^{3} = 7
$$</p>

<p>Example with two solutions
$$
\left(\frac{36}{13}\right)^{3} - \left(\frac{17}{13}\right)^{3} = \left( \frac{109}{31}\right)^{3} - \left(\frac{90}{31}\right)^{3} = 19
$$
Solutions to this problem seems to be scarce, so can any integer be written in this form?</p>

<p>Thanks</p>
",number_theory
"<p>I need your support.</p>

<p>Suppose I am performing an NTT in a finite field $GF(p)$. I assume it contains the needed primitive root of unity.</p>

<p>I am using it to compute the convolution of two vectors of length $n=2^m, m\in \mathbb{N}$. As usual, I double the length of the vectors to $2n=2^{m+1}$ to make the convolution in fact acyclic (right? may be wrong here) and thus guarantee the exact interpolation of the product during INTT. </p>

<p>These vectors are in fact long integers, with all coefficients less than $BASE\in\mathbb{N}$. I wanted to come up with an inequality for the prime number $p$ so that the convolution is recoverable (i.e. equal to the real product of polynomials). </p>

<p>Here are my considerations:</p>

<p>The worst case is when all coefficients of the vectors are equal to $BASE-1$. Then the convolution coefficients are</p>

<p>$$c_0 = a_0 b_0 = (BASE-1)^2$$
$$c_1 = a_0 b_1 + a_1 b_0 = 2\cdot (BASE-1)^2$$
$$...$$
$$c_{n-1} = a_0 b_{n-1} + ... + a_{n-1} b_0 = n\cdot (BASE-1)^2$$
$$c_n = \underbrace{a_0 b_n}_{=0} + a_1 b_{n-1} + ... + a_{n-1} b_1 + \underbrace{a_n b_0 }_{=0} = (n-1)\cdot (BASE-1)^2$$
...
$$c_{2n-1}=0$$.</p>

<p>Thus I have come up with an inequality for the prime $p$:</p>

<p>$$n \cdot (BASE-1)^2 &lt; p.$$</p>

<p>Does it guarantee that the convolution is computed correctly or have I missed something?</p>
",number_theory
"<p>In Calculus, whenever we see a constant and want to take the derivative of it, it always is 0. However in Number Theory, we have something called the arithmetic derivative in which we can differentiate to get some nonzero term. 
So we can denote the arithmetic derivative the same way as in calculus, say for some $x$, we can say $x'$ to be the arithmetic derivative. Some properties of arithmetic derivatives are that:</p>

<ul>
<li>For all primes, the arithmetic derivative is $1$.</li>
<li>Product Rule: $(xy)'=x'y+xy'$</li>
<li>$0'=1'=0$</li>
</ul>

<p>Now, there is also some lesser-known sub-part to the arithmetic derivative called the Arithmetic Logarithmic Derivative, $L(n)$, which is equal to $\frac{n'}{n}$. My question is that less than $100$, how many pairs of distinct positive integers (call them $a$ and $b$) does $L(a)=L(b)$?</p>
",number_theory
"<p>This question arose through a response to [this post] <a href=""http://math.stackexchange.com/questions/1644522/is-there-any-partial-sums-of-harmonic-series-that-is-integer/1644552#1644552"">Is there any partial sums of harmonic series that is integer?</a></p>

<p>For which integers $N&gt;1$ does the fraction $\frac 1N$ appear in the Egyptian Fraction expansion of $\frac {N-1}{N}$?</p>

<p>To specify: As such expansions are not unique, I should say which one I refer to. Here we consider the expansion obtained through the greedy algorithm.  </p>

<p>Thus $$\frac 12=\frac 12\;\;\&amp;\;\;\frac 34=\frac 12+\frac 14\;\;\&amp;\;\;\frac {11}{12}=\frac 12+\frac 13+\frac 1{12}$$ are easy examples.</p>

<p>A quick search for $N&lt;100$ yields $N=\{2,4,12,84\}$ as examples.  Taking that (short) list to OEIS leads to $[A053631][1]$, the sequence $a_i$ starting with $a_1=2$ and having the property that, for $i&gt;1$, $\{a_{i-1}+1,a_i,a_i+1\}$ are a Pythagorean triple. That sequence continues from $84$ as $3612,\, 6526884,\, 21300113901612,\dots$ and it is easy to verify that those three, at least, are examples for the present question as well.</p>

<p>Are these all examples?  Are there others?</p>

<p>Edit:  as remarked in the comments, in each of the cases cited above, $\frac 1N$ appears as the final term in the expansion.  </p>
",number_theory
"<p>I would like to prove the following equality</p>

<p>$$\sum_{n=1}^N \mu^2(n) = \sum_{k=1}^{\sqrt{N}} \mu(k) \cdot \lfloor N / k^2 \rfloor$$</p>

<p>with N a square number.</p>

<p>Can anyone give me a hint?</p>

<p>p.s. I know already that</p>

<p>$$\frac{\zeta(s)}{\zeta(2s) } = \sum_{n=1}^{\infty}\frac{ \mu^2(n)}{n^{s}}$$</p>

<p>Perhaps this can help?</p>
",number_theory
"<blockquote>
  <p>Find 
  $$ \sum_{n=1}^{\infty}\sum_{m=1}^{\infty}\sum_{p=1}^{\infty}\frac{1}{mnp(m+n+p+1)}. $$</p>
</blockquote>

<p>Use $$ \frac{1}{m+n+p+1}=\int_{0}^{1}{{{t}^{m+n+p}}\,dt} $$ so the sum equals $ -\int_0^1\ln^3(1-t)\,dt. $</p>

<p>But I don't understand the way that sum is that integral (or how the integral is distributed or something like this).</p>

<p>Help $\ddot\smile$</p>
",number_theory
"<p>Assuming the Riemann hypothesis is true, is it really possible to find high prime numbers more easily?</p>
",number_theory
"<p>Suppose $x$ and $y$ are some integers satisfying $$x^2-16=y^3.$$ I'm trying to show that $x+4$ and $x-4$ are both perfect cubes.</p>

<p>I know that the greatest common divisor of $x+4$ and $x-4$ must divide $8$, but I don't know where to go from there. Would anyone be able to help?</p>
",number_theory
"<p>I came across with the infinite series
$$\sum_{n=1,3,5,\ldots}^{\infty} \frac{1}{n^4}= \frac{\pi^4}{96}$$
when calculating a problem about an infinite deep square well in quantum mechanics.</p>

<p>Mathematica gives the result in the title, which is enough for a physics problem. But I just want to find how to evaluate the series. I think this sum should be connected to $\zeta(4)=\pi^4/90$, but can't figure out their relation. </p>
",number_theory
"<blockquote>
  <p>What is the sum of the digits of the smallest positive integer $n^4 + 6n^3 + 11n + 6$ is divisible by $700$. </p>
</blockquote>

<p><strong>Hints please.</strong></p>

<p>I got that $P(n) = n(n+1)(n+2)(n+3) \equiv 0 \pmod{700}$</p>

<p>I cannot seem to do anything else, what now?</p>

<p><strong>Hints only.</strong></p>
",number_theory
"<p>As a background, Ramanujan also gave a continued fraction for $\zeta(3)$ as</p>

<p>$\zeta(3) = 1+\cfrac{1}{u_1+\cfrac{1^3}{1+\cfrac{1^3}{u_2+\cfrac{2^3}{1+\cfrac{2^3}{u_3 + \ddots}}}}}\tag{1}$</p>

<p>where the sequence of $u_n$, starting with $n = 1$, is given by the <em>linear</em> function</p>

<p>$u_n = 4(2n-1) = 4, 12, 20, 28, \dots$</p>

<p>This has rather slow convergence. Using an approach similar to Apéry's of finding a faster converging version, I found via <em>Mathematica</em> that,</p>

<p>$\zeta(3) = \cfrac{6}{v_1 + \cfrac{1^3}{1 + \cfrac{1^3}{v_2 + \cfrac{2^3}{1 + \cfrac{2^3}{v_3 +\ddots}}}}}\tag{2}$</p>

<p>where the $v_n$ are now given by the <em>cubic</em> function</p>

<p>$v_n = 4(2n-1)^3 = 4, 108, 500, 1372, \dots$</p>

<p><em>Question</em>: Can anyone prove that (2), with $v_n$ defined by the cubic function, is indeed true?</p>

<p><em>Postscript</em>: A short description of Apéry's accelerated continued fractions for $\zeta(2)$ and $\zeta(3)$ is given <a href=""http://tpiezas.wordpress.com/2012/05/04/continued-fractions-for-zeta2-and-zeta3/"">here</a>.</p>
",number_theory
"<p>So the question is in the title. And I mean dense in positive real numbers ofcourse. Somehow I cannot grasp if this is very trivial or not. The prime numbers aren't that dense, but are there enough of primes to make the fractions constructed from them dense?</p>
",number_theory
"<p>Let $a \in (\mathbb{Z/nZ})^\times$ then $ax+ny = 1$ for some $x,y\in \mathbb{Z}$</p>

<p>$$-a = n - a$$</p>

<p>Then</p>

<p>$$ny = 1 - ax = 1 + (-a)x$$ </p>

<p>Putting value of -a</p>

<p>$$ny = 1 + (n-a)x \qquad \implies (a-n)x + ny = 1 \qquad \implies ax + n(y-x) = 1$$ </p>

<p>Am I right?</p>
",number_theory
"<p>Given small $\epsilon&gt;0$ how small should $n\in\Bbb N$ be such that if $a,b,c,d,q,r,u,v,x,y,m,m'\in\Bbb N$ with $gcd(a,b)=gcd(a,x)=gcd(b,y)=1$ the following relations can hold with constraints $c,d=(n^3,2n^3)$, $a,b\in(n,2n)$, $x\in(1,a)$, $y\in(1,b)$, $m,m'=\theta(n)$ ($\theta$ is landau function), $u,v\in(n^{2+\epsilon},2n^{2+\epsilon})$ and $q,r\in(n^4,2n^4)$? 
$$c{b^2}=au + qm,\quad q=ca-x$$
$$d{a^2}=bv + rm',\quad r=db-y$$</p>

<p>In other words given small $\epsilon&gt;0$ and large $n\in\Bbb N$ how many $a,b,c,d,q,r,u,v,x,y,m,m'\in\Bbb N$ satisfy these constraints?</p>

<hr>

<p>Note these imply $$c^2b^2-cqm=qu+xu$$ $$d^2a^2-drm'=rv+yv$$</p>
",number_theory
"<p>I am curious about the frequency of occurance of prime numbers in natural numbers. For example starting with the first non-prime 4 = 2^2, then 6 = 2x3, 8 = $2^3$, 9 = $3^2$ etc. Now of course a prime can not be a factor of a number $n \in \mathbb{N}$. Thus taking prime factorization of larger numbers to see some more interesting sets of primes. </p>

<p>1674 = $2^1 \times 3^3 \times 31^1$</p>

<p>1675 = $5^2 \times 67^1$</p>

<p>1676 = $2^2 \times 419^1$</p>

<p>and so on. I am wondering if there has been research done on the frequency of primes. I have found much about how prime numbers themselves are distributed among the natural numbers - but nothing about the frequency of their occurrences as constituents of numbers.</p>

<p>Thanks for any insight, or references to this subject matter.</p>

<p>Thanks,</p>

<p>Brian</p>
",number_theory
"<p>Let $S$ be a set of size $n$.  There is an easy way to count the number of subsets with an even number of elements.  Algebraically, it comes from the fact that</p>

<p>$\displaystyle \sum_{k=0}^{n} {n \choose k} = (1 + 1)^n$</p>

<p>while</p>

<p>$\displaystyle \sum_{k=0}^{n} (-1)^k {n \choose k} = (1 - 1)^n$.</p>

<p>It follows that </p>

<p>$\displaystyle \sum_{k=0}^{n/2} {n \choose 2k} = 2^{n-1}$.  </p>

<p>A direct combinatorial proof is as follows: fix an element $s \in S$.  If a given subset has $s$ in it, add it in; otherwise, take it out.  This defines a bijection between the number of subsets with an even number of elements and the number of subsets with an odd number of elements.</p>

<p>The analogous formulas for the subsets with a number of elements divisible by $3$ or $4$ are more complicated, and divide into cases depending on the residue of $n \bmod 6$ and $n \bmod 8$, respectively.  The algebraic derivations of these formulas are as follows (with $\omega$ a primitive third root of unity):  observe that</p>

<p>$\displaystyle \sum_{k=0}^{n} \omega^k {n \choose k} = (1 + \omega)^n = (-\omega^2)^n$</p>

<p>while</p>

<p>$\displaystyle \sum_{k=0}^{n} \omega^{2k} {n \choose k} = (1 + \omega^2)^n = (-\omega)^n$</p>

<p>and that $1 + \omega^k + \omega^{2k} = 0$ if $k$ is not divisible by $3$ and equals $3$ otherwise.  (This is a special case of the discrete Fourier transform.)  It follows that</p>

<p>$\displaystyle \sum_{k=0}^{n/3} {n \choose 3k} = \frac{2^n + (-\omega)^n + (-\omega)^{2n}}{3}.$</p>

<p>$-\omega$ and $-\omega^2$ are sixth roots of unity, so this formula splits into six cases (or maybe three).  Similar observations about fourth roots of unity show that</p>

<p>$\displaystyle \sum_{k=0}^{n/4} {n \choose 4k} = \frac{2^n + (1+i)^n + (1-i)^n}{4}$</p>

<p>where $1+i = \sqrt{2} e^{ \frac{\pi i}{4} }$ is a scalar multiple of an eighth root of unity, so this formula splits into eight cases (or maybe four).  </p>

<p><strong>Question:</strong>  Does anyone know a direct combinatorial proof of these identities? </p>
",number_theory
"<p>Let $\pi(x)$ be the number of primes not greater than $x$.</p>

<p><a href=""http://en.wikipedia.org/w/index.php?title=Prime-counting_function"">Wikipedia article</a> says that $\pi(10^{23}) = 1,925,320,391,606,803,968,923$.</p>

<p>The question is how to calculate $\pi(x)$ for large $x$ in a reasonable time? What algorithms do exist for that?</p>
",number_theory
"<p>A Fi-binary number is a number that contains only 0 and 1. It does not contain any leading 0. And also it does not contain 2 consecutive 1. The first few such number are 1, 10, 100, 101, 1000, 1001, 1010, 10000, 10001, 10010, 10100, 10101 and so on. I have n. How to calculate the nth Fi-binary number ?</p>
",number_theory
"<blockquote>
  <p>Find all triples $(a,b,c)$ of positive integers such that if $n$ is not divisible by any prime less than $2014$, then $\color{red}n+\color{red}c$ divides $\color{red}a^n+\color{red}b^n+\color{red}n$</p>
</blockquote>

<p>This problem is from the New Zealand TST 2014 and there is only one solution:</p>

<p>$\textbf{answer}$:$\color{red}(\color{red}a,\color{red}b,\color{red}c)\color{red}=(1,1,2)$</p>

<p>Can you someone help explain why there is only one solution?</p>
",number_theory
"<p>Can we prove by induction that for every integer $k &gt;1 $ , $2+2^k \choose r$ is even for all $2 &lt; r \le n=1+2^{k-1}$ ? Or by some divisibility properties of Binomial co-efficients ?</p>

<p>I wanted to start as $2^k \choose r$ $+$ $2$$2^k \choose r-1$ $+$ $2^k \choose r-2$ $=$$ 2+2^k \choose r$ but I don't know whether $2|{2^k \choose m}$ or not ... Please help . Thanks in advance  </p>
",number_theory
"<p>The question is this.</p>

<blockquote>
  <p>Suppose that p is a prime, $p\ge7$. Show that $(\frac np)=(\frac {n+1}p)=1$ for at least one number n in the set {1,2,...,9}.</p>
</blockquote>

<p>I think seperating into two cases when n=1 and when n=4 will help me prove it. But I can't think further...</p>

<p>Plz, HELP ME!!!!</p>
",number_theory
"<p><strong>Question:</strong></p>

<blockquote>
  <p>For any  $a,b\in \mathbb{N}^{+}$, if $a+b$ is a square number, then $f(a)+f(b)$ is also a square number. Find all such functions.</p>
</blockquote>

<p><strong>My try:</strong> It is clear that the function
$$f(x)=x$$ satisfies the given conditions, since:
 $$f(a)+f(b)=a+b.$$</p>

<p>But is it the only function that fits our needs? </p>

<p>It's one of my friends that gave me this problem, maybe  this is a Mathematical olympiad problem.  Thank you for  you help.</p>
",number_theory
"<p>$$s^{2}=4m^{2}n^{2}+p^{2};
p^{2}=m^{2}+n^{2};
1&lt;m&lt;n&lt;p&lt;s$$
I think that this equation does not have positive Integer solution, but how to prove?</p>
",number_theory
"<p>Use Polya's enumeration to determine the number of six-sided dice that can be manufactured if each of three different labels must be placed on two of the faces. </p>

<p>Can you help me please to solve this exercise ? I have looked for Polya's enumeration formula on Wikipedia but it is very strange for me. </p>

<p>Thanks :)</p>
",number_theory
"<p>Using Burnside's Lemma find out: </p>

<p>How many different necklaces having $5$ beads can be formed using $3$ different kinds of beads, if we discount :</p>

<p>(a) Both flips and rotations?</p>

<p>(b) Rotations only?</p>

<p>(c) Flips only?</p>

<p>I don't know how to apply this lemma. Have you some solved exercises?</p>

<p>thanks :) </p>
",number_theory
"<p>Is it possible that there be something simple and essential in number theory that great mathematicians could have missed so that we still do not have any proof of Riemann Hypothesis?</p>

<p>Is it meaningfully probable to take the consideration that conjectures like Riemann Hypothesis, Twin Prime conjecture etc are elementary but that we have missed something in number theory to find that simple $7$ page proof that an average undergraduate could understand?</p>
",number_theory
"<p>I have been studying cuban primes and while the official definition of cuban primes contains only two variations, I have also seen a reference to generalized cuban primes, which has a much larger set. I have also seen on only one site a third variation of the equation where the difference between the first and second cubed number is four, instead of one or two, which are the ones included in the official definition, and is a subset of generalized cuban primes (from what I can tell). </p>

<p>What exactly is the difference between generalized cuban primes and cuban primes, other than the equation that defines them? Do generalized cuban primes essentially state that there are more than two variations of the classic definition of cuban primes?</p>

<p>Cuban primes are defined as $\frac{x^3-y^3}{x-y}$, and generalized cuban primes are defined as ""primes of the form $x^2 + xy + y^2$; or primes of the form $x^2 + 3y^2$; or primes $\equiv 0$ or $1 \pmod 3$."" </p>

<p>The two officially recognized forms of cuban primes are those where $y=x+1$ and $y=x+2$, and the ""unofficial"" third form that I have seen one mention of on oeis.org is where $y=x+4$. I have been unable to find any other variations (such as $y=x+5$) even in oeis.org, however if it is applied, $y=x+5$ seems to be a subset of the generalized cuban primes.</p>
",number_theory
"<p>A monotonic number is a number in which the digits are in non-decreasing order. I found by computer that most of these numbers are squares of these numbers 
$$3 \ldots 34,3 \ldots 35,3 \ldots 37,3 \ldots 367,3\ldots 36 \ldots 7,16\ldots 67$$ 
My question is if there are finite amount of exceptions. I found in <a href=""http://math.fau.edu/Yiu/RecreationalMathematics2003.pdf"" rel=""nofollow"">this</a> (page 133) that if you are squaring only monotonic numbers then there are a finite amount of exceptions.</p>
",number_theory
"<p>Given a prime $p$ and positive integer $t \ll \log p$ (say $t = \sqrt{\log p}$), is there an  algorithm that is polynomial time in $\log p$ to sample uniform $X, Y \in \mathbb{F}_p$ conditioned on the following constraints:</p>

<p>1) For some $a \in \mathbb{F}_p$, $$X Y = a \mod p.$$
2) Express $X$ as a bitstring $X_1 \ldots X_{\lceil \log p\rceil}$ using the binary representation. Then the $\lceil \log p\rceil$ binary random variables so obtained lie in a given subspace of $\mathbb{F}_2^{\lceil \log p \rceil}$ of dimension $\lceil\log p\rceil - t$. </p>

<p>3) Same condition as 2) for $Y_i$'s.</p>

<p>I will be happy to get any pointers or reference for this. Even some intuition on why this might or might not be true will be helpful.</p>
",number_theory
"<p>Let $m\geq 3$, I need to show that  $ d \equiv 0 \ mod \ m $ where $d=\sum_{i \in (\frac{\mathbb{Z}}{m\mathbb{Z}})^*} i$ .</p>

<p>That is if we sum all elements in the group of units in $\frac{\mathbb{Z}}{m\mathbb{Z}}$,then it divisible by $m$. </p>
",number_theory
"<p>Suppose we are given a continued fraction $$\frac{p}{q}=a_{1}+\frac{1}{a_{2}+\frac{1}{a_{3}+\frac{1}{a_{4}+\cdots}}}$$</p>

<p>I am trying to find an expression, possibly asymptotic, for the sum of the $a_i$'s for a given $\frac{p}{q}$.</p>

<p>I understand that this is related to the Stern-Brocot tree. In particular, our problem is equivalent to finding on which row does the fraction $\frac{p}{q}$ first appear in the Stern-Brocot tree.</p>

<p>Are there any results to this problem?</p>
",number_theory
"<p>Imagine that i have a 50 x 100 cm baking tray, and i have a load of cinnamonbuns, shaped like a circle with a diameter of 10cm.</p>

<p>How do i calculate the best place to place my cinnamonbuns, as the ammount of cinnamonbuns increases?</p>

<p>When i say ""best"" i mean the position where each cinnamonbun is the farthest away from other cinnamonbuns (and the side of teh tray) possible.</p>
",number_theory
"<p>Could someone give me a hint on the computation of the asymptotic bound for the following series
$$
\sum_{n\leq x}\frac{\log n }{ \varphi(n)}\,,
$$
where $\varphi(n)$ is the Euler totient function? Also a bibliography suggestion would be ok.</p>
",number_theory
"<blockquote>
  <p>Let $M=\begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix} \in M_{2}(\mathbb Z)$, prove that there exist
  $A,B,C \in M_{2}(\mathbb Z)$ such that $M=A^2+B^2+C^2$.</p>
</blockquote>

<p>My idea: if we can find $a_{i},b_{i},c_{i},d_{i}\in \mathbb Z,i=1,2,3$ such</p>

<p>$$a=a^2_{1}+a^2_{2}+a^2_{3}$$
$$b=b^2_{1}+b^2_{2}+b^2_{3}$$
$$c=c^2_{1}+c^2_{2}+c^2_{3}$$
$$d=d^2_{1}+d^2_{2}+d^2_{3}$$</p>

<p>then we prove it. But I can't find such numbers. Thank you.</p>

<p>This problem is from this paper: (has a solution)  (45)
<a href=""http://mathproblems-ks.com/?wpfb_dl=8"" rel=""nofollow"">http://mathproblems-ks.com/?wpfb_dl=8</a></p>

<p>And in fact I want to see other methods? Thank you (because I think this problem has other methods.)</p>
",number_theory
"<p>Would it be possible to bound this function for primes in terms of the maximum difference between the images of the function and their closest primes (for instance, the fifth term is 33 and has difference of two in terms of its closest prime, 31):</p>

<p>$2 g(n-1) = g(n)+1$</p>

<p>I have found that the images are main,y bounded by a difference of four 4 or 2 for the closest primes, however certain images can be bound by 30 as I have heuristicly found. But, my question is, would it be possible, perhaps using the P.N.T. and other number theoretical or group theoretical tools,to find a bound for the primes for each image?</p>
",number_theory
"<p>Is $$1+\cfrac{1}{1+\cfrac{1}{2+\cdots}} $$ or$\{1,1,2,3,4,5,\cdots,i,\cdots \} , i\in \mathbb{N}$ the simple continued fraction algebraic or transcendental?</p>

<p>Any reference is appreciated</p>

<p><strong>EDIT</strong> and replacing $\{1,1,2,3,4,5,\cdots,i,\cdots \}$ with $\{1,2,2^2,2^3,2^4,2^5,\cdots,2^i,\cdots \} $ $i\in \mathbb{N}$ or any other patternful sequences that are upper unbounded ,can we get an algebraic number?</p>
",number_theory
"<p>Show that it is possible to arrange the numbers 1, 2, . . . , n
in a row so that the average of any two of these numbers
never appears between them. </p>

<p><em>Hint</em>: Show that it suffices
to prove this fact when n is a power of 2. Then use mathematical
induction to prove the result when n is not a power of 2.</p>

<p>This is a problem from Rosen's discrete mathematics book.</p>

<p>I tried to think of it this way:</p>

<hr>

<p>Take any n,find its nearest power of 2,(say m)less than or equal to n,find the arrangement for 1,2,...m,then the rest of numbers m+1,....,n just fill in the gaps within the sequence 1,...,m in a certain way.</p>

<hr>

<p>e.g.,Take n=12,nearest power of two less than or equal to n,is,8.So arrange 1,2,...,8 which gives 1,5,3,7,2,6,4,8.Now the numbers 9,10,11,12 just fills in the arranged sequence in a particular way.Its the last part I am struggling with. How exactly does the rest of the numbers fit in?
I may be wrong with the above approach,so please share your solution,in that case.</p>
",number_theory
"<p>The Möbius inversion formula says given two arithmetic functions $\hat{g}(k)$ and $g(k)$ related by $$\sum_{d\mid k}\hat{g}(d)=g(k)$$
Then $$\sum_{d\mid k}\mu(d)g\left(\frac{k}{d}\right)=\hat{g}(k)$$
Can someone give me a very elementary proof of this?</p>

<p>I don't know anything about analytic number theory, though I know the definition of the Möbius function, and have used it before with out ever reading to deeply into it for example: I know that,
$\frac{x}{1-x}=x+x^2+x^3+x^4+\cdots$
And that if I subtract the even powers I get,
$\frac{x}{1-x}-\frac{x^2}{1-x^2}=x+x^3+x^5+x^7+x^9+\cdots$
And then If I subtract the the powers that are multiples of 3 I get,
$\frac{x}{1-x}-\frac{x^2}{1-x^2}-(\frac{x^3}{1-x^3}-\frac{x^6}{1-x^6})=x+x^5+x^7+x^{11}+\cdots$
Continuing in this matter one sees we are essentially yielding combinations of the original sum where the argument is a combination of distinct primes, and the coefficients are determined by weather or not the number of primes is even or odd. So by the definition of the Möbius function I can easily see, $\sum_{k=1}^\infty\frac{\mu(k)x^k}{1-x^k}=x$, although the first theorem I mentioned doesn't seem so obvious to me, and so I would appreciate a simple proof.</p>
",number_theory
"<p>I try to understand something from number theory and the author gave this as an excersise: Prove that $z\longmapsto 2\sqrt{p}\cos z$ is a bijection of a set $\Theta_{p}=\left[i\log\sqrt{p},0\right]\cup\left[0,\pi\right]\cup\left[\pi,\pi+i\log\sqrt{p}\right]$ onto $\left[-\left(p+1\right),p+1\right]$. Here $p&gt;2$ is a prime number. I proved that the picture lies in $\left[-\left(p+1\right),p+1\right]$, but injection and sirjection I can't prove. Help.</p>
",number_theory
"<blockquote>
  <p>Let $a_1$ be an integer. Then we assume  </p>
  
  <p>$$
a_{n+1} =
\begin{cases}
3a_n+1,&amp;\text{$a_n$ is odd}\\
\frac{a_n}{2},&amp;\text{$a_n$ is even}
\end{cases}
$$</p>
</blockquote>

<p>Now we prove that</p>

<blockquote>
  <p>for any $a_1\in\mathbb N$, there exists $N$ which satisfy: $a_n=1,2$ or $4$,$n\geq{N}$.</p>
</blockquote>

<p>At first I want to give it a suitable category for the problem: analysis. And I want to use the basic method: evaluate the upper bound for $a_n$, however I find it's not easy because the iteration is rely on the odd or even property of $a_n$. So I attempt the method of number theory. But I failed to find any way to go over it. Can anyone have idea? Thank you. </p>
",number_theory
"<p>Prove there is an infinite amount of natural numbers for which $\displaystyle \frac{n(n+1)}{2}$ is a perfect square. </p>
",number_theory
"<p>Please could someone give me a hint on this sequences question? The question is to prove that every integer appears infinitely many times in the following sequence:</p>

<p>$$ \pm 1^{2} , \pm 1^{2} \pm 2^{2} , \pm 1^{2} \pm 2^{2} \pm 3^{2} , \pm 1^{2} \pm 2^{2} \pm 3^{2} \pm 4^{2} , ... $$</p>

<p>Any help would be much appreciated, thank you (:</p>
",number_theory
"<p>Let $\mu(d)$ be the Möbius function, and $\mu_r(d)$ be the modified Möbius function which satisfies $\mu_r(d)=0$ if $d$ has strictly more than $r$ distinct prime factors. Let $\psi_r(n)=\sum_{d\mid n}\mu_r(d)$. Finally, we let $P_z$ be the product of all primes less than or equal to $z$. Then, what I am humbly requesting help with proving, is 
$$
\sum_{d\mid P_z}\frac{1}{d}\sum_{\delta\mid d}\mu(d/\delta)\psi_r(\delta) = 
\sum_{\delta\mid P_z}\frac{\psi_r(\delta)}{\delta}\sum_{d\mid P_z/\delta}
\frac{\mu(d)}{d}.
$$
Thank you for the help!</p>
",number_theory
"<p>Is there a polynomial $p(x)$ with real coefficients and degree at least one such that $[p(n)]$ is prime for every natural number $n$? If yes, what is such a polynomial $p(x)$ and if no, how to prove?</p>
",number_theory
"<p>I am looking for a reference/hints of proof towards statements of the kind;</p>

<p>Given an irreducible system of $n$ polynomial equations over $\mathbb Q$ in $n$ variables
$$P_i(x_1,...,x_n)=0,\quad i=1,...,n\,,$$
with $k$ (generally) complex solutions $\sigma_1,...,\sigma_k$, the following is true. </p>

<p>For any $P$ and $Q$ polynomials (*edit : in $n$ variables) over $\mathbb Q$, the following sum is an element of $\mathbb Q$;
$$\sum_{a=1}^k \frac{P(\sigma_a)}{Q(\sigma_a)}\in \mathbb Q\,.$$</p>

<p>I suppose that it is possible to prove this by hand in the simpler case of purely polynomial sums, I have no clue for the rational-function case.</p>
",number_theory
"<p>One question, two parts...</p>

<p>(a) Consider the group $(Z_n, + \mod{n})$. If $n$ is an odd prime number, determine (with proofs) if all automorphisms of $(Z_n, + \mod{n})$ are even permutations of $Z_n$. </p>

<p>(b) Determine the automorphism group of the group $S_3$ (under functional composition).</p>

<p>Strategy?</p>
",number_theory
"<p>Is every integer (say $d$) a quadratic residue mod some prime number $p$?</p>
",number_theory
"<p>I'm reading the book <em>A First Course In Modular Forms</em> and it defines the term <strong>weakly modular of weight $k$</strong> as following:</p>

<p>Let $K$ be an integer. A meromorphic function $f:H\rightarrow\mathbb{C}$ is weakly modular of weight $k$ if
$$
f(\gamma(\tau))=(c\tau+d)^kf(\tau)
$$</p>

<p>for every $\gamma\in$ SL$_2(\mathbb{Z})$ and $\tau\in H$, where $H$ means the upper half complex plane.</p>

<p>My question is, why in definition we use meromorphic function?</p>

<p>I think meromorphic means such function has poles in a set of isolated points. What if let $\tau$ be such a point? Then the RHS of the equation will be $(c\tau+d)^k\infty$, which is undetermined.</p>

<p>Any suggestion?</p>
",number_theory
"<p>Imagine a binary string of increasing length, up to infinity.</p>

<p>What makes it so special? Well, just a simple ""rule"":</p>

<p>for any given length (odd or even), if one folds the string in half, there is at least one couple of ones that overlaps.</p>

<p>The question is now about the distribution of ones (zeros), as a function of string length. What are its properties? Are there any?</p>

<p>A trivial example that follow the rule is the string $111010101010....$.</p>
",number_theory
"<p>I have tried fermats little theorem with fail. I cannot see how to proceed with this problem, find all prime $x$ such that $x^2+2$ is a prime.</p>
",number_theory
"<p>What is the most motivating way to introduce LCM of two integers on a first elementary number theory course? I am looking for real life examples of LCM which have an impact. I want to be able to explain to students why they need to study this topic.</p>
",number_theory
"<p>Open problem in Geometry/Number Theory.  The real question here is:</p>

<p><em>Is there an infinite family of points on $y=x^2$, for $x \geq 0$, such that the distance between each pair is rational?</em></p>

<p>The question of ""if not infinite, then how many?"" follows if there exists no infinite family of points that satisfies the hypothesis.</p>

<p>We have that there exists a (in fact, infinitely many) three point families that satisfy the hypothesis by the following lemma and proof.</p>

<p><strong>Lemma 1:</strong>  <em>There are infinitely many rational distance sets of three points on $y=x^2$.</em></p>

<p>The following proof is by Nate Dean.</p>

<p><em>Proof.</em>  Let $S$ be the set of points on the parabola $y = x^2$ and let $d_1$ and $d_2$ be two fixed rational values.  For any point, $P_0(r)=(r, r^2) \in S$, let $C_1(r)$ be the circle of radius $d_1$ centered at $P_0(r)$ and let $C_2(r)$ be the circle of radius $d_2$ centered at $P_0(r)$.  Each of these circles must intersect $S$ in at least one point. Let $P_1(r)$ be any point in $C_1(r) \cap S$ and likewise, let $P_2(r)$ be any point in $C_2(r) \cap S$.  Now let $dist(r)$ equal the distance between $P_1(r)$ and $P_2(r)$. The function $dist(r)$ is a continuous function of $r$ and hence there are infinitely many values of $r$ such that $P_0(r)$, $P_1(r)$,
and $P_2(r)$ are at rational distance. $ \blacksquare $</p>

<p>This basically shows that the collection of families of three points that have pairwise rational distance on the parabola is dense in $S$.</p>

<p>Garikai Campbell has shown that there are infinitely many nonconcyclic rational distance sets of four points on $y = x^2$ in the following paper: <a href=""http://www.ams.org/journals/mcom/2004-73-248/S0025-5718-03-01606-5/S0025-5718-03-01606-5.pdf"">http://www.ams.org/journals/mcom/2004-73-248/S0025-5718-03-01606-5/S0025-5718-03-01606-5.pdf</a></p>

<p>However, to my knowledge, no one has come forward with 5 point solutions, nor has it been proven that 5 point solutions even exist.</p>

<p>But I know that many people have not seen this problem!  Does anyone have any ideas on how to approach a proof of either the infinite case or even just a 5 point solution case?</p>

<p><strong>Edit:</strong>  The above Lemma as well as the paper by Garikai Campbell do <strong>not</strong> include the half-parabola ($x \geq 0$) restriction.  However, I thought that the techniques that he employed could be analogous to techniques that we could use to make progress on the half-parabola version of the problem.</p>
",number_theory
"<p>I need to define a formula for a half unit of the smallest decimal place in unit price ($UP$), or understand if this can be defined with a formula?</p>

<p>What I have is this</p>

<p>$$ T_{min,max} = Amt +/- (Qty * NT)$$</p>

<p>Where</p>

<p>$T$ - Tolerated Amount<br>
$Amt$ - Original Amount<br>
$Qty$ - Original quantity<br>
$NT$ - Half unit of the smallest decimal place in Unit Price ($UP$)</p>

<p>Examples of $NT$</p>

<p>$$UP = 2.456 {\implies} NT = 0.0005$$
$$UP = 2.4 {\implies} NT = 0.05$$
$$UP = 2.44500230012 {\implies} NT = 0.000000000005$$</p>

<p><strong>How do I write formula to calculate $NT$?</strong></p>
",number_theory
"<p>I'm looking for literature on solving problems of the form
$$
n_1^\alpha+\cdots+n_k^\alpha=(n_1+\cdots+n_k)^\beta
$$
for positive integers $n_1,\ldots,n_k$ and fixed parameters $k$ and $\alpha\ne\beta.$ Any ideas?</p>

<p>This is perhaps similar to multigrade equations or ""equal sums of like powers"" but not quite similar enough to use those results (as far as I can see). But surely this is too simple not to have been studied?</p>
",number_theory
"<p>I was thinking about this and am wondering if it is true. Currently trying to look for a counter example, but haven't found anything yet.</p>

<p>Conjecture: $p^\alpha$ can be written as the sum of two primes, for any prime $p$, $\alpha \geq 2 \in \mathbb{N}$.</p>
",number_theory
"<p>There are 3 parts of the problem.</p>

<ol>
<li>Let d be a perfect square, possibly 0. Show that there is a quadratic form $ax^2+bxy+cy^2=0$ of discriminant d for which a=0.<br><br></li>
<li>Let a,b,c be integers with $a\ne0$. Show that if one root of the eqatuion $au^2+bu+c=0$ is rational then the other one is, and that $b^2-4ac$ is a perfect square, possibly 0.</li>
<li>Show also that if $b^2-4ac$ is a perfect square, possibly 0, then the roots of the equation $au^2+bu+c=0$ is rational.</li>
</ol>

<p>For question 1., I wrote $d=k^2$ for some integer k. Then, I got to $b^2-k^2=4ac$ and got stuck.</p>

<p>For question 2 and 3, all the claims of the problem sounds perfectly right (which should be always right...) and I couldn't start from both of those ones.</p>

<p>Thank you.</p>
",number_theory
"<p>I understand the mechanics of the proof of Ostrowski's Theorem, but I'm a little unclear on why one should expect valuations to be related to primes. Is this a special property of number fields and function fields, or do primes of K[x,y] correspond to valuations on K(x,y) in the same way?</p>

<p>I'm hoping for an answer that can explain what exactly are the algebraic analogs of archimedian valuations, and how to use them - for example, I've heard that the infinite place on K(x) corresponds to the ""prime (1/x)"" - how does one take a polynomial in K[x] ""mod (1/x)"" rigorously?</p>

<p>Thanks in advance.</p>
",number_theory
"<p>Is it true that there are infinitely many nonprime integers $n$ such that $3^{n-1} - 2^{n-1}$ is a multiple of $n$?</p>
",number_theory
"<p>Apparently Fermat stated but didn't provide proofs of various theorems named after him, including <a href=""http://en.wikipedia.org/wiki/Fermat&#39;s_little_theorem"" rel=""nofollow"">Fermat's little theorem</a>, <a href=""http://en.wikipedia.org/wiki/Fermat&#39;s_theorem_on_sums_of_two_squares"" rel=""nofollow"">Fermat's theorem on sums of two squares</a>, <a href=""http://en.wikipedia.org/wiki/Fermat_polygonal_number_theorem"" rel=""nofollow"">Fertmat's polygonal number theorem</a>, and most famously, of course, <a href=""http://en.wikipedia.org/wiki/Fermat&#39;s_Last_Theorem"" rel=""nofollow"">Fermat's Last Theorem</a>. Why is this?</p>
",number_theory
"<p>How to find all natural $x$ for that $x^2 + (x+1)^2$ is a perfect square?</p>
",number_theory
"<p>Can you give a definition of the Conway base-13 function better than the one actually present on wikipedia (<a href=""http://www.google.it/url?sa=t&amp;source=web&amp;cd=1&amp;ved=0CBgQFjAA&amp;url=http%3A%2F%2Fen.wikipedia.org%2Fwiki%2FConway_base_13_function&amp;ei=empRTNK-OsqWON2_uPUE&amp;usg=AFQjCNFqIS-UhBV9Miw1QnAZJaxnswI3Yg&amp;sig2=AlFPiLqMkh3gd4VPEHJI-Q"">here</a>), which isn't clear? Maybe with some examples?</p>
",number_theory
"<p>Let's call $A\subseteq\mathbb{N}$ <em>dense</em> if $$\text{lim inf}_{n\to\infty}\frac{|A\cap\{1,\ldots,n\}|}{n} = 1.$$</p>

<p>Is the intersection of two dense sets dense again? Or does the intersection of two dense sets at least satisfy the weaker statement $$\text{lim sup}_{n\to\infty}\frac{|A\cap\{1,\ldots,n\}|}{n} = 1?$$</p>
",number_theory
"<p>This September I am participating in a competition called the Australian Intermediate Mathematics olympiad, and you may not have heard of it but it's very similar to the AIME. Could you please tell me how I could prepare for it well because I really want to do well.</p>

<p>I bought some math books on the internet and am studying them... is this a good way or preparing? These math books cover topics such as proving, number theory, combinatorics and so on... Here is a practice paper for the competition and I have done it many times. It is easy but I hope that this year's will be similar, however it is always better to preparing for it. => <a href=""http://www.amt.edu.au/wuaimo.pdf"" rel=""nofollow"">http://www.amt.edu.au/wuaimo.pdf</a></p>

<p>Edit: How much time should I be spending everyday practicing?</p>
",number_theory
"<p>I have a question regarding the follow problem:</p>

<blockquote>
  <blockquote>
    <p>Show that the prime number 27644437 splits completely in $L = \mathbb{Q}(\sqrt{55})$.</p>
  </blockquote>
</blockquote>

<p>From what I understand. This deals with ramification. </p>

<p>\begin{eqnarray}
\sum_1^{r}e_if_i = n &amp;, &amp;\text{where }n = [L:K]
\end{eqnarray}</p>

<p>For our prime number, $p$, to split completely into $L$, then $e_i=f_i =1$ for all $i$. Now in order for it to be completely split, it can not be ramified. Being ramified will require at least one of the $e_i&gt;1$. However, we do not need to worry about this situation in this problem because $p\not| \text{disc}(L)$. </p>

<p>Minimal Polynomial of $L$ is $x^2-55$. Since it is not ramified, this will only leave two possibilities: inert or split. Since we are dealing with a second degree polynomial and we already ruled out the possibility of being ramified, then it must be completely split. Thus, inert or completely split. </p>

<p>This is where it gets complicated. If I want to show it is completely split I need to find at least one integer such that $x^2 -55 (\text{mod}p) = 0$. </p>

<p>I do not need to find the second integer because $p$ does not ramify $L$. Looking over so many numbers just to verify it meets this condition is ridiculous. There has to be another approach.</p>

<p>I asked my professor and he gave me a hint suggesting I use the Quadratic Reciprocity Law. However, I do not know how to apply it correctly in this case. I would assume looking at the Quadratic Residue symbol formed by the discriminate of $L$ and the prime number $p$. This will either result in an answer of $0, 1, \text{or, } -1$; however, I am not sure what the value would mean. </p>

<p>Thank You for your time, and thank you in advance for any feedback. </p>
",number_theory
"<p>It is an exercise on the lecture that i am unable to prove.</p>

<p>Given that $gcd(a,b)=1$, prove that $gcd(a+b,a^2-ab+b^2)=1$ or $3$, also when will it equal $1$?</p>
",number_theory
"<p>I know that there's a proof (of Landau from 1908) that the numbers of integers that can be represented as sum of two squares which are smaller than $n$ is</p>

<p>$$
\Theta\left(n\over\sqrt{log (n)}\right)
$$</p>

<p>I would be thankful if someone can direct me to the proof (I only found a book in German),
or better yet if someone can prove it to me :)</p>

<p>Thank You</p>
",number_theory
"<p>A magic square of order $N$ is an $ N \times N $ matrix with positive integral
entries such that the elements of every row, every column and the two diagonals all add up to the same number. If a magic square is filled with numbers
in arithmetic progression starting with $a \in N $ and common dierence $ d  \in N$,
what is the value of this common sum?</p>

<p>I am stuck on this problem. Can anyone help me please...</p>
",number_theory
"<p>The fundamental theorem of arithmetic says that every integer $n&gt;1$ is of the form</p>

<p>$$ n = \prod_i {p_i}^{a_i} $$</p>

<p>where $p_i$ is the $i$ th prime and $a_i$ is a nonnegative integer.</p>

<p>My question is how many $m$ satisfy $ 1&lt;m&lt;n $ and </p>

<p>$$ m = \prod_i {(p_i-1)}^{b_i} $$</p>

<p>where $p_i$ is the $i$ th ODD prime and $b_i$ is a nonnegative integer.</p>

<p>Lets call $f(n)$ the amount of $m$ that satisfy the above.</p>

<p>What is a good approximation to $f(n)$ ?</p>
",number_theory
"<p>Let $G$ be a finite group. I know that the set of irreducible representations of $G$ over the complex numbers (up to isomorphism) is finite.</p>

<p>Let us fix our attention on some irreducible representation of $G$ over $\Bbb{C}$ 
$$\rho: G \longrightarrow GL_n(\Bbb{C})$$
My intuition tells me that there exists some finite extension $K \supset \Bbb{Q}$, and some irreducible representation
$$\sigma:G \longrightarrow GL_n(K)$$
such that $\rho = i \circ \sigma$, where $i: GL_n(K) \longrightarrow GL_n(\Bbb{C})$ is the inclusion (every matrix with entries in $K$ has entries also in $\Bbb{C}$).</p>

<p>For example, if $G=C_2$ is the group with two elements, we can think the two irreducible representations of $C_2$ as $\sigma_1, \sigma_2 : C_2 \longrightarrow GL_1(\Bbb{Q})$, so $K=\Bbb{Q}$.</p>

<p>However I don't know if this is true for any finite group  (but I strongly believe that this is true, maybe you can give me some reference).</p>

<p>My question is: given $G$ a finite group, can we find some number field $K$, such that all irreducible representations of $G$ over the complex numbers can be thought as irreducible representations over $K$ (i.e. all involved matrices actually have entries in $K$)? Can we find a minimal such number field?</p>
",number_theory
"<p>I've solved for it making a computer program, but was wondering there was a mathematical equation that you could use to solve for the nth prime?</p>
",number_theory
"<p>In part of my research, the following problem has come up.</p>

<p>Consider the system of equations (in complex numbers)</p>

<p>$$z^b w^c = 1,\quad z^d w^e = 1.$$</p>

<p>I am interested in the solution set when we restrict both $z$ and $w$ to be $a^{\textrm{th}}$ roots of unity, for some positive integer $a$. Of course, one immediately sees that $(z, w) = (1, 1)$ is a solution.  </p>

<blockquote>
  <p>What are some nice necessary and sufficient conditions on $a, b, c, d,$ and $e$ which guarantee that $(z, w) = (1, 1)$ is the ONLY solution?</p>
</blockquote>

<p>To give an idea of the flavor of answer I'd be most happy with, one must have $\textrm{gcd}(a, b, d) = \textrm{gcd}(c, e) = 1$, because if $z$ is any $\textrm{gcd}(a, b, d)^{\textrm{th}}$ root of $1$ (which is neccesarily an $a^{\textrm{th}}$ root of $1$), then $(z, 1)$ is a solution to both equations.</p>

<p>It also turns out that $z$ and $w$ must both be $\textrm{gcd}(a, be - cd)^{\textrm{th}}$ roots of $1$.</p>

<p>I'd love to have an answer like ""$\textrm{gcd}(a, be - cd) = \textrm{gcd}(a, b, d) = \textrm{gcd}(c, e) = 1$ is necessary and sufficient"", with, perhaps, a few more estimates on gcd terms.</p>

<p>This problem can also been generalized (and I am interested in that case as well).  Suppose you are given $3$ equations</p>

<p>$$z^a w^b = 1,\quad z^c w^d = 1,\quad z^e w^f = 1,$$</p>

<p>with $z$ and $w$ complex numbers of modulus $1$.</p>

<blockquote>
  <p>What are necessary and sufficient conditions on $a, b, c, d, e$ and $f$ which guarantee that the only simultaneous solution is $(z, w) = (1, 1)$?</p>
</blockquote>

<p>The previous problem is a special case of this (which comes from setting $b = 0$.  Clearly then, $z$ must be an ath root of unity.  It turns that if $b$ is $0$, using the fact that $\textrm{gcd}(d, f) = 1$ one can show $w$ must also be an $a^{\textrm{th}}$ root of unity).</p>

<p>And please feel free to retag as appropriate!</p>

<p>Thank you in advance.</p>
",number_theory
"<blockquote>
  <p>If $\gcd(a,30)=1$ then $60 \mid (a^4+59)$.</p>
</blockquote>

<p>If $\gcd(a,30)=1$ then we would be trying to show $a^4\equiv 1 \mod{60}$ or $(a^2+1)(a+1)(a-1)\equiv 0 \mod{60}$. We know $a$ must be odd and so $(a+1)$ and $(a-1)$ are even so we at least have a factor of $4$ in $a^4-1$. Was thinking I could maybe try to show that there is also a factor of $3$ and $5$ necessarily giving that $a^4-1\equiv0 \mod{60}$.</p>

<p>Other things I was thinking was that as $Ord_n(a) \mid \phi(n)=\phi(60)=16$ that we just need to show that $Ord_n(a) \in \{1,2,4 \}$.</p>

<p>Any hints? I have the exam soon =/</p>
",number_theory
"<blockquote>
  <p>Prove that 
  $$(a+b+c)^{333}-a^{333}-b^{333}-c^{333}$$
  is divisible by
  $$(a+b+c)^{3}-a^{3}-b^{3}-c^{3},$$
  where $a,,b,c -$ integers, such that $(a+b+c)^{3}-a^{3}-b^{3}-c^{3}\not =0$</p>
</blockquote>

<p><strong>My work so far:</strong></p>

<p>$(a+b+c)^{3}-a^{3}-b^{3}-c^{3}=3(a+b)(b+c)(c+a)$</p>

<p>Let $333=3\cdot111=3t,$ where $t=111$.</p>

<p>$(a+b+c)^{333}-a^{333}-b^{333}-c^{333}=(a+b+c)^{3t}-a^{3t}-b^{3t}-c^{3t}$.</p>

<p><strong><em>I need help here.</em></strong></p>
",number_theory
"<p>Let $V$ be the set of prime together with the symbol $\infty$. For a prime $v=p$, denote the $p$-adic numbers by $\mathbb{Q}_p$ and the real numbers by $\mathbb{Q}_\infty$. For $v\in V$ the Hilbert symbol is defined for $a,b\in\mathbb{Q}^*_v$ as</p>

<p>\begin{align*}
(a,b)_v=\begin{cases}+1,&amp;\text{ if }ax^2+by^2=z^2\text{ has a non-zero solution }(x,y,z)\in \mathbb{Q}_v^3;\\-1,&amp;\text{ else.}\end{cases}
\end{align*}</p>

<p>Furthermore for $v\in V, a,b\in\mathbb{Q}^*$ we denote by $(a,b)_v$ the Hilbert symbol of $(\bar a,\bar b)_v$ where $\bar a,\bar b$ are the images of $a,b$ in $\mathbb{Q}_v$.</p>

<p>Now a theorem by Hilbert says that $(a,b)_v=1$ for almost all $v\in V$ (and that furthermore $\prod_{v\in V}(a,b)_v=1$, but I'm not interested in this at the moment). The theorem can be found in ""A course in Arithmetic"" by Jean-Pierre Serre for example.</p>

<p>It basically says that there is a finite set $E\subseteq V$ such that 
\begin{align*}
(a,b)_v=\begin{cases}+1,&amp;\text{ if }v\notin E\\-1,&amp;\text{ if }v\in E\end{cases}
\end{align*}</p>

<p>My question is if this set $E$ has a common name in the literature. Something like $E_{a,b}$ would make sense to me (since it depends on $a$ and $b$). If there is no widely used name, what are your suggestions?</p>
",number_theory
"<p>Has anybody read <a href=""http://www.wired.com/wiredscience/2013/05/twin-primes/"">Yitang Zhang</a>'s paper on prime gaps? Wired reports ""$70$ million"" at most, but I was wondering if the number was actually more specific.</p>

<p>*<em>EDIT</em>*$^1$:</p>

<p>Are there any experts here who can explain the proof? Is the outline in the annals the preprint or the full accepted paper?</p>
",number_theory
"<p>I am stuck on this, and cannot advance. Prove with the pigeonhole principle that there must be a power of seventeen that ends in 00001.</p>
",number_theory
"<p>Is $\ln\ln n &lt; \sigma(n)/n$, where $\sigma(n)$ is the sum of the divisors of $n$? Or is this grossly innacurate or too vague? </p>
",number_theory
"<p>I've recently been working on a practice midterm for my number theory class, and here is a problem I've come across. As there are no solutions posted, I'd like to verify that what I'm doing is actually on the right track.</p>

<blockquote>
  <ol start=""6"">
  <li>Find all $a, b\in\mathbb Z$ such that $\frac12(\sqrt a+\sqrt b)$ is an algebraic integer.</li>
  </ol>
</blockquote>

<p>First I set $x = \frac12(\sqrt a + \sqrt b)$, and after squaring both sides, moving over the $a,b$ term, and squaring again, I get:
$16x^4 -8x^2(a+b) + (a-b)^2 = 0$. Therefore, $\frac12(\sqrt a + \sqrt b)$ is algebraic iff $2\mid(a+b)$ and $4\mid(a-b)$</p>
",number_theory
"<p>Find the set of primes $p$ for which $-3$ is quadratic residue $\text{mod } p$.</p>

<p>I have started my solution like this:</p>

<p>$1= \left(\dfrac{-3}{p}\right) = \left(\dfrac{-1}{p}\right)\left(\dfrac{3}{p}\right) = (-1)^\frac{p-1}{2}\left(\dfrac{3}{p}\right)$ </p>

<p>Using quadratic reciprocity  $\left(\dfrac{-3}{p}\right)$ becomes $(-1)^\frac{p-1}{2}\left(\dfrac{3}{p}\right)$</p>

<p>So up to here I have $1 = (-1)^\frac{p-1}{2}\cdot (-1)^\frac{p-1}{2}\left(\dfrac{p}{3}\right) = (-1)^{p-1}\left(\dfrac{p}{3}\right)$</p>

<p>Where $\left(\dfrac{a}{b}\right)$ stands for the Legendre symbol. What is my next step? I can not seem to see how to break down $p/3$ further. My solution should be when $p\equiv 1 \pmod 3$ but I cant seem to get there.</p>
",number_theory
"<p>This is a challenge problem in the Pell Equations chapter of my number theory book, but I'm not seeing the connection to Pell Equations. The Pell Equation with the coefficient $5$ is $5b^2+1=a^2$, but it doesn't look like the one I have.</p>

<p>Thanks if you can help me.</p>
",number_theory
"<p>Let $V$ be the elliptic curve V: $x^3$+ $y^3$ = A$z^3$ where  A > 2 is cube free natural number. A conjugate quadratic point of $V$ is one of the form $(a + b\sqrt d, a - b\sqrt d, c)$ (note that all quadratic point $(x, y, z)$ of $V$ can be reduced to have $z$ rational integer multiplying by the conjugate of $z$). I have found the result which follows and I am interested in knowing the opinion and remarks or possible objections of readers and mainly I expect for another proof. </p>

<p><strong>Prove that $V(\mathbb Q)$ has no rational points distinct of $(1, -1, 0)$ if and only if all the quadratic points of $V$ are conjugates.</strong></p>

<p>EXAMPLE.- This is true even with $x^3$ + $y^3$ = 2$z^3$ in which the only rational points are $(1, 1, 1)$ and $(1, -1, 0)$. One has here, with $A = 2$, the point $(4 +2\sqrt{-11}, -1 + \sqrt{-11}, -6)$ which is not conjugate because of the rational point $(1, 1, 1)$. </p>
",number_theory
"<p>There is a circumference with 14 points $\{p_{1}, p_{2}, ... p_{14}\}$. These points are assigned numbers 1 to 14 randomly. It must be proven that if points are taken three-by-three, these triplets being formed by consecutive points, there will be at least one triplet which has a sum bigger than 29.</p>

<p>This is how I operated: </p>

<p>There are 14 sums $\{s_{1}, s_{2}, ... s_{14}\}$ where $$s_{1} = p_{1} + p_{2} + p_{3}$$$$s_{2} = p_{2} + p_{3} + p_{4}$$$$...$$$$s_{14} = p_{14} + p_{1} + p_{2}$$ So each number appears 3 times, this is $$s_{1}+s_{2}+...+s_{14} = 3*(1+2+3+4+5+6+7+8+9+10+11+12+13+14) = 315$$ And, $$14*29 = 406$$ This is where I get stuck and don't know how to prove the statement using the pigeonhole principle.</p>
",number_theory
"<p>For $p$ an odd prime, why does $$\sum_{x=1}^{p-1}\left(\frac{x}{p}\right)=\left(\frac{0}{p}\right)$$</p>

<p>where $\left(\frac{x}{p}\right)$ is the Legendre symbol.</p>

<p>I'm not sure if I have given enough context for this to necessarily be true, but I read it in lecture notes and can't understand why it is true.</p>
",number_theory
"<p>Does every soluble negative pell equation, $a^2-Db^2=-1$, have infinitely many integer solutions $(a,b)$ where $a,b$ are <em>both</em> positive integers?</p>
",number_theory
"<p>Let $0&lt;x \leq 1$, We define a function such that $f(x)=y=\frac{1}{x}$ which results $y \geq 1$ . We have infinitely many numbers between $0$ and $1$, so we can match any $x$ to a number $y$ greater than $1$ via $f(x)$. There are also infinitely many numbers greater than $1$. We can match the numbers between this two intervals one to one. Which intuitively results  that the number of elements of these two intervals are equal. I am confused. How can it be possible?</p>
",number_theory
"<p>Show that in any finite field,each of its elements can be written as the sum of two squares.</p>

<p>Well,I hate to admit-this being also my first post-that I have not proven it yet.I tried to work on the multiplicative group but to no avail.Any help/tip will be welcome.</p>
",number_theory
"<p>Is (the number of primes $&lt; n$)   less than (the number of positive integers less than $n$ and relatively prime to $n$)?</p>
",number_theory
"<p>At least in physicist's thinking, information, vaguely, is something that allows one to select a subset from a set. </p>

<p>Say, a system can be in states A and B, we have done a measurement on it (extracted information), then it is in either A or B. Now we are able to say, in which state among all the possible states is the system in.</p>

<p>Now, consider numbers, say number e. One can write many digits to specify the boundaries of an interval to which e belongs. In fact, arbitrarily good precision can take arbitrarily large amount of information to specify the decimal representation of the number.</p>

<p>Now, however, one can also write an expression for e, say $e = \sum_{n}\dfrac{1}{n!}$, and it seems like e is defined to an arbitrary precision straight away. That is to say, here we have something, for which we would have needed infinite amount of information.</p>

<p>The question then: does this expression contain infinity of information/any information at all? Or, can information be defined at all for expressions? </p>

<p>One might surely argue that given an expression, one still has to perform infinite number of evaluations to obtation a decimal expression of the number. But then a number of other questions would arrive: ""Is it evaluations of faculties and additions then that produce information?"", ""Is the information only about decimal representations of numbers, but not the numbers themselves?"", and perhaps many more.</p>
",number_theory
"<p>When I look up why  $\mathbb{R}$ and $\mathbb{Q}$ are not homeomorphic, almost all the answers just say something along the line of ""Because, Cardinality"" and then ends there.</p>

<p>Can someone provides the reason or the proof as to why cardinality would matter?</p>
",number_theory
"<p>Koblitz states in his book on p-adic numbers on page 84:</p>

<blockquote>
  <p>Suppose that $\alpha \in \mathbb Q$ is such that $1 + \alpha$ is the square of a nonzero rational number $a/b$.
  Let $S$ be the set of all primes $p$ for which the binomial series for $(1 + \alpha)^{1/2}$ converges in $|\cdot|_p$.
  There is no $\alpha$ other than $8$, $16/9$, $3$, $5/4$ for which $(1 + \alpha)^{1/2}$ converges to the same value in $|\cdot|_p$ for all $p \in S$.</p>
</blockquote>

<p>Why is this an example of a very general theory of E. Bombieri? What does the theory (or theorem) say and what are its possible connections with p-adic numbers? Is it the Bombieri–Vinogradov theorem from analytic number theory?</p>
",number_theory
"<p>I have come across two instances of ""Coleman map""</p>

<p>Let $E$ be an elliptic curve defined over $\mathbb{Q}_p$. Let $k_\infty$ be the unique $\mathbb{Z}_p$ extension of $\mathbb{Q}_p$ contained in $\mathbb{Q}_p(\mu_{p^\infty})$ with Galois group $\Gamma = 1+p\mathbb{Z}_p \cong \mathbb{Z}_p$. Let $k_n$ be the $n$-th layer in this tower. Let $T=T_p(E)$ be the $p$-adic Tate module  of the elliptic curve $E$. Then the $\textit{Coleman map for E}$ is a map $$Col: \varprojlim_{n}  H^1(k_n, T^*(1)) \rightarrow \Lambda=\mathbb{Z}_p[[\Gamma]] $$
I am referring to page 572 of <a href=""https://www.math.uni-bielefeld.de/documenta/vol-coates/kobayashi.pdf"" rel=""nofollow"">this paper</a> where I learn that the power series $Col_z(x)$ equals the $p$-adic L-function of the elliptic curve E when $z$ is a special element discovered by Prof. Kato. </p>

<p>There is another instance where I have come across a Coleman power series, as a power series that generates norm-coherent sequence of units in the tower $\mathbb{Q}_p(\mu_{p^ \infty})/\mathbb{Q}_p$. That is, if I have a sequence of units $\mathbb{u}=(u_n)_{n \geq 0} \in \varprojlim_{n \geq 0} \mathcal{O}^{\times}_{\mathbb{Q}_p(\mu_{p^n})}$ (the inverse limit on the right hand side is w.r.t. the norm map of fields $\mathbb{Q}_p(\mu_{p^m}) \rightarrow \mathbb{Q}_p(\mu_{p^n}),  m \geq n$), then $\exists!$ unique power series $Col_{\mathbb{u}}(x) \in \mathbb{Z}_p[[x]]$ such that $Col_{\mathbb{u}}(\zeta_{p^{1+n}}-1)=u_n, \forall n\geq 0$. How does the first Coleman map relate to the second? Or even more generally, are there other instances where Coleman maps arise, and what is  the general philosophy behind Coleman maps? Any thoughts and/or link to any articles/notes are welcome. Thank you!!</p>
",number_theory
"<p>Prove: If a prime number $p\in \mathbb N$ is from the form $p=4k+3,k\in \mathbb N$, then its also a prime number in $\mathbb Z[i]$,i.e. if $p|(z_1\cdot z_2)$ then $p|z_1$ or $p|z_2$.</p>

<p>I dont have any idea how to solve it, so I am looking for some <strong>hints</strong>.</p>

<p>Thanks in advance :)</p>
",number_theory
"<p>I have an equation: $ x+y+z+t = 7$. I want to know how many solutions does this equation have? $x,y,z$, and $t$ are positive integers. I have no idea how to solve this. Can you please help me to solve this question?</p>
",number_theory
"<p>Is it true that, if $a^2-Db^2=-1$ is solvable in integers, then so is $x^2-Dy^2=D$ (*)?</p>

<p>For $D=5$ this is true, you can take $x=5$ and $y=2$, and indeed $5^2-5(2^2)=5$, so (*) is solvable. Is this true in general?</p>
",number_theory
"<p>The identity</p>

<p>$\displaystyle (n+1) \text{lcm} \left( {n \choose 0}, {n \choose 1}, ... {n \choose n} \right) = \text{lcm}(1, 2, ... n+1)$</p>

<p>is probably not well-known.  The only way I know how to prove it is by using <a href=""http://planetmath.org/encyclopedia/KummersTheorem.html"">Kummer's theorem</a> that the power of $p$ dividing ${a+b \choose a}$ is the number of carries needed to add $a$ and $b$ in base $p$.  Is there a more direct proof, e.g. by showing that each side divides the other?</p>
",number_theory
"<p>I'm new to modular form, reading the book <em>A First Course in Modular Forms</em></p>

<p>We have the weight 2 Eisenstein series
$$
G_2(\tau)=\sum_{c\in\mathbb{Z}}\sum_{d\in\mathbb{Z}_c'}\frac{1}{(c\tau+d)^2}
$$</p>

<p>where $\mathbb{Z}_c'=\mathbb{Z}-\{0\}$ when $c=0$ otherwise $\mathbb{Z}$.</p>

<p>Now I am given that
$$
(G_2[\gamma]_2)(\tau)=G_2(\tau)-\frac{2\pi ic}{c\tau+d}\text{for }\gamma=\begin{bmatrix}a&amp;b\\c&amp;d\end{bmatrix}\in\text{SL}_2(\mathbb{Z})
$$</p>

<p>And I am asked to prove that if we know that the above formula is correct for two particular matrices $\gamma_1,\gamma_2$,then it is correct for $\gamma_1\gamma_2$.</p>

<p>I try to do as following:
$$
\begin{align*}
(G_2[\gamma_1\gamma_2]_2)(\tau)&amp;=(G_2[\gamma_1]_2[\gamma_2]_2)(\tau)\text{ by property of the operator}\\
&amp;=(G_2[\gamma_1]_2)(\gamma_2(\tau))\cdot j(\gamma_2,\tau)^{-1}\text{ by the definition}
\end{align*}
$$</p>

<p>But after substitute $\tau$ by $\gamma_2(\tau)$ in the above given formula, I can not get the desired equation.</p>

<p>Can anyone help?</p>
",number_theory
"<p>How many incongruent solutions are there to $x^2 \equiv 1 \space (mod \space m)$?</p>

<p>As a hint, my teacher said make use of the Chinese Remainder Theorem.</p>

<p>What I have done so far is a case by case approach - I looked at $a=0,1,2$ and $a \geq 3$.</p>

<p>For each $p_i^{b_i}$, I found that there are two possible solutions, $x= \pm 1$, but passed this, I'm not too sure where to go.</p>
",number_theory
"<p>Are $(1,2), (2,3), (3,4)$, and $(8,9)$ the only consecutive integers that are a power of two and a power of three? And if they are, how do I prove this?</p>
",number_theory
"<p>Let $$a_n=1+\frac{1}2+\frac{1}3+\cdots+\frac{1}n=\frac{p_n}{q_n},$$ 
where $gcd(p_n,q_n)=1.$</p>

<p>$$\{a_n\}=\left\{1,\frac{3}{2},\frac{11}{6},\frac{25}{12},\frac{137}{60},\frac{49}{20},\frac{363}{140},\cdots\right\}$$</p>

<p>Hence $p_1=1,p_4=5^2,p_6=7^2,$ are there any other $n$ such that $\sqrt{p_n}\in\mathbb N$?</p>
",number_theory
"<p>I'd like to solve the following Pell equation:
$$
x^2-7y^2=-3
$$
Where $x$ and $y$ are integers. I applied the usual procedure, which avoids continued fractions:</p>

<p>The two minimal positive integer solutions are $(x_0,y_0)=(2,1)$ and $(x_1,y_1)=(5,2)$, thus the minimal rational solution of $x^2-7y^2=1$ should be $(p,q)=\left(\frac{4}{3},\frac{1}{3}\right)$. My script (it is in german so I don't link it here) tells me, that in this case, every pair of solutions is given by:
$$
x_{n+1}=\frac{4}{3}x_{n}+7\cdot\frac{1}{3}y_n \\
y_{n+1}=\frac{1}{3}x_{n}+\frac{4}{3}y_n
$$
If we proceed further, we can find that this gives:
$$
x_n=\frac{a_n}{3^n} \space\text{where}\space a_0=2,\space a_1=15,\space a_{n+1}=8a_n-9a_{n-1} \\
y_n=\frac{b_n}{3^n} \space\text{where}\space b_0=1,\space b_1=6,\space b_{n+1}=8b_n-9b_{n-1}
$$
But if we take these equations modulo $9$, we see that $(2,1)$ and $(5,2)$ are the only integer solution, but there surely is also $(37,14)$. Where did I go wrong? Every answer will be appreciated, but I'm not used to the approach with continued fractions, so preferably I would like to see an answer avoiding this.</p>

<p>EDIT:</p>

<p>My main question is:</p>

<p>Where is my fault? Or is my script wrong?</p>
",number_theory
"<p>...and encoding it as a probability distribution.</p>

<p>Suppose we have a sequence of non-negative integers that is periodic with period $N$: </p>

<p>\begin{equation*}
A_{1},A_{2},...,A_{N},A_{1}...
\end{equation*}</p>

<p>Each $A_{k}$ takes on a value no greater than some constant $B$:</p>

<p>\begin{equation*}
0 \leq A_{k} \leq B
\end{equation*}</p>

<p>We then take this sequence and do a simple convolution, for some constant $L &gt; 0$ and $1 \leq n \leq N$:</p>

<p>\begin{equation*}
S_{L}(n) = A_{n} + A_{n+1} +...+ A_{n+L-1}.
\end{equation*}</p>

<p>From $S_{L}(n)$ we then form a probability distribution $P(n)$ which gives the frequency of each of its values. Let $e_{j}(k) = 1$ if $j = k$ and $0$ otherwise. Then:</p>

<p>\begin{equation*}
P(n) = (e_{n}(S_{L}(1)) + e_{n}(S_{L}(2)) +...+ e_{n}(S_{L}(N))) / N.
\end{equation*}</p>

<p>What I would like to find out is the extent to which this process can be reversed. I have two data points:</p>

<p>1) I know (pretty much) everything about the probability distribution $P(n)$: the distribution itself, its mean, range, variance, skewness, kurtosis, etc.</p>

<p>2) I can tell you the frequency of values of $A_{k}$ in one period, so that if the sequence is 1,0,2,3,1,0, I can tell you there are two 0's, two 1's, one 2, and one 3.</p>

<p>To what extent am I able to reconstruct the sequence $A_{k}$ from these two data points?</p>
",number_theory
"<p>Consider the prime counting function</p>

<p>$$ \pi(x) = \ the \ number \ of \ primes \ less \ than \ or  \ equal \ to \ x$$</p>

<p>It is well known due to the sieve eratosthenes that given an integer $n$ and the set of primes less than or equal to $\sqrt{n} = p_1, ... p_k$ that the total number of additional primes generated is:</p>

<p>$$ A(n)=  n - \sum_{i = 1}^{k}\left[ \frac{n}{p_i} \right] +\sum_{i = 1, j \ne i, j = 1}^{k,k}\left[ \frac{n}{p_i p_j} \right] ...  $$</p>

<p>Based on simple inclusion and exclusion:</p>

<p>Therefore naturally I would assume that </p>

<p>$$\pi(\sqrt{n}) + A(n) = \pi(n)$$</p>

<p>That is primes less than the the root of n plus primes bigger than the root of n but less than n gives all the primes less than n.</p>

<p>But instead the formula in this wiki page: <a href=""http://en.wikipedia.org/wiki/Prime-counting_function#Algorithms_for_evaluating_.CF.80.28x.29"" rel=""nofollow"">http://en.wikipedia.org/wiki/Prime-counting_function#Algorithms_for_evaluating_.CF.80.28x.29</a> asserts what I have is:</p>

<p>$$\pi(n) + 1 = \pi(\sqrt{n}) + A(n)$$</p>

<p>Where is this '1' coming from?</p>
",number_theory
"<p>I've read <a href=""http://math.stackexchange.com/questions/59680/how-to-tell-if-some-power-of-my-integer-matrix-is-the-identity/59709#59709"">this question</a> about identity power of an integer matrix. </p>

<p>But how about power of a matrix modulo $p^\alpha$.
$$A^m \equiv I \pmod{p^\alpha} $$</p>

<p>How can I find the minimal $m$ that the above equation hold?</p>

<p>Or how to prove that such $m$ does not exist? </p>
",number_theory
"<p>I've a very basic question on absolute values on fields. If $K$ is a valued field with absolute value $|- |:K\to \mathbb R_{\geq0}$ then is the map $|-|':K\to \mathbb R_{\geq0}$ defined by $|x|'=|x|^r$ for some $r&gt; 0$ also an absolute value? How do I show that the triangle inequality still holds for $|-|'$? Maybe this is not possible?</p>

<p>Many thanks. </p>
",number_theory
"<p>I have recently read ""The music of the primes"" by Marcus du Sautoy (see excerpt <a href=""https://plus.maths.org/content/music-primes"" rel=""nofollow"">here >>></a>). There he writes:</p>

<p>""So how fair are the prime number dice? Mathematicians call a dice ""fair"" if the difference between the theoretical behaviour of the dice and the actual behaviour after $N$ tosses is within the region of the square root of $N$. The heights of Riemann's harmonics are given by the east-west coordinate of the corresponding point at sea-level. If the east-west coordinate is $c$ then the height of the wave grows like $N^c$. This means the contribution from this harmonic to the error between Gauss's guess and the real number of primes will be $N^c$. So if the Riemann Hypothesis is correct and $c$ is always $1/2$, the error will always be $N^{1/2}$ (which is just another way of writing the square root of $N$). If true, the Riemann Hypothesis means that Nature's prime number dice are fair, never straying more than the square root of $N$ from Gauss's theoretical prime number dice.""</p>

<p>However, we know from Helge von Koch (1901)[2] that if the Rieman Hypothesis true, then:
$$\pi(x)=Li(x)+\mathcal O(\sqrt x \log x)$$
where $\pi(x)$ prime counting function and $Li(x)$ according Gauss.</p>

<p><strong>My question:</strong></p>

<p>Is what Sautoy says correct? Is the error indeed $(\sqrt x \log x)$ or as Sautoy states $\sqrt x$? Or did I misunderstand something?</p>

<p>[2]: Von Koch, Helge (1901). ""Sur la distribution des nombres premiers"" (On the distribution of prime numbers). Acta Mathematica (in French). 24 (1): 159–182.</p>
",number_theory
"<p>Let $\mathbb{K}$ a finite extension of $\mathbb{Q}$ and $\mathcal{O}_\mathbb{K}$ its ring of integers. Assume $\mathcal{O}_\mathbb{K}=\mathbb{Z}[\alpha]$, that is generated as a ring by a single element $\alpha\in\mathbb{K}$. I am asked to show that, for every prime $p\in\mathbb{Z}$, there are at most $p$ places on $\mathbb{K}$ over $p$, that is at most $p$ ways to extend the non archimedean value $|\cdot|_p$ to $\mathbb{K}$.</p>

<p>I don't know how to start attacking the problem, any hint?</p>

<p><strong>Edit</strong>: there was a typo in the original problem. The <em>correct</em> question was to prove that there are at most $p$ places on $\mathbb{K}$ over $p$ <strong>of residue degree 1</strong>, and the proof follows from Adam Hughes' answer.</p>
",number_theory
"<p>A few months ago, someone told me there existed a scheme theoretic proof of the irreducibility of cyclotomic polynomials. I've tried coming up with a proof, and when that didn't really yield anything $($just the scattered thoughts I have below$)$, I searched online for a reference to a proof, to no avail. Can anyone provide a proof or a reference to one? Does a proof even exist via schemes, or was this someone trolling me? Would this question be a better fit on MathOverflow?</p>

<p>Here are my thoughts so far on such a proof, if it were to exist.</p>

<p>The standard linear algebraic $($or in context of ""modern"" frameworks, the ""$p$-adic""$)$ formulation of the irreducibility of cyclotomic polynomials is as follows.</p>

<p><strong>Theorem.</strong> Let $n \in \mathbb{N}$. The degree of $\mathbb{Q}(\zeta_n)/\mathbb{Q}$ is $[\mathbb{Q}(\zeta_n):\mathbb{Q}] = \phi(n)$.</p>

<p>This is saying is that the vector space generated by the powers of $\zeta_n$ over $\mathbb{Q}$ is of dimension $\phi(n)$. The most important case in the proof is where $n = p$, where one shows that the $\mathbb{Q}$-vector space $\mathbb{Q}(\zeta_p)$ has dimension $p-1$. This is done by showing $$\dim_\mathbb{Q}(\mathbb{Q}(\zeta_p)) = \dim_\mathbb{Z}(\mathbb{Z}[\zeta_p]) = \dim_{\mathbb{F}_p}(\mathbb{Z}[\zeta_p]/p),$$and that $\dim_{\mathbb{F}_p}(\mathbb{Z}[\zeta_p]/p) = p-1$.</p>

<p>Now, the purpose of scheme theory is to make geometry out of rings. In the case of this elusive proof, I imagine the scheme theoretic perspective claims that the extension of rings $\mathbb{Z}[\zeta_n]/\mathbb{Z}$ is like a ramified cover of topological spaces. One imagines $\mathbb{Z}$ as space populated by its primes, and similarly for $\mathbb{Z}[\zeta_n]$. The scheme theoretic restatement of the above theorem is that this is a connected cover of degree $\phi(n)$. In the standard proof of the linear algebraic formulation above one sees this by looking above the prime $p$, where one sees ""nilpotency"" of order $p-1$, which implies that the cover must have degree $p-1$.</p>

<p>Is this viable? Should I use some sort of monodromy or something? $($But that's harder to make sense of in the arithmetic setting...$)$</p>
",number_theory
"<p>The number $711000000$ can be written as $79^1 \times 2^6 \times 3^2 \times 5^6$. How are these numbers found? </p>

<p>I guess the more general question is - given $n \in \mathbb Z $, how can you 'decompose' it into the product of primes raised to different powers?</p>
",number_theory
"<p>Let $n\in\mathbb{N}$.  Then, when is $p^n(p^n-1)$ divisible by $2n$ for all $p$ prime?  I know the following:</p>

<ul>
<li>$n$ must be $1$ or even. (in the odd case, $p=2$ gives a counterexample).</li>
<li>If $n=2^k$ for $k\geq 0$, then $p^n(p^n-1)$ divisible by $2n$ for all $p$ prime.</li>
</ul>

<p>There are more values for $n$ that work as well for $p$ prime ($e.g.$ $n=6$). However, for example, $n=10$ does not work ($i.e.$ $2^{10}(2^{10}-1)=1047552$ which is not divisible by $20$). </p>

<p>Is there something more general to be said?  I'm hoping for a statement along the lines of:</p>

<blockquote>
  <p>""$p^n(p^n-1)$ divisible by $2n$ for all $p$ prime <em>if and only if</em> $\ldots$"" </p>
</blockquote>
",number_theory
"<h1>Problem</h1>

<p>Let $A^{*}_{S}$ be the set of sentences consisting of S1, S2, and all sentences of the form</p>

<p>$\phi (0)\rightarrow\forall v_{1}(\phi (v_{1}\rightarrow\phi(Sv_{1}))\rightarrow\forall v_{1}\phi (v_{1})$</p>

<p>where $\phi$ is a formula ( in the language of $\mathfrak{N}_{S}$ in which no variable except $v_{1}$ occurs free. Show that $A_{S}\subseteq\mathrm{Cn}A^{*}_{S}$. Conclude that $\mathrm{Cn}A^{*}_{S}=\mathrm{Th}\mathfrak{N}_{S}$. (Here $\phi(t)$ is by definition $\phi^{v_{1}}_{t}$. The sentence displayed above is called the induction axiom for $\phi$.)</p>

<p>Where</p>

<p>S1. $\forall x Sx\neq0$</p>

<p>S2. $\forall x \forall y (Sx=Sy\rightarrow x=y)$</p>

<p>S3. $\forall y(y\neq 0 \rightarrow \exists x y=Sx)$</p>

<p>S4.n $\forall x S^nx\neq x$</p>

<h2>So Far</h2>

<p>So, I understand thus far that to show $A_{S}\subseteq\mathrm{Cn}A^{*}_{S}$ I need to show that the induction axiom above defines S3 and S4.n; I understand that the best way to do this is by induction, and that the base case for showing S3 is (below).  What I do not understand is where to take the induction step from there.</p>

<h2>Prove S3</h2>

<p>Base Case: Let y in $\forall y(y\neq 0 \rightarrow \exists x y=Sx)$ be 0.  It is the case that $A_{S}^{*}\vdash(0\neq0\rightarrow\exists x0=Sx)$, as the antecedent is logically false ($\vdash 0\ne 0$).</p>

<p>Induction Step: ...Not really sure.</p>
",number_theory
"<p><strong>Question:</strong></p>

<p>Suppose that $\mathbb Q[\sqrt{d}]$ is a UFD, and $α$ is an integer in $\mathbb Q[\sqrt{d}]$ so that $α$ and $\barα$ have no common factor, but $N(α)$ is a perfect square in $\mathbb Z$. How can I show that $α$ is a perfect square in the quadratic integers in $\mathbb Q[\sqrt{d}]$?</p>

<p><strong>What I have Done:</strong></p>

<p>I'm not sure if I'm approaching this correctly but if  $\alpha$ and  $\bar{\alpha}$ have no common factor, then $\alpha=\pi_{1}\pi_{2}\cdots\pi_{k}$ and  $\bar{\alpha}=\pi'_{1}\pi'_{2}\cdots\pi'_{j}$ where $ \pi_{i}$ and  $\pi'_{i} $ are prime in  $\mathbb{Q}(\sqrt{d})$. But $N(\alpha) = \alpha\bar{\alpha}=\pi_{1}\pi_{2}\cdots\pi_{k}\pi'  _{1}\pi'_{2}\cdots\pi'_{j}=n^{2}$ where  $n \in \mathbb{Z}$. Somehow I need to show that $\alpha=\beta^{2}$ where  $\beta$ is a quadratic integer in $ \mathbb{Q}(\sqrt{d})$ (i.e.,  $\alpha$ is a perfect square in the quadratic integers in  $\mathbb{Q}(\sqrt{d})$)</p>
",number_theory
"<p>Is it known exactly for which integers $a,b,c$ the equation $ax^2+bxy+cy^2=0$ has a nontrivial solution? If not, what is known about this problem in general? (I am asking about the specific problem of ""for which integers $a,b,c$ does $ax^2+bxy+cy^2=0$ have a nontrivial solution in integers $x$ and $y$?)</p>

<p>Thanks</p>
",number_theory
"<p>Can $\pi(x)$ be written in terms of $\psi(x)$? I can only seem to approximate it:</p>

<p>$$
\pi(x)\approx\sum_{n=1}^{\infty}\left[\dfrac{\mu(n)}{n}\left(\dfrac{1}{\log(x^{1/n})}\left(\psi(x^{1/n})-x^{1/n}+\sqrt{\pi}\right)+\operatorname{li}(x^{1/n})-1\right)\right]
$$</p>

<p>Is there a relationship of equivalence between $\psi(x)$ and $\pi(x)$ (ie, an inversion formula), or can it only approximate it?</p>

<p>Out of interest I include the difference up to $10^5$ between the RHS and the LHS</p>

<p><img src=""http://i.stack.imgur.com/WuXn9.gif"" alt=""enter image description here""></p>

<p>and both together for very small $x$</p>

<p><img src=""http://i.stack.imgur.com/y4hvX.gif"" alt=""enter image description here""></p>
",number_theory
"<p>In my algebraic structures textbook I have come across a tricky question that I am trying to solve which goes as follows:</p>

<p>suppose that $d|(a^n-1) $ and $d|(a^m-1)$ where  $m,n$ are natural numbers and $a,d$ are integers, then show that $ d|(a^{gcd(m,n)}-1) $ . What I know is that clearly $a^m$ and $a^n$ are congruent to 1 modulo d, and that by Bezout's theorem the $gcd(m,n)$ is of the form $k=xm+yn$ so that $a^{gcd(m,n)}$ can be written as $a^{xm}a^{yn}$ but I am not sure how to tie all these ideas together. Any hints would be appreciated.</p>
",number_theory
"<p>By congruence computation we get that $n= a^5+b^5+c^5$ implies $n \not \equiv  4,5,6,7  \pmod{11} $<br>
 (with $a,b,c \in \mathbb{Z}$)  </p>

<p>For $a,b,c \in \{-100,-99, \dots , 99, 100\}$, the set of integers $n \in \{0,1,\dots , 99,100 \}$ we get is<br>
$$\{ 0, 1, 2, 3, 12, 30, 31, 32, 33, 34, 63, 64, 65, 96 \}$$The point is that it is exactly the same for $a,b,c \in \{-10000,-9999, \dots , 9999, 10000\}$, so that we could expect that there is no other natural number $n \le 100$ representable like that. Nevertheless according to what happens for cubes (see <a href=""http://mathoverflow.net/a/223121/34538"">here</a>), we could also expect the existence of such representations with large integers. By the congruences above, the smallest natural numbers to look is $n=8$.  </p>

<p><em>Question:</em> Can a sum of three fifth power of integers be $8$?    </p>

<p>Next we should look to $n = 9,10,11,13,14,19,20,21,22,23,24,28,29, \dots$ </p>
",number_theory
"<p>I know this has been hinted at a previous page but I can't seem to find a complete answer.</p>

<p>we know that $\gcd(a,m) = ax_1+mx_2$ from the euclidean algorithm. In a similar way, we know that $\gcd(b,m)=bx_2+mx_3$ and $\gcd(ab,m)=abx_5+mx_6$, and so</p>

<p>$$\frac{\gcd(a,m)\gcd(b,m)}{\gcd(ab,m)}=\frac{(ax_1+mx_2)(bx_2+mx_3)}{abx_5+mx_6}=\frac{abx_1x_3+amx_1x_4+bmx_2x_3+m^2x_2x_4}{abx_5+mx_6}$$</p>

<p>I don't understand how we can say that it divides without a remainder.</p>

<p>this is not homework. I'm doing this for sports.</p>
",number_theory
"<p>The question is as follows.</p>

<blockquote>
  <blockquote>
    <p>Let $K = \mathbb{Q}(\sqrt[m]{a},\sqrt[n]{b}) $, where $m,n,a,b$ are positive integers such that they are pairwise coprime. Assume that $[K:\mathbb{Q}]=mn$/ Prove that no prime numbers can totally ramify in $K/\mathbb{Q}$.</p>
  </blockquote>
</blockquote>

<p>I assume we would need to find such prime numbers that are ramified in $\mathbb{Q}(\sqrt[m]{a})/\mathbb{Q}$, $\mathbb{Q}(\sqrt[n]{b})/\mathbb{Q}$ respectively. I know if $p|\text{disc}(L)$, then it is ramified. The discriminate can be found using the following:</p>

<p>$$
\text{disc}(\alpha) = (-1)^{\frac{k(k-1)}{2}}\left[(-1)^{1-k}(k-1)^{k-1}c^k + k^kd^{k-1}\right]
$$</p>

<p>Where $f(x) = x^k + cx + d$. And since $a,b,n,m$ are pairwise coprime, then disc($K$)=disc$(\mathbb{Q}(\sqrt[m]{a}))^n$disc$(\mathbb{Q}(\sqrt[n]{b}))^m$. </p>

<p>Now if there is a prime number that will totally ramify in $K/\mathbb{Q}$, then there is only one ramification index, $e_i$, such that $e = mn = [K:\mathbb{Q}]$. All I would need to do is show that there is more than one ramification index via transitivity. This is where I am stuck. How would I go about showing there is more than one ramification index, such that no prime number that totally ramifies $K/\mathbb{Q}$. </p>

<p>Thanks in advance for any feedback.  </p>
",number_theory
"<blockquote>
  <p>If $p$ is an odd prime and $k$ an integer with $0&lt;k&lt;p-1$ prove that $1^k + 2^k + \ldots + (p-1)^k$ is divisible by $p$. Given hint: use primitive root.</p>
</blockquote>

<p>This is a question on a practice final of mine. For $k$ being odd, it seems obvious (as the $\pm$ terms cancel out), but I cannot figure out how to do this for the general case.</p>
",number_theory
"<p>I have researched this question and need help.  In general is there only one solution to the equation $\sigma(nx) = (n+4)x$ for every $n$?  Specifically, is there only one solution to $\sigma(5x) = 9x$? ( I know x = 2 is a solution, but is there a way to prove that there are no more?)</p>
",number_theory
"<p>Throughout this question, an L-function is both an automorphic L-function and an element of the Selberg class such that whenever $F$ and $G$ are L-functions, then so are $F.G$ and $F\otimes G$, where $\otimes$ denotes the Rankin-Selberg convolution.</p>

<p>Let's now consider the 'kernel affine space' of an L-function $F$, defined as the affine space of minimal dimension containing all the non trivial zeroes of $F$. The analogue of RH for $F$ holds if and only if its kernel affine space is 1-dimensional.</p>

<p>My question is the following: as the tensor product of $R^{n}$ with $R^{m}$ is isomorphic to $R^{mn}$ can one establish that the kernel affine space of $F\otimes G$ is 1-dimensional if and only if the kernel affine spaces of both $F$ and $G$ are themselves 1-dimensional? Is a 'motivic' interpretation possible?</p>

<p>Thanks in advance.</p>
",number_theory
"<p>For example:</p>

<p>If n = 12</p>

<p>Then starting at 4! because 3! is less than 12</p>

<p>(4!) % 12 == 0</p>

<p>Therefore (4!) * 5 = (5!) % 12 == 0 </p>

<p>etc </p>

<p>and so on until (n-1!) because every factorial after that would obviously be divisible by n. </p>

<p>This is not easy for my (extremely out of date)computer to solve so here is a short list of numbers I have found this to be true for:</p>

<p>1,2,3,6,8,12,24,30,40,60,120,144,180,240,360,720,840,1008,1260,1680,2520, 5040,5760,6720</p>

<p>*arguably 1 2 and 3 should not be included in this list</p>
",number_theory
"<blockquote>
  <p>Prove that $(m, n) = (1, 1)$ is the only solution for the Diophantine Equation $$2 \cdot 5^n = 3^{2m} + 1$$ where $(m, n) \in (\mathbb{Z}^+)^2$.</p>
</blockquote>

<p>I've managed to prove that both $m$ and $n$ are odd seeing $\bmod 3\text{ and } 10$ respectively. Also, $\forall n \ge 1$, $10$ divides the LHS. I am not able to proceed from here. Any help would be appreciated.</p>
",number_theory
"<p>I know Dijkstra's algorithm to find the shortest way between 2 nodes, but is there a way to find the shortest path between 3 nodes among $n$ nodes? Here are the details:</p>

<p>I have $n$ nodes, some of which are connected directly and some of which are connected indirectly, and I need to find the shortest path between 3 of them.</p>

<p>For example, given $n = 6$ nodes labelled A through F, and the following graph:</p>

<pre><code>A--&gt;B--&gt;C
A--&gt;D--&gt;E
D--&gt;F
</code></pre>

<p>How can I find the shortest path between the three nodes (A,E,F)?</p>

<p>I am looking for a solution similar to Dijkstra's shortest path algorithm, but for 3 nodes instead of 2.
<br/>
Please Note : <br/>
1- The Starting Node is A  <br/>
2- The Sequential is not important just the path needs to cover all these Nodes   <br/>
3- Their is no return back to A   <br/>
Please find the diagram Image
<img src=""http://i.stack.imgur.com/M1wxF.png"" alt=""enter image description here"">
Regards &amp; Thanks<br />
Nahed</p>
",number_theory
"<p>I was recently thinking about prime numbers, and at the time I didn't know that they had to be greater than $1$. This got me thinking about negative prime numbers though, and I soon realized that, for example, $-3$ could not be prime because $3 \cdot (-1) = -3$. In some sense $-1$ could be though because its only factors that are integers are $-1$ and $1$, and this is allowed for primes. Is there some way, by this logic, that $-1$ can be considered a prime then?</p>
",number_theory
"<p>Prove that the equation $n^a + n^b = n^c$, with $a,b,c,n$  positive integers, has infinite solutions if $n=2$, and no solution if $n\ge3$.</p>
",number_theory
"<blockquote>
  <p>Find all the numbers $a$ such that the number $an(n+2)(n+4)$ is an integer for all $n \in \mathbb{N}$</p>
</blockquote>

<p>It's trivial to see that if $a$ is irrational, we get no solution. </p>

<p>Thus $a \in \mathbb{Q} \Rightarrow a = \dfrac{p}{q} ~ (*)$ where $p, q \in \mathbb{Z}$ and $\gcd(p,q)=1$. Then</p>

<p>$$\begin{split} an(n+2)(n+4)=k &amp;\stackrel{(*)}{\Rightarrow} \dfrac{p}{q}n(n+2)(n+4)=k \\ &amp; \Rightarrow pn^3+6pn^2+8pn-kq=0 \end{split}$$</p>

<p>By the integer root theorem, for $n$ to be an integer it should be $kq = zn ~ (1)$. Hence </p>

<p>$$\begin{split} \Rightarrow pn^3+6pn^2+8pn-kq=0 &amp;\stackrel{(1)}{\Rightarrow} pn^2+6pn+8p-z=0 \\ &amp;\Rightarrow n = \dfrac{-6p \pm 2\sqrt{p^2+zp}}{2p} \\ &amp;\stackrel{n&gt;0}{\Longrightarrow} n = -3 + \dfrac{\sqrt{p^2+zp}}{p} \in \mathbb{Z}\end{split}$$ </p>

<p>But again for $n$ to be an integer it should be $p^2+zp=p^2m^2 \Rightarrow p = \dfrac{z}{m^2-1} ~(2)$ </p>

<p>By (1) and (2) we get that $$kq=p(m^2-1)n \Rightarrow \dfrac{p}{q} = \dfrac{k}{(m^2-1)n} \stackrel{n=m-3}{\Longrightarrow} \boxed{a = \dfrac{k}{(m-3)(m-1)(m+1)}}$$</p>

<p>We see that if $m$ is a small number (like $2$ and $3$) the equation is satisfied, but for $m$ being a larger number (like $10$)then the initial number is not an integer. Please tell me if I have done anything wrong or if I should add anything to my solution.</p>
",number_theory
"<p>I have to divide $2860$ by $3186$. The question gives only $2$ minutes and that division is only half part of question. Now I can't possibly make that division in or less than $2$ minutes by applying traditional methods, which I can't apply on that division anyways.</p>

<p>So anyone can perform below division using faster technique?</p>

<p>$2860/3186$</p>

<p>Thanks for reading, hoping to get some answers. :)</p>

<p>This is a multiple choice question, with answers $6/7$, $7/8$, $8/9$, and $9/10$.</p>
",number_theory
"<p>Bernouli's Formula for sum of kth powers of first n natural numbers is given by: 
$$f_k(n)=\frac{1}{k+1}\sum_{j=0}^k{k+1\choose j}B_j(n+1)^{k+1-j}$$
where $Bj$ is the $j^{th}$ Bernoulli Number and is in a sense recursively given by:$$B_j=-\frac{1}{j+1}\sum_{i=0}^{j-1}{j+1 \choose i}B_i$$.</p>

<p>I did find a generalized proof of this for Generalized case where powers can be complex numbers. I am looking for simpler proofs. Do you have any idea if this can be proved by induction.</p>

<p>Thank you.</p>

<p>PS. I am not sure of tags and appreciate if they are corrected.</p>

<p><strong>Added</strong> By simpler I mean that do involve only integer powers.</p>
",number_theory
"<p>This is Problem 1.7 from <a href=""http://www.colby.edu/personal/fqgouvea/deform.dvi"" rel=""nofollow"">Gouvea's lecture notes on deformations of Galois representations</a>. In particular, he asks you to show that it has many subgroups of finite index which are not closed. So here's what I've got so far, which may be wrong.</p>

<p>I can write the compositum as F = <b>Q</b>[&radic;–1, &radic;2, &radic;3, &radic;5, &radic;7 ...] (can I?) and then the Galois group G = Gal(F/<b>Q</b>)  is isomorphic to a direct product &Pi;<sub>p</sub> (<b>Z</b>/2<b>Z</b>) where the product is taken over all primes p, as well as p=-1, and the pth component is generated by the conjugation &sigma;<sub>p</sub> defined by &radic;p -> –&radic;p.</p>

<p>An example of a subgroup which isn't closed would be the subgroup <strong>H</strong> consisting of <i>finite</i> products of conjugations, since for example, <strong>H</strong> contains the sequence &sigma;<sub>2</sub>, &sigma;<sub>2</sub>&sigma;<sub>3</sub>, &sigma;<sub>2</sub>&sigma;<sub>3</sub>&sigma;<sub>5</sub>, &sigma;<sub>2</sub>&sigma;<sub>3</sub>&sigma;<sub>5</sub>&sigma;<sub>7</sub>... which converges to the automorphism ""conjugate everything"", and this automorphism is not contained in <strong>H</strong>.</p>

<p>However this subgroup is nowhere near being finite index--it has the cardinality of the natural numbers, whereas G has the cardinality of the reals. The only finite index subgroups I can think of take are of the form Gal(F/K) where K is a finite extension of <b>Q</b>, but of course these are by definition all closed. So I guess I've stuffed up somewhere, and I'd be really grateful for any help?! In know this may seem a bit ""homework questiony"" but it's not, it's just something that's really bugging me!</p>
",number_theory
"<p>what is the best Schnirelmann Constant for Goldbach Conjecture  ?</p>

<p>On <a href=""http://mathworld.wolfram.com/SchnirelmannConstant.html"" rel=""nofollow"">http://mathworld.wolfram.com/SchnirelmannConstant.html</a> 
the best Schnirelmann Constant is 7 ( from Ramaré )</p>

<p>My understanding is that Ramaré results is only for sufficiently large number, not for <strong>all numbers</strong>.</p>

<p>Is my understanding right ?</p>

<p>If so, what is the current best Schnirelmann Constant for <strong>all number</strong> ?</p>
",number_theory
"<p>Let $W_{s,r,n}$ be the total number of ways that the sum $s$ can be displayed after throwing $r$ number of $n$-sided dice. Define</p>

<p>$$W_{s,0,n} =
\begin{cases}
1,  &amp; \text{if s = 0} \\
0, &amp; \text{if s $\neq$ 0} \\
\end{cases}
$$</p>

<p>for all $s \in \mathbb Z$ and $n \in \mathbb N^*$. Can you prove that</p>

<p>$$W_{s,r,n} =W_{s-1,r,n} + W_{s-1,r-1,n} - W_{s-(1+n),r-1,n}$$</p>

<p>for all $s \in \mathbb Z$, $r \in \mathbb N^*$, and $n \in \mathbb N^*$?</p>
",number_theory
"<p>Does a positive constant $\nu$ exist so that $\varphi(n)&gt;\nu\cdot n$ for all $n$? Clearly this problem is exactly the same as asking if $\prod\limits_{i=1}^\infty \frac{p_i-1}{p_i}=0$. This is because $\varphi(n)=n\prod\limits_{p|n}\frac{p-1}{p}$. And if $n$ has $k$ prime divisors this is clearly greater than $n\prod_{i=1}^k\frac{p_i-1}{p_i}$.</p>

<p>So the problem breaks down to figuring out to what the sequence $a_n=\prod\limits_{i=1}^n\frac{p_i-1}{p_i}$ converges. (It clearly converges since it is decreasing and bounded). In fact we only need to figure out if it converges to zero or something else.</p>
",number_theory
"<p>Not really sure how to approach this one at all.</p>

<p>I tried</p>

<p>$$\begin{align}
n^{k+1} &amp; \equiv n^k + 1 \pmod p \\
n^k \times n &amp; \equiv n^k + 1 \pmod p \\
n^k \times n - n^k &amp; \equiv 1 \pmod p \\
n^k \times (n - 1) &amp; \equiv 1 \pmod p
\end{align}$$</p>

<p>but since $n$ is a primitive root, this means that $n^{p-1} \equiv 1 \bmod p$ but I can't really figure out what to do from here.</p>

<p>Any suggestions?</p>
",number_theory
"<p>Prove that $(k^k)$ is periodic modulo 3 and find its period. Not sure how to approach this.</p>

<p>Edit: So I know the sequence is 1, 1, 0, 1, 2, 0, ... (plugging in k = 1, 2, 3, ...) so I think the period should be 6 since thats the length of each cycle. I also know a function f(x) is periodic if there exists some minimum n such that f(x + n) = f(x) for all x in the domain of f.</p>

<p>Plugging every 6 term is 0 so f(x + 6) = f(x) mod 3.. is this right?</p>
",number_theory
"<p>$$\int_0^\infty x^t\operatorname{csch}x\text{ d}x=\frac{a\zeta(t+1)}{b}$$
for $t\in\Bbb{N}$</p>

<p>How might one represent $a,b$ in terms of $t$?
(Note that $a,b\in \Bbb{N}$)</p>

<p>If possible, could one also provide a proof please? </p>
",number_theory
"<p>Is $\pi$ periodic in any base-k numeral system, where k is integer ? And what is the status of this problem?</p>
",number_theory
"<p>I'm having trouble figuring out how to show the general existence part of the following problem. </p>

<p>Suppose $n\in\{1,2,3...\}$ and $n\equiv 7\mod{10}$. Show that $\exists$ a prime divisor $p$ of $n$ s.t. $p\equiv 3\mod{10}$ or $p\equiv 7\mod{10}$.</p>
",number_theory
"<p>I feel like this wants to use the Hasse bound somehow since that's really the only tool we talked about with regard to counting points on a curve, but I'm not entirely sure how to get to that conclusion.</p>
",number_theory
"<p>I have $k = 37$ and $m = 101$<br>
How do I find $a$, given the value of $a^k \bmod m$?</p>

<p>I think this has to do with order of integers.</p>
",number_theory
"<p>How can I calculate $27^{41}\ \mathrm{mod}\ 77$ as simple as possible?</p>

<p>I already know that $27^{60}\ \mathrm{mod}\ 77 = 1$ because of <a href=""http://en.wikipedia.org/wiki/Euler%27s_theorem"">Euler’s theorem</a>:</p>

<p>$$ a^{\phi(n)}\ \mathrm{mod}\ n = 1 $$
and
$$ \phi(77) = \phi(7 \cdot 11) = (7-1) \cdot (11-1) = 60 $$</p>

<p>I also know from using modular exponentiation that $27^{10} \mathrm{mod}\ 77 = 1$ and thus</p>

<p>$$ 27^{41}\ \mathrm{mod}\ 77 = 27^{10} \cdot 27^{10} \cdot 27^{10} \cdot 27^{10} \cdot 27^{1}\ \mathrm{mod}\ 77 = 1 \cdot 1 \cdot 1 \cdot 1 \cdot 27 = 27 $$</p>

<p>But can I derive the result of $27^{41}\ \mathrm{mod}\ 77$ using $27^{60}\ \mathrm{mod}\ 77 = 1$ somehow?</p>
",number_theory
"<p>This is probably an easy question. Im Assuming whoever can answer this has access to S-boxes and P boxes etc. </p>

<p>Suppose the input to a round of DES is
$1010101010......10101010$. (64 bits)</p>

<p>Suppose the round key is
$11111111111111111111.....1111111111111111$ (48 1’s)</p>

<p>Compute the 53rd output bit of this round.</p>

<p>I am a little confused in how to approach this. Do I break up the 64 inputs into two 32 inputs and transform the second 32 into 48? Do I then add to the key mod 2?</p>

<p>If anyone can provide an answer or even the relevent steps involved (Ie like how to know which S-box to use) that would be great.</p>
",number_theory
"<p>I'm having some trouble with this proof. Here's the question: Use mathematical induction and Euclid's Lemma to prove that for all positive integers $s$, if $p$ and $q_1, q_2, \dotsc, q_s$ are prime numbers and $p$ divides $q_1q_2\dotsb q_s$, then $p=q_i$ for some $i$ with $1 ≤ i ≤ s$.</p>

<p>Here's what I know: Euclid's Lemma says that if $p$ is a prime and $p$ divides $ab$, then $p$ divides $a$ or $p$ divides $b$. More generally, if a prime $p$ divides a product $a_1 a_2 \dotsb a_n$, then it must divide at least one of the factors $a_i$. For the inductive step, I can assume $p$ divides $q_1q_2\dotsb q_{s+1}$ and let $a=q_1q_2\dotsb q_s$. Then, $p$ divides $aq_{s+1}$ and either $p$ divides $a$, $p$ divides $q_{s+1}$, or $p=q_{s+1}$. I know that since $q_i$ is prime, it cannot divide $q_i$ unless $p=q_i$ for some $1 ≤ i ≤ s$. I'm just not sure how to formulate the proof. Usually with Induction I can set some property $P(n)$ and test it is true for some base like $P(0)$ or $P(1)$ for the base step. I'm unsure how to go about it here. </p>
",number_theory
"<p>Let $p$ be a prime. If $\frac{p-1}{4}$ and $\frac{p+1}{2}$ are also primes then prove that $p=13$.</p>
",number_theory
"<p>I have an application that wants controllable random functions from $\mathbb{Z}^2$ and $\mathbb{Z}^3$ to $2^{32}$ , where by controllable I basically mean seedable by some parameters (say, on the order of 3 to 5 32-bit integers) such that the same seeds will always produce the same functions.  The most obvious way of doing this (for the two-dimensional case, say) would seem to be computing the value at some point $(x,y)$ by using $x$, $y$, and the seed parameters as seeds for something like an LFSR generator or a Mersenne Twister, then running the RNG for some fixed number of steps and taking the resultant value as the value of the function at that point.</p>

<p>My question is, how can I be certain that this procedure won't keep too much correlation between adjacent 'seed points', and is there either a straightforward analysis or even just some general guideline for how many iterations would be necessary to eliminate that correlation?  My first back-of-the-envelope guess would be that each iteration roughly doubles the decorrelation between given seed values, so that 32 iterations would be necessary to achieve the requisite decorrelation over a range of $2^{32}$ values (and in practice I'd probably double it to 64 iterations), but that's strictly a guess and any proper analysis would be welcome!</p>

<p><strong>Edited for clarification:</strong> To further outline the issue, I may be sampling this random function $f$ (for some given seed parameters) at arbitrary values, and need those samples to be identical between passes; so for instance, if a first application computes $f(0, 0)$, $f(437, 61)$, $f(-23, 129)$, and then $f(5,3)$, and a second (potentially concurrent) application computes $f(1,0)$ and then $f(5,3)$, both passes need to find the same value of $f$ at $(5,3)$.  I may also be sampling $f$ at arbitrary points, so I'd like the evaluation to take constant time (and in particular, evaluating $f(x,y)$ shouldn't take time linear in $x+y$).</p>
",number_theory
"<p>This question was motivated by pondering <a href=""http://math.stackexchange.com/questions/1442/is-there-a-direct-proof-of-this-lcm-identity"">this lcm identity</a>.</p>

<p>Consider that $\gcd(1,6,15) = 1$, but $\operatorname{lcm}(1,6,15)=30$, but $1\cdot 6\cdot 15 = 90$.  $(2,6,15)$ shows a similar phenomenon.</p>

<p>So what is the correct identity for $n$-ary $\gcd$/$\operatorname{lcm}$?</p>
",number_theory
"<p>I'm reading Ergodic Theory and Differential Dynamics by Ricardo Mane. 
There is a theorem in the book that states the following:
If x $\in$ $R^n$, the translation L $_{\pi(x)}$: $T^n \rightarrow T^n$ is ergodic if and only if (k,x) $\notin$ Z for every k $\in Z^n$.</p>

<p>I was hoping someone could either give me or direct me to, a comprehensible proof of this result, as Mane's does not give very much explanation.</p>
",number_theory
"<p>This is a problem from Elementary Number Theory by Burton (7th ed.)
I am finding the smallest odd number n such that $2^n-1$ is divided by twin primes $p$ and $q$, where $3 &lt; p &lt; q$.</p>

<p>I followed a hint from the book, and result are $p \equiv -1\pmod {24}$ and $q \equiv 1\pmod {24}$. Now, how can I solve this?</p>
",number_theory
"<blockquote>
  <p>Show that $x^3 + y^3 + z^3 + t^3 = 1999$ has infinitely many integer solutions.</p>
</blockquote>

<p>I have not been able to find a single solution to this equation. With some trial I think there does not exist a solution with all of them positive. Can you please help me proceed?</p>

<p>Thanks.</p>
",number_theory
"<p>I am reading a book in discrete mathematics and it assumes that a multiplication of two integers yields an integer. </p>

<p>Although that this book's saying is justifiable since the book is making an assumption, I found that that this is ""completely wrong but it is still a good estimation"". </p>

<p>let $n \ge 1$ be an integer. Then, by the above assumption, $(n^2-3) * 5$ yields an integer. But, this is not accurate. </p>

<p>Factorize $n^2-3 = (n+\sqrt{3}) (n-\sqrt{3})$.</p>

<p>Now, use a computer system to evaluate this statement substituting any integer ($1$ or larger). You will find that, extremely, the result is not an integer and therefore we kinda have an contradiction between $n^2-3$ and its factorization. </p>

<p>So, ""Is it accurate to say that multiplication of two integers yields an integer ?""</p>
",number_theory
"<p>I have been given $\phi(m)$ and $m = pq$.<br>
Because $p$ and $q$ are primes, $\phi(m) = (p - 1)(q - 1)$<br>
So I was able to find that $p+q$ = sum<br>
But how do I find $p$ and $q$ after this?
The sum is larger than $23000$, so I do not know how to find $p$ and $q$. </p>
",number_theory
"<blockquote>
  <p>for $N \ge 4$. Show for prime numbers,  $p \equiv 1$ mod $(N!)$ that none of the numbers $1,2,...,N$ are primitive roots modulo $p$</p>
</blockquote>

<p>I can't figure out where to start with this question, all I can think to use is the Legendre symbol and Euler's Criterion but I haven't been able to do it. Any help would be much appreciated.</p>
",number_theory
"<blockquote>
  <p>The generating function for Bernoulli polynomials is given by:<br>
  $$\frac{ue^{ux}}{e^u-1}=\sum_{n\geq 0}B_n(x)\frac{u^n}{n!}$$  </p>
</blockquote>

<p>Now, I have the following expression:<br>
$$\frac{1}{\alpha}\frac{u^2e^{u(\alpha x+y)}}{e^u-1}\sum_{k=1}^{\alpha-1}\frac{1}{e^u-e^{2\pi ik/\alpha}}$$<br>
and I want to rewrite it in terms of Bernoulli polynomials and then extract the coefficients of $\frac{u^n}{n!}$. </p>
",number_theory
"<p>Let $g_1(n)=\displaystyle{\sum_{p|n}} p$ and $g_2(n)=\displaystyle{\sum_{p^{\alpha}||n}} \alpha p,$ where $p^{\alpha}||n$ means that $p^{\alpha}|n$ and $p^{\alpha+1}$ does not divide $n.$ I am searching for estimates of these two functions or even upper bounds for them is sufficient for me.
Can someone help me?</p>

<p>Thanks in advance.</p>
",number_theory
"<p>I read a question on mathematics.I have not been able to figure out the answer.</p>

<p>the question is</p>

<p>given a set $Q=\{1,2,3,4,5,6,7\}$ such that I can have a subset $L$ from this set $Q$. I have been given a number string $Y$ in such a way that I know its starting digit and the end digit.</p>

<p>Now the rest of the digits from second digit to the last but one digit can be have any numbers of digits from the subset $L$.</p>

<p>Now the question how can i decide whether $Y$ can be made divisible by $3$ or $7$.</p>
",number_theory
"<p>When trying around with the <code>DivisorSigma</code> function of Mathematica, I found this Identity:</p>

<p>$\#\{a\mid\exists b\in\mathbb{Z}[i]: ab=n\}=\underbrace{\#\{a\mid\exists b\in\mathbb{N}: ab=n\}^2}_{\sigma(0,n)^2}\Leftrightarrow \forall p|n,\;p\text{ prime}: p\equiv 1\mod 4$</p>

<p>(In words: the number of gauss integer divisors of n is equal to the square of the number of integer divisors of n iff n is in <a href=""http://oeis.org/A004613"" rel=""nofollow"" title=""A004613"">A004613</a>)</p>

<p>I could verify it for values up to 10 million. However, I have been unable to find any Identities that could allow me to prove them. I could take several results from exactly that OEIS page, however none of those helped me out. I am missing some result that connects the gaussian integer divisors with the real ones. I would be very happy with any help on this problem.</p>
",number_theory
"<p>Let $p$ be a prime number. Then if $ f(x) = (1+x)^p$ and $g(x) = (1+x)$, then is $f \equiv g \mod p$?</p>

<p>I'm trying to prove that for integers $a &gt; b &gt; 0$ and a prime integer $p$, ${pa\choose b} \equiv {a \choose b}.$ To do this I use FLT to show that  $(1+x)^{pa} \equiv (1+x)^a \mod p$ and compare the coefficients of $x^b$ to complete the proof. Am I applying FLT correctly?</p>

<p>In general, do most theorems regarding integers/reals generalize to polynomials over the integers/reals? Are there some common pitfalls that I could make when trying to generalize such theorems?</p>
",number_theory
"<p>Find the smallest possible value of $n_1+n_2+\cdots+n_k$ such that $LCM(n_1,n_2,\ldots,n_k)=(2^2)(3^3)(5^5)$. Note that $k$ is not fixed.</p>

<p>I know the answer should be $k=3$, $n_1=2^2$, $n_2=3^3$, and $n_3=5^5$. How do I prove this rigorously?</p>

<p>Note: LCM is least common multiple.</p>
",number_theory
"<p>Let $f_n(x)$ be defined as the $n$th digit of the number $x$.</p>

<p>The result of $f_n(x)$  can  be only ${0,1,2,3,4,5,6,7,8,9}$ for base 10.</p>

<p>For example, if $x=12.46$, then</p>

<p>$f_2(x)=0$;$f_1(x)=1$;$f_0(x)=2$;$f_{-1}(x)=4$; $f_{-2}(x)=6$ ; $f_{-3}(x)=0$.</p>

<p>If we have such function , we can write any real number easily as shown below:</p>

<p>$x=\sum \limits_{n=-\infty}^\infty f_n(x) 10^n$</p>

<p>I tried to find  power series expression of the function.
$f_n(x)=a_0(n)+a_1(n)x+a_2(n)x^2+\cdots$</p>

<p>$$\begin{align*}
x&amp;=\sum \limits_{n=-\infty}^\infty f_n(x) 10^n\\
&amp;=\sum \limits_{n=-\infty}^\infty (a_0(n)+a_1(n)x+a_2(n)x^2+\cdots
) 10^n\\
\sum \limits_{n=-\infty}^\infty a_0(n) 10^n&amp;=0\\
\sum \limits_{n=-\infty}^\infty a_1(n) 10^n&amp;=1\\
\sum \limits_{n=-\infty}^\infty a_2(n) 10^n&amp;=0
\end{align*}$$</p>

<p>But this do not give me so many thing to define $a_k(n)$</p>

<p>Is it possible to find  $a_k(n)$ with some method that known?</p>

<p>I also wonder what the function properties of $f_n(x)$ are? (such as $f_n(x+y)$, $f_n(x.y)$  etc.) I wonder the literature about the function. </p>

<p>Could you please share your knowledge about the function?
Sorry for your time if It was asked before or very basic for number theory.</p>

<p>Thanks a lot for advices and answers</p>
",number_theory
"<p>Fermat's theorem on sum of two squares states that an odd prime $p = x^2 + y^2 \iff p \equiv 1 \pmod 4$</p>

<p>Applying the descent procedure I can get to $a^2 + b^2 = pc$ where $c \in \mathbb{Z} \gt 1$</p>

<p>I want $c = 1$, so how do I proceed from here? How do I apply the procedure iteratively?</p>

<p><strong>Example:</strong></p>

<p>$$
p = 97
$$</p>

<p>$$97 \equiv 1 \pmod 4 \implies \left(\frac{-1}{97}\right) = 1 \implies x^2 \equiv -1 \pmod {97}$$ has a solution</p>

<p>$$x^2 + 1 \equiv 0 \pmod {97}$$
$$x^2 + 1 = 97m$$
We find an $x,m$ that solves the equation.
$$x = 75, m = 58$$
Now, we pick an $a,b$ such that $\frac{-m}{2} \leq a,b \leq \frac{m}{2}$
$$a \equiv x \pmod m = 17$$
$$b \equiv y \pmod m = 1$$</p>

<p>Observations:</p>

<ol>
<li><p>$ a^2 + b^2 \equiv x^2 + 1 \equiv 0 (\mod m)$</p></li>
<li><p>$ (a^2 + b^2) = mc$</p></li>
<li><p>$ (x^2 + 1) = mp$</p></li>
</ol>

<p>Plugging in $a,b,m$ for 2, we get $c = 5$</p>

<p><br>
By <a href=""https://en.wikipedia.org/wiki/Brahmagupta%E2%80%93Fibonacci_identity"" rel=""nofollow"">this</a> identity, we know that</p>

<p>$(a^2 + b^2)(c^2 + d^2) = (ac + bd)^2 + (ad - bc)^2$</p>

<p>**$(a^2 + b^2)(x^2 + 1^2) = (ax + b)(a - bx) = m^2pc$</p>

<p>Dividing ** by $m^2$, $pc = (\frac{ax+b}{m})^2 + (\frac{a-bx}{m})^2$</p>

<p>Plugging in $a,b,m,p,c$ we get that $22^2 + (-1)^2 = 97*5$</p>

<p>So we have two squares that add up to 5 times our $p$. How do we turn the 5 into a 1? What is the next step in the descent?</p>
",number_theory
"<h2>Question</h2>

<p>If:</p>

<p>$$f(a) + f(b) = f(ab)$$
$$ f(1) = 0 $$
$$ a&lt;b \implies f(a) &lt; f(b)  \forall  a,b \in N  $$</p>

<p>where $N$ is the set of natural numbers.</p>

<p>Prove or disprove $f$ must be the $\log$ function.</p>

<h2>Background</h2>

<p>I was recently wondering about the uniqueness of a function given:</p>

<p>$$f(a) + f(b) = f(ab)$$
$$ f(1) = 0 $$
$$ a&lt;b \implies f(a) &lt; f(b)  \forall  a,b \in R^+  $$</p>

<p>where $R^+$ is the set of positive real numbers.</p>

<p>All of these imply it must be the $\log$ function. I was wondering however what would be the consequence of relaxing the third condition </p>

<p>$$a&lt;b \implies f(a)&lt;f(b)  \forall  a,b \in N $$</p>

<p>where $N$ is the set of natural numbers.</p>

<p>This would allow $f(x)$ to be a combination of the $\log$ and number theoretic functions such as $A(x)$. Where </p>

<p>$$A(x) = \text{number of prime factors of $x$}$$</p>

<p>We note,</p>

<p>$$ A(x) + A(y) = A(xy)$$
$$ A(1) =0 $$</p>
",number_theory
"<p>I needed (for my research) to solve a Diophantine equation, in particular,
$$ 2 a + 3 b + 4 c + 5 d = 12 .$$
And I could easily solve it
(for example, on solution is $a=2, b=1, c=0, d=1$).
But this made me wonder if such equations, with their coefficients increasing sequences of
natural numbers, are a special case of Diophantine equations that are <em>always</em> explicitly solvable, 
despite the negative solution to Hilbert's 10th problem.</p>
",number_theory
"<p>Let p be a prime with p > 7. Prove that there are at least two consecutive quadratic residues modulo p. [Hint: Think about what integers will always be quadratic residues modulo p when p ≥ 7.]</p>
",number_theory
"<p>How you prove this? I'm looking the Erdös proof from Bertrand Postulate and there are many things I don't get. 
Please don't hints, I'm newbie in combinatorics techniques.</p>

<p>In the  book I don't get how $$\displaystyle\prod_{m+1&lt; p\leq 2m+1}p  \leq \left( \begin{matrix} 2m+1 \\ m \end{matrix} \right).$$</p>
",number_theory
"<p>I am currently running into a problem related to coprime numbers.</p>

<p>Consider a set of $d$-dimensional integer vectors, $z \subset \mathbb{Z}^d$ such that each component $z_i$ is bounded by another integer $K$. Let us denote this set as:</p>

<p>$$Z_K^d = \Big \{ z \in \mathbb{Z}^d ~\big|~ z_i \in \{0,1,\ldots,K \} ~ i = 1,\ldots, d \Big\}$$</p>

<p>We can visualize $Z_K^d$ as the set of integer coordinates within a $d$-dimensional hypercube of size $K+1$. Note that $Z_K^d$ contains $\big|Z_K^d\big| = (K+1)^d$ distinct vectors, as each of its $d$ components can take on $K+1$ values. </p>

<p>I am interested in determining the number of vectors $z \in Z_d^K$ that are <a href=""http://en.wikipedia.org/wiki/Coprime_integers#Generalizations"" rel=""nofollow"">coprime</a>. Formally, a vector $z \in Z_d^K$ is said to be coprime if the greatest common divisor of all of it's components is 1. <a href=""http://en.wikipedia.org/wiki/Coprime_integers#Properties"" rel=""nofollow"">As explained in the Wiki article</a>, we can also think of these vectors as points with integer coordinates that are 'visible' from the origin (in the sense that there is no other point with integer coordinates between these points and the origin). </p>

<p>Let us denote this subset of coprime vectors $P_K^d \subseteq Z_K^d$ and define it as:</p>

<p>$$P_K^d = \Big \{ z \in Z_K^d ~\big| ~\text{gcd}(z_1,\ldots,z_d)=1 \Big\}$$</p>

<p>I am wondering if there is a <strong>closed-form expression</strong> or a <strong>closed-form upper bound</strong> for the <em>density</em> of these coprime vectors in my original set:</p>

<p>$$\gamma_K^d = \frac{\big|C_K^d\big|}{\big|Z_K^d\big|}$$</p>

<p>I have been actively reading up on the topic (which is outside of my area of expertise) and it seems that the value of $\gamma_K^d$ is asymptotically related to the Riemann zeta function as </p>

<p>$$ \lim_{K\rightarrow\infty} \gamma_K^d = \zeta(d)$$</p>

<p>While this is insightful, it does not take into account that the set that I am interested in is bounded. In addition, the value of $\zeta(d)$ can either be an upper bound or a lower bound on this ratio (so I cannot use it in another bound).</p>
",number_theory
"<p>I was looking at a 10x10 multiplication table, and I decided to count the unique products. There are 42 out of a possible 100 numbers represented. I had to wonder, why 42? I counted the 58 non-listed numbers -- most of them are either primes >10 or multiples of those primes. I couldn't figure out a satisfying reason like that for 75, 84, 96 and 98. I feel like the number 42 should be calculable from the natural log of 100 and 10, or something, but I can't really figure it out.</p>

<p>Also, I counted the frequency of all the numbers represented. They all have either 1, 2, 3, or 4 instances. The six numbers that have only 1 instance are all squares -- those of 1, 5, 7, 8, 9, and 10. This makes sense -- squares don't fall into that 4x5 = 5x4 redundancy. The 23 numbers with 2 instances are kind of the default I guess. The four with 3 are the remaining squares -- 4, 9, 16, and 36. 4 and 9 make sense to me, as they are squares within the basic range of the times table, so they are hit by themselves, their square root, and 1. I'm having trouble accounting for why 16 and 36 have three representatives. I'm also having trouble seeing the pattern (or patterns) in the numbers with four representatives.</p>

<p>I ultimately want to find a way to, given a times table of any size, calculate whether a given number will appear, and how many times.</p>

<p>Also, I'm pretty sure that for times tables 7x7 and below, more than half of the possible numbers are represented on the table, but for times tables above 7x7, less than half are represented. Why is 7 the turning point?</p>
",number_theory
"<p>I was told that multinomial expansion can be used to determine how many representations of four squares a number like 53 has?  I have a number theory textbook and have done some googleing neither has turned up anything much on this method. Can any of you shed any light?</p>
",number_theory
"<p>let $n$ be an integer $&gt;1$, and suppose that $p=2^n+1$ is a prime. 
Show that $3^{(p-1)/2} +1$ is divisible by $p$ (First show that $n$ must be even)</p>
",number_theory
"<p>I am trying to solve a very interesting problem about the ring $\mathbb{Z}/n\mathbb{Z}$ and Euler function $\phi (n)$, but i am not sure how to start, i have a few ideas, but none of them leads me to the end of the proof. So, here is the problem.</p>

<p>Let $n$ be a squarefree integer( integer is one divisible by no perfect square, except 1 ). Let $k\in \mathbb{Z}/n\mathbb{Z}$ and $e=1+j\phi (n)$, where $\phi (n)$ is the Euler function and $j\in \mathbb{N}$. Show that $k^{e}=k$.</p>

<p>My first thought, when i saw what i have to prove, was that i have to show the idempotence of the element $k$. I tried to show it, but i couldn't...
Then i recalled that $\phi (n)$ is the order of the unit group of $\mathbb{Z}/n\mathbb{Z}$, but i don't know how should i use it here...or i also know that $\phi(n)$ is always positive and even number, so $j\phi(n)$ must be also even, so the number $e$ is odd...</p>

<p>Can anybody help me with this problem? I have the feeling the things must be easy. I would be glad to read your hints, ideas or remarks. Thank you in advance!</p>
",number_theory
"<p>Riemann gave an explicit form for the counting function of the primes.</p>

<p>Is there an explicit form for the counting function $f(x) = \sum_p \ln(\ln(p))$ where the sum is over $p$ : the number of primes smaller than $x$ such that $\ln(\ln(p)) &gt;0$ ?</p>
",number_theory
"<p>I was testing out a few summation using my previous descriped methodes when i found an error in my reasoning. I'm really hoping someone could help me out.</p>

<p>The function which i was evaluating was 
$\sum_{n=1}^{\infty} n\ln(n)$ which turns out to be $-\zeta'(-1)$. This made me hope i could confirm my previous summation methode for divergent sums. </p>

<p>My divergent summtion methode (see previous questions) gives for every $d\geqslant2$:
$$\sum_{n=1}^{\infty}f(dn)-f(n)=\sum_{n=1}^{\infty}\sum_{p=1}^{d-1} f(n)e^{ip\pi2n/d}$$
$$\sum_{k=0}^{\infty} \sum_{n=1}^{\infty}\sum_{p=1}^{d-1} -(d)^{2k} n\ln(d^kn)e^{2i\pi*pn/d}=\sum_{n=1}^{\infty} n \ln(n) \tag 1$$</p>

<p>Fill in $d=2$ cause that's the most easy, gives:
$$\sum_{k=0}^{\infty} \sum_{n=1}^{\infty} -(2)^{2k}k n\ln(2)(-1)^n-(2)^{2k} n\ln(n)(-1)^n$$
$$\sum_{k=0}^{\infty} \sum_{n=1}^{\infty} -(4)^{k} n\ln(n)(-1)^n=\sum_{n=1}^{\infty}  n\ln(n)/3(-1)^n \tag 2$$
$$\sum_{k=0}^{\infty} \sum_{n=1}^{\infty} -(2)^{2k}k n\ln(2)(-1)^n=\sum_{n=1}^{\infty} -\frac{4}{9}n\ln(2)(-1)^n= \frac{1}{9}\ln(2) \tag 3$$</p>

<p>equation (1)=(2)+(3)
$$(\sum_{n=1}^{\infty} (-1)^n*n \ln(n)/3)+\ln(2)/9\approx 0.165421153 \tag 4$$</p>

<p>Now i work out $\lim_{m\to\infty}  \sum_{n=1}^{m} n \ln(n)$
$$\sum_{n=1}^{m} n \ln(n)=m(m+1)\ln(m+1)/2-(m)(m+2)/4+\ln(m+1)/12+error \tag 5$$
It turns out the error is most likely $-1/6+~0.165421153$ so the value above.
The fact i get an expression with the value found above is cool. Actualy i'm close but       </p>

<p>$\textbf{[Question]}$ why the $-1/6$. Did i failed isolating a constant part in my approximation? And if so were did i fail to get it out.     </p>

<p>Ps: since i guessed the formula, it would be nice if someone could confirm the fomula if correct (or false).</p>
",number_theory
"<p>Suppose that $x$ solves $x^4-x^2+1= 0 \pmod p$. Show that $p=1 \pmod {12}$. Following a hint I have rewritten the equation as $(x^2-1)^2=-3 \mod p$ and $(2x^2-1)^2=-x^2 \pmod p$. The first equation gives that $p=1 \pmod 3$ by using quadratic reciprocity and noting that $1$ is the only applicable quadratic residue. However, I am not able to show that $p=1 \pmod 4$. Since this is a condition in some formulations of quadratic reciprocity I guess that it should be used here as well. This is exercise 13 chapter 5 from the book by Ireland and Rosen if it is any help. Thankful for any hints!</p>
",number_theory
"<p>Today I set out to invent a two character numeral system designed to make factorization trivial. Indeed, it lets one factor non-trivial numbers with over thousand digits within 30 seconds per hand - the upshot is that the notation isn't particularly suited for arithmetic. In fact, when I try to add certain two digit numbers, my computer gives me an overflow warning. </p>

<p>The idea is to not use any base like binary or decimal, as in $28=2\cdot 10^1+8\cdot 10^0$, but to hardcode the prime factors $28=2^2\cdot 3^0 \cdot 5^0 \cdot 7^1$ into the notation. So denote the start and end of a number by ""$s$"" and ""$e$"". I set </p>

<p>$0:=se$</p>

<p>and declare a natural number to be any string of the form ""$sxe$"" where $x$ is a finite string of numbers. The $n$'th number in the sequence $x$ denotes the power oth the $n$'th prime number and ""$sxe$"" is the associated product. So from an ordinal point of view</p>

<p>$1=2^0=s0e=ssee$</p>

<p>$2=2^1=s1e=ssseee$</p>

<p>$3=2^0\cdot 3^1=s01e=ssesseee$</p>

<p>$4=2^2=s2e=sssseeee$</p>

<p>$5=2^0\cdot 3^0\cdot 5^1=s001e=ssesesseee$</p>

<p>...</p>

<p>$28=2^2\cdot 3^0 \cdot 5^0 \cdot 7^1=s2001e=sssseeesesesseee$</p>

<p>I came to the conclusion that the language consists of all the strings with equal number of $s$'s and $e$'s, where while scanning from the left there are always more $s$'s than $e$'s and the substring $esee$ isn't allowed. The first condition makes sure that all numbers close and the second one disallows superfluous factor of powers of 0.</p>

<p>I've written a script which brute force generates these strings (it forms all permutations of even numbers of $s$'s and $e$'s and then drops the disallowed ones) and also one to translate them to decimal expression (which relies on knowing what the $n$'th prime is):</p>

<p><a href=""http://pastebin.com/RwkGX6TV"">http://pastebin.com/RwkGX6TV</a></p>

<p>This e.g tells me that 2417851639229258349412352 is sssesssseeeeee and the nice thing is that all numbers factor easily:</p>

<p>$sssesssseeeeee$ </p>

<p>$= s(s(se)(s(s(s(se)e)e)e)e)e$</p>

<p>$=s(s0(s(s(s0e)e)e)e)e$</p>

<p>$=s(s0(s(s1e)e)e)e$</p>

<p>$=s(s0(s2e)e)e$</p>

<p>$=s(s0(2^2)e)e$</p>

<p>$=s(2^0\cdot 3^{2^2})e$</p>

<p>$=2^{3^{2^2}}.$</p>

<p>For now, I've generated most of the numbers with 20 characters and I've added an artificial bound of $R=10^{50}$ to the size of the exponents. This is necessary, as e.g. the number $13$, being the $6$th prime, reads $ssesesesesesseee$, i.e. $s000001e$ but it's neighbors in this enumeration can be numbers with thousands of digits. Generating the strings is simple down at $14$ but multiplication is hard. Later, also higher number of strings are needed and the way I produce the permutation is probably inefficient. </p>

<p>To generate a bigger library of numbers, I'd like to know if someone has an idea for a less arbitrary enumeration of the the strings which avoid the uncomputably big numbers. </p>

<p>Does someone maybe know an good way to enumerate the numbers in the form $1,2,3,2^2,5,2\cdot 3,7,\cdots,3^{2^5}\cdot 11^2\cdot 19^3,\cdots$?</p>
",number_theory
"<p>Denote $\pi(x)$ be the number of primes $\leq x,$ $p(n)$ be the $n$-th prime number. 
We have $\pi(p(n))=n.$</p>

<p>It's well known that 
$$\pi(x)\sim \frac{x}{\log x}
\\p(n)\sim n\log n.$$</p>

<p>Is it always true that if $f(x)$ is a function and</p>

<ul>
<li><p>$f(x)&gt;0, \forall x&gt;0$</p></li>
<li><p>$f(x)$ is a <a href=""http://en.wikipedia.org/wiki/Monotonic_function"">monotonic function</a> </p></li>
<li><p>$f(x)=O(x^r)$ for some $r&gt;0$</p></li>
<li><p>$\sum_{n=1}^{\infty}f(n)=\infty$</p></li>
</ul>

<p>then $$\sum_{p\leq x}f(p)\sim \sum_{t\leq \pi(x)}f(t\log t)$$?</p>
",number_theory
"<p>Let $O$ be the ring of integers of some number field and $I$ any nonzero ideal of $O$. Prove that there is some number $n \in \mathbb{Z}_+$  that is in ideal $I$.
I suppose I should use that $O$ is Dedekind domain, so every ideal can be written as product of prime ideals, but I don't know how to use that. Any help is appreciated. </p>
",number_theory
"<p>The question is :
If $n$ be a six digit number formed by the numbers $1,2,3,4,5,6$ such that $n$ is divisible by $5$, then what are the possible remainders if $n$ is divided by $45$.
Now,since $n$ is divisible by $5$ so it must end with $5$ and the remaining five numbers can be arranged in $5!$ ways in five different positions.Now,the important thing that I observe is that most of the numbers leave the remainder $30$ when they are divided by $45$. I use the word 'most' as I have not checked all such numbers.But I don't find suitable reason behind it.Do all these numbers belong to the same remainder class which is $30$. If the answer is 'Yes' then can anybody explain me the actual reason behind it</p>
",number_theory
"<p>What is the largest computable mathematical division in terms of the number of digits that can be handled by a typical desktop computer using the best available big number libraries, assuming input is a decimal string and output is an exact answer? By an exact answer I mean a value that shows the fixed and repeating values, e.g. 1/832 = 0.001201923(076923)</p>

<p>By ""computable"" I mean the value can be calculated by a desktop computer within a day.</p>

<p>Note that because any division can be performed by multiplying by the reciprocal, this is equivalent to asking, what is the largest computable value for the denominator of a reciprocal given current desktop technology?</p>

<p>For example, if I have input string ""1 / 3127362377"", then this decimal might have as many as several billion digits in the repeating or non-repeating portion of the value. Would these billion digits be computable within a day by a desktop computer? If not, what is the largest (smallest?) analogous reciprocal that could be so calculated?</p>
",number_theory
"<p>Algebraic class field theory tells us that $\text{Gal}(\mathbb{Q}^{ab}/\mathbb{Q})$ is isomorphic to the group of connected components of the quotient $\mathbb{Q}^{\times}\backslash \mathbb{A}_{\mathbb{Q}}^{\times}\cong \prod_p \mathbb{Z_p}^{\times}\times \mathbb{R}_{&gt;0}$, where $\mathbb{A}_{\mathbb{Q}}$ is the ring of adèles of $\mathbb{Q}$. </p>

<p>It's then said that the group of connected components is given by $\prod_p \mathbb{Z_p}^{\times}$, how can I see this?</p>

<p>Thank you very much in advance!</p>
",number_theory
"<p>I've been trying to see whether following assertion is true in order to give a quick proof of another problem I was doing: if $K$ is a finite dimensional extension of the $p$-adic numbers $\mathbb{Q}_p$, we have the multiplicative field norm $N_{K/\mathbb{Q}_p}: K \rightarrow \mathbb{Q}_p$.  While the norm is not guaranteed to be surjective, is it always possible to find some $k \in K$ such that $N_{K/\mathbb{Q}_p}(k)$ has ($p$-adic) absolute value $1/p$?</p>

<p>One way I would imagine to do this is to show that there exist $\alpha, \beta \in K$ such that $|N(\alpha)| = p^A$ and $|N(\beta)| = p^B$ with $A, B$ relatively prime.  The assertion then follows because there exist integers $x, y$ such that $xA + yB = 1$, whence $\alpha^{-x}\beta^{-y} \in K$ with $|N(\alpha^{-x}\beta^{-y})| = |N(\alpha^{-x})N(\beta^{-y})| = |a|^{-x}|b|^{-y} = p^{-Ax}p^{-By} = 1/p$.  </p>

<p>My claim seems to me altogether reasonable since otherwise there exists some prime $q$ such that the absolute value $p^s$ of every $N(k)$ as $k$ runs through all of $K$ will be such that $s$ is always divisible by $q$, which doesn't seem right.</p>
",number_theory
"<p>I just have a really quick question of an example that I was trying to come up with. </p>

<p>Are there any number rings which are UFDs but not PIDs?</p>
",number_theory
"<p>Let m be a positive integer greater than 1.</p>

<p>Prove that if r is a primitive root of m, then $r^{φ(m)/2} ≡ -1$ (mod m).</p>
",number_theory
"<p>The <a href=""http://eom.springer.de/p/p072630.htm"" rel=""nofollow"">Phragmen-Lindelöf theorem</a> gives a consequence of the Riemann hypothesis, viz, the <a href=""http://en.wikipedia.org/wiki/Lindel%C3%B6f_hypothesis"" rel=""nofollow"">Lindelöf hypothesis</a>. As such this is weaker than Riemann hypothesis; but it is still considered that even a proof of this weaker result will be a breakthrough.</p>

<p>Question:</p>

<blockquote>
  <p>What is the strongest known result yet on the Lindelöf hypothesis?</p>
</blockquote>
",number_theory
"<p>This is probably obvious, but I don't quite see it.</p>

<p>Archimedean completions of different number fields are always isomorphic to the same $\mathbb{R}$ or $\mathbb{C}$. Is the same true in the non-archimedean case?</p>

<p>More precisely, llet $K$, $L$ be non-isomorphic number fields, and $\mathfrak{p}$ a nonarchimedean prime  of both $K$ and $L$.</p>

<blockquote>
  <p>When is it true that $K_\mathfrak{p}\cong L_\mathfrak{p}$?</p>
</blockquote>
",number_theory
"<p>Let $\mathcal{V_K}$ be the set of valuations of a number field $K$.</p>

<blockquote>
  <p>Can it be that $\mathcal{V_L}=\mathcal{V_K}$, for the set of
  valuations of another number field $L$ non-isomorphic to $K$?</p>
</blockquote>
",number_theory
"<p>I recently read a very good inequality concerning the no of primes $\pi(x)$:</p>

<p>$$\pi(n)>\frac{1}{6}\frac{n}{\log n}\mathrm{\ for\ }n\ge 2$$</p>

<p>Are any other such elementary inequalities concerning the primes?</p>
",number_theory
"<p>The problem is from my friend who sent a message looking for help. I don't think for a long time to solve, so I hope someone can help me to solve it. Thank you </p>

<p><strong>Question</strong>:</p>

<blockquote>
  <p>Given a integer $n$ greater than $1$, suppose that $x_{1},x_{2},\cdots,x_{n}$ are integers such that none of them is divisible by $n$, and neither is their sum. Prove that there exists at least $n-1$ non-empty subsets $A\subseteq \{1,2,3,\cdots,n\}$, such that $\displaystyle\sum_{i\in A}x_{i}$ is divisible by $n$.</p>
</blockquote>
",number_theory
"<p>We know that if $ \displaystyle d(n)= \sum\limits_{d \mid n} 1$, then we have </p>

<p>$$ \sum\limits_{n \leq x} d(n)= x\log{x} + (2C-1)x + \mathcal{O}(\sqrt{x})$$</p>

<p>I have referred Apostol's ""Analytic Number theory"" and i understood the first half of the proof where the error term is $\mathcal{O}(x)$, but please tell me as to how to improve the error term to $\sqrt{x}$.</p>
",number_theory
"<p>Hello :) I want to compute alle reduced quadratic numbers with discriminat $65$. We call a number $\gamma$ reduced if $\gamma&gt;0$ and $-1&lt;\gamma'&lt;0$. We are working in quadratic field extension $\Bbb{Q}(\sqrt{m})$ and intergers in this extension. Thus we know $b^2-4ac=65$ and $\gamma=\frac{-b+\sqrt{65}}{2a}$, thus we must have: $0&lt;-b+\sqrt{65}&lt;2a&lt;b+\sqrt{65}$. But what then? Must we start with a $b$ and find the right $a$ and $c$? Can someone give an example? </p>

<p>Another question: Suppose $\mathfrak{p}$ is a prime ideal above 2 (thus $\mathfrak{p}\cap\Bbb{Z}=p\Bbb{Z}$) in $\Bbb{Q}(\sqrt{65})$. Show that $\mathfrak{p}^2$ a principal ideal is an compute the generator. ..... Here i have no idea how to start. Someone with hints, ideas or solutions?</p>

<p>Thank you :)</p>
",number_theory
"<p>How can we efficiently find square root of 5 in a mod prime field. By quadratic reciprocity we can argue that 5 is a square in modulo p(prime) is p is square modulo 5. But how exactly can we calculate it.</p>
",number_theory
"<p>I was wondering if the following is already a known result in mathematics. I have tested it and it seems to work every single time. </p>

<p>If I write the Fibonacci sequence in $\bmod (a)$ form and it repeats after $b$ terms, I will call this the period, and one of the two conditions is true then $a$ is a prime. </p>

<p>If $$b = \frac{a - 1}{n}$$ such that $\frac{a - 1}{n}$ yields a natural number.</p>

<p>Or:</p>

<p>If $b = n(a + 1)$</p>

<p>Then $a$ must be a prime number. </p>

<p>However if $a$ is a prime will not necessarily exhibit these properties. </p>

<p>I would really appreciate your help.</p>
",number_theory
"<p>Suppose $a_i$ is a sequence of positive integers. Define $a_1 = 1$, $a_2 = 2$ and $a_{n+1} = 2a_n + a_{n-1}$. Does it follow that </p>

<p>$$ \gcd(a_{2n+1} , 4 ) = 1 $$ ???</p>

<p>Im trying to see this by induction assuming above holds, we need to see that $\gcd(a_{2n+3} , 4 ) = 1$.</p>

<p>But, $\gcd(a_{2n+3} , 4 ) = n_0(2a_{2n+1} + a_{2n-1}) + 4n_1$ for integers $n_0, n_1$. But this quantity does not seem to give me $1$. Can someone help me with this problem? thanks</p>
",number_theory
"<p>Show that $\operatorname{Hom}_{\mathbb{Z}}\left ( \mathbb{Z}/n\mathbb{Z},\mathbb{Z}/m\mathbb{Z} \right )\cong \mathbb{Z}/\left ( n,m \right )\mathbb{Z}$</p>

<p>I think that the hom-set (of $\mathbb{Z}$ module homomorphisms ) is isomorphic to $\left \{ a\in \mathbb{Z}/m\mathbb{Z},na=m\mathbb{Z} \right \}=\left \{ k+m\mathbb{Z} \right \}$ where $m\mid (nk)$ but I can't show that it's isomorphic to $\mathbb{Z}/\left ( n,m \right )\mathbb{Z}$</p>
",number_theory
"<p>I know that there exists nine 2007 digit number where each two digit number is made up of two neighbor digits, those numbers are:</p>

<ol>
<li>$$12345678901234....90123456789012345678   $$         </li>
<li>$$23456789012345....01234567890123456789$$</li>
<li>$$34567890123456....12345678901234567890$$</li>
<li>$$45678901234567....23456789012345678801$$</li>
<li>$$56789012345678....34567890123456789012$$</li>
<li>$$67890123456789....45678901234567890123$$</li>
<li>$$78901234567890....56789012345678901234$$</li>
<li>$$89012345678901....67890123456789012345$$</li>
<li>$$90123456789012....78901234567890123456$$</li>
</ol>

<p>Why there is nine numbers? because number can not be started with '0' digit! Right?</p>

<p>Anyway I can not find out which numbers can be divided by 17 or 23 from this list?
I have no idea how to get there. Any hints or ideas on how I should tackle this one?</p>
",number_theory
"<p>Evaluate the following Legendre symbols using quadratic reciprocity:</p>

<ol>
<li>$\left(\frac{295}{401}\right)$</li>
<li>$\left(\frac{713}{1009}\right)$</li>
</ol>

<p>I know that can flip the numbers and reduce because both $401$ and $1009$ are equivalent to $1 \pmod{\!p}$ and so on, but I am starting to get weird numbers and I think I did something wrong in one of my steps.</p>
",number_theory
"<p>Let $E$ be an elliptic curve with a 3-torsion point $P$ and $G = \operatorname{Gal}(\overline{\mathbb{Q}}/\mathbb{Q})$. Let $X = \{O, P, -P\}$ where $O$ is the point at infinity and $X$ is a $G$-module. Why does $H^{1}(G, X)$ inject into $\operatorname{Sel}_{3}(E/\mathbb{Q})$?</p>
",number_theory
"<p>Show that, for any prime $p$, there are integers $x$, and $y$ such that $p$ is divisible by $(x^2+y^2+1)$    Can you show me what to start with? do I prove $p$ is divisible by $x^2$ and $y^2$ separately?</p>
",number_theory
"<p>Let $G$ be a finite group, although this may not be necessary for almost everything that follows. One of the ways of defining Galois homology groups is using the standard resolution for the $\mathbb{Z}$, explicitly we do the following. Let </p>

<p>$$ \cdots\to P_2\to P_1 \to P_0 \to \mathbb{Z} $$ </p>

<p>be the standard resolution. Let $I\subset \mathbb{Z}[G]$ be the ideal generated by elements of the type $(g-1)$. For two $G$-modules $M,N$ the $G$ module structure on $M\otimes N$ is given by $$g\cdot (m\otimes n):=gm\otimes gn.$$</p>

<p>Define 
$$H_i(G,M)=H_i\bigg(\cdots\to \frac{P_2\otimes M}{I(P_2\otimes M)}\to \frac{P_1\otimes M}{I(P_1\otimes M)} \to \frac{P_0\otimes M}{I(P_0\otimes M)}\to 0\bigg).$$</p>

<p>If $$0\to M'\to M\to M''\to 0$$ is a short exact sequence of $G$-modules then we have a short exact sequence of $G$-modules 
$$0\to \frac{P_i\otimes M'}{I(P_i\otimes M')}\to \frac{P_i\otimes M}{I(P_i\otimes M)} \to \frac{P_i\otimes M''}{I(P_i\otimes M'')}\to 0.$$
As a consequence we get a short exact sequence of complexes 
$$0\to \frac{P_\bullet\otimes M'}{I(P_\bullet\otimes M')}\to \frac{P_\bullet\otimes M}{I(P_\bullet\otimes M)} \to \frac{P_\bullet\otimes M''}{I(P_\bullet\otimes M'')}\to 0$$
and consequently a long exact sequence of homology groups. The connecting homomorphism is defined in the usual way; we start with an element in $\frac{P_i\otimes M''}{I(P_i\otimes M'')}$ which is 0 under the differential, lift it to an element in $\frac{P_i\otimes M}{I(P_i\otimes M)}$ and apply the differential to get an element in $\frac{P_{i-1}\otimes M'}{I(P_{i-1}\otimes M')}$, whose homology class is the required element. </p>

<p>Now consider the case when $M=\mathbb{Z}[G]$ and $M''=\mathbb{Z}$, and $\bullet=1$. In this case the connecting homomorphism should give an isomorphism $H_1(G,\mathbb{Z})\to H_0(G,I)$.
Let $\alpha$ be an element in $\frac{P_1}{IP_1}$ whose differential is 0. We can lift this to the element $\alpha\otimes 1$ in $\frac{P_1\otimes \mathbb{Z}[G]}{I(P_1\otimes \mathbb{Z}[G])}$, but now applying the differential, which in this case is $d\otimes 1$, we will always get 0 since $d\alpha=0$, which is clearly not correct. The same problem would appear if $M''$ is a summand of $M$ as abelian groups. Could someone please point out what is it that I am doing wrong.</p>
",number_theory
"<p>\begin{align}
    a^2 + ba + c &amp;= 0 &amp; \text{{No real roots.}}\\
    \lfloor a^2 \rfloor + ba + c &amp;= 0 &amp; \text{{At least one real roots.}}
\end{align}</p>

<p>Are there any values of b and c that will make the given number of roots correct?</p>

<p>The first thing I thought about doing was finding the discriminant .In order for the first equation to have no real roots, we must have $b^2 – 4c &lt; 0$. That means that $b^2 &lt; 4c$. 
I know that the discriminant of the second one must be 0 but I am not sure how to express it because a floor function is involved. What should I do? 
Will this approach get me anywhere or are there any better methods? </p>
",number_theory
"<p>Do there exist $10$ distinct integers such that the sum of any $9$ of them is a perfect square?</p>
",number_theory
"<p>We know that $\displaystyle\zeta(2)=\sum\limits_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}$ and it converges.</p>

<blockquote>
  <ul>
  <li>Does there exists a bijective map $f:\mathbb{N} \to \mathbb{N}$ such that the sum $$\sum\limits_{n=1}^{\infty} \frac{f(n)}{n^2}$$ converges.</li>
  </ul>
</blockquote>

<p>If our $s=2$ was not fixed, then can we have a function such that $\displaystyle \zeta(s)=\sum\limits_{n=1}^{\infty} \frac{f(n)}{n^s}$ converges</p>
",number_theory
"<p><strong>Problem</strong>: Let $n$ be an integer and $p$ a prime dividing $5(n^2-n+\frac{3}{2})^2-\frac{1}{4}$. Prove that $p \equiv 1 \pmod{10}$.</p>

<p>The polynomial can be re-written as $(\sqrt{5}(n^2-n+\frac{3}{2})-\frac{1}{2})(\sqrt{5}(n^2-n+\frac{3}{2})+\frac{1}{2})$. If this vanishes mod $p$ then $5$ is a quadratic residue mod $p$, which shows that $p \equiv \pm 1 \pmod{5}$ (the primes 2 and 5 are easily ruled out). It feels like the problem should be solvable by understanding the splitting of primes in the splitting field of this polynomial, but I can't find an appropriate ""reciprocity law"".</p>

<p>The things I'm not sure about are:</p>

<ol>
<li>How does one rule out the primes congruent to $-1$ mod $5$?</li>
<li>Under what circumstances is it the case that the set {rational primes that split in the ring of integers of some number field} is the union of arithmetic progressions? This a kind of generalized reciprocity law but I don't know in what generality they are known to hold.</li>
</ol>
",number_theory
"<p>This question is a variant of problem 4, pg. 21, from Birkhoff and Maclane, <em>A Survey of Modern Algebra</em>. </p>

<blockquote>
  <p>Given a function $w: \mathbb{N}^+ \rightarrow \mathbb{N}$  that behaves like a valuation function, i.e., </p>
  
  <p>(1) $ w(ab) = w(a) + w(b) $</p>
  
  <p>(2) $ w(a+b) \geq \min(w(a), w(b)).$</p>
  
  <p>Show that it is either</p>
  
  <ol>
  <li>constant $0$ function, $w(a) = 0$
  or </li>
  <li>a multiple of a $p$-adic valuation, in other words $\forall a \in \mathbb{N}^+, w(a) = k v_p(a)$ for some $p, k$ with $v_p(p^\alpha d) = \alpha $ when $(p, d) = 1 $.</li>
  </ol>
</blockquote>

<p>Note that this problem is relatively simple if $w$ is defined over $\mathbb{Z}\backslash \{0\}$ instead of $\mathbb{N}^+$ which is the problem listed in the book. My question is whether the stronger statement above is also true. </p>

<p>My current proof attempt is incomplete.</p>

<p>If $\forall a,\ w(a) = 0$ we are done. Otherwise let $n$ be the least number s.t. $w(n) \neq 0$. Easy to show from (1) that $n \neq 1$ since $w(1) = 0$ and that $n$ is prime.</p>

<p>By unique factorisation theorem and (1) to get the result I need only prove that for all primes $p$, $p\neq n \implies w(p) = 0$.</p>

<p>I tried to proceed using well founded induction. If $p \lt n$ done. Otherwise $p \gt n$. If $n \gt 2$ then $n, p$ are odd and $n+p$ is even hence $n+p=2q$. Now $n \nmid p$ so $n \nmid n + p$. If $n \gt 2$ we have $n \nmid q$. Since $q \lt p$ the induction hypothesis gives us $w(q) = 0$ and since $n \gt 2$, $w(2) = 0$. Thus $w(n+p) = w(2q) = w(2) + w(q) = 0 \ge \min(w(n), w(p))$. This gives us that $w(p) = 0$. </p>

<p>I can't see how to solve the $n=2$ case. Is the case where $n=2$ solvable or is there a counterexample? </p>

<p>Some perhaps useful facts. </p>

<p>If $w(2) \neq 0$ and any other $w(p')=0$ for $p'$ prime, $p'\neq 2$ then $w(p) =0$ for all primes $p\neq2$. Easy to prove since every prime $p$ is an even multiple less than some power $r$ of $p'$ and by (1) $w(p^r) = 0$ and then by (2) $w(p) = 0$.</p>

<p>It can't be the case that $w$ behaves identically on all primes, i.e. $w(p) = k$ for all primes $p$ since it is easy to compute counterexamples, e.g. $2^2*5^2 + 3^5 = 7^3$ that will contradict (2).</p>

<p>Thus it must be distinct at some two primes $p_1, p_2$. This gives two distinct relatively prime numbers where w is equal, $ p_1^{w(p_2)} $ and $p_2^{w(p_1)}$. I hoped that this would lead to a contradiction but haven't found a way forward yet.</p>
",number_theory
"<p>A generalization of the conjecture </p>

<p>$$\pi(x+x^{\theta}) - \pi(x) \sim \frac{x^\theta}{\log x} $$ (Ingham, 1937 or earlier) might be</p>

<p>$$\Delta \pi_k = \pi_k((x+1)^2) - \pi_k(x^2)\sim \frac{x}{\log x}\frac{(\log\log x^2)^{(k-1)}}{(k-1)!} $$</p>

<p>in which $\pi_k(x)$ is the number of numbers with k primes including repetitions not exceeding x. </p>

<p>For the case $k = 1$ we have $\Delta \pi_1 \sim \frac{x}{\log x},$ suggesting that the number of primes on a square interval approaches that of the interval $[1,x].$ All very speculative. My question is simply whether we can find a similar (speculative) statement for $\Delta \pi_2,$ etc., relating the number of primes on the square interval to that of some interval $[1,x]?$ In other words, can we solve for example:</p>

<p>$$\frac{x}{\log x}\log\log (x^2)= \frac{y}{\log y} \sim \pi(y) $$ for y in terms of x?   </p>

<p>It's easy enough to plot $f(x)=\frac{x}{\log x}\log\log x$ and find $\pi(y)\approx f(x).$ For example: </p>

<p>$$\frac{1000}{\log 1000}\log\log 1000^2 \approx \frac{3048}{\log 3048}.$$  </p>

<p>Thanks for any insight.  </p>

<p>I have failed the Turing test twice today, so editing appreciated.</p>
",number_theory
"<p>Find two positive integers $x$ and $y$ such </p>

<p>$$\sqrt{69+20\sqrt{11}}=\sqrt{x}+\sqrt{y}$$</p>

<p>I have worked intensively with this task but I really can't find a solution to this problem. I hope that I can get a hint here. </p>
",number_theory
"<p>I have thought of a conjecture similar to Goldbach Conjecture. I have shown the result to be true with a program in C++ up until $n=30000$.</p>

<blockquote>
  <p>$\forall n&gt;2$ with $n$ even,there exists two primes $p,q$ with $n&lt;p,q&lt;2n$ $\;$ and $\;$  $p+q=3n$</p>
</blockquote>

<p>We know Betrand's postulate:</p>

<blockquote>
  <p>For any integer $n &gt; 3$, there always exists at least one prime number $p$ with
  $n &lt; p &lt; 2n - 2$.</p>
</blockquote>

<p>But I don't know if this postulate can help me.</p>

<p>I wanted to place it somewhere public so people can think about it.
Are there any results similar to this?</p>
",number_theory
"<p>It is well known that a polynomial $$f(n)=a_0+a_1n+a_2n^2+\cdots+a_kn^k$$ is composite for some number $n$.</p>

<p>What about the function $f(n)=a^n+b$ ? </p>

<blockquote>
  <p>Do positive integers $a$ and $b$ exists such that $a^n+b$ is prime for every natural number $n\ge 1$ ?</p>
</blockquote>

<p>I searched for long chains in order to find out whether there is an obvious upper bound. For example $4^n+4503$ is prime for $n=1,\ldots,14$.</p>
",number_theory
"<p>Recently I am reading Stein's <em>Complex Analysis</em>, and he is going to prove the prime number theorem after estimating the value $1/\zeta(s)$. However, I don't understand the technical details of the proof in Proposition 1.6 in chapter 7. Here are what I have before going to my problem.</p>

<ol>
<li>If $\sigma \ge1$ and $t\in\mathbb R$, then $\log\left|\zeta^3(\sigma)\zeta^4(\sigma+it)\zeta(\sigma+2it)\right|\ge1$ (Chapter 7, Corollary 1.5)</li>
<li>If $\sigma,t\in \mathbb R$, $|t|\ge1$, $0\le\sigma_0\le1$ and $\sigma_0\le\sigma$, then for every $\epsilon&gt;0$, there exists a constant $c_\epsilon$ such that $|\zeta(\sigma+it)|\le c_\epsilon|t|^{1-\sigma_{0}+\epsilon}$ (Chapter 6, Proposition 2.7)</li>
</ol>

<p>Here is my question, in Chapter 7, Proposition 1.6: The book tells that the following inequality holds for $\sigma\ge1$ and $|t|\ge1$:</p>

<p>$$|\zeta^4(\sigma+it)|\ge c|\zeta^{-3}(\sigma)||t|^{-\epsilon}\ge c'(\sigma-1)^3|t|^{-\epsilon}$$</p>

<p>The first inequality is obviously concluded from (1) and (2) above. However I can't see why the second inequality holds. Can anybody give me some hints on it?</p>
",number_theory
"<p><strong>Statement</strong>  For every $n > 1$ there is always at least one prime $p$ such that $n &lt; p &lt; 2n$.</p>

<p>I am curious to know that if I replace that $2n$ by $2n-\epsilon$, ($\epsilon>0$) then what is the  $\inf (\epsilon)$ so that the inequality still holds, meaning there is always a prime between $n$ and $2n-\epsilon$</p>
",number_theory
"<p>Let $\Lambda$,$\Lambda'$ be two lattice in $\mathbb{C}$ and $m\neq 0\in\mathbb{C}$ satisfying 
$$
m\Lambda\subset\Lambda'
$$</p>

<p>The, the book I'm reading says that by the theory of finite Abelian groups there exists a basis $\{\omega_1,\omega_2\}$ of $\Lambda$' and positive integers $n_1,n_2$ such that $\{n_1\omega_1,n_2\omega_2\}$ is a basis of $m\Lambda$.</p>

<p>I wonder which theorem is it using to deduce such conclusion? There is even no finite Abelian groups there.</p>

<p>update:</p>

<p>I think the author means theory of finitely-generated Abelian groups, doesn't him?</p>
",number_theory
"<p>In 1893 Hadamard proved that:</p>

<p>$$\xi(s) = \xi(0) \prod_{\rho} \left(1- \frac{s}{\rho} \right) \left(1- \frac{s}{1-\rho} \right)$$</p>

<p>where $\xi(z) = \frac12 z(z-1) \pi^{-\frac{z}{2}} \Gamma(\frac{z}{2}) \zeta(z)$ and $\rho = \sigma + \gamma i$ is a non-trivial zero of $\zeta(s)$ (i.e. $\gamma_n$ is the imaginary part of the n-th $\rho)$).</p>

<p>Riemann had already conjectured this in 1859 and since he needed an 'always real' function for his next thought steps, he assumed $s=\frac12 + t i$ and defined the function $\Xi(t)=\xi(s)$ that has been proven to be equal to:</p>

<p>$$\Xi(t)= \Xi(0)\prod_\gamma\left(1-\frac{t^2}{\gamma^2}\right)$$</p>

<p>It is known that $\xi(s)=\xi(1-s)$ and $\xi(s)=\overline{\xi(\overline{s})}$ and this implies that $\xi(s)\xi(\overline{s})$ must be real. Also known is that when there is a non-trivial zero $\rho$ lying off the critical line, then also $1-\rho, \overline{\rho}, \overline{1-\rho}$ must be zeros and their product will always be real:</p>

<p>$$\displaystyle\prod_\gamma\left(1-\frac{s}{\sigma+i \gamma}\right)
\left(1-\frac{s}{\sigma-i \gamma}\right)\left(1-\frac{s}{1-(\sigma+i \gamma)}\right)
\left(1-\frac{s}{\overline{1-(\sigma+i \gamma)}}\right)$$</p>

<p>This brought me to the following conjecture. Suppose $s=a+t i$ and $\Xi_a(t)=\xi(s)$ so $\Xi_a(0)=\xi(a)$, then the following product holds and is always real:</p>

<p>$$\Xi_a(t)\Xi_a(-t) = \Xi_a(0)^2\prod_\gamma \left(1-\frac{t^2}{\gamma^2}\right)\left(1-\frac{(-t)^2}{\gamma^2}\right)$$</p>

<p>or simpler:</p>

<p>$$\Xi_a(t)\Xi_a(-t) = \left(\xi(a)\prod_\gamma \left(1-\frac{t^2}{\gamma^2}\right)\right)^2$$</p>

<p>Numerical tests indicate that the conjecture is correct, but I am obvioulsy keen to find a proof (I do realise this is a way too big of a question to ask here!). Does anybody have a link that explains how $\Xi(t)= \Xi(0)\prod_\gamma\left(1-\frac{t^2}{\gamma^2}\right)$ has been derived? Also appreciate any other thoughts/steers on how to further progress this conjecture.</p>

<p>Thanks!  </p>
",number_theory
"<p>Since it is particularly easy to write down a basis of a Kummer extension $K=k(\mu)/k$ (where $\mu^n=a \in k$) as a $k$-vector space, I suspect that it is should not be terribly hard to write an explicit formula for a norm of an element in terms of its coordinates in this basis.</p>

<p>Is there a standard text where this derivation is carried out?</p>
",number_theory
"<p>How would you go about solving a multivariable, non-linear Diophantine Equation?</p>
",number_theory
"<p>Supose we have a set $S$ of natural numbers. We define: 
$$ f(x) = \begin{cases} {x \over 2} &amp; x \text{ is even } \\ {x - 1 \over 2} &amp; x \text{ is odd }\end{cases} $$</p>

<p>Now let $a_0 = a_1 = 1$ and $a_n = a_{n-1} + a_{n-2}$ for $n \notin S$ and $a_n = f(a_{n-1} + a_{n-2})$ otherwise for $ n &gt; 1$.</p>

<p>I want to calculate the remainder of $a_n \bmod p $ for $p$ prime. The problem is that the numbers become quite large so I can not store then. I must work with the reminders.</p>

<p>My fist idea was to work with the modular inverse of $2$ and e kept the remainder mod p at each step and instead of dividing by $2$, I multiply by $1/2$. The problem is that is does not work if $S$ has more than one element.</p>

<p>I think the solution is to keep the values $\bmod 2^y\cdot p$ where $y$ is the number of elements in $S$ $(\#S)$. And in the end take do remainder of $a_n \bmod p$. It seems to work but I don't understand why...</p>

<p>I'm sorry if I was not clear.</p>

<p>Thank you.</p>
",number_theory
"<p>The book I'm reading doesn't provide the definition of degree of an isogeny and I failed to google it. Can anyone tell me?</p>
",number_theory
"<p>Ramanujan defined his function $\phi(x)$ as $$\phi(q)=\sum^{\infty}_{n=-\infty}q^{n^2}$$ and other one as $$\psi(q)=\sum^{\infty}_{n=0}q^{\frac{k(k+1)}{2}}$$ So I have a question that is there an integral representation for these functions? </p>
",number_theory
"<p>As we know that $f(x)=x^2+1\equiv0 \pmod p $ has no integer solutions if $p\equiv 3\pmod 4$, does there exist a cubic polynomial $f(x)=ax^3+bx^2+cx+d~(a,b,c,d \in\mathbb Z,a\neq 0) $ such that $f(x)\equiv0 \pmod p $ has no integer solutions if $p\equiv 3\pmod 4$?</p>

<p>I only know that $f(x)=0$ has no integer solutions.</p>
",number_theory
"<p>Explaining my work on Maass wave forms to friends and family (all non-mathematician) typically earns me blank faces. So I wonder whether there is some good example to explain their meaning to laymen. I am aware of the inner-mathematical importance of Maass wave forms, but what are real life applications of Maass wave forms?</p>
",number_theory
"<blockquote>
  <p>Prove that $$\displaystyle \sum_{k=1}^n \bigg(\dfrac{1}{k}+\dfrac{2}{k+n}\bigg ) \leq \ln(2n) + 2 -\ln(2).$$</p>
</blockquote>

<p>I was thinking of using mathematical induction for this. That is,</p>

<p>We prove by induction on $n$. The case $n=1$ holds trivially since $2 \leq 2$. Now assume the result holds for some $m$. Then by assumption we know that $$\displaystyle \sum_{k=1}^{m+1} \bigg(\dfrac{1}{k}+\dfrac{2}{k+m}\bigg ) \leq \ln(2m) + 2 -\ln(2)+\dfrac{1}{m+1}+\dfrac{2}{2m+1}. $$ </p>

<p>We must relate this somehow to $\ln(2(m+1)) + 2 -\ln(2)$.</p>
",number_theory
"<p>I have to show that $2x^4-20x+8$ cannot be divided by $16$ without remainder. The only thing comes to my mind is to write $16$ as $4^2$ which hasn't been of any help.</p>

<p>Could you give me some hints to prove this?</p>
",number_theory
"<p>Let $n=3^{1000}+1$. Is n prime?</p>

<p>My working so far:</p>

<p>$n=3^{1000}+1 \cong 1 \mod 3$</p>

<p>I notice that n is of form; $n=3^n+1$</p>

<p>Seeking advice tips, and methods on progressing this.</p>
",number_theory
"<p>Let $K=\mathbb{Q}(\zeta_m)$. Then if $p\nmid m$ is any odd prime, how i can show that Frobenius map is
$(p,K/\mathbb{Q})(\zeta_m)=\zeta_m^p$.</p>

<p>We know, if $P$ is a prime above $p$ </p>

<p>$$(p,K/\mathbb{Q})(x) \equiv x^p (\mbox{mod } P) \quad\forall x \in \mathbb{Z}_K$$</p>

<p>Thanks!</p>
",number_theory
"<p>In p-adic case, Schwart function is the function which has compact support and locally constant. But can we say its uniform continuity from this?</p>

<p>I think it would not be true, but I am not certain with great convince.</p>

<p>Would you let me know this?</p>
",number_theory
"<blockquote>
  <p>Solve in positive integers: $5x^2+6x^3=z^3$.   </p>
</blockquote>

<p>$x^2(6x+5)=z^3$ </p>

<ul>
<li>If $(x,5)=5$, let $x=5k$. So $k^2(6k+1)=\left(\frac{z}{5}\right)^3$, we're left with solving $6n^3+1=m^3$.    </li>
<li>If $(x,5)=1$, then we're left with solving $6n^3+5=m^3$.   </li>
</ul>

<p>Here we only used $(a,b)=1,\: ab=c^3$ gives $a=n^3, b=m^3$.   </p>

<p>How to solve these 'cubic Pell equations'?</p>
",number_theory
"<p>Few friends are going to a party. Each person has his own collection of T-Shirts. There are 100 different kind of T-Shirts. Each T-Shirt has a unique id between 1 and 100. No person has two T-Shirts of the same ID.</p>

<p>They want to know how many arrangements are there in which no two persons wear same T-Shirt. One arrangement is considered different from another arrangement if there is at least one person wearing a different kind of T-Shirt in another arrangement.</p>

<p><strong>Example 1 :</strong> If Their are 2(=N) friends and Each of the next N lines contains at least 1 and at most 100 space separated distinct integers, denoting the ID's of the T-Shirts ith person has.</p>

<pre><code>3 5
8 100
</code></pre>

<p>Answer for this case is 4 </p>

<p>Explanation : 4 possible ways are (3,8), (3,100), (5,8) and (5,100).</p>

<p><strong>Example 2 :</strong> If N=3 and collection with each of 3 friends is as follow :</p>

<pre><code>5 100 1
2
5 100
</code></pre>

<p>Then here also answer will be 4 as 4 possible ways are (5,2,100), (100,2,5), (1,2,100), and (1,2,5).</p>
",number_theory
"<p>In a book I'm reading the following modulus comes up,
$$ \operatorname{mod} \: \mathbb{Q}^{*2}$$ 
and I'm struggling to understand what it means. I understand $\mathbb{Q}^{*} = \mathbb{Q}\backslash \{0\}$ but not the square.</p>

<p>Context: $\delta := \frac{a.b}{2} \: (\operatorname{mod} \: \mathbb{Q}^{*2})$ with $a,b \in \mathbb{R}$.</p>
",number_theory
"<p>Here is the problem:</p>

<p>$ 445^{445} + 225^{225}  \pmod{9}$</p>

<p>I found out that for $ 445^{445}  \pmod{9} = 7$.</p>

<p>but for $ 225^{225}  \pmod{9}$ when I do this:</p>

<p>$ (225 \bmod 9)^{225  \bmod 8}$ for the first equation I have $0$ mod.</p>

<p>What should I do?</p>
",number_theory
"<p>Would someone be kind enough to correct my error here?</p>

<p>$S=1+2+3+4+\cdots$</p>

<p>Now starting with the 1st prime number, regroup the sum:</p>

<p>$S=(1+3+5+7+\cdots) + (2+4+6+\cdots)$</p>

<p>$S=(1+3+5+7+\cdots) + 2(1+2+3+\cdots)$</p>

<p>$S=(1+3+5+7+\cdots) + 2S$</p>

<p>Now repeat the same procedure for every prime to acquire:</p>

<p>$S=1+2S+3S+5S+\cdots$</p>

<p>$1=\frac{1}{S}+2+3+5+\cdots$</p>

<p>$S=1-\frac{1}{2}-\frac{1}{3}-\frac{1}{5}-\cdots$</p>

<p>Does this logic make sense at all?</p>
",number_theory
"<p>Let $q$ be a prime such that $q \equiv 2 (\mod 3)$ , then is it true that $a^2+ab+b^2=qc^2$ has no solution in non-zero integers $a,b,c$ ? </p>
",number_theory
"<p>I seek a (very) elementary proof that the zeta function of an elliptic curve $E$ over $\mathbb{F}_q$ has the form
$$Z(T)=\frac{1-aT+qT^2}{(1-T)(1-qT)}.$$
Something tedious and computational making use of Weierstrass Normal Form (I am happy to assume that char$(\mathbb{F}_q)\neq 2,3$) would be good! I am also happy if someone can suggest a reference which only deals with a certain class of elliptic curve. </p>

<p>Many thanks!</p>
",number_theory
"<p>Number of ordered triples $(a, b, c)$ with $gcd(a, b, c) = 1$ and $1 \leq a, b, c \leq n$ can be computed using the following formula:
$$
C(n) = \sum_{k=1}^n\mu(k) \left \lfloor \frac{n}{k} \right \rfloor^3
$$,
where $\mu(n)$ is Moebius function. </p>

<p>But how it can be derived?</p>

<p>Thanks!</p>
",number_theory
"<p><em>This is a ""fiddling"" in a small project of mine with which I'm concerned from time to time for <a href=""http://math.stackexchange.com/questions/39378/series-of-logarithms-sum-limits-k-1-infty-lnk-ramanujan-summation?rq=1"">three years now</a>. I try to focus on the core of the problem, please ask if more context is needed.</em><br>
<hr>
Consider the divergent series 
$$ \sum_{k=1}^\infty {(-1)^{k-1} \over k }\zeta(-k) \underset{\mathcal N}{=} s_1 = -0.081061466...   $$
Here the symbol ""$\underset{\mathcal N}{=} $"" means, that I did that sum by the Noerlund-summation-method using 64 terms. The value which I expect by some other derivation which I'll explain below is $ -\zeta(0)' = 0.91893853 $ which differs exactly by 1.        </p>

<p>More context: the coefficients at the zetas are taken just from the matrix of Stirling-numbers of the first kind, denote them simply as $s1_{r,c}$ , so the defition stems really from:
$$ \sum_{r=1}^\infty s1_{r,1} \cdot {1! \over r! }\zeta(-r) \underset{\mathcal N}{=} s_1  $$</p>

<p><hr>
Next consider the divergent series taken from the next column in the Stirling matrix:
$$ \sum_{k=1}^\infty s1_{k,2} \cdot { 2! \over k! }\zeta(-k) \underset{\mathcal N}{=} s_2 = -0.006356455...   $$
The value which I expect by the other derivation is $ \zeta(0)'' = -2.00635645591... $ which differs (relatively near) by $2!$. (The difference can be made smaller by taking more terms for the Noerlund-summation)
<hr>
To make things short, I'm doing the dotproduct
$$ Z \cdot S1 \underset{\mathcal N}{=} Y $$
where the infinite rowvector $Z$ contains the consecutive zetas $\zeta(0),\zeta(-1),\zeta(-2), ...$ and $S1$ is the matrix containing the Stirlingnumbers first kind, scaled by factorials such that
$$ S1_{r,c} = s1_{r,c} \cdot { c!\over r!} $$
getting the result-vector $Y$ which deviates from my expected result of derivatives  $ \zeta(0)^{(c)}$ by factorials such that
$$ Y[c]= (-1)^c \cdot (\zeta(0)^{(c)} + c!) $$
<hr>
The problem is connected with that of the Ramanujan-summation of the series of like powers of logarithms:
$$ \sum_{k=0}^{\infty} \log(1+k)^c \underset{\mathcal Z}{=}  (-1)^c \cdot \zeta(0)^{(c)} $$
where I get (by ""$\mathcal  Z $"" eta-regularization) the ""magic constants"" having the same values as I described above and which deviate by the expected values for that sums (by the signed $\zeta(0)$-derivatives) exactly the factorials. (See <a href=""http://math.stackexchange.com/questions/39378/series-of-logarithms-sum-limits-k-1-infty-lnk-ramanujan-summation?rq=1"">my earlier question in MSE</a> but in which I had not yet that more general view with the columns of the Stirlingmatrix)           </p>

<p><em>Additional remarks:</em> the complete background can be found <a href=""http://go.helms-net.de/math/divers/BernoulliForLogSums.pdf"" rel=""nofollow"">in this article</a> (I'm just editing the concerning paragraphs) and was remotivated by the <a href=""http://math.stackexchange.com/questions/437690/computing-the-value-of-logarithmic-series-qs-n-ln1s-ln2s-ln3"">recent question here in MSE</a>      </p>
",number_theory
"<p>I was wondering whether it has been proven/disproven yet or at least conjectured that the bernoulli denominator of $B_{2n}$ is divisible by $2n+1$ if and only if $2n+1$ is prime?</p>

<p>If not, must the denominator always share a common factor with the value $2n+1$?</p>

<p>Or the question could be written as is denom($B_{2n}) = \prod\limits_{p:(p-1)|(2n)} p    = (2n+1)m$ where m is an integer always true if and only if $2n+1$ is prime?</p>
",number_theory
"<p>I search a composite number near $4^{4^4}$ with a very large smallest prime factor. A candidate is $$4^{4^4}+253=4^{256}+253$$</p>

<p>The number is composite and has $155$ digits, so it is in the range , the quadratic sieve can handle. But the calculation will take several days.</p>

<p>I ran $500$ elliptic curves with $B1=250K$ and $150$ curves with $B1=1M$ and will continue the search with ECM. Everyone reading this is invited to run MPQS.</p>
",number_theory
"<p>Let $r_k(n)$ be the number of ways to write $n$ as the sum of $k$ squares of integers. </p>

<blockquote>
  <p><strong>Theorem:</strong> If $k \ge 5$ then there are constants $C,c&gt;0$ such that for any $n$, $$cn^{k/2 - 1} \le r_k(n) \le Cn^{k/2 - 1}$$</p>
</blockquote>

<p>What is the simplest way to prove it as stated? I am especially interested in the lower bound. Is there a recommended book on the subject?</p>

<p>I have read about the Hardy-Littlewood circle method in E. Grosswald's <em>Representations of Integers as Sums of Squares</em>, but it seems to give a much more precise formula than what I need, and I feel there's a chance it might be simpler than that.</p>
",number_theory
"<p>Let $E=\mathbb{C}/\Lambda$ be a complex elliptic curve where $\Lambda=\omega_1\mathbb{Z}\oplus\omega_2\mathbb{Z}$</p>

<p>Let $f$ be a nonconstant elliptic function with respect to $\Lambda$.</p>

<p>Let $P=\{x_1\omega_1+x_2\omega_2:x_1,x_2\in[0,1]\}$ be the parallelogram with opposing boundary identified appropriately.</p>

<p>There exists some constant $t$ such that $f$ has no zeros and poles on $t+\partial P$.</p>

<p>Now I want to compute the integral
$$
\frac{1}{2\pi i}\int_{t+\partial P}\frac{zf'(z)}{f(z)}d{z}
$$</p>

<p>I need to show that it is 
$$
\sum_{x\in E}\nu_x(f)x
$$
where $\nu_x(f)$ is the order of $f$ at $x$, which means $f(z)=(z-x)^{\nu_x(f)}g(z)$ where $g(x)\neq 0$.</p>

<p>I can find that it is 
$$
\omega_1\int_{t}^{t+\omega_2}\frac{f'(z)}{f(z)}dz-\omega_2\int_{t}^{t+\omega_1}\frac{f'(z)}{f(z)}dz
$$</p>

<p>and each integral is an integer because $f$ is the same at the two endpoints. But I cannot get the desired formula.</p>

<p>Any help?</p>
",number_theory
"<p>Let $f$ be a meromorphic function on the region $Im(z)&gt;0$, $v_p(f)$ be the order of $p$. (The number $n$ such that $\frac{f(z)}{(z-p)^n}$ is holomorphic and non-zero at $p$.)</p>

<p>Moreover, assume $f$ is a $modular$ $function$ for $SL(\mathbb Z)$ of weight $k$.</p>

<p>Then we have the following application of $residue$ $theorem$.</p>

<p><img src=""http://i.stack.imgur.com/Lfqzo.png"" alt=""enter image description here""></p>

<p>Why is the last limitation true? The argument principle only tell us the integral over a circle.</p>
",number_theory
"<p>Similar to the cfracs in <a href=""http://math.stackexchange.com/questions/1778344/two-complementary-continued-fractions-that-are-algebraic-numbers"">this post</a>, define the two complementary continued fractions,</p>

<p>$$x=\cfrac{-(m+1)}{km\color{blue}+\cfrac{(-1)(2m+1)} {3km\color{blue}+\cfrac{(m-1)(3m+1)}{5km\color{blue} +\cfrac{(2m-1)(4m+1)}{7km\color{blue}+\cfrac{(3m-1)(5m+1)}{9km\color{blue}+\ddots}}}}}\tag1$$</p>

<p>$$y=\cfrac{-(m+1)}{km\color{red}-\cfrac{(-1)(2m+1)} {3km\color{red}-\cfrac{(m-1)(3m+1)}{5km\color{red}-\cfrac{(2m-1)(4m+1)}{7km\color{red}-\cfrac{(3m-1)(5m+1)}{9km\color{red}-\ddots}}}}}\tag2$$</p>

<p>The first one is the superfamily which contains Nicco's cfracs in <a href=""http://math.stackexchange.com/questions/1775471/a-continued-fraction-related-to-pythagoras-theorem-a2b2-c2"">another post</a>. Let $i$ be the <em>imaginary unit</em>. For $k&gt;1$ and $m&gt;1$, it can be empirically observed that $x$ obeys,</p>

<p>$$\left(\frac{(x+i)^m-(x-i)^m}{(x+i)^m+(x-i)^m}\right) \color{blue}{\left(\frac{(k+i)^{m+1}+(k-i)^{m+1}}{(k+i)^{m+1}-(k-i)^{m+1}}\right)^{(-1)^m}}=1\tag3$$</p>

<p>while $y$ obeys,</p>

<p>$$\left(\frac{(y+1)^m+(y-1)^m}{(y+1)^m-(y-1)^m}\right) \color{blue}{\left(\frac{(k+1)^{m+1}+(k-1)^{m+1}}{(k+1)^{m+1}-(k-1)^{m+1}}\right)^{(-1)^{m+1}}}=-1\tag4$$</p>

<p>where the colored part is a constant that depends on the choice of $k,m$. Hence, as shown in <a href=""http://math.stackexchange.com/questions/1581041/how-to-solve-in-radicals-this-family-of-equations-for-any-degree-k"">this post</a>, $x,y$ are <em>radicals</em> and algebraic numbers of degree $m$.</p>

<blockquote>
  <p><strong>Question:</strong> <em>How do we prove that $(3)$ and $(4)$ are indeed true?</em></p>
</blockquote>

<p><strong>P.S.</strong> Since,</p>

<p>$$\left(\frac{(z+i)^m+(z-i)^m}{2}\right)^2+i^2\left(\frac{(z+i)^m-(z-i)^m}{2}\right)^2 = (z^2+1)^m$$</p>

<p>then the structure of $(3)$ explains the observations about $a^2+b^2=c^m$ in Nicco's post.</p>
",number_theory
"<p>Is there a way to find 2 sqare numbers with a certain distance without trying every square number?</p>

<p>Example:</p>

<p>$$
a^2 + 204 = b^2
$$</p>
",number_theory
"<p>Let $\Lambda$,$\Lambda'$ be two complex lattices and $m\neq 0\in\mathbb{C}$ satisfying $m\Lambda\subset\Lambda'$. Suppose $\omega_1,\omega_2$ are the basis of $\Lambda$, $\omega'_1,\omega'_2$ are the basis of $\Lambda'$. So we have</p>

<p>$$
\begin{bmatrix}m\omega_1\\m\omega_2\end{bmatrix}=\alpha\begin{bmatrix}\omega_1'\\\omega'_2\end{bmatrix}\text{ for some }\alpha\in M_2(\mathbb{Z})
$$</p>

<p>Then it is said that $[\Lambda',m\Lambda]=\det\alpha$.</p>

<p>Why?</p>
",number_theory
"<p>As in, why does the iteration of the function until $g_{64}$ guarantee this property that defines Graham's number? Why was this number chosen?</p>

<p>If I had to guess (emphasis on guess), I'd say that the Ramsey theoretical problem involving  Graham's number involves ${4 \choose 2} = 6$ line segments between four points and two ways to color each, and $2^6 = 64$. But I don't know at all.</p>
",number_theory
"<p>Is it guaranteed that there will be some $p$ such that  $p\mid2^n-1$ but $p\nmid 2^m-1$ for any $m&lt;n$?</p>

<p>In other words, does each $2^x-1$ introduce a <em>new</em> prime factor?</p>
",number_theory
"<p>The following example is drawn from Milne's Galois Theory notes, p.42 (<a href=""http://www.jmilne.org/math/CourseNotes/FT.pdf"" rel=""nofollow"">http://www.jmilne.org/math/CourseNotes/FT.pdf</a>)</p>

<p>We study the extension $\mathbb{Q}[\zeta]/\mathbb{Q}$ where $\zeta=e^{2\pi i/7}.$</p>

<p>We find that $\mathbb{Q}[\zeta]$ is the splitting field for the minimal polynomial $x^7-1,$ and that it is a degree 6 Galois extension over $Q.$</p>

<p>We let $\sigma$ be the element of $\text{Gal}(\mathbb{Q}[\zeta]/\mathbb{Q}) = (\mathbb{Z}/7\mathbb{Z})^{\times}$ such that $\sigma \zeta= \zeta^3.$ Note that $\sigma$ is a generator for $\text{Gal}(\mathbb{Q}[\zeta]/\mathbb{Q}).$</p>

<p>We now ask: what is the subfield $S$ of $\mathbb{Q}[\zeta]$ which corresponds to the order 2 subgroup $&lt;\sigma^3&gt;.$ </p>

<p>We note that $\sigma^3 \zeta=\zeta^6= \overline{\zeta}.$ So in particular, $\zeta+ \overline{\zeta}$ is fixed by $\sigma^3$ and so $\mathbb{Q}[\zeta+\overline{\zeta}] \subset S.$ </p>

<p>Milne claims that we also have $S \subset \mathbb{Q}[\zeta+\overline{\zeta}].$ While this seems reasonable, is there a systematic way to see this? </p>
",number_theory
"<p>I would like to pose the following conjecture.Given</p>

<p>$$\phi(q) =\cfrac{1}{1-q+\cfrac{q(1-q)^2}{1-q^3+\cfrac{q^3(1-q^2)^2}{1-q^5+\cfrac{q^5(1-q^3)^2}{1-q^7+\ddots}}}}$$ </p>

<p>and</p>

<p>$$\psi(q)=\cfrac{-q}{1-q+\cfrac{q(1-q)^2}{1-q^3+\cfrac{q(1-q^2)^2}{1-q^5+\cfrac{q(1-q^3)^2}{1-q^7+\ddots}}}}$$ </p>

<p>Then prove/disprove that the two continued fractions are equivalent</p>

<p>$$\phi(q)=\psi\left(\frac{1}{q}\right)$$</p>
",number_theory
"<p>Let $a,b$ be positive integers such that $a\mid b^2 , b^2\mid a^3 , a^3\mid b^4 \ldots$ that is $a^{2n-1}\mid b^{2n} ; b^{2n}\mid a^{2n+1} , \forall n \in \mathbb Z^+$ , then is it true that $a=b$ ?</p>
",number_theory
"<p>Prove that a number in the sequence $2,3,4,...,n \ (n>2$, is relatively prime to all other numbers if and only if it is a prime that exceeds $\displaystyle\frac{n}{2}$. Does such a prime always exist?</p>
",number_theory
"<p>Everyone knows that $\pi$ is an irrational number, and one can refer to this <a href=""http://planetmath.org/encyclopedia/PiAndPi2AreIrrational.html"" rel=""nofollow"">page</a> for the proof that $\pi^{2}$ is also irrational.</p>

<p>What about the highers powers of $\pi$, meaning is $\pi^{n}$ irrational for all $n \in \mathbb{N}$ or does there exists a $m \in \mathbb{N}$ when $\pi^{m}$ is rational.</p>
",number_theory
"<blockquote>
  <p>Given integers $m$, $c$ and $n$. Find $m$ such that $m^2 \equiv c \ (\mod n) $</p>
</blockquote>

<p>I used <a href=""https://en.wikipedia.org/wiki/Tonelli%E2%80%93Shanks_algorithm"" rel=""nofollow"">Tonelli-Shanks algorithm</a> to caculate the square root, but in my case $n$ is not a prime number, $n = p^2,\ p$ is a prime number. </p>

<p>I read <a href=""http://www.mersennewiki.org/index.php/Modular_Square_Root"" rel=""nofollow"">this page</a>. It is said that:</p>

<blockquote>
  <p>In this article we will consider the case when the modulus is prime.
  Otherwise we can compute the square roots modulo the prime factors of
  $p$ and then generate a solution using the <a href=""https://en.wikipedia.org/wiki/Chinese_remainder_theorem"" rel=""nofollow"">Chinese Remainder Theorem</a>.</p>
</blockquote>

<p>Using Tonelli-Shanks algorithm again, I found $m_p$ such that $m_p^2 \equiv {c} \ (\mod p)$.</p>

<blockquote>
  <p>I'm stuck with finding $m$ from $m_p$. That page above does not tell me clearly about how to solve that case. Please help me !</p>
</blockquote>
",number_theory
"<p>Let $V$ a finite dimensional vector space over $\mathbb{Q}$ and let $F$ be a number field. Assume that there is an injective morphism of rings $F \hookrightarrow End(V)$. I would like to understand why $V_\mathbb{C}:=V \otimes_{\mathbb{Q}} \mathbb{C}$ decomposes into a direct sum </p>

<p>$$
V_\mathbb{C}=\bigoplus_{\sigma \in Hom(F, \mathbb{C})} V_\sigma 
$$ </p>

<p>according to complex embeddings of $F$. My idea is the following: if $F=\mathbb{Q}(\alpha)$ then the endomorphism $\alpha \in End(V)$ has the same minimal polynomial as $\alpha$ viewed as an element of $F$. Its roots are $\{\sigma(\alpha)\}_{\sigma \in Hom(F, \mathbb{C})}$ so one can define </p>

<p>$$
V_\sigma=\{ x \in V_\mathbb{C}| \alpha \cdot x=\sigma(\alpha)x\} 
$$</p>

<p>1) Why this is independent of $\alpha$?</p>

<p>2) Is there a more conceptual way to think of it? </p>
",number_theory
"<p>I used similar technique as Fourier's proof of irrationality of $e$ <a href=""https://en.wikipedia.org/wiki/Proof_that_e_is_irrational"" rel=""nofollow"">https://en.wikipedia.org/wiki/Proof_that_e_is_irrational</a> to show that this series is indeed an irrational number but I was wondering if there are other elementary proofs, specially techniques related to polynomials with rational coefficients. Any hint, complete proof, reference, etc. is much appreciated. </p>

<p>EDIT : presenting my proof as @AndréNicolas requested : I just followed the same steps; let's assume the series is $s$. Now choose $k_0$ such that $m^{k_0^2} &gt; q$. Define $x = q m^{k_0^2} \left(s - \sum_{k=1}^{k_0}{\frac{1}{m^{k^2}}} \right)$. Now if $s$ is not irrational then $s=\frac{p}{q}$ for some non-negative $p$ and $q$. Then it is easy to check that $x$ is an integer. Now we need to reach to a contradiction by proving that $x &lt; 1$. 
After simple manipulations, $x = q m^{k_0^2} \sum_{k=k_0+1}^{k_0}{\frac{1}{m^{k^2}}}$
Now, for $k=k_0+1,k_0+2, \ldots$, we have $k^2 &gt; k+k_0^2$ so
$$ q m^{k_0^2} \sum_{k=k_0+1}^{k_0}{\frac{1}{m^{k^2}}} &lt; q m^{k_0^2} \sum_{k=k_0+1}^{k_0}{\frac{1}{m^{k+k_0^2}}} = \frac{q}{m^{k_0^2+1}}\frac{1}{1-\frac{1}{m}}=\frac{1}{m-1}$$ which follows from our assumption about $q$ and $k_0$.</p>
",number_theory
"<p>When I test for small values of k, it seems that the order of $5+2^k\mathbf{Z}$ in $(\mathbf{Z}/2^k\mathbf{Z})^*$ is $2^{k-2}$. How do I prove this?</p>
",number_theory
"<p>Is there any recent research into the <a href=""http://en.wikipedia.org/wiki/Sprague%E2%80%93Grundy_theorem"" rel=""nofollow"">Sprague-Grundy values</a> of <a href=""http://en.wikipedia.org/wiki/Grundy%27s_game"" rel=""nofollow"">Grundy's game</a>?</p>

<p>It was calculated to $2^{35}$ integers but with no sight of recurrence.</p>

<p>Has anyone come up with anything new to compute a SG formula for the game?</p>
",number_theory
"<p><code>Legendre</code>, <code>Jacobi</code> and <code>Kronecker</code> Symbols are powerful multiplicative functions in computational number theory. They are useful mathematical tools, essentially for <a href=""https://en.wikipedia.org/wiki/Primality_test"" rel=""nofollow"">primality testing</a> and <a href=""https://en.wikipedia.org/wiki/Integer_factorization"" rel=""nofollow"">integer factorization</a>; these in turn are important in cryptography.</p>

<p>Yet, it would be nice to have a discussion here on their use in classical number theory and math problems. In other words, what kind of problems can they be effectively applied to? Or simply, when/where to use them?</p>

<p><strong>Definitions</strong></p>

<p>For any integer $a$ and any positive odd integer $n$ the <code>Jacobi</code> symbol is defined as the product of the <code>Legendre</code> symbols corresponding to the prime factors of $n$:</p>

<p>$\left(\tfrac{a}{p}\right)$ represents the <code>Legendre</code> symbol, defined for all integers $a$ and all odd primes $p$ by
$$\Bigg(\frac{a}{n}\Bigg) = \left(\frac{a}{p_1}\right)^{\alpha_1}\left(\frac{a}{p_2}\right)^{\alpha_2}\cdots \left(\frac{a}{p_k}\right)^{\alpha_k}\mbox{ where } n=p_1^{\alpha_1}p_2^{\alpha_2}\cdots p_k^{\alpha_k}.$$
$$
\left(\frac{a}{p}\right) = \left\{
\begin{array}{rl}
0 &amp; \text{if } a \equiv 0 \pmod{p},\\
1 &amp; \text{if } a \not\equiv 0\pmod{p} \text{ and for some integer } x:\;a\equiv x^2\pmod{p},\\
-1 &amp; \text{if } a \not\equiv 0\pmod{p} \text{ and there is no such } x.
\end{array}
\right.
$$ 
Following the normal convention for the empty product, $\left(\tfrac{a}{1}\right) = 1$. The <code>Legendre</code> and <code>Jacobi</code> symbols are indistinguishable exactly when the lower argument is an odd prime, in which case they have the same value.</p>

<p>The <code>Kronecker</code> symbol, written as $\left(\frac an\right)$ or $(a|n)$, is an extension of the <code>Jacobi</code> symbol to all integers.</p>

<p>Let $n$ be a non-zero integer, with prime factorization </p>

<p>$$n=u \cdot p_1^{e_1} \cdots p_k^{e_k},$$</p>

<p>where $u$ is a unit (i.e., $u=\pm1$), and the $p_i$ are primes. Let $a$ be an integer. The <code>Kronecker</code> symbol $(a|n)$ is defined by </p>

<p>$$ \left(\frac{a}{n}\right) = \left(\frac{a}{u}\right) \prod_{i=1}^k \left(\frac{a}{p_i}\right)^{e_i}. $$</p>

<p>For odd number $p_i$, the number $(a|p_i)$ is simply the usual <code>Legendre</code> symbol. This leaves the case when $p_i=2$. We define $(a|2)$ by </p>

<p>$$ \left(\frac{a}{2}\right) = 
\begin{cases}
 0 &amp; \mbox{if }a\mbox{ is even,} \\
 1 &amp; \mbox{if } a \equiv \pm1 \pmod{8},  \\
-1 &amp; \mbox{if } a \equiv \pm3 \pmod{8}.
\end{cases}$$</p>

<p>Since it extends the <code>Jacobi</code> symbol, the quantity $(a|u)$ is simply $1$ when $u=1$. When $u=-1$, we define it by</p>

<p>$$ \left(\frac{a}{-1}\right) = \begin{cases} -1 &amp; \mbox{if }a &lt; 0, \\ 1 &amp; \mbox{if } a \ge 0. \end{cases} $$</p>

<p>Finally, we put</p>

<p>$$\left(\frac a0\right)=\begin{cases}1&amp;\text{if }a=\pm1,\\0&amp;\text{otherwise.}\end{cases}$$</p>

<p>These extensions suffice to define the <code>Kronecker</code> symbol for all integer values $a,n$.</p>
",number_theory
"<p>Let $\psi(x) := \sum_{n\leq x} \Lambda(n)$ where $\Lambda(n)$ is the Von-Mangoldt function.
I want to show that if $$ \lim_{x \rightarrow \infty} \frac{\psi(x)}{x} =1 $$ then also $$\lim_{x\rightarrow \infty} \frac{\pi(x) \log x }{x}=1.$$</p>

<p>I tried to play a little bit with $\psi$, what I want to show is that:</p>

<p>$$\left| \frac{\pi(x) \log x}{x} -1 \right| \leq \left| \frac{\psi(x)}{x} -1 \right| \rightarrow 0$$</p>

<p>So I tried to develop $\psi$ a little bit, but I got astray.</p>

<p>So I have 
$$ \frac{\psi(x)}{x} -1 = \sum_{p^k \leq x , k \geq 1} \frac{\log p}{x} -1 = \frac{1}{x}\left(\sum_{p\leq x} \log p + \sum_{p^2\leq x} \log p + ...+ \sum_{p^k \leq x, p^{k+1} &gt;x} \log p \right) -1 $$
and I want to estimate its aboslute value from below, but I don't have any idea?</p>

<p>Any hints?</p>

<p>Thanks.</p>
",number_theory
"<p>I am working with the solutions in integers of another equation, and I have arrived to the problem of find all solutions $(x,t)$ of $x^2 +45x= t^2 $, but I don´t know how to solve this kind of equations.
What part of number theory does apply here?</p>
",number_theory
"<p>Show that </p>

<p>$$\sum_{n=1}^{\infty}\frac{\sinh\big(\pi n\sqrt2\big)-\sin\big(\pi n\sqrt2\big)}{n^3\Big({\cosh\big(\pi n\sqrt2}\big)-\cos\big(\pi n\sqrt2\big)\Big)}=\frac{\pi^3}{18\sqrt2}$$</p>

<p>I have no hint as to how to even start.</p>
",number_theory
"<p>Let $p_N/q_N$ be the $N^\text{th}$ convergent of the continued fraction for some irrational number $\alpha$. It turns out that for any other approximation $p/q$ (with $q \le q_N$) which isn't a convergent $|\alpha q - p| > |\alpha q_{N-1} - p_{N-1}|$. I'm wondering if there are any nice proofs for this result?</p>

<hr>

<p>In my book this is proved by picking $x,y$ that solves</p>

<p>$$
\begin{pmatrix} p_N &amp; p_{N-1} \\ q_N &amp; q_{N-1} \end{pmatrix}
\begin{pmatrix} x \\ y \end{pmatrix} =
\begin{pmatrix} p \\ q \end{pmatrix}
$$</p>

<p>since $x$ and $y$ have opposite sign, as well as $\alpha q_N - p_N$ and $\alpha q_{N-1} - p_{N-1}$ have opposite sign we can conclude that $|\alpha q - p| = |x (\alpha q_N - p_N) + y (\alpha q_{N-1} - p_{N-1})| = |x| |\alpha q_N - p_N| + |y| |\alpha q_{N-1} - p_{N-1}|$ which proves the theorem.</p>

<p>I am looking for different proofs than this one.</p>
",number_theory
"<p>The Riemann zeta function, is the function of the complex variable $s$, defined in the half plane $\Re(s)&gt;1$ by the absolutely convergent series $\zeta(s) = \sum_{n} n^{-s}$</p>

<p>and extends to the whole of $\mathbb{C}$ by analytic continuation. It is known that all the complex zeros of $\zeta(s)$ satisfy $0&lt;\Re(s) &lt;1$.</p>

<p>But am not sure how on they are calculated ?</p>
",number_theory
"<p>Given,</p>

<blockquote>
  <p>$$aX + bY = c$$</p>
</blockquote>

<p>where,</p>

<blockquote>
  <p>$$c &gt; b &gt; a &gt; 0;\quad X, Y &gt; 0;\quad b\nmid c, a\nmid c$$</p>
</blockquote>

<p>I want to find out if a solution exists as efficiently as possible (I'm not interested in the solutions). Are there any calculations I can make before (or without the need for) finding $\operatorname{gcd}(a, b)$ that can possibly save some time (even if for only few special cases)? $c, b, a$  can be very large numbers.</p>

<p>""Probably not"" still counts as answer for me. You don't have to be 100% certain. I just want to make sure I'm not missing something that's very obvious. </p>

<p>P.S.,
English is not my first language.</p>
",number_theory
"<p>How many positive factorials are also perfect Squares. So for example $1!=1=1^2$. How many others exist other than 1?</p>

<p>Is there any way to prove this?</p>
",number_theory
"<p>Is it true that $\sin(n^k) ≠ (\sin n)^k$ for any positive integers $n$ and integers $k ≠ 1$?</p>

<p>What if $n &gt; 0, k ≠ 1$ are rational?</p>
",number_theory
"<p>Proth number is a number of the form :</p>

<p>$z⋅2^k+1$
where z is an odd positive integer and k is a positive integer such that : $2^k&gt;z$</p>

<p>Is there a form for divisors of Proth Numbers? (Like Mersenne and Fermat Numbers have specific forms of divisors) 
My search did not turn any results.</p>

<p>Thank you...</p>
",number_theory
"<p>Let $N={abc}$ be Three Digit Number such that $$abc+bca+bac+cab+cba=3194$$ Find the Number</p>

<p>My Try: I added both sides the left over number $acb$ both sides Then we get</p>

<p>$$222(a+b+c)-3194=b+10c+100a$$</p>

<p>Help needed from here</p>
",number_theory
"<p>I'm stuck on a line in the proof of Bombieri implies Linnik, where</p>

<blockquote>
  <p><strong>Bombieri</strong>: 
  For primitive $\chi$ mod $q$ with $q \leq T$ we define $$N(\alpha, T; \chi)=\#\{\rho=\beta+i\gamma \;:\; \Lambda(\rho,\chi)=0, \beta&gt;\alpha, |\gamma|&lt;T\}.$$</p>
  
  <p>There exists $c&gt;0$ such that, for all $T \geq 2$ and all $1/2 \leq \alpha &lt;1$, $$\sum_{q \leq T}\sum_{\chi \text{ mod }q}^*N(\alpha,T;\chi)=O(T^{c(1-\alpha)})$$</p>
  
  <p>where the asterisk on the sum over characters indicates that only primitive characters are to be inlcuded. </p>
  
  <p>If there exists a real primitive character $\chi_1$ mod $q_1$ with $q_1&lt;T$, such that $\Lambda(s,\chi_1)$ has zero $\beta_1&gt;1-\frac{\delta}{\log T}$, then we have the improved estimate</p>
  
  <p>$$\sum_{q \leq T}\sum_{\chi \text{ mod }q}^*N'(\alpha,T;\chi)=O(T^{c(1-\alpha)}(1-\beta_1)\log T)$$</p>
  
  <p>where the ' on the $N(\alpha,T;\chi)$ indicates that the single exceptional zero is to be excluded.</p>
  
  <p><strong>Linnik</strong>: If $a$ and $q$ are coprime then there exists a prime $p \equiv a$ mod $q$ with $p&lt;O(q^{O(1)})$.</p>
</blockquote>

<p>In the exceptional zero case, assuming Bombieri, I've got to the point where</p>

<p>$$\sum_{p \leq x, p \equiv a \text{ mod }q }\log p \geq \frac{1}{2 \phi(q)}\left(x-\frac{x^{\beta_1}}{\beta_1}\right)+O\left(\frac{x(\log x)^2}{T}\right)$$</p>

<p>for $T=q^A$ with $A&gt;3$ and $x=T^B$ with $B&gt;12$ a large constant. I also know that $$\beta_1\leq 1-\frac{c}{\sqrt{T}(\log T)^2}.$$</p>

<p>I think what I want to show is that $x^{\beta_1}\leq x^{1-\epsilon}$ for some $\epsilon&gt;0$, because since $(O(x(\log x)^2/T)=O(x^{1-\epsilon})$ for small enough $\epsilon$, Linnik's theorem will follow. But just throwing in the bound for $\beta_1$ doesn't seem to give me this.</p>
",number_theory
"<p>I looking to find a measure of the following set:
$A=\{ (a_1,a_2,...a_k) \in \mathbb{R}^k : |1+a_1z_1+a_2z_2+...+a_kz_k|&lt;\delta \}$
and where $z_i \in \mathbb{Z}$.
I believe the measure of this set should be $\mu(A) \le c\delta$  where $c$ is some constant.</p>

<p>Can any one suggest any thing? I also, would like to know what branch mathematics deals with a problems like this.
Thank you in advance.  </p>
",number_theory
"<p>I want to show that, given an ideal $I \subseteq \mathcal O_K$ (where $K/\mathbb Q$ is an algebraic number field), there is a finite extension $K'/K$ such that,
$I\mathcal O_{K'}$ becomes a principal ideal in $\mathcal O_{K'}$.</p>

<p>The example solution for this problem uses $K' = K[X]/(X^h - x)$ where $(x) = I^h$
and $h$ is the class number for the field $K$.</p>

<p>I see why $I\mathcal O_{K'}$ is a principal ideal, however what I fail to see is why $K'$ is a field. I know that $K'$ being a field is equivalent to $(X^h - x)$ being a maximal ideal, and this in turn is equivalent to $X^h - x$ being irreducible. Why is this the case?</p>
",number_theory
"<p>I am trying to solve an equation in integers to give a square number.</p>

<p>$$2 x^2 + 3 x +1 = y^2$$</p>

<p>while also satisfying $x=k^2 * n$ where $n$ is a very large integer given to us and $k$ can be any integer chosen to form a solution. The $y$ can be any integer needed to form a solution.</p>

<p>I am looking for a method to find solutions in integers only.</p>

<p>I am new to this kind of equation and can't tell easy from hard from impossible.
This is not school work.  </p>

<p>Thanks for your help.</p>
",number_theory
"<p>What function when given the inputs $x, y$ returns the given $z$? </p>

<ul>
<li>When $x = 2, y = 10$, $z = 1$</li>
<li>When $x = 6, y = 10$, $z = 2$</li>
<li>When $x = 50, y = 70$, $z = 5$</li>
<li>When $x = 16, y = 17$, $z = 1$</li>
<li>When $x = 1, y = 3$, $z = 0$</li>
<li>When $x = 20, y = 30$, $z = 3$</li>
<li>When $x = 100, y = 140$, $z = 9$</li>
</ul>

<p>I'm trying to find if there is a relation between these examples.</p>
",number_theory
"<p>Assume $a$ and $b$ are natural numbers, $A=\{a,a^2,a^3,\cdots\}$ and $B=\{b,b^2,b^3,\cdots\}$, find $\min\left|a_i-b_j\right|$ where $a_i\in A$ and $b_j\in B$. </p>

<p>For example, if $a=3$, $b=10$, then $\min\left|a_i-b_j\right|=\left|3^2-10^1\right|=1$. </p>

<p>Variation: what if $a$ and $b$ are both prime numbers? </p>
",number_theory
"<p>I am trying to prove the local Kronecker-Weber theorem for tamely ramified abelian extensions $L|\mathbb{Q}_p$. At some point in the proof I need to show that $\mathbb{Q}_p(u^{1/e})$ is unramified under the assumptions that $u$ is a unit (possibly in some extension field) and $(e,p)=1$. Supposedly the following argument works: Since $e$ and $p$ are coprime and $u$ is a unit, the discriminant of $x^e-u$ is not divisible by $p$ and hence the splitting field is unramified.</p>

<p>I can't see why the discriminant is not divisible by $p$. I have expanded the discriminant but keep running into an issue where the number of terms may be divisible by $p$,.</p>
",number_theory
"<blockquote>
  <p>Show that the norm of a prime ideal in a number field $K$ is a power of some prime number, i.e., if $P$ is a prime ideal in $O_K$ for some number field $K$, then $N_\mathbb{Q}^K(P)=p^n$ for some prime number $p$ and some positive integer $n$. </p>
</blockquote>

<p>Here is my approach:</p>

<p>Any prime ideal lies over some prime number $p$. If we consider the ideal decomposition of $pO_K$, and apply the norm operator, we get the following: </p>

<p>$pO_K=p_1^{e_1} \cdots p_r^{e_r}$ for some $r$ since $O_K$ is a Dedekind domain. Applying the norm operator to this, we get</p>

<p>$N(pO_K)=N(p_1^{e_1} \cdots p_r^{e_r}) = N(p_1^{e_1})\cdots N(p_r^{e_r})$ since the norm has the multiplicative property. </p>

<p>This is where I am unsure if I have completely answered the question because I found a list of primes as opposed to the suggested $p^n$ in the problem statement.</p>

<p>Thanks in advance, any help is greatly appreciated. </p>
",number_theory
"<p>John has been newly hired to clean tables at his restaurant. So whenever a customer wants a table, he must clean it.</p>

<p>But John happens to be a lazy boy. So in the morning, when the restaurant is opened, all the tables are dirty from night before.</p>

<p>The customer don't leave the table unless they are politely requested to do so. And customers can order meal later again. So if they were already having a table, they can be served on the same table [John doesn't have to clean]. But if they don't have a table then they must be given some table [John must clean]</p>

<p><strong>Problem :</strong> </p>

<p>The restaurant has N tables. When a customer requires a table, he/she can occupy any unoccupied table. However if all tables are occupied, then John is free to ask politely any customer to leave his/her table. And the freed table can be given to the waiting customer.</p>

<p><strong>Now Given the  list telling the order of customer meal requests for the entire day, 
we need to find find the minimum number of times he has to clean the tables.</strong></p>

<p><strong>Example 1 :</strong> Let their are 2 tables that mean N=2 and their are 4 order that means M=4 and list showing the  order in which customers ask for meal is [1 2 3 4]</p>

<p>Then here answer is 4 </p>

<p><strong>Explanation :</strong> In the starting all tables i.e. 2 tables are unoccupied. 
When customer 1 asks for table, he can be given any of the 2 tables. 
John has to clean either of the table. Next customer 2 can occupy the other free table. John must clean second time. When customer 3 comes John can ask either customer 1 or 2 to leave. Suppose he asks customer 1 to leave. Then he has to clean table for the third time. When customer 4 comes, he can ask customer 2 or 3 to leave. In either case He will have to clean the table for the fourth time.</p>

<p><strong>Example 2:</strong> Let N=3 and M=5 and list be [1 2 1 3 4]</p>

<p>Then here answer will be 4.</p>

<p><strong>Explantion :</strong> Suppose the tables are listed as [-, -, -]. A possible optimal order of allocating tables can be [1, -, -] -> [1, 2, -] -> [1, 2, -] -> [1, 2, 3] -> [4, 2, 3]. So John will have to clean table for order no. 1, 2, 4 and 5. That is 4 times.</p>
",number_theory
"<p>Can sieve method prove ternary (three) prime Goldbach conjecture (Vinogradov Theorem) ?</p>

<p>I had done some research, I could not find any articles on this.
Can anyone provide some help on this ?</p>

<p>I assume that sieve method will be prove ternary (three) prime Goldbach conjecture (Vinogradov Theorem), because it can prove (1, 2) Chen's Theorem.</p>
",number_theory
"<p>I have given expression $(X+X^a+X^b+X^c+X^d+....)^k$ where $a$, $b$, $c$ ... and $k$ are whole numbers.</p>

<p>How we can find the $Z$ coefficient, i.e, $X^Z$ of the above term $1\le Z \le k$?</p>

<p>For Example $(X+X^3+X^5+X^8)^4$. How can I find the $X^{13}$ coefficient.</p>
",number_theory
"<p>The problem concerns covering the unit square with translates of a specific figure, which I will refer to as a ""cross"", using as few translates as possible. The difficulty seems to result from the fact that the figure is very concave.</p>

<p>To begin with, let $T^2$ be the unit square $[-1/2,1/2]^2$ with the opposite sides identified. Also, fix a parameter $\varepsilon &gt; 0$. Let us consider a ""cross"" $K$ defined as:
$$ K = \{(x,y) \in T^2 \ : \ |xy| &lt; \varepsilon \} $$
For reasonably small $\varepsilon$ this looks like the coordinate axes ""thickened"" somewhat. We are interested in the translates of $K$, with the convention that if a part of the translate $K$ ""sticks out"" of $T^2$ it gets ""wrapped around"" on the opposite side; thus $(x,y) \in K + (a,b)$ iff $(x,y) \equiv (x'+a,y'+b) \pmod{1}$ for some $(x',y') \in K$. The task is now to cover $T^2$ using as few crosses as possible. It is fairly obvious that the exact number cannot be found, so I am only asking for the asymptotics of this number for sufficiently small $\varepsilon$. </p>

<p>The obvious attempt is to find a suitable rectangle contained in a cross, and use these rectangles to cover the square. One can easily find rectangles of area $\Theta(\varepsilon)$ (i.e. $C \varepsilon$ for a universal constant), so one can cover the square with $\Theta(1/\varepsilon)$ crosses. The area of the largest convex figure that fits into a cross is $\Theta(\varepsilon)$, so this cannot be significantly improved without new insight.</p>

<p>On the other hand, the area of a cross is $\Theta(\varepsilon \log \frac{1}{\varepsilon})$. Thus, one needs at least $\Theta(1/\varepsilon \log \frac{1}{\varepsilon})$ crosses for a cover.</p>

<p>Unfortunately, the two bounds do not agree. Ideally, I would like to know (asymptotically) what's the least cardinality of a cover. More realistically, I would appreciate any argument showing that either of the bounds can be improved.</p>

<p><em>Motivation: The problem came up when I was considering recurrence rates of generalised polynomials. It is related to asking for an upper bound on the least positive integer $n$ so that $\left&lt; n \alpha \right&gt; \left&lt;n \beta \right&gt; \in (-\varepsilon,\varepsilon)$, where the brackets indicate the fractional part.</em></p>
",number_theory
"<p>Let $a, m$ be positive integers and $m &gt; 1$. I'm interested in the sequence $(a^k)_{k 
\in \mathbb{N_0}} \mod m$. Since there are only $m$ different values that can occur in the sequence and since $a^k = a \cdot a^{k-1}\ \ \forall k &gt; 0$ is only dependent on the previous element, I conclude that there exist $i, C \leq m$, such that $a^{k + C} = a^k\ \ \forall k \geq i$.</p>

<p>Example: $a = 2, m = 12$, we get the sequence $1, 2, 4, 8, 4, 8, 4, 8... \mod 12$ with $x = 2, C = 2$.</p>

<p>Given $a$ and $m$, I want to algorithmically find some $i$ and $C$ with the above property. I'm especially interested in the case where $gcd(a,m) \neq 1$, since otherwise a trivial solution is $i = 0, C = \phi(m)$ according to <a href=""http://en.wikipedia.org/wiki/Euler%27s_theorem"" rel=""nofollow"">Euler's theorem</a>, if I'm not mistaken. The obvious algorithm is naive in that it just evaluates the sequence element by element and stops as soon as it hits a duplicate. I'm sure we can do better than $O(m)$ exponentiations by using the Chinese Remainder Theorem and factorizing $m$ or something, but since I don't have a math background it's a bit hard for me to put my finger on it.</p>

<p>The ultimate goal is to evaluate ""exponential-tower""-type expressions of the form ${a_1}^{{a_2}^{a_3^{a_4^{\ldots}}}}$ modulo some prime $p$, as asked in <a href=""http://stackoverflow.com/questions/21367824/how-to-compute-an-exponential-tower-modulo-a-prime/21368784#21368784"">an algorithm question on Stack Overflow</a> I tried to contribute my two cents there by applying some observations, but I'm personally interested in this problem and pretty sure the algorithm can be improved if we can solve the particular problem of finding the cycle length faster.</p>

<p>If somebody has another general idea of solving the exponential-tower problem, that's very interesting as well and I'd love to hear it, but it's not the primary point of this question :)</p>
",number_theory
"<p>I am not sure if it's possible to get infinite prime numbers from this sum:
$$p=k^j+j^k$$
with $j\in\mathbb{N}, k\in\mathbb{N}$
I tried for $j=1,2,...9,k=1,2,...9$ and I get only eleven prime numbers.
If I consider the matrix:
$$A(k,j)=k^j+j^k$$
in which the components $A(j,k)=1$ iff $p$ is prime
this is a sparse matrix in which the prime numbers are mostly in the first four rows. Can someone give me some hint to prove $A$ contains infinite prime numbers in the limit $j\to \infty$, $k\to\infty$</p>
",number_theory
"<p><strong>Question</strong>- A lattice point $(x,y)\in\mathbb{Z}^2$ is called <em>visible</em> if $gcd(x,y)=1$. Prove that given a positive integer $n$, there exists a lattice point $(a,b)$ whose distance from every <em>visible</em> point is greater than $n$.</p>

<p>I am totally nowhere near progress on this. I was thinking of trying pigeon hole principle, but cant find any appropriate candidate pigeons. Please give any hints to start.</p>
",number_theory
"<p>I am reading the article <a href=""http://ac.els-cdn.com/S0022314X06002381/1-s2.0-S0022314X06002381-main.pdf?_tid=58e1dbf6-6492-11e6-964f-00000aacb35d&amp;acdnat=1471449220_0d78b1e8734f32b6dfb2fcea25dc7313"" rel=""nofollow"">On $L^{\infty}$ norms of holomorphic cusp forms</a>. I am particularly interested to the following :
<img src=""http://i.stack.imgur.com/ra62s.png"" alt=""Image""> 
I don't see how we can get from
$$ |y^k f(z)|     \ll \frac{y^k k^\epsilon(4\pi)^{k-1/2}}{\sqrt{\Gamma(2k)}(2\pi y)^{k-1/2}}\sum_{n\ge 1}(2\pi ny)^{k-1/2+\epsilon}e^{-2\pi ny}$$
that  : $|y^kf(z)|\ll k^{{1/4}+\epsilon}$ for $y\gg k.$</p>

<p>Can someone clarify to me it ?</p>
",number_theory
"<p>I'm trying solve: $~a^3 + b^3 = c^3~$ has no nonzero integer solutions.<br>
If $~(c−b)=1~$ then $~c^3-b^3=3c^2-3c+1=a^3,~$</p>

<p>from  <a href=""http://www.wolframalpha.com/"" rel=""nofollow"">Wolframalpha</a> get:</p>

<p>$$
c = \dfrac{3- \sqrt{3}\sqrt{4a^{3}-1}}{6} \\
c = \dfrac{\sqrt{3}\sqrt{4a^{3}-1}+3}{6}
$$
How to prove $~\sqrt{3}\sqrt{4a^{3}-1}~$ isn't an integer? (eidt: while $~a,\ b,\ c ~$ are nonzero integers)</p>
",number_theory
"<p>Is it true that for $n \in \mathbb{N}$ we can have $4n = x^{2} + y^{2}$ or $4n = x^{2} - y^{2}$ for $x,y \in \mathbb{N} \cup (0)$.</p>

<p>I was just working out a proof and this turns out to be true from $n=1$ to $n=20$. After that I didn't try, but I would like to see if a counter example exists for a greater value of $n$.</p>
",number_theory
"<p>solve $x^3 + 2y^3 + 3z^3 = 4xyz$ for $x,y,z \in \mathbb{Q}$</p>

<p>My main question is how to solve this in $\mathbb{Q}$, i know how to solve these kind of problems in $\mathbb{Z}$, where i usually look at modulo small primes, such as 3,5. But with $\mathbb{Q}$ i get totally confused, any smart methods i can use solving this?</p>

<p>Kees</p>
",number_theory
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://math.stackexchange.com/questions/169797/write-down-the-sum-of-sum-of-sum-of-digits-of-44444444"">Write down the sum of sum of  sum of digits of $4444^{4444}$</a>  </p>
</blockquote>



<p>If we write $ 4444^{4444}$ in decimal form .Then the sum of digits is equal to :$A$ .If we assume that: $B$ is the sum of digits :$A$ .How to find the sum of digits :$B$</p>
",number_theory
"<p>This is a pet idea of mine which I thought I'd share.  Fix a prime $q$ congruent to $1 \bmod 4$ and define a sequence $F_n$ by $F_0 = 0, F_1 = 1$, and</p>

<p>$\displaystyle F_{n+2} = F_{n+1} + \frac{q-1}{4} F_n.$</p>

<p>Then $F_n = \frac{\alpha^n - \beta^n}{\alpha - \beta}$ where $\alpha, \beta$ are the two roots of $f(x) = x^2 - x - \frac{q-1}{4}$.  When $q = 5$ we recover the ordinary Fibonacci numbers.  The discriminant of $f(x)$ is $q$, so it splits $\bmod p$ if and only if $q$ is a quadratic residue $\bmod p$.  </p>

<p>If $\left( \frac{q}{p} \right) = -1$, then the Frobenius morphism $x \mapsto x^p$ swaps $\alpha$ and $\beta$ (working over $\mathbb{F}_p$), hence $F_p \equiv -1 \bmod p$.  And if $\left( \frac{q}{p} \right) = 1$, then the Frobenius morphism fixes $\alpha$ and $\beta$, hence $F_p \equiv 1 \bmod p$.  In other words,</p>

<p>$\displaystyle F_p \equiv \left( \frac{q}{p} \right) \bmod p.$</p>

<p>Quadratic reciprocity in this case is equivalent to the statement that</p>

<p>$\displaystyle F_p \equiv \left( \frac{p}{q} \right) \bmod p.$</p>

<p><strong>Question:</strong>  Does anyone have any ideas about how to prove this directly, thereby proving quadratic reciprocity in the case that $q \equiv 1 \bmod 4$?</p>

<p>My pet approach is to think of $F_p$ as counting the number of ways to tile a row of length $p-1$ by tiles of size $1$ and $2$, where there is one type of tile of size $1$ and $\frac{q-1}{4}$ types of tiles of size $2$.  The problem is that I don't see, say, an obvious action of the cyclic group $\mathbb{Z}/p\mathbb{Z}$ on this set.  Any ideas?</p>
",number_theory
"<p>One version of Modularity Theorem says that </p>

<blockquote>
  <p>The elliptic curves with rational $j$-values arise from modular forms.</p>
</blockquote>

<p>Where </p>

<p>$$j(\tau)=1728\frac{g_2^3(\tau)}{\Delta(\tau)}$$</p>

<p>I know every terminology in the statement, but I don't know what ""arise from"" mean. Can anyone tell me?</p>
",number_theory
"<p>Polygonal numbers are of the form $\cfrac{n^2(s-2)-n(s-4)}{2}$, where $s$ is the number of sides of the polygon and $n$ is to say which one it is (the $n^{th}$ $s$-gonal number)</p>

<p>So my question is, how can you tell if a number is polygonal, and if it is, which $n,p$ plugged into the formula get you the number. Basically is there some kind of check if a number is polygonal?</p>
",number_theory
"<p>I need some help in proving </p>

<p>$$\left( \displaystyle\int_{0}^{\infty} t^{50} e^{-t} \,\mathrm dt \right)^{1/2}$$</p>

<p>isn't a perfect square. The only way I can think is repeated integration by parts which is obviously impractical and I still likely wouldn't be able to deduce if the result was a perfect square.</p>

<p>Thanks very much guys! :D </p>
",number_theory
"<p>For any natural number $n > 1$, define $E(n)$,to be the highest exponent to
which a prime divides it. For instance, $E(12)=E(36)=2$. Show that $$\lim_{N \to \infty} \frac{1}{N} \sum\limits_{n=2}^{N} E(n)$$ exists and find its value </p>
",number_theory
"<p>By mathematical induction, how would you show $\gcd(n,n+1)= 1$ for every integer $n$?</p>

<p>I'm thinking you would start by knowing that some integer, d, would divide both n and n+1. That's all I have so far. </p>
",number_theory
"<p>I am out of hints here. Its trivial to show $1$ is a solution. How to show it's the only solution?</p>

<p>Can someone please give me some hints?</p>

<p><em>Please do not use congruence, limits or derivatives because they are out of scope of the chapter which has this question.</em></p>
",number_theory
"<p>I understand that $\mathbb{Q}(x) \cong \mathbb{Q}(u)$ for all transcendental $u$, where $\mathbb{Q}(x)$ is the field of rational forms over $\mathbb{Q}$ and thus that all simple extensions of the rational numbers by transcendental ones are isomorphic to one another, but is it true, proven, that these extensions are not all $equal$ to each other? </p>

<p>I understand that that would be an incredible thing to prove, and could simplify many problems in transcendental number theory if true, so is it possible for it to be? $Could$ these extensions all equal each other? Or is that, easily or otherwise, proven to be an impossible task? I recall that transcendental numbers are uncountable, whereas I would assume that $\mathbb{Q}(x)$ is, though I have not enough knowledge of set theory to settle that in my mind.</p>
",number_theory
"<p>Give the postive integer $n&gt;1$, there exist infinite positive integer $k$
such that $\lfloor \dfrac{n^k}{k}\rfloor$ is odd </p>

<p>Maybe we can Use Euler's theorem,$$n^{\phi{(k)}}\equiv 1\pmod k$$
let
$$n^{\phi{(k)}}=rk+1\Longrightarrow n^k=\left(kr+1\right)^{\frac{k}{\phi{(k)}}}\Longrightarrow \dfrac{n^k}{k}=\dfrac{\left(kr+1\right)^{\frac{k}{\phi{(k)}}}}{k}$$I don't think this last part is relevant to understanding the exercise as stated, but I may be wrong. </p>
",number_theory
"<blockquote>
  <p>$(m_1,m_2)=1, a \equiv b \pmod {m_1} , a \equiv b \pmod {m_2} \Leftrightarrow a \equiv b \pmod {m_1 \cdot m_2}$</p>
</blockquote>

<p>The proof of the direction $"" \Rightarrow ""$ is the following:</p>

<p>$a \equiv b \pmod {m_1} , a \equiv b \pmod {m_2}$</p>

<p>Then $m_1 \mid a-b, m_2 \mid a-b$</p>

<p>So $[m_1, m_2] \mid a-b$</p>

<p>But $[m_1, m_2]=\frac{m_1 \cdot m_2}{(m_1, m_2)}=m_1 \cdot m_2$</p>

<p>So $m_1 \cdot m_2 \mid a-b$, so $a \equiv b \pmod {m_1 \cdot m_2}$</p>

<p>$$$$
Could you explain me how we conclude from $""m_1 \mid a-b, m_2 \mid a-b ""$ that $""[m_1, m_2] \mid a-b""$??</p>
",number_theory
"<p>I was just wondering why can't we use prime number's theorem to prove <a href=""http://en.wikipedia.org/wiki/Bertrand%27s_postulate"" rel=""nofollow"">Bertrand's postulate</a>.<br>We know that if we show that for all natural numbers $n&gt;2, \pi(2n)-\pi(n)&gt;0$ we are done. <br>Why can't it be proven by just showing (By using the prime number's theorem) that for every natural numbers $n&gt;2, \frac{2n}{ln(2n)}-\frac{n}{ln(n)}&gt;0$?</p>
",number_theory
"<p>Find a function $h_3(c)$ that will make
$$g_3 : \Bbb N × \Bbb N × \Bbb N → \Bbb N, \qquad (a, b, c) \mapsto 2^{a−1}3^{b−1}h_3(c)$$
a bijection. Your $h_3(c)$ should be an increasing function, i.e. $h_3(c_2) &gt; h_3(c_1)$ if $c_2 &gt; c_1$, and may have a multi-part definition, i.e. of the form
$$
h_3(c) =\cases{h_3'(c) &amp; if a certain condition is satisfied\\ h_3''(c) &amp; otherwise}
$$</p>
",number_theory
"<p>Is there any solution of the equation other than $x=2$?
Please help me. Thank you in advance.</p>
",number_theory
"<p>Solve for positive integers $x,y,z$</p>

<p>$$\frac{4}{13}=\frac{1}{x}+\frac{1}{y}+\frac{1}{z}$$</p>

<p>I tried to solve it by some generel work but it didn't help.</p>
",number_theory
"<p>Let $\sigma$ be the divisor sum function, $\gamma$ the Euler-Mascheroni constant and $n&gt;5040$. Robin showed that if the inequality$$\displaystyle \sigma(n)&lt;e^{\gamma}n\log\log n$$ ever fails, it does infinitely often. It is quite intuitive that infinitely many of the counterexamples (if not all) would be <a href=""http://en.wikipedia.org/wiki/Superabundant_number"" rel=""nofollow"">superabundant</a>, i.e. natural numbers $a$ such that $\displaystyle \frac{\sigma(a)}{a}&gt;\frac{\sigma(b)}{b}$ for all $b&lt;a$. 
My proof, which I'd like to have verified:</p>

<hr>

<p>Let $SA_k$ be the $k$-th superabundant number. Then assume, without loss of generality, </p>

<p>$$
\left\{ 
\begin{array}{c}
\sigma(SA_k)&lt;e^{\gamma}SA_k\log\log SA_k \\ 
\sigma(m)\ge e^{\gamma}m \log \log m \\ 
SA_l &lt; SA_k&lt;m&lt;SA_{k+1}
 \ , \end{array}
\right. 
$$
where $SA_l$ is the largest superabundant counterexample.
So we must have $$\displaystyle \frac{\sigma(m)}{\sigma(SA_k)}&gt;\frac{m \log\log m}{SA_k\log\log SA_k} \\ \ \ \ \ \ \ \frac{\sigma(m)}{m \log\log m} &gt;\frac{\sigma(SA_k)}{SA_k\log\log SA_k}. \ \ \ \ \ \  (1)$$
But since $m$ is between two consecutive superabundant numbers, it is not superabundant itself, hence it is by definition $\displaystyle \frac{\sigma(m)}{m}\le\frac{\sigma(SA_k)}{SA_k}$. Given that $ \log\log m &gt;\log\log SA_k$, we easily find $$\displaystyle \frac{\sigma(m)}{m \log\log m} &lt;\frac{\sigma(SA_k)}{SA_k\log\log SA_k},$$ contradicting $(1)$. As a result, we have no counterexamples $&gt; SA_l$, which is an absurdity. $ \ \ \ \ \ \ \ \ \ \  \square$</p>

<hr>

<p>Any comment, suggestion for improvement or alternative proof would be highly appreciated.</p>
",number_theory
"<p>Solve for $x,y,z\in\mathbb{N}$</p>

<p>$\frac{4}{13}=\frac{1}{x}+\frac{1}{y}+\frac{1}{z}$</p>

<p>I tried by some general methods but they didn't help me.</p>
",number_theory
"<p>Let $g(n)=\displaystyle{\sum_{p^{\alpha}||n}} \alpha p,$ where $p^{\alpha}||n$ means that $p^{\alpha}|n$ and $p^{\alpha+1}$ does not divide $n.$ Can someone provide me with a non trivial estimate of this function or even an upper bound is sufficient for me?</p>

<p>Thanks in advance.</p>
",number_theory
"<p>Is the following theorem well known?</p>

<p>Theorem
Odd positive integer N is a prime number if and only if there is no non-trivial solution for Diophantine equation</p>

<p>$x^2−y^2=N$</p>

<p>(trivial solution: $x=(N+1)/2; y=(N−1)/2)$</p>
",number_theory
"<p>If i have a large number (&lt;=10^5 Digits) how can i tell that if i can shuffle the number so that it become a multiple of 30 . if it is possible then i have to find the maximum multiple . Suppose if i have this number 
  97980 
if i make any combination of this number , all the combinations will be divisible by 30 , but the maximum one is 99870 . How can i shuffle this very large number and know whether it is possible or not ?</p>
",number_theory
"<p>I have the following assignment:</p>

<p>consider the map </p>

<p>$$|\cdot|:\mathbb{Z}[i]\longrightarrow \mathbb{N},\qquad |a+ib|:=a^2+b^2$$</p>

<p>1) Prove that $|\alpha|&lt;|\beta|$ iff $|\alpha|\leq |\beta|-1$ and $|\alpha|&lt;1$ iff $\alpha=0$</p>

<p>2) Let $\alpha,\beta\in\mathbb{Z}[i],\beta\neq 0$. Prove that the map $f:\mathbb{Z}[i]\longrightarrow\mathbb{Z}[i], f(\gamma):=\alpha-\gamma\beta$ is the composition of a dilatation by the factor $\sqrt{|\beta|}$, a rotation (angle?) and a translation.</p>

<p>3) Deduce that there exists $\gamma\in\mathbb{Z}[i]$ such that $|f(\gamma)|$ is strictly smaller than $|\beta|$.</p>

<p>$\textbf{Hint:}$ compare the size of a cell of the lattice $f(\mathbb{Z}[i])$ and the size of the set of points whose distance to $0$ is $\leq\sqrt{|\beta|}$.</p>

<p>What i did: point 1) is a trivial consequence of the fact that the norm takes integer non negative values. For point 2), I use complex multiplication of numbers which is: multiply absolute values and add angles. For point 3), i'm actually waiting for a miracle... I suppose i should prove that there exists a cell in $f(\mathbb{Z}[i])$ intersecting the open ball centered at the origin with radius $\sqrt{|\beta|}$, but i have no idea how to write down this. Only thing i noticed is that $f$ acts with a rotation, which does not affect distance from the origin, so that the only changes in $|\gamma|$ come from dilatation and by adding $\alpha$.</p>

<p>Could someone put me on the right direction?</p>
",number_theory
"<p>Given coprime $a,b$ and $n\in\Bbb N$, is there a simple criterion to find if there is <strong>no</strong> positive integer solution to
$$ax+by=n?$$</p>
",number_theory
"<p>I'm wondering, if it is true that the torsion subgroup of $y^2=x^3+p$ (for $p$ some prime, greater than 2), is always trivial?.</p>

<p>I was trying to prove this using Lutz-Nagell, but I can't quite get it.</p>

<p>Thank you</p>
",number_theory
"<p>In the <strong>Wikipedia</strong> article for the <a href=""https://en.wikipedia.org/wiki/Digamma_function"" rel=""nofollow"">Digamma function</a> one finds some identities due to <strong>Gauss.</strong> I've used the fourth of those from the section <strong>Some finite sums involving the digamma function</strong> to show if there were no mistakes that for $m&gt;1$ </p>

<p>$$\sum_{\substack{1\leq k\leq m-1 \\ (k,m)=1}}\sum_{r=1}^{m-1}\psi\left(\frac{r}{m}\right)\sin\left(\frac{2\pi r k}{m}\right)=\pi\frac{m\phi(m)}{2}-\pi\frac{m\phi(m)}{2}=0,$$</p>

<p>where $\phi(m)$ is the <strong>Euler's totient</strong> function and as you see in the reference $\psi(s)$ is the <strong>digamma function</strong>.</p>

<p>My approach was use Apostol's Exercise 14 with $f(x)=x$, from Chapter 2 of <strong>Apostol</strong>, Introduction to Analytic Number Theory, <strong>Springer</strong> (1976), also I need that $\sum_{\substack{1\leq k\leq m-1 \\ (k,n)=1}}k=\frac{n}{2}\phi(n)+\frac{n}{2}\sum_{d\mid n}\mu(d)=\frac{n}{2}\phi(n)+\frac{n}{2}$, on assumption that $n&gt;1$. Also the <strong>Gauss</strong> identity for the sum of the first $n$ positive integers.</p>

<blockquote>
  <p><strong>Question 1.</strong> Can you say if my statement (the first identity of current post) was right? <strong>Thanks.</strong></p>
</blockquote>

<p>After I tried the same with the other identity that is feasible do this calculations, that is the third, also due to Gauss. My calculations were $$\sum_{\substack{1\leq k\leq m-1 \\ (k,m)=1}}\sum_{r=1}^{m-1}\psi\left(\frac{r}{m}\right)\cos\left(\frac{2\pi r k}{m}\right)=m\phi(m)\log 2+m\cdot\log\left(\prod_{\substack{1\leq k\leq m-1 \\ (k,m)=1}}\sin \frac{k\pi}{m}\right)+\gamma\phi(m).$$</p>

<p><strong>There was a typo, fixed.</strong></p>

<blockquote>
  <p><strong>Question.</strong> Is there a <em>nice</em> closed-form for the factor $$\prod_{\substack{1\leq k\leq m-1 \\ (k,m)=1}}\sin \frac{k\pi}{m}$$ in the context of this post (I say nice/good in the context of the first question)? <strong>Thanks in advance.</strong></p>
</blockquote>
",number_theory
"<p>Given, $p$ is a prime number and $p&gt;3$. How do we prove that the remainder $r$ is always $1$ if $p^2$ is divided by $12$?</p>
",number_theory
"<p>Dirichlet's simultaneous approximation theorem says:</p>

<p>Given any $n$ real numbers $\alpha_1,\ldots,\alpha_n$ and for every natural number $N \in \mathbb{N}$, there exist integers $q \leq N$, and  $p_1,\ldots,p_n \in \mathbb{Z}$, such that:</p>

<p>$$ \Bigg|\alpha_i - \frac{p_i}{q}\Bigg| &lt; \frac{1}{qN^{1/n}} \text{    for } i=1,\ldots,n $$</p>

<p>I would like to prove a similar theorem, but want to insist that the $p_i$ all be odd.  It's easy to prove a version which has all the $p_i$ even, because the set of points in $\mathbb{R}^n$ with even coordinates is a lattice.  </p>

<p>The general version of Minkowski's Theorem say that a symmetric region containing the origin, if it's volume is sufficiently large, must contain a nonzero lattice point.  But the set of points with odd coefficients is only a coset of the lattice of points with even coefficients.</p>

<p>This seems obviously true that one should be able to replace ""lattice"" with ""coset of the lattice"" in Minkowski's Theorem, but I sure don't see how to do it.  I can get the result I want in one dimension by modifying the continued fraction construction, but that doesn't export to $n$ dimensions.  References and insights welcome.</p>
",number_theory
"<p>Although I am very much new to ""Analytic Number Theory"", there are some non mathematical questions which puzzle me. First of all, why was <strong>G.H.Hardy</strong> so much keen to have an elementary proof of the <strong>Prime Number Theorem</strong>. He also stated that producing such a proof, will change the complexion of Mathematics, but nothing like that has happened. What was on Hardy's mind? </p>

<p>The elementary proof although has some intricate tricks involved, I am curious to know whether the methodology can be applied for attacking more complex problems. I have seen that the analytic proof has a continuation and is not over and discuss some more interesting properties regarding the $\zeta$ function. </p>

<p>I also saw <a href=""http://mathoverflow.net/questions/16735/is-a-non-analytic-proof-of-dirichlets-theorem-on-primes-known-or-possible"">this thread</a>. Are there any such theorem's which piques peoples curiosity in getting an elementary proof. (While writing this FLT comes to my mind!!).</p>
",number_theory
"<p>Is there an extant published expository account, comprehensible to all mathematicians, of the conceptual differences between ancient Greek mathematical concepts and modern ones?</p>

<p>I have in mind things like this:</p>

<ul>
<li>Euclid (I'll need to look between the covers of a book to be sure whether this is right&nbsp;.&nbsp;.&nbsp;.&nbsp;.) didn't know how to multiply more than three numbers because no more than three lines can be mutually orthogonal; but he did know how to find the smallest number measured by more than three numbers (what today we would call the LCM);</li>
<li>Consequently (?) he didn't know about factoring numbers into primes (for example, $90= 2\cdot3\cdot3\cdot5$ is not the LCM of its prime factors) (and that's why he stopped short of stating, let alone proving, the uniqueness of prime factorizations), but of course they did know that every number is ""measured by"" at least one prime number;</li>
<li>(Maybe?) Euclid did not consider $1$ to be a number;</li>
<li>The ancient Greeks had no concept of real number.  They had a concept of congruence of line segments, so that they could say that one line segment goes into another between $6$ and $7$ times, and the remainder goes into the shorter segment between $2$ and $3$ times, etc. etc., so they knew what it meant to say the ratio of the length of segment A to that of segment B is the same as the ratio of the length of segment C to segment D.  They even knew what it means to say the ratio of lengths A to B is the same as the ratio of areas E to F, and similarly volumes.  But they did not make the mistake of knowing whether a particular area is less than a particular length.  Modern mathematicians seem to make that mistake by saying those are real numbers; I think modern physicists may avoid that error.</li>
<li>They did not have a concept of irrational number (since they didn't have a concept of real number), but they knew what it meant to say that two line segments <b>have no common measure</b>, and how to prove it in some cases (e.g. no segment can be laid end-to-end some number (=&nbsp;cardinality) of times to make the length of the side of a square and some other number of times to make the diagonal).</li>
</ul>
",number_theory
"<p>Suppose $H$ is an automorphic L-function obtained by applying the Rankin-Selberg convolution to two automorphic L-functions $F$ and $G$ each of them being different from the Riemann Zeta function. Is the set $\{F,G\}$ entirely determined by $H$?</p>
",number_theory
"<p>Question as in title, where $L(s,\chi)$ is the Dirichlet $L$-function associated with the nontrivial character modulo $3$. Please provide complete SAGE code. Thank you in advance.</p>
",number_theory
"<p>Square of an irrational number can be a rational number e.g. $\sqrt{2}$ is irrational but its square is 2 which is rational.</p>

<p>But is there a irrational number square root of which is a rational number?</p>

<p>Is it safe to assume, in general, that $n^{th}$-root of irrational will always give irrational numbers?</p>
",number_theory
"<p>A bijection
$g_4 : \mathbb N\times \mathbb N \times\mathbb N \times\mathbb N \to\mathbb N$, with $$(a, b, c, d) \mapsto 2^{a−1}3^{b−1}5^{c−1}h_4(d)$$
is constructed, with $h_4(d)$ as an increasing function. Find the values of $a, b, c, d$ such that</p>

<p>(i) $g_4(a, b, c, d) = 7236$</p>

<p>ii) $g_4(a, b, c, d) = 833$</p>
",number_theory
"<p>In a related <a href=""http://math.stackexchange.com/questions/2571/about-powers-of-irrational-numbers"">question</a> we discussed raising numbers to powers.  </p>

<p>I am interested if anybody knows any results for raising numbers to irrational powers.  </p>

<p>For instance, we can easily show that there exists an irrational number raised to an irrational power such that the result is a rational number. Observe ${\sqrt 2 ^ {\sqrt 2}}$. Since we do not know if ${\sqrt 2 ^ {\sqrt 2}}$ is rational or not, there are two cases.  </p>

<ol>
<li><p>${\sqrt 2 ^ {\sqrt 2}}$ is rational, and we are finished.  </p></li>
<li><p>${\sqrt 2 ^ {\sqrt 2}}$ is irrational, but if we raise it by ${\sqrt 2}$ again, we can see that
$$\left ( \sqrt 2 ^ \sqrt 2 \right ) ^ \sqrt 2 = \sqrt 2 ^ {\sqrt 2 \cdot \sqrt 2} = \sqrt 2 ^ 2 = 2.$$</p></li>
</ol>

<p>Either way, we have shown that there exists an irrational number raised to an irrational power such that the result is rational.</p>

<p>Can more be said about raising irrational numbers to irrational powers?  </p>
",number_theory
"<p>Let $\mathbb{P}$ denote the set of prime numbers. How would one evaluate
$$\prod_{p\in \mathbb{P}}\frac{p-1}{p}$$ I do not think that the fact that $$\prod_{n=2}^{\infty}\frac{n-1}{n}=\lim_{n\to\infty}\frac{1}{n}=0$$ can be applied, but it is worth noting. Additionally, if we take the log, we obtain
$$\log\left(\prod_{p\in \mathbb{P}}\frac{p-1}{p}\right)=\sum_{p\in\mathbb{P}}\log\left(\frac{p-1}{p}\right)=\sum_{p\in\mathbb{P}}\log(p-1)-\sum_{p\in\mathbb{P}}\log(p)$$</p>
",number_theory
"<p>Find $x \in \mathbb{Z}[i]$ such that:</p>

<p>$(1+2i)x \equiv 1 \mod 3+3i$</p>

<p>How would you go about doing this? Best I can think of is keep guessing....</p>
",number_theory
"<p>I have trouble in understanding Weil paring on $N$-torsion points on an elliptic curve. Please see <a href=""http://en.wikipedia.org/wiki/Weil_pairing"" rel=""nofollow"">Wikipedia</a> for the definition of Weil paring. I would like to know what Weil paring is  computing intuitively. I would also want to see some basic computation. </p>

<p>I will really appreciate your help. </p>
",number_theory
"<p>(This is different than <a href=""http://math.stackexchange.com/questions/50791/if-xm-e-has-at-most-m-solutions-for-any-m-in-mathbbn-then-g-is-cycl"">If $x^m=e$ has at most $m$ solutions for any $m\in \mathbb{N}$, then $G$ is cyclic</a>)
<br/>I was trying to solve this:</p>

<blockquote>
  <p>Let $G$ be a finite abelian group of order $n$ for which the number of solutions of $x^m=e$ is at most $m$ for any $m$ dividing $n$. Prove that $G$ must be cyclic. [Hint:Let $\psi (m)$ be the number of elements in $G$ of order $m$. Show that $\psi (m)\leq \phi (m)$, and use $n=\Sigma_{m\mid n}\phi (m) $] </p>
</blockquote>

<p>What I have proven is that $\Sigma_{d|n}(ψ(d)−ϕ(d))=0$, then if the statement in the hint holds, ψ(d)=ϕ(d) for every d|n. n divides itself, therefore, $\psi (n)=ϕ(n)≠0$. Therefore G admits a generator, and we'll be done.The problem is to prove the statement in the hint. Yet I have conluded a different seemingly contradictory result, which doesn't help solve the problem at all, since it could be that $ψ(n)=0,ψ(n)−ψ(d)&lt;0$ and $ψ(d)−ϕ(d)&gt;0$ for some $d≠n$. Of course I don't know how to show that $\psi (m)\leq \phi (m)$, and here is how I got this contradiction:
<br/>If $\psi (m)\neq 0$, then let $m\neq 1,m\mid n$. Consider an element $a\in G,|a|=m$. Within its cyclic group, there will be $\phi (m)$ elements with order $m$ since any element $a^i$ in it is a generator if and only if $\gcd(m,i)=1$. Therefore $\psi(m) \geq \phi (m)$ since some element out side the cyclic group may have order $m$ too.
<br/>If this reasoning is correct, I think it will contradict with the fact in the hint which is $\phi(m) \geq \phi(m)$. The number of solutions is $\Sigma_{d|m}\psi (d)$, which is always greater than $\psi (m)$. So no matter how great $\psi (m)$ is, or how $\psi (m) &gt;\phi (m)$, the number of solution may still be less than $m$. What's going wrong? How to prove the statment in the hint? Help me please. Also I have read through <a href=""http://math.stackexchange.com/questions/50791/if-xm-e-has-at-most-m-solutions-for-any-m-in-mathbbn-then-g-is-cycl"">If $x^m=e$ has at most $m$ solutions for any $m\in \mathbb{N}$, then $G$ is cyclic</a>, but for the accepted answer, it doesn't show how to prove the fact in the hint, and other answers do not use the fact in the hint.</p>
",number_theory
"<p>Let a, n be positive integers. Prove that n divides $\phi(a^n-1)$, where $\phi$ is Euler's $\phi$-function.</p>

<p>I know this problem can be done using number theory approaches, however I am rusty on those concepts can someone help me? </p>
",number_theory
"<p>I am <a href=""https://github.com/gazman-sdk/quadratic-sieve"" rel=""nofollow"">implementing</a> the <a href=""https://en.wikipedia.org/wiki/Quadratic_sieve"" rel=""nofollow"">quadratic sieve</a> algorithm. And I got run in unexpected problem.</p>

<p>Take a look at those two final steps of the algorithm as described in wiki.</p>

<blockquote>
  <ol start=""4"">
  <li>Use linear algebra to find a subset of these vectors which add to the zero vector. Multiply the corresponding $a_i$ together naming the
  result mod $n$: a and the $b_i$ together which yields a B-smooth square $b^2$.</li>
  <li>We are now left with the equality $a^2=b^2$ mod $n$ from which we get two square roots of ($a^2$ mod $n$), one by taking the square root in the
  integers of $b^2$ namely $b$, and the other the $a$ computed in step 4.</li>
  </ol>
</blockquote>

<p>In my case I found more than $100$ vectors with the size of $30+$ digits each, when multiplying them I get a number that got too many digits, so squaring it becomes a problem, it takes more time than solving the matrix itself(I use the <a href=""https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Babylonian_method"" rel=""nofollow"">babylon method</a> for squaring).</p>

<p>Is there a way to avoid creating such big numbers?</p>
",number_theory
"<p>So I think I understand how to calculate something like $(208\cdot 2^{-1})\mod 421$ using extended euclidean algorithm. But how would you calculate something like $(208\cdot2^{-21})\mod 421$? </p>

<p>Thanks, this is basically for my cryptography class; I'm just trying to understand the ""big step, baby step"" algorithm.</p>
",number_theory
"<blockquote>
  <p>Is there a (number theoretic or algebraic) trick to find a large
  nunber modulo some number?</p>
</blockquote>

<p>Say I have the number $123456789123$ and I want to find its value modulo some other number, say, $17$.</p>

<p>It's not fast for me to find the prime factorisation first. It's also not fast to check how many multiples of $17$ I can ""fit"" into the large number. </p>

<p>So I was wondering if there is any method out there to do this efficiently. </p>

<blockquote>
  <p>I am looking for something like the other ""magic trick"" where you sum
  all the digits and take the result $\mod 9$. </p>
</blockquote>
",number_theory
"<p>I'll try to format my question in a manner such that you can skip (irrelevant) parts.</p>

<p><strong>Exercise:</strong></p>

<blockquote>
  <p>Find all natural $n$ such that $3^{2n+1}-4^{n+1}+6^n$ is prime.</p>
</blockquote>

<p><strong>Motivation:</strong></p>

<p>I'm trying to prepare talented elementary school children for mathematics competition and the question from the title popped up somewhere as suggested for the purpose (explicitly stating this should be number theory exercise for elementary school). Now, this immediately rang some alarms, as powers are learned in grade 8 (final grade before high school), when they certainly don't know any modular arithmetic or induction, let alone more advanced number theory. I tried to solve it anyway to see if this could actually be used, but to my surprise, I couldn't. Obviously, when $n=1$ we get $17$, which is prime, but for $n&gt;1$ it seems that it will never be prime again, although I fail to show it (computer says that the expression is never prime in range $n\in[2, 100000000]$). There is, of course, possibility of a typo in question, but computer check up makes me believe that this is ""legit"" question.</p>

<p><strong>My work:</strong></p>

<p>First of all, for $n=1$ we have $3^{2n+1}-4^{n+1}+6^n = 17$ which is prime.</p>

<p>Secondly, it is easy enough to check that for $n = 2k,\ k\in\mathbb N$ we have $5\mid 3^{2n+1}-4^{n+1}+6^n$.</p>

<p>This looked promising, but for $n = 5$, we get $3^{2n+1}-4^{n+1}+6^n = 211\cdot 857$ as prime decomposition which is definitely worrisome.</p>

<p>I tried to find some appropriate $d\in\mathbb N$ such that $n = qd + r$ to build some casework with respect to $r$, but had no luck.</p>

<p>What I did notice is that if you pick $n$ in some non-trivial ideal $(d)$, there is at least one prime $p_d$ such that $p_d\mid 3^{2n+1}-4^{n+1}+6^n$, for all $n\in (d)$. </p>

<p><em>(though, I proved this only for $d=2$, for $d&gt;2$ this is but a computer inspired conjecture)</em></p>

<p>Here is a table:</p>

<p>\begin{array}{c | c}
d &amp; p_d \\ \hline
2 &amp; 5 \\
3 &amp; 19 \\
4 &amp; 5, 13 \\
5 &amp; 211 \\
6 &amp; 5, 7, 19 \\
7 &amp; 29, 71 \\
8 &amp; 5, 13, 97 \\
9 &amp; 19, 1009 \\
10 &amp; 5, 11, 211\\
\end{array}</p>

<p>Another attempt was obviously to try to factor $3^{2n+1}-4^{n+1}+6^n$ directly. Some obvious attempts led me to believe this approach might fail too. Indeed, polynomials $$x^{2n+1} - y^{2n+2} + x^ny^n,$$ $$x^{2n+1} - (x-1)^{2n+2} + x^n(x-1)^n$$ and $$x^{2n+1} - (x+1)^{n+1} + x^n(x-1)^n$$ are irreducible over $\mathbb Q$.</p>

<p>This leaves me without ideas. Any help would be much appreciated.</p>
",number_theory
"<p>Following a previous <a href=""http://math.stackexchange.com/questions/680122/cram%C3%A9rs-model-the-prime-numbers-and-their-distribution-part-1"">question</a> (here you'll find an introduction):</p>

<p>The book states that using the convergence of the binomial distribution towards the Poisson distribution, it's easy to show that $$|\{x\le\xi:\pi_S(x+\lambda \log x)-\pi_S(x)=k\}|\sim\xi\mathrm e^{-\lambda} \frac{\lambda^k}{k!}\quad(\xi\to\infty)$$ holds almost surely.</p>

<p>I couldn't prove this.</p>
",number_theory
"<blockquote>
  <p>Let $x,y$ be integers and $y$ be a (nonzero) quadratic residue modulo $p$ ($p$ is a prime). Prove that $xy$ is a quadratic residue modulo $p$ if and only if $x$ is a quadratic residue modulo $p$. </p>
</blockquote>

<p>If $x$ is a quadratic residue modulo $p$, then the result is trivial. How do we prove the other direction?</p>
",number_theory
"<p>Following a previous <a href=""http://math.stackexchange.com/questions/884932/cram%C3%A9rs-model-the-prime-numbers-and-their-distribution-part-3"">question</a> (<a href=""http://math.stackexchange.com/questions/680122/cram%C3%A9rs-model-the-prime-numbers-and-their-distribution-part-1"">here</a> you'll find an introduction):</p>

<p><a href=""http://projecteuclid.org/download/pdf_1/euclid.mmj/1029003189"" rel=""nofollow"">A paper by Maier</a> which refutes Cramer's Model suggests we should replace the heuristic ""$\Bbb P(n\in\mathcal P)=1/\log n$"" with $$\Bbb P(n\in\mathcal P|P^-(n)\gt z)=\frac{1}{\log n}\prod_{p\le z}_{p\in\mathcal P}(1-1/p)^{-1}\quad (z\approx \log n)$$ where $P^{-}(n)$ denotes the least prime number that divides n.
The book states that the new heuristic leads us to expects that the strong Cramér's conjecture $$\limsup_{n\to\infty}\frac{p_{n+1}-p_n}{(\log p_n)^2}=1$$ (which is derived in <a href=""http://matwbn.icm.edu.pl/ksiazki/aa/aa2/aa212.pdf"" rel=""nofollow"">this paper by Cramer</a>) is false and should be replaced by $$\limsup_{n\to\infty}\frac{p_{n+1}-p_n}{(\log p_n)^2}=2\mathrm e^{-\gamma}$$ where $p_n$ denotes the $n^{th}$ prime number, and $\gamma$ denotes Euler's constant.
For proving this last implication, I should mention Mertens' formula: $$\prod_{p\le z}_{p\in\mathcal P}(1-1/p)^{-1}=\mathrm e^\gamma\log z+O(1)\quad(z\ge 1)$$</p>

<p>I couldn't prove this.</p>
",number_theory
"<p>Greetings to one an all!</p>

<p>How can we prove the curve ""$x^2 -x = y^5-y$"" is a hyperelliptic curve?</p>

<p>Is a hyperelliptic curve the same as a hyperbolic elliptic curve or are there any differences?</p>
",number_theory
"<p>Following a previous <a href=""http://math.stackexchange.com/questions/884902/cram%C3%A9rs-model-the-prime-numbers-and-their-distribution-part-2"">question</a> (<a href=""http://math.stackexchange.com/questions/680122/cram%C3%A9rs-model-the-prime-numbers-and-their-distribution-part-1"">here</a> you'll find an introduction):</p>

<p>The book states that almost surely $$\pi_S(x+y)-\pi_S(x)=\mathrm{li}(x+y)-\mathrm{li}(x)+O(\sqrt y)$$ as soon as $y/(\log x)^2\to\infty$, with $y\le x$.</p>

<p>I couldn't prove this.</p>
",number_theory
"<p>Let $a,b,c$ and $d$ be rational.Find a rational parametric solutions for $a,b,c$ and $d$ so that 
$$(4/3)b^2c^2+(4/3)a^2d^2-(1/3)a^2c^2-(4/3)b^2d^2=\square.$$</p>
",number_theory
"<p>Does any one know how to prove the following identity?
$$
\mathop{\mathrm{Tr}}\left(\prod_{j=0}^{n-1}\begin{pmatrix}  
2\cos\frac{2j\pi}{n} &amp; a \\
b &amp; 0
\end{pmatrix}\right)=2
$$
when $n$ is odd. The product sign means usual matrix multiplication, and $a$ and $b$ are arbitrary real numbers.</p>

<p>Since the product of $2\cos\frac{2j\pi}{n}$ is $2$, so we only need to prove that the trace is a constant polynomial in $a$ and $b$.</p>

<p>Because of the cosine term, the approach of polynomial analysis used in <a href=""http://mathoverflow.net/questions/213246/product-of-a-finite-number-of-matrices-related-to-roots-of-unity"">my previous post</a> does not seem to work here.</p>
",number_theory
"<p>Let's say you have a 20 sided dice and every side is considered bad, but each time you roll a bad side it will no longer be bad for future rolls. 
I am looking for the mathmatical term for the scale of increase on the expected amount of times you will be able to roll success as bad sides are removed </p>
",probability
"<blockquote>
  <p>Let $X\sim\mathcal N(μ_1,σ_1^2)$ and $Y\sim\mathcal N(μ_2,σ_2^2)$ and $\mathsf{Cov}(X,Y)=c$ How can we compute $\mathsf {Cov}(X^2,Y^2)$?</p>
</blockquote>

<p>I think the answer should be something like $c^2$ and I think the joint PDF is really not necessary here. I think the approach is using some independent standard normal random variables by variable changing. But I can't make it out. </p>

<p>Thanks.</p>
",probability
"<p>How can one determine the probability function $f(x)$ given a situation and no equations? I am unsure if there is a special method or if you should just plug in values and look for a pattern.</p>

<p>For example, if you draw 2 numbers from 0 through 9 without replacement, and $X=$ {total of the 2 numbers}, then how could you determine $f(x)$? I came up with the sample space $|S|= {10 \choose 2}$, and found probabilities for X = 1,2,3, ... etc. </p>

<p>I got $\frac{1}{10 \choose 2}$ for $X=1$ and $X=2$ and then the numerator increases by 1 for $X=3,4$, increases again by one for 4 and 5, and then values are repeated in pairs like that if I have done this correctly. My confusion is how to determine a formula now. Can it even be done?</p>
",probability
"<p>Problem statement: Suppose we have a random sample $\{X_i:1\le i\le10\}$ from a normal distribution with mean $\mu=20$ and variance $\sigma^2=100$. Find the probability,
$$P\left(\sum_{i=1}^6X_i&gt;X_7+2X_8+2X_9+X_{10}+16\right)$$
My initial thoughts: For any $X_i$, we know the MGF is $M_{X_i}(t)=20t+50t^2$. I defined a new random variable $Y$ denoted by the linear combination in which every term in the inequality is on one side, i.e.
$$Y=X_1+\cdots+X_6-X_7\cdots-X_{10}-16$$
so that now the problem is finding $P(Y&gt;0)$. I find that the MGF of $Y$ is
$$M_Y(t)=e^{-16t}\left(20t+50t^2\right)^6\left(-20t+50t^2\right)^2\left(-40t+200t^2\right)^2$$
Is this making the problem more difficult than it needs to be? I don't think this looks like the MGF of a distribution I might be familiar with.</p>
",probability
"<p><img src=""http://i.stack.imgur.com/HqML7.png"" alt=""enter image description here""></p>

<p>im on the last part and my attempt was to:</p>

<p>find $P(|\bar{X_n} - \mu| &lt; 0.01) &gt; 0.99$ but in the solutions showed the equation is $P(|\bar{X_n} - \mu|/\mu &lt; 0.01 ) &gt; 0.99$ why do we have to divide through my $\mu$?</p>
",probability
"<p>Motivation: A friend asked me this question.</p>

<p>The Problem: Suppose you start off with a dollar. You flip a fair coin, if it lands on heads you win $50$ cents otherwise you lose $50$ cents. If after $n$ flips you have a nonzero amount of money, you win. What's the probability you win? What about the limiting case as $n$ tends to infinity?</p>

<p>edit: In this game you are not allowed to have negative money. Thanks, Jonathan Fischoff, the linked helped greatly.</p>
",probability
"<p>Imagine a process with two variables <em>min</em> and <em>max</em>, and two counters <em>hi</em> and <em>lo</em>.</p>

<p>We initialize <em>min</em> and <em>max</em> by selecting two random numbers (assume a uniform (0,1) distribution for convenience), and sorting them.  We also set the <em>hi</em> and <em>lo</em> counters to 0.</p>

<p>At each step we select a new random number <em>r</em> from our distribution and do the following</p>

<pre><code>if (r &lt; min) {
  lo++;
} else if (r &gt; max) {
  hi++;
} else if (lo &gt; hi) {
  max = r;
  hi++;
} else if (hi &gt; lo) {
  min = r;
  lo++;
} else {
  if (rand(0,1) &gt; 0.5 ){
    max = r;
    hi++;
  } else {
    min = r;
    lo++;
  }
}
</code></pre>

<p>If the random number is outside our range, we increment the appropriate counter, and if it lies inside our range we increment the lower counter and adjust our range appropriately.  The question is, after <em>n</em> iterations, where do we expect min and max to end up.</p>

<p>It can be seen that the difference between min and max (assuming a uniform(0, 1) distribution) is distributed as the minimum of <em>n + 2</em> uniform (0, 1) random variables.  However, it should be possible to say considerably more about the location of <em>min</em> and <em>max</em> over time.</p>

<p><strong>Edit</strong>  This algorithm is only vaguely related to median finding.  The process given here just takes a sequence of unifomly distributed random numbers and attempts to guess the median by remembering only two values.  This, of course is not an effective method, but similar algorithms are used (remembering more than two variables).</p>

<p>The process that I want to analyze has two values and two counters, and takes a sequence of random numbers, if the random number is larger than both, then increase the <em>hi</em> counter, if the number is smaller than both then increase the <em>lo</em> counter, and if the number lies between the two, either replace <em>max</em> with the current number and increase <em>hi</em> or else replace <em>min</em> with the current number and increase <em>lo</em>, whichever makes the <em>hi</em> or <em>lo</em> counters closer (in cases where either choice could be made, flip a coin).  <em>hi</em> and <em>lo</em> are counting the numbers that we have seen that are larger than <em>max</em> or smaller that <em>min</em> respectively.</p>

<p>What I want to know, is how to figure out the distribution of <em>min</em> and <em>max</em> as the number of iterations becomes large, also of interest is the distribution of <em>hi - lo</em>.  I can find the distribution of <em>max - min</em> using elementary order statistics.</p>

<p>If <em>min = max</em>, then <em>hi - lo</em> is an ordinary one dimensional random walk, and is easy to analyze.  When they are different the walk is subtly biased towards 0.  Similarly the values of <em>min</em> and <em>max</em> are biased towards 0.5, I want to know how to find out by how much they are biased.</p>
",probability
"<p>Let $X_n $ be uniformly distributed on $[0,1]$. We say $X_k$ is a local maximum if $X_k&gt; X_{k\pm 1}$. Let $A_n$ count the number of local maxima of the sequence unto and including $n$. Find $a_n, b_n$ such that </p>

<p>$$\frac{A_n-a_n}{b_n} \longrightarrow N(0,1)$$</p>

<p>If someone could give a hint on how to approach this problem that would be great. I understand that I will need to use the Lindberg central limit theorem at some point to show the convergence. </p>
",probability
"<p>Given two random integers $a$, $b$ calculate probability of $a^2$ + $b^2$ is divisible by $10$.</p>

<p>I've tried to simulate this process and got a result about $0.18$ (maybe incorrect), but have no idea why.</p>
",probability
"<p>If the stars are distributed randomly within the universe, what is the probability for a star to be the nearest neighbor of a star that is its nearest neighbor? What if the number of spatial dimensions is higher than 3 or even grows without limit? </p>

<p>PS. I am interested in the asymptotic behavior with the number of stars growing without bound.</p>

<p>PPS. It's a well-known problem (the ""birds on a wire problem"" in higher dimensions) and I know the answers. However, no idea how to solve this analytically.</p>
",probability
"<p>Vince buys a box of candy that consists of six chocolate pieces, four fruit pieces and two mint pieces.  He selects three pieces of candy at random without replacement.</p>

<blockquote>
  <ol>
  <li><p>Calculate the probability that the first piece selected will be fruit flavored and the other two will be mint.</p></li>
  <li><p>Calculate the probability that all three pieces selected will be the same type of candy.</p></li>
  </ol>
</blockquote>
",probability
"<p>I have a probability density function over $SO\left(3\right)$, which I am trying to sample from. The $pdf$ is given as a generalized fourier series:</p>

<p>$$ f\left(\omega,\theta,\phi\right)=\sum s_{\lambda}^{n}Z_{\lambda}^{n}\left(\omega,\theta,\phi\right)$$</p>

<p>where $s_{\lambda}^{n}$ are the coefficients and $Z_{\lambda}^{n}\left(\omega,\theta,\phi\right)$ are basis functions (symmetrized hyperspherical harmonics), and $SO\left(3\right)$ is parameterized by the variables $\left(\omega,\theta,\phi\right)$, which are the rotation angle, and spherical coordinates of the rotation axis, respectively. I want to sample values of $\left(\omega,\theta,\phi\right)$ (i.e. rotations) from this distribution, but I'm having trouble doing so.</p>

<p>So far I have essentially tried two methods: rejection sampling, a discrete method.</p>

<p>Both methods have given me something that is qualitatively similar to what I would expect, but they seem to have an erroneous uniform distribution superimposed. So I have two questions:</p>

<p><strong>(1) Any ideas why I might be getting this uniform noise?</strong></p>

<p><strong>(2) Any suggestions of how to fix it or a better way to sample from this kind of distribution?</strong></p>

<p><strong>Further Details:</strong>
To check my sampling method I used some software to generate a known distribution and sample rotations. I then computed $s_{\lambda}^{n}$ from these ""correct samples"". Then I tried to generate samples myself from the spectral form of $f\left(\omega,\theta,\phi\right)$ given above. Next I calculated $s_{\lambda}^{n}$ from my samples and compared the two. My samples led to the low order terms being generally too small in magnitude and the higher order terms being too large in magnitude.</p>

<p>The discrete method that I used consisted of generating a ""grid"" of points over $SO\left(3\right)$, and using these as the centers of bins. The bins were sized proportional to the probability density at the bin center. Then uniform samples were generated and the number that fell in each bin was then proportional to the associated probability of the respective bins.</p>

<p>Again, both methods produced a sort of background noise which looks like a uniform distribution on top of the correct distribution.</p>

<p>As, a side note, it seems like I ought to be able to exploit the form of this expression for efficient sampling, but I haven't made use of the spectral decomposition at all in my attempts.</p>
",probability
"<p>I am reading a book that defines the Malliavin derivative $D_tF$ as follows:
If  </p>

<ol>
<li><p>$F = \sum_{n=0}^{\infty} I_n(f_n)$ is the Wiener Chaos expansion.</p></li>
<li><p>$F$ is in the brownian filtration and $F \in L^2(P)$.</p></li>
<li><p>$\sum_{n=0}^{\infty} n n! ||f_n||_{L^2([0,T]^n)}^2 &lt; \infty$</p></li>
</ol>

<p>Then
 $D_tF = \sum_{n=1}^{\infty} nI_{n-1}(f_n(.,t))$.</p>

<p>My question is why do we need 3 to be so strong. It seems that in the theory the $n!$ is never used. Is it defined this way in order to have it match the malliavin derivative constructed using other methods?</p>

<p>If it is used in the theory can you please tell me the point where it becomes important.</p>

<p>Thank you</p>
",probability
"<p>This is for the GRE:</p>

<p><code>A fair coin is tossed once and a fair die with sides numbered 1, 2, 3, 4, 5, and 6 is rolled once. Let A be the event that the coin toss results in a head. Let B be the event that the roll of the die results in a number less than 5. What is the probability that at least one of the events A and B occurs?</code></p>

<p>How do you solve this to come up with $\frac{5}{6}$ (correct answer)? Probabilities are not easy. Any tip you can give is appreciated. Thanks.</p>
",probability
"<p>I have a sequence of iid Bernoulli random variables $X_1, X_2, \dots, X_n$ with $Pr(X_j) = p$, and I'd like to know (a lower bound on) the probability that there exists a consecutive subsequence of length $k$ of them (e.g. $X_i, X_{i+1},...X_{i+k-1}$) such that every random variable in the subsequence takes on the value 1.</p>

<p>Even though the individual variables are independent from each other, the subsequences aren't, and that's where I'm stuck.</p>

<p>Letting $E_{n,k}$ be the event that there is a subsequence of $k$ variables all set to 1: here are the first few terms.</p>

<p>For $k = 2, n=2, Pr(E_{n,k}) = p^2$</p>

<p>For $k = 2, n = 3, Pr(E_{n,k}) = p^3 + 2p^2(1-p)$</p>

<p>For $k = 2, n = 4, Pr(E_{n,k}) = p^4 + 4p^3(1-p) + 3p^2(1-p)^2$</p>

<p>For $k = 2, n = 5, Pr(E_{n,k}) = p^5 + 5p^4(1-p) + 9p^3(1-p)^2 + 4p^2(1-p)^3$</p>

<p>There's simple recurrences for the first, second, and last terms of this sequence, but I can't see how to generate the middle terms, much less sum everything up in a neat way.</p>
",probability
"<p>An extra sum of squares $SSR(X_p|X_1,...X_{p-1})$, assuming that no pair of predictor variables are perfectly correlated, measures the marginal reduction in the error sum of squares. Eventually one can view an extra sum of squares as measuring the measuring the marginal increase in the regression sum of squares when one or several predictor variables are added to the regression model.</p>

<p>Assuming the number of observational data $n$ is lager than the number of predictor variables $p$.</p>

<p>Can I have a rigourous proof that $SSTO=\sum_{i=1}^n (Y_i-\bar{Y})^2\geq SSR(X_p|X_1,...X_{p-1})\geq0$ ?</p>

<hr>

<p>Applying LSE</p>

<p>$SSE(X_1,...,X_{p-1})=\sum(Y_i-b_0-b_1X_{1,i}-...-b_{p-1}X_{p-1,i})^2=\sum(Y_i-b_0-b_1X_{1,i}-...-b_{p-1}X_{p-1,i}-0\times X_{p,i})^2\geq\sum(Y_i-b_0'-b_1'X_{1,i}-...-b_{p-1}'X_{p-1,i}-b_p'X_{p,i})^2=SSE(X_1,...,X_{p-1},X_p)$</p>

<p>$SSR(X_p|X_1,...X_{p-1})=SSE(X_1,...,X_{p-1})-SSE(X_1,...,X_{p-1},X_p)\geq 0$</p>

<p>Proved.</p>
",probability
"<p>Given an urn with a number of two objects, $A$'s and $B$'s, if I am to find the probability of the $i$-th object drawn without replacement to be an $A$ would I need to compute all the different ways that $i-1$ objects can first be drawn?</p>

<p>For example if $i = 3$ would I need to first compute the probability that the first two objects drawn are $A$ then $A$, $A$ then $B$, $B$ then $A$, and $B$ then $B$. Then find the probability of the 3rd object drawn being $A$ in each of these instances and sum all 4 ways that the 3rd objects is $A$? My particular $i$ is 6 so I want to make sure this is correct before actually doing it.</p>
",probability
"<p>Question: An urn contains n red and m blue balls. They are withdrawn one at a time until a total  of r; r · n, red balls have been withdrawn. Find the probability that a total of k balls are  withdrawn.</p>

<p>My attemp:</p>

<pre><code>let A=event that first k-1 draws will get r-1 red balls
let B=event that last (kth) draw will get rth red ball
P(kth draw is the rth red ball)= P(A AND B) = P(A)xP(B)

P(A)=  # of  ways to draw r-1 red balls in k-1 trail
     -----------------------------------------------------
               # of ways to draw k-1 balls
</code></pre>

<p>So I got stuck; I was thinkg that </p>

<pre><code> RBBB *R is one way to achieve P(A AND B)
 BBBR *R is another way. 
</code></pre>

<p>but the solution  for P(A) is:</p>

<pre><code> solution: P(A)= nC(r-1) x mC(n-r) x 1/(n+m)C(k-1)
</code></pre>

<p>This solution is like assuming</p>

<pre><code> R1B1B2B3 * R2       is one way
 R2B4B5B6 * R3       is another way   
</code></pre>

<p>Because they use nC(r-1)x mC(n-r).  Any ideas?</p>
",probability
"<p>Set of non negative weights $w_j$, set of non negative i.i.d. random variables $X_j$ and $f(y)$ is a decreasing nonnegative function in $y$. </p>

<p>I want to claim that: </p>

<p>if $\sum w_i&lt;\sum w^{\prime}_i$,then $\mathbb E f(\sum w_iX_i)&gt;\mathbb E f(\sum w^{\prime}_iX_i)$.</p>

<p>This seems intuitive but I would like a formal proof.</p>

<p>My attempt: The next line holds if all r.vs are coupled to a common r.v. $X_i\sim U$. But not sure if we can do that.
$$\sum w_iX_i&lt; \sum w^{\prime}_iX_i,$$
We have  $$f(\sum w_iX_i)&gt; f(\sum w^{\prime}_iX_i),$$ almost surely.</p>

<p>And we take expectation $$\mathbb E f(\sum w_iX_i)&gt;\mathbb E f(\sum w^{\prime}_iX_i). \;\;\;\;\;\;\; (a)$$  Therefore the result holds a.s.</p>

<p>Is this proof correct? If wrong where is the mistake?</p>

<p>The function $f$ I have is $\log(1+\frac{1}{y})$ and $X_i$ are exponential r.vs.</p>
",probability
"<p>I know this isn't that hard, but I have been looking and I don't know how to solve it.</p>

<p>The number of students whose grade is higher than 1149 is 44, and the total of students is 135. If the question where only for 1 random student, it would be 32%, but I don't know how it is for more than that.</p>

<p>Please help me.</p>
",probability
"<p>Let $X_1,X_2,\dots$ be I.i.d. And $S_n = X_1+X_2+\dots +X_n. $Prove if $S_n/n \to 0$ in probability then $(\max_{1\leq m \leq n}S_m)/n \to 0$ in probability.</p>

<p>I know the idea and there is a detail I don't know how to prove. 
If |Sn-Sk|$\leq$|Sn|+|Sk| and Sn/n limits to 0 in probability, how can I prove that minP(|Sn-Sk|$\leq n\delta$)$\to $ 1 as $ n \to \infty$ ($0\leq k \leq n$)</p>
",probability
"<p>The spectrum of a discrete random variable X consists of the points 1, 2, 3,..., n  and its probability mass function (pmf) fi = P(X = i) is proportional to 1/i(i+1). Determine the distribution function of X. Further, compute P(3 &lt; X &lt;= n).</p>
",probability
"<p>If four dice are tossed, find the probability that exactly 3 fives will show ( answer to the nearest thousandth in the for 0.xxx)?</p>
",probability
"<p>Given $P(A|B)= 0.5, P(B|A)=0.4,$ and $P(A) + P(B) = 0.9$ what is $P(A)=$ ?.</p>
",probability
"<p>The number of total outcomes of an experiment are $25$. If $A$ and $B$ are two non-empty independent events of the experiment such that outcomes in favour of event $A$ are $15$, then the minimum number of outcomes in favour of event $B$ can be? </p>
",probability
"<p>Assume we have a lottery with payouts $(2,3,5)$. So if you buy a ticket you can win a pot which will payout your ticket price multiplied by one of those numbers.<br>
The organizer expects a margin profit of $4\%$ from all tickets. So if the player plays with $1\$$ the mathematical expectation of outcomes will be $0.96$.</p>

<p>In my <a href=""http://math.stackexchange.com/questions/1470264/lottery-payout-with-organizer-margin"">previous question</a> I asked almost the same question thinking that my approach calculating the probability of each payout was right. I wanted the probability of each payout to be proportional to the payout $P_i \propto \frac1{x_i}$ (where $P_i$ is the probability of winning the $i$ payout and $x_i$ is the value of that payout). So I got an answer with these probabilities $(0.192,0.096,0.0576)$ and this explanation $$
\begin{align}
\sum P_i \cdot x_i &amp;= 0.192 \cdot 2 + 0.096 \cdot 3 + 0.0576 \cdot 5 \\
&amp;= 0.96
\end{align}
$$
Can someone please explain or help me to understand how these probabilities can be counted and the idea behind that. </p>

<p>My previous method which I used and assume was wrong looked like this.<br>
If $P_i$ is the probability of payoff $i$ and there are $N$ total positive payoffs that $P_ii = 0.96/N$. Then you get the formula that $P_i = \frac{0.96}{iN}$, which would look like this in my question <br>
$P_2 = \frac{0.96}{2*3}$ where $3$ is the number of positive payouts. <br>
Thank you</p>
",probability
"<p>The first $12$ natural numbers are given. Two distinct numbers are selected. What's the probability that their sum is divisible by $3$? </p>

<p>This looks very easy. I know answer is $1/3$ but in spite of knowing permutations and combinations I had to find favourable cases. The numbers were few. What if we were given  question like probability that two numbers natural less than $100$ are selected and their sum is divisible by $3$? Any smart guy wouldn't go on counting. There has to be some way out which I am missing. Can you guys tell what's the best way? Thanks!</p>
",probability
"<p>I have 3 (not independent) events $A, B, C$ and I know everything about how any two of them correlate. For example, I know:</p>

<p>$$ P[A], P[B], P[C], P[A,B], P[A,C], P[B,C], P[A|B], P[A|C], P[B|C], P[B|A], ...$$</p>

<p>Is there any way to use this information to calculate a correlation for the three of them, i.e.</p>

<p>$$    P[A,B,C] \text{ or } P[A,B|C]  \text{ or } P[A|B,C] $$</p>

<p>A numerical algorithm would also be fine if there isn't an exact formula.
If it is not possible, is there a way to get a confidence interval for these values?</p>
",probability
"<p>I have a $64$-card deck, with $4$ colours - red, green, blue, yellow, $4$ numbers - $1,2,3,4$ and $4$ letters A,B,C,D. So an example card could be yellow2D.</p>

<p>I was attempting to calculate the probability of $4$ of a kind, i.e. $4$ green cards, $4$ $3$'s, etc... having been dealt $k$ cards.</p>

<p>But I got all stuck!</p>
",probability
"<p>Say I roll a $6$ sided dice and I want to roll a $6$. what is the probability that I will have rolled the number I want after $6$ rolls?</p>

<p>I have been using this: $\displaystyle1-\left(1-\frac{1}{x}\right)^y$</p>

<p>where $x$ is the number of sides and $y$ is the amount of rolls, so it would be $\displaystyle1-\left(1-\frac{1}{6}\right)^6$ for rolling a specific number in $6$ rolls, which is $\approx66.5\%$ is this the correct way of calculating the probability of something like this, if not what is the proper way?</p>

<p>i'm not really sure why that formula works(if it does) so some elaboration on that would be nice.</p>

<p>sorry for lack of technical language</p>

<p>thanks in advance</p>
",probability
"<p>I have a population C of candidates C1..Cn<br>
An event will occur to Ci with unknown probability Pi (Pi are independent)</p>

<p>The population is divided into disjoint sets S1..Sm
For each sub set Si, P(Si) is known.</p>

<p>(right now, it the probability of an event happening to ANY member of Si, but it can
also be probability of an event happening to all members if it makes analysis easier..)</p>

<p>I am given a set of population subsets R1.. (independent, possibly overlapping subsets of C)</p>

<p>For each Ri, what can i say about P(Ri) ??<br>
Even better, are there any unions of subsets Ri U Rj U Rk for which the computation of P(union) is more accurate ?</p>

<p>Any ideas and pointers are helpful<br>
(I have a Bsc/Msc in CS, Math but i i am really rusty)</p>
",probability
"<p>I have a fairly simply question which I am not sure about. A 3 digits number is being chosen by random (100-999). What is the probability of getting a number with two identical digits ? (like 101). Thank you !</p>
",probability
"<p>Standard 52 cards deck, calculate the probability of drawing any 4 AND after that any of clubs. </p>

<p>My first intuition is this, there are two possibilities: a) drawing a non clubs 4; or b) drawing a clubs 4, after that you just deduct the card from the deck, so you get:</p>

<p>a) 3/52 * 13/51
b) 1/52 * 12/51</p>

<p>But in the classroom this was resolved as:</p>

<p>a) 4/52 * 13/51
b) 4/52 * 12/51</p>

<p>I don't understand the rationale behind this, is it right/wrong? </p>
",probability
"<p>Let $X$ be a random variable. let 
\begin{align*}
Y=\alpha_1+\alpha_2 X
\end{align*}
where $\alpha_1$ and $\alpha_2$ are parameters.</p>

<p>Now let 
\begin{align*}
Z=\hat{\alpha}_1+\hat{\alpha}_2 X
\end{align*}
where $\hat{\alpha}_1$ and $\hat{\alpha}_2$ are estimates of parameters.</p>

<p>As $n \rightarrow \infty$ , $\hat{\alpha}_1 \overset{p}{\to} \alpha_1$ and $\hat{\alpha}_2 \overset{p}{\to} \alpha_2$. </p>

<p>Now can I say $Y\overset{p}{\to}Z$ ($Y$is becoming $Z$ asymptotically, someone critize me by saying that it is strange to say a variable converge in probability to a variable) or $Y\overset{d}{\to} Z$ (in distribution)?</p>
",probability
"<p>A random number between $1$ and $100$ is generated every second.
What would be the average waiting time for a specific number ($1$ for instance) to be generated?
Probability distribution is uniform.
Each number is generated independently of the others.</p>
",probability
"<p>If $E(X^2)=1$ and $E(|X|)\ge a &gt;0$, then $P(|X|\ge\lambda a)\ge (1-\lambda)^2a^2$ for $0\le \lambda \le 1$.</p>

<p>I can see from the well known inequality $E(|X|) \le E(|X|^2)^{1/2}$ that it must be the case that $a\le 1$. But what to do next I'm not sure.</p>
",probability
"<p>If we have 3 players, playing extreme RPS game like image below:</p>

<p><img src=""http://i.stack.imgur.com/OZtXR.jpg"" alt=""enter image description here""></p>

<p>How much tie probabilities?</p>

<p>Thanks</p>
",probability
"<p><strong>This is my problem</strong></p>

<p>My problem is modeled by a basic Bayesian Network with only two layers. So I have parent and child nodes but the children has no children. Essentially a bipartite graph. The children depend on one or more of the parents and these edges/relations have a probability. The model is also extended by completing the bipartite graph with low probability edges to account for noisy data. So in the finished model each child $(C_x)$ has a dependency on each parent $(P_x)$.</p>

<p>What I want to be able to do is to infer the most probable solution by maximizing,</p>

<p>$$ max_{P_1,P_2,\dots,P_n}(P(P_1,P_2,\dots,P_n|C_1,C_2,\dots,C_m)) $$ 
where $ C_i \in \{0,1\} $, $ P_j \in \{0,1\} $. For a given observation on the state of the children.</p>

<p>So for a observation $O=\{C_1=0, C_2=1, C_3=1\}$</p>

<p>I want to calculate
$$P(P_1=1,P_2=0,P_3=0|C_1=0, C_2=1, C_3=1)$$
$$P(P_1=0,P_2=1,P_3=0|C_1=0, C_2=1, C_3=1)$$
$$P(P_1=1,P_2=1,P_3=0|C_1=0, C_2=1, C_3=1)$$
and so on.</p>

<p><strong>Here is how I try to solve it</strong></p>

<p>I want to be thorough so I will explain how I try to solve this. I'm not sure that I'm doing it right. Please point out to med if I'm doing this wrong.</p>

<p>What I do first is I complete the conditional distribution tables for the child nodes. From the model I have the CPT as for a child node $C_x$ something like this, the probabilites are chosen to make the example easy.</p>

<p>\begin{array}{ l l l|l l }
P_1 &amp; P_2 &amp; P_3 &amp; P &amp; \lnot P \\
  \hline
	0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
	0 &amp; 0 &amp; 1 &amp; 0.1 &amp; 0.9 \\
	0 &amp; 1 &amp; 0 &amp; 0.4 &amp; 0.6 \\
	1 &amp; 0 &amp; 0 &amp; 0.2 &amp; 0.8 \\
\end{array}</p>

<p>And I complete this table by calculating</p>

<p>\begin{array}{ l l l|l l }
P_1 &amp; P_2 &amp; P_3 &amp; P &amp; \lnot P \\
  \hline
	0 &amp; 1 &amp; 1 &amp; (1- \lnot P) &amp; 0.9 \times 0.6 \\
	1 &amp; 0 &amp; 1 &amp; (1- \lnot P) &amp; 0.9 \times 0.8 \\
	1 &amp; 1 &amp; 0 &amp; (1- \lnot P) &amp; 0.6 \times 0.8 \\
	1 &amp; 1 &amp; 1 &amp; (1- \lnot P) &amp; 0.9 \times 0.6 \times 0.8 \\
\end{array}</p>

<p>And then I calculate the joint conditional probability by doing something like</p>

<p>$$P(P_1=1,P_2=0,P_3=0|C_1=0, C_2=1, C_3=1) = $$
$$P(P_1=1,P_2=0,P_3=0|C_1=0) \times$$ 
$$P(P_1=1,P_2=0,P_3=0|C_2=1) \times$$
$$P(P_1=1,P_2=0,P_3=0|C_3=1)$$</p>

<p>Basically I'm not convinced that the last step is correct. <strong>Any help or comments is greately appreciated!</strong></p>

<p>Yes, this is school related but it is not regular homework. It is a part of a thesis project I'm doing at a company.</p>

<p><strong>Graph update on request</strong></p>

<p><img src=""http://i.stack.imgur.com/eX6iS.png"" alt=""Graph""></p>

<p>Here is a graph example of my model. The regular edges are direct dependencies and the dotted edges are noisy or guess edges added to allow for noisy data. Guess edges has a low probability of $p = 0.0001$ and the regular edges all have the probability $(1-p)$. In my problem I do not care for the probability of individual events like $P(L_1)$ or $P(C_2)$, so they are assumed to be $1$. I make an observation on the state of the variables $C_1...C_n$ and given the graph model above I want to infer to most plausible cause. The possible causes  are $P_1...P_n$ or a combination of them that is most likely. Like I stated earlier on the example observation above.</p>

<p>Here is an example of the basic truth tables for this graph.
\begin{array}{ l|l l }
C_1 &amp; T &amp; F \\
  \hline
	P_1 &amp; 0.9999 &amp; 0.0001 \\
	P_2 &amp; 0.9999 &amp; 0.0001 \\
	P_3 &amp; 0.9999 &amp; 0.0001 \\
\end{array}</p>

<p>\begin{array}{ l|l l }
C_2 &amp; T &amp; F \\
  \hline
	P_1 &amp; 0.0001 &amp; 0.9999 \\
	P_2 &amp; 0.9999 &amp; 0.0001 \\
	P_3 &amp; 0.9999 &amp; 0.0001 \\
\end{array}</p>

<p>\begin{array}{ l|l l }
C_3 &amp; T &amp; F \\
  \hline
	P_1 &amp; 0.0001 &amp; 0.9999 \\
	P_2 &amp; 0.0001 &amp; 0.9999 \\
	P_3 &amp; 0.9999 &amp; 0.0001 \\
\end{array}</p>

<p>Does that make it any clearer?</p>
",probability
"<p>We have a fair dice that can produce <code>n</code> different numbers. How many times should we roll the dice to see every number at least once with probability <code>p</code>?</p>

<p>Not a homework, just interesting. Tried to solve myself but with no luck. </p>

<p>I think it could be sort of coupon collector problem, but I can't get exact formula.</p>
",probability
"<p>If one word can be at most 63 characters long. It can be combination of :</p>

<ul>
<li>letters from a to z</li>
<li>numbers from 0 to 9</li>
<li>hyphen - but only if not in the first or the last character of the word</li>
</ul>

<p>I'm trying to calculate possible number of combinations for a given domain name. I took stats facts here :</p>

<p><a href=""http://webmasters.stackexchange.com/a/16997"">http://webmasters.stackexchange.com/a/16997</a></p>

<p>I have a very poor, elementary level of math so I've got this address from a friend to ask this. If someone could write me a formula how to calculate this or give me exact number or any useful information that would be great.</p>
",probability
"<p>Can someone please give me a reference  to an (simple, realworld, i.e. not constructed) example of a discrete probability space such that there are three events in it that are pairwise independent but all three together are not independent (although I wouldn't mind, if someone would give me the example as an answer).</p>
",probability
"<p>Among $t = 60$ lottery tickets there are $w = 20$ prizes. We buy $b = 6$.
What is the probability that $g$ tickets will win, with $g=2$? Generalize this
to arbitrary numbers $t,w, b, g$.</p>
",probability
"<p>I want to create a model that tries to predict a user's behavior based on the random walks of similar users. The problem is similar to Netflix's recommendation challenge. One of the popular solutions was to use singular value decomposition to find movies that user would most likely like to see. </p>

<p>My question is more like this: what genre of a movie would a user like to see on a particular day? You move to each state with a probability, and one state could be ""watching no movie"". Does it make sense or even is it even feasible to approach the problem as a Markov process? How has this been done before?</p>

<p>I took only one class on Markov chains in college. 
Thanks.</p>
",probability
"<p>Given a poll, where $N$ people were polled, and $n_i$ people voted for party $i$, so that: $$\sum{n_i} = N$$
If there are M parliament seats in total we can expect: 
$$m_i = M\cdot\lim_{N\rightarrow\infty} (n_i/N)$$
To be the number of parliament seats party $i$ will have. </p>

<p>My question regards the error involved in this prediction: </p>

<p><strong>What is it's error distribution and what is it's variance?</strong> </p>

<p>If the number of seats were not finite, I'd say that the distribution would be Poisson and each poll value should be $n_i \pm \sqrt{n_i}$, but since the sum is given, It would seem the errors must be correlated in some way.</p>

<p>Any ideas?</p>
",probability
"<p>Five people check identical suitcases before boarding an airplane. At the baggage claim, each person takes one of the five suitcases at random. What is the probability that every person ends up with the wrong suitcase?</p>

<p>I think I need to use the principle of inclusion exclusion to solve this but I'm not quite sure how.</p>
",probability
"<p>I am examining Bayes' Theorem, and wondering about the alternative interpretations of ~A, as being:</p>

<ul>
<li>not A, &not; A</li>
<li>everything but A, &forall;-A</li>
</ul>

<p>And how this will affect the use of probabilities.</p>

<p>So, this is not so much a question about Bayes' Theorem, and more to do with how this split interpretation effects the numbers.</p>
",probability
"<p>A company that sells annuities must base the annual payout on the distribution of the length of life of the participants in the plan. Suppose the distribution of male participants' lifetimes is normally distributed with a mean of 68 years and a standard deviation of 5 years. Let the random variable X represent the lifetime of a male participant. What is the probability that a male participant would die between 64 and 65 years old?</p>
",probability
"<p>X, Y are both random variables of uniform distribution, $0\le\ X \le\ 3$, $0\le\ Y \le\ 4$, then what is the probability of $X \lt Y$? </p>
",probability
"<p>I'm working on a problem from Chow and Teicher's book on Probability Theory, page 123, #6(ii):</p>

<p>If $X_n, n\geq 1$ are i.i.d., $\mathcal{L_1}$ r.v.s, then $\sum (X_n / n)$ converges a.c. if $E|X_1|log^+ |X_1| &lt;\infty$ and $EX_1 = 0$.</p>

<p>The most relevant theorem that I've been thinking of using is one that says if $X_n$ are i.i.d. and $\mathcal{L_p}$ for $0&lt;p&lt;2$, then $\sum \left(X_n / n^{1/p} - E\left(\dfrac{X_nI_{\{|X_n|\leq n^{1/p}\}}}{n^{1/p}}\right)\right)$ converges a.c.; since, in this case, $p =1$, it would suffice to show that the series $\sum E\left(\dfrac{X_nI_{\{|X_n|\leq n\}}}{n}\right)$ converges a.c. to complete the exercise. However, I'm having trouble incorporating the $E|X_1|log^+ |X_1| &lt;\infty$ condition. I see how $EX_1 = 0$ implies that the summands of the series satisfy the following: $E\left(\dfrac{X_nI_{\{|X_n|\leq n\}}}{n}\right) = -E\left(\dfrac{X_nI_{\{|X_n|&gt; n\}}}{n}\right)$, but unfortunately I've been thus far unable get anything resembling a logarithmic series by manipulating summands here.</p>

<p>Perhaps I'm missing something obvious? Any help is greatly appreciated. </p>
",probability
"<p>I've been trying to understand the following:</p>

<blockquote>
  <p>The distribution of two continuous random variables is given by
  $$f_{X,Y}(x,y)=\frac{3}{7}x\space\space 1\le x\le 2,0\le y\le x$$and $0$ otherwise. What is the
  marginal distribution of $Y$ when $0\le y\le 1$?</p>
</blockquote>

<p>My question is, how do I choose the limits for the integral
$$\int_{-\infty}^{\infty}f_{X,Y}(x,y)dx$$</p>

<p>In the school solution they  did
$$f_Y(y)=\int_{1}^{2}\frac{3}{7}xdx=\frac{9}{14}$$</p>

<p>Why are those the limits? What if I wanted to calculate the marginal distribution of $Y$ when $1\le y\le$ 2? Any thumbs rules?</p>

<p>Thanks!</p>
",probability
"<p>So there are 480 squares and 99 mines on the advanced level of minesweeper. It got me thinking, what would be the chances of winning the game randomly clicking each square? So not being influenced by numbers and without it doing any multi openings, so you would need to click 381 boxes (I think) :)</p>
",probability
"<p>A bag contains 5 red and 7 black balls. Second bag contains 4 blue and 3 green balls. 1 ball is drawn from each bag. Find the probabilty for
1 red and 1 blue ball.</p>

<p>The answer is 5/21
But don't know the way to get it. 
Plzz help.</p>
",probability
"<p>Your (honest) opponent choose a random number from 1 to 13 inclusive. You have to guess the number, and you win if the guess is correct. If not, your opponent either reduces the number chosen by one or increases it by 1, and you guess again.</p>

<p>The question is, what is the minimum # of attempts necessary to guarantee a win for you.</p>

<p>I am not able to get a handle on the problem.</p>

<p>Also, (a new variant just thought of), how many guesses should be allowed for a fair or ""nearest to fair"" game ?</p>
",probability
"<p>Suppose I toss a fair coin 10 times. What is the probability that there is a run of at least 4 consecutive heads?</p>

<p>An approach would be to use the Principle of Inclusion-Exclusion on the events $E_i$ where 4 heads occur in positions $i,i+1,i+2,i+3$, where $1\leq i\leq 7$. But this results in a big calculation. </p>

<p>On the other hand, I found the generalization <a href=""http://math.stackexchange.com/questions/59738/probability-for-the-length-of-the-longest-run-in-n-bernoulli-trials"">here</a>, but I think for this problem (with small values $10$ and $4$) maybe there is an easier way to compute the desired value. What would be an easier way?</p>
",probability
"<p>I came across the following probability problem:</p>

<p>Start with $1$ black ball and $1$ white ball in a box. At each step, we will put in a new ball. If there are $a$ black balls and $b$ white balls, we put in a black ball with probability $\dfrac{a}{a+b}$ and a white ball with probability $\dfrac{b}{a+b}$. We do this until there are $n$ balls ($n\geq 2$). Prove that the probabilities that there are $1,2,\ldots,n-1$ black balls are all equal.</p>

<p>This problem is trivial by induction on $n$, the total number of balls. I wonder, however, if there is an intuitive way to interpret the result, without the use of induction?</p>
",probability
"<p>I would like to ask <strong>how can we derive PGF of any multivariate distribution</strong>?
and can anyone give <strong>an example</strong> of deriving the PGF of a multivariate distribution?
That will be great.
Thanks advance.</p>
",probability
"<p>I have stumbled upon many questions, and one of the weaknesses is the ability to test if the concept is distinguishable or not. For example this: </p>

<blockquote>
  <p>Nine delegates, three each from three different countries, randomly select chairs at a round table that seats nine people. Let the probability that each delegate sits next to at least one delegate from another country be $\frac{m}{n}$, where $m$ and $n$ are relatively prime positive integers. Find $m+n$.</p>
</blockquote>

<p>Take the race: $AAA$ Then are the people distinguishable or not? Is it: $A_1, A_2, A_3$ or not? I ask this because of cyclic shifts. I asked this question <a href=""http://math.stackexchange.com/questions/1399651/the-probability-that-each-delegate-sits-next-to-at-least-one-delegate-from-anoth"">Here.</a>. But drhab said they are not, but he uses the concept of $AaA$, or $AAa$ or $aAA$? Is there something with the chair being distinguishable or what is the whole issue exactly?</p>
",probability
"<p>Sorry for the topic being weird, but as a person not too good at math I would like to know whether the following argument is mathematically valid:</p>

<blockquote>
  <p>If $50$% of pregnancies are aborted, is it valid to say that a fetus has $50$% chance to be aborted? Considering that criteria for abortion is random. </p>
  
  <p>Is the following sentence that I heard, mathematically valid?
  ""$50$% of pregnancies are aborted, therefore if you are a fetus you have $50$% chance of not coming out alive""</p>
</blockquote>

<p>Thanks in advance.</p>
",probability
"<p>Let $N_t$ be a Poisson process and $S_{N_t}=X_1+...+X_{N_t}$. </p>

<p>Let $A_t=t-S_{N_t}$ and $B_t=S_{N_t}-t$</p>

<p>1) Show $P(B_t \geq x \ \text{and}\ A_t \geq y)=\frac{1}{E(X_1)} \int_{x+y}^{\infty} P(X_1 \geq u)du\:\:$ with $x,y,t \geq 0$</p>

<p>2) Deduce $A_t$ is independent of $B_t$</p>

<p>For the question 2) I don't know but for the question 1) I tried:</p>

<p>$P(B_t \geq x \ \text{and}\ A_t \geq y)=P(X_{N_t}-A_t \geq x | A_t \geq y)P(A_t \geq y)=P(X_{N_t} \geq x+y)P(A_t \geq y)=P(X_1 \geq x+y)P(A_t \geq y)$</p>

<p>However after I don't know:
$P(X_1 \geq x+y)=\int_{x+y}^{\infty}F'(u)du$ and $P(A_t \leq y)=P(S_{N_t-1} \leq t-y)$</p>

<p>Thank you</p>
",probability
"<p>Let's say I have $3$ events with probabilities $P(A) = 0.5, P(B) = 0.5$ and $P(C)= 0.5,$ and I need to find if </p>

<p>$$P(A \cap B \mid C) = P(A \mid C)P(B \mid C)$$</p>

<p>I am tying to prove this by expanding the formula above to:</p>

<p>$$P(A \cap B \mid C) = \frac{P(A \cap C)}{P(C)}\frac{P(B \cap C)}{P(C)}$$</p>

<p>Is this a correct assumption?</p>
",probability
"<p>Is the following statement true or not?</p>

<blockquote>
  <p>Let $X$, $Y$, $Z$ be $3$ events in the same sample space such that $p(X)$, $P(Y)$, $p(Z) &gt; 0$ and every pair of these events is independent. Then $p(X \cap Y \cap Z) &gt; 0$.</p>
</blockquote>
",probability
"<p>Abe and Bernard are dealt five cards each from the same $52$ card deck. Let $A$ be the event that Abe gets a flush (five cards of the same suit) and $B$ be the event that Bernard’s five cards are of pairwise different kinds (i.e. pairwise independent). Are $A$ and $B$ independent?</p>

<p><strong>Thoughts.</strong> Is $P(A) = P(A|B)$? In other words, is the probability of $A$ the same as the probability of $A$ given that $B$ occurred?</p>
",probability
"<p><strong>Three people have been exposed to a certain illness. Once exposed, a person has a 50-50 chance of actually becoming ill.</strong></p>

<p>a) What is the probability that exactly one of the people becomes ill?</p>

<p>I am a bit unsure, how to solve this question.</p>
",probability
"<p>I am looking at the proof of convergence in probability implying convergence in distribution. The proof begins by stating that if $X_n \leq x$ then either $ X \leq x + \epsilon $ or $ |X_n - X| &gt; \epsilon $. I can't quite see this implication;</p>

<p>$ X_n \leq x \Rightarrow X \leq x + \epsilon$ or $ X &gt; x + \epsilon$</p>

<p>$\Rightarrow X \leq x + \epsilon$ or $ X - X_n \geq X - x &gt; \epsilon $</p>

<p>but how do I obtain $X_n - X &gt; \epsilon$ ? </p>
",probability
"<p>Do you have an idea how I could model the following process somehow as a sum of independent indicator random variables?</p>

<p>I have given a grid of size $n \times n$ for $n \rightarrow \infty$. </p>

<p>Now I color each point of this grid uniformly at random with one out of $k$ colors, where $k=\mathcal{O}(1)$. </p>

<p>I am interested in the probability that none of the $3 \times 3$-subgrids in this grid are monochromatic (monochromatic=all 9 points have the same color) and should show this probability is at most $e^{- \Omega(n^2)}$.  </p>

<p>My task is explicitly to model this such that I can use Chernoff bounds. 
Chernoff bounds, in the context we had it, can be applied if we have a sum $X:=\sum_{i=1}^m X_i$ of independent indicator random variables $X_i \sim Be(p_i)$.</p>

<p>My problem is that clearly the different $3 \times 3$ grids are <em>not</em> independent, so the easy approach to state $X=\sum_{s \in S} X_s$ where $S$ is the set of all $3\times 3$ subgrids and $X_s$ is $1$ if $s$ is a monochromatic grid, and calculate $P[X=0]$ does not work. </p>

<p>Would be very happy about any hint. 
Thank you very much!</p>
",probability
"<blockquote>
  <p>Let $k\leqslant n$ denote two positive integers, $A$ an $n \times k$ matrix with $A'A = I_k$, and $X$ and $Y$ two independent random variables on $\mathbb R^n$, each rotationally invariant (that is, their distributions do not change under the orthogonal transformations). 
  Write $X' = (U',W')$ and $Y' = (V',Z')$ with $U$ and $V$ on $\mathbb R^k$ and $W$ and $Z$ on $\mathbb R^{n-k}$.</p>
  
  <p>Prove that $(A'X, A'Y)$ has the same distribution as $(U,V)$. </p>
</blockquote>

<p>I know that by the Cramer-Wold theorem, for rotationally invariant random variables if we have a linear functional $t$ then $t'X$ has the same distribution as $|t|U$. Also $U$ and $W$ are rotationally invariant each in its own right in this case. I think these two assumptions should be used somewhere in the proof I just don't know how to start, because to me this is basically saying that the joint distribution of $(X, Y)$ is completely determined by the distribution of their first coordinate which is similar to Cramer-Wold except that the factor $|t|$ here is one so somehow ""length"" of $A'$ should be $1$ or it should appear as $A'A$ which is the identity. 
Any help would be appreciated. </p>
",probability
"<p>A factory has produced n robots, each of which is faulty with probability $\phi$. To each robot a test is applied which detects the faulty (if present) with probability $\delta$. Let X be the number of faulty robots, and Y the number detected as faulty.</p>

<p>Assuming the usual indenpendence, determine the value of $\mathbb E(X|Y)$.</p>

<p>Please explain me the result in detail or give me a good hint pls, since I am very new to this concept (of conditional expectation).</p>

<p>Thanks!</p>
",probability
"<p>I'm trying to solve a question from Pathria's statistical mechanics textbook (10.21) but it is more math oriented.</p>

<p>Show that, for a general Gaussian distribution of variables $u_j$ , the average of the exponential of a linear combination of the variables obeys the relation:</p>

<p>$\left\langle \exp\left(\sum_j a_j u_j\right) \right\rangle=\exp\left(\dfrac{1}{2}\left\langle\left(\sum_j a_j u_j\right)^2 \right\rangle \right)$</p>

<p>I'm not entirely sure how to write this; I was doing Taylor series expansions of exponentials and I could solve it easily if it were a standard normal (mean=0).  I believe the linear combination of normal variables is normal, so this seems to have something to do with the log-normal distribution?  </p>

<p>I don't need a full solution; just a hint to go forward.</p>
",probability
"<p>A decision making problem will be resolved by tossing $2n + 1$ coins. If Head comes in majority one option will be taken, for majority of tails it’ll be the other one. Initially all the coins were fair. A witty mathematician replaced $n$ pairs of fair coins with $n$ pairs of biased coins, but in each pair the probability of obtaining head in one is the same the probability of obtaining tail in the other. Will this cause any favor for any of the options available? Justify with logic</p>
",probability
"<p>Tv company receives 90 job application. Information about applicants:</p>

<pre><code>--------------------------------------------
     | have bachelor | dont have bachelor |
     |     (B)       |     (B) negation   |
---------------------------------------------
exp  |     18        |          9         |
(D)  |               |                    |
---------------------------------------------
no exp |      36     |         27         |
(D)     |            |                    |
negation|------------|--------------------|
</code></pre>

<p>Calculate probability for: <code>P(D/B) and P(B neg/ D neg )</code></p>

<p>answers:  <code>P(D/B) =&gt; 1/3</code>,  <code>P(B neg/ D neg ) =&gt; 3/7</code></p>

<p>I tried to do this-></p>

<p>D/B = D - DnB = 18+9 - 18 = 9</p>

<p>P(D/B) = 9/90 = 1/10 (wrong)</p>

<p>and</p>

<p>D/B = B - BnD = 54 - 18 = 36</p>

<p>P(D/B) = 36/90 = 4/10 (wrong)</p>

<p>I have no idea where I am wrong. How to figure out the answer?</p>
",probability
"<p>A fair die is rolled nine times. What is the probability that 1 appears three times, 2 and 3 each appear twice, 4 and 5 once and 6 not at all?</p>

<hr>

<p>My approach is fairly simple. The dice is  fair, so we have a total of $6^9$ possible strings. Consider the set $\{1,1,1,2,2,3,3,4,5\}$. From this set is a total possible number of combinations of</p>

<p>$$\frac{9!}{3!2!2!}=30240$$</p>

<p>Thus, the probability of the above occuring is $30240/6^9$</p>

<p>My question is whether or not I have properly accounted for the probability of $4$ and $5$, and whether or not I should account for their probabilty of being rolled by considering the probability of <strong>never</strong> rolling a $6$. </p>

<p>Could someone explain why I should or should not have these concerns?</p>
",probability
"<p>I think I have some problem understanding markov chains, because we defined them as abstract objects but our professor does proofs with them as if they where just elementary conditional probabilities.</p>

<p>This is our <strong>definition</strong> of a <strong>markov chain</strong>: Given prob. space $(\Omega, \mathcal{A}, \mathbb{P})$, standard borel space $(S, \mathcal{S})$ and a sequence of random variables $X_n: \Omega \to \mathcal{S}, n \in \mathbb{N}$. $(X_n)_{n\in \mathbb{N}}$ is called markov chain if 
$$\forall B \in \mathcal{S}: \mathbb{E}[\mathbb{1}_B(X_n)|\sigma(X_0, ..., X_{n-1})] = \mathbb{E}[\mathbb{1}_B(X_n) |\sigma(X_{n-1})]$$</p>

<hr>

<p>So far, so good. But now we've got the following <strong>preposition</strong>: </p>

<p>Given $(\xi_i)_{i\in \mathbb{N}}$ iid rv on $\mathbb{R}^d$ and random variable $X_0$ independent of $(\xi_i)_{i \in \mathbb{N}}$ (also on $\mathbb{R}^d$) we define $X_n := X_0 + \sum_{i=1}^n \xi_i$. Then $(X_n)_{n \in \mathbb{N}_0}$ is a markov chain.</p>

<p><strong>Proof</strong>: $$P(X_n \in B | X_0 = x_0, ..., X_{n-1} = x_{n-1}) = $$</p>

<p>$$= P(\xi_n + x_{n-1} \in B | X_0 = x_0, X_0 + \xi_1 = x_1, ..., X_0 + \sum_{i=1}^{n-1}\xi_i = x_{n-1}) = $$</p>

<p>$$=_{independce} P(\xi_n + x_{n-1} \in B) = ... = P(X_n \in B | X_{n-1} = x_{n-1})$$
Why do we start treating these conditional expectations just like elementary conditional probability for events?</p>

<p>Sorry for the awful formatting of the proof </p>
",probability
"<p>Let $[n+1]$ be the set defined by $[n+1]=\{1,2,\ldots,n+1\}$.</p>

<p>Call a subset of $[n+1]$ with $r+1$ distinct elements an $(r+1)$-subset. How many $(r+1)$-subsets of $[n+1]$ have $(k+1)$ as their largest element?</p>

<hr>

<p>This seem fairly facile, so I am concerned that I am doing it wrong. By definition, $[n+1]$ is a bounded set. If $(r+1)$ is a subset of $[n+1]$, then $(r+1)$ is bounded as well. Denote that bound as $k+1$ s.t. $k \geq r_0 \forall r_0 \in (r+1)$.</p>

<p>Is anything wrong here?</p>

<p>Additionally, I am supposed to deduce that </p>

<p>$$\sum^n_{k=r}{k\choose r}={n+1\choose r+1}.$$</p>

<p>I have no idea where to start for this one. </p>

<p><strong>EDIT:</strong> Using the hints given by Hagen von Eitzen, I claim that the total number of subsets of $[n+1]$ that have $(k+1)$ as their largest element is $k$. Note that an $(r+1)$-element subset of $[n+1]$ is an $(r+1)$-element subset of $[n+1]$ that has $k+1$ as maximal elelment for exactly one k∈{r,…,n}.</p>

<p>I am fairly sure that I can prove this by induction. Can someone suggest anything for the second half and whether I did the first half correctly?</p>
",probability
"<p>I have been playing a game and came up with this question:</p>

<p>There are $n$ different object, and each time you randomly choose one of them. </p>

<p>One success is defined as one of the objects being selected $m$ times. What is the expected time to get one success (accumulating $m$ of any one object)?</p>

<p>In addition, what is the expected rate of success? </p>

<p>Please help...</p>
",probability
"<p>I came to the following problem: 
Let $A_1, A_2, ...$ be events in a probability space $(\Omega, F, \mathbb{P})$ and $\mathbb{P}[A_j]=1$ for all $j&gt;1$. I need to show that the probability of the intersection of all those events $A_j$, where j goes from 1 to infinity, is also $1$. </p>

<p>From what I understand, the events we have are not dependent so we can use the formula for a joint probability, so it will be the product of the probabilities of the events. However, I am not sure whether that formula holds in the general case. </p>

<p>Any suggestions?</p>
",probability
"<p>I want to calculate $P(X=Y)$, where $X,Y$ are independent and geometrically distributed, which means: $P(X=k) = P(Y=k) = p(1-p)^k$, $k \in \mathbb N_0$ and $p \in (0,1)$.</p>

<p>Can anybody tell me how to do this? I'm afraid I don't have an idea..</p>

<p>Thanks in advance!</p>
",probability
"<p>If we have two coins of radius of $R_1=8$ and $R_2=12$. Assume that 99% of people will be able to tell the size within $\pm5\%$ by touch it only, and assume it is a normal distribution.</p>

<p>Question A: How many people will mistakenly think a given coin is the other one.</p>

<p>Question B: If insert a third coin in between in a average radius, how many people make the mistakes for each coin?</p>

<p>Question C: If insert n coins in between with same step of change, what will be the worst case? (It must be a function of n, right?)</p>

<p>If the question does not make sense, please let me know.</p>
",probability
"<p>Suppose we have an urn with $N$ white balls and $M$ black balls. Suppose we draw $n$ balls and each time a ball is drawn, then we put it back. Let $X =$ number of white ball we get. Let $U = \{1,2,...,N+M\}$. For our probability space, we take $\Omega = U^n $. We want to find </p>

<p>$$ P(X = x) \; \; \; \text{where} \; 0 \leq x \leq n  $$</p>

<p>I am stuck trying to solve this problem. I know the cardinality of $\Omega$ is $(N+M)^n$.</p>
",probability
"<p>Let $Y_1,\,Y_2\ldots$ be a sequence of real random variables and $Y(\omega)=\liminf_{n\to\infty}Y_n(\omega)\in R$. I define using ricursion the sequenze $\tau_k(\omega)=\inf \{n&gt;\tau_{k-1} : |Y_n(\omega)-Y(\omega)|\leq 1/k\}$ and I want to prove that $\tau_k$ is measurable. Can anyone give me any idea? Thank you in advance.</p>
",probability
"<p>Let $\left\{ X_t \right\} $ be a stochastic process $MA(2)$ such that $X_t = Z_t + 0.8Z_{t-2}$. Where $\left\{ Z_t \right\} $ is White Noise $WN(0,1)$.</p>

<p>Compute variance of $$\frac{X_1+X_2+X_3+X_4}{4}$$</p>

<p>I don't have any idea how can I compute it. Could you give me a tip?</p>
",probability
"<p>Consider two real random variables $X,Y$ and the conditional expectation $\mathbb E[Y|X]$, also a random variable. What is the conditional expectation $\mathbb E[\mathbb E[Y|X]|Y]$? Is it $=Y$? Is it $=\mathbb E[Y|X]$? Is it even well-defined?</p>
",probability
"<p>Consider two Normally distributed random variables, $X_1 \sim N(0,T_1)$ and $X_2 \sim N(0,T_2)$, such that $X_2-X_1 \sim N(0,T_2-T_1)$. How to calculate $E[X_2^2\mid X_1]$?</p>
",probability
"<p>In the group of $100$ microprocessors $10$ microprocessors are faulty. $5$ microprocessors are selected randomly. Find the probability that</p>

<p>a) All selected microprocessors are correctly</p>

<p>b) Exactly one microprocessor is faulty</p>

<p>c) At least one microprocessor is faulty</p>

<p>d) Maximum $3$ microprocessors are correctly </p>

<p>I tried</p>

<p>a) $\frac{\binom{90}{5}} {\binom{100}{5}}$ =0.5837</p>

<p>b) $\frac{\binom{10}{1}*\binom{90}{4}} {\binom{100}{5}}$ = 0.3393</p>

<p>c) ${\binom{90}{5}}+{\binom{90}{3}}*{\binom{10}{1}}+{\binom{90}{3}}*{\binom{10}{2}}+{\binom{90}{2}}*{\binom{10}{3}}+{\binom{90}{1}}*{\binom{10}{4}} {\binom{100}{5}}$</p>

<p>and all that divided with ${\binom{100}{5}}$</p>

<p>d) ${\binom{90}{1}})*{\binom{10}{4}}+ {\binom{90}{2}}*{\binom{10}{3}}+{\binom{90}{3}}*{\binom{100}{2}}$</p>

<p>and all that divided with ${\binom{100}{5}}$</p>

<p>Is this good way or I made mistake in reasoning? </p>
",probability
"<p><strong>Given:</strong> $X = Y^2 + Z^2$ (hence $E[X] = E[Y^2] + E[Z^2]$)</p>

<p>$p(X = 1) = .52$, $p(X = 4) = .24$, $p(X = 16) = .24$<br>
$p(Y = -1) = .5$, $p(Y = 3) = .5$</p>

<p><strong>Question:</strong> Despite not being handed any information about $Z$, prove that this could never hold in classical probability theory.</p>
",probability
"<p>We've got a random sample of iid $X_1,\dots,X_n$. We're testing the mean of $X \sim \mathcal{N}(\mu,\sigma^2)$, where $\sigma^2$ is known. The size of the test $\alpha=0.05$.</p>

<p>$H_0: \mu=0$</p>

<p>$H_1: \mu=v$</p>

<p>By the Neyman-Pearson lemma the Most Powerful test is $\phi(X) = \mathbf{1}_A$ where the set $A =\{ x: \prod_{i=1}^n \frac{f(\mu_1,\sigma^2)}{f(\mu_0,\sigma^2)} &gt; k \} $</p>

<p>simplyfying we can reduce the test to:
\begin{equation}
\frac{1}{n}\sum_{i=1}^n X_i &gt; \frac{2\sigma^2(\log k+\mu_1^2 n)}{n \mu_1}
\end{equation}</p>

<p>where $\mu_1 = v$.
Calculating the critical value $k$ we evaluate:
$$
\begin{align}
\alpha=\mathbb{E}[\phi(X) |H_0] &amp;= \frac{1}{\sqrt{2 \pi \sigma^2}} \int_{-\infty}^{\infty}\phi(x) e^{-\frac{x^2}{2\sigma^2}} dx\\
&amp;=\frac{1}{\sqrt{2 \pi \sigma^2}} \int_{-\infty}^{\infty}\mathbf{1}_A e^{-\frac{x^2}{2\sigma^2}} dx\\
&amp;= \frac{1}{\sqrt{2 \pi \sigma^2}} \int_{k}^{\infty}e^{-\frac{(x-\mu_1)^2}{2\sigma^2}} dx\\
&amp;= \frac{1}{\sqrt{2 \pi }} \int_{\frac{k-\mu_1}{\sigma}}^{\frac{\infty-\mu_1}{\sigma}}e^{-\frac{x^2}{2}} dx\\
&amp;=1-\Phi\Bigg(\frac{k-\mu_1}{\sigma} \Bigg)
\end{align}
$$</p>

<p>therefore we can derive $k=\mu_1 + \sigma \Phi^{-1}(1-\alpha)$</p>

<p>Is my approach correct, or did I mess up the calculation of the critical value?</p>
",probability
"<p>Given an infinitely differentiable function $ g: \mathbb{R} \rightarrow \mathbb{R}$, can we always find a distribution function $f_X$ of some random variable $X$ so that 
$g(t) = \int_{-\infty}^\infty e^{tx}f_X(x) dx$?</p>

<p>If my question is too vague or ill-posed, can anyone recommend any literature on the characterization of moment-generating functions?</p>
",probability
"<p>I'm attemtping to solve this problem:</p>

<blockquote>
  <p>Suppose a shot is fired at a circular target.  The vertical and the
  horizontal coordinates  of the point of impact (taking the center of
  the target as origin) are independent random variables, each
  distributed according to the standardized normal distribution. </p>
  
  <p>a. Write down the PDFs of the two coordinates.<br>
  b. Write down the joint
  PDF of the coordinates of the point of impact.<br>
  c. What is the PDF of
  the radius of the point of impact $r = \sqrt{x^2 + y^2}$ ?  Show all  steps you used to
  derive this expression.<br>
  <em>Hint: you can use the CDF method for finding the PDF of a transformed RV.</em><br>
  d. What is the probability that the
  point of impact will land in the ring of radii 2-3?</p>
</blockquote>

<p>MY attempt at a solution:</p>

<p>a)
P.D.F. of x is: $$\frac{1}{2\sqrt{\pi}}e^{-\frac{x^2}{2}}$$
P.D.F. of y is: $$\frac{1}{2\sqrt{\pi}}e^{-\frac{y^2}{2}}$$</p>

<p>b)
joint PDF is:
PDF(x) * PDF(y) = $$\frac{1}{2\sqrt{\pi}}e^{-\frac{y^2}{2}} * \frac{1}{2\sqrt{\pi}}e^{-\frac{x^2}{2}} = 2\pi^{-1}e^{\frac{-(x^2 + y^2)}{2}} $$</p>

<p>c) this is where I'm getting hung up on...</p>

<p>So the C.D.F. of a std. normal R.V. $x$ is:</p>

<p>$$\phi (x) = \frac{1}{\sqrt{2 \pi}}\int e^{\frac{-t^{2}}{2}}dt$$ </p>

<p>correct?</p>

<p>since $r = \sqrt{x^2 + y^2}$  is given, then is the CDF of $r$ just
$$\phi (r) = \frac{1}{\sqrt{2 \pi}}\int e^{\frac{-r^{2}}{2}}dr$$
And then would the PDF of the radius just be the first derivative of this?</p>
",probability
"<p>I am trying to solve this:</p>

<blockquote>
  <p>Consider a stick of length 1.  You break the stick in two
  random places, X and Y.<br>
  a. Define the individual
  probability distribution functions of the breaking points X and Y.<br>
  b. Write the joint PDF of the breaking points, if X and Y are
  independent.  Sketch its  support (domain) and indicate the density
  values of this domain.<br>
  c. Assume that Y is such that $Y &gt; X$. What is the joint PDF of $(X,Y)$ if it needs to be  uniform on this domain. Again, sketch its support and indicate the density value.<br>
  d. The two breaking points divide the stick in three segments. 
  What is the probability of the left-most segment is the shortest
  segment, when $Y &gt; X$?  Sketch the area in the $X-Y$  plane that
  corresponds to this event.  (Hint: to be the shortest segment the
  leftmost segment  needs to satisfy two constraints simultaneously.)</p>
</blockquote>

<p>Solutions:</p>

<p>a/b)</p>

<p>$$PDF(X,Y) = 1 | (x,y) \in [0,1]\times [0,1]$$$$0|otherwise$$</p>

<p>c) we know that $X$~U$(0,1)$. The clause that $Y\gt X$ means that $Y$~U$(X, 1)$.  </p>

<p>Now, Y has become dependent on X, correct? Therefore, the joint PDF isn't as simple as multiplying the PDF's together. How do I get the joint PDF in this case? </p>

<p>The answer I was given is that $$PDF(X,Y) = 2|(X,Y)\in [0,1]\times [0,1] \cap (Y &gt; X)$$ but I'm having trouble understanding why this is... </p>

<p>I think I understand the concept that, because $Y&gt;X$, the area in which Y can live is halved, because, when X is chosen (since it is chosen uniformly), Y's value depends on the value of X, and the uniform distribution means that the area Y can occupy is halved. but, why does the P.D.F. = 2 in this case? Wouldn't it still be equal to 1, as in: $$PDF(X,Y) = 1|(X,Y)\in [0,1]\times [0,1] \cap (Y &gt; X)$$ I thought the only change would be in the are for which the PDF was valid (hence the distribution needing to intersect the area where $Y&gt;X$</p>

<p>d) For this one, I came up with 3 constraints: $\frac{1}{2} &lt;Y&lt;\frac{3}{4}$ and $X&lt;\frac{1}{4}$</p>

<p>thus, $X$~U$(0,\frac{1}{4} )$ and $Y$~U$(\frac{1}{2} , \frac{3}{4})$</p>

<p>making $$PDF(X) = \frac{1}{\frac{1}{4}} = 4$$and $$PDF(Y)= \frac{1}{\frac{3}{4} -\frac{1}{2}} = 4$$</p>

<p>so joint $PDF(X,Y) = 16|\frac{1}{2} &lt;Y&lt;\frac{3}{4}$ and $X&lt;\frac{1}{4}$</p>

<p>However, this is incorrect, and I can't rightly figure out why.</p>

<p>Any advice as to where I'm going wrong? Thank you very much!</p>
",probability
"<p>I was wondering if someone could critique my argument here. The problem is to find the probability where exactly 2 people in a room full of 23 people share the same birthday.</p>

<p>My argument is that there are 23 choose 2 ways times $\displaystyle \frac{1}{365^{2}}$ for 2 people to share the same birthday. But, we also have to consider the case involving 21 people who don't share the same birthday. This is just 365 permute 21 times $\displaystyle \frac{1}{365^{21}}$. To summarize:</p>

<p>$$\binom{23}{2} \frac{1}{365^2} \frac{1}{365^{21}} P\binom{365}{21}$$ </p>
",probability
"<p>I deal a standard deck of 52 cards to you face up, one card at a time. Before
any deal of any card you can shout out ""NOW"". If you shout out ""NOW"" and the
next card I deal is a queen, then the game finishes and I give you $100. If the next
card isn't a queen, then the game finishes and I give you nothing. What is a fair
price for you to pay me in order to play this game with me?</p>

<p>What I think of is to use the optional sampling theorem and show it is a martingale. But I am a bit lost on the setup.</p>
",probability
"<p>Given some real number $a$ can anyone prove that if
$$
P(X &gt; a) &gt; P(Y &gt; a)
$$
is true then
$$
P(X &gt; Y) &gt; \frac12
$$
is also true.</p>
",probability
"<p>Suppose there are thirteen slips in a bag, labelled 1-13. If I draw a 10, 11, 12, or 13 then I stop adding to the sum and return the sum. If not, I add the number I draw to the current sum and place the slip back in the bag. </p>

<p>What is the expected value of the sum?</p>

<p><strong>My Attempt:</strong></p>

<p>S: total sum</p>

<p>Xi: the ith drawn slip</p>

<p>Probability of drawing a slip from 1-9: 9/13</p>

<p>Have a 9/13 chance of getting # from 1-9 and expect to add average of 5 and trying again...</p>

<p>Ending with a 10, 11, 12, or 13 each has 1/4 chance
$$
E[S] = \frac{1}{4}(\frac{9}{13}(5+E[S]) +10) + \frac{1}{4}(\frac{9}{13}(5+E[S]) + 11) +... +\frac{1}{4}(\frac{9}{13}(5+E[S])+13)
$$</p>

<p>which gives E[S] = 48.625</p>

<p>I wasn't sure how to factor in the four different ways that we could end the drawing (i.e. ending with a 10, 11, 12, 13). The answer doesn't seem right to me. </p>

<p>Additionally, let Y be the number of times a number of a particular number is drawn. What is E[Y]? I have no idea how to start with this with this part.  </p>
",probability
"<p>A non-closed path is chosen at random on the complete graph K9. All
paths are equally likely. What is the probability that the path contains
the edges {23} and {34} given that it is length 6? Given that it has
the edge {89}?</p>
",probability
"<p>I have a conditional probability problem I'm unsure can be answered given the information I have - as such I'm unsure if Bayesian Theorem is the way to answer it, or if the answer is staring at me in the face and I can't spot it.</p>

<p>It's easiest to think of this problem in terms of a game of baseball, with two teams - A and B.  I want to work out:</p>

<p><strong>Pr(A scores first and A wins)</strong> (A1) - and similarly<br>
<strong>Pr(B scores first and B wins)</strong> (A2)</p>

<p>Obviously these two scenarios alone won't sum to 100% as there are the possibilities that a team could score first and go on to lose.  Also worth keeping in mind that in a baseball setting Team A will bat first and have first chance to score.</p>

<p>I have the following known information:</p>

<p>Pr(A Wins) = 0.58  (B1)<br>
Pr(B Wins) = 0.42  (B2)</p>

<p>Pr(A Scores First) = 0.51 (C1)<br>
Pr(B Scores First) = 0.49 (C2)</p>

<p>Pr(The team who scores first wins) = 0.75  (D1)<br>
Pr(The team who scores first loses) = 0.25  (D2)</p>

<p>Is it as simple as saying that A1 = C1 * D1 (ie, the prob of team A scoring first by the prob that the team who scores first wins is the prob that team A will score first and win).  </p>

<p>In the back of my mind it seems to me this isn't valid as there is some dependency here, hence I'm unsure whether I need to use Bayes Theorem - or is it the case there isn't enough information here?</p>

<p>Thanks in advance.</p>
",probability
"<p><img src=""http://i.stack.imgur.com/5VGgn.jpg"" alt=""enter image description here""></p>

<p>Find $E[X]$ and $Var[X]$</p>

<p>So for the expectation so far I got that:</p>

<p>$$E[X] = E[X|N=n]P(N=n) = \large\frac{n+1}{\lambda} \frac{\lambda^{n}}{n!}e^{-\lambda}$$
but for conditioning on both a discrete and continuous random variable I am not sure whether to use the summation or integration. For integration it comes out to be just $\frac{n+1}{\lambda}$ which does not seem right since that would indicate that the expectation is independent of each other.</p>
",probability
"<p>A box contains $3$ yellow socks, $4$ blue socks, $1$ orange sock, and $2$ green socks. What is the probability of picking $2$ blue socks at the same time? What is the probability of picking $1$ green and $1$ blue sock at the same time?</p>

<p>I was thinking it is:<br>
$\large\frac{4}{10} \cdot \frac39$ for the $1^{st}$ question,  </p>

<p>$\large\frac{2}{10} \cdot \frac49$ for the $2^{nd}$ question.</p>
",probability
"<p>Question: </p>

<p>A store opens at $t =0$ and potential customers arrive in a Poisson manner at an average arrival rate of $λ$ <em>potential</em> customers per hour. As long as the store is open, and independently of all other events, each particular potential customer becomes an <em>actual</em> customer with probability $p$. The store closes as soon as ten actual customers have arrived.</p>

<p>Considering only customers arriving between $t =0$ and the closing of the store, what is the probability that no two <em>actual</em> customers arrive within $τ$ time units of each other?</p>

<p>Thanks! Could you give me idea or answer? 
Why downvote? The given answer is a little werid that I could not understand...</p>
",probability
"<p>I have a question.</p>

<p>I'm looking to calculate the probability of getting $4$ different suits cards in a $5$ card poker game using a standard $52$ card deck.</p>

<p>I think this is: $$\frac{\dbinom{4}{1}\dbinom{13}{2}\dbinom{13}{1}^{3}}{\dbinom{52}{5}}$$</p>

<p>What do you think?
Thanks.</p>
",probability
"<p>Consider a homogenenous Markov chain $\{X_n\,:\, n\in \mathbb N\}$ ($0\in\mathbb N$). The state space is $S$ with $|S|\le |\mathbb N|$ and $i\in S$. Consider moreover the function $1_{\{i\}}:S\longrightarrow\{0,1\}$ such that $1_{\{i\}}(i)=1$ and $1_{\{i\}}(s)=0$ if $s\neq i$ and then define the following random variable:</p>

<p>$$N_i:=\sum_{n=1}^\infty1_{\{i\}}(X_n)$$</p>

<p>Clearly $N_i$ counts (starting from $X_1$) ""the passages"" of the Markov chain from the state $i$.</p>

<p>I don't understand the following equality that can be found in the book  ""A course in stochastic - D. Bosq, H.T.Nguyen"" (page 57 on my edition):</p>

<p>$$E(N_i|X_0=i)=\sum_{n=1}^\infty P(X_n=i|X_0=i)$$</p>

<p>where $E(\cdot|\cdot)$ is the conditioned expected value. Please give me an explaination.</p>

<p>Thanks in advance.</p>
",probability
"<p>I'm trying to find the probability that $X$ is greater than, given a mean of $50$ and a std deviation of $5$.</p>

<p>I enter <code>normalcdf(66, 1E99, 50, 5)</code> in my calculator and receive and error.</p>

<p>Please help.</p>
",probability
"<p>A am a bit confused, when we are using choosing the critical value for a wilcoxon rank sum test (2-samples unpaired) when do we use the upper bound and when do we use the lower bound. So far i have only used the lower bound with the lowest of the two W values but keep seeing questions (A-level exam questions) where they specifically take the upper bound. For what reasons and when do we use the upper critical value and when the lower??</p>
",probability
"<p>Let E and F be independent with E = AUB and F=AB. Prove that either P(AB)=0 or else P(not A and not B)=0.
I dont know how to solve it. Please help.
Thank you very much.</p>
",probability
"<p>This is another question like <a href=""http://math.stackexchange.com/questions/520844"">this one</a>. And by the same reason, the book only has the final answer, I'd like to check if my reasoning is right.</p>

<p>A couple has 2 children. What is the probability that both are girls if the eldest is a girl?</p>
",probability
"<p>A population consists of F females and M males;the population includes f female smokers and m male smokers. If A is the event that the individual is female and B is the event he or she is a smoker , find  the  condition on f, m, F and M so that A and B are independent events?
The answer is f/F=m/M
I dont know how to get that answer. Please help.
Thank you.</p>
",probability
"<p>I'm trying to find if my approach to this kind of problems is correct. </p>

<p>For example: You have 3 boxes, and you have a 33% chance of finding an item in a box. What is the probability of finding items in: 0, 1, 2, 3 (all) boxes?</p>

<p>My answer:</p>

<p>$P=0.33$ $(!P =1 - 0.33=0.67)$</p>

<p>for 0 boxes: $(!P * !P * !P) * 3 = (0.67 ^ 3) * 3= 0.9$</p>

<p>for 1 box: $P * !P * !P + !P * P * !P + !P * !P * P  = (0.33 * 0.67 ^ 2) * 3 = 0.44$</p>

<p>for 2 boxes: $P * P * !P + P * !P * P + !P * P * P = (0.33 ^ 2 * 0. 67) * 3 = 0.21$</p>

<p>for 3 boxes: $(P * P * P) * 3 = (0.33 ^ 3) * 3 = 0.10$</p>

<p>The reasoning (for example for the 1 box case) is that we need to take the probability that the first chest contains an item AND $(*)$ the other don't, OR $(+)$ the second chest contains an item and the other don't, OR the third contains an item and the other don't.</p>

<p>Is this the correct way to calculate the probability for this type of problem?</p>
",probability
"<p>Let $X$ be a non-negative random variable. Prove that $$\Pr(X\geq a) \leq \frac{E[e^X]}{e^a}$$ </p>

<p>where e is Napier's base.</p>

<p>Can I know what the question means and how to prove it.</p>
",probability
"<p>If Government increases payment then they increase it by 9% . now if whether government will increase payment follows binomial distribution with parameters n=2 and p=(2/3) , then what percentage of payment increase is expected ? </p>

<p>my logic is let 
X denotes  government will increase payment.
then  x follows Bin(2, 2/3)</p>

<p>then E(X)=4/3.
so expected payment increase is 9*(4/3)=12%</p>
",probability
"<blockquote>
  <p>Let $X$ denote the number of tosses required to get the 5th head and $Y$ the number between the 6th and 7th heads. Are $X$ and $Y$ independent?</p>
</blockquote>

<p>Y will always depend on X . NO ?
i know geometric distribution has lack of memory property . but in this the underlying distribution is i think negative binomial. </p>

<p>i think 'no, they are not independent ' . help please. </p>
",probability
"<p>Let $\{X_n\}$ be a sequence of independent random variables on some probability space. </p>

<p>Then, by definition(according to the book that I am reading), I know that $\{\sigma(X_1),\sigma(X_2),\dots, \}$ is independent. </p>

<p>Then, I am wondering whether $\sigma(X_{n+1})$ is independent of $\sigma(\sigma(X_1),\sigma(X_2),\dots,\sigma(X_n))$. </p>

<p>Or in general, is $\sigma(\sigma(X_{n_1}),\sigma(X_{n_2}),\dots,\sigma(X_{n_k}))$ is independent of 
$\sigma(\sigma(X_{j_1}),\sigma(X_{j_2}),\dots,\sigma(X_{j_l}))$, where $\{n_1,n_2,\dots,n_k\} \cap \{j_1,j_2,\dots,j_l\} = \emptyset$?</p>
",probability
"<p>I know that there exists a particular measure, called <a href=""https://en.wikipedia.org/wiki/Haar_measure"" rel=""nofollow"">Haar measure</a>, defined on random matrices, i.e. $n \times n$ orthogonal complex matrices. 
My question is the following: can we define a probability measure on the space of $n \times n$ symmetric matrices with non negative integer coefficients? If yes, can you suggest me some case?</p>
",probability
"<p>Firstly apologies for lack of maths skill, I am a biologist and sadly fit the stereotype of being terrible at maths. </p>

<p>I am designing a set of unique identifiers for sample identification, which are generated from the genetic data associated with the sample. </p>

<p>I am trying to calculate the probability that within a given population of samples, two or more samples will be assigned the same identifier, which clearly is not desirable.</p>

<p>The identifiers are an ordered concatenation of $22$ pieces of data, each with three states i.e. RR, RA &amp; AA. These three states each have a different frequency in the population, as well as being different between the 22 pieces of data. I think that for these 22 pieces of data the number of possible identifiers will be $3^{22}$ =~ $3.14x10^{10}$. Presumably the average probability for each identifier would be $\large \frac{1}{3.14x10^{10}}$, but it would be the upper outliers that would be the limiting factor on the use of the method.</p>

<p>I have calculated the probability of the most probable identifier occurring in a single sample, which is ~$2x10^{-7}$. As such, I think that:</p>

<p>$p$ = $(2x10^-7)^{2}$ $\cdot n$</p>

<p>where p is the probability of the most likely identifier being assigned twice and n is the number of samples in the population.</p>

<p>This is as far as my maths can take me, though this clearly fails say where the identifier can be assigned more than twice, and as there are $3.14x10^{10}$ identifiers which could potentially also be repeatedly assigned. </p>

<p>I am struggling to see a way to deal with the multiple identifiers issue other than presuming that all identifiers have the same probability as this most likely identifier, though this would surely result in an enormously conservative estimate. </p>

<p>Once I have a way to do this I will then try to calculate the maximum size of a population sampled while maintaining a probability of replication of less than say $0.05$.</p>

<p>Any help with this would be greatly appreciated, sorry for the rather cumbersome explanation. I and others in my group have some skill in programming, so computational approaches that are more accurate are viable, and indeed preferable to conservative estimations.</p>

<p>Many thanks</p>
",probability
"<p>Say we have a compact space $X$ and a probability measure $P$ on $X$.</p>

<p>Assume that we know that for some event $A$ the sequence $f_n(x)\rightarrow f_\infty(x)$ converges a.s. in $Q$ which is the regular conditional probability space generated by conditioning $P$ on the event  $A$.</p>

<p>Under which conditions we can conclude that $f_n(x)\rightarrow f_\infty(x)$ converges a.s. in $P$ also?</p>
",probability
"<p>Given the probability density function $(x+y)$ if $0 \leq x \leq y \leq c$, $0$ otherwise.</p>

<p>I want to calculate $c$. I clearly do not know at all where to start. I tried to take some integrals but I just do not know how to find the ""limit"" of the function.
 However, my math skills are not too advanced that is why I am not quite sure if there actually is some calculation involved.</p>

<p>I would appreciate some help, thanks. </p>
",probability
"<p>I'll just give you the four rules that matter in this problem and explain my thought process and the other opinion.</p>

<p>Rule #1: 15 players are playing a game.</p>

<p>Rule #2: One player (J) can secretly select a player (not themselves).</p>

<p>Rule #3: A different player (K) can then secretly select a player (not themselves) and kill them.</p>

<p>Rule #4: If J selects K, then K will be given no choice and will kill J.</p>

<p>Clarification: J and K can select the same person.</p>

<p>It is then revealed that K killed J. What is the probability that J had selected K?</p>

<p>Let Q be the required probability.</p>

<p>I will attempt to calculate the probability that J did NOT select K given that K killed J.</p>

<p>Let's call A the event {J does NOT select K} and B the event {K kills J}. </p>

<p>We're trying to calculate P(A/B), which is equal to P(AB)/P(B). Clarification: AB means A∩B.</p>

<p>P(Β) first. B can happen if J selects K (1/14), or K selects J (1/14), minus the intersection (1/196). Thus, P(B)=2/14-1/196=27/196.</p>

<p>AB now. The probability that K selects J (1/14), minus P{K selects J AND J selects K} (1/196). So, P(AB)=13/196.</p>

<p>Thus, P(A/B)=0.481481... or about 48%. And Q=0.52. Almost.</p>

<p>Some people, however, argued that since we know J died to K, the sample space only includes the events {K killed J}, of which there are 14, and only 1 of those also includes J selecting K, thus Q=1/14. Part of the argument is that P(B)=1, since we know that K killed J.</p>

<p>I am not sure wether we are looking for dependent probability or intersection. The problem, however, is perfectly defined. If it is revealed that K killed J, what are the odds of J having selected K?</p>

<p>EDIT: Another clarification: While, yes, both J and K do not have to select another player, we assume that both did (although K will kill J if he is selected, even if he doesn't want to kill anyone).</p>

<p>I was also a bit vague about what J does when he selects another player because it is irrelevant. If you must know, during the day he selects the player he wants to interrogate that night, and in all nights except the first one (which this problem examines), kill them if he so wants. There are exceptions, but this is the general rule.</p>
",probability
"<p>We choose a random number from 1 to 10. We ask someone to find what number it is by asking a yes or no question. Calculate the expected value if the person ask if it is $x$ number till you got it right?</p>

<p>I know the answer is around 5 but i can't find how to get there.</p>

<p>I tried $\frac{1}{10}(1)+\frac{1}{9}(2)+\frac{1}{8}(3)+\frac{1}{7}(4)+\frac{1}{6}(5)+\frac{1}{5}(6)+\frac{1}{4}(7)+\frac{1}{3}(8)+\frac{1}{2}(9)$</p>

<p>but it doesn't work. Any help to point me in the right direction would be greatly appreciated.</p>

<p>Thank you</p>
",probability
"<p>You are dealt $20$ cards. What is the probability you have all kings given that you hold at least one king?</p>

<p>So I set it up like 
$$
P(4\textrm{ Kings | at least one king}) =\frac{{4 \choose 4}{48 \choose 9}}{{52 \choose 20}-{48 \choose 20}}
$$
Does this setup look correct? </p>
",probability
"<p>Suppose that I have a finite population of A's and B's, with properties:</p>

<ul>
<li><p>Population size: $n$</p></li>
<li><p>There are $n_1$ A's and $n - n_1$ B's  (so that $p = \frac{n_1}{n}$, $q = \frac{n - n_1}{n}$)</p></li>
</ul>

<p>I'm taking a sample of size r without replacement. What I need to demonstrate (<strong>if it can be demonstrated</strong>, I'm not sure) is that: if p > 0,5 then the probability that sample proportion $\bar{p}$ > p is greater than the probability that $\bar{p}$ &lt; p.</p>

<p>Put another way: <strong>If p > 0,5, then Prob($\bar{p} \ge p$) > Prob($\bar{p} \le p$)</strong></p>

<p>Plainly, that if deviations from the expected value occur, then they are more likely to occur in the direction of the more frequent type of member.</p>

<p>As an additional premise I have that $pr \in \mathbb{Z}$.</p>

<p>So, instead of using a cumulative hypergeometric distribution, I thought it would be simpler (avoiding the sums) to reformulate the problem in this manner:</p>

<p>$$\frac{\binom{n_1}{pr} \binom{n - pr}{r - pr}}{n \choose r} &gt; \frac{\binom{n - n_1}{qr} \binom{n - qr}{r - qr}}{n \choose r}$$</p>

<p>Is this ok? What it says -on the left for example- is basically ""from the population, take a subset of pr A's (so you know now that the sample will contain at least the same proportion of A's than the population), and then take the rest of the sample from the remainder of the population as you please"".</p>

<p>If this is ok, then how do I go on from there?
I managed to reduce what I need to prove to:</p>

<p>$$\frac{(pn)!}{(pn -pr)!} (n - pr)! &gt; \frac{(n - pn)!}{(n - r - (pn -pr))!} (n - (r - pr))!$$</p>

<p>(since the denominators cancel and, after applying the binomial coeeficient formula, (r - pr)! = (qr)! and (r - qr)! = pr! can also be cancelled).</p>

<p>Is what i've got so far all right? where to go from here? Thank you</p>

<p>EDIT: I've been trying the conjecture for various values here: <a href=""http://stattrek.com/online-calculator/hypergeometric.aspx"" rel=""nofollow"">http://stattrek.com/online-calculator/hypergeometric.aspx</a>  and the result seems to hold. Furthermore, there seem to be some interesting properties, such as, the greater p is, the greater the difference between $Prob(\hat{p} \ge p)$ and $Prob(\hat{p} \le p)$.</p>

<p>It seems to hold for sampling with replacement as well, which can be tried here: <a href=""http://onlinestatbook.com/simulations/CLT/clt.html"" rel=""nofollow"">http://onlinestatbook.com/simulations/CLT/clt.html</a></p>
",probability
"<p>Here's a nice probability puzzle I have thought about for a class I'm TAing, I'm curious to see different solutions :) It goes like this:</p>

<p>We have a classroom with $n$ seats available and $m \leq n$ incoming students. Each student has an (ordered) list of $k \leq n$ preferences for the seat he is going to take, where $k$ is some fixed positive integer. If at the moment of his arrival, a person's $k$ favorite seats are already taken, then he randomly chooses a seat from the remaining $n-k$. What is the probability that everyone occupies one of his favorite $k$ seats?</p>
",probability
"<p>Given two points $X,Y$ on two sides of square $[0,1]\times [0,1]$ ($X:(0,1/2),Y:(1,1/2)$ (PS: My original question is $X,Y$ on opposite of a square, but I think that's not the real case) )and $n$ points distributed uniformly(i.i.d) in the square (where $n$ is large, and $A$ denotes the set of $n$ points), can I caluculate the asymptotic behavior of the value $M(n)$, where $M$ is defined as
$$M(n)=E\left[\min_{B\subset A} \sum_{k=1}^{|B|+1} d(B_k,B_{k-1})^2\right]$$
where $B_k$ is the $k$th element of $B$,$B_0=X,B_{m+1}=Y$(We let $m=|B|$), and the expected value is taken over all the possible $A$ . That is to say, I would like to compute the expected value of the minimal weight defined as sum of the square of distance.</p>

<p>I know that when $n\to\infty,M(n)\to 0$. And in the $1$-dim case, this is easy, since it is only a Poisson process, and the distance between two consecutive points are surely exponential distribution.(Calculation suggests it's about $(n+3)/((n+1)(n+2))$,where $n$ is number of points added) But in the two dimensional case, I got stuck and don't know how to tackle it. This is a problem arouse from the calculation of the cost of a network. Any hint or reference are welcomed, Thanks!</p>

<p>(Some computer experiment suggests that the weight is about $\approx 1.1/\sqrt{n}=O(1/\sqrt{n})$. I also wonder if there are some similar results?)</p>
",probability
"<p>N uniform spheres are to be segregated into 4 boxes labelled A,B,C,D. What is the probability of not finding a sphere in box A if :</p>

<ol>
<li>N=4</li>
<li>N=10</li>
</ol>

<p>?</p>

<p>According to me , if they are the spheres and boxes are represented by X and * respectively and  listed as a string eg.XX*X*X* (Actually the * represents the separation between regions that represent a box ie. two spheres in each box would be shown as- XX*XX*XX*XX), the no. of ways in which they could be segregated is $\binom{10 +4-1}{10}$ where 10 is the no. of spheres and in this case the 10 spaces in the resultant 13 character string.</p>

<p>Subsequently, if one box is ignored as per the requirement of the question , the required probability should be :  $\frac{\binom{10+3-1}{10}}{\binom{10+4-1}{10}}$</p>

<p>Please provide an answer to the probability question and any mistakes that I may have made in my approach.</p>
",probability
"<p>Then you toss a fair coin as many times as the number of pips. For each heads, you win \$20; for each tails, you lose \$1. Let X = total amount you win (or lose if $X&lt;0$). </p>

<p>What is $E(X)$?</p>

<p><strong>My thoughts:</strong></p>

<p>If you roll $n$ you lose $n$ and then gain ($20 \cdot$ expected head) $-$ ($1 \cdot$ expected tails) </p>

<p>Expected heads = expected tails = $\frac{n}{2}$. </p>

<p>Probability of rolling $n$ is $\frac{1}{6}$. Therefore:</p>

<p>$E(X) = \sum_{n=1}^6 \frac{-n + 20\frac{n}{2} - 1\frac{n}{2}}{6}$ </p>

<p>$= \sum_{n=1}^6 \frac{-n + 10n - \frac{n}{2}}{6}$ </p>

<p>$= \sum_{n=1}^6 \frac{8.5n}{6}$ </p>

<p>$= \frac{8.5}{6}\cdot \frac{6\cdot7}{2}= \frac{(8.5)\cdot7}{2} = 29.75$</p>

<p>Does this work seem correct? I feel like I did something wrong. Thanks!</p>
",probability
"<p>I have a rectangular section of constant height and length and I choose a random starting point anywhere along its length. From the randomly chose starting point, I first add <code>x</code> units of red material immediately to its right and then fill the remaining section to the right of the red material with blue material.</p>

<p>Here's a graphic I drew up as an example:</p>

<p><img src=""http://i.stack.imgur.com/V1gQt.jpg"" alt=""enter image description here""></p>

<p>My questions is, how do I go about finding the probability that the variable blue material section will be greater than the static red material section?</p>

<p>And also is there a way to determine an average size of the blue section?</p>

<p>My idea was that that the average starting point would be in the middle of the rectangle, therefore the average blue material section would be:</p>

<p>$$
\frac{length\_rectangle}{2} - x
$$</p>

<p>Is that correct?</p>

<p>For the probability component, I figure that for the red material section to be greater than the blue section, the starting point would have to start at such a point that:
$$
(length\_rectagle - start\_point) &lt; 2x 
$$
Therefore, the probability that the starting point satisfies the inequality, would be just less than:
$$
\frac{2x}{length\_rectangle}
$$</p>
",probability
"<p>This is an interview question.</p>

<p>Given n red balls and m blue balls and some containers, how would you distribute those balls among the containers such that the probability of picking a red ball is maximized, assuming that the user randomly chooses a container and then randomly picks a ball from that. </p>

<p>My solution: </p>

<p>suppose we have c containers, distribute n/c read balls to each c. 
     If c == 1, put all of them together, it is
                n/(m+n)    </p>

<pre><code> If c == 2,  put 1 red in c1 and all left red and all blue ones in c2 in this way , we have:
              1/2 + 1/2 *(n-1) /(m+n-1) &gt; 1/2

 If c == 3,   put a red in c1, put a red in c2, put left red and all blue in c3, we have:
    1/3 + 1/3 + 1/3 * (n-2)/(m+n-2) &gt; 2/3

 If c == n,  put a red in each of p -1, and all left red and blue in pth container, we have:
            ( Sum of (1/n) from 1 to n-1 ) +  ( 1/n * 1/(m+1) )
            (n-1)/n + 1/n * 1/(m+1) == 1 (almost)
</code></pre>

<p>As n is large, the (n-1)/n is very close to 1 so that we maximize the probability to get a red balls.  </p>

<p>Any better ideas ? </p>
",probability
"<p>Suppose you ﬂip a fair coin repeatedly until you see a Heads followed by a
Tails. What is the expected number of coin ﬂips you have to ﬂip?</p>

<p>By manipulating an equation based on the result of the first flip, shown at this link:</p>

<p><a href=""http://www.codechef.com/wiki/tutorial-expectation"">http://www.codechef.com/wiki/tutorial-expectation</a></p>

<p>the answer is 6. This also makes sense intuitively since the expected value of the number flips until HH or TT is 3. But is there a way to tackle this problem by summing a series of probabilities multiplied by the values?</p>

<p>Thank you!</p>
",probability
"<p>If there is an 82% chance that within your average lifetime, lets assume 70 years (25567 days), that ""E"" event will happen: what is the percent chance that it will happen on any given day?
<br><br>I'm assuming that it'll be something like .02347% or something small. My problem is I've only taken up through Advanced Algebra and that was six years ago. I would have searched for this on google to solve it myself, but I'm not even sure what to call this beyond ""math I don't know"". 
<br><br>So if you could help me identify the solution, how to solve it, and what this is (i.e. I imagine terms like 'graphing polonomials' 'deductive statistics' or some such name that would give me an idea of what exactly it is that I should be learning to handle similar questions on my own). Thanks for the help in advance.</p>
",probability
"<p>I am trying to show that the stationary distribution for a Markov Chain on a continuous state space can be obtained by building a transition density kernel, which obeys the detailed balance rule where $P_{t+1|t}(X_{t+1}=i|X_{t}=j)P_{t}(X_{t}=j) = P_{t+1|t}(X_{t+1}=j|X_{t}=i)P_{t}(X_{t}=i)$. The Markov Chain is time-homogeneous so $P_{t+1|t}(X_{t+1}=i|X_{t}=j)=T(X_{t+1}=i|X_{t}=j)$ is independent of time step $t$ and $T$ is the continuous transition kernel (density kernel). I suppose that the distribution at the time $t$ is the stationary distribution $\pi$, which is $P_{t}(X_{t}=i) = \pi(i)$ and I aim to show that $P_{t+1}(X_{t+1}=i) = \pi(i)$ given the detailed balance.</p>

<p>I am currently proving this already but I am not sure whether my way of proof is mathematically valid.</p>

<p>Here is what I am doing:</p>

<p>1) I calculate $P_{t+1}(X_{t+1}=i)$ as $P_{t+1}(X_{t+1}=i) = \int_{-\infty}^{\infty} P_{t+1|t}(X_{t+1}=i|X_{t})P_{t}(X_{t})dX_{t} = \int_{-\infty}^{\infty} P_{t+1,t}(X_{t+1}=i,X_{t})dX_{t}$</p>

<p>2) According to the detailed balance, for each $i,j \in \mathbb{R}$, it is $P_{t+1|t}(X_{t+1}=i|X_{t}=j)P_{t}(X_{t}=j) = P_{t+1|t}(X_{t+1}=j|X_{t}=i)P_{t}(X_{t}=i)$. This means that the joint distribution function is symmetrical: $P_{t+1,t}(X_{t+1}=i,X_{t}=j) = P_{t+1,t}(X_{t+1}=j,X_{t}=i)$. Here, I think about the joint distribution as an uncountable sized, symmetric matrix. Therefore the integration over the row ""belonging"" to $X_{t+1}=i$ is equal to the integration over the column ""belonging"" to $X_{t}=i$. According to this logic it must be $P_{t+1}(X_{t+1}=i) = \int_{-\infty}^{\infty} P_{t+1,t}(X_{t+1}=i,X_{t})dX_{t} = \int_{-\infty}^{\infty} P_{t+1,t}(X_{t+1},X_{t}=i)dX_{t+1} = P_{t}(X_{t}=i)$.</p>

<p>3)Since $P_{t}(X_{t}=i) = \pi(i)$ we have that $P_{t+1}(X_{t+1}=i) = \pi(i)$ and this ends the proof.</p>

<p>The part 2 is where I am feeling uneasy about my way of proof. I know that the symmetry induced on the joint distribution of consecutive random variables must yield the change of integration variables in the step 2 as valid. This is indeed the case, if we had a finite state space Markov Chain. The joint distribution would be a finite sized matrix and the symmetry would immediately tell that the $i$th row and $i$th column are equal. But I am not comfortable with this way of thinking on a continuous state space, mainly because of my shallow mathematical background.</p>

<p>What would be a more mathematically rigorous way to show that the step 2 is correct? How should we show that integrals in the step 2 are equal to each other?</p>

<p>Thanks in advance.</p>
",probability
"<p>How to evaluate $$\frac{\Gamma\left(\frac{n}{2}\right)}{\Gamma\left(\frac{n-1}{2}\right)}$$, where n is integer > 0?</p>

<p>I know the gamma function formula will give</p>

<p>$$ \frac{(\frac{n-2}{2})!}{(\frac{n-3}{2})!}$$ How to simplify it?</p>
",probability
"<p>We say that a graph $G$ is distributed with $\mathcal{G}_{n,p}$ if it is a graph on $n$ vertices, and for which each of the ${n\choose 2}$ possible edges is chosen independently of the other edges and with probability $p$.</p>

<p>A <em>monotone property</em> $P$ of a graph is a set of graphs (on $n$ vertices) that is closed from above (that is, if $G\in P$ and $G\subseteq H$ then $H\in P$.</p>

<p>A function $f(n)$ is said to be a <em>threshold</em> for a property $P$ if for any $p(n)=\omega(f(n))$, $G\sim\mathcal{G}_{n,p}$ has $P$ asymptotically almost surely (a.a.s.), and for any $p(n)=o(f(n))$, $G\sim\mathcal{G}_{n,p}$ does not have $P$ a.a.s.</p>

<p>For example, if $P$ is ""has a triangle as a subgraph"", then $P$ is clearly monotone, and $f(n)=n^{-1}$ is a threshold for $P$. $f(n)=\frac{\ln{n}+\ln\ln{n}}{n}$ is a threshold for the Hamiltonicity property (in a stronger sense).</p>

<p><strong>My question is this:</strong> what are the thresholds for the properties of having ""quite short"" paths or cycles? By ""quite short"" I mean of length $\Theta(n^\varepsilon)$ for some $0&lt;\varepsilon&lt;1$, or of length $\Theta(\ln{n})$.</p>
",probability
"<p>We have $11$ bins with $10$ objects each. Every object is either black or white, and the $i$th bin ($1 \le i \le 11$) has precisely $(i -1)$ black objects in it. Someone selects, uniformly at random, one of those bins and then selects, also uniformly at random, two objects from it. What is the probability that these two objects are of the same color?</p>
",probability
"<p>The chances of being born with a certain disease are estimated as $1$ in $1200$. What is a good estimate of the chance that an island with $10000$ inhabitants has precisely $8$ people born with that particular disease? We assume that all $10000$ events of being born with that particular disease are mutually independent.</p>
",probability
"<p>Is it true that for continuous distribution $$E(X^a) =  \int_{-\infty}^{+\infty} x^a\cdot g(x)dx $$ where $g(x)$ is probability density function?</p>
",probability
"<p>If I have two events that occur on a specific interval (one every 8 seconds, the other every 200 milliseconds) but were not started synchronously, how can I calculate the frequency with which these two events will occur at the same time?</p>

<p>Looking at the numbers, it seems that unless they start synchronously, they will <em>never</em> coincide. If they started synchronously, in a perfect world, it would be every 8 seconds.</p>

<p>Obviously there is some variation/imperfection because they <em>do</em> coincide occasionally despite not starting at the same time.</p>

<p>I suppose I am looking for a harmonic, or additive function. Forgive me, my math knowledge is lacking.</p>
",probability
"<p>Is it</p>

<ul>
<li>The number of failures BEFORE the first success OR</li>
<li>The number of trials required to get a first success?</li>
</ul>

<p>Also, if I was to work out the expected value of a geometric random variable, say $p = 0.25$ (Expected value = $3$), does that mean that I will have $3$ failures AND THEN a success, or $2$ failures and then a success??</p>

<p>I would immensely appreciate some help here.
Thank you so much x</p>
",probability
"<p>The urn consists 4 balls (black and white) with at least 1 white. Two randomly drawed balls were both white. What it the probability of getting white ball again?</p>

<p>My solution:</p>

<pre><code>balls(w/b)    || 4:0  | 3:1  | 2:2  | 1:3  | 0:4
P(prior)      || 1/15 | 4/15 | 6/15 | 4/15 | 0/15
P(2w|prior)   || 1    | 1/2  | 1/6  | 0    | 0
P(posterior)  || 1/4  | 1/2  | 1/4  | 0    | 0
P(w|posterior)|| 1    | 1/2  | 0    | 0    | 0

P(w) = ∫P(w|u) P(u) du = 1 * 1/4 + 1/2 * 1/2 + 0 * 1/4 = 1/2
</code></pre>

<p>But the answer is $7/12$. Where have I made a mistake?</p>

<p>The prior was assumed:</p>

<pre><code>balls(w/b)    || 4:0 | 3:1 | 2:2 | 1:3 | 0:4
P(prior)      || 1/8 | 3/8 | 3/8 | 1/8 | 0/8
</code></pre>

<p>Meaning the first ball was white and all others were decided by coin toss. However, I think the original formulation does not correspond to this problem and should be replaced with something like: </p>

<pre><code>In an urn with a white ball one puts another 3 balls ...
</code></pre>
",probability
"<p>Let there be $2$ urns containing $a$ white, $b$ black balls and $c$ white, $d$ black balls respectively.Everytime a ball is drawn at random from the first urn  and is transferred to the second and similarly a ball from the second urn is transferred to the first urn , both events taking place  simultaneously at a particular moment.After n such operations, a ball is randomly selected from the first urn .Find the probability that it is white.</p>

<p>{Inspired by a problem of J.V. Uspensky}</p>
",probability
"<p>Let N denote the number of automobile accidents on a given stretch of interstate
highway over a specific period. It is known that N has the geometric distribution with pmf </p>

<p>$f_N(n)=x(1-x)^{n-1}$, $n=1,2,3,...$ </p>

<p>where x is bounded between 0 and 1, $0&lt; x&lt; 1$ </p>

<p>for the ith accident $Y_i=1$ if accident contains a fatality, </p>

<p>$Y_i=0$ if no fatality,</p>

<p>for each i, $P(Y_i=1)=p$, each $Y_i$ is independent</p>

<p>Let T be the total number of accidents with at least one fatality. </p>

<p>Then, $T=Y_1 + Y_2 +...+Y_N$</p>

<p>Find $E(T)$ and $Var(T)$,
I was thinking that since each $Y_i$ is bernoulli that is dependent on N then sum of each $E(Y_i)$ is $Nxp$ and the variance would be summing $p(1-p)$ which is $Npx(1-px)$</p>

<p>Maybe this is $E(T)=E(E(T|N))=\frac{p}{x}$ then $Var(T)=...$</p>

<p>Find $Corr(N,T)$=
$\frac{E(NT)-E(N)E(T)}{sd(T)sd(N)}$</p>

<p>Find $P(T=0)$</p>

<p>I seem to be missing something in my analysis that would lead me to get the rest of the problem</p>
",probability
"<p>Every night, different meteorologist gives the probability of rain for the next day. To judge their predictions, we use the following scoring system: if a meteorologist predicts rain with the probability $\color{blue}{p^*}$ and is right, that meteorologist receives a score of $1-(1-p)^2$; if wrong, they receive a score of $(1-p)^2$. After a while we will be able to know which meteorologist is the best. Assumming one meteorologist knows the scoring system, what is the best way for them to maximise their expected value?</p>

<p>I know they probably should predict with a 50% accuracy everytime because that is where both fucntion intersect but what is the formula i should use to get to the right answer?</p>
",probability
"<p>I've been trying to answer this question for the past few days, and I'm absolutely stuck. Without further ado, here's the mystery:</p>

<p>We are given a pair of boxes. There are n red balls in box number 1, and n blue balls in box number 2. Every turn, a ball is randomly taken out of the first box, and not returned. After the ball is taken out, a blue ball from the second box is inserted into the first one. This continues until there are no more blue balls to be transferred from box 2 to box 1. That means that there are n+1 turns in which a ball is randomly taken out of box 1. </p>

<p>I am asked to find the probability that the last ball taken out of box 1 (which means in the (n+1)-th turn) is red. Here's what I've got so far:</p>

<p>Event A - the ball taken out of box 1 in the last turn is red.</p>

<p>Event B(i) - i red balls were left in box 1 after n turns.</p>

<p>I'm trying to find P(A). Bayes wasn't helpful, and the law of total probability was not useful as well, since I can't seem to know what P(B(i)) is for any given i (other than, of course, i=0 and i=n-1). I did find a two-dimensional recursive function for P(B(i)), but that doesn't seem to be the right solution. </p>

<p>Any thoughts about how to properly approach (and hopefully solve) this question would be highly appreciated. </p>
",probability
"<p>Suppose we flip 10 times an unfair coin that fall a probability of $p$ on 'heads'. Knowing that we obtained 'heads' 6 times out of the 10 flips, find the conditionnal probability of the first three flips being heads, tails, tails.</p>

<p>My effort: Since we don't know the exact probability of getting heads i would think it would be somthing like:</p>

<p>A: Probability of getting 6 'head' out of 10
B: Probability for the first 3 flip to be 'heads''tails''tails'</p>

<p>$A:\binom{10}{6}(p)^6(1-p)^4$</p>

<p>$B:p(1-p)^2$</p>

<p>$(B|A):???$</p>

<p>Any help to point me in the right direction would be greatly appreciated.</p>

<p>Thank you.</p>
",probability
"<p>Suppose we have a set of $b^n$ different numbers. Every time we randomly choose a number from this set and put it in a list of length  $b^\frac  n2$.
So we want to fill this list with unique numbers. However every time we choose a number we place it back to the set, giving it another chance to be selected. of course we would like numbers on our list be unique so I guess the probability to have a list of unique numbers is:</p>

<p>$\prod_{i=0}^{b^\frac n2 -1} \left(\frac{b^n-i}{b^n}\right)$</p>

<p>With sufficiently large $n$ and regardless of base $b$, computer analysis shows that it converges into 0.606 but I cannot fathom the reason. I wonder if someone can show me how this happens.</p>
",probability
"<p>I have a circle iwth radius $r$. I want to test the hypothesis that $r \leq 2$ vs. $r &gt;2$ based on the posterior of $r$. $r$ follows the prior distribution: $f(r) = \frac{2}{r^{2}}$, $ r &gt;0.5$. I observed the following points $(x,y): (1,3), (2,1), (0.5,1.4)$. My question is What should be the likelihood?</p>

<p>Edited:
The center of the circle is (0,0)</p>
",probability
"<p>I have a large set $S$ of items, but the set is not exactly known. All I know are the cardinal numbers of <em>categories</em> i.e. a number of disjoint subsets, </p>

<p>$ \vert{S_1}\vert \dots \vert S_n\vert$ with $\bigcup S_i = S$. </p>

<p>Thus I also know the cardinal number $\vert S\vert = \sum\vert S_i\vert$.</p>

<p>I then want to apply a predicate $p$ and estimate the cardinal number of the subset of $T \subset S$ which satisfies $p$, i.e. </p>

<p>$\vert T\vert = \vert \lbrace x\in S \mid p(x)\rbrace\vert$. </p>

<p>The predicate $p$ is precisely known and so are the predicates $p_i$ which need to be satisfied to fall into one of the categories $S_i$ (the ""meanings"" of $S_i$ are known).</p>

<p>In other words, I want to describe a large set with a few numbers $ \vert{S_1}\vert \dots \vert S_n\vert$, which still contain enough information, so I can estimate the cardinal number of the result of the filtering with $p$. I am willing to do a costly transformation on $p$ as long as the final computation of $\vert T\vert$ is fast.</p>

<p>I have the feeling that this is a textbook problem, but I don't know where to look for ideas. </p>

<ul>
<li>I don't know how to do this at all, and </li>
<li>I don't know what is the best way to define $p_i$. </li>
<li>What happens when my $S_i$ are not disjoint? Can I still say <em>something</em> about $\vert S\vert$ and $\vert T\vert$?</li>
<li>I suppose the more $p_i$s I have, the better the estimate will be, but I'd like to be be able to say something quantitatively about the accuracy.</li>
</ul>
",probability
"<p>Let $n$ be a positive integer. Suppose $a$ and $b$ are randomly (and independently) chosen two $n$-digit positive integers which consist of digits 1, 2, 3, ..., 9. (So in particular neither $a$ nor $b$ contains digit 0; I am adding this condition so that division by $b$ will be possible, and that we don't get numbers of the form $0002$ and so on). Here ""randomly"" means each digit of $a$ and $b$ is equally likely to be one of the 9 digits from $\{1,2,3,..., 9\}$. </p>

<p>My question concerns the divisibility of these integers:</p>

<blockquote>
  <p>1) What is the probability that $b$ divides $a$ ?</p>
</blockquote>

<p>The answer, of course, will depend on $n$. Denote this probability by $p(n)$. I would be happy with rough estimates for $p(n)$ as well :)</p>

<blockquote>
  <p>2) Is it true that $p(n)\to 0$ as $n\to\infty$?</p>
</blockquote>

<p>I think answer to question 2) is yes (just by intuition). </p>
",probability
"<p>Let $X_1, \ldots, X_n$ be a collection of random variables. Consider the directed graph with vertex set $\{ 1, 2, \ldots, n \}$ where there is a directed edge $i \to j$ if $\mathbb{P}(X_i &gt; X_j) &gt; \frac{1}{2}$. </p>

<p><strong>Question 1:</strong> What directed graphs can arise in this way? Certainly they must be simple and have no loops. Is that the only restriction? Alternatively, $\mathbb{P}(X_i &gt; X_j) &gt; \frac{1}{2}$ defines an irreflexive antisymmetric relation on $\{ 1, 2, ... n \}$. Which such relations arise in this way? </p>

<p><strong>Question 2:</strong> Does the answer change if we require the $X_i$ to all be defined on a finite sample space? </p>

<p><strong>Question 3:</strong> What if we require the $X_i$ to be independent? </p>

<p>It is known (see <a href=""http://en.wikipedia.org/wiki/Nontransitive_dice"">nontransitive dice</a>) that this graph can have directed cycles even if the $X_i$ are independent; in particular, the corresponding relation need not be transitive. </p>
",probability
"<p>Assume that we have a biased coin with probability $p_1$ of getting H and $1−p_1$ of getting T on the first trial, $p_2$ of getting H and $1−p_2$ of getting T on the second trial and so on such that
$2/3&lt;p_1&lt;p_2&lt;p_3...&lt;p_n&lt;1$. The probability $p_i$ of getting H increases as long as we get head in a row. If a tail appears, then we reset to probability $p_1$ of getting H in the next trail and so on.  </p>

<p>What is the expected number of trials to get $n$ H in a row?</p>
",probability
"<p>If a particle performs a random walk on the vertices of a cube, what is the mean number of steps before it returns to the starting vertex S? What is the mean number of visits to the opposite vertex T to S before its first return to S and what is the mean number of steps before its first visit to T?</p>

<p>Nobody ever explained random walks to me, so I find it all very odd right now. Maybe someone can explain how to handle these problems or you can link me to a site where these kinds of problems are explained well? Thanks a lot!</p>
",probability
"<p>If U has a $\chi^2$ distribution with v df, find E(U) and V(U).</p>

<p>By definition, $E(U)
=\int^{\infty}_{0} u\frac{1}{\gamma(\frac{v}{2})2^\frac{v}{2}}u^{\frac{v}{2}-1} e^\frac{-u}{2}\,du 
=\int^{\infty}_{0} \frac{1}{\gamma(\frac{v}{2})2^\frac{v}{2}}u^\frac{v}{2} e^\frac{-u}{2}\,du$.</p>

<p>How do I integrate this?</p>

<p>Note: This isn't a homework problem.</p>
",probability
"<p>Recently I took a Master's-level class on probability. I was very interested in the material, but the class itself was average. It used a textbook which I didn't care for (by Grimmett and Stirzaker). I've been looking for another text on probability to deepen my knowledge. I am familiar with measure theory, so I am fine with a book that employs it.</p>

<p>I am looking at Feller's book <em><a href=""http://rads.stackoverflow.com/amzn/click/0471257087"" rel=""nofollow"">An Introduction to Probability</a></em>, which seems to be well-regarded. I really like the examples and the way the material is covered. One thing I'm concerned about is that the book does not seem to involve measure theory. </p>

<p>How much of the soul of probability will I be missing if I read a book which covers it from non-measure-theoretic perspective? Will I have to consult another resource if I want to really understand the heart of what's going on?</p>

<p>Perhaps I should use Feller to become acquainted with the basics of probability theory, and supplement it by referring to a more theoretical text for the ""real"" proofs of certain theorems?</p>
",probability
"<p>Suppose a random walk on an infinite line $[...-3,-2,-1,0,1,2,3,...]$, starting from 0. Probability to go right or left are equal. 
Does such a process stationary?
I think that it is NOT, since the support of each step is different. I.e., $x_1\in{\{-1,1\}},  x_2\in{-2,0,2}, ...$. 
Thanks.</p>
",probability
"<p>Let a stochastic process defines as:
$$X(t+1)=A X(t)+B U(t)$$
with: $X(t) \in R^n$, $U(t) \sim N(0,Q_t)$, $Q_t$ semi-positive-definite of size $n \times n$, $X(0) \sim N(0,W_0)$, $A$ of size $n \times n$, $B$ of size $n \times n$.</p>

<p>Is there any condition on $A$ and $B$ to state the existence and the form of the conditional pdf $p_{X_t|X_{t-1}}(x_t|x_{t-1})$?</p>

<p>Thanks in advance.</p>
",probability
"<p>Let $X\geqslant 0$ be a random variable. Then, we have</p>

<p>$$\mathcal{E}(X)=\int_0^\infty P(X&gt;t)dt$$</p>

<p>(provided $\mathcal{E}(X)$ exists).</p>

<p>Suppose we have a finite data set $\{(d_1, a_1), \ldots, (d_n, a_n)\}$ consisting of pairs or real numbers where $d_i$ stands for a level (height) of some vessel and $a_i$ is the area of the surface of the vesel at level $d_i$.</p>

<p>How can I apply the above mentioned formula to calculate the (expected) capacity of the vessel?</p>
",probability
"<p>Let $X,Y$ random variables with $Y$ real valued. I was wondering if any inequality of the type: 
\begin{equation}
\mathbb{E}[f(X,Y)] \leq g \left[\sup_{\displaystyle s \in \mathbb{R}} \mathbb{E}[f(X,s)] \right]
\end{equation}</p>

<p>exists, where $g$ is some function. It seems very wrong at first sight, but I was wondering if you knew something of this type.</p>
",probability
"<p>Assume ""standard"" bingo (75 numbers) with the columns ranging the following inclusive ""semi-random"" values B: 1 to 15, I: 16 to 30, N: 31 to 45, G: 46 to 60, O: 61 to 75. By semi-random I mean restricted to a small range (15 at a time).  There is a free space in the middle of the 5x5 playing board.  Numbers (from 1 to 75 inclusive) are randomly drawn one a time without replacement (without any repeats in each game) and with equal probability of being drawn.  A win (Bingo) is defined as a completed line segment of 5 adjacent squares made only from the drawn numbers but which may include the free space (and must include it if it is beneficial).  A bingo card has 25 of these board squares arranged in a 5x5 matrix.</p>

<p>So my question is if there are 20 players, each with a unique playing card (randomly generated by computer out of I think 552 septillion possible playing cards), what are the chances/probability that 2 or more players will get Bingo on the same drawn number?.  For example, someone could win bingo with as few as 4 drawn numbers but likely it would take much more.  So I am asking if balls are drawn until at least one person wins, what are the chances that at least 2 people will win at the same time?  The game is considered finished / decided when there is at least 1 winner for that game.  You can assume that all players are good enough not to make any mistakes (not true in real bingo but assume here).</p>

<p>I am not sure how to set this up mathematically and because there are so many possible bingo cards, computer simulation of all of them is not a good idea.  Perhaps what can be done with simulation is to first simulate 20 legitimate bingo cards (out of 552 septillion), and then have the computer draw one random number at a time until we have at least 1 winner.  Do this for maybe 1 million trials and count how many have simultaneous multiwinners.  For example, after 11 balls drawn there are no winners yet for that game but on the 12 drawn ball, there are 2 or more winners.  I would like to know how often the multiwinner situation occurs.</p>

<p>I could probably do the simulation with a fair amount of work but wanted to know if this problem can be done mathematically or if is too difficult to set up.</p>

<p>One concern I see is that if one card has for its first column (the B column), from top to bottom, 1, 4, 7, 10, and 15 and some other card has for column B (also from top to bottom), 15, 10, 7, 4, and 1 in that order.  Problem there is even though the cards have different order for the B column numbers, if those 5 numbers are drawn, both players may win at the same time.  So my point is it makes a difference if we say (or not) that multiple bingo cards cannot have the same exact 5 numbers in a row, column, or diagonal but just in a different order.  That might be an interesting problem in itself to figure out how many fewer ""legit"" bingo cards there are with that constraint so someone could comment about it but the actual question is about the multiwinner probability.  I think the answer to the no permutation bingo card restriction is about 111 quadrillion legit bingo cards.</p>
",probability
"<p>I am trying to prove that if F is a cdf with finite right extreme ($\tau &lt; \infty $), then $G=F(\tau - 1/x) , x&gt;0$ is a cdf on $(0,\infty)$. For one of the steps:
$$
\lim_{x \to 0} F( \tau - 1/x)
$$
and this should be equal to zero. Intuitively $-1/x$ goes off to $-\infty$ so the limit should be $F(-\infty) =0$ but should I be making another step first? or does the jump make sense?</p>
",probability
"<p>John and Mary arrive under the clock tower independently. Let X be John's arrival time and let Y be Mary's arrival time. If John arrives first and Mary is not there then he will leave. If Mary arrives first then she will wait up to one hour before leaving. John's arrival time, X, is exponentially distributed with mean of 1. Mary's arrival time has density $f(y) = {2y\over 9}$, $0≤y≤3$. Calculate the probability they will meet. </p>

<p><strong>What I've tried.</strong> </p>

<p>I figured this problem should be the summation of two probabilities. The probability that Mary arrives before John + The probability that John arrives within an hour of Mary. </p>

<p>the joint distribution is $f(x,y) = {2y\over 9}e^{-x}$, therefore the first probability could be written as $P[X&gt;Y]$ of the joint distribution. </p>

<p>$$\int_0^3 \int_0^y f(x,y) dxdy$$</p>

<p>this gives the answer of .822, which is well above the answer given in the book of .1125, without the second probability even being found. </p>

<p>I'm not even sure how to set up the limits for the second probability.  </p>

<p>Any help would be appreciated. </p>
",probability
"<p>If I have that $\limsup_{n}E|X_n|^{r} \leq E|X|^{r}$, is that enough to show that $\{|X_n|^{r}:n\geq 1\}$ is uniformly integrable? I am not sure here if the limsup condition here is as strong as if I had a uniformly bound. Does anyone have any hints as to how I can work with such a definition? Thanks.</p>
",probability
"<p>Even before attempting the problem, I immediately defaulted to an answer: $\frac{1}{2}$.</p>

<p>I thought that this was a possible answer since the probability of flipping a head on one flip is definitely $\frac{1}{2}$.</p>

<p>I then worked through the problem:</p>

<p>Let E be the event in the problem statement.</p>

<p>The total number of possible outcomes of $10$ coin flips: $N = 2^{10}$</p>

<p>The total number of ways in which E can result:for $n=10,r=5, nCr= 252$</p>

<p>$P(E) =\frac{n}{N} = .246$</p>

<p>How do I correct my intuition?</p>
",probability
"<p>I met an interesting but challenging problem in my homework:</p>

<p>Suppose $n-1$ independent points $x_1$, $x_2$, ..., $x_{n-1}$ are uniformly distributed on unit interval [0,1]. These $n-1$ points seperate the unit interval into $n$ pieces. Suppose the lengths of these $n$ intrvals are $v_1$, $v_2$, ..., $v_n$. What is the probablity that $v_i &lt; a$ for $i = 1,2,...,n$ ?
Here $1/n &lt; a &lt; 1$ is a constant.</p>

<p>The joint distribution of $v_1$, $v_2$, ..., $v_{n-1}$ is a uniform distribution on a $n-2$ dimention simplx with $f(v_1, v_2,...,v_{n-1}) = (n-1)!$. The simplex is
$$v_i \geq 0, \; i=1,2,...,n-1$$
$$v_1 + v_2 + ... + v_{n-1} \leq 1$$
The proof of this density distribution is not easy.</p>

<p>I followed this idea but I found it's still hard. Maybe there are some other starting points to consider this problem.</p>
",probability
"<blockquote>
  <blockquote>
    <p>Consider the situation of decoding a 6-digit password that consists of the symbols A to Z and 0 to 9, where all possible combinations are tried randomly and uniformly. </p>
  </blockquote>
</blockquote>

<p>Consider the following decoding method: At first a combination is chosen randomly and uniformly. At the next trial a digit from this combination is chosen uniformly at random and its entry is substituted by a uniformly randomly chosen element from $\left\{A,...,Z,0,...,9\right\}$. This procedure is repeated until the password is found. </p>

<p>(a) What is the probability that the correct password will never be entered?</p>

<p>(b) What is the probability that eventually the same combination will be entered two consecutive times?</p>

<hr>

<p>I already asked how to get the anwers to (a) and (b) without using the here mentioned special decoding method and I got great help, see <a href=""http://math.stackexchange.com/questions/1012075/probability-concerning-a-6-digit-password"">Probability concerning a 6-digit password</a>.</p>

<p>Now I have to answer (a) and (b) using the decoding method and again I have enormous problems! Combinatorical thoughts are not my favourite business. Nevertheless I tried to find the probabilities in an analog way as it was shown to me in the linked thread. </p>

<p>Additionally, <em>I wonder if this task now maybe has something to do with Markov chains</em> because the lecture this task is from is about Markov chains.</p>

<hr>

<p>I think there are (at least) the two following ways to understand the described decoding strategy, which sense is meant?</p>

<p><strong>Sense 1</strong> <em>We choose (randomly and uniformly) one of the $36^6$ possible combinations. If it is the right, we stop. Otherwise we then choose (randomly and uniformly) one of the 6 digits and substitute it (randomly and uniformly) by a symbol out of the alphabet. Then we choose (randomly and uniformly) one of the remaining 5 digits and subtitute it and so on until we substituted all the 6 digits. If this was the right password, we stop. If not, we again start substituting the 6 digits (the digits of the combination that we chosed at the beginning, that is, we stick to this combination).</em></p>

<p><strong>Sense 2</strong> <em>Same as above with the difference that after we substituted all 6 digits and saw that it is the wrong password, we choose (randomly and uniformly) another combination out of the $36^6$ possibilities (it can be the same as before) and then substitute the digits of this new combination.</em></p>

<p><strong>I think that sense 1 is meant and thus I considered the task in this sense.</strong></p>

<p><strong>(a)</strong> Anyway, my result here is $0$, because as far as I see the probability not to have reached the right password after n passages is
$$
\left(1-\frac{1}{36^6}\right)\cdot\left(1-\prod_{k=1}^6\frac{1}{k\cdot 36}\right)^n
$$
and this tends to $0$ as $n\to\infty$.</p>

<p><em>Remark</em>: If we decode without this special method (see the linked thread) then the probability of (a) is 0, too.</p>

<p><strong>(b)</strong> The probability that we have eventually one pair of consecutive equal guesses is - to my results - 
$$
\sum_{n=0}^{\infty}\left(1-\frac{1}{36^6}\right)\cdot\left(\prod_{k=1}^6\frac{35}{k\cdot 36}\right)\cdot\left(\prod_{k=1}^6\frac{34}{k\cdot 36}\right)^n\left(\prod_{k=1}^6\frac{1}{k\cdot 36}\right)
$$</p>

<p><strong>Edit</strong></p>

<p>I think my last result for <strong>(b)</strong> was <em>not</em> correct, I think instead it has to be
$$
\sum_{n=0}^{\infty}\left(1-\frac{1}{36^6}\right)\cdot\left(1-\prod_{k=1}^k\frac{1}{k\cdot 36}\right)\cdot\left(1-\prod_{k=1}^{6}\frac{2}{k\cdot 36}\right)^n\cdot\left(\prod_{k=1}^{6}\frac{1}{k\cdot 36}\right).
$$</p>

<p>If I know compute the geometrical series and use that $1-\prod_{k=1}^{6}\frac{1}{k\cdot 36}\approx 1$, then I get that (with $p:=\frac{1}{36^6}$) the probability of (b) is
$$
\approx \left(\frac{1}{2}\right)^6\cdot (1-p)
$$</p>

<p><em>Remark</em>: When decoding without this method (see the linked thread) then the probability of (b) is $\frac{1}{2}\cdot (1-p)$. That is, using the method, if my result is correct, we have a much smaller probability for (b). So this decoding method is more efficient.</p>

<hr>

<p>Would be great to get a feedback from you to know if I am right. And, as mentioned, I am interested to know if the task has something to do with the context of Markov chains.</p>

<p>Ciao &amp; greetings</p>

<p>Salamo</p>
",probability
"<p>I am working through Hamming's <em>The Art of Probability</em> and am having trouble with a problem in the Bernouilli Trials section. The wording is the following</p>

<blockquote>
  <p>Expand the binomials in the probabilities of 0, 1, 2, and 3 occurrences, and show that the expansions cancel out to the next term provided $np \lt 1$. Hence if $np \ll 1$, the first term neglected in the expansion is close to the exact result for 4 or more events.</p>
</blockquote>

<p>I am assuming that the solution should give something like $\sum_{k = 0}^{3}B(k; n, p) = np + \mathcal{O}\left [(np)^4 \right ]$ but I can't actually get anything that cancels to the first order.</p>

<p>Using the recursion relation of Bernouilli trials, $B(k+1; n, p) = \frac{n - k}{k+1}\frac{p}{q}B(k; n,p)$, I get</p>

<p>$$(1 - p)^n \left (1 + \frac{np}{q} + \frac{n(n-1)}{2}\frac{p^2}{q^2} + \frac{n(n-1)(n-2)}{6}\frac{p^3}{q^3} \right)$$</p>

<p>Expanding this and keeping the terms 0th and first order in $np$ yields</p>

<p>$$(1-p)^n \left (1 - \frac{1}{6}\frac{6 p^3 -29 p^2 + 33 p - 12}{(1-p)^3} + \mathcal{O}\left [(np)^2 \right ]\right )$$</p>

<p>Am I misunderstanding the question? I expected the second term to cancel.</p>

<p><strong>Edit:</strong> I guess one could use the expansion for $\exp (-np) \approx \left ((1-p)^{\frac{1}{p}} \right )^{-np}$ and then expand it in a Taylor series, $\exp (-np) = 1 - np + \frac{(np)^2}{2} - \frac{(np)^3}{6} + \mathcal{O}\left [(np)^4\right ]$. This matches the terms of the form $(np)^k$ and they do have the opposite signs, but I don't quite understand why you can get away with ignoring the $q$ in the denominator. That is,</p>

<p>$$\begin{eqnarray}
&amp; \exp (-np) + \frac{np}{q} + \frac{n(n-1)}{2}\frac{p^2}{q^2} + \frac{n(n-1)(n-2)}{6}\frac{p^3}{q^3} \\ 
\approx &amp; 1 - np + \frac{(np)^2}{2} - \frac{(np)^3}{6} + \frac{np}{q} + \frac{n^2p^2}{2q^2} + \frac{n^3p^3}{6q^3} + \mathcal{O}\left [(np)^4\right ]\\
\approx &amp;1 + \mathcal{O}\left [(np)^4\right ] ?
\end{eqnarray}$$</p>
",probability
"<p>The hydrocarbon emissions are known to have decreased dramatically during the 1980s.</p>

<p>A study was conducted to compare the hydrocarbon emissions at idling speed, in parts per million (ppm), for automobiles of 1980 and 1990. Ten cars of each year model were randomly selected and their hydrocarbon emission levels were recorded. The data are as follows:</p>

<p>1980 models: 295 545 236 388 290 152 391 291 132 206</p>

<p>1990 models: 281 279 212 157 241 121 275 134 139 217</p>

<p>Assume that the hydrocarbon emission levels are normally distributed.</p>

<p>(a) Conduct a hypothesis test (by specifying the critical region) about the variability in hydrocarbon emission of cars of 1980 versus 1990. Use a 0.10 signiﬁcance level.</p>

<p>(b) Conduct a two-sided hypothesis test (by specifying the critical region) to compare the means of the hydrocarbon emission level of cars of 1980 and 1990 models. Use a 0.10 signiﬁcance level.</p>

<p>(c) Compute (or give bounds to) the p-value for the test in (b).</p>
",probability
"<p>A roulette from a casino contain 18 red cases, 18 black cases and 1 green cases. A player shows up with $10$dollars. He decides to bet $1$dollar on red 10 consecutives times. If it's red, he wins a dollar and if not he loses his dollar. Let $S$ be the the amount of money the player has after 10 bets. Find the value $S$ can have, then calculate $P(S&lt;3|S\leq18)$.</p>

<p>So the value S can take is every natural numbers $0\leq S\leq20$</p>

<p>but after that I'm confused on how to proceed. I guess we could do it using a density function but i don't know how.</p>

<p>Any help to point me in the right direction would be greatly appreciated.</p>

<p>Thank you.</p>
",probability
"<p>In the book, ""A Practical Guide to Quantitative Finance Interviews"", the following question is posed on page 75:</p>

<blockquote>
  <p>Jason throws two darts at a dartboard, aiming for the center.  The second dart lands farther from the center than the first.  If Jason throws a third dart aiming for the center, what is the probability that the third throw is further from the center than the first?  Assume Jason's skillfulness is constant.</p>
</blockquote>

<p>At first glance, it seems the second throw is irrelevant - since his skillfulness is constant, the second throw in no way influences his third throw.  Furthermore, it seems like this question can only be answered in terms of the distance from the center of the first toss.  Indeed, denote this distance by $D_1$.  Then assuming the area of the dart board is $1$, the probability that the third throw is further than the first is just the area of the annulus, which is given by $1 - \pi D_1^2$.</p>

<p>However, the solution given in this text is $\frac{2}{3}$, which is arrived at by enumerating the possible outcomes.  Let $D_i$ be the distance of the $i$th throw.  Then the possible outcomes assuming the second throw is further than the first are:
$$
D_3 &lt; D_1 &lt; D_2 \\
\boxed{D_1 &lt; D_3 &lt; D_2} \\
\boxed{D_1 &lt; D_2 &lt; D_3}
$$</p>

<p>The two boxed outcomes satisfy our event in question, so the probability must be $\frac{2}{3}$.  But, this seems to be answering a different question, namely,</p>

<blockquote>
  <p>What's the probability the third throw is not the best out of three, given the second throw is worse than the first?</p>
</blockquote>

<p>Are the two block-quoted questions really asking the same thing, and I've misunderstood the first one?</p>
",probability
"<p>If $A \sim N (\mu, \frac{1}{a})$ and $B \sim N(0, \frac{1}{b})$, and $S = A + B$, then what is
the distribution of $A$ given $S=s$? Assume $A$ and $B$ are independent.</p>
",probability
"<p>Let $X(t)$ be a stationary Gaussian process with mean $\mu$, variance $\sigma^2$ and stationary correlation function $\rho(t_1-t_2)$. If $X(t)$ is a white noise process the correlation function is given by the Dirac delta function $\rho(t_1-t_2) = \delta(t_1-t_2)$.</p>

<p>The integral of this process is given by:</p>

<p>$$I = \int_0^L X(t) \, dt$$</p>

<p>According to this <a href=""http://stats.stackexchange.com/questions/229877/max-and-min-variance-of-the-integral-of-a-stationary-stochastic-process/229896?noredirect=1#comment435077_229896"">CrossValidated post</a> the variance of $I$ is given by:</p>

<p>$$\text{Var}[I] = L\sigma^2$$</p>

<p>However this does not agree with the results I obtained through simulation. The approach is to discretise the white noise Gaussian process into $N$ independent normal variables. The integral can then be approximated through:</p>

<p>$$ I = \int_0^L X(t) \approx \frac{L}{N}\sum_{i=1}^NX_i$$</p>

<p>Where $X_i$ are indepedent random variables $X_i \sim \mathcal{N}(\mu,\sigma^2)$. In simulation I find that as $N$ grows large then $\text{Var}[I] \rightarrow 0$. Why does it not approach $L\sigma^2$? What is the problem with my approximation?</p>
",probability
"<p>Let $X, Y$ be conditionally independent given $Z$. Based on this, I am trying to get an intuition of what happens with the associated sigma-algebras and the conditional expectation. In particular, I want to calculate </p>

<p>$$ \mathbb{E}[B \vert X, Y,Z] = \mathbb{E}[B\vert \mathcal{F}]$$</p>

<p>where $B$ is an event and $\mathcal{F}$ is the sigma-algebra generated by $X,Y,Z$. Given the conditional independence stated above, I know that $\sigma(X)$ and $\sigma(Y)$ are conditionally independent given $\sigma(Z)$, but what does that mean for $\mathcal{F}$? Could I somehow partition this sigma-algebra into two independent components depending on $X,Z$ and $Y,Z$? In general, any intuition about the structure of $\mathcal{F}$ given conditional independence would be great.</p>
",probability
"<p>Given $$X_1\sim f_{X_1}(x_1)$$ and $$X_2\sim f_{X_2}(x_2)$$ are independent Random Variables, does this mean that $$Z=X_1+X_2$$ has distribution $$f_Z(z)\sim f_{X_1}f_{X_2} $$  or does it mean that the distribution is given by convolution of the two pdfs.</p>
",probability
"<p>In a Poker match, asumming 52 cards (13 of each type). This is the state:</p>

<ul>
<li><p>On my hand I have cards [3] and [4] of any type.</p></li>
<li><p>In table, there are these cards: [1] [2] [3] [?] [?], this is, two unknown cards and 1 [3].</p></li>
<li><p>There are other two players, each one with two unknown cards. So in the deck there are remaining 52 - 6 = 46 cards.</p></li>
</ul>

<p>The question is: <strong>what is the probability of other players to get Three of a kind composed of [3]. (Only three of a kind, no four) in ""river""?</strong></p>

<p>I can try to solve this problem partioning probabilities first for table, then for each case probability for next player, then for each case for the last player. But I'll need to solve the same problem for a table for 5 players, so this will be very laborious.</p>
",probability
"<p>Here is the problem that I'm solving:<img src=""//i.stack.imgur.com/6NGRt.jpg"" alt=""enter image description here""></p>

<p>So a) was quite easy (if I didn't miss anything :) )
Now for b): my CDF does converge to Exp(1) when x is from 0 to n</p>

<p>But if x more then n my function is constant 1 and Exp(1) is not. </p>

<p>Would it be a good explanation if I say that when n goes to infinity, x less than n with probability 1?
Would appreciate any constructive critique of my solution and advice on explaining part b)</p>
",probability
"<p>How do I solve the following?</p>

<p>$$
\lim_{x \rightarrow \infty} \int_0^{x} \left[ 1 + \text{erf} \left( \frac{\epsilon - a}{b} \right) \right] \left[ 1 + \text{erf} \left( \frac{\epsilon - c}{d} \right) \right] d\epsilon
$$</p>

<p>Related (but the problem is slightly different):
<a href=""http://math.stackexchange.com/questions/63026/integral-of-product-of-two-error-functions-erf"">Integral of product of two error functions (erf)</a></p>

<p>Or help me solve this (simpler version of the above)...</p>

<p>$$
\lim_{x \rightarrow \infty} \int_0^{x} \text{erf} \left( \frac{\epsilon - a}{b} \right) \text{erf} \left( \frac{\epsilon - c}{d} \right) d \epsilon
= \lim_{x \rightarrow \infty} \frac{4}{\pi} \int_0^{x} \int_0^{ \frac{\epsilon - a}{b} } \int_0^{ \frac{\epsilon - c}{d} } e^{-t^2 - s^2} ~ ds ~ dt ~ d\epsilon 
$$</p>

<p>Mathematica can provide a closed form solution in terms of erf if we change the order of integration from $ds ~ dt ~ d\epsilon$ to $d\epsilon ~ ds ~ dt$.</p>

<p>We can let,
$$
f(\epsilon, t) = \int_0^{ \frac{\epsilon - c}{d} } e^{-t^2 - s^2} ~ ds
$$</p>

<p>So we can focus on changing the order from $ds ~ dt ~ d\epsilon$ to $ds ~ d\epsilon ~ dt$.
$$
\int_0^{x} \int_0^{ \frac{\epsilon - a}{b} } f(\epsilon, t) ~ dt ~ d\epsilon
$$</p>

<p>To obtain,
$$
\int_0^{\frac{x-a}{b}} \int_{tb+a}^x f(\epsilon, t) ~ d\epsilon ~ dt - \int_{-\frac{a}{b}}^0 \int_0^{tb+a} f(\epsilon, t) ~ d\epsilon ~ dt \\
\int_0^{\frac{x-a}{b}} \int_{tb+a}^x \int_0^{ \frac{\epsilon - c}{d} } e^{-t^2 - s^2} ~ ds ~ d\epsilon ~ dt - \int_{-\frac{a}{b}}^0 \int_0^{tb+a} \int_0^{ \frac{\epsilon - c}{d} } e^{-t^2 - s^2} ~ ds ~ d\epsilon ~ dt
$$</p>

<p>Next, to switch the integral order from $ds ~ d\epsilon ~ dt$ to $d\epsilon ~ ds ~ dt$. Someone please continue the rest...</p>
",probability
"<p>I'm trying to prove urns version of Laplace's law of succession my professor suggested. Laplace's law states that the chance that the next trial is a success given $j$ successes out of the first $n$ is $\frac{(j+1)}{(n+2)}$. Here is how the problem states: </p>

<p>""If we have $n+k+1$ urns and urn $i$ has $i$ balls labeled $1$ and $n+k-i$ labeled zero. We pick an urn at random and draw $n$ balls from it without replacement say $j$ of them are ones. Show that the conclusion of Laplace's law holds for this setup. In other word, the chance that the next ball is a one is $\frac{(j+1)}{(n+2)}$.""</p>

<p>I've proved one version of the law, which close to this version <a href=""http://math.stackexchange.com/questions/102417/an-elementary-version-of-laplaces-method-of-succession"">An elementary version of Laplace&#39;s Method of Succession</a>. I tried to use similar approach but somehow my answer always in form of $k$ and I can't get rid of it. What is the intuition behind this $k$? Is it just to increase the complexity of the problem, or it has some meaning behind it?     </p>
",probability
"<blockquote>
  <p>The probability that a randomly chosen male has a circulation problem is 0.25.  Males who have a circulation problem are twice as likely to be smokers as those who do not have a circulation problem.  What is the conditional probability that a  male has a circulation problem, given that he is a smoker?</p>
</blockquote>

<p>Let:</p>

<p>C = Circulation Problem</p>

<p>S = smoker.</p>

<p>The problem is asking you to solve for $\Pr(C \mid S)$.  I thought I could solve problem by using a table and I completed it below.  I interpreted the statements as such:</p>

<p>1:  ""a randomly chosen male has a circulation problem is 0.25"":  $\Pr(C)=0.25$</p>

<p>2:  ""Males who have a circulation problem are twice as likely to be smokers as those who do not have a circulation problem."":  $\Pr(C \cap S) = 2x$ and $\Pr(C' \cap S) = x$</p>

<p>\begin{array}
{|c|c|c|c} \hline &amp; C &amp; C' &amp;  \\ \hline S&amp; 2x&amp; x&amp;\\ \hline S'&amp; &amp; &amp;\\ \hline &amp; 0.25 &amp; &amp;1\\ 
\hline . \end{array}</p>

<p>Which becomes:</p>

<p>\begin{array}
{|c|c|c|c} \hline &amp; C &amp; C' &amp;  \\ \hline S&amp; 2x&amp; x &amp; 3x\\ \hline S'&amp; &amp; &amp;\\ \hline &amp; 0.25 &amp; 0.75 &amp;1\\ 
\hline . \end{array}</p>

<p>So I did $\Pr(C\mid S) = \cfrac{\Pr(C \cap S)}{\Pr(S)}=\cfrac{2x}{3x}=2/3$ which is wrong.  The answer is 2/5!  </p>

<p><strong>Am I incorrectly interpreting statement 2 above as an intersection when instead it is a conditional probability?  In other words, should I be writing $\Pr(S\mid C)=2x$ and $\Pr(S\mid C')=x$?</strong></p>

<p>Thank you in advance.</p>
",probability
"<p>I've got a general question regarding a certain sticking point I often encounter. When tackling questions where for example an UMVUE (uniformly minimum-variance unbiased estimator) has to found I get stuck at the part where an expectation has to be determined. Maybe I'm overlooking certain theorems. </p>

<p>Example 1.  Consider a random sample of size $n$ with $X_i\tilde{}Poi(\mu)$. </p>

<p>I am able to find the UMVUE of $\mu$ and the MLE (Maximum Likelihood Estimator) of $\theta=e^{-\mu}$. But then for example follows the question: is this MLE unbiased for $\theta$?</p>

<p>If I want to determine the expectation, should I just write out the sum as follows from the definition of the expected value of a discrete distributed variable? This seems to lead to quite an ugly expression...</p>

<p>(<em>For this particular problem I found that Jensen's Inequality could come in handy to show biasedness (or actually non-unbiasedness))</em> </p>

<p><strong>But if I could summarize the problem I've got: how to rewrite expected values of functions of stochast in general?</strong>
Which theorems or properties should I use... for example I do use $E(aX)=aE(X)$ for $a$ a constant and $var(X)=E(X^2)-E(X)^2$ to rewrite certain expectations to a combination of simpler/known ones.</p>

<p>Example 2. Take a random sample $n$ of a distribution with pdf $f(x;\theta)=\theta x^{\theta -1}$ if $0&lt;x&lt;1$ and else $0$ and with $\theta &gt; 0$.</p>

<p>Find the UMVUE of $\theta$</p>

<p>Here I get stuck again at the expectation. I've got a sufficient and complete statistic in 
$\sum ln(X_i)$.</p>

<p>The expected value, i'd figure, is equal to $nE(ln(X_i))=-n/ \theta$  $\,\,\,\,$(where $[-ln(X)]=\frac{1}{\theta}$ was given as a hint).</p>

<p>But what if I want to determine the expected value of $\frac{1}{\sum_{i}ln(X_i)}$ ?</p>

<hr>

<p>In general: how to determine the expectations of functions of stochasts?
For example $E[ln(X)]$or $E[e^{\bar{X}}]$...?</p>
",probability
"<p>Let $X$~Binom($n,1/2$) and $Y$~Binom($m,1/2$) be independent. Calculate $P(X=Y)$.</p>

<p>My attempt:</p>

<p>Assume $m\le n$
$$P(X=Y)=\sum_{k=0,\ldots,m} P(X=k)P(Y=k)=(\frac{1}{2})^{n+m} \sum_{k=0,\ldots,m}{n \choose k}{m \choose k}$$</p>

<p>I have no idea how can I move further. Any ideas?</p>
",probability
"<p>I have a question regarding conditional probabilities. </p>

<p>Experiment: we toss a coin $10$ times. We count the amount of head and we toss that amount again. Let $X$ be the amount of heads in the first $10$ trials and $Y$ the total amount of heads. </p>

<p>Clearly, $X$~$bin(10, 1/2)$. I suppose $Y$~$bin(10+X, 1/2)$, but not sure about that though.</p>

<p>Question: what is $P[Y=5|X=7]$. But that seems pretty silly to me, because this basically says: 'What is the chance of having $5$ heads in total given that we have $7$ heads in the first $10$ trials'. Isn't that just $0$ since $Y \geq X$? </p>
",probability
"<p>Let $A,B,C$ be events. The event ""$A$ and $B$ occur but $C$ does not"" may be expressed as $A \cap B \cap C^c$. </p>

<p>(a)  Find an expression for the event ""at least one of B and C occur, but A does not""</p>

<p>(b)  Show that the probability of event in (a) is equal to</p>

<p>$\mathbb{P}(B)+\mathbb{P}(C)-\mathbb{P}(B\cap C)-\mathbb{P}(A\cap C)+\mathbb{P}(A\cap B \cap C)$</p>

<hr>

<p>I claim that the answer to (a) is $(B \cup C)\cap A^c$. Can someone confirm or deny?</p>

<p>I have no idea how to proceed from here. From previous work, I have proven the following results:</p>

<p>$\mathbb{P}(A\setminus B)=\mathbb{P}(A)-\mathbb{P}(A \cap B)$</p>

<p>$\mathbb{P}(A\cup B)=\mathbb{P}(A)+\mathbb{P}(B)-\mathbb{P}(A\cap B)$</p>

<p>My main concern about (a) is what exactly they mean by ""at least one"" and the use of the operator ""and"".</p>
",probability
"<p>Studying for a final:</p>

<blockquote>
  <p>1) Suppose we have four indistinguishable red balls, 6 indistinguishable blue balls, and 2 indistinguishable green balls. How many different color patterns can be obtained by arranging these balls in a straight line?</p>
</blockquote>

<p>I did ${12\choose4} {12\choose6} {12\choose2} = 30,187,080$ but that's definitely not correct.</p>

<blockquote>
  <p>2) A fair, ordinary six-sided die is colored red on one face, blue on two faces, and green on the remaining three faces. Find an explicit expression (but do not simplify it) for the probability that, in the 12 rolls fo this die, red will come up 4 times, blue will come up 6 times, and green will come up 2 times? <em>Hint: What is the probability of observing the sequence RBBRGBBRGBRB?</em></p>
</blockquote>

<p>I'm not really sure what to do and the hint only made me even more confused.</p>
",probability
"<blockquote>
  <p>If $X$ is a normally distributed random variable with standard deviation $\sigma=10$, and $P(X&gt;16.34) = .1212$, what is the mean (expected value) of $X$?</p>
</blockquote>

<p><strong>Attempt at solution:</strong>
This problem doesn't make sense... standard deviation is given, by the probability $X&gt;16.34$ has no upper bound, so how can this be computed? The expected value is just the summation of all the values which $=.1212$ here, so I'm not exactly sure what is being asked. please help! </p>
",probability
"<p>Let $X_n\xrightarrow[d]{}N(0,\sigma^2_x)$ and $Y_n\xrightarrow[d]{}N(0,\sigma^2_y)$.</p>

<p>$X_n, Y_n$ are not independent.</p>

<p>Can I say that $\left( \begin{array} {}
X_n \\
Y_n \end{array} \right)\xrightarrow[d]{}N(\mathbf{0},\mathbf{C})$, with $\mathbf{C}$ a variance-covariance matrix?</p>

<p>Would $\mathbf{C}=\left( \begin{array}{ccc}
\sigma^2_x &amp; \lim Cov(X_n,Y_n)  \\
\lim Cov(Y_n,X_n) &amp; \sigma^2_y \end{array} \right)$ ?</p>
",probability
"<p>I have a system of linear equations as follows.</p>

<blockquote>
  <p>$$M(p) = 1+\frac{n-p-1}{n}M(n-1) + \frac{2}{n} N(p-1) + \frac{p-1}{n}M(p-1)$$
   $$N(p) = 1+\frac{n-p-1}{n}M(n-1) + \frac{p}{n}N(p-1)$$
   $$M(1) = 1+\frac{n-2}{n}M(n-1) + \frac{2}{n}N(0)$$
   $$N(0) = 1+\frac{n-1}{n}M(n-1)$$</p>
</blockquote>

<p>$M(p)$ is defined for $1 \leq p \leq n-1$.  $N(p)$ is defined for $0 \leq p \leq n-2$.  What is $M(n-1)$?</p>
",probability
"<p>I have a stochastic process $X_t$, and I have a function $a(x | t)$ that reflects my beliefs about the value of $X_t$ ($a$ is a density function in its first parameter).  I am studying the properties of the stochastic process $Y_t = \int_0^t X_s ds$.  I am thinking of using the following method to find a density function $b(y | t)$ for $Y_t$:</p>

<p>Let $M_n$ be a function that returns the $n^{th}$ moment of a random variable.  By Fubini's Theorem, $\int_0^t M_n(X_s) ds = M_n(\int_0^t X_s ds) = M_n(Y_t)$.  Since this gives me a function that spits out all moments of $Y_t$, and since a random variable is uniquely determined by its moments, this is enough information to find $Y_t$.</p>

<p>My questions:
(1) Have I applied Fubini's Theorem correctly?  I'm having trouble formalizing the proof of that first equality, but I intuitively feel that it's true.
(2) Are there any other obvious flaws with this method?</p>

<p>Thank you.</p>
",probability
"<p>We are preparing this for an exam.</p>

<p>Given the division of a plane into a number of regions of different sizes. We would like to find, or guess, which is the biggest region, by doing the following.</p>

<p>We will shoot a number of random points at the plane, and then conclude that the region containing the most points, is also the biggest.</p>

<p>The question is: how do use Chernoff bounds to say how many random points we need to shoot, to know that we have found the biggest region with, say, 75% probability? </p>
",probability
"<p>All the workers at a certain company drive to work and park in the company’s lot. The company is interested in estimating the average number of workers in a car. Which of the following methods will enable the company to estimate this quantity? </p>

<ol>
<li>Randomly choose $n$ workers, find out how many were in the cars in
which they were driven, and take the average of the $n$ values.</li>
<li>Randomly choose $n$ cars in the lot, find out how many were driven
in those cars, and take the average of the $n$ values.</li>
</ol>

<p>My intuition goes for number 2, but I'm not able to justify it formally.</p>
",probability
"<p>There is a notation used in many sources (e.g. Wikipedia: <a href=""http://en.wikipedia.org/wiki/Exponential_family"" rel=""nofollow"">http://en.wikipedia.org/wiki/Exponential_family</a>) for the natural parameters of exponential family distributions which I do not understand, and I cannot find a description of.</p>

<p>With vector parameters and variables, the exponential family form has the dot product between the vector natural parameter, ${\boldsymbol\eta}({\boldsymbol\theta})$ and the vector sufficient statistic, ${\mathbf{T}}({\mathbf{x}})$, in the exponent. i.e. $e^{{\boldsymbol\eta}({\boldsymbol\theta})^{\top}{\mathbf{T}}({\mathbf{x}})}$. </p>

<p>However, many examples of these parameters for different distributions are vectors composed of matrices &amp; vectors. E.g. the multivariate Normal distribution has parameter $[\Sigma^{-1}\mu\space\space-\frac{1}{2}\Sigma^{-1}]$ and sufficient statistic $[\mathbf{x}\space\space\mathbf{xx^{\top}}]$.</p>

<p>So what are these ""vectors"" and moreover, how is the dot product between them defined? Does this notation have a name?</p>
",probability
"<p>Should I use a certain table for this question or should I use a special formula. A random value has a normal distribution with the mean 102.9 and the standard deviation 4.7. What are the probabilities that this random variable will also take on a value</p>

<p>a. Less than 110.1;</p>

<p>b. Greater than 95.6;</p>

<p>c. Between 104.5 and 105.9;</p>

<p>d. Between 98.7 and 150?</p>

<p>I have worked so far by finding the z value and im going on to find it through the table. </p>
",probability
"<p>Attempting to understand Exercise 20 (pdf page 44) in the paper: (Warning: large paper; small exercise)</p>

<p><a href=""http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/090310.pdf"" rel=""nofollow"">Bayesian Reasoning and Machine Learning</a> </p>

<blockquote>
  <p>The party animal problem corresponds to the network in g(3.14). The boss is angry and the worker has a headache - what is the probability  the worker has been to a party?</p>
  
  <p>When set to 1 the statements are true: P = Been to Party, H = Got a Headache, D = Demotivated at work, U = Underperform at work, A =Boss Angry. Shaded variables (A, H) are observed in the true state.</p>
  
  <p>$\begin{matrix} &amp; &amp; D \\ &amp; &amp; \downarrow \\ P &amp; \rightarrow &amp; U \\ \downarrow &amp; &amp; \downarrow \\ (H) &amp; &amp; (A)\end{matrix} $</p>
</blockquote>

<p>I would like to solve the following:</p>

<ul>
<li>Prove that p(P|H,A ) = a*p(P,H,A) where a is a constant.</li>
<li>Expand p(P, H, A) by marginalizing over the variables U and D.</li>
<li>how to compute 'a'</li>
</ul>

<p>Any help is greatly appreciated.</p>

<p>Thank You.</p>
",probability
"<p>would the answer to this question be right by any chance? Thanks.</p>

<p>A stain remover is tried out on various stain patches. It is found that 40% of stain is removed on the first application, but the remaining stains become resistant so that the proportion removed in any subsequent application is only one half that of the preceding application. Find the probability that a stain patch will survive 3 applications:</p>

<p>Answer: 40/( 100)  ×  20/( 100)  ×  10/( 100) =  8000/1000000 = 0.008</p>
",probability
"<p>Given  $x_1, x_2,..x_n ; x_i \in R$ that drawn from an unknown distribution $P(x)$ and a constant $ C$  $ 0 \leq C \leq 1$.
Find $x^{*}$ such that
$$P(x^{*}) =C$$.</p>

<p>We want to use the kernel density estimation to estimate $P(x)$ here. So:</p>

<p>$$P(x^{*}) \approx \frac{1}{N} \bigg( \sum_{i=1}^N K_h(x^{*};x_i) \bigg)$$ </p>
",probability
"<p>Let $p \in (0,1)$ and $n \in \mathbb{N}$. We consider a sample of $n$ i.i.d. Bernoulli variables $X_1,\dots,X_n$ with parameter p.</p>

<p>Computer $E[e^{\lambda\bar{X_n}}]$ such that $\bar{X_n}= \frac{1}{n} \sum_{i=1}^n X_i$</p>

<p>$E[e^{\lambda\bar{X_n}}]=E[e^{\frac{\lambda}{n} \sum_{i=1}^n X_i}]=e^{\frac{1}{n}}E[e^{\lambda\sum_{i=1}^n X_i}]= e^{\frac{1}{n}}E[e^{\lambda X_1}]\dots E[e^{\lambda X_n}]=e^{\frac{1}{n}}(1-p+pe^{\lambda})^n$</p>

<p>Is it correct ?</p>
",probability
"<p>I took mathematical probability last semester and now I am taking financial mathematics, but only probability was a pre requisite for financial math (no finance classes were required). These types of questions re confusing me because I don't quite understand financial terminology and I guess my professor thinks that we had taken finance classes in the past. Can someone explain what a portfolio is and what $V(O)$, $V(T)$, and $K_v$ is referring to in this question?</p>

<blockquote>
  <p>Let $A(0)=90$, $A(T)=100$, $S(0)=25$ dollars and let<br>
    $$S(T) =
\begin{cases}
30,  &amp; \text{with probability } p \\
20, &amp; \text{with probability } 1-p
\end{cases}$$</p>
  
  <p>where $0 &lt; p &lt; 1$. For a portfolio with $x=10$ shares and $y=15$ bonds, calculate $V(0)$, $V(T)$, and $K_V$.</p>
</blockquote>

<p>I know what a random variable is and how to solve for expectation because I learned that in probability, but I just don't know what these finance terms are refering to?</p>
",probability
"<p>$\DeclareMathOperator{\var}{var}\DeclareMathOperator{\cov}{cov}$</p>

<blockquote>
  <p>The signal-to-noise ratio (SNR) of a random variable quantifies the accuracy of a measurement of a physical quantity. It is defined as $E^2[X]/\var(X)$ and is seen to increase as the mean, which represents the power of the measurement error, that is, $X - E[X]$, decreases. For example, if $X\sim\mathcal{N}(\mu, \sigma^2)$, then $\text{SNR} = \mu^2/\sigma^2$. Determine the SNR if the measurement is $X = A + U$, where $A$ is the true value and $U$ is the measurement error with $U\sim\mathcal{U}(-1/2, 1/2)$. For an SNR of $1000$, what should be $A$?</p>
</blockquote>

<hr>

<p>The mean and variance of a uniform random variable is $E[U] = 0$ and $\var(U) = \frac{1}{12}$. Since the SNR is $1000$, we have that
  $$
  1000 = \frac{\mu^2}{\sigma^2}\Rightarrow 10\sqrt{10} = \frac{\mu}{\sigma}
  $$
where $\mu = E[X] = E[A + U] = E[A] + E[U] = E[A]$ and $\sigma^2 = \var(X) = \var(A + U) = \var(A) + \var(U) + 2\cov(A, U) = \var(A) + \frac{1}{12} + \cov(A, U)$.</p>

<ol>
<li>Without knowing anything about $A$ how do I find $E[A]$ and $\var(A)$?</li>
<li>What is meant by what should $A$ be? Is it asking what type of distribution?</li>
</ol>
",probability
"<p>Define a sequence of r.v.'s {$X_n$}$_{n\ge 1}$ iteratively, such that $X_1\sim\text{Unif}(0,1]$ and $X_{n+1}\sim\text{Unif}(0,X_n]$. </p>

<p>Could someone please explain why this is equivalent to:</p>

<p>Let a sequence of r.v.'s {$U_n$}$ \stackrel{iid}{\sim}\text{Unif}(0,1]$. For a sequence of r.v's {$X_n$}$_{n\ge 1}$, set $X_1=U_1$. Then set $X_{n+1}=U_{n+1}X_{n}$.</p>

<p>In general, what about the construction of $X_n$ in the first formulation tells us that we can construct a sequence of products in the second formulation?</p>

<p>Thank you.</p>
",probability
"<p>We say that $X$ is smaller than $Y$ in distribution (which we denote by $X \stackrel{D}{&lt;} Y$) if $\mathbb{E}[h(X)] \leq \mathbb{E}[h(Y)]$ for all positive, increasing and bounded functions $h$.</p>

<p>We say that $X$ and $Y$ are equal in distribution (which we denote by $X \stackrel{D}{\sim} Y$) if $X \stackrel{D}{&lt;} Y$ and $Y \stackrel{D}{&lt;} X$</p>

<p>I've already answered the following question :</p>

<blockquote>
  <ol>
  <li>Prove that $X \stackrel{D}{&lt;} Y$ if and only if the cumulative
  distribution functions $F$ and $G$ of $X$ and $Y$ respectively
  satisfy $F \geq G$</li>
  </ol>
</blockquote>

<p>Indeed, it suffices to take $h(x) = 1\!\!1_{x \geq c}$ for different values of $c$.</p>

<p>But I don't know how to answer the following two questions :</p>

<blockquote>
  <ol start=""2"">
  <li>Prove that $X \stackrel{D}{&lt;} Y$  if and only if we can find two random variables $X'$ and $Y'$ such that $X \stackrel{D}{\sim} X'$, $Y \stackrel{D}{\sim} Y'$ and $X' \leq Y'$ a.s.</li>
  <li>Suppose that $X \leq Y$ a.s. and $X \stackrel{D}{\sim} Y$. Prove that $X = Y$ a.s.</li>
  </ol>
</blockquote>

<p>Can I have some help on these two questions ?</p>
",probability
"<p>Two processes $(X_t)_{t \in T}$, $(Y_t)_{t \in T}$ are known to be equal in distribution if and only if they agree on all finite-dimensional distributions, i.e.,
for all $t_1$, $t_2$, $\ldots$, $t_n$, $n \in \mathbb{B}$,
$$
(X_{t_1}, \ldots X_{t_n}) \overset{d}{=}   (Y_{t_1}, Y_{t_2}, \ldots Y_{t_n})
$$</p>

<p>How to give sense of this by using the $\pi-\lambda$ theorem, when the process takes value on a countable state space?</p>
",probability
"<p><strong>Q.1)</strong> A family has $n$ children, $n\geq2$. We ask from the father, ""Do you have at least one daughter named Lilia?"" He replies, ""Yes!"". What is the probability that all of their children are girls? </p>

<p>In other words, we want to find the probability that all $n$ children are girls, given that the family has at least one daughter named Lilia. </p>

<p>Here we can assume that if a child is a girl, her name will be Lilia with probability $\alpha\ll1$ independently from other children's names. If the child is a boy, his name will not be Lilia.</p>

<p><strong>Q.2)</strong> In a family of $n$ children. We pick one among them and found that she is a girl. What is the probability that all children are girls?</p>

<hr>

<p>My solution to Q.1)</p>

<p>$$
\begin{equation}
\begin{split}
P(\text{all are girls | at-least one named Lila}) &amp;= \frac{P(\text{at-least one name Lila | all are girls})\ \times\ P(\text{all are girls})}{P(\text{at-leat one named Lila})}\\
&amp;= \frac{{n\choose1}\ \alpha\ (1-\alpha)^{n-1}\ \times\ \frac{1}{2^n}}{{n\choose1}\ \alpha \ \frac{1}{2^{n-1}}}
\end{split}
\end{equation}$$</p>

<p>My solution to Q.2)</p>

<p>$$\begin{equation}
\begin{split}
P(\text{all are girls | at-least one girl}) &amp;= \frac{P(\text{at-least one girl | all are girls})\ \times\ P(\text{all are girls})}{P(\text{at-least one girl})}\\
&amp;= \frac{1\ \times\ \frac{1}{2^n}}{{n\choose1}\ \frac{1}{2} \ \frac{1}{2^{n-1}}}
\end{split}
\end{equation}$$</p>
",probability
"<p>I am reading a paper and there is a theorem which says:</p>

<p>Let $(S, A, \mu)$ be a probability space, and let $\theta$ be a $\mu$-measure
preserving transformation on it. Then
there exists a subset $S_0 \subset S$ of full $\mu$-measure such that ....</p>

<p>What does ""there exists a subset $S_0 \subset S$ of full $\mu$-measure"" mean?</p>
",probability
"<p>I'm having a bit of trouble with this problem.</p>

<p>Three cards are drawn from a pack of regular playing cards. What's the probability of getting different suits, as well as different denominations (number, face, etc.)?</p>

<p>Bonus question. In the above case, it isn't specified whether the cards are drawn simultaneously, or one by one. Would it make a difference?</p>
",probability
"<p>16 players, $S1,S2...S16$ are divided into eight pairs. What's the probability of only one of $S1$ or $S2$ coming out as one of the eight quarterfinalists?</p>

<p>To clarify, only one of them qualify. And all players are of equal strength. And, the pairings are completely random.</p>
",probability
"<p>when a biased coin is tossed 5 times the probability of having 2 heads is same as that of having 3 (and not 0) What is the probability of having heads exactly 3 out of 5?</p>
",probability
"<p>This problem seems to me a brain teaser, in the form of a probability puzzle. I would be really grateful if someone could help me to solve this simple conditional probability problem.
We have a $n \times n$ $(0,1)$-matrix $M$. Let $R$ be the set of rows and let $C$ be the set of columns. Finally, we indicate the $i$-th row and column with $R_i$ and $C_i$ respectively, and the set $\{1, 2, ..., n\}$ with $[n]$.</p>

<p>We have the following information:</p>

<p>(1) Given any $i \in [n]$ and $y \in \{0,1\}$, we know the number $f_{y}(R_i)$ of indices $k \in [n]$ such that $M_{i, k}=y$. Analogously, we also know the number $f_{y}(C_i)$ of indices $k \in [n]$ such that $M_{k, i}=y$.</p>

<p>(2) Given any pair of integers $(i,j) \in [n] \times [n]$ and any value $y \in \{0,1\}$, we know the number $f_{y, 1}(R_i, R_j)$ of vector component indices $k$ such that $M_{j,k}=1$ when $M_{i,k}=y$.  </p>

<hr>

<p>We select at the same time three integers $i$, $j$ and $k$ uniformly at random in $[n]$. We then read the value of $M_{i, k}$ and observe it is equal to a certain value $y$ (where therefore $y \in \{0,1\}$). </p>

<p>QUESTION: How can we calculate the probability that $M_{j,k}=1$?</p>

<p>Using the second part of information (1) solely, I guess one would answer $f_{1}(C_k)/n$. On the other hand, using all information except the second part of (1), I guess one would answer $f_{y, 1}(R_i, R_j)/f_{y}(R_i)$ (please observe $f_{y}(R_i)$ cannot be null). I do not know how to combine all the information.</p>

<p>Thank you very much for your help!
Cheers,
T.</p>
",probability
"<p>I have set of sample which are grouped in different size. If I want to find probability of an event in each group, how can I normalize the probability over all the groups. For example, Let say I have 3 set of samples each sized 3, 8 and 30 respectively. If the probability of an event to occur in set $1$ is $\frac{1}{3}$, in set $2$ it is $\frac{3}{8}$ and in set $3$ it is $\frac{4}{30}$. How can I normalize the probability so that highest probability is assigned for set $3$ then set $2$ and then set $1$.</p>
",probability
"<p>Let $X_{n,k}$ be a double sequence of random variables. </p>

<p>Assume for each fixed $k$, $X_{n,k}\xrightarrow[n\rightarrow\infty]{p}\alpha_k$, where $\alpha_k$ is a non-random scalar. Assume further that $\alpha_k\xrightarrow[k\rightarrow\infty]{p.w} \alpha$, where $\alpha$ is again non-random. Is it possible to show the following?</p>

<p>$$X_{n,k}\xrightarrow[n,k\rightarrow\infty]{p} \alpha$$</p>

<p>My attempt: Let $f$ be any arbitrary Lipschitz Cont. function bounded by $M&lt;\infty$ and satisfying the contraction $\vert f(x_1) - f(x_2)\vert \leq K\vert x_1 - x_2\vert$ for some $K$ (by definition). Then consider
\begin{align}
\mathbb{E}\big\vert f(X_{n,k}) - f(\alpha)\big\vert&amp;\leq\mathbb{E}\big[\big\vert f(X_{n,k}) - f(\alpha_k)\big\vert\big] + \big\vert f(\alpha_k) - f(\alpha)\big\vert\\
&amp;=\mathbb{E}\big\vert f(X_{n,k}) - f(\alpha_k)\big\vert\mathbb{1}_{(\vert X_{n,k} - \alpha_k\vert\leq \epsilon)} + \mathbb{E}\big\vert f(X_{n,k}) - f(\alpha_k)\big\vert\mathbb{1}_{(\vert X_{n,k} - \alpha_k\vert&gt; \epsilon)} + \big\vert f(\alpha_k) - f(\alpha)\big\vert\\
&amp;\leq K\epsilon + M\mathbb{P}[\vert X_{n,k} - \alpha_k\vert&gt; \epsilon] + K\vert \alpha_k - \alpha\vert
\end{align}</p>

<p>Now, we know that there exists a $K^*$ large enough such $K\vert \alpha_k - \alpha\vert\leq K\delta$ for all $\delta&gt;0$</p>

<p>Similarly, $\mathbb{P}[\vert X_{n,k} - \alpha_k\vert&gt; \epsilon]&lt;\delta$ for large enough $N^{*}$.</p>

<p>Is it enough to choose $N = \max(N^{*},K^{*})$ to show that $\mathbb{E}\big\vert f(X_{n,k}) - f(\alpha)\big\vert\leq \delta$ for all $n,k\geq N$? Then I could use the Portmanteau lemma to show the rest.</p>
",probability
"<p>How do I calculate the pdf for the following case?  In general, if we have 2 r.v. $x,y$ which are normal, then the pdf of the difference of 2 r.v. which are Gaussian will also be Gaussian, I think with mean $\mu_Z = \mu_x - \mu_y$ and variance $\sigma^2_Z = \sigma^2_x + \sigma^2_y$.</p>

<p>Based on this premise, how to find the pdf from a Gaussian Mixture model (GMM). The time series $Z$ has the pdf $f_Z$ which is GMM distribution. The time series contains 2 r.v $x,y$.  So, both the r.v. together constitute a GMM. Considering that there are only 2 mixtures.
I have observations of multivariate time series $Z_i = {[x_i,y_i]}_{i=1}^n$ where $x,y$ are the random variables. The pdf of $Z$ is Gaussian mixture model (GMM). The parameters of the GMM model are learnt through Expectation Maximization.   How to get the functional form for the pdf $f(d_i) = f(x_i-y_i)$ where $d_ i = x_i-y_i$. Thank you for help.</p>
",probability
"<p>I am probably missing something obvious but here goes: Lets say we have ten people, and over a period of five days, five of them die. One does each day
The probability of any person dying on Day 1 is 1/10, Day 2 is 1/9, and so on.
I started off with the (obvious) premise that the probability of dying was 1/2. I then calculated that there were 10P5 possible permutations of YES DYING and of NOT DYING. There are 9P4 permutations that just include NOT DYING. 9P5/10P5 = 1/2.</p>

<p>PROBLEM: Some of those 10P5 possibilities include YES DYING more than once, which is not really an valid possibility. So now I am left with the absurd situation where the probability of dying is less than 1/2!
Where is my error?
Thanks</p>
",probability
"<p>Fifty marbles numbered 1 to 50 are placed in a barrel and twenty drawn one at a time without replacement. What is the probability that at least one will be drawn in sequence? i.e. 1 is drawn first, two is drawn second etc.</p>
",probability
"<p>I <em>understand</em> the concept of standard deviation as the <strong>square root</strong> of the <strong>square</strong> of the <strong>mean</strong> of <strong>each sample value - the <em>mean</em> of the sample values</strong>.<br>
Here is the mathematical representation (I've solved out the proof independently) :</p>

<p>1.) $\sigma = \sqrt{\{x^2\} - \{x\}^2}$<br>
where $\{\,\}$ is the average and $x$ is a sample value.  </p>

<p>2.) There is an alternate mathematical representation using summation sigma (for discrete random variable also) that more people are probably acquainted with. <strong>Or does this one have a slightly different meaning, I'm not sure?</strong> </p>

<p>My question is, can someone explicitly show me the derivation for the standard deviation of a binomial distribution.<br>
Here is  the information I know:</p>

<p>1.) Final formula:  $\sigma = \sqrt{pqN}$</p>

<p>2.) $p =$ probability of event A occurring AKA $p = n(A)/N$</p>

<p>where $A$ is an event OR <strong>the first binomially distributed random variable</strong>, $n(A)$ is the amount of times event $A$ happens, and $N$ is the total number of events</p>

<p>3.) $q =$ probability of event $B$ occurring AKA $p = n(B)/N$ where $B$ is an event OR <strong>the second binomially distributed random variable</strong>, $n(B)$ is the amount of times event $B$ happens, and $N$ is the total number of events. Also, $q = 1-p$ because there are only two events, $A$ and $B$.</p>
",probability
"<p>I am currently working on conditional probability and I am somewhat confused about how exactly to complete this problem. I know that to find conditional probability that you utilize:</p>

<p>$$P(A|B) = \frac{P(A\cap B)}{P(B)}$$</p>

<p>I also know that there is a $6/36$ chance to roll a sum of 7, and that if you roll a sum of 7 that there is a $4/6$ chance to get a sum without using the number 2. I do not know what else is necessary however in order to finish this problem and to find $P(A|B)$.</p>
",probability
"<p>Let $B=(B_t)_{t\ge 0}$ be a Brownian motion on a probability space $(\Omega,\mathcal{A},\operatorname{P})$. By definition of $B$, for $\operatorname{P}$-almost every $\omega\in\Omega$ $$[0,\infty)\to\mathbb{R}\;,\;\;\;t\mapsto X_t(\omega)\tag{1}$$ is continuous. Generally, a stochastic process $X=(X_t)_{t\in I}$ on $(\Omega,\mathcal{A})$ with $I\subseteq\mathbb{R}$ can be viewed as a mapping $$X:\Omega\mapsto\mathbb{R}^I\;,\;\;\;\omega\mapsto \left(t\mapsto X_t(\omega)\right)\tag{2}$$ I've frequently read that $B$ is considered to be a mapping $\Omega\to C\left([0,\infty)\right)$, where $C(I)$ is the space of continuous functions $I\to\mathbb{R}$.</p>

<hr>

<p>Why can we do that? Clearly, there exists a $\operatorname{P}$-null set $N\subseteq\mathcal{A}$ such that $(1)$ is continuous for all $\omega\in\Omega\setminus N$. Moreover, I know that we can alter measurable functions on null sets without changing their measure related properties. However, is it guaranteed that we can alter $B$ on all null sets on which $(1)$ is not continuous such that $(1)$ is continuous for all $\omega\in\Omega$?</p>

<hr>

<p>Remark: Maybe we can use the <em>Kolmogorov-Chentsov theorem</em> to prove that $(1)$ can indeed be assumed as continuous for all $\omega\in\Omega$. The theorem can be formulated as follows:</p>

<p>Let $X=(X_t,t\ge 0)$ be a real-valued stochastic process such that for all $T&gt;0$, there exists $\alpha,\beta,C&gt;0$ with $$\operatorname{E}\left[\left|X_t-X_s\right|^\alpha\right]\le C|t-s|^{1+\beta}\;\;\;\text{for all }s,t\in [0,T]]$$ Then, there exists a <em>modification</em> of $X$ which is locally Hölder-continuous of order $\gamma\in \left(0,\frac \beta\alpha\right)$.</p>

<p>Stochastic processes $X,Y$ are called <em>modifications</em> of each other, if $X_t=Y_t$ almost surely.</p>
",probability
"<p>Here is one I'm stumped on. </p>

<blockquote>
  <p>A ball can be in any one of $n$ boxes. It is the $i^{th}$ box with probability $p_i$. If the ball is in the $i^{th}$ box a search of that box will uncover it with probability $\alpha_i$. Given that a search of box $i$ did not uncover the ball, what is the conditional probability the ball is actually in box $j$ where $i,j=1,\ldots,n$? </p>
</blockquote>

<p>I tried fooling around with the multinomial distribution but kept getting tripped up. Any thoughts?</p>
",probability
"<p>Is there any way to simplify the following expression?</p>

<p>$$
\sum_{d = 1}^k \left(\sum_{i=1}^d \frac{1}{i}\right) \frac{{n-t \choose d}{t \choose k-d}}{{n \choose k}}
$$</p>

<p>This formula comes from the expected number of record lows over the first $k$ elements in a permutation of $[1,n]$, given some minimum threshold $t$ below which the elements don't count as a record low. </p>

<p>Let $L$ be the number of record lows, and let $d$ be the number of elements above the threshold.
$$
E[L] = E[E[L|d]] = \sum_{d=1}^k E[L|d]\cdot P(d)
$$</p>

<p>where $P(d)$ is a <a href=""http://en.wikipedia.org/wiki/Hypergeometric_distribution"" rel=""nofollow"">hypergeometric</a> distribution, with n-t success states, population size $n$, and $k$ draws.</p>

<p>This comes up for example in this question: <a href=""http://math.stackexchange.com/q/139523/23846"">Expected number of cards in the stack?</a></p>
",probability
"<p>Consider the density $f(x,y)=\large\frac{1}{2\pi}\frac{1}{\sqrt{1-x^2-y^2}}$ on the unit disk centered at the origin. There is a particular characterization of this distribution: it is the unique circularly symmetric distribution whose projections onto any line through the origin are uniformly distributed. </p>

<p>Showing the projections of $f(x,y)$ are uniform is simple calculus. However I can't seem to think of an elegant proof for uniform projections implying $f$ must have the above density. If we let $R$ denote any rotation of coordinates $x,y\rightarrow x',y'$, then by assumption, $f(x,y)=R\circ f(x,y):=f(x',y')$. It would then suffice to show that $f(x,0)=\large\frac{1}{2\pi}\frac{1}{\sqrt{1-x^2}}$. Writing out the projected density as $u(x)$:</p>

<p>$$u(x):=\int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}}f(x,y)dy$$</p>

<p>and we must have that $u(x)=1/2$ (being uniform on $[-1,1]$). Differentiating in $x$ with Leibnitz's rule seems to get nowhere. I've also tried considering the characteristic function of $f$ but got nowhere. </p>

<p>If it helps, $f(x,y)$ arises from projecting the uniform distribution on the sphere to the $x,y$ plane. So in essence this is Archimedes rule for the sphere inscribed in a cylinder: the surface areas are equal. My gut feeling is that this is not entirely dissimilar from showing that the multivariate Gaussian distribution is the only rotationally invariant distribution with independent components.</p>
",probability
"<p>is there a simple way to prove that $X_n \rightarrow_{L^p} X$ implies that $\mathrm{E}(X^p_n) \rightarrow \mathrm{E}(X^p)$? the proof for $p=1$ is easy. but what about the case $p&gt;1$? I would appreciate any comments. many thanks!</p>
",probability
"<p>I have encountered two definitions of weak convergence in $L^1$:</p>

<p>1) $X_n\rightarrow X$ weakly in $L_1$ iff $\mathrm{E}(X_n\mathrm{1}_A)\rightarrow \mathrm{E}(X\mathrm{1}_A)$ for every measurable set $A$.</p>

<p>2) $X_n\rightarrow X$ weakly in $L_1$ iff $\mathrm{E}(X_n f)\rightarrow \mathrm{E}(X\mathrm{1}f)$ for every (essentially) bounded measurable function $f$.</p>

<p>my question: are 1) and 2) equivalent?</p>

<p>I see that 2) implies 1) (indicators are bounded), but I have difficulties establishing that 1) implies 2). I tried approximating $f$ by simple functions $f_m$, say, assuming $X_n,X$ are nonnegative for simplicity; the problem: I cannot justify the interchange in the order of taking the limits (first with $n$, and then with $m$). any ideas? I would appreciate any sort of help. many thanks!</p>
",probability
"<p>This question is from DeGroot's ""Probability and Statistics"" :</p>

<blockquote>
  <p><strong>Unbounded p.d.f.’s.</strong> Since a value of a p.d.f.(probability density function) is a probability density, rather than a
  probability, such a value can be larger than $1$. In fact, the values of the following
  p.d.f. are unbounded in the neighborhood of $x = 0$:$$f(x) =
\begin{cases}
\frac{2}{3}x^{-\frac{1}{3}}  &amp; \text{for 0&lt;$x$&lt;1,} \\
0 &amp; \text{otherwise.}  \\
\end{cases}$$</p>
</blockquote>

<p>Now, I don't know how the p.d.f. can take value larger than $1$.Please let me know the difference between the probability and probability density.</p>
",probability
"<p>I asked <a href=""http://math.stackexchange.com/questions/1402463/2011-aime-problem-12-probability-round-table"">Here</a> This question and I am still confused. I got that, for at least one group together there are:</p>

<p>$$3 \cdot 9 \cdot \binom{6}{3, 3}$$</p>

<p>But why do we subtract: $3 \cdot 9 \cdot 4$. </p>

<p>Lets begin with $AAA$ suppose circularly. (We multiply by $3$ in the end for $BBB, CCC$ so not to worry about that). There are $9$ possible places for $AAA$. I saw that: $BCBCBC, CBCBCB$ are two already. Then :$BBCBCC, BCBBCC$, etcc... that is more than $4$.</p>

<p>What am I missing here? </p>
",probability
"<p>Three players A, B and C take turns to roll a fair die; they do this in the order ABCABC... 
(a) Find the probability that, of the three players, A is the ﬁrst to throw a 6, B is the second, and C is the third. 
(b) Find the probability that the ﬁrst 6 to appear is thrown by A, the second 6 to appear is thrown by B, and the third 6 to appear is thrown by C.</p>

<p>I am confused as to the difference between the two questions. 
Also, can anyone give me shorter ways to solve the first part?</p>
",probability
"<p><strong>Question</strong>: 
Consider n independent tosses of a $k$-sided fair dice. Let $X_i$ be the number of tosses that result in $i$.</p>

<p>What is the covariance $\mathrm{cov}(X_1,X_2)$ of $X_1$ and $X_2$.</p>

<hr>

<p>\begin{align}
\mathrm{cov}(X_1,X_2) = \mathbf{E}[X_1X_2] - \mathbf{E}[X_1]\mathbf{E}[X_2]
\end{align}</p>

<p>I get a different $\mathbf{E}[X_1X_2]$ than the given solution.</p>

<p><strong>The solution given is</strong></p>

<p>Let $A_t$ (respectively, $B_t$) be a Bernoulli random variabe that is equal to 1 if and only if the $t$th toss resulted in 1 (respectively, 2). We have <strong>E</strong>$[A_tB_t] = 0$ (since $A_t \neq 0$ implies $B_t \neq 0$)</p>

<p>$$ \mathbf{E}[A_tB_s] = \mathbf{E}[A_t]\mathbf{E}[B_t] = \frac{1}{k} \cdot \frac{1}{k}   \mathrm{for}\  s \neq t.$$</p>

<p>Thus,</p>

<p>\begin{align}
\mathbf{E}[X_1X_2] &amp;= \mathbf{E}[(A_1+\cdots + A_n)(B_1+\cdots B_n)]\\
 &amp;=n\mathbf{E}[A_1(B_1+\cdots+B_n)] = n(n-1)\cdot   \frac{1}{k} \cdot \frac{1}{k} \\
&amp;= \frac{n(n-1)}{k^2}
\end{align}</p>

<p>and</p>

<hr>

<p><strong>My solution that gives slightly off answer</strong></p>

<p>My approach uses iterated expectations.
\begin{align}
\mathbf{E}[X_1X_2] = \mathbf{E}[\mathbf{E}[X_1X_2|X2]]
\end{align}
If I had $k$ instead of $k-1$ in the following equation, I would get an answer identical to given solution but if I already know $X_2=x_2$ then dice tosses should be identically distributed among k-1 remaining options, right?
\begin{align}
\mathbf{E}[X_1|X_2=x_2] = \frac{n-x_2}{k-1} 
\end{align}</p>

<p>Then 
\begin{align}
\mathbf{E}[X_1X_2|X_2] = \frac{n-X_2}{k-1} \cdot X_2
\end{align}
\begin{align}
\mathbf{E}[\mathbf{E}[X_1X_2|X_2]] = \mathbf{E}[\frac{nX_2-{X_2}^2}{k-1}]
\end{align}</p>

<p>given $\mathbf{E}[{X_2}^2] = \mathbf{E}[{X_2}] = \frac{n}{k}$</p>

<p>\begin{align}
\mathbf{E}[X_1X_2] = \frac{n(n-1)}{k(k-1)}
\end{align}</p>

<p>So my answer differs to the solution on the matter of $\mathbf{E}[X_1X_2]$</p>

<p>\begin{align}
\mathbf{E}[X_1X_2] = \frac{n(n-1)}{k^2} \neq \frac{n(n-1)}{k(k-1)}
\end{align}
Whats wrong with my logic? Or maybe MIT is wrong.</p>
",probability
"<p>Let $X$, $Y,$ and $Z$ be random variables. (There are no restrictions on these variables, but you may assume that these are continuous random variables if you want.) Suppose that $X$ and $Z$ are independent, and also suppose that $Y$ and $Z$ are independent. Does it follow that $\mathrm{cov}(XY,Z)=0$? (I understand that $XY$ and $Z$ may not be independent, but this does not rule out the zero covariance.)</p>

<p>Under the assumption that $X$ and $Z$ are independent and that $Y$ and $Z$ are independent, I am able to show that $$\mathrm{cov}(X,YZ) = \mathrm{cov}(Y,XZ) = \mathrm{cov}(XY,Z) + \mathrm{E}[Z]\cdot \mathrm{cov}(X,Y).$$ Showing this is fairly straightforward: $\mathrm{cov}(XY,Z)=\mathrm{E}[XYZ]-\mathrm{E}[XY]\cdot\mathrm{E}[Z]$; in addition, $\mathrm{cov}(X,YZ)=\mathrm{E}[XYZ]-\mathrm{E}[X]\cdot\mathrm{E}[YZ]=\mathrm{E}[XYZ]-\mathrm{E}[X]\cdot\mathrm{E}[Y]\cdot\mathrm{E}[Z]$, implying that $\mathrm{cov}(X,YZ)=\mathrm{cov}(XY,Z)+\mathrm{E}[XY]\cdot\mathrm{E}[Z]-\mathrm{E}[X]\cdot\mathrm{E}[Y]\cdot\mathrm{E}[Z]$, which is obviously equal to $\mathrm{cov}(XY,Z) + \mathrm{E}[Z]\cdot\mathrm{cov}(X,Y).$ And, of course, $\mathrm{cov}(X,YZ) = \mathrm{E}[XYZ]-\mathrm{E}[X]\cdot\mathrm{E}[Y]\cdot\mathrm{E}[Z]= \mathrm{cov}(Y,XZ)$, proving the above result.</p>

<p>However, to proceed further, my intuition tells me that $\mathrm{cov}(XY,Z) = 0$ and thus that $\mathrm{cov}(X,YZ) = \mathrm{cov}(Y,XZ) = \mathrm{E}[Z]\cdot\mathrm{cov}(X,Y)$. Am I wrong in thinking that $\mathrm{cov}(XY,Z) = 0$? But if it is true that $\mathrm{cov}(XY,Z) = 0$, is there a simple proof that does not possibly involve measure theory? Thanks.</p>
",probability
"<p>Let $\mathbf{u} =\begin{bmatrix}u_1 &amp; u_2 &amp; \dots &amp; u_N \end{bmatrix}^T$ and $\mathbf{v} = \begin{bmatrix} v_1 &amp; v_2 &amp; \dots &amp; v_N\end{bmatrix}^T$. All the elements of $\mathbf{u}$ and $\mathbf{v}$ are complex Gaussian random variables with zero mean and variance $\frac{1}{N}$ and $N$ is large. Also let $x_1, x_2 \in \{-1,1\}$ where $x_1$ a can be $-1$ or $1$ with equal probability $(p=0.5)$ and similaraly $x_2$. </p>

<p>Define $d^2$ as the square of the euclidean distance between $\mathbf{u}x_1 \text{and } \mathbf{v}x_2$: $$d^2=\mathbf{|u}x_1-\mathbf{v}x_2|^2 = |u_1x_1-v_1x_2|^2 + \dots +|u_Nx_1-v_Nx_2|^2 \\ \text{let} ~~d_\min = \min(d^2)~~ \text{what is} ~~ E(d_\min) \text{?}$$.</p>

<p>There are $4$ combinations for $(x_1, x_2)$: $(1,1),(1,-1),(-1,1),(-1,-1)$ and therefore $4$ combinations for $d^2$ $$d_1^2=|u_1-v_1|^2 + \dots +|u_N-v_N|^2 \\ d_2^2=|u_1+v_1|^2 + \dots +|u_N+v_N|^2 \\ d_3^2 = |-u_1-v_1|^2 + \dots + |-u_N-v_N|^2 \\ d_4^2 = |-u_1+v_1|^2 + \dots +|-u_N+v_N|^2$$
Since $u_i$ and $v_i$ are complex Gaussian, $|u_i-v_i|$ is Rayleigh and $|u_i-v_i|^2$ is going to be exponential. $N$ is large here and since all terms $|u_i-v_i|^2$ are independent I can use the central limit theorem and say that $d_1^2,d_2^2,d_3^2,d_4^2$ are all Gaussian. I can use the CDF method to calculate the distribution of $d_\min$ and then calculate the average minimum distance but $d_1^2,d_2^2,d_3^2,d_4^2$ are not independent and I don't know how to proceed. Any help/guidance is greatly appreciated.</p>
",probability
"<p>I was trying to solve the following question:</p>

<blockquote>
  <p>Out of 2 Boys and 2 Girls, two students are chosen to advance to the next level. What is the probability that two girls advance to the next level</p>
</blockquote>

<p>However, because the question was ambiguous I calculated the probabilities considering all four cases of whether they were distinguishable or indistinguishable, and whether order mattered or didn't matter and got different probabilities for each case.</p>

<p>However, I want to know why this happens. All you are doing is simply picking two students and seeing if they are both girls. You keep doing this and after infinite trials, divide the number of times they were both girls by the number of total trials. How does this outcome depend upon whether you view them as distinguishable, indistinguishable, ordered, or non-ordered? </p>

<p>Cases:</p>

<ol>
<li><p>Indistinguishable, order matters: $\frac{1}{2\cdot 2}=\frac{1}{4}$ (Cases are BB, BG, GB, GG)</p></li>
<li><p>Indistinguishable, order does not matter: $\frac{1}{3}$ (Cases are BB, B+G, GG)</p></li>
<li><p>Distinguishable, order matters: $\frac{2}{\text{Permutation}(4,2)} = \frac{1}{6}$</p></li>
<li><p>Distinguishable, order does not matter: $\frac{1}{\binom{4}{2}}=\frac{1}{6}$</p></li>
</ol>
",probability
"<blockquote>
  <p>Six teams play a tournament in which every team plays every other team exactly once. No ties occur, and each team has a $\dfrac{1}{2}$ probability of winning any game it plays. Find the probability that no two teams win the same number of games.</p>
</blockquote>

<p>This is what I have so far:</p>

<p>There are $\binom{6}{2} = 15$ pairs of teams, and $2^{15}$ possible outcomes. The min and max possible # of games won are from $0$ to $5$. If $h$ represents the # of games on by a certain team, than $0 \leq k \leq 5$. Because of this, there are $5!$ outcomes in which no two teams win the same number of games. Therefore, the probability is: $\dfrac{5!}{2^{15}}$. When simplified, we get $\dfrac{15}{4096}$. However, when I imputed this answer into the question, it was wrong. Where was my error, and how can I fix it? </p>

<p>NOTICE: The probability of a team winning in each game is 1/2 , NOT 1/12. </p>
",probability
"<p>$8$ students take an exam.</p>

<p>All of them are prepared average, so probability that they will pass or fail is the same.</p>

<p>After checking half of the tests, it's discovered that $3$ of them passed and $1$ failed.</p>

<p>What is probability that in the next $3$ tests, $1$ will pass and $2$ will fail</p>

<p>My reasoning:</p>

<p>If $A$ is event in which $1$ out of checked $4$ has passed and $2$ have failed and $B$ is event in which $3$ out of checked $4$ have passed and $1$ has failed then that two events are independent??</p>
",probability
"<p>I have a 60-40 weighted distribution, of uniform(0,7.5) and uniform(7.5,10) respectively, i.e. 
$$f_X(x)=(0.6/7.5)1_{x∈[0,7.5)}+(0.4/2.5)1_{x∈[7.5,1]}$$</p>

<p>I have worked out that 
$$E(X) = 0.6(7.5/2) + 0.4((10+7.5)/2) = 5.75$$ 
$$Var(X) = 9.0208$$</p>

<p>Right now this distribution is continuous, and I would like to make it discrete via the method of moment matching, with number of moments p = 2 and span h = 1.25.</p>

<p>How do I go about this?</p>

<p>I sort of understand how the equations work for p=1 (matching $m_0^k$ and $m_1^k$), but I'm not sure how to work it out for p=2.</p>

<p>*Notes: </p>

<p>Method of moment matching for arithmetizing a continuous distribution</p>

<p>We construct an arithmetic distribution that matches p moments of the arithmetic and the true severity distributions. Consider an arbitrary interval of length $ph$, denoted by $[x_k ; x_{k+ph})$. We locate point masses $m^k_0$, $m^k_1$, $m^k_2$, ... , $m^k_p$ at points $x_k$, $x_k + h$, ... , $x_k + ph$ so that the first p moments are preserved.</p>

<p>The system of p + 1 equations reflecting these conditions is
$$\sum_{j=0}^p (x_k + jh)^rm^k_j = \int_{x_k􀀀􀀀 - 0}^{x_k􀀀􀀀 + ph - 0} x^r dF_X(x) - (*)$$</p>

<p>where r = 0,1,2,...,p and the notation “􀀀- 0” at the limits of the integral indicates that discrete probability at $x_k$ is to be included but discrete probability at $x_k + ph$ is to be excluded.</p>

<p>Arrange the intervals so that $x_k+1 = x_k + ph$ and so the endpoints coincide. Then the point masses at the endpoints are added together.</p>

<p>With $x_0 = 0$, the resulting discrete distribution has successive probabilities:</p>

<p>$f_0 = m_0^0$, $f_1 = m_1^0$, $f_2 = m_2^0$, ...</p>

<p>$f_p = m_p^0 + m_0^1$, $f_{p+1} = m_1^1$, $f_{p+2} = m_2^1$, ...</p>

<p>We need to solve the system of equations defined by $(*)$.</p>

<p>The solution of $(*)$ is $$m_j^k = \int_{x_k􀀀􀀀 - 0}^{x_k􀀀􀀀 + ph - 0} \prod_{i \neq j}\frac{x - x_k - ih}{(j-i)h}dF_X(x)$$
where j = 0,1,...,p</p>
",probability
"<p>When you pick three cards, without replacement, from a standard 52 card deck, what are the probabilities of:</p>

<ul>
<li>only one suit in your three cards</li>
<li>two different suits in your three cards</li>
<li>three different suits in your three cards</li>
</ul>

<p>For the first I have the probability of $4 \cdot \frac{13}{52} \cdot \frac{12}{51} \cdot \frac{11}{50} = \frac{22}{425} $</p>

<p>But I cannot think of a way to determine the possibilities you have two or three different suits in the three chosen cards. Any help is appreciated.</p>
",probability
"<p>Let $(X_{n,m})_{n\geq 1,m\geq1}$ be a double sequence of random variables such that $X_{n,m}\Rightarrow X_m$ (weak convergence) as $n\rightarrow\infty$, $X_{n,m}\rightarrow X_n$ (almost sure convergence) as $m\rightarrow\infty$, and $X_m\rightarrow X$ (almost sure convergence) as $m\rightarrow\infty$. I am trying to determine whether these conditions are sufficient to establish that $X_n \Rightarrow X$ as $n\rightarrow\infty$, or if not, what additional assumptions would have to be made in order to ensure the result. This is what I have done so far. Let $f$ be continuous and bounded. Using continuity of $f$ and then its boundedness (to apply dominated convergence theorem) we have:
$$\mathbb{E}(f(X))=\lim_{m\rightarrow\infty}\mathbb{E}(f(X_m))=\lim_{m\rightarrow\infty}\lim_{n\rightarrow\infty}\mathbb{E}(f(X_{n,m})).$$
If I could interchange the two above limits, I would be able to conclude, since:
$$\mathbb{E}(f(X))=\lim_{n\rightarrow\infty}\lim_{m\rightarrow\infty}\mathbb{E}(f(X_{n,m}))=\lim_{n\rightarrow\infty}\mathbb{E}(f(X_{n})),$$
also by continuity of $f$ and dominated convergence. However, I am having difficulties proving that we can effectively interchange these two limits (to do so, one of the two limits needs to be uniform), and wondering if the assumptions I currently have are sufficient? Any comments or ideas would be greatly appreciated.</p>

<p>update: I think it's probably better to consider $f$ to be continuous with compact support instead, as we can therefore use the uniform continuity of $f$.</p>
",probability
"<p>A box contains two coins: a regular coin and one fake two-headed coin (P(H)=1). One coin is choose at random and tossed $n$ times. </p>

<p>If the first n coin tosses result in heads, What is the probability that the $(n+1)^{th}$ coin toss will also result in heads?</p>

<hr>

<p>My solution:</p>

<p>$$\text{Required Probability} = \frac{1}{2}\times \left(\frac{1}{2}\right)^n \times \frac{1}{2}+\frac{1}{2} \times 1^n \times 1$$</p>
",probability
"<p>Suppose that you are playing blackjack against the dealer. In a freshly shuffled deck (standard $52$ cards), what is the probability that neither of you are dealt a blackjack. Blackjack being $2$ cards adding to $21$ i.e. $Ace + 10,J,Q,or K$ (or vice versa as order does not matter).</p>

<p>The farthest I've really come is that the odds of the first player getting dealt a blackjack is $128\over 2652$. </p>

<p>First case: Odds of getting an Ace are $4\over52$, odds of the next being 10,J,Q,or K are $16\over51$.</p>

<p>Other case: Odds of getting 10,J,Q,or K are $16\over52$ and Ace $4\over 51$ so ${((4*16)*2)\over (52*51)} == {128\over 2652}$</p>

<p>Not sure where to go from here...</p>
",probability
"<p>Having two binary numbers of length 6, what is the probability that they match exactly? What is the probability that they have hamming distance of exactly 1?  or of 2?  </p>

<p>For the first part, the number of possible variants of the binary number is 2^6 I believe. What is the probability of the second binary number matching the first?  It seems to me that this probability would be 1/2 ^ 6?  </p>

<p>If this probability is found is it a simple matter to then find the probability of when they mismatch by exactly one number?  </p>
",probability
"<p>We note that given a probability distribution function $P$ over a space $U$ the expected value of a function of the elements in U:</p>

<p>$$ E(f(x)) = \int_{U} f(x)P(x) $$ </p>

<p>We thus consider the mean as the expected value of the numbers that is:</p>

<p>$$ E(x) = \int_{U} x P(x) $$</p>

<p>Now we consider ""standard deviation"" to be the expected difference between a variable from the mean that is</p>

<p>$$ Std(x) = E(|x - E(x)|)  = E\left(\sqrt{(x - E(x))^2}\right) $$</p>

<p>Yet Standard deviation is always measured as:</p>

<p>$$ \sqrt{E((x - E(x)^2)} $$</p>

<p>The latter formula doesn't make sense to me. Can someone explain why mine is wrong and hte latter is corret?</p>
",probability
"<p>Consider the following game of chance. A fair coin is tossed until the first tails appears.
You place an initial bet of k. If the 1st tails appears on the nth toss, you receive a total of $2^n$ (2 to the power of n) in return for your initial bet. How large should k be in order for your expected winnings to be zero (note, expected winnings of zero is sometimes called a “fair” game)?</p>

<p>I did the question and the answer comes to infinite. Is that correct? If not, what did I do wrong?</p>

<p>In other words, we can rephrase the question as: what is the expectation value of $2^n$ given $p(n)=1/2^{(n+1)}$?</p>
",probability
"<p>The material I'm reading derives Jeffrey's prior (or rather, the Fisher information for the Jeffrey's) for single-parameter binomial distribution in a manner quite similar to <a href=""https://en.wikipedia.org/wiki/Fisher_information#Single-parameter_Bernoulli_experiment"" rel=""nofollow"">this Wikipedia article</a>.</p>

<p>I could work out the steps until (following Wikipedia's notation, $A$ is number of successes, $B$ failures, $A+B$ total number of trials)</p>

<p>$$E [\frac{A}{\theta^2} + \frac{B}{(1-\theta)^2}] \\
= \frac{E[A]}{\theta^2} + \frac{E[B]}{(1-\theta)^2}
$$</p>

<p>Maybe my background in probability calculus is just lacking, but I'm not exactly sure about the justification for this step. $E[\frac{A}{\theta^2}] + E[\frac{B}{(1-\theta)^2}]$ follows from the linearity properties of expected value, but the next step? Are we treating $\frac{1}{\theta^2}, \frac{1}{(1-\theta)^2}$ as constants?</p>
",probability
"<p>I have this scenario:</p>

<blockquote>
  <p>1 animal with 30% probability of be moved to Japan. <br> 1 animal with
  30% probability of be moved to Japan. <br> 1 animal with 30%
  probability of be moved to Japan. <br> 1 animal with 30% probability
  of be moved to Japan. <br> 1 animal with 30% probability of be moved
  to Japan. <br> 1 animal with 30% probability of be moved to Japan.
  <br> 1 animal with 30% probability of be moved to China. <br> 1 animal
  with 30% probability of be moved to Japan. <br> 1 animal with 80%
  probability of be moved to Brazil. <br> 1 animal with 30% probability
  of be moved to Japan. <br> 1 animal with 20% probability of be moved
  to Brazil. <br> 1 animal with 30% probability of be moved to Japan.
  <br> 1 animal with 50% probability of be moved to Mexico. <br> 1
  animal with 30% probability of be moved to Japan. <br> (...)</p>
</blockquote>

<p>Resuming, 10 animals with 30% of probability of being moved to Japan.</p>

<p>Is that ""right"" to expect that 3 animals gonna be moved to Japan?</p>

<p>The formula is:
30/100 * 10 = 3</p>

<p>Can I use <strong>Binomial Distribution</strong> for this scenario?
If yes, how to elaborate the formula?</p>

<p>Thanks a lot!</p>
",probability
"<p>I understand the question but I am not sure how to solve it. For example, if we flip HHHTTTTT then the next three must be heads because of the question. This however seems counterintuitive. I believe that there are $2^{10}$ possible strings, but I am unsure of how to count all possible strings that begin with HHH.</p>
",probability
"<p>Given that time interval $T^*$ in seconds between certain events has a negative exponential distribution. </p>

<p>The instrument cannot detect intervals which are less than $\delta$ seconds.</p>

<p>Let $T_1, ..., T_n$ be a sample of independent intervals measyred by the instrument. The distribution of one of those observation $T_i$ is the conditional distribution of $T^*$ given that $T^*&gt;\delta$</p>

<p>In this question, if I want to find the probability density function of $T_i$, should I consider the <strong>shifted exponential distribution</strong> such that:
$$f_T(t) = \begin{cases} \lambda e^{-\lambda (t- \delta)} &amp; t&gt;\delta, \\ 0 &amp; otherwise \end{cases}$$</p>

<p>with $E(T)=\delta + \frac{1}{\lambda}$ and $Var(T) = \frac{1}{\lambda ^2}$ </p>

<p>Thank you</p>
",probability
"<p>Let $X,Y$ be two i.i.d. r.v.'s with zero mean and unit variance. If $X+Y$ and $X-Y$ are independent, then $X$ and $Y$ are both standard normal distributed.</p>

<p>Is there any short proof for this problem?</p>
",probability
"<p>There are two independent variables X and Y. Y is an input for non deterministic algorithm f, and the output of f(Y) is Z. How to prove that X and Z are independent?</p>
",probability
"<p>I'm trying to calculate the probabilities of different lengths of repetitions of X length number however I know I'm doing it incorrectly since when I add all the probabilities together they don't total to 1</p>

<p>e.g. 
Here is my reasoning to calculate the probabilities of the different lengths repetitions for length 4</p>

<p>Probability that there are 0 repeating sequences: 
e.g. WXYZ
10/10 * (9/10)^3 = 729</p>

<p>Probability that there is 1 repeating sequence of length 2: 
e.g XXYZ or YXXZ or YZXX
10/10 * (9/10)^2 * 1/10 * 3 = 243</p>

<p>Probability that there is 2 repeating sequence of length 2: 
e.g XXYY or YYXX
10/10 * 9/10 * (1/10)^2 * 2 = 18</p>

<p>Probability that there is a repeating sequence of length 3: 
e.g XXXY or YXXX
10/10 * 9/10 * (1/10)^2 * 2 = 18</p>

<p>Probability that there is a repeating sequence of length 4:
e.g XXXX
10/10 * (1/10)^2 * 3 = 1</p>

<p>When I add the number of outcomes I get 1009, when I should be getting a 1000.
Anyone know what I'm doing wrong?</p>

<p>Thanks in advance!</p>
",probability
"<p>I have recently seen a probability question which says<br>
""i am asking randomly the persons I met if they are having two chidren and one of them is a boy who was born on tuesday. At last I met one whose answer is yes. What is the probability that the other child is also a boy. Assume equal probability to either gender and equal probability to be born on each day of the week""<br></p>

<p>I could actually solve it to 2/21. Did I do it right or can some one help me solve it?</p>
",probability
"<p>I'm a little confused in some simple question in probability theory,</p>

<p>Say that the probability for rain in London in some random day is $P_{rain}$; and the probabilities of rain in one day and another are independent.</p>

<p>We know that the probability for rain in exactly 3 days of 7 is $C(7,3) \cdot P_{rain}^3 \cdot(1-P_{rain})^4$.</p>

<p><em>Question:</em> Say that I arrived to London in a rainy day, what's the probability of rain in 3 days of the current week?</p>

<p>Does it equal $C(6,2) \cdot P_{rain}^2 \cdot(1-P_{rain})^4$ ? (I think so because of the fact that the probabilities are independent...)</p>
",probability
"<p>Assuming I can play forever, what are my chances of coming out ahead in a coin flipping series?</p>

<p>Let's say I want ""heads""...then if I flip once, and get heads, then I win, because I've reached a point where I have more heads than tails (1-0).  If it was tails, I can flip again.  If I'm lucky, and I get two heads in a row after this, this is another way for me to win (2-1).</p>

<p>Obviously, if I can play forever, my chances are probably pretty decent.  They are at least greater than 50%, since I can get that from the first flip.  After that, though, it starts getting sticky.</p>

<p>I've drawn a tree graph to try to get to the point where I could start see the formula hopefully dropping out, but so far it's eluding me.</p>

<p>Your chances of coming out ahead after 1 flip are 50%.  Fine.  Assuming you don't win, you have to flip at least twice more.  This step gives you 1 chance out of 4.  The next level would be after 5 flips, where you have an addtional 2 chances out of 12, followed by 7 flips, giving you 4 out of 40.</p>

<p>I suspect I may be able to work through this given some time, but I'd like to see what other people think...is there an easy way to approach this?  Is this a known problem?</p>
",probability
"<blockquote>
  <p>Let $X$, $Y$ be independent random variables with the common pdf
   \begin{eqnarray*} f(u) &amp;=&amp; \left\{\begin{array}{ll} u\over2 &amp;
 \mbox{for } 0 &lt; u &lt; 2\\ 0 &amp;\mbox{elsewhere} \end{array}\right.\\
\end{eqnarray*}
  Set up an explicit double integral for $P(X Y &gt; 1)$</p>
  
  <p>Let $Z$ be the maximum of $X,Y$ (That is, $Z = X$ if $X \geqslant Y$, and $Z= Y$ 
   if $Y &gt; X$). Find $P(Z\leqslant 1)$</p>
  
  <p>Find the pdf $g(z)$ of $Z$, being sure to define $g(z)$ for all
   numbers $z$.</p>
</blockquote>

<p>This is a problem on a practice exam I'm studying, but I really have no idea how to approach the problem.</p>
",probability
"<p>Let $\pi$ be a random permutation of $n$ objects and let $ T := \text{the number of transpositions in } \pi $. Use Chebychev's Inequality to find an upper bound for $T\geqslant k$.</p>

<p>Okay the problem I'm having here is with $\mathbb{Var}(T)$, I'm not sure how to find it. I know the expectation is $\frac{1}{2}$, so my formula so far is $$\mathbb{P}\left(T-\frac{1}{2}\geqslant k\right) \leqslant \frac{\mathbb{Var}(T)}{k^2}$$ </p>
",probability
"<p>Let $F$ be the number of fixed points of a random permutation on $n$ items. Show that as $n$ approaches infinity, the distribution of $F$ approaches a Poisson distribution with a mean $(\lambda)=1$.</p>
",probability
"<p>In his book <a href=""http://rads.stackoverflow.com/amzn/click/159420411X"">The Signal and the Noise</a>, Nate Silver presents this example application of Bayes's Theorem on pp. 247-248:</p>

<blockquote>
  <p>Consider a somber example: the September 11 attacks. Most of us would
  have assigned almost no probability to terrorists crashing planes into
  buildings in Manhattan when we woke up that morning. But we recognized
  that a terror attack was an obvious possibility once the first plane hit
  the World Trade Center. And we had no doubt we were being attacked
  once the second tower was hit. Bayes's theorem can replicate this result.</p>
</blockquote>

<p>You can view the complete example in Amazon.com's previw, and I've made the two pages available <a href=""http://imgur.com/YI2rv,nIakZ,rwbYH,MB8U6,07VIA#0"">here</a>.</p>

<p>Silver assumes the prior probability of a terrorist plane attack to be 1 in 20,000. After the first plane crash, using Bayes's Theorem he updates that to 38%. And after the second plane crash, he comes up with a 99.99% probability. However, I think he may be mistaken. I'll provide the details below.</p>

<p>To be precise, let us define the following three events:</p>

<ul>
<li>$PC$ = Plane Crash: At least one plane crashes into a Manhattan skyscraper on a given day. </li>
<li>$TPA$ = Terrorist Plane Attack: At least one plane is intentionally crashed into a Manhattan skyscraper on a given day.</li>
<li>$APC$ = Accidental Plane Crash: At least one plane is accidentally crashed into a Manhattan skyscraper on a given day.</li>
</ul>

<p>We assume all plane crashes into buildings are either terrorist plane attacks or accidental (i.e. $PC = TPA \cup APC$). Using historical data, Silver estimates the prior probability of an accidental plane crash to be 1 in 12,500. In summary: $$P(TPA) = \frac{1}{20000},$$$$P(APC) = \frac{1}{12500}.$$</p>

<p>Furthermore, Silver assumes $P(APC) = P(PC|\overline{TPA})$ (which is true if $APC$ and $TPA$ are independent events).</p>

<p>Applying Bayes's Theorem, he comes up with 
$$\begin{align}P(TPA|PC) &amp;= \frac{P(PC|TPA) \times P(TPA)}{P(PC|TPA) \times P(TPA) + P(PC|\overline{TPA})(1-P(TPA))} \\
&amp;= \frac{1 \times \frac{1}{20000}}{1 \times \frac{1}{20000} + 
\frac{1}{12500} \times (1 - \frac{1}{20000})} = 0.385\end{align}$$</p>

<p>Silver continues:</p>

<blockquote>
  <p>The idea behind Bayes's theorem, however, is not that we update our 
  probability estimates just once. Instead, we do so continuously as new
  evidence presents itself to us. Thus our posterior probability of a
  terror attack after the first plane hit, 38 percent, becomes our
  <em>prior</em> probability before the second one did. And if you go through the calculation again, to  reflect the second plane hitting the World
  Trade Center, the probability that we were under attack becomes a
  near-certainty -- 99.99 percent.</p>
</blockquote>

<p>That is (this is Silver's calculation): $$P(TPA|PC) = \frac{1 \times 0.385}{1 \times 0.385 + 
\frac{1}{12500}(1-0.385)} = 99.99 \%$$</p>

<p>""Cool!"" I thought, until I thought a bit more. The problem is that you can apply the same logic to calculate the conditional probability of an <em>accidental</em> crash, too. I'll spare you the math, but I come up with $P(APC|PC) = 0.615$ after the first crash, and $P(APC|PC) = 99.997\%$ after the second.</p>

<p>So we can be almost certain the second plane crash is a terrorist attack, and we can be even more certain that it's accidental?  </p>

<p>I think the problem is that when Silver applies Bayes's Theorem after the second crash, he uses the updated probability of a terrorist plane attack as his prior, but fails to update the prior probability of an accidental plane crash (which should become 0.615). After the second crash, then, the correct formula is
$$P(TPA|PC) = \frac{1 \times 0.385}{1 \times 0.385 + 
0.615(1-0.385)} = 0.504$$</p>

<p>Similarly, the probability that we're observing an accidental crash given that there have been two crashes is 
$$P(APC|PC) = \frac{1 \times 0.615}{1 \times 0.615 + 
0.385(1-0.615)} = 0.806$$</p>

<p><strong>Question 1</strong>: Am I correct that Nate Silver is doing it wrong?</p>

<p><strong>Question 2</strong>: Am I doing it right?</p>
",probability
"<p>In my book:
$\mathbf{X}=(X_1,\ldots,X_n)$
$f(\mathbf{x})$ is the joint density, where $f$ is either $f_0 \text{ or } f_1$.</p>

<p>Suppose we want to test $H_0: f=f_0$ or $H_1: f=f_1$. The test, whose test function is</p>

<p>$$\phi(\mathbf{X})=1\text{ if }\frac{f_1}{f_0}\geq k;$$</p>

<p>$$\phi(\mathbf{X})=0 \text{ otherwise,}$$</p>

<p>(for some $0&lt;k&lt;\infty$) is a most powerful test of $H_0$ versus $H_1$ at level $E_0(\phi(\mathbf{X}))$.</p>

<p>My question is how is $k$ defined? Can I interpret the lemma as if $\forall k \in (0,\infty)$ there will be a test function $\phi(\mathbf{X})$ such that it will determine the size for which the test with test function $\phi(\mathbf{X})$ is most powerful?</p>

<p>I'm just trying to understand which kind of relationship $k$ and the size of the test have between each other.</p>

<p>EDIT: </p>

<p>Here is a citation from the book I'm using: «the Neyman-Pearson lemma as stated here does not guarantee the existence of an MP $\alpha$ level test but merely states that the test that rejects $H_0$ for $T(X)\geq k$ will be an MP for some level $\alpha$» This makes me want to interpret as $\forall k \exists \alpha$. May I? </p>
",probability
"<p>Suppose I have $n$ random number generators.  Once an hour, on the hour, each one generates a random real number $x_k$ such that $0 \le x_k \lt \infty$. Each generator produces its values according to its own independent probability distribution function $f_k()$, which is a known function.  For example, one generator might follow an exponential distribution, another might follow a normal distribution, etc.</p>

<p>Let $X = \sum\limits_{k=1}^n x_k$ for all of the number generators in any one hour.</p>

<p>Given $y$ such that $0 \le y \lt 1$ (a probability), I need to find a value $z$ such that $P(X \le z) = y$.</p>

<p>Basically, I need to be able to do something like find the value that $X$ will be less than or equal to 50% of the time.</p>

<p>I apologize if I've gotten any of the notation wrong, I'm actually a software engineer so I know some things about math but not others.  I know enough about probability to express the problem above, but I don't even know where to begin in terms of solving it. Any help, or even suggested readings would be much appreciated.</p>
",probability
"<p>Under an insurance policy, a maximum of five claims may be filed per year by a policy holder. Let $p_n$ be the probability that a policy holder files $n$ claims during a given year, where $n = 0, 1, 2, 3, 4, 5.$</p>

<p>An actuary makes the following observations:</p>

<blockquote>
  <p>(i) $p_n\geq p_{n+1}$ for $0\leq n \leq 4$</p>
  
  <p>(ii) The difference between $p_n$ and $p_{n+1}$ is the same for $0 \leq n \leq 4$</p>
  
  <p>(iii) Exactly $40\%$ of policyholders file fewer than two claims during a given year.</p>
</blockquote>

<p>Calculate the probability that a random policyholder will file more than three
claims during a given year.</p>

<p><strong>Source:</strong> Marcel B. Finan's <em>A Probability Course for the Actuaries</em></p>

<p><strong>My thoughts:</strong> The goal is to find $P(n &gt; 3)$. We are given that $P(n&lt;2)=.4$, which means that $P(n\geq2)=.6$. $P(n&gt;3) = p_4 + p_5$. From this, we know that $p_0 + p_1 = .4$, and $p_2 + p_3 + p_4 + p_5 = .6$; so, $p_2 + p_3 + P(n &gt; 3) = .6$. But I don't know how to solve for $p_2$ or $p_3$ to find $P(n &gt; 3)$. Any help would be greatly appreciated.</p>
",probability
"<p>We'll start off with an example of a question of finding expected value.</p>

<p>What is the expected number of tries to get ’6′ when rolling dice?
E(x)=1/6*1 + 5/6 (1+E(x))
E(x)=6</p>

<p>I understand the intuition, there is a 1/6 probability of getting 6 in one roll and 5/6 of not getting 6, so we roll again and add 1 to the counter since we have done one roll. I wonder what is the formal proof of such method?</p>
",probability
"<p>Given a square $S$ with size $1 \times 1$. Two randomly selected points $A$ and $B$ are inside the square. Let $U$ be a square with diagonal $AB$. How to find out the probability $P$($U$ is inside $S$).
<img src=""http://i.stack.imgur.com/KO82j.png"" alt=""example""></p>
",probability
"<p>My task is: assess the probability that for some number $n_0$, $A_n$ will happen for every $n&gt;n_0$, where $A_n = \{|\frac{S_n}{n} -p| \le \epsilon\}$ ($S_n $ is the number of successes in Bernoulli scheme with probability of the success equal to $p$).
I don't really understand what exactly should I do. My first attempt was that I found $P(|\frac{S_n}{n} -p| \ge \epsilon) = e^{\frac{-n\epsilon^2}{4}}$ (which was quite easy to do), but I don't know how to use it here? May somebody show me? I would be grateful.</p>
",probability
"<p>Given $A$, $B$ and $C$ where $A$ and $B$ are mutually exclusive. </p>

<p>If $P(A\cap C)=0.2$, $P(B\cap C)= 0.1$, $P(C)=0.6$, $P(A\cup B)= 0.6$, $P(A\cup C)= 0.8$, and the relation $P(A) = 2P(B)$, find the probabilities of $A$ and $B$.</p>
",probability
"<p>Let us have a walk on $\mathbb Z$ of size $2^n$. To compute the final height of the walk, the trivial way is to sum $1$ for an ascending step and $-1$ for a descending step all along the walk. I would like to have some method to infer the final height in a more efficient way.</p>

<p>More formally, let us denote $\bar h = \frac{h}{2^n}$, where $h$ is the final height. Given an error $\epsilon$ and a probability $p$, I'd like to compute $g$ such that $\mathbb P(\lvert g- \bar h \rvert &gt; \epsilon) &lt; 1-p$, in some ""efficient"" way (i.e in polynomial time in $n$, and the smaller $\epsilon$ and $p$ are, the more I'll give myself time).</p>

<p>What I have is that if I take $i\in \{1,\cdots,2^n\}$, and set $X_i$ to be $1$ if the $i$-th step is ascending and $-1$ if the step is descending, then the expectation of $X_i$ is exactly $\bar h$. I repeat this $k$ times and set $g = \frac{1}{k}\sum_{i=1}^k X_i$. What should be $k$ for $g$ to be close to $\bar h$ with good probability? I guess this should have the flavour of a Chernoff bound, but all I found on this talks about boolean random variables, and I don't know if I can finish we this. How should I conclude?</p>
",probability
"<p>I would like to calculate conditional expectation $E[X|A]$, where $A$ is a set, only from the characteristic function $\phi(\omega)$ of a random variable $X$. How can I do this?</p>

<p>Since the characteristic function describes the density function completely, I should be able to do everything at the frequency domain but I dont know how it can be done. If there is no conditioning then, the result is simply the derivative of the characteristic function.</p>

<p>I also wonder how to calculate 
$$\int_{-\infty}^A f(t)\mathrm{d}t$$
from the chracteristic function $\phi(\omega)$ without going back to the density domain.</p>

<p>Thanks alot...</p>

<p>NOTES:</p>

<p>I found a solution to the second part of my question from</p>

<p>$$F_X(x)=\frac{1}{2}+\frac{1}{2\pi}\int_0^\infty \frac{e^{iwx}\phi_X(-w)-e^{-iwx}\phi_X(w)}{iw} \mathrm{d}w$$
with $F_X(A)$</p>
",probability
"<p>how would I be able to answer this question?</p>

<p>The first box contains 3 white and 7 black balls, and the second box contains 6 white and 3 black balls, A ball is chosen at random from the first box, and, without looking at its colour, put into the second box. Then a ball is chosen at random from the second box, and it is white. Is it more likely that the ball moved from the first box to the second was black?</p>
",probability
"<p>I am currently reading a book ""measure, integral and probability"" by Capinski and Kopp. The correlation between random variables $X$ and $Y$ is defined as the cosine of the angle between $X_c$ and $Y_c$, that is:
$$
\operatorname{corr(X,Y)} = \frac{(X_c,Y_c)}{(\|X\|\cdot\|Y\|)},
$$
where $X_c$, $Y_c$ are centered random variables defined by $X_c=X-\mathbb{E}(X)$, $Y_c=Y-\mathbb{E}(Y)$.
The question that immediately arises is:
Why do we divide by $\|X\|\cdot\|Y\|$, and not $\|X_c\|\cdot\|Y_c\|$? </p>

<p>I want to understand the concept of correlation, independence and other concepts of probability from the point of view of functional analysis. I would be very happy if you could recommend some literature that has a treatment of this topic, and desirably, detailed discussion of the following questions: Are uncorrelated variables just orthogonal? or only if $\mathbb{E}(X)=0=\mathbb{E}(Y)$? How is the ""centred"" vector different from original, ""geometrically""? I know in infinite dimenstions it is hard to visualise geometry, but still... Thank you very much.</p>
",probability
"<p><strong>There are $n$ seats in a room. If $n$ people come to the room, what is the probability that $j$ specified people occupy $j$ specified seats? ($j$ names were tagged on the $j$ seats)</strong></p>

<p>$n$ people can occupy $n$ seats in $n!$ ways.
I can't get my head around how to go forward from here.
Any help would be appreciated.</p>
",probability
"<p>Suppose I have three random variables, $X,Y,Z$ with $X$ independent of $Z$, $Y$ independent of $Z$.</p>

<p>Which transformation can I apply to $X,Y$ to that the result is again a random variable independent of $Z$? Or better, for which $f(x,y)$ is $f(X,Y)$ independent of $Z$?</p>

<p>For example $f(x,y) = xy$ does not work because in general $XY$ is not independent of $Z$. </p>

<p>Is there a general result?</p>
",probability
"<blockquote>
  <p>Suppose we have a box containing $n$ balls numbered $1, 2,\dotsc,n$. A random sample of size $k$ is drawn without replacement and the numbers on the balls noted. These balls are than returned to the box and a second random sample of size $r$ is then drawn without replacement. $(r + k &lt; n)$ Find the probability that two samples contain all different balls.</p>
</blockquote>

<hr>

<p>This was my approach.<br>
Take the $k$ balls first.<br>
Then the probability that of not getting the same $k$ balls again is $$1-\frac{1}{(n)(n-1)(n-2)\dotsm(n-k)}$$
I hope that makes sense.<br>
In this I ignored the second sample size, I don't think that matters. 
Is it right?</p>
",probability
"<p>Suppose a fair coin is tossed $900$ times. Find the probability of getting more than $475$ heads. Use the continuity correction.</p>

<p>My answer:</p>

<p>$n=900, p=1/2, q=1/2$</p>

<p>$\mu=900(1/2)=450, npq=\sigma^{2}=225,\sigma=15$</p>

<p>$Z=(X-\mu)/\sigma$</p>

<p>$P_B(X\geq475)=P_B(475 \leq x \leq 900)$</p>

<p>$=P_N(474.5 \leq 900.5)$</p>

<p>$Z=(X-\mu)/\sigma$</p>

<p>$=(474.5-450)/15=1.63$</p>

<p>$Z=(X-\mu)/\sigma$</p>

<p>$(900.5-450)/15=30.03$</p>

<p>$=P_N(0&lt;z&lt;1.63)+P_N(0,z,30.03)$</p>

<p>$.4484+.5000$</p>

<p>$.9484$</p>

<p>Then we get:</p>

<p>$1-.9484$</p>

<p>$.0516$</p>

<p>I was just trying this problem to see what it would be like after reading about the topic. I wanted to know what I did wrong. The answer says $.0446$. Can someone help me with this?</p>
",probability
"<p>I want to show</p>

<p>Px$(B(s)\ge0 $ for all 0 $\le s \le t$ and B(t) $\in$ M) = Px(B(t) \in M)$-$P-x$(B(t) \in M)$</p>

<p>where,x>0,M is measurable set in [0,$\infty$).</p>

<p>The difficulty for me is how to handle the left side of the equation.I know the distribution of hitting time.But here it is not only about hitting time.</p>
",probability
"<p>Question: </p>

<p>I have $5$ yellow bulbs and $4$ red bulbs. These bulbs will be placed in a straight line such that $2$ on the left side are the same colour as each other, and $2$ on the right side are also the same colour (but not the same as the left side). How many ways are there of planting the bulbs?</p>

<p>I'm really not sure about how to answer this question, I assumed you would go about it by doing $5C2 + 5C3$. But I'm really not too sure. </p>

<p>Thanks!</p>
",probability
"<p>So the question is really hard I think. I tried using a simple way by calculating the probability of each combination that makes a sum divisible by six, but it would take forever. Does anyone have any ideas?</p>

<p>Suppose that we roll a six-sided die ten times. What is the probability
that the total of all ten rolls is divisible by six?</p>
",probability
"<p>I was wondering how the ordinary expectation value $E(X)$ is related to $E(X|\mathcal{F})$ where $\mathcal{F} \subset \mathcal{E}$ where the latter is supposed to be the sigma algebra on our probability space.</p>

<p>My first thought was that $E(X|\mathcal{E}) = E(X),$ but this is clearly wrong, as $X$ is $\mathcal{E}$ measurable and thus $E(X|\mathcal{E})= X.$</p>

<p>Then I noticed that by the total law of expectation $E(E(X|\mathcal{F}))=E(X)$ we have something like a tower property for the standard expectation value, but in the sense that $E(.)$ wins over any $E(.|\mathcal{F}).$ Spoken in terms of tower properties, this would mean that if $E(X)$ can be represented as a conditional expectation, it must be a maximally small sigma algebra. So my guess is $E(X|\{\emptyset, \Omega\})=E(X),$ is this true?</p>

<p>At first glance, it seems to fulfill all the properties of the conditional expectation, so my guess is yes, but I would like to have your confirmation.</p>
",probability
"<p>Determine the probability that in a group of $7$ randomly drawn cards from well
mixed deck of $52$ cards will be exactly $2$ cards with a picture and exactly $4$ red cards (hearts or diamonds)</p>

<p>I don't know how to start I have trouble with reasoning in this case</p>
",probability
"<p>Convergence in Probability talks about two RVs, $X_n$ and $X$ , associated with an experiment  - </p>

<p>$\lim_{n \rightarrow \infty} P\big(|X_n-X| \geq \epsilon \big)=0, \qquad \textrm{ for all }\epsilon&gt;0.$</p>

<p>I'm quite not able to understand what $P( \vert X_n - X \vert &gt; \epsilon)$ means in terms of elementary outcomes of the experiment.</p>

<p>I can understand that $P(X_n &gt; a)$ means the sum of probabilities of all outcomes, $o_i$,  such that $X_n(o_i)$ = $x_i$ and $x_i &gt; a$</p>

<p>Similarly, an expression like $P(X &gt; b)$.</p>

<p>But an expression like $P( \vert X_n - X \vert &gt; \epsilon)$ involves 2 random variables. How do we explain this expression in terms of elementary outcomes of the experiment ?</p>
",probability
"<p>You have $n = n_A + n_B$ $k$-sided dice. The $n_A$ dice are thrown and a <em>set</em> of the resulting values, call it $S_A$, is built; likewise for the $n_B$ dice, calling the resulting set $S_B$.</p>

<p>What is the probability of $S_A \cap S_B = \varnothing$?</p>
",probability
"<p>Past Exam Paper Question -</p>

<p>Prof. Smith is crossing the Pacific Ocean on a plane, on her way to a conference.
The Captain has just announced that an unusual engine fault has been
signalled by the plane’s computer; this indicates a fault that only occurs once in
10,000 flights. If the fault report is true, then there’s a 70% chance the plane
will have to crash-land in the Ocean, which means certain death for the passengers.
However, the sensors are not completely reliable: there’s a 2% chance of
a false positive; and there’s a 1% chance of the same fault occurring without the
computer flagging the error report.</p>

<p><strong>Question</strong> </p>

<p>Formulate this problem in terms of conditional probabilities of outcomes, existence of
a fault and whether or not it is reported and use Bayes’ rule to compute Prof. Smith’s chances of survival. </p>

<p><strong>My Attempt</strong></p>

<p>P(Fault) - 0.0001</p>

<p>P(Crash | Fault) - 0.7</p>

<p>P(FalsePositive | Fault) - 0.02</p>

<p>P(NoReport | Fault) - 0.01</p>

<p>I have no idea what to do next, every example I look at seems  a lot easier than this. Could someone help me out? </p>
",probability
"<p>Consider the random variables $W_i,W_j, X_i, X_j$ with $X_i\sim X_j$, $X_i\perp X_j$ and $W_i\sim W_j, W_i\perp W_j$, where $\sim$ denotes equal probability distribution and $\perp$ denotes independence. </p>

<p>Suppose $W_i, W_j$ are continuously distributed with support $\mathcal{W}$ with everywhere strictly positive density. Suppose $X_i, X_j$ have support $\mathcal{X}$. </p>

<p>Consider the function $p(X_i,X_j): \mathcal{X}\times \mathcal{W}\rightarrow [0,1]$ continuous in $W_i$ $(W_j)$ for any realisation of $X_i$ $(X_j)$. </p>

<p>Consider the function $\lambda(p): [0,1]\rightarrow \mathbb{R}$ continuous in p.  </p>

<p>Suppose that the support of $(X,W)$ is $\mathcal{X}\times \mathcal{W}$. </p>

<p>I think that under these conditions
$$
\mathbb{P}(\lambda(p(X_i,W_i))-\lambda(p(X_j,W_j))&lt;\epsilon| X_i=x, X_j=\tilde{x})&gt;0 \hspace{2cm}(\star)
$$
$\forall x, \tilde{x}\in \mathcal{X}^2, x\neq\tilde{x} $, $\forall \epsilon&gt;0$. </p>

<p>Could you help me to formalise a proof? Do I need $\mathcal{W}$ compact?</p>

<hr>

<p><strong>Attempt:</strong> </p>

<p>(1) Since $\lambda$ is the composition of continuous functions, it is continuous in $W_i$ $W_i$ $(W_j)$ for any realisation of $X_i$ $(X_j)$. </p>

<p>(2) Given $X_i=X_j=x$ (and if $\mathcal{W}$ is compact?) $\exists$ $w,\tilde{w}\in \mathcal{W}^2, w\neq \tilde{w}$ such that $\lambda(p(x,w))-\lambda(p(x,\tilde{w}))&lt;\epsilon$ $\forall \epsilon&gt;0$</p>

<p>(3) Does (2) imply $\lambda(p(x,w))-\lambda(p(\tilde{x},\tilde{w}))&lt;\epsilon$ $\forall \epsilon&gt;0$ $\forall x, \tilde{x}\in \mathcal{X}^2, x\neq\tilde{x} $?</p>

<p>(4) As the support of $(X,W)$ is $\mathcal{X}\times \mathcal{W}$ and $W$ has everywhere positive density on $\mathcal{W}$, $(\star)$
follows. </p>

<p>(5) Where do I use the fact that $X_i\sim X_j$, $X_i\perp X_j$ and $W_i\sim W_j, W_i\perp W_j$?</p>
",probability
"<p>In a book about machine learning, it reads,</p>

<blockquote>
  <p>Generally, the probability that $x$ generated independently by a continuous probability distribution $p(x)$ have the same value is zero. Otherwise, $\int p(x)dx = \infty$. </p>
</blockquote>

<p>Why is it impossible that the same value is sampled more than once?</p>
",probability
"<p>Assume we toss a coin 10 times, independent of each other. 
Each time we can get Heads (H) or Tails (T) , regardless of whether it is fair or not.</p>

<p>So for example this is one possible outcome: HHHHHHHHHH ie 10 heads. Let's call this a 10-toss sequence. </p>

<p>The total number of possible 10-toss sequences is 2^10 because each toss has 2 possible outcomes: Heads or Tails.</p>

<p>--The first question is What is the meaning of 10!/(3!7!) ? The answer is that It is the total number of ways, by which we can place the three heads inside the 10-toss sequence. The order by which we place the three heads does not matter. </p>

<p>--The second question is : What is the total number of possible 3-head sequences?
Is it 10!/(3!7!)? Some say YES. Others, say NO.<br>
A 10-toss sequence with three heads, can be this one: HHH THTHTHT. So three positions are fixed to 'heads'. The remaining seven positions can be H or T. So we have 2^7 possible 7-toss sequences. And the three heads can be anywhere in this 10-toss sequence. </p>

<p>So an answer can be that the total number of 10-toss sequences with 3 heads is 10!/(3!7!) multiplied by (2^7) . That is in the 10-toss sequence the number of ways by which we can place 3 heads is 10!/(3!7!). Then, we have to say something about the remaining 7-toss sequence. Each position can take Heads or Tails . So 2^7 is the possible number of this 7-toss sequence. </p>

<p>However, I know that the correct answer is 10!/(3!7!) and that we don't need to multiply by 2^7. But I cannot understand why.  </p>
",probability
"<p>In an example, where a test has a maximum score of $200$, and a minimum score of $0$, can one eliminate the infinite boundaries?</p>

<p>Let's say my $\mu$ is $100$, and my $\sigma$ is $50$. Integrating the normal function for $200 \leq X$, I get:</p>

<p>$$\int^\infty_{200} \frac{e^{-\frac{(x-100)^2}{2\times50^2}}}{50\sqrt{2\pi}}dx \approx 0.022$$</p>

<p>There is a 2.2% chance that one will score over the limit of 200. Is there any way to make scoring over 200 impossible, and changing the maximum bound from $\infty$ to 200, and $-\infty$ to 0 in a way, that the integral below is true:</p>

<p>$$\int^{200}_{0} \frac{e^{-\frac{(x-100)^2}{2\times50^2}}}{50\sqrt{2\pi}}dx = 1$$</p>
",probability
"<p>If $Y_1,\ldots,Y_n$ independent each having pdf:
$$ f(y\mid \beta,\theta, x)=\theta e^{-\theta(y-\beta x)},~~ y&gt;\beta x$$
where $x_1,\ldots,x_n$ are given, the parameters $\beta$ and $\theta$ are unknown. I know the joint sufficent statistics for $\beta$ and $\theta$ are $\overline{Y}$ and $\min\{Y_i\}$. But can I say that the sufficient statistic for $\beta$ is $\min\{Y_i/X_i\}$?</p>

<p>I don't know why, but I feel strange calculating sufficient statistics for only part of the parameters.</p>
",probability
"<p>I have been working on this problem from a previous exam in Probability theory but I can't understand the next step I am supposed to take. Here is the problem:</p>

<p>Suppose that $Z_1$ and $Z_2$ are independent exponential random variables with
parameter 1 and let $X=\frac{Z_1}{Z_1 + Z_2}$.
Find the cumulative distribution function of X and identify the corresponding distribution.</p>

<p>I tried this:
$$
\begin{align}
P(X \le x) &amp;= P(\frac{Z_1}{Z_1+Z_2} \le x)\\
&amp;= P(Z_1 \le xZ_1+xZ_2)\\
&amp;= P(Z_1 \le Z_2(\frac{x}{1-x}))\\
&amp;= P(Z_1 \le g(Z_2))\\
\end{align}
$$</p>

<p>At this point I would like to use CDF for $Z_1$ like this $1-e^{-x*g(Z_2)}$ but the key uses
$\int_{0}^{\infty}e^{-x}P(Z_1 \le\frac{x}{1-x}z)dz$.  How do I make this jump because it doesn't seem to follow from the work I have done.</p>
",probability
"<p>I am using Ross' A First Course In Probability (4th). On page 113, Example 1d states the following:</p>

<blockquote>
  <p>Independent tirals consisting of the flipping of a coin having
  probability $p$ of coming up heads are continually performed until
  either a head occurs or a total of $n$ flips is made. If we let $X$
  denote the number of times the coin is flipped, then $X$ is a random
  variable taking on one of the values 1, 2, 3, ..., n with respective
  probabilities</p>
  
  <p>$P\{X=1\} = P\{H\} = p$</p>
  
  <p>$P\{X=2\} = P\{(T,H)\} = (1-p)p$</p>
  
  <p>$P\{X=3\}=P\{(T,T,H)\} = (1-p)^2p$</p>
  
  <p>.</p>
  
  <p>.</p>
  
  <p>.</p>
  
  <p>$P\{X=n-1\}=P\{(T,T,...,T,H)\}=(1-p)^{n-2}p$</p>
  
  <p>$P\{X=n\}=\{(T,T,...,T,T),(T,T,...,T,H)\}=(1-p)^{n-1}$</p>
</blockquote>

<p>There are a couple of things that are confusing to me here. To my understanding, they are defining $X$ to be ""the number of times the coin is flipped until a head occurs or a total of $n$ flips is made."" Then, We would have $P\{X\}$ to be</p>

<p>$P\{X = n\} = \sum\limits_{i=1}^n (1-p)^{i-1}p^i + (1-p)^i$    , isn't it?</p>

<p>Also, wouldn't $P\{X=n\} =(1-p)^{n-1}p$? How does it turn out to be $(1-p)^{n-1}$?</p>

<p>Any help would be appreciated.</p>
",probability
"<p>I am new in this forum and I am happy to find it, because it seems a very precious place for asking questions.
My question is  about some probability inequality. I formulate this as following.
Let $(X_k)_{1\leq k \leq K}$, with $K$ a nonzero integer, be a discrete-random variables live in   $\{2, ..., n\}$ where $n \geq 2$ . Then, if  $(n_k)_{0\leq k \leq K}$, with $n_0 =1$, is a sequence of integers in  $\{1, ..., n\}$, one can prove that
$$ \mathbb{P}\big( \exists k\in \{1, ...., K\};\, X_k \leq n_{k-1}\big) \leq \sum_{k=1}^K 2^{k-1}\mathbb{P}\big(\max\{ 1\leq \ell \leq K; X_\ell \leq n_{\ell-1}\} = k\big).
$$ </p>

<p>Thank you very much for your sugggestions, </p>

<p>Emera</p>
",probability
"<p>This is what I got. $\dfrac{1}{6} \cdot \dfrac{1}{6} = 2.78\% \cdot 24 = 66.72\%$</p>

<p>I believe that since it is a six sided dice, since you roll both of them simultaneously it would be $\dfrac{1}{6} \cdot \dfrac{1}{6}$. </p>

<p>So since they are rolling them $24$ times, I would just multiply it by $24$, so $2.78\% * 24$ would be $66.72\%$, which would mean I have a  $67.7\%$ chance of rolling a double six.</p>

<blockquote>
  <p>Do you think this is correct? Am i doing this correctly? </p>
</blockquote>
",probability
"<p>I'm facing the following problem.</p>

<p>Let's say I have N dices in a hand. I need to calculate how much time I should roll my dices to make all of them equal selected (pre-defined) number. Each time when I roll dice with selected number I'm removing this dice(s) from my hand and roll the rest.</p>

<p>Example:
I have 2 dices and I want to all six. I'm rolling two dices until I will get 6 (or possible two) six. When I will get one I will remove this dice and will roll 1 dice instead of two. How much times I need roll dices in my hand to get all six (to make my hand empty)?</p>

<p>I suppose that correct answer is (for two dices): 1/6 + 1/6 + 1/6*1/6 but it seems to be wrong because I tried to implement algorythm to calculate probability running 1M continuous rolls to calculate average amount of required rolls.</p>

<p>Any help appreciated</p>
",probability
"<p>I've had a crack at this question however I don't seem to be getting the correct answer and I can't figure out why. I've been given a table of the 'Normal Distribution Function' where the left tail is tabulated for $0\leq x\leq 4$.</p>

<blockquote>
  <p>Given that $Z\sim N(0,1)$, what is the value of $P(-1.1 &lt; Z &lt; 0.35)$
  to 4 decimal places?</p>
</blockquote>

<p>My working is as follows:
Rearranging the equation first then looking up the values in the given tables.
$$P(Z &lt; 0.35) - P(X &gt; -1.1)$$
$$P(Z &lt; 0.35) - P(X &lt; 1.1)$$
$$0.6368 - 0.8643 = -0.2275$$</p>

<p>The given answer for this question is $0.5011$.</p>

<p>Could someone please explain where I'm falling short and how to correctly solve this question?</p>
",probability
"<p>A family is considering buying a dog. The probability that they will buy a small dog is $0.1$, that they will buy a medium-size dog is $0.3$, that they will buy a large dog is $0.2$, and that they will buy a very large dog is $0.1$. What is the probability that the family will buy a dog? </p>
",probability
"<blockquote>
  <p>Let $\phi_X(t)$ be the characteristic function of $X$. Let $N$ be a Poisson random varivale with mean $1$ and $(X_i)_{\in\mathbb{N}}$ be i.i.d. copies of $X$. Then how to derive the charactersitics function of $S=\sum_{i=1}^NX_i$.</p>
</blockquote>

<p>My attempts: $\phi_S(t)=E(e^{it\sum_{i=1}^NX_i}).$ How to continue?</p>
",probability
"<p>A restaurant has 3 fish dishes, 6 meat dishes and 5 vegetarian dishes on the menu. Suppose that customers select their dish at random. Five customers enter the restaurant.
Note that more than one customer can have the same dish.</p>

<p>a) What is the probability that the first customer chooses a vegetarian and two fish dishes are chosen?</p>

<p>b)What is the probability that two customers choose a fish dish given that only one customer chooses a vegetarian dish?</p>

<p>c)What is the probability that the first customer orders a fish and the second, a vegetarian?</p>

<p>Very interested in how probability distribution can be used in solving these, my current approach was the conventional use of combinations and permutations but not getting the correct answers.</p>
",probability
"<p><strong>Problem.</strong> Suppose we have $n + 1$ random variable $\xi_0, \xi_1, \dots, \xi_n$ and they are independent and all standard normal distributed. Find probability that $\xi_0$ greater than $\max\{\xi_1, \dots, \xi_n\}$ at least in $\alpha &gt; 1$ times.</p>

<p><strong>Solution.</strong></p>

<ol>
<li><p>Let's find distribution of $\max\{\xi_1, \dots, \xi_n\}$. For me it's pretty obvious and intuitive that if $\xi_0$ has a distribution $F(x)$ and density $f(x)$ then $\max\{\xi_1, \dots, \xi_n\}$ distributed like $(F(x))^n$ and its density will be $f(x)n(F(x))^{n-1}$.</p></li>
<li><p>Let's integrate it over suitable domain.
$$
\int_{-\infty}^{+\infty} \int_{\alpha y}^{+\infty} f(x) n(F(y))^{n-1}f(y) dx dy = \int_{-\infty}^{+\infty} (1 - F(\alpha y)) n(F(y))^{n-1}f(y) dy
$$</p></li>
</ol>

<p>and I don't know how to deal with this integral because $F(x)$ has no good explicit form.</p>
",probability
"<p>I got this problem:</p>

<p>Given a $7\times 7$ grid, if we distribute $29$ disks on the grid such that each square cannot hold more than $1$ disk, what is the probability that there will be at least one row full of disks on the grid?</p>

<p>My first try:<br/>
$P(\{\text{there is at least one row full of disks}\}= \frac{7\times{42\choose 22}}{49\choose 29}$</p>

<p>Since we have $7$ ways to choose the row that we will fill by disks, and then we have remaining $22$ disks which we will distribute over the remaining $42$ squares. But this is obviously wrong since we count some combinations multiple times.</p>

<p>My second try:<br/>
$P(\{ \text{there is at least one row full of disks}\}= P(\{\text{there is exactly 1 row full of disks}\}\cup\{\text{there is exactly 2 rows full of disks}\}\cup\{\text{there is exactly 3 rows full of disks}\}\cup\{\text{there is exactly 4 rows full of disks}\})=P(\{\text{there is exactly 1 row full of disks}\}+P(\{\text{there is exactly 2 rows full of disks}\}+P(\{\text{there is exactly 3 rows full of disks}\}+P(\{\text{there is exactly 4 rows full of disks}\}$</p>

<p>But this probably makes things harder and does not simplifies things.</p>

<p>My third try:<br/>
$P(\{\text{there is at least one row full of disks}\}= 1-P(\{\text{there are no rows full of disks}\})$</p>

<p>But I got stuck, I tried to count the number of combinations in which each row got an empty square but here too I counted some combinations multiple times.</p>

<p>Any hint/help will be appreciated.</p>
",probability
"<p>How do we use the Chernoff bound to prove that </p>

<p>$$ Q(x)\leq e^{-\frac{x^{2}}{2}} $$</p>

<p>where Q(x) is the probability that a standard normal random variable X takes a value greater than x</p>
",probability
"<p>I am having a very hard time understanding Strict Sense Stationary Random Processes(SSSRP). One of the examples I am given has $X[n]$ being a SSSRP. We then have $Y[n] = X[n]^2$. Does this make $Y[n]$ SSS? </p>

<p>I originally thought yes, because $Y[n+t] = X[n+t]^2$ which would make it SSS, correct? </p>

<p>(Homework)</p>
",probability
"<p>I just came back from a class on Probability in Game Theory, and was musing over something in my head.</p>

<p>Assuming, for the sake of the question:</p>

<ul>
<li>Playing cards in their current state have been around for approximately eight centuries</li>
<li>A deck of playing cards is shuffled to a random configuration one billion times per day</li>
<li>Every shuffle ever is completely (theoretically) random and unaffected by biases caused by human shuffling and the games the cards are used for</li>
<li>By ""deck of cards"", I refer to a stack of unordered $52$ unique cards, with a composition that is identical from deck to deck.</li>
</ul>

<p>This would, approximately, be on the order of $3 \cdot 10^{14}$ random shuffles in the history of playing cards.</p>

<p>If I were to shuffle a new deck today, completely randomly, what are the probabilistic odds (out of $1$) that you create a new unique permutation of the playing cards that has never before been achieved in the history of $3 \cdot 10^{14}$ similarly random shuffles?</p>

<p>My first thought was to think that it was a simple matter of $\frac{1}{52!} \cdot 3 \cdot 10^{14}$, but then I ran into things like <a href=""http://en.wikipedia.org/wiki/Birthday_Paradox"">Birthday Paradox</a>.  While it is not analogous (I would have to be asking about the odds that any two shuffled decks in the history of shuffled decks ever matched), it has caused me to question my intuitive notions of Probability.</p>

<p>What is wrong in my initial approach, if it is wrong?</p>

<p>What is the true probability?</p>

<p>And, if the probability is less than $0.5$, if we how many more years (centuries?) must we wait, assuming the current rate of one billion shuffles per day, until we reach a state where the probability is $0.5$+?   $0.9$+?</p>

<p>(Out of curiosity, it would be neat to know the analogous birthday paradox answer, as well)</p>
",probability
"<p>Randomly break a stick (or a piece of dry spaghetti, etc.) in two places, forming three pieces.  The probability that these three pieces can form a triangle is $\frac14$ (coordinatize the stick form $0$ to $1$, call the breaking points $x$ and $y$, consider the unit square of the coordinate plane, shade the areas that satisfy the triangle inequality <em>edit</em>: see comments on the question, below, for a better explanation of this).</p>

<p>The other day in class<sup>*</sup>, my professor was demonstrating how to do a Monte Carlo simulation of this problem on a calculator and wrote a program that, for each trial did the following:</p>

<ol>
<li>Pick a random number $x$ between $0$ and $1$.  This is the first side length.</li>
<li>Pick a random number $y$ between $0$ and $1 - x$ (the remaning part of the stick).  This is the second side length.</li>
<li>The third side length is $1 - x - y$.</li>
<li>Test if the three side lengths satisfy the triangle inequality (in all three permutations).</li>
</ol>

<p>He ran around $1000$ trials and was getting $0.19$, which he said was probably just random-chance error off $0.25$, but every time the program was run, no matter who's calculator we used, the result was around $0.19$.</p>

<p>What's wrong with the simulation method?  What is the theoretical answer to the problem actually being simulated?</p>

<p>(<sup>*</sup> the other day was more than $10$ years ago)</p>
",probability
"<p>Two mathematicians each come into a coffee shop at a random time between 8:00 a.m. and 9:00 a.m. each day. Each orders a cup of coffee then sits at a table, reading a newspaper for 20 minutes before leaving to go to work.</p>

<p>On any day, what is the probability that both mathematicians are at the coffee shop at the same time (that is, their arrival times are within 20 minutes of each other)?</p>
",probability
"<p>Recently I discussed an experiment with a friend. Assume we start a random experiment. At first there is an array with size $100,000$, all set to $0$. We calculate at each round a random number modulo $2$ and select one random position in that array. If the number in the array is $1$, nothing is changed and otherwise the pre-computed value is set. The question is: how many distinct hash values would we have added in $1$%, $5$%, $50$%, $95$%, $99$% of all cases?</p>

<p>Example: $4$ rounds with array of size $10$:</p>

<pre><code>Array                     Position   random number
[0,...,0]                    5              0
[0,...,0]                    7              1
[0,...0,1,0,0,0]             6              1
[0,..0,.1,1,0,0,0]           6              0
[0,..0,.1,1,0,0,0]           2              0
</code></pre>

<p>First we considered this a somehow simple problem, but after thinking for some hours, searching the web, and asking some math students, we couldn't find a solution. Do you know a probability distribution for this problem? </p>

<p>Remark: Was also posted on <a href=""http://mathoverflow.net/questions/33335/looking-for-a-probability-distribution"">Math Overflow</a> and got its answer there.</p>
",probability
"<p>Say there are three jars, $j_1, j_2, j_3$ filled with different binary sequences of length two.  </p>

<p>The distribution of the binary sequences in each of the jars is given by the $p_i^k(1-p_i)^{n-k}$, where 
$p_i = \frac{i}{m + 1}$ where $m$ is the number of jars, $i$ is the jar index, $k $is number of 1$$'s and $n$ is the length of the string.  </p>

<p>So for three jars we have $p_1 = 0.25, p_2 = 0.5$, and $p_3 = 0.75$ for $j_1, j_2, j_3$ respectively.  </p>

<p>Here are the sequences and their probabilities for $j_1$ with $p_1 = 0.25$:</p>

<p>\begin{align*}
P(00) = 9 / 16 \\
P(10) = 3 / 16 \\  
P(01) = 3 / 16 \\  
P(11) = 1 / 16.
\end{align*}</p>

<p>If I tell you that I have selected a binary sequence and the first element is $1$ what is the E($p_i$)?</p>

<p>Well, this can be calculated by looking at each of the jars and adding up the probability of candidate sequences times the value of $p_i$.</p>

<p><strong>Edit:</strong> I wasn't normalizing this conditionally space properly. I'm skipping a step which I'll explain, someone wants.</p>

<p>\begin{equation*}
E(p_i) = (4/24 * 1/4) + (8/24 * 1/2) + (12/24 * 3/4) = 14 / 24 = 0.58.
\end{equation*}</p>

<p>So the question is ... what is $E(p_i)$ when the numbers of jars goes to infinity (or alternatively, when $p$ can take on values between $0$ and $1$)? Also what happens when the size of the binary strings goes to infinity? Does it have an effect on the outcome? If it does, does the order we take the limits change the answer?</p>

<p>And most importantly what is the general case for when I have $s$ 1's and $r$ $0$'s?, with a continuous $p$ from $0$ to $1$ and infinite sequences?</p>
",probability
"<p>A rather fundamental concept which I somewhat failed to grasp and now is jeopardising my further understanding/solving of probability problems..</p>

<p>In the case of this question, where we are to find the probability, that the minimum of two throws of a fair die equals $k$, $k \leq 6, k \in \mathbb{N}$, do we have to account for the ordering of the dice? </p>

<p>I.e., assuming $k = 3$, is the probability $P(\{3\}) = \frac{1}{6}\times\frac{4}{6}\times 2$ in order to account for the fact that the first throw could be $3$ and the second throw anything from $3$ onwards OR vice versa (the first throw anything from $3$ onwards and the second throw $= 3$)? Or should it just be $P(\{3\}) = \frac{1}{6}\times\frac{4}{6}$ since the dice are similar and there is no mention that the two dice are unique (e.g. different in colour, size etc.).</p>

<p>The general question, hence, is, for cases where coins/dice are involved and are not uniquely labelled, should the order be regarded, if there is no additional mention of a first/second throw? </p>

<p>Hope you all get my drift..</p>
",probability
"<blockquote>
  <p>Let $A$ and $B$ be events, $P(A) = \frac{1}{4} $, $P(A\cup B) = \frac{1}{3} $ and $ P (B) = p $. </p>
  
  <ol>
  <li>Find $p$, if $A$ and $B$ are mutually exclusive.</li>
  <li>Find $p$, if $A$ and $B$ are independent.</li>
  <li>Find $p$, if $A$ is a subset $B$.</li>
  </ol>
</blockquote>

<p>Can someone help me to solve it?</p>
",probability
"<p>$n$ balls, each with a weight $p_i$, are thrown into $m$ bins. Each bin is chosen with uniform probability.</p>

<p>Prove or disprove that the expected value of the maximum load among the loads of bins is $\frac1m\sum_{j=1}^n p_j$, where with ""load"" means the sum of the weights of the balls in that bin.</p>

<p>Now, I was able to model the problem on the expected value of each bin and this is:
$E[X_i]=\frac1m\sum_{j=1}^n p_j$, where $X_i$ is the load of the bin $i$.</p>

<p>Should I calculate something like this:
$$E[\max_{1 \leq i \leq n} {X_i}]$$</p>

<p>Do you have any idea? Or is the equation to disprove? But, I have no idea how to have to find a counterexample to disprove with expected values.</p>
",probability
"<p>Suppose we pick a random real number between 0 and 1 and call it $x$. There are $2^{\aleph_0}$ possible values, so the chance of picking any specific number (such as $x$) in that range is 0. But in the end, we did manage to pick $x$, despite its probability of 0.</p>

<p>Does this mean that a 0% chance is actually possible, or is there some flaw in this logic?</p>
",probability
"<p>Given the probability density function of the random variable $X$ is $f_X(x)$ and the probability of set $A=\{x:a&lt;X&lt;b\}.$ How can we find the conditional probability density function $f_{X\mid A}(x)$?</p>

<p>My attempt:</p>

<p>When $x\notin A$, $f_{X\mid A}(x)=0.$</p>

<p><strong>Correction according to comment</strong>
When $x\in A$, $f_{X\mid A}(x)=\cfrac{f_X(y)}{P(A)}$ where $P(A)$ is the probability of even $A$.</p>

<p>This seems to give a valid probability distribution that sums to 1. But I am not sure if it is correct. Also is it a definition that I just wrote? Or can we derive it from some fundamentals?</p>

<p>Thanks a lot in advance. </p>
",probability
"<p>Suppose I have $20$ red balls in one box and $20$ blue balls in another box. There $12$ red balls and $7$ blue balls have stars on them. </p>

<p>I randomly take out one red ball and one blue ball at each time, don't put them back, and repeat this $10$ times. </p>

<p>What is the probability that I get one red ball with stars and one blue ball with stars for at least $5$ times?   </p>
",probability
"<p>I have four random variables <strong>A,B,C</strong> and <strong>S</strong>. A,B and C are conditionally independent given S. So, I need to obtain <strong>P(A,B,C,S)</strong></p>

<p>By the chain rule:
$$P(A,B,C,S)=P(S)P(A|S)P(B|A,S)P(C|A,B,S)$$
By the conditional independence
$$P(B|A,S)=P(B|S)$$
Is this correct? $$P(C|A,B,S)=P(C|S)$$
So $$P(A,B,C,S)=P(S)P(A|S)P(B|S)P(C|S)$$</p>

<p>Also I have doubts in the calculation of the joint probability between A,B and C.
$$P(A,B,C)=P(A)P(B|A)P(C|A,B)$$
I am not sure how to compute $P(C|A,B)$ I know the diverse marginal probabilities and conditional between two variables.
Thanks.</p>
",probability
"<p>Suppose $\sum_{n=1}^\infty X_n = \infty$ almost surely for nonnegative $X_n$. Let $\mathcal F_n = \sigma(\{X_0, X_1, \ldots, X_n \})$. </p>

<p>Can we show that $\sum_{n=1}^\infty \mathbf{E} (X_n | \mathcal F_{n-1}) = \infty$? </p>
",probability
"<p>Suppose $X_1, X_2, \ldots, X_n$ are a Bernoulli($\theta$) with pmf:</p>

<p>$$P(X|\theta)=\theta^X(1-\theta)^{1-X}, \; X \in \{0,1\}$$</p>

<p>Prove or disprove that $\bar{X}(1-\bar{X})$ is an unbiased estimator of $\theta(1-\theta)$</p>

<p>My attempt:</p>

<p>After taking the expectation of $\bar{X}(1-\bar{X})$, I'm getting $E(\bar{X})-E(\bar{X}^2)$. I know that $E(\bar{X}^2)=Var(\bar{X}^2)+[E(\bar{X})]^2$.</p>

<p>If I'm on the right course, how do I calculate $Var(\bar{X}^2)$?
Or Is there an alternative method for this?</p>
",probability
"<p>First of all, I'm asking this because I'm writing a game, so this is probably not a typical question in probability. However I'm new to game design so I don't even know what this would be called.</p>

<p>Suppose I have a certain event that should occur and the probability of that event happening (over a certain amount of time). For example, let's suppose the probability is 15% per day.</p>

<p>Is there a <em>single calculation</em> I can perform that will, along with an evenly distributed random number, predict <em>when</em> that event will occur?</p>

<p>Predict is probably not the best word to use here, since I'm not going for accuracy in a single prediction, only a realistic distribution, were it to be predicted over and over again with different random numbers.</p>

<p>Ideally it should not be limited to a certain temporal resolution. I.e. it should not be an even number of days, but should be a continuous function giving me a result right down to the second.</p>
",probability
"<p>Suppose you roll a fair 6-sided dice three times. There are $6^3$ possible outcomes and each is equally likely.</p>

<p>Let $A_1$, $A_2$, $A_3$, $A_4$, $A_5$, and $A_6$ be the events that the last value is a $1$,$2$,$3$,$4$,$5$, and $6$ respectively. 
Let $B$ be the event that the first value is less or equal to the second value and the second value is less or equal to the
third value.</p>

<p>What is $P(B)$?</p>

<p>The total probability law states that </p>

<p>$$P(B) = P(A_i)P(B|A_i)+....+P(A_n)P(B|A_n)$$</p>

<p>Let's assume that $x_i$ are values of $A_i\cap B$, then 
$$P(B|A_n) = \frac{x_i}{P(A_i)}$$</p>

<p>What I am getting confused at is that, if I substitute $P(B|A_n)$ in I'd get $$P(A_i)\frac{x_i}{P(A_i)} = x_i+...+x_n$$ which is just the addition of $x_i$'s.</p>

<p>I don't feel this is the correct way to simplify the total probability law. I am looking for some clarification. </p>
",probability
"<p>How to find a Probability Density/Mass Function for a random variable without assuming it follows a predetermined distribution, say, Normal or Poisson etc,. Lets say i have two hours of data of vehicle arrives at a specific point and i want to know what kind of distribution it has? Please help me understand this. Thank You, Guys.</p>
",probability
"<p>Good morning,</p>

<p>I want to calculate the probability density function of a random variate $Z=cos(Y)$, where $Y=Φ_1−Φ_2$ and $Φ_{1,2}∼U(0,2π)$, that is both variables are uniformly distributed in $(0,2π)$ and also independent. This last hypothesis makes $Y$ a triangular distribution in $(−2π,2π)$, so with this pdf:
\begin{equation}
f_Y(y)=\frac{1}{2π}\biggl( 1−\frac{|y|}{2π} \biggr )
\end{equation}</p>

<p>I calculate Z using the funtamental theorem. When $−2π&lt;y&lt;2π$ we have 4 solution to the equation $z=cos(y)$:
\begin{align}
f_Z(z) &amp; =∑f_Y(\cos^{−1}(z)) \biggl |\frac{1}{−\sin(\cos^{−1}(z))} \biggr |  =4⋅\frac{\frac{1}{2π}(1−\frac{|\cos^{−1}(z)|}{2π})}{\sqrt{1-z^2}} \\
&amp;=\frac{2\biggl (1−\frac{\cos^{−1}(z)}{2π}\biggr)}{π \sqrt{1 - z^2}},  \ \ \ \ \ \ −2π&lt;\cos^{−1}(z)&lt;2π
\end{align}</p>

<p>I have now two problems:</p>

<ol>
<li><p>it's not verified the property of normalisation of $f_Z(z)$;</p></li>
<li><p>if I calculate the cumulative distribution function by integrating the pdf from $-1$ to $\infty$
$$
    F_Z(z)=\frac{\cos^{−1}(z)(\cos^{−1}(z)−4π)}{2π^2}+3/2
$$
and compare this CDF with the ECDF estimated with Matlab, the <a href=""http://i.stack.imgur.com/CQIWD.jpg"" rel=""nofollow"">comparison</a> is not good, it's like something's missing.</p></li>
</ol>

<p>Somebody can tell me where's the mistake?</p>

<p>Thanks for your help, </p>

<p>Stephen</p>
",probability
"<p>Recall that a forward contract on $S_T$ contracted at time $t$, with time of delivery $T$, and with forward price $f(t; T, S_T)$ can be seen as a contingent T-claim $X$ with payoff:
$$
X = S_T - f(t; T, S_T)
$$
The forward price is determined at time t in such a way that the price of X is zero at time t, i.e. $\pi(t;X) = 0$.</p>

<p>How can I compute the forward price $f(t; T, S_T )$ in the Black-Scholes model?</p>
",probability
"<p>Assume that $X,X_1,X_2,...$ are iid with characteristic function $\phi(t)=\mathbb E[e^{itx}]$, and let $S_n = X_1 + X_2 + X_3 + ...$.</p>

<p>(a) For a random variable $X$, $X$ and $-X$ have the same distribution iff $\phi$ is real.</p>

<p>Comment: I can show this by the inversion formula. I just plug in the formula; however, is there a simple way to see this rather than writing all the steps out?</p>

<p>(b) Express the characteristic function of the sample average, $\phi_{\frac{S_n}{n}}(t)$, in terms of $\phi$.</p>

<p>Comment: This one is easy. $\phi_{\frac{S_n}{n}}(t) = [\phi(\frac{t}{n})]^n$.</p>

<p>(c) Assume $\phi'(0)=0$. Show that $\frac{S_n}{n}$ converges to zero in probability.</p>

<p>I have no idea about this one.</p>

<p>For (d) and (e), we assume $X$ has density: $f(x)=c\frac{1}{x^2 ln|x|} \chi_{\{|x|&gt;4\}}$, where $c$ is the appropriate normalizing constant.</p>

<p>(d) Show $\mathbb E{|X|}=\infty$</p>

<p>Commnet: Just plug in the definition formula of the expectation.</p>

<p>(e) Show that the ch.f for $X$ has $\phi'(0)=0$.</p>

<p>Like (c), I don't know how to show this one either.</p>

<p>Thanks.</p>
",probability
"<p>If I have a $6,7$ spades in my hand, and the flop shows $4$ clubs, $5$ spades and $Q$ spades. What is the probability I will hit my straight or flush with $2$ cards still to come?  I see $15$ cards that help me with $32$ that don't help me. So about $32\%$ with one card. But with $2$ yet to come?</p>
",probability
"<p>I'm given a circle with point $A$ defined by $(x,y)$. Then $T=1-d[O,A]$, so $T=1-\sqrt{(x^2+y^2)}$.</p>

<p>Asked to find:</p>

<ol>
<li>$P[T&lt;=u]$</li>
<li>$E[T]$</li>
<li>$Var(T)$</li>
</ol>

<hr>

<p>Alright, so $d[O,A]$ has the CDF $u^2$. So, for the first piece, $P[T&lt;=u]=1-u^2$.</p>

<p>However, our professor has given us also the hint that $u^2$ is beta-distributed. For $Y$ that follows a beta distribution,</p>

<p>$$E[Y]=\frac{a}{a+b}$$
  $$Var(Y)=\frac{ab}{(a+b)^2(a+b+1)}$$</p>

<p>So I kind of know what the answers are supposed to be, aside from the fact that I don't see how $u^2$ follows a beta distribution, so I don't know what the values $a$ and $b$ would be. </p>

<p>Ultimately, I think the generalized answers are:</p>

<ol start=""2"">
<li>$$E[T]=E[1-Y]=E[1]-E[Y]=1-\frac{a}{a+b}$$</li>
<li><p>$$Var(T)=Var(1-Y)=Var(T)=\frac{ab}{(a+b)^2(a+b+a)}$$</p>

<p>Help uncovering the beta distribution parameters would be greatly appreciated. Thank you!</p></li>
</ol>
",probability
"<p>I am developing an app that will create a chart and show trends based on a couple factors, but cannot find the <em>correct</em> way of calculating deviations over a period of time where multiple different scenarios are taken into account and averaged. <strong>Here is an example scenario to help:</strong></p>

<p>Lets say we have two people playing games in a casino. Bob and Tom.</p>

<p>Bob plays <code>3000 hands</code> of Mississippi Stud at an average bet of <code>$25/hand</code>.
Mississippi stud has a <code>variance of 121</code>. House edge of <code>5% (-0.05 EV)</code>.
Here is what Bob's end of session results would look like:</p>

<pre><code>Expected Return (ER): -$3,750 (EV * Avg Bet * Hands)
Most Expected (2 Devs): +$26,374.74 (ER + (sqrt(Hands)*((Avg Bet * sqrt(Variance))*2)
Least Expected (2 Devs): -$33,874.70 (ER - (sqrt(Hands)*((Avg Bet * sqrt(Variance))*2)
</code></pre>

<p>Tom plays <code>5 hands</code> of Blackjack at an average bet of <code>$200/hand</code>. Blackjack has a variance of <code>1.44</code>. House edge of <code>0.5% (-0.005 EV)</code>. Here is what Tom's end of session results would look like:</p>

<pre><code>Expected Return (ER): -$26
Most Expected: +$506
Least Expected: -$454
</code></pre>

<p>Calculating these things is very easy. The problem comes when I try to get the average. If I were to combine both into one line chart, and try to find the Most/Least Expected after BOTH players had finished, I get a very unrealistic number. Since Tom only played 5 hands, his play should barely affect Bob's play and possible variance. After both I get:</p>

<pre><code>ER: -$3,776
Most Expected: $13,440.37
Least Expected: -$17,164.40
</code></pre>

<p>This is definitely incorrect because you cannot simply average them and must take into account the weight of duration. Any help would be greatly appreciated.</p>
",probability
"<p>Total number of trials = N. The trials are independent. Probability of success = p. Probability of failure = 1-p. What would be probability of getting m or more consecutive successes?</p>

<p>Is there some online/downloadable efficient software where I can input N, m, p and it gives me the answer? Can scientific calculators can do this job?</p>
",probability
"<p>I have the following problem where I have difficulties grasping the intuition: </p>

<blockquote>
  <p>Lets say we have three boxes, with two of them empty and one
  containing a gold price. Lets say we randomly select one of the boxes.
  After our selection, we are given which one of the remaining two boxes <strong>does not</strong> contain the price. Now the question is: Should I
  stick with my original selection or select another box from the two
  possible alternatives left. What are the probabilities?</p>
</blockquote>

<p>I empirically tried this problem by making a computer program to repeat this experiment 1,000,000 times with first staying with the original choice and then always changing the selection. I got the probabilities to be: </p>

<p>$$P(golden\; price\;with\;original\;selection)\approx33\%$$
$$P(golden\; price\;with\;changing\;selection)\approx 66\%$$</p>

<p>Intuitively the probabilities seem at first to be 50% for both of these choices, but it seems it's not the case. I can't grasp on why?...</p>

<p>P.S. please let me know if my question is unclear</p>
",probability
"<p>We have: $X_n \rightarrow X$ in $L^p$ and $Y_n \rightarrow Y$ in $L^q$. Moreover $p,q&gt;1$ are such that $\frac{1}{p} + \frac{1}{q} =1$. Prove that $X_nY_n \rightarrow XY$ in $L^1$. Please, can you help?</p>
",probability
"<blockquote>
  <p>A fair die and two unbiased coins are tossed. What are possible outcomes of each object and the probability of each outcome?</p>
</blockquote>

<p><strong>My solution:</strong></p>

<ul>
<li>Probability for a fair Die $D$: $\frac{1}{6}$</li>
<li>Probability for unbiased Coin $C_1$:  $\frac{1}{2}$</li>
<li>Probability for unbiased Coin $C_2$: $\frac{1}{2}$</li>
</ul>

<p>So we can calculate it this way:</p>

<p>$$\Pr(D) * \Pr(C_1) * \Pr(C_2) = \frac{1}{6} * \frac{1}{2} * \frac{1}{2} = \frac{1}{6 * 2 * 2} = \frac{1}{24}$$</p>

<p><em>or</em></p>

<p>$$\frac{1}{\binom{6}{1} \binom{2}{1} \binom{2}{1}} = \frac{1}{6 * 2 * 2} = \frac{1}{24}$$</p>

<p><strong>Is this correct?</strong></p>
",probability
"<p>I know that the pdf $X$ conditional on $Y=y$ is
$$f_{X|Y}(x|y)=\frac{f_{(X,Y)}(x,y)}{f_Y(y)},$$
and this can be used to calculate conditional probabilities such as $P(X&gt;\alpha | Y&gt;\beta)$ (for example). My question is know do we find conditional probabilities such as $P(X^2&gt;a|Y=b)$ or things of this nature, wherein there is a transformation of the random variable $X$. </p>
",probability
"<p>What is the probability that in a randomly chosen group of r people at least three people have the same birthday?</p>

<p>I have tried doing this question as fallows- 1-(probability of all people having different birthday+ any 2 people have same birthday+2 people in each of 2 sets have same birthdays but distinct for particular set+probability of 2 people in each of 3 sets have same birthdays but distinct for particular set+.......) </p>

<p>but i can't generalize it....</p>
",probability
"<blockquote>
  <p>Let $50$ balls numerated on a box. Let the event be ""to draw five balls such that the order doesn't matter and there's no replacement"".
  Let $\alpha \in\{1,2,...,50\}$. The probability of $\alpha$ being drawn is given by 
  $\frac{^{49}C_{4}}{^{50}C_{5}}$.</p>
</blockquote>

<p>But if the event is repeated $n$ times, how can I compute the probability of the $\alpha$ number to be drawn again, $p$ times $\left( p \leq n \right)$?</p>

<p>I thought about the binomial distribution where the probability of success is $\frac{^{49}C_{4}}{^{50}C_{5}} \approx 0,1$.</p>
",probability
"<p>Let $X_t,t\geq 0$ be a Poisson process with rate parameter $\lambda$. Compute the Karhunen-Loève expansion of $X$ in interval $[0, T]$. How about the KL expansion of the centered process $X_t−\lambda t$?</p>

<p>The auto-correlation function of Poisson process is $R(s,t)=\lambda^2st+\lambda \min(s,t)$. By definition, KL expansion should satisfy $\int^T_0 R(s,t)\phi_n(t)dt=\lambda_n \phi_n(s)$.</p>

<p>I've problems figuring out how to solve the integrated equation.</p>

<p>For Wiener process, <a href=""http://mathoverflow.net/questions/59337/karhunenloeve-approximation-of-brownian-motion-and-diffusions"" rel=""nofollow"">this link</a> and Wikipedia article on KL expansion was useful.</p>

<p>This is a mirror question of <a href=""http://mathoverflow.net/questions/95941/karhunen-loeve-expansion-of-poisson-process"" rel=""nofollow"">this MO question</a>.</p>
",probability
"<p>A fair die is thrown until a score of less than 5 is obtained. How to find the probability of less than 3 in the last throw?</p>

<p>I am not too sure how to approach this one, any ideas?</p>
",probability
"<p>On <a href=""http://en.wikipedia.org/wiki/Benford%27s_law"" rel=""nofollow"">wikipedia</a> i have find this statement:</p>

<blockquote>
  <p>...it is scale invariant, and the only continuous distribution that fits this (scale invariance) is one whose logarithm is uniformly distributed.</p>
</blockquote>

<p>how can be proven?</p>
",probability
"<p>I am trying to show the following: </p>

<p>\begin{equation*}
E[e^{-\gamma W}]=e^{-\gamma(E[W]-\frac{\gamma}{2}Var [W])}
\end{equation*}</p>

<p>but I really can't remember what I am supposed to do to get from the LHS to the RHS. I have tried using integration this way</p>

<p>\begin{equation*}
\int We^{-\gamma W}dW
\end{equation*}</p>

<p>and then use integration by parts, but even though what I get resembles it, it can't be correct (because $e^{-\gamma W}$ is not the distribution of W).</p>

<p>I have also tried using Taylor series expansion, but I think I am way off, and I don't think an approximation here is what I need, because the equality above is exact.</p>

<p>FYI, this is not homework, I am working through a <a href=""http://www.princeton.edu/~markus/research/papers/liquidity.pdf"" rel=""nofollow"">paper</a> (page 10) and I would really like to know how every step was derived.</p>

<p>Can anyone at least point me to the right direction?</p>

<p><strong>EDIT</strong>: This expectation on the RHS is very similar to the moment generating function formula (with a negative exponent). If you check <a href=""http://en.wikipedia.org/wiki/Moment-generating_function#Examples"" rel=""nofollow"">here</a>, you will see that the moment generating function for the normal distribution is like the LHS (but with a positive sign). So in a way I have my answer, but I still would like to know how to derive it, if there is a way. I know little if anything at all about moment generating functions, so maybe I shouldn't try and derive it but rather just use the result? Does it even make sense to try and derive it?</p>
",probability
"<p>When I have watched Deal or No Deal (I try not to make a habit of it) I always do little sums in my head to work out if the banker is offering a good deal. Where odds drop below ""evens"" it's easy to see it's a bad deal, but what would be the correct mathematical way to decide if you're getting a good deal?</p>
",probability
"<p>Let $P$ be a probability function. It satisfied <a href=""http://en.wikipedia.org/wiki/Probability_axioms"" rel=""nofollow"">probability axioms</a>. Can we deduce from it that if $P(A)=0$ then $A=\emptyset $ ?</p>
",probability
"<p>I'm failing to understand how to come to the answer to this question.</p>

<p>If you roll a fair die six times, what is the probability that the numbers recorded are $1$, $2$, $3$, $4$, $5$, and $6$ in any order?</p>

<p>The answer given is $6!(1/6)^6 = 3/324$</p>

<p>Can anyone explain to me how to get to that answer? I would really appreciate the help! :)</p>
",probability
"<p>There is a classic problem:</p>

<blockquote>
  <p>Suppose that $X_1,\ldots,X_n$ form an i.i.d. sample from a distribution with the following pdf:</p>
  
  <p>$$f(x\mid\theta) = 
\begin{cases}
e^{\theta-x}\quad&amp;\text{for }\, x&gt; \theta \\
0 &amp;\text{otherwise}.
\end{cases}$$</p>
</blockquote>

<p>I would like to show that the MLE of $\theta$ does not exist. </p>

<p>The argument I have is that the likelihood function will be a maximum when $\theta$ is made as large as possible subject to the strict inequality $\theta &lt; \min\{X_1, \ldots, X_n\}$. Therefore, the value $\theta = \min\{X_1,\ldots , X_n\}$ cannot be used and there is no MLE.</p>

<p>However, I do not understand WHY we want $\theta$ to the equal to the maximum of the values. </p>

<p>Also, is there a way to show mathematically why this MLE doesn't exist?</p>

<p>I get that the log-likelihood function is:</p>

<p>$$L(\theta) = n\theta - (X_1+\ldots+X_n)$$</p>

<p>but when you differentiate via $\theta$ and set to $0$, we get:</p>

<p>$n=0$. How does the fact $n=0$ fit into the fact the MLE doesn't exist for $\theta$? Thanks!</p>
",probability
"<p>Let $X$ be random variable such that $\begin{align} F_X(x) = 1- e^{-x} \end{align}$ if $x \ge 0$ and $F_X(x)=0$ in other case. Find distribution function $Y= \min(1,X)$, $Z=\max(1,X)$. </p>

<p>If I have to find $\max(X,Y)$ or $\min(X,Y)$ ($X,Y$ - random variable) I don't have any problem. But in this case I have number - what should I do?</p>
",probability
"<p>A wheel of fortune is divided into 40 sectors, numbered from 1 to 40. Tickets are sold representing each sector. Tickets are \$1 each. All 40 tickets must be sold before the wheel can be spun. Only the winning ticket receives a \$10 prize.  Calculate the probability of winning the \$10 prize in one game and again in the next game.</p>
",probability
"<p>Given $\bar{X} \sim N(\bar{\mu}, \sigma)$ is a vector of independent continuous random variables (with identical variance) and $Y_j = ( \bar w_{j} \cdot \bar X + b_j &gt; 0)$ is a set of dependent discrete random variables is there a nice expression for the joint probability $P(Y_0 = 1, Y_1 = 1)$?</p>

<p>Also, I think the marginal distributions are given by: </p>

<p>$P(Y_j=1) = \int^{\infty}_{0} N(\bar w_j \cdot \bar \mu + b_j, \sigma) dx = 0.5 - 0.5 erf \left ( -{\bar w_j \cdot \bar \mu + b_j \over \sigma \sqrt {2}} \right )$</p>

<p>Is this correct?</p>
",probability
"<p>I have a midterm I am studying for and I don't have the solutions to this homework problem. Can anyone please explain how to do it? I would really appreciate it.
Here is the problem:</p>

<p><a href=""http://i.stack.imgur.com/oTIYm.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/oTIYm.png"" alt=""two tables of MATHEMATICS letters""></a></p>

<p>I googled the answer for this question, but I did not understand the solution. Can anyone please explain or give their own interpretation of the answer? Thanks!!</p>

<p><a href=""http://users.wpi.edu/~hservat/cs2022d12finalsolutions.pdf"" rel=""nofollow"">http://users.wpi.edu/~hservat/cs2022d12finalsolutions.pdf</a> </p>

<p>Page 2 has the solution I am confused about.</p>
",probability
"<p>Suppose you pick a number between $1$ and $30$ uniformly at random. Let $A$ be the event that
the number is even. Let $B$ be the event that the number is divisible by $3$. Let $C$ be the event that the number
is divisible by $5$. Using the above formula, what is the probability that the number is divisible be at least one
of the values $2, 3,$ or $5$?</p>

<p>$$|A|=15$$
 $$ |B| = 10$$
 $$ |C| = 6$$</p>

<p>From what I have worked out</p>

<p>$$P(A) = \frac{1}{2}$$
$$P(B) = \frac{1}{3}$$
$$P(C) = \frac{1}{5}$$
$$P(A \cap B) = \frac{1}{6}$$
$$P(A \cap C) = \frac{1}{10}$$
$$P(B \cap C) = \frac{1}{15}$$</p>

<p>I am using the formula of inclusion=exclusion</p>

<p>$$ P(A ∪ B ∪ C) = P(A) + P(B) + P(C) − P(A ∩ B) − P(A ∩ C) − P(B ∩ C) + P(A ∩ B ∩ C)$$</p>

<p>When I add it all up I end up with $P(A ∪ B ∪ C) = 1.03$ </p>

<p>How is that possible? Logically, there are 8 numbers that would not divide by $2,3,5$ Thus, if you take the opposite, there should be $\frac{22}{30}$ probability that you would get a number divisible by $2,3,5$. So what am I doing wrong?!</p>
",probability
"<p>Let $X\to Y\to Z$ be three random variables.</p>

<p>The data processing inequality states $I(X;Y)\geq I(X;Z)$.</p>

<p>Further assume $Y=f(X)$ where $f:\mathcal{X}\to\mathcal{Y}$ is an arbitrary function.</p>

<p>What more can we say about how $I(Y;Z)=I(f(X);Z)$ relates to $I(X;Y)=I(X;f(X))$ and $I(X;Z)$?</p>

<p>I.e. can one somehow add the mutual informations along the path or obtain an inequality relating the three pairwise mutual informations? Somehow the choice of $f$ establishes an upper bound on what information can potentially be shared between $X$ and $Z$, but how does it affect the mutual information $I(Y;Z)=I(f(X);Z)$?</p>
",probability
"<p>There are four Envelopes with letters. Two are chosen Randomly and opened and found that they are wrongly addressed. Find the Probability that there are exactly two wrongly addressed envelopes.</p>

<p>My Try: Let the Envelopes be $E_1$,$E_2$,$E_3$ and $E_4$ and Corresponding Letters be $L_1$,$L_2$,$L_3$ and $L_4$ Since two opened are found wrongly addressed,implies there are minimum of two wrongly addressed envelopes.So Favorable cases are :</p>

<p>$1$.There are Exactly two wrongly addressed Envelopes i.e.,Remaining two are correctly addressed and this can happen in $\binom{4}{2}=6$ ways</p>

<p>$2$.There are exactly three wrongly addressed envelopes i.e., remaining one has correctly addressed and this an happen in $\binom{4}{3}\left(3!-1\right)=20 $ways</p>

<p>$3.$There are exactly four wrongly addressed envelopes and this an happen in $\left(4!-1\right)=23 $ways, so Required Probability is</p>

<p>$\frac{6}{6+20+23}=\frac{6}{49}$. I am not sure whether i have done in a right way, please help me if i am wrong.</p>
",probability
"<p>Boxes 1 and 2 contain 4 white, 3 red and 3 blue balls; and 5 white, 4 red and 3 blue balls respectively. If one ball is drawn at random from each box, what is the probability that both the balls are of the same colour?</p>
",probability
"<p>Say we have custom-marked 6-sided die: 1-2-3 is marked as a toad, 4-5 - as a bird, 6 - as a monkey.</p>

<p>So, what is probability of rolling both toad and monkey rolling 4 dice?</p>

<p>I'm totally confused with this example.</p>
",probability
"<p>I'm studying Markov's chain and a very important condition is the detailed balance condition.I'm a bit curious and my question is:</p>

<p>Why is detailed balance condition called like that?</p>

<p>Anyone explains this name in any book.</p>
",probability
"<p>Assume we have a server, the time between two packets received by our server is defined as exponential distributed with intensity   $\lambda=2 \text{ packets}/10 \text{ mins}$</p>

<p>Now calculate the probability that the time from $X$(random time) until the next packet-received, is $5$ minutes or longer?</p>

<p>We that we can model waiting time as exponential function, therefore we get </p>

<p>$f(t)= (1/10)*e^{-t/10}$</p>

<p>Now we need to find out the probability that the time from $X$(random time) until the next packet-received, is 5 minutes or longer?</p>

<p>We integrate $f(t)$ and get $[e^{-t/10}]$ but i am not sure how to choose my limits ?</p>

<p>Am I thinking right here?</p>
",probability
"<blockquote>
  <p>Two envelopes are given. Envelope 1 contains $x$ dollars and envelope 2 contains $2x$ dollars. We opened one of them and found in it $100$$. Now we have the option  to change envelopes or not.</p>
  
  <ol>
  <li><p>Formulate the problem as a Baisian estimation problem.</p></li>
  <li><p>Is it worthwhile to exchange the envelopes? </p></li>
  </ol>
</blockquote>

<p>This is the original question. In order to simplify it, I added the condition that the envelopes can contain only $5{$},10{$},20{$}$ and $100{$}$ bills. </p>

<p>As I understood, a Baisian estimation problem formulation contains the following terms:</p>

<p>$\Omega$-the set of possible states, $X$-the set of observations,$P$-a probablistic model, $A$-possible actions, $\Gamma$-cost for any action.</p>

<p>I also understood that there is a risk function: $R(\alpha_k|x_j)=\Sigma_{\omega_i\in \Omega}\lambda(\alpha_k|\omega_i)P(\omega_i|x_j)$, a probability to be in a state $\omega_i$: $P(\omega_i|x_j)=\frac{P(x_j|\omega_i)}{P(x_j)}P_0(\omega_i)$, and a total risk function: $R[\alpha(x)]=\Sigma_jR(\alpha(x_j)|x_j)P(x_j)$.</p>

<p>But, I am not sure how to build this risk function for the above exercise.
It seems like the set of optional actions is $a_0$-not exchanging envelopes,$a_1$-exchanging envelopes.
What are the possible states set $\Omega$ for example? What is a possible state in this example? If I choose to exchange envelopes and there are $5+5+10$ bills in envelope 1 and $5+5+10+20$ in envelope 2, is this considred one possible state? Also, what is the cost of being wrong?</p>

<p>Any ideas?
Thanks!</p>
",probability
"<p>My question is based on the beginning of Chapter 8.3.2 in the book ""Modelling Extremal Events"" by Embrechts,Klüppelberg and Mikosch.
We consider a Cramer-Lundberg-Model and assume that the conditions of the Cramer-Lundberg-Theorem are satiesfied.</p>

<p>More specifically:
Let $X$ be a positive random variable with distribution function $F$ and mean $E[X] = \mu$, $Y$ a random variable, which follows an $Exp(\lambda)$-distribution independent of $X$, $c &gt; 0$ a constant.
We set $Z:=X-cY$.</p>

<p>We assume that the Lundberg-Exponent exists, i.e. a  $\nu &gt; 0$, that satisfies 
$
\int_{0}^{\infty} xe^{\nu x}(1-F(x))dx = \frac{c}{\lambda}
$
Further assume that $X$ has a moment generating function, which is finite in some neighbourhood of $0$.</p>

<p>Now consider $\kappa(s):= E\left[e^{sZ}\right]$. My goal is to show that $\kappa(\nu) = 1$, which is stated in the book without further explaination.</p>

<p>I get that:
$
\kappa(\nu) = E\left[e^{\nu Z}\right] = E\left[e^{\nu X}e^{-\nu cY}\right] = E\left[e^{\nu X}\right] E\left[e^{-\nu cY}\right] = E\left[e^{\nu X}\right] \frac{\lambda}{\lambda + \nu c}
$
but I am stuck at this point and don't see how to use the equation above to show that this is equal to $1$.</p>

<p>Any help is appreciated :)</p>
",probability
"<p>I am trying to prove theorem 7.3.23 in Casella and Burger. </p>

<p>Theorem: 
Let T be a complete sufficient statistic for a parameter $\theta$, and let $\phi(T)$ be any estimator based only on T. Then $\phi(T)$ is the best unbiased estimator of its expected value. </p>

<p>Here is my attempt to prove this:</p>

<p>To show that $\phi(T)$ is best unbiased estimator for E[$\phi(T)$], I must show that $\phi(T)$ is uncorrelated with any unbiased estimator of $0$. So I must show that $Cov({\phi(T)}, W)=0$ for any W such that W is an unbiased estimator of $0$. For any W such that E[W]=0, $E[E[W|T]]=0$=>$E[W|T]=0$ by completeness of T. So $E[W|T]=0=E[W]$. So W is independent of T. So W and $\phi(T)$ are uncorrelated? So $\phi(T)$ is best unbiased for  its expected value. Is this correct?</p>
",probability
"<p>I have a Markov chain as follows:</p>

<ul>
<li>$G+1$ finite states, it begins from $s=G$ and completes at $s=0$</li>
<li>A transition ($s\to s-1$) occurs in case if event $A$ happens. No other form of transition is possible. Denote the transition probabilities by $P_{ij}^{A}$</li>
</ul>

<p>We want to improve this system to complete faster. So I devised a set of operations denoted by $B$. If $B$ is successful with probability $\beta$, it is just like $A$ is repeated $k$ times, where $k$ is a random variable with known probability. Otherwise, another [real] $A$ should happen to change the state (with probability 1-$\alpha$). Any advise on how to model the Markov chain of the improved system using on $P_{ij}^A$ is appreciated.</p>
",probability
"<p>I tried to look for a similar question but didn't find the exact thing (the closest I found was <a href=""http://math.stackexchange.com/questions/102673/what-is-the-expected-number-of-trials-until-x-successes"">this</a> but AFAIK it is not the same)</p>

<p>I have $r$ coins that land heads w.p. $p$. I want at least $m$ heads. On the first step I toss all of $r$ coins and from the second step and on I toss only the coins that didn't land heads already.</p>

<p>What is the expected number of steps until I have at least $m$ heads?</p>

<p>Thank you in advance!</p>
",probability
"<p>A and B play a game of chess. They play 20 games of which A wins 12 and B wins 4.The remaining 4 games are drawn.If 3 games are played between them, find the probability that 
i)B wins at least 1 game?ii) the probability that 2 games are drawn?</p>
",probability
"<p>I have a problem about intuition:
substracting the mean of iid RVs seems to increase the mutual information.</p>

<p>Say $X,Y$ are real iid RVs, then $\frac{X-Y}{2}$ and $\frac{Y-X}{2}$ are not independent because one is just the negative of the other?</p>

<p>If this is right, it seems contraintuitive to me, as subtracting the mean is such a usual preprocessing step for iid samples.
What am I missing or where did I go completely wrong? It's probably rather stupid but my intuition fails or tricks me here. Guess I am mixing up things. Sorry.</p>
",probability
"<p>A box contains $3$ coins . Among these three , each of  two coins have the probability of giving head $\dfrac 23$ and the remaining one have the probability of turning head $\dfrac 12$ . One coin is chosen randomly from the box and tossed three times and each time it turns out to be head . What is the probability that the coin chosen from the box was the unbiased one i.e. the one with head probability $\dfrac 12$ ?   </p>
",probability
"<blockquote>
  <p>Let $p,q \in (0,1)$. Let $Y$ be the R.V denotes the number of days of the storm in the ocean. $Y\sim \text{Bin}(n,p)$. Let $X$ be the number of ships drowned during the storm and we know that the number of ships drowned in the $k$-day is $\text{Bin}(k,q)$. Find $E(x)$.</p>
</blockquote>

<p>Now, I look at the solution which starts like this:</p>

<p>$$E(X) = E(E(X|Y)) = E(q+2q+\ldots + Yq) = \ldots $$</p>

<p>Why is it true?  </p>

<p>I thought about splitting $X$ to $\sum_{k=1}^Y X_k$ where $X_k$ is the number of ships drowned in the $k$ day. Hence,</p>

<p>$$E(X|Y) = E(\sum_{n=1}^Y X_k| Y) = \sum_{n=1}^Y E(X_k |Y) = \sum_{n=1}^Y E(X_k) = Y\cdot kq$$</p>

<p>But it's not the right answer, apparently.</p>
",probability
"<p>I looking for confirmation, or not, that I am on the correct track with the following proof.</p>

<p>Show that if $P(A\mid B) = P(A\mid B^c), 0 &lt; P(B) &lt; 1$, then $A$ and $B$ are independent? </p>

<p><strong>Attempt</strong></p>

<p>By way of contradiction assume that $A$ and $B$ are not independent. Then,
\begin{align*}
P(A\mid B)=P(A\mid B^c)&amp;\Rightarrow\dfrac{P(B\cap A)}{P(A)}=\frac{P(B^c\cap A)}{P(A)}\quad\text{by definition}\\
&amp;\Rightarrow P(B\cap A)= P(B^{c}\cap A)
\end{align*}
But this contradicts $0 &lt; P(B) &lt; 1$. Thus, $A$ and $B$ must be independent.</p>

<p>Thank you in advance for any helpful feedback. Cheers.</p>
",probability
"<p>A container contains 4 Red marbles and 2 Green Marbles. I pull out each marble one at a time, without putting an marbles back in. X is a random variable that is the number of red marbles before pulling out a Green. Y is a random variable that is the number of green marbles that I draw out in the first three tries.</p>

<p>What is the Range of X and Y?</p>

<p>Calculate the probability mass function of P(x) for X? (Make a table of the  probability distribution for X)</p>

<p>Is {X ≤ 1} or {Y ≤ 1} likely?</p>

<hr>

<p>I figured the range of X is {0, 1, 2, 3, 4} since you cant have more than 4 marbles coming before Green and for Y is {0, 1, 2} since you're only limited to two green marbles. </p>

<p>For the second question would P(X = 0) = Pr(GGRRRR) since no Reds come before Green and P(X = 1) = Pr(RGGRRRR), P(X = 2) = Pr(RRGGRRR) and so on. I'm not sure how to find these values, since these events aren't independent I would have to make a tree diagram with 6 sets of ""generations"" until I have an outcome space of 6 marbles. </p>
",probability
"<p>Is there a difference between:</p>

<p>$$p(y|x,z) = \frac{p(y,x|z)}{p(x|z)}$$
and
$$p(y|x,z) = \frac{p(y,x,z)}{p(x,z)}$$</p>

<p>I was working on a problem that asks one to prove $p(x, y|z) = p(x|z)p(y|x, z)$ and the second one just came to my mind.</p>
",probability
"<p>You flip a coin with the goal of maximizing the ratio of heads to total flips; you can decide to stop whenever. What is the expected value of this ratio?</p>

<p>My thoughts: The ratio is at least $3/4$. With $1/2$ probability we flip heads first and stop.</p>

<p>Otherwise, we flip until the ratio is $1/2$ (random walks return to the origin with probability $1$) giving an expected ratio of $3/4$. Can we do better?</p>
",probability
"<p>Suppose you want to show $sup_{x\in D}|f_n(x)|\to_p 0$, for $n\to \infty$, where $D\subset \mathbb R$ is a compact interval, $f$ is continuous depending on one or more random variables, and $\to_p$ means convergence in probability. For example, $f_n(x)=\sum_{i=1}^n(X_i-x)$ (this, however, is not the problem).</p>

<p>Because showing statements as the one above directly is rather difficult I was wondering if it is sufficient to show $sup_{x\in D}| Ef_n(x)|\to 0$ and $sup_{x\in D}| Var(f_n(x))|\to 0$. Where $E$ and $Var$ are the expectation and variance operator, respectively. If some of you know a good read on this I appreciate your suggestions. Thanks in advance. Cheers.</p>
",probability
"<p>I am wondering if there is a closed form for finding the expected value or variance for a conditional exponential distribution.</p>

<p>For example:
$$ E(X|x &gt; a) $$ where X is exponential with mean $\lambda$.</p>

<p>Same question for variance.</p>

<p>What about for a joint distribution of independent exponentials?</p>

<p>$$ E(X|y &gt; a) $$ where X is exponential with mean $\lambda$, Y is exponential with mean $\theta$ and X &amp; Y are independent.</p>

<p>A sample problem for the actuarial P/1 exam (#124 for those also studying) asks:</p>

<blockquote>
  <p>The joint probability for $f(x,y) = 2e^{-x-2y}, ~ x &gt; 0, ~ y &gt; 0$. Calculate the variance of Y given $x &gt; 3, ~ y &gt; 3$.</p>
</blockquote>

<p>The solution goes like this: (Math on the right, reasoning on the left)</p>

<blockquote>
  <ol>
  <li>$Var (Y|x&gt;3, y&gt;3) =$</li>
  <li>$Var (Y|x&gt;3) = ~~~~~$Independence</li>
  <li>$Var (Y + 3) = ~~~~~$Memoryless</li>
  <li>$Var (Y) + Var (3) =~~~~~$Independence of Y and 3.</li>
  <li>$Var (Y) = ~~~~~ $ Since $Var (3) = 0$.</li>
  <li>$0.25 ~~~~~ $Exponential Variance, $\lambda = 2$.</li>
  </ol>
</blockquote>

<p><strong>So this says to me that  $Var (Y|x&gt;3) = Var (Y)$.</strong>  Is that true?  If so, is it always true?  If not, then how does this solution work?</p>

<p>Could one also replace E(Y) for Steps 1 - 4, Use $E(a) = a$ and get $E(Y| y&gt;a) = E(y) + a$?</p>

<p>Shortcuts like this are immensely valuable for a timed test.  (Not just faster, but less error prone).</p>
",probability
"<blockquote>
  <p>A fair coin is tossed:</p>
  
  <ul>
  <li>If <em>heads</em>: an unbiased die is thrown <strong>three</strong> times. The sum of the outcomes of the three rolls is recorded.</li>
  <li>If <em>tails</em>: an unbiased dice is thrown <strong>once</strong>. The result is recorded.</li>
  </ul>
  
  <p>What are the possible outcomes of each action and the probability of
  each outcome?</p>
</blockquote>

<p><strong>My solution:</strong></p>

<ul>
<li><p>if <em>heads</em>:</p>

<ul>
<li>Dice 1: $\Pr(\frac{1}{6})$</li>
<li>Dice 2: $\Pr(\frac{1}{6})$  </li>
<li>Dice 3: $\Pr(\frac{1}{6})$</li>
</ul>

<p>This outcome will yield  $\Pr(\frac{1}{6}) * \Pr(\frac{1}{6}) * \Pr(\frac{1}{6}) = \frac{1}{36}$</p></li>
<li><p>if <em>tails</em>:</p>

<ul>
<li>Dice: $\Pr(\frac{1}{6})$</li>
</ul>

<p>This outcome will yield  $\Pr(\frac{1}{6}) = \frac{1}{6}$</p></li>
</ul>

<p><em>Am I on the right track?</em></p>
",probability
"<p>If 20 persons were invited for a party, in how many ways will two particular persons be seated on either side of the host in a circular arrangement?</p>

<p>According to me the answer should be $17!.2!$. But the given answer is $18!.2!$.</p>

<p>If we consider the guest and the host as one unit and let them take the first three chairs the other 17 can be occupied by 17! ways and the two particular persons can then rearrange them by 2! ways.</p>

<p>What am i doing wrong?</p>
",probability
"<blockquote>
  <p>A fair die is thrown three times:  </p>
  
  <ul>
  <li>What is the probability of getting: three sixes?  </li>
  <li>What is the probability of getting: six, one, six?</li>
  </ul>
</blockquote>

<p><strong>My solution:</strong></p>

<p>Probability of getting three sixes:</p>

<p>$$\Pr(\text{1st dice six}) + \Pr(\text{2nd six}) + \Pr(\text{3rd six})$$
$$ = \frac{1}{6} \frac{5}{6} \frac{5}{6} + \frac{5}{6} \frac{1}{6} \frac{5}{6} + \frac{5}{6} \frac{5}{6} \frac{1}{6} = 3 \cdot \frac{25}{216} = \frac{75}{216} = \frac{25}{72}$$</p>

<p>Probability of getting six, one, six:</p>

<p>$$\Pr(\text{1st dice six}) + \Pr(\text{2nd one}) + \Pr(\text{3rd six})$$
$$ = \frac{1}{6} \frac{5}{6} \frac{5}{6} + \frac{5}{6} \frac{1}{6} \frac{5}{6} + \frac{5}{6} \frac{5}{6} \frac{1}{6} = 3 \cdot \frac{25}{216} = \frac{75}{216} = \frac{25}{72}$$</p>

<p><em>Am I on the right track?</em></p>

<hr>

<h2><em>Update:</em></h2>

<p>The problem am trying to solve does not specify order. Can we assume that order matters?</p>

<p>How about the following question, would the result be different from the initial question?</p>

<blockquote>
  <p>A fair die is thrown three times:  </p>
  
  <ul>
  <li>What is the probability of getting: three sixes, where the first throw MUST be six?</li>
  <li>What is the probability of getting: six, one, six, where the first throw MUST also be six?</li>
  </ul>
</blockquote>
",probability
"<p>I know this question is asked over and over, but I still can't understand anything.</p>

<p>Say I'm introduced to a random father of two and I want to know what's the probability that both his children are boys. Currently:</p>

<ul>
<li><strong>BB</strong> BG GB GG ⇢ 1/4</li>
</ul>

<p>Where the first letter represents the younger sibling and the second letter represents the older sibling. So far so good.</p>

<p>(1) Now the father tells me that his youngest child is boy:</p>

<ul>
<li><strong>BB</strong> BG <strike><em>GB GG</em></strike> ⇢ 1/2</li>
</ul>

<p>(2) If, instead, he told me that at least one of his children is a boy:</p>

<ul>
<li><strong>BB</strong> BG GB <strike><em>GG</em></strike> ⇢ 1/3</li>
</ul>

<p>Makes sense, kind of.</p>

<p>(3) But if the father brought one of his children with him without telling whether he's the younger child or the older child and that child happened to be a boy, I think I could have still honestly arrived to the 50/50 probability:</p>

<ul>
<li><strong>BB</strong> BG <strike><em>GB GG</em></strike> ⇢ 1/2</li>
</ul>

<p>Where the first letter represents the boy I've just seen and the second letter represents his sibling.</p>

<p>Now, say, the father first told me that he has at least 1 boy. That's the case (2).</p>

<p>Then the father called (one of) the boy(s) here, and somehow the situation turned into the case (3)!</p>

<p>What exactly has changed? What kind of new information did I just get? OK, I've seen (one of) the boy(s), but the only thing it tells me is that one of the children is a boy, which I already knew from the father's own words.</p>

<p>It seems to me that anything he could bring that has some kind of relationship to (one of) the boy(s) so as to allow me to uniquely identify him would work: a photo, a footprint on a beach, etc. Even if he simply told me that he has just thought about one of his children who is a boy, I think I could still have done this:</p>

<ul>
<li><strong>BB</strong> BG <strike><em>GB GG</em></strike> ⇢ 1/2</li>
</ul>

<p>Where the first letter represents the boy the father has thought about at XX/XX/XXXX XX:XX:XX UTC, and the second letter represents his other child.</p>

<p>Is this magic? Or am I just stupid?</p>

<p>Can't I simply construct such a way of identification myself? For example, let the first letter represent the youngest boy (the only boy if there's just one), and let the other letter represent the other child. Since the father is not an abstract entity, this would uniquely identify some child.</p>

<hr>

<p>I don't see how changing the representation changes things.</p>

<p>Say I saw one of the father's on a photo behind a thick blurry glass that doesn't let me see whether it's a girl or a boy. Therefore:</p>

<ul>
<li><strong>BB</strong> BG GB GG ⇢ 1/4</li>
</ul>

<p>Where the first letter represents the child on the photo and the second letter represents the other child.</p>

<p>Now the glass is removed and I can see the photo clearly and it's indeed a boy:</p>

<ul>
<li><strong>BB</strong> BG <strike><em>GB GG</em></strike> ⇢ 1/2</li>
</ul>
",probability
"<p>(There are 4 districts in the land of Oz. At home, the inhabitants of
each region wear ties of a special colour, Munchkins (M) wear blue, Scarecrows
(S) wear purple, Tin Men (T) wear red and Wizards (W) wear yellow. When visiting the Emerald city however, some inhabitants wear green ties, 25% of Munchkins, 35% of Scarecrows, 45% of Tin Men and 55% of Wizards. As a visitor approaches, the gatekeeper of the Emerald city who knows the tourism rate for the last few years assigns the probabilities as follows:</p>

<p>P(M)=1/3, P(S)=1/4; P(T)=1/6; P(W)=1/4</p>

<p>(i) What is the probability that the visitor will wear a green tie?</p>

<p>(ii) Given that a visitor is wearing a green tie, calculate the
probability that the visitor is a Munchkin.</p>
",probability
"<p>Given a box which contains $3$ red balls and $7$ blue balls. A ball is drawn from the box and a ball of the other color is then put into the box. A second ball is drawn from the box, What is the probability that the second ball is blue? </p>

<p>could anyone provide me any hint? </p>

<p>Please, don't offer a complete sketch of the solution, a hint is enough for me as this is a homework problem. </p>
",probability
"<p>From medical investigations it is known that the symptoms $S_1$ and $S_2$ can appear with three different diseases $K_1, K_2, K_3$. The conditional probabilities $a_{i,j}=P(S_j|K_i), i \in \{1,2,3\}, j \in \{1,2\}$ are given by the following matrix.</p>

<p>$$ A= (a_{i,j}) = \left(
\begin{array}{cc}
 0.8 &amp; 0.3 \\
 0.2 &amp; 0.9 \\
 0.4 &amp; 0.6 \\
\end{array}
\right)$$</p>

<p>In the first part of the question I already calculated $P(S_j)$ and $P(K_i|S_j)$. For the second part of the question, I'm given the conditional probabilities $P(S_1 \cap S_2 |K_i)$ by the following vector $(0.2, 0.1, 0.3)$. Assuming that a patient shows symptoms $S_1$, but not $S_2$, what is the probability that he suffers from $K_1, K_2$ and $K_3$?</p>

<p>So I'm looking for $P(K_i|S_1 \cap S_2^C)$. I can get $P(S_1 \cap S_2^C)$ using $P(S_1 \cap S_2^C) = P(S_1) - P(S_1 \cap S_2)$, but I have problems getting the joint distribution $P(S_1 \cap S_2, K_i)$.</p>

<p>First I was trying to show that $S_1$ and $S_2$ are independent and use that to derive the joint probability, but they are not. Alternatively, is it true that the formula $P(S_1 \cap S_2^C) = P(S_1) - P(S_1 \cap S_2)$ remains true when conditioning on K, so that I have $P(S_1 \cap S_2^C | K_i) = P(S_1 | K_i) - P(S_1 \cap S_2 | K_i)$? Or can anybody help me by providing an alternative way to solve this?</p>
",probability
"<blockquote>
  <p>Let $(\mu_n)_{n\in\mathbb{N}}$ be a sequence of probability measures on $\mathbb{N}$, such that the Laplace transform $\phi_n(\lambda)=\int e^{-\lambda x}\mu_n(dx)$ converges pointwise to a limit $\phi(\lambda)=\int e^{-\lambda x}\mu(dx)$ for some probability measure $\mu$ and $\lambda$ in some non-empty interval $(a,b)$. Prove that $\mu_n$ converges weakly to $\mu$.</p>
</blockquote>

<p>Hint: Fix $\lambda_0\in(a,b)$ and rewrite $\phi_n$ as Laplace transform of the new probability measure $\eta_n(dx)=e^{-\lambda_0x}\frac{\mu_n(dx)}{\phi_n(\lambda_0)}$, with $\eta$ defined similarly. Show that $\eta_n$ is tight and converges weakly to $\eta$ and then deduce that $\mu_n$ converges weakly to $\mu$.</p>

<p>This is the continuity theorem with respect to Laplace transform. I have found it in ""An introduction to Probability"" by Feller. But it doesn't provide proofs clearly. Does anyone see the proof of the the continuity theorem with respect to Laplace transform? Can you recommend me the source about this?</p>
",probability
"<p>Okay so <a href=""http://math.stackexchange.com/questions/835/optimal-strategy-for-deal-or-no-deal"">this question</a> reminded me of one my brother asked me a while back about the hit day-time novelty-worn-off-now snoozathon <a href=""http://en.wikipedia.org/wiki/Deal_or_no_deal"">Deal or no deal</a>.</p>

<h3>For the uninitiated:</h3>

<p>In playing deal or no deal, the player is presented with one of 22 boxes (randomly selected) each containing different sums of money, he then asks in turn for each of the 21 remaining boxes to be opened, occasionally receiving an offer (from a wholly unconvincing 'banker' figure) for the mystery amount in his box.</p>

<p>If he rejects all of the offers along the way, the player is allowed to work his way through several (for some unfathomable reason, emotionally charged) box openings until there remain only two unopened boxes: one of which is his own, the other not. He is then given a choice to stick or switch (take the contents of his own box or the other), something he then agonises pointlessly over for the next 10 minutes.</p>

<h3>Monty hall</h3>

<p>[If you have not seen the monty hall 'paradox' check out this <a href=""http://en.wikipedia.org/wiki/Monty_Hall_problem"">wikipedia link</a> and prepare to be baffled, then enlightened, then disappointed that the whole thing is so trivial. After which feel free to read on.]</p>

<p>There is a certain similarity, you will agree, between the situation a deal or no deal player finds himself in having rejected all offers and the dilemma of Monty's contestant in the classic problem: several 'bad choices' have been eliminated and he is left with a choice between a better and worse choice with no way of knowing between them.</p>

<h3>So???</h3>

<blockquote>
  <p><strong>Question:</strong> The solution to the monty hall problem is that it is, in fact, better to switch- does the same apply here? Does this depend upon the money in the boxes? Should every player opt for 'switch', cutting the 10 minutes of agonising away???</p>
</blockquote>
",probability
"<p>Say a gossip magazine editor is paying 2 sources to gather information about a particular celebrity. From his past experience the editor knows source# 1 is right 80% of time, and source# 2 is right 65% of the time. </p>

<p>Now, for a particular case, the editor wants to be sure at least 95%. Say the source #1, gives the editor some information piece x. What is the end probability in the following cases:</p>

<p>a. source# 2 also gives same information
b. source# 2 gives a different information about same thing than what source#1 gave. </p>

<p>In both above cases, what is the probability of the info from source #1 being correct?</p>
",probability
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://math.stackexchange.com/questions/140836/a-probability-problem"">A probability problem</a>  </p>
</blockquote>



<blockquote>
  <p>Let $A$ and $B$ be events, $P(A) = \frac{1}{4} $, $P(A\cup B) = \frac{1}{3} $ and $ P (B) = p $. </p>
  
  <ol>
  <li>Find $p$, if $A$ and $B$ are mutually exclusive.</li>
  <li>Find $p$, if $A$ and $B$ are independent.</li>
  <li>Find $p$, if $A$ is a subset $B$.</li>
  </ol>
</blockquote>

<p>I know for 1) mutually exclusive: $P(A) + P(B) = P(A \cup B)$, but  how I can find p ? 
I don't know how to solve it. Please help me.</p>

<p>Obs: Sorry for duplicate post.</p>
",probability
"<p>I am trying to prove Boole’s inequality</p>

<p>$$P\left(\ \bigcup_{i=1}^\infty A_i\right) \leq \sum_{i=1}^\infty P(A_i).$$</p>

<p>I can show it of any finite $n$ using induction. What to do for $\infty$ ?</p>
",probability
"<p>Show that if $P(A_{i}) = 1$ for all $i \geq 1$ then $P(\ \bigcap_{i=1}^{\infty}A_i)=1$</p>
",probability
"<p>When playing many board games, the first step is to have everyone roll a die to see who goes first, with a roll off in the case of a tie.  While doing that over the Christmas break, my husband suggested that we roll two dice instead of one, with the assertion that this would make ties less likely.  My brother disagreed, claiming it wouldn't make any difference.  I'm interested in investigating this question.</p>

<p>I've been able to calculate the probability of ties for the case of rolling one die for any number of players, and the case for rolling two dice with two players.  However, I haven't actually found a general solution in either case (I mostly used a brute force approach in the one die case).  Is anyone here aware of any sources that have investigated this issue?</p>

<p>(For the record, I'm pretty sure both my husband and brother have forgotten the conversation, so you don't need to worry about hurting anyone's feelings.  :) )</p>
",probability
"<p>I have what seems like a simple question, but it's been a while since I've done any P/S. So i come to SE for help!</p>

<blockquote>
  <p>Two player pool/billiards: P1 has probability p of sinking a ball on any shot and has N balls remaining, while P2 has prob q and M balls remaining.</p>
  
  <p>Question: What is the probability of the first player winning?</p>
</blockquote>

<p>I can type out my reasoning (and will in an edit - will post before i reason it out though), but my answer has come down to:</p>

<p>$$\sum_{j=0}^{M-1} [p^N q^j \sum_{i=0}^\infty [(1-p)^i (1-q)^i]]$$</p>

<p>Is this correct or close?</p>

<p>Reasoning:</p>

<p>not really theoretical reasoning, but extrapolating the simple cases outwards:</p>

<p>(hit = h, miss = m, with probability p = w/p)</p>

<p>1 ball each: possible victory paths - </p>

<p>P1 wins w/p, </p>

<p>P1 m w/ (1-p), P2 m w/ (1-q), P1 wins w/ p</p>

<p>... etc - $p \sum_{i=0}^\infty (1-p)^i (1-q)^i$</p>

<p>2 and above balls each:</p>

<p>At some point, all the P1 hits must occur - $p^N$</p>

<p>All possible amounts of P2 hits must be accounted for - $\sum_{j=0}^{M-1} q^j$</p>

<p>Every miss variation is accounted for - <em>*</em> &lt;-- This is where i think I am wrong. Is it actually a double sum in and of itself? IE $\sum_{i=0}^\infty \sum_{k=0}^\infty (1-p)^i (1-q)^k$ ?</p>

<p>EDIT: Some wolfram alpha shows me that $\sum_{i=0}^\infty (1-p)^i = \frac 1 p$, so I guess my final final equation can be simplified to</p>

<p>$$\sum_{j=0}^{M-1} \frac{p^N q^j}{pq} $$ ??</p>

<p>etc.</p>
",probability
"<p>what is the probability of a person with a last name “Doe” replacing a house vacated by another “Doe”. Assuming 1% of the population has last name “Doe”? I have a excel sheet where I have 50 most popular name in the US. Let's say ""Doe"" is the most popular name and 1% of the toal population have last name ""Doe""? Let's assume ""John"" is the second most popular name and .8% of the population have last name ""John"". I want to know what is the probability of ""Doe"" replacing a house vacated by another ""Doe""? Or ""John"" replacing a house vacated by another ""John""? Thanks</p>
",probability
"<p>Let there be a family consisting of 2 children such that :</p>

<p>B : Event in which both children in a family are girls.</p>

<p>L : Event in which at least one child is a girl<br>
\begin{align}
P(B\mid L)&amp;=?\\
\text{I found it by enumeration as:}&amp;
\{(g,g),(g,b),(b,g),(b,b)\}\\
P(B|L)=1/3
\end{align}
Is there a way of arriving at this answer <em>without</em> enumerating?
\begin{align}
P(B|L)&amp;=P(BL)/P(L)\\
P(L)&amp;=1-P(\text{No Girls})\\&amp;=1-1/4=3/4\\P(BL)&amp;=?
\end{align}
Obviously, the answer has to be $1/4$ and I can see that from the enumeration but I can't deduce why.</p>
",probability
"<p>I want to calculate a conditional expectation and I do not see where my mistake is. I'm solving the following exercise (namely, 1a):</p>

<blockquote>
  <p><img src=""http://i.stack.imgur.com/IotJc.png"" alt=""enter image description here""></p>
</blockquote>

<p>(<a href=""http://www.math.ethz.ch/education/bachelor/lectures/hs2012/math/mff/MFF_2012_ex05beta.pdf"" rel=""nofollow"">source</a>)</p>

<p>Here $S^1,S^2$ are stochastic processes, which model for example a stock price. At time (day) $0$, $S^1_0=100$, which means that the price of stock one is $100$ unit of money. Then the stock price can go up, with probability $p_u=\frac{2}{3}$ and go down with prob. $p_d=\frac{1}{3}$. Hence at day $1$ it can take the prices $S^1_1=104$ or $S^1_1=98$ and so on.</p>

<p>The exercise want to construct an equivalent martingale measure for $S^1$.
To have an equivalent martingale for $S^1$ I need to find transition probabilities $q_u,q_d=1-q_u$ (u=up, d=down) and $q_{u,u},q_{u,d}=1-q_{u,u},q_{d,u},q_{d,d}=1-q_{d,u}$ such that $S^1=(S^1_k), k=0,1,2$ is a $Q^1$-martingale. The equivalence of the measure follows immediately if $q_j,q_{j,i}&gt;0$, $i,j\in\{u,d\}$. The filtration is generated by $S^1$, i.e. $\mathcal{F}_0=\sigma(S^1_0)$ which is trivial and $\mathcal{F}_1=\sigma(S^1_1)$. To be a martingale under the measure $Q^1$ (which is characterized by transition probabilities $q_j,q_{j,i}$ $i,j\in\{u,d\}$ we have to solve the equations:</p>

<p>$$E_{Q^1}[S^1_1]=100$$
$$E_{Q^1}[S^1_2|\mathcal{F}_1]=S^1_1$$</p>

<p>the first one is easy to solve and gives $q_u=\frac{1}{3}$ and $q_d=\frac{2}{3}$. Now for the second equation I want to use that $\mathcal{F}_1$ is generated by $\sigma(A_1,A_2)$, where $A_1=\{S^1_1=104\},A_2=\{S^1_1=98\}$. Then I know that </p>

<p>$$E_{Q^1}[S^1_2|\mathcal{F}_1]=\sum_{j=1}^2\frac{E[S^1_2\mathbf1_{A_j}]}{Q^1[A_j]}\mathbf1_{A_j}$$</p>

<p>hence for writting this out gives two equations:</p>

<p>$$\frac{1}{Q^1[A_1]}(116.48\cdot q_{u,u}+(1-q_{u,u})\cdot 99.84)=104$$
$$\frac{1}{Q^1[A_2]}(101.92\cdot q_{d,u}+(1-q_{d,u})\cdot 96.04)=98$$</p>

<p>where clearly $\frac{1}{Q^1[A_1]}=\frac{1}{q_u}$ and $\frac{1}{Q^1[A_2]}=\frac{1}{q_d}$. I would get the right result without the $\frac{1}{Q^1[A_j]}$ in the front of the equations. But I do not see why they do not have to be there. Right result: $q_{u,u}=\frac{1}{4}$, $q_{d,u}=\frac{1}{3}$. It would be very helpful, if someone could point out, where I my mistake is exactly.</p>

<p>As mentioned in the comment, I used the following theorem for calculating the conditional expectation:</p>

<blockquote>
  <p>Let $(\Omega,\mathcal{F},P)$ be a prob. space, $A_i\in \mathcal{F}$, for $1\le i\le N\le\infty$ pairwise disjoint measurable sets with $P(A_i)&gt;0$ and $\bigcup_{i=1}^N A_i=\Omega$. Let $\mathcal{A}=\sigma(A_i;1\le i\le N)$. Let $X\in L^1(\Omega,\mathcal{F},P)$, then
  $$E[X|\mathcal{A}]=\sum_{i=1}^N\frac{E[X\mathbf1_{A_i}]}{P(A_i)}\mathbf1_{A_i}$$</p>
</blockquote>
",probability
"<p>I'm reading <a href=""http://machinelearning.wustl.edu/mlpapers/paper_files/BleiNJ03.pdf"" rel=""nofollow"">http://machinelearning.wustl.edu/mlpapers/paper_files/BleiNJ03.pdf</a> and trying to understand the notation and concepts behind LDA, in order to implement it myself. I've followed some tutorials about the Poisson and Dirichlet distribution but I'm not super comfortable with them as topics yet.</p>

<p>Can someone explain what is meant on page 4 of the PDF:</p>

<blockquote>
  <p>LDA assumes the following generative process for each document w in a
  corpus D:</p>
  
  <ol>
  <li>Choose N ~ Poisson(ξ).</li>
  <li>Choose θ ~ Dir(α).</li>
  </ol>
</blockquote>

<p>What are these symbols referring to? Extracting words from the Poisson Distribution? How is that even possible? And extracting parameters from a Dirichlet distribution is equally confusing.</p>
",probability
"<p>I understand that when you apply a transformation $\sigma Y+\mu$ to $Y$~$N(0,1)$ ,we get a new random variable that is distributed $N(\mu,\sigma^2)$. However, I dont know through which mechanism this was obtained. Is it by multiplying the pdf by $\sigma^2$ and adding $\mu$? In general, I usually think about it as the following for normal distribution manipulations:</p>

<p>If you multiply, leave the mean alone but square the variance</p>

<p>If you add, leave the variance alone but add to the mean. </p>

<p>Is there another way of thinking about normal manipulations? Thanks!</p>
",probability
"<p>Let $\{X_i\}_{i\in\mathbb{N}}$ 
be a sequence of random variables taking values in 
$\{\pm e_1,\pm e_2\}$, 
where $\{e_1,e_2\}$ is the standard basis of $\mathbb{R}^2$.
If $\{X_i\}$ are i.i.d. uniformly distributed over $\{\pm e_1,\pm e_2\}$, 
then the simple random walk $S_N$ on $\mathbb{Z}^2$ have the mean square displacement given by $\mathbb{E}[\|S_N\|^2] =N$. We also know that the random 
walk $S_n$ is recurrent, i.e., 
$$
\sum_{n=1}^{\infty}\mathbb{P}(S_{2n}=0)=+\infty.
$$
<b>Question</b> Suppose now that the random variables $X_i$ $(i=1,2,\ldots)$ have some kind of dependence between its coordinates (but the steps $X_{i}'s$ are independent) so that the mean 
square displacement now obeys the following inequality for any $N\in\mathbb{N}$
$$
C_1N^2 \leq \mathbb{E}[\|S_N\|^2] \leq C_2N^2,
$$ 
where $0&lt;C_1&lt;1/2$ and $1/2&lt;C_2&lt;1$ are positive constants.
Is this inequality enough to assures that this random walk is transient ?</p>
",probability
"<p>I had a doubt on one ""diagonlization argument"" used to show Prohorov's Theorem. I am simplifying the discussion, so lets say that we consider the space $\mathbb{R}^{\infty}$
, and a set Π of probability measures on $\mathbb{R}^{\infty}$. Let us assume that $\Pi$ is tight. Now we want to show that it is relatively compact, i.e. every sequence $P_n \in \Pi$ has a subsequence $P_{n^{\prime}}$ which has a weak limit.</p>

<p>This statement below is easily proved:</p>

<p>Statement: Assume that we know that if the replace in the above statement $\mathbb{R}^{\infty}$ by $\mathbb{R}^{k}$
, then it is true, i.e. for a tight set in the set of measures on $\mathbb{R}^{k}$
, every sub-sequence has a weak limit.
Now we note that the projections $π_k$ of elements of $\mathbb{R}^{\infty}$ to $\mathbb{R}^{k}$
 are continuous, which implies that the sets ${Pπ^{−1}_k:P∈\Pi}$ are tight. Hence for every sequence $P_n$, by passing onto subsequence, $π^{−1}_k P_{n^{\prime}}$ has a weak limit. Now there is a ""diagonalization"" argument, which I had a problem absorbing. It essentially says that ""prune"" the above $P_{n^{\prime}}$ inductively to obtain a sequence $P_{\tilde{n}}$ which is such that the projection sequence of measures $π^{−1}_l P_{\tilde{n}}$ have a weak limit for all $l=1,2,\ldots$.</p>

<p>My problem is that if the ""pruning"" of the sequence $P_{n^{\prime}}$ was to be done only finitely many times, I know that after ""pruning"" the left over sequence is non-empty. But the problem here is that I have to prune the sequence infinitely many times, so how come in the end I get a non-empty set? I have seen this diagonalization argument used at many places but no one talks of the non-empty limit set.</p>

<p>I posted this question at some other site and was told this is connected to Tychonoff's Theorem. I get it that if at each step of pruning if I take the closure of the the subsequence, then they are compact, and hence their intersection is compact. But then who guarantees me that the intersection is non-empty??</p>
",probability
"<p>In a problem in the book, there is a batter never swings, and the pitcher has a .5 probability to strike and a .5 to throw a ball.</p>

<p>In this situation, we found:
P(batter strikes out) = 21/32
P(batter walks) = 11/32</p>

<p>(Keep in mind that it takes 3 strikes to strike out and 4 balls to walk)</p>

<p>We found this by adding the probability of the batter striking out on the 3rd, 4th, 5th, and 6th pitch. </p>

<p>To do this:</p>

<pre><code>P(Strike out on 3rd pitch) = (.5)^3 = 4/32  (3 strikes)

P(Strike out on 4th pitch) = C(3, 2)(.5)^2(.5)(.5) = 6/32
</code></pre>

<p>(2 strikes, 1 ball, then another strike)</p>

<pre><code>P(Strike out on 5th pitch) = C(4, 2)(.5)^2(.5)^2(.5) = 6/32
</code></pre>

<p>(2 strikes, 2 balls, then another strike)</p>

<pre><code>P(Strike out on 6th pitch) = C(5, 2)(.5)^2(.5)^3(.5) = 5/32
</code></pre>

<p>(2 strikes, 3 balls, then another strike)</p>

<p>So, add those up to get <code>P(Strike out) = 21/32</code></p>

<p>Find the probability for P(pitcher throws a strike) for which P(batter walks) = P(batter strikes out) = 1/2</p>

<p>My thinking was to turn this into an equation. Let x represent P(pitcher throws a strike). So then we have P(strike out) is</p>

<p>= <code>x^3 + C(3,2)x^3(1-x) + C(4,2)x^3(1-x)^2 + C(5,2)x^3(1-x)^3</code></p>

<p>= <code>x^3( 1 + C(3,2)(1-x) + C(4,2)(1-x)^2 + C(5,2)(1-x)^3</code></p>

<p>This makes it a little easy to try out... but to solve I was thinking that if we need 21/32 to be 1/2 then.... (21/32)x = .5 => x = 16/21. But I am not sure what to do with this</p>
",probability
"<p>From <em>A First Course in Probability (9th Edition)</em>:</p>

<blockquote>
  <p>3.5 An urn contains 6 white and 9 black balls. If 4 balls are to be
  randomly selected without replacement, what is the probability that
  the first 2 selected are white and the last 2 black?</p>
</blockquote>

<p>This method is straightforward and results in the correct answer (according to the book):
$$\frac{6}{15} \cdot \frac{5}{14} \cdot \frac{9}{13} \cdot \frac{8}{12} = \frac{6}{91} $$</p>

<p><em>(This is just the multiplication principle and probability of drawing the color of that ball at that time)</em> </p>

<p>However, I want to understand this in terms of conditional probability. I don't understand why <em>this</em> doesn't work:</p>

<p>$$P(E \mid F) = \frac{P(E \cap F)}{P(F)} ={\frac{{6 \choose{2}}{9 \choose 2}}{{15 \choose{2}}{13 \choose 2}}}÷{\frac{{6 \choose{2}}}{{15 \choose{2}}}} = {\frac{{9 \choose 2}}{{13 \choose 2}}} = \frac{6}{13} \ne \frac{6}{91}$$</p>

<p>$\frac{6}{13}$ is exactly 7 times more than the previous answer. Why does this method fail to work? What mistake have I made? I tried to use the exact same method used in question 3.3, where this resulted in the correct answer. </p>

<hr>

<p>Optional – About 3.3</p>

<pre><code>3.3 Use Equation (2.1) to compute in a hand of bridge the conditional 
probability that East has 3 spades given taht North and South have a 
combined total of 8 spades.
</code></pre>

<p>Here, we see that:
$$P(E \mid F) = \frac{P(E \cap F)}{P(F)} ={\frac{{13 \choose{8}}{39 \choose 18}{5 \choose 3}{21 \choose 10}}    {{52 \choose{26}}{26 \choose 13}}}÷{\frac{{13 \choose{8}}{39 \choose 18}}{{52 \choose{26}}}} = {\frac{{5 \choose 3}{21 \choose 10}}{{26 \choose 13}}} = \frac{29}{115} \approx 0.339$$</p>

<p>Which is the answer in the back of the book.</p>
",probability
"<p>I have N balls and M boxes. The balls are thrown at random onto the boxes. What is the probability that some box contains at least 3 balls? </p>

<p>Based on the Birthday problem, I know how to find the solution to the problem if we are finding the probability that some box contains at least 2 balls.</p>

<p>I am struggling to find the solution to this problem. Any help is much appreciated.</p>

<p>Here is what I have tried:
If we have M boxes and N balls, then the probability that some box contains at least two balls is approximately equal to $$ 1-e ^{ (-n^2 / 2m)} $$</p>

<p>Let us suppose that we have 4 balls and 6 boxes, then the probability that some box has at least 2 balls is approximately equal to $$ 1 - e ^ {(-16/12)} .$$ This is approximately equal to 0.7364.</p>

<p>Now I would like to find the probability that some box will contain at least 3 balls, when 4 balls are thrown at random onto 6 boxes.</p>

<p>Thanks
Sekhar </p>
",probability
"<p>(Quant job Interviews - Questions and Answers - Joshi et al, Question 3.5)</p>

<blockquote>
Suppose you have a fair coin. You start with 1 dollar, and if you toss a H your position doubles, if you toss a T your position halves. What is the expected value of the money you have if you toss the coin to infinity ?
</blockquote>

<p>Now the answer is stated as follows:</p>

<blockquote>
We work out what happens with one toss, then $n$ tosses and then let $n$ tend to infinity.

Let X denote a toss then:
$$\mathbb E (X) = \frac{1}{2} * 2 + \frac{1}{2} * 0.5= {5\over4} $$

Provided the tosses are independent, the product of expectations is the expectation of the product. Let $X_j$ be the effect of toss $j$. This means that
$$ \mathbb E (\prod_{j=1}^{n} X_j) = \prod_{j=1}^{n} \mathbb E (X_j) = ({5\over4})^n$$
this clearly tends to infinity as n tends to infinity
</blockquote>

<p>Now, I don't understand this answer :(</p>

<p>First, the way the answer is written out, surely the ${5\over4}$ is the expectation of the outcome of the first toss $X_1$ , not that of a toss $X_j , j \ge 1$ ?</p>

<p>Secondly, whilst I do understand that the tosses are independent, it would seem that the $X_{j+1}$ is actually quite heavily dependent on the $X_{j}$ before it ?</p>

<p>So then why is it so obvious that $\mathbb E ( X_{j+1} ) = \mathbb E ( X_{j})$ ?</p>
",probability
"<p>My aim is to become sharp in the necessary knowledge of basic probability and counting to follow my studies of Statistics for Computer Science.</p>

<p>Right now I found the following book:</p>

<p><a href=""http://aops-cdn.artofproblemsolving.com/products/intro-counting/toc.pdf"" rel=""nofollow"">http://aops-cdn.artofproblemsolving.com/products/intro-counting/toc.pdf</a></p>

<p>But the price is too high.</p>

<p>Are there any other cheaper alternatives that cover the same ground?</p>
",probability
"<p>Suppose a sample of <strong>120</strong> items is drawn from a population of manufactured products and the number of defective items is recorded. Prior experience has shown that the proportion of defectives is <strong>0.05</strong>.</p>

<p>a) Describe the sampling distribution of <strong>p̂</strong>, the proportion of defectives.</p>

<p>b) What is the probability that the sample proportion is less than <strong>0.10</strong>?</p>

<p>My Work:</p>

<p>a) $$np ≥ 5$$</p>

<p>because</p>

<p>$$ 120*0.05 =6$$</p>

<p>and</p>

<p>$$nq = 120*0.95 = 114 ≥ 5$$</p>

<p>therefore the sampling distribution is approximately normal distributed. </p>

<p>b) $$P(p̂&lt;0.10) = P(z &lt; (0.10-0.05)/[\sqrt{(0.05x0.95)/120)})$$</p>

<p>$$= P(z&lt;0.05/0.0199) = P(z&lt;2.5126)$$</p>

<p>$$ =0.9940$$</p>

<p>resulting in <strong>99.4%</strong>.</p>

<p>I'm not sure if I'm solving this problem properly, any help is greatly appreciated!</p>
",probability
"<p>Let $X_{1}, X_{2},\ldots, X_{n},\ldots$ be independent and identically distributed random variables with distribution</p>

<p>$P(X_{n}=0)=P(X_{n}=1)=P(X_{n}=2)=P(X_{n}=3)=\frac{1}{4}$</p>

<p>Assume that the sequence $\{Y_n\}$ is defined as: $Y_{0}=0$ and for all $n\in\mathbb{N}$ we have</p>

<p>$Y_n=\begin{cases} 3 &amp;\text{if } X_n=3,\\\min{\{Y_{n-1},X_n\}} &amp;\text{if } X_n&lt;3. \end{cases}
$</p>

<p>Compute $\displaystyle \lim_{n\to +\infty}E[Y_{n}Y_{n-1}]$?</p>

<p>I don't know how to start.</p>
",probability
"<p>If I get to draw $3$ cards from a standard deck. </p>

<p>With replacement - a) What is the probability of drawing a $10,J,Q$ in that order?</p>

<p>Without replacement - b) What is the probability of drawing a $10,J,Q$ in that order?</p>

<p>With replacement - c) Drawing at least one ace (I got $= \left(\frac{4}{52}\right)^3$).</p>

<p>Without replacement - d) Drawing at least one ace (I got $= \left(\frac{4}{52}\right)\left(\frac{3}{51}\right)\left(\frac{2}{50}\right)$)</p>

<p>Having trouble with a) and b) I know that order matters so I would have to use combinations.</p>

<p>Any thoughts? Thanks.</p>
",probability
"<p>We flip a fair coin. Then, if the result is tails, we stop.  If it is heads, 
we flip a second time and then stop. Let $X$ be the number of heads from the flip(s). If $X = 0$, let $Y = 0$. If $X = 1$ or $X = 2$, choose $Y$ uniformly at random from the interval $[0,X]$.</p>

<p>How can I find the c.d.f. of $Y$? I know that $P(X = 0) = 1/2$, $P(X = 1) = 1/4$, and $P(X = 2) = 1/4$. But, how can I extend this information to get the c.d.f. of $Y$?</p>
",probability
"<p>You have $n$ urns, each containing $p_i$ white balls and $q_i$ black ones. One of the urns is selected uniformly at random, and balls are extracted with replacement from it until a black ball is found.</p>

<p>What is the distribution of the number of draws needed?</p>

<p>This is simply a random selection out of $n$ independent geometric distributions, but I'm unable to find this particular ensemble anywhere. Does this distribution have a proper name? Is it a geometric distribution itself?</p>
",probability
"<p>In this <a href=""http://math.stackexchange.com/questions/331280/probability-distribution-of-tossing-a-coin-until-obtaining-k-heads"">Question</a> the correct answer is the negative binomial distribution. My problem is: What is the distribution if I want the k heads in a row?</p>

<p>Any help is apreciated.</p>
",probability
"<blockquote>
  <p>The finite population correction in sample survey is :</p>
  
  <p>(A) $n/N$</p>
  
  <p>(B) $N/n$</p>
  
  <p>(C) $1-\frac{n}{N}$</p>
  
  <p>(D) $1-\frac{N}{n}$</p>
</blockquote>

<p>I know that , finite population correction factor is 
$$fpc=\sqrt{\frac{N-n}{N-1}}$$where , $n=$sample size and $N=$population size.</p>

<p>How I can deduce from it to get one option ? Please help..</p>
",probability
"<p>In a dancing party, there are 3 pairs of married couple. Each husband will pick his female dancing partner randomly. So, the probability of every wives will dance with her non-husband is...?</p>
",probability
"<p>I am trying to set up a probability table for the events of drawing two cards from a $52$ card deck. What counts is either an exact match or a match in flush with two already drawn cards from another deck. I am not sure the table is correct, so I would be grateful for a judgement. </p>

<ol>
<li><p>Two exact matches:                        $\frac{1}{1326}$</p></li>
<li><p>One exact match + one flush match: $\frac{13 \times 2-1}{1326}$</p></li>
<li><p>One exact match only:                  $\frac{26 \times2}{1326}$</p></li>
<li><p>Two flush matches:               $\frac{13 \times13\times2-39}{1326}$</p></li>
<li><p>One flush match only:            $\frac{26 \times 26-52}{1326}$</p></li>
<li><p>No match at all:                        $\frac{325}{1326}$</p></li>
</ol>
",probability
"<p>May I please borrow your expertise or could anyone check if I'm on the right track please?</p>

<p>Consider customers arriving at a bank. The bank has $2$ types of customers - business and personal. On average, $10$ business customers arrive per hour, and $20$ personal customers. The times between arrivals of the business customers are independent of each other, and exponentially distributed, and is the same for personal customers. The two streams are independent of each other. Suppose no new customers have entered the bank in the last $5$ minutes.</p>

<p>1) What is the probability that no business customers arrive in the next $3$ minutes?</p>

<p>I'm assuming the arrival time for business customers is 60/10 = 6 customers
Thus, by using the exponential equation and also that this is a memoryless property,</p>

<p>$1 - e^{-3/6}$ (am I on the right track here anyone)?</p>

<p>2) What is the probability that no personal customers arrive in the next $3$ minutes?</p>

<p>Assuming the arrival time for personal customers to be 60/20 = 3 customers
Using the equation from question 1)</p>

<p>$1 - e^{3/3}$ (is this right)?</p>

<p>3) What is the probability that no customers at all arrive in the next $3$ minutes?</p>

<p>Assuming that this is something like $1 - ((1-e^{-3/6}) + (1-e^{-3/3}))$
by adding the no personal customer and business customer together and minus it by 1</p>

<p>4) What is the distribution of the time until the arrival of the next customer?</p>

<p>(Any hints on how I might be able to use to get the answer for this question?)</p>

<p>Your helps are much appreciated. Thanks,</p>
",probability
"<p>For a discrete RV $X$, is it true that the conditional distribution $P_{X \mid Y} (B \mid y)$ is discrete as well for all $y$?</p>

<p>I only managed to prove that this is true almost surely. Let $\Pr(X\in C) = 1$ for countable $C$, then by definition $\Pr (X \in C, Y \in \mathbb{R}) =\mathbf{E} [P_{X \mid Y} (C \mid Y) ; Y \in \mathbb{R}] = 1$.</p>
",probability
"<p>Say I have an image, with pixels that can be either $0$ or $1$. For simplicity, assume it's a $2D$ image (though I'd be interested in a $3D$ solution as well). </p>

<p>A pixel has $8$ neighbors (if that's too complicated, we can drop to $4$-connectedness). Two neighboring pixels with value $1$ are considered to be connected. </p>

<p>If I know the probability $p$ that an individual pixel is $1$, and if I can assume that all pixels are independent, how many groups of at least $k$ connected pixels should I expect to find in an image of size $n\times n$?</p>

<p>What I really need is a good way of calculating the probability of $k$ pixels being connected given the individual pixel probabilities. I have started to write down a tree to cover all the possibilities up to $k=3$, but even then, it becomes really ugly really fast. Is there a more clever way to go about this?</p>
",probability
"<p>I want to solve the following exercise:</p>

<p>Suppose that two sets $X$ and $Y$ are chosen independently and uniformly at random from all the $2^n$ subsets of $\{1, \dotsc, n\}$. </p>

<p>Determine $P[X \subseteq Y]$ and $P[X \cup Y = \{1, \dotsc, n\}]$.</p>

<p><strong>MY IDEA:</strong> </p>

<p>My idea is that a random subset is the same as deciding for each element independently with probability $\frac{1}{2}$ whether it is in the subset or not. </p>

<p>Then $$P[X \subseteq Y] = P[ \forall x \in X \colon x \in Y]$$</p>

<p>Now I have the first problem, because I am not sure how to express the for all $x$ that are in $X$. I mean, is this the same as computing $$\sum_{x=1}^n P[x \in X] P[x \in Y | x \in X] = \sum_{x=1}^n P[x \in X] P[x \in Y] = \frac{n}{4},$$
since this computation does not feel right. Can someone intuitively tell me what the above calculation calculates and how to solve the actual problem? My problem is here that we have somehow to condition on the event that this $x$ is already in $X$, otherwise we need not do anything. </p>

<p>The second one sounds a bit easier to me. There we have
$$P[X \cup Y = \{1, \dotsc, n\}] = P[\forall x \in \{1, \dotsc, n\} \colon x \in X \vee x \in Y] =\prod_{x=1}^n P[x \in X \vee x \in Y] = \prod_{x=1}^n (P[x \in X] + P[x \in Y] - P[x \in X \wedge x \in Y] ) =\prod_{x=1}^n (P[x \in X] + P[x \in Y] - P[x \in X] P[ x \in Y] =  \prod_{x=1}^n (\frac{1}{2}+\frac{1}{2}-\frac{1}{4})= \left(\frac{3}{4}\right)^n.$$
Is this correct? Is there an easier way?</p>
",probability
"<p>I have a somewhat open-ended question. Let's say I have a sequence of random variables $(X_n: n \geq 1)$ which are <strong>neither independent, ergodic, nor identically distributed</strong>. Normally I would say that I am completely dead in the water, <strong>but let's say that $X_n \overset{d}{\to} X$</strong>. Are there any additional assumptions under which I can say that:</p>

<p>$$ \frac{1}{n} \sum_{i=1}^n X_n \;\overset{P}{\to}\; \mathbb{E}X $$</p>

<p>Even if I assume that expectation of the left-hand side converges to $\mathbb{E}X$, I'm stuck thinking about this more generally. Any tips?</p>

<p>EDIT: Thinking about this some more, I feel like making a martingale out of the LHS and then checking under what conditions we have the desired martingale convergence would be a reasonable route to follow. Any thoughts on this?</p>

<p>EDIT 2: per Nate Eldredge's comment below, I need to assume that the expectation of the LHS of the partial-sum object converges to $EX$... it doesn't follow from $X_n \overset{d}{\to} X$. </p>
",probability
"<p>Two piece of gold are contained in two same-looking black boxes respectively. It is known that one piece weights twice as the other, but do not know which is which.  </p>

<p>Two persons, say A and B, randomly choose a box. One person, say A, opened his box, but he does not known whether it is lighter or weightier. </p>

<p>Question: Is A willing to exchange his box with B?</p>

<p>This might be a well-known problem, but I do not know the proper name to search it online. </p>

<p>Intuitive, it make no difference to exchange the boxes.</p>

<p>On the other hand, if we compute the expectation for A, it seems that A should change the box (the expectation is 1.25 of the current holding).</p>

<p>I would like to hear your answer to the question and preferably fuller story about this paradox.</p>
",probability
"<p>Here is lottery machine, if the current no. on the screen is ""1"" then probability of getting ""2"" is ""a"" and probability of getting ""3"" is ""b"" and probability of getting ""1"" is ""c"", after each step.<br>
where ""a""+""b""+""c""=1.<br>
similarly, <br>
if the current no. on the screen is ""2"" then probability of getting ""1"" is ""d"" and probability of getting ""3"" is ""e"" and probability of getting ""2"" is ""f"".<br>
where ""d""+""e""+""f""=1.<br>
and,<br>
if the current no. on the screen is ""3"" then probability of getting ""1"" is ""g"" and probability of getting ""2"" is ""h"" and probability of getting ""3"" is ""i"".<br>
where ""g""+""h""+""i""=1.<br>
<br>
then what is probability of getting ""1"" after exactly k steps, if current no. on screen is:<br>
a)""1"",<br>
b)""2"",<br>
c)""3"".<br></p>
",probability
"<p>Trying to work out the probability of a fault occuring over a 12.5 year time period. The probability of a fault occuring per year is 1/15. </p>

<p>Does this mean the probability of no fault occuring over the period is (14/15)^12.5 = 0.422</p>

<p>And of one fault occuring 1 - 0.422 = 0.578?</p>

<p>How could I go about calculating the probabilty of two faults occuring?</p>
",probability
"<p>My book states that $E[X^2]$ is the average power. It then says for $\mathcal{N}(0, 1)$, the average power is $\frac{1}{2}$ and for $\mathcal{N}(0, \sigma^2)$ is $\frac{\sigma^2}{2}$.</p>

<p>How can this be?</p>

<p>The second moment of the Gaussian is $\mu^2 + \sigma^2$ so the average power for $\mathcal{N}(0, 1)$ should be one and $\sigma^2$ for $\mathcal{N}(0, \sigma^2)$.</p>

<p>It makes since to multiple by $1/2$ since we average by $1/N$ but the book just states the average power is $E[X^2]$ not $\frac{1}{2}E[X^2]$.</p>

<p>Can someone shed some light on this?</p>
",probability
"<p>In Bayesian probability, does the prior distribution $\pi(\theta)$ only depend on $\theta$? For example, suppose the prior distribution of the unknown parameter $\theta$ is binomial. Then does $$ \pi(\theta) = \binom{n}{\theta} p^{\theta} (1-p)^{n-\theta}$$ </p>

<p>Whereas if $f(\theta|x_1)$ is binomial then  $$f(\theta|x_1) = \binom{n}{x_1} p^{x_1}(1-p)^{n-x_1}$$</p>

<p>Is this correct?</p>
",probability
"<p>Is there any way to calculate the restricted Laplace transform of the random variable $X$, i.e., $$ 
\int_{0}^{u}e^{-sx}dF(x)\ 
$$
$(u&lt;\infty)$, based on its Laplace transform?</p>
",probability
"<p>Given the definition of conditional expectation as E$[X|B] = \frac{E[1(B) \cdot X]}{P(B)}$, and understanding $1(B)$ as an indicator function that returns $1 (0)$ when $B$ is true (false), it would seem $E[1(B)\cdot X]$ takes the expected value of members of $X$ where $B$ is true. Why the further division by $P(B)$? Intuitive as well as formal explanation requested.</p>

<p>E.g., suppose we have:</p>

<blockquote>
  <p>$(S,P)$:
  $(1,3)$
  $(1,4)$
  $(0,3)$
  $(0,2)$
  $(0,1)$
  $(0,0)$
  $(1,1)$
  $(1,2)$
  $(1,3)$
  $(0,2)$</p>
</blockquote>

<p>$P(S = 1) = 0.5$, $E[1(S=1) \cdot P] = \frac{13}{5} \approx 2.6 $ (where $1[x]$ is an indicator function that flips to $1$ if $S = 1$ and $0$ if $S != 1$). </p>

<p>Thus $E[P|S = 1] = \frac{E[1(S=1) \cdot P]}{P(S = 1)} \approx 5.2$? What am I doing wrong here?</p>
",probability
"<p>A book has 10 short and 10 long chapters. Short chapters span 10 pages, and long chapters span 20 pages.</p>

<p>Why does the probability that you will pick a long or a short chapter differ between these  strategies?</p>

<p>Strategy #1: Flip to a random page, back up to the start of that chapter, and start reading.<br />
Strategy #2: Flip to a random page, go forward to the start of the next chapter, and start reading (and pick the first chapter if the page you pick lies within the last chapter).</p>
",probability
"<p>Math and probability wasn't ever my strong side, so I need to ask for a help in calculating simple (as I assume) value. Here is situation description.</p>

<blockquote>
  <p>Player <strong>A</strong> throws seven times with ten-side dice (numbers in range 1-10). Writes down results and shows them to player <strong>B</strong>. Player <strong>B</strong> throws three times with the same dice.</p>
  
  <p><em>What is the probabillity that among all ten numbers (both players) there will be no repeats - i.e. all three player <strong>B</strong>'s numbers will be exactly different than all player <strong>A</strong>'s numbers?</em></p>
</blockquote>

<p>This comes from a simple game, that I've been playing. Developer of this game suggests that above mentioned situation can appear fairly often (sometimes 2-3 times per particular game) completely random. While I'm pretty sure, that probability of such situation is so extremely low, that it can't happen that often, without any changes to game random generator, to make game itself much harder to complete. In other words -- I claim that game's random generator is not that random.</p>

<p>Thank you in advance for any help.</p>
",probability
"<p>How would I calculate the probability of randomly selecting a house and getting the current owner’s last naming same as previous owner’s last name? For example, let’s say 1% of the population has the last name “Doe” and picking a house randomly getting the current owner’s name is Doe and the previous owner’s name was Doe too. Thanks </p>
",probability
"<p>Jar $A$ contains $3$ red and $3$ black marbles, and Jar $B$ contains $4$ red and $6$ black marbles. If a marble is randomly selected from each Jar, what is the probability that the marbles will be the same color?</p>

<p>I'm having difficulty approaching this problem.  It seems like I should use Baye's Theorem to solve this problem, that is, let $A = \{\text{select a marble randomly from Jar A and Jar B}\}$ and $B = \{\text{the color of the marbles is the same}\}$.  I think I'm suppose to find $P(A|B)$ by Baye's Theorem.  However, I get stuck here as I need $P(A)$ and $P(B|A)$.  Perhaps my approach is incorrect.   </p>
",probability
"<p>I've heard somewhere from someone about a theorem that roughly says ""the probability of an event decreases as time increases""</p>

<p>I couldn't find the exact theorem (assign it exists at all.)</p>

<p>So figure I should ask all of you great mathematicans here if anyone has ever heard of this.</p>
",probability
"<p>Forgive me if this is really basic:</p>

<blockquote>
  <p>Tammy is a general contractor and has submitted two bids for two projects (A and B). The probability of getting project A is 0.65. The probability of getting project B is 0.77. The probability of getting at least one of the projects is 0.90. What is the probability that she will get both projects?</p>
</blockquote>

<p>Is this a simple question using the addition law or am I missing something? I calculated that her probability of getting both would be 0.52.</p>

<p>(0.65 + 0.77 - 0.90) = .52</p>
",probability
"<blockquote>
  <p>Given the random vector $(X,Y)$ with joint probability $P(0,1)=\frac{1}{18}$, $P(1,2)=\frac{3}{18}$, $P(1,4)=\frac{5}{18}$, $P(2,0)=\frac{2}{18}$, $P(2,1)=\frac{4}{18}$, $P(2,3)=\frac{3}{18}$ and $0$ otherwise, I need to find:</p>
</blockquote>

<ol>
<li>Domain, probability and distribution for $(Y|X=2)$</li>
<li>Domain and probability for $Z=X+Y$</li>
</ol>

<p>1) I need to find the marginal $p_X$ for $X$ as:</p>

<p>$p_X(2)=\sum_yp(2,y)=\frac{2}{18}+\frac{4}{18}+\frac{3}{18}=\frac{9}{18}$</p>

<p>Now I can calcolate che conditional $(Y|X=2)$</p>

<p>$p_{Y|X}(2,0)=\frac{p(2,0)}{p_X(2)}=\frac{2}{9}$</p>

<p>$p_{Y|X}(2,1)=\frac{p(2,1)}{p_X(2)}=\frac{4}{9}$</p>

<p>$p_{Y|X}(2,3)=\frac{p(2,3)}{p_X(2)}=\frac{3}{9}$</p>

<p>2) I read that $p_Z(z)=\sum_{x}p(x,z-x)$, but I don't know how to proceed. And suggestion?</p>
",probability
"<p>I need help with solving one of the questions the teacher gave us to prepare for an upcoming exam. I tried solving it but with no luck. Here is the question:</p>

<blockquote>
  <p>On one shelf there are 5 hardcover books and 6 paperbacks and on the other shelf there are 7 hardcover and 4 paperback. From the first shelf we pick two books randomly and put them on a table and from the second shelf we pick one book randomly and also put it on the table. And at last we randomly pick one book from the table. What is the possibility for that book to be a hardcover?</p>
</blockquote>

<p><strong>EDIT:</strong> I gave it a shot with something like this: I calculated $P1$ like so with fractions $P(5 hard, 6 paper) = 5/11 + 4/10$ - so I can see the probability of taking 2 hardcover books from the first shelf then I gave $P2 7/11$ from the second shelf and the final P(A) I tried adding then together. This was of no use as you can see.. </p>
",probability
"<p>Let $X^1$ and $X^{-1}$ be two simple random walk in $\mathbb{Z}$ starting respectively from $1$ and $-1$. Let $\tau$ be the first time one of them reaches the origin,</p>

<p>$$\tau = \inf \{ j \geq 0 \, : \, X^{-1}(j) = 0 \, \, \mbox{or}\, \,  X^{1}(j) = 0 \}.$$</p>

<p>How much is $E[\tau]$, the expectation of $\tau$?</p>

<p><strong>Comment:</strong> If there was only a random walk, then the expectation of $\tau$ would be infinite, as $P(\tau &gt;k ) \sim 1/k$. However, for two random walks I think it should not be infinite, as $P(\tau &gt;k ) \sim 1/k^2$. How to make it rigorous and compute the exact number? </p>
",probability
"<p>Say we role $n$ identical, fair dice, each with $d$ sides (every side comes up with the same probability $\frac{1}{d}$). On each die, the sides are numbered from $1$ to $d$ with no repeating number, as you would expect. So an ordinary $d$ sided die pool. </p>

<p>Every dice in the outcome that shows a number equal or higher than the threshold number $t$ is said to show a hit. Every die that shows the maximum result of $d$ is rolled again, which we call ""exploding"". If the re-rolled dice show hits, the number of hits is added to the hit count. Dice that show the maximum after re-rolling are rolled again and their hits counted until none show a maximum result. <strong>Given the values of</strong></p>

<p>$$ d\ ...\ \text{Number of sides on each die}\ \ d&gt;0 $$
$$ n\ ...\ \text{Number of dies rolled}\ \ n\ge 0$$
$$ h\ ...\ \text{Number of hits, we want the probability for}$$
$$ t\ ...\ \text{Threshold value for a die to roll a hit}\ \ 0 &lt; t \le d$$</p>

<p><strong>what is the probability to get exactly exactly $h$ hits?</strong> Lets call it: $$p^\text{exploding}(d,n,t,h) = p_{d,n,t,h}$$ 
Can you derive a formula for this probability?</p>

<p><strong>Example roll:</strong></p>

<p><em>We roll 7 six-sided dice and count those as hits that show a <code>5</code> or a <code>6</code>. In this example, $d=6$, $n=7$, $t=5$. The outcome of such a roll may be <code>6</code>,<code>5</code>,<code>1</code>,<code>2</code>,<code>3</code>,<code>6</code>,<code>1</code>. That's three hits so far, but we have to roll the two sixes again (they explode). This time it's <code>6</code>, <code>2</code>. One more hit, and one more die to roll. We are at four hits at this point. The last die to be re-rolled shows <code>6</code> again, we re-roll it yet another time. On the last re-roll it shows a <code>4</code> - no more hits. That gives five hits in total and the roll is complete. So, for this roll $h=5$.</em></p>

<p><strong>Simple case for just one die $n=1$</strong>:</p>

<p>If we roll only one die with the same threshold as above, so ($d=6$, $n=1$,  $t=5$), the probabilities can be easily calculated:</p>

<p>$$ p_{6,1,5,0} = \frac{4}{6} \quad \text{(Probability for exactly 0 hits - roll 1-4 on the first roll, no explosion here)} $$
$$ p_{6,1,5,1} = \frac{1}{6} + \frac{1}{6} \cdot \frac{4}{6} \quad \text{(Probability for exactly 1 hit - roll either a 5 or a result of 1-4 after a 6)} $$
$$ p_{6,1,5,2} = \frac{1}{6} \cdot \frac{1}{6} + \frac{1}{6} \cdot \frac{1}{6} \cdot \frac{4}{6} \quad \text{(Probability for exactly 2 hits - either a 6 and 5 or two sixes and 1-4)} $$
$$ p_{d,1,t,h\ge 1} = \left(\frac{1}{d}\right)^{h-1}\frac{d-t}{d}  + \left( \frac{1}{d} \right)^h \cdot \frac{t-1}{d} \quad \text{(Probability for exactly $h\ge 1$ hits - either $h-1$ maximum rolls and non-maximal success or $h$ maximum rolls and a non-success )} $$</p>

<p><strong>Without Explosion:</strong></p>

<p>For none-exploding dice the probability would just be <a href=""https://en.wikipedia.org/wiki/Binomial_distribution"" rel=""nofollow"">binomially distributed</a>:</p>

<p>$$ p^\text{non-exploding}_{d,n,t,h} = \binom{n}{h} \left( \frac{d-t+1}{d} \right)^h \left( 1 - \frac{d-t+1}{d} \right)^{n-h} $$</p>

<p>$$ E^\text{non-exploding}_{d,n,t} = n \frac{d-t+1}{d}; \qquad V^\text{non-exploding}_{d,n,t} = n \frac{(d-1)(d-t+1))}{d^2} $$</p>

<p>Where $E_{d,n,t}$ is the expected number of hits, and $V_{d,n,t}$ its variance.</p>

<hr>

<p><strong>Edit1:</strong> In the mean time I found <a href=""http://math.stackexchange.com/q/391792/11949"">Probability of rolling $n$ successes on an open-ended/exploding dice roll</a>. However I'm afraid, I don't fully get the answer there. E.g. the author says $s = n^k + r$, which does not hold for his examples. Also I'm not sure how to get $s$, $k$ and $r$ from my input values stated above (which are $d$, $n$, $h$ and $s$).</p>

<p><strong>Edit2:</strong> If one had the probability for $b$ successes via explosions, given that the initial role had $l$ successes prior to the explosions, one could just subtract all those probabilities for all values of $b$ from the value for the pure binomial distributions with $l$ successes and add the respective value to the pure binomial probability of $b+l$ successes. Just an idea. I suppose this should be something like a combination of geometric and binomial distribution.</p>

<p><strong>Edit3:</strong> I accepted <a href=""http://math.stackexchange.com/users/224454/brian-tung"">Brian Thug</a>'s excellent answer, giving the formula:
$$ p^\text{exploding}_{d,n,t,h} = \frac{(t-1)^n}{d^{n+h}}
             \sum_{k=0}^{\max\{h, n\}} \binom{n}{k} \binom{n+h-k-1}{h-k}
             \left[ \frac{d(d-t)}{t-1} \right]^k $$</p>

<p>$$ E^\text{exploding}_{d,n,t} = n\frac{d+1-t}{d-1}; \qquad V^\text{exploding}_{d,n,t} = E_{d,n,t} - n\frac{(d-t)^2-1}{(d-1)^2} $$</p>

<p>Here is a graph from a <a href=""https://github.com/con-f-use/Exploding-Diepool"" rel=""nofollow"">simulation</a> (<a href=""http://con-f-use.github.io/Exploding-Diepool/"" rel=""nofollow"">html</a>) that illustrates the whole thing:</p>

<p><img src=""https://github.com/con-f-use/Exploding-Diepool/raw/master/img/hist_d6_n15_t5.png"" alt=""Comparison between exploding and non-exploding dice pools""></p>
",probability
"<p>My text book uses the linearity of the expected value to compute it. It defines a random variable $X_i$ that indicates whether the urn $i$ contains $k$ balls or not. So the asked value is $E[X_1 + X_2 + ... + X_n]$.</p>

<p>What is not entirely clear for me is the following. It states that $P\{X_i=1\}={r \choose k}({{1}\over{n}})^k({1-{{1}\over{n}}})^{r-k}$. However, if the balls are indistinguishable, I thought we should compute that probability with the ""stars and bars"" approach?</p>
",probability
"<p>Is there an explicit formula for the probability that a simple symmetric random walk on $\mathbb{Z}$ starting from $1$ will not hit $0$ before time $t$?</p>
",probability
"<p>For $X_i \sim$ i.i.d with cdf $F_x$, and $\forall c \in \mathbb R$, then, letting $M_n$ denote the maximum observation</p>

<p>$$
M_n \le c+  \sum_i^n (X_i - c) \mathbb I(X_i &gt; c)
$$
I proved this by taking $n=1$ and $X_i = c$ and showing that this was a contradiction. Now, I am trying to show that, for $\bar{F}(x)= 1- F(x)$ :</p>

<p>$$
E(M_n) \le c + n \int_c^\infty \bar{F}(x)dx
$$
My attempt so far, using the initial result, then then the same inequality must hold for the expectations of both sides, that is:
\begin{align*}
E(M_n) &amp;\le c+  \sum_i^n E[(X_i - c) \mathbb I(X_i &gt; c)] \\
&amp;\overset{\text{iid}}{=}c+ n E[(X - c) \mathbb I(X &gt; c)] \\
&amp;= c+ n \int_{-\infty}^ \infty (x-c)\mathbb I(X &gt; c) f_X(x) dx \\
&amp;= c+ n \int_{c}^ \infty (x-c)  f_X(x) dx \\
&amp;= c+ n \int_{c}^ \infty x  f_X(x) dx - nc \int_c^\infty f_X(x)dx \\
&amp;=c+ n \int_{c}^ \infty x  f_X(x) dx -nc \bar{F}(c)\\
\end{align*}</p>

<p>I think i take a wrong turn somewhere, maybe I shouldn't expand the term in the integral, I still don't quite get where the second integral would come from, to define the CDF in the required inequality... any hints?</p>
",probability
"<p>The probability that it will rain on Saturday is 25% and the probability that it will rain on Sunday is also 25%. Is it true that the probability that it will rain on the weekends is 50%. Explain why or why not.</p>

<p>What i tried</p>

<p>I know that it is not true.
Let $P(A)$ represent the probability that it will rain on Saturday, while $P(B)$ represent the probability that it will rain on Sunday. Hence $P(A \cap B)$ will represent the probability that it would rain on both days (weekends) and since $$P(A \cap B)=P(A)+P(B)-P(A\cup B)$$</p>

<p>From the formula above we can see that the sum of  $P(A)$ and  $P(B)$ alone would not add up to $P(A \cap B)$ which means that we simply could not just add the two probabilities together to get $50$%. Since i find this rather counterintutive could anyone provide a simpler and more clearer explanation to this problem.Thanks</p>
",probability
"<p>If I have the probability distribution $f(x) = \begin{cases}x &amp; 0 &lt; x &lt; 1 \\ 2-x &amp; 1 &lt; x &lt; 2 \\ 0 &amp; \text{otherwise} \end{cases}$,</p>

<p>how do I calculate $E(X)$, and $E(X^2)$, and therefore $VAR(X)$?</p>

<p>I understand that $E(X)=\int_{-\infty}^\infty xf(x)~dx$, and $E(X^2)=\int_{-\infty}^\infty x^2f(x)~dx$, but don't know how to apply this given that the function takes different forms over $(0,1)$ and $(1,2)$.</p>
",probability
"<blockquote>
  <p>In a coorporation there are 3% absence due to sickness each day. 60% of those are men. 30% of the cooporations employees are women. So, </p>
  
  <p>M = the employee are  male<br>
  F = the employee are female<br>
  S = employee is home due to sickness.  </p>
  
  <p>My task is to find P(M) and P(S|M).</p>
</blockquote>

<p>I've tried to look around for some examples to apply to this problem but I can't manage to find one.</p>

<p>I need a hint or something to get started. I'm very rusty in probability-calculation.</p>
",probability
"<blockquote>
  <p>Suppose there are three students wanting to meet a Professor in his office. The time $i$-th student takes with the Professor is $Exponential(\lambda_i)$ distributed, and they are independent. Assume all students start talking to the Professor simultaneously. Find the distribution of the time until only one student is left.</p>
</blockquote>

<p>If I denote $T$ to be the desired time and $T_i$ to be the discussion time for $i$-th student, how exactly can I write $\{T\leq x\}$ in terms of $T_i$?</p>

<p>It seems that $\{T\leq x\}=\{T_1\leq x,T_2\leq x\}\cup\{T_2\leq x,T_3\leq x\}\cup\{T_1\leq x,T_3\leq x\}$.</p>

<p>Am I right?</p>
",probability
"<p>A player with unlimited money decides to play roulette. He bets $1$ on red, if he loses, he bets $2$, if he loses again he bets $4$ and so on till he wins. Prove that he is guaranteed to make a profit.</p>

<p>I know this is the theory of martingale and I looked for proof online but everything I found was way more complex than what's needed here. Isn't there a formula to prove that after unlimited tries the probability of never winning is $0$?</p>

<p>I understand why it works but I'm having a hard time explaining it using mathematics. Any help would be greatly appreciated.</p>

<p>Thank you</p>
",probability
"<blockquote>
  <p>Given $x_1, \ldots, x_N$, independent and all distributed as a
  Gaussian with mean $\mu$ and variance $\sigma^2$. Then, the average
  $$\bar{x} = \frac{1}{N}\sum_{i=1}^Nx_i$$ is distributed as a Gaussian
  with mean $\mu$ and variance $\frac{\sigma^2}{N}.$</p>
</blockquote>

<p>This is a very well-known result. Anyway, I'm looking around to find a proof for this and I'm not having luck.</p>
",probability
"<p>I have a problem proving an inequality regarding probabilities.
You may prefer to skip to the definitions and the inequality right away 
without reading the paragraph below.</p>

<p>Suppose there are $n$ light bulbs. Independently, each light bulb is ON with probability $x$ and OFF with probability $(1-x)$. After the random variables realized, i.e., after it is observed which bulbs are on or off, one is smashed and this one is selected randomly among those that are OFF.</p>

<p>Let 
$$\alpha = x^{n-2}$$
be the probability that, given two lights $i$ and $j$ are OFF, all other lights are ON.</p>

<p>Let 
$$\beta_i = \sum\limits_{i=0}^{n-2} {n-2 \choose i}\frac{1}{i+1} x^{n-2-i}(1-x)^i = \frac{1-x^{n-1}}{(n-1)(1-x)}$$
be the probability that, given light $i$ is off and light $j$ is on, light bulb $i$ is smashed.
Similarly, define $\beta_j = \beta_i$.</p>

<p>Let 
$$\beta_{i,j} = \sum\limits_{i=0}^{n-2} {n-2 \choose i}\frac{2}{i+2} x^{n-2-i}(1-x)^i$$
be the probability that either $i$ or $j$ are smashed, given both of them are OFF.</p>

<p>It should hold that
$$ (1-\alpha) (1-\beta_{i,j}) \geq (1-\beta_i) (1- \beta_j) \quad  \forall n &gt; 2, x\in [0,1]  $$
Unfortunately, I am not able to show that this generally holds. It would be great to point me to the basic math that I am missing.</p>
",probability
"<p>Let $\{X_t\}_{t\ge 0}$ be a Poisson Process with parameter $\lambda$. Suppose that each event is type 1 with probability $\alpha$ and type 2 with probability $1-\alpha$. Let $\{X^{(1)}_t\}_{t\ge 0}$ the number of type 1 events up until time $t$ and $\{X^{(2)}_t\}_{t\ge 0}$ the number of type 2 events up until time $t$ </p>

<p>Prove that $\{X^{(1)}_t\}_{t\ge 0}$ and $\{X^{(2)}_t\}_{t\ge 0}$ are Poisson Processes with parameter $\lambda \alpha$ and $\lambda(1-\alpha)$ respectively </p>

<p>Furrthermore prove that for each $t\ge 0$ the random variables $\{X^{(1)}_t\}_{t\ge 0}$ and $\{X^{(2)}_t\}_{t\ge 0}$ are independent</p>

<p>My attempt: In order to prove that they are poisson process I will use the next definition:</p>

<p>An stochastic process $\{Y_t\}_{t\ge 0}$ is a poisson process iff:</p>

<p>a) $Y_0=0$</p>

<p>b) It has independent increments</p>

<p>c) $Y_{t+s}-Y_{s}$~$Poisson(\lambda t)$ for any values $s\ge 0$ and $t&gt;0$</p>

<p>a) For any $t\ge 0$ we have: $X_t=X^{(1)}_t+X^{(2)}_t$; we know that $\{X_t\}_{t\ge 0}$ is a poisson process hence $X_0=0$ $\Rightarrow X^{(1)}_0+X^{(2)}_0=0 \Rightarrow X^{(1)}_0=0$ and $X^{(2)}_0=0$</p>

<p>b)Let $n\in \mathbb N$ In this part I need to prove that for any $n$ arbitrary times $0&lt;t_1\le t_2\le...\le t_n$ and states $x_1,...,x_n$
 $$P[X^{(1)}_{t_1}=x_1,X^{(1)}_{t_2}-X^{(1)}_{t_1}=x_2,...,X^{(1)}_{t_n}-X^{(1)}_{t_{n-1}}=x_n]=P[X^{(1)}_{t_1}=x_1]P[X^{(1)}_{t_2}-X^{(1)}_{t_1}=x_2]...P[X^{(1)}_{t_n}-X^{(1)}_{t_{n-1}}=x_n]$$</p>

<p>I don´t know how to Formally prove this part, and I don´t think this is trivial. Any help would be highly appreciated </p>

<p>c) $$P[X^{(1)}_t=k]=\sum_{i=k}^\infty P[X^{(1)}_t=k|X_t=i]P[X_t=i]=\sum_{i=k}^\infty \binom{i}{k}\alpha^i(1-\alpha)^{i-k}{e^{-\lambda t}(\lambda t)^i \over i!}={e^{-\lambda \alpha t}(\lambda \alpha t)^k\over k!}$$</p>

<p>Know I need to compute $P[X^{(1)}_{t+s}-X^{(1)}_t=n]=\sum_{j=0}^\infty P[X^{(1)}_{t+s}-X^{(1)}_t=n|X^{(1)}_s=j]P[X^{(1)}_s=j]$</p>

<p>This part is also giving me trouble because I dont´know what to do from here </p>

<p>I would really apreciate if you can help me with this problem. Also I hope that this won´t be marked as a duplicate because I haven´t seen a formal proof about the splitting poisson process.</p>
",probability
"<p>Let $\{ X(t), t \ge 0\}$ be standard Brownian motion.</p>

<p>How do I find Cov$[X(3) - 2X(2), X(4)]$? </p>

<p>The answer is $-1$, but I can't seem to get there no matter what I hit it with. I know that $X(3) \sim N(0,3)$, $2X(2) \sim N(0, 4)$, and $X(4) \sim N(0,4)$. Furthermore, I know that $\text{Cov}[X(s),X(t)] = \min (s,t)$; but this is only for Brownian motion, which isn't preserved (I assume) by the new normal random variable created by $X(3) - 2X(2)$. I imagine that I need to somehow transform $X(3) - 2X(2)$ in a way that preserves Brownian motion so that I can use the above property, but I'm at a loss here.</p>
",probability
"<p>A fair die having two faces coloured blue, two red and two green, is thrown repeatedly. Find
the probability that not all colours occur in the first $k$ throws.</p>

<p>My attempt:
Denote by $G_k$ the number of results=green in $k-$tosses, and similarly $R_k$ and $B_k$. Then we have $\mathbb{P}(G_k=0)=(2/3)^k=\mathbb{P}(R_k=0)=\mathbb{P}(B_k=0)$. In this way the answer is $\mathbb{P}(G_kR_kB_k=0)=(2/3)^{3k}$.</p>
",probability
"<p>A crabs' life expectancy can be modeled exponentially, and a crab lives 3 months on average.</p>

<p>I am absolutely not sure about this, because there is nothing concerning this in our book, so I guess it was meant to be solved in some obvious/easy fashion, here's what I tried:</p>

<blockquote>
  <p>If it were only one crab, I could simply plug 9 into $\lambda e^{-\lambda x}$, where $\lambda=1/3$. </p>
  
  <p>$60$ is $10\%$ of $600$, so maybe I need to look after what time 90% died, intuitively I would resort to</p>
  
  <p>$$1-e^{-x/3}=0.9$$
  $$0.1=e^{-x/3}$$
  and so on, which would give me $\approx 6.9$ months, and then do <em>something</em> about the remaining $2.1$ months.</p>
</blockquote>

<p>The last thing I was thinking of is to calculate the probability for 540 crabs dying at some point before the 9 month mark, and then taking the converse probability, but that I'd only know how to do with the help of a computer. </p>
",probability
"<p>Assume the expected number of transitions (events) it takes until a Markov chain with $G+1$ states ranging from $s=0$ to $s=G$ is completed is $M$. Suppose we have $K$ independent instances of this Markov chain synchronized such that a single event can lead to a transition to all of them. We are interested in the average number of transitions required to complete all of them.</p>

<p>One approach is to model this using a new Markov chain with a state space of size $(G+1)^K$ that corresponds to vectors (0,...0) to (G,...,G), calculate the transition probabilities and then derive the expected number of required transitions. We are already aware of how to do it. However, it is very interesting and insightful to approximate this using $M$ and $K$. Any suggestions is appreciated.</p>
",probability
"<p>I have a very basic propability question:</p>

<p>There are 200 socks in my basket. 25 are white, the rest are black. If I pick 10 socks, what's the probability of picking 3 white ones?</p>

<p>I tried to calculate as follows:</p>

<p>P_3 = [25/200 * 24/199 * 23/198] * [175/197 * 174/196 * 173/195 * 172/194 * 171/193 * 170/192 * 169/191]</p>

<p>However, when I create all P_{0-10} and sum them up I don't get a overall probability of 1. So I must be doing something wrong?</p>
",probability
"<p>Let $C(\mathbb{R})$ be the set of continuous and bounded functions $\mathbb{R}\to\mathbb{R}$.</p>

<p>Is there a probability measure $p$ on $C(\mathbb{R})$ such $\forall g\in C(\mathbb{R}),\ \forall \varepsilon&gt;0,\ p(\{f\in C(\mathbb{R}), |f-g|&lt;\varepsilon\})&gt;0$ ?</p>
",probability
"<p>I want to know if the following distribution has a name or a PDF in the literature. I have:
$$ Z = \left(\sum_{i=1}^{N}{X_i^2}\right)^{\alpha}$$
where $\{X_i\}_{i=1}^{N}$ are independent Gaussian random variables with mean $\mu_i$ and variance $\sigma_i^2$ and $\alpha \in \mathbb{R}$.</p>

<p>Thanks.</p>
",probability
"<p>I am looking to solve the following integration. Given $Z_1,Z_2,\ldots,$ are all independent and standard gaussian variable, $Z_i = N(0,1)$.</p>

<p>For the first case, I am interested in the probability $P(Z_1+Z_2&lt; \sqrt{2}\alpha , Z_2+Z_3&lt;\sqrt{2}\alpha)$, or simply 
$$\frac{Z_1+Z_2}{\sqrt{2}} &lt; \alpha$$
$$\frac{Z_2+Z_3}{\sqrt{2}} &lt; \alpha$$</p>

<p>where $\alpha$ is a constant. I can solve this numerically. First question is there analytical solution to this?</p>

<p>Secondly, for higher dimensional case, what is the probability that
$$\frac{Z_1+Z_2+Z_3}{\sqrt{3}} &lt; \alpha$$
$$\frac{Z_2+Z_3+Z_4}{\sqrt{3}} &lt; \alpha$$
$$\frac{Z_3+Z_4+Z_5}{\sqrt{3}} &lt; \alpha$$</p>

<p>Thank you for your help.</p>
",probability
"<p>In fair gambler's ruin problem, we already knew that the expected time of winning is $E(\tau_n|\tau_n&lt;\tau_0)=\frac{n^2-k^2}{3}$, where $k$ is how much money we have in the beginning and $\tau_i$ is the first hitting time at $i$. I know how to solve it by using first step analysis in markov chain, but my teacher wants me to use martingale instead, he said it is much easier. I think I have to use optional stopping time theorem, but I don't know how to use it in this problem. Any idea? Thank you so much</p>
",probability
"<p>I'm trying to solve a certain problem but I'm stuck at a point.</p>

<p>The problem is:
I have a uniform r.v. $U$ on [$-\pi,+\pi$] and I have a sequence of r.vs $X_1,X_2...$ where $X_k=cos(kU)$.
Then I have $S_n=X_1+X_2+...+X_n$.</p>

<p>The problem is to find what is $lim_{n\rightarrow \infty} P{(|\frac{S_n}n|&lt;\epsilon)}$</p>

<p>My attempt:</p>

<p>I know that $E[\frac{S_n}n]=0$ and its variance is $2\pi^2/n$.</p>

<p>I know that $P{(|\frac{S_n}n|&lt;\epsilon)} =P_{\frac{S_n}n}([-\epsilon,+\epsilon])= \begin{matrix} \int_{-\epsilon}^{\epsilon} f_{\frac{S_n}n}(x) dx \end{matrix}$</p>

<p>Where $f_{\frac{S_n}n}(x)$ is the probability density of $\frac{S_n}n$.</p>

<p>I don't know how to find this probability density: I tried with the characteristic function of the sum but the result is not very ""writable"".</p>

<p>Maybe there is another way to find that probability with $n\rightarrow \infty$?</p>

<p>Thank you</p>
",probability
"<p>I asked similar question in <a href=""http://math.stackexchange.com/questions/395666/a-special-random-subset-of-uniformly-distributed-numbers-is-still-uniformly-dist"">A special random subset of uniformly distributed numbers is still uniformly distributed?</a></p>

<p>Here, I slightly change my random number generation method, and want to see whether the sampled numbers are still uniformly distributed.</p>

<p>Assume that I have a value range [1,1000].</p>

<p>Goal: I want to have 10 numbers randomly sampled from [1,1000].</p>

<p>case1:</p>

<pre><code>I sample 20 numbers, a1, ..., a20 from [1,1000].

Then I sample b1, ..., b10 from [a1, a2, ..., a20].

b1, ..., b10 are what I want.
</code></pre>

<p>case2:</p>

<pre><code>I sample 20 numbers, a1, ..., a20 from [1,1000].

Then I sort a1, ..., a20.

For notation simplicity, I assume that after sorting, a1&lt; ...&lt; a20.

Then, for each consecutive pair of numbers, 

I uniformly at random select one number.

Eventually, I can get 10 numbers as well.
</code></pre>

<p>I know the numbers in case1 are uniformly distributed.</p>

<p>Does anyone have idea whether the numbers in case2 are uniformly distributed?</p>
",probability
"<p>The probability generating function of $X$ is $G_x(s)=\frac{1}{2}(s^9(1+s^2))$. Find $EX$ and probability distribution function.</p>

<p>$EX=G_x^{'}(s)=\frac{1}{2}(9s^8+11s^{10})$</p>

<p>How about pdf? Do I need to expand $G_x(s)$ function with Taylor series?</p>
",probability
"<p>Two of my facebook friends had their birthdays on the same day</p>

<p>The first guy's name was ""Wael Toujeni""</p>

<p>The second guy's name was ""Wael Jeni""</p>

<p>How do I calculate the probability of this event happening?</p>

<p>The event: two of your facebook friends have the same birthday, and have similar names except an n characters difference in their last names.</p>
",probability
"<p>I have a two week holiday after finishing this semester and I was hoping to study something. Ideally, I would like to study something that I can benefit from in any upcoming courses I take. I'm thinking of either fourier series or probablity theory. Currently I'm leaning towards Fourier because it's very relevant to electrical engineering, however, Probablity theory seems intriguing to me (also opens up interesting areas such machine learning).</p>

<p>So how relevant is probablity theory to undergraduate electrical engineering ?!</p>
",probability
"<p>If we know that the two random sequences $\{X_n\}$ and $\{Y_n\}$
$$
X_n \stackrel{d}{\longrightarrow} N(0,\sigma_1^2)\\
Y_n \stackrel{d}{\longrightarrow} N(0,\sigma_2^2)
$$
and $\mathrm{cov}(X_n,Y_n) \to 0$, can we conclude that the joint random vectors
$$
\pmatrix{X_n \\ Y_n} \stackrel{d}{\longrightarrow} N(0,\mathrm{diag}\{\sigma_1^2, \sigma_2^2\})
$$</p>

<p>Is there any counterexample or proof? I have considered using the characteristic function with expansion but did not work it out....</p>

<p>Many thanks to any help!</p>
",probability
"<p>Consider the normal distribution. We know that $$p(x| \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}} $$</p>

<p>The kernel is $$ p(x| \mu, \sigma^{2}) \propto e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}} $$ omitting the part that isn't a function of $x$. Why write $p(x|\mu, \sigma^{2})$ like this? </p>
",probability
"<p>A cube is painted on all its faces. It is then cut into 64 smaller identical cubes, which are then thoroughly. What is the probability that 2 randomly chosen smaller cubes have exactly 2 coloured faces each?</p>

<p>I have a doubt , there will be 24 <strong>identical</strong> cubes whose 2 faces will be painted, 8 <strong>identical</strong> cubes with 3 faces painted,  24 <strong>identical</strong> cubes with one face painted and 8 <strong>identical</strong> cubes with no face painted. 
Now total cases to pick 2 smaller cubes should be 4C2 not 64C2 .
correct me if I am wrong</p>
",probability
"<p>Is there a way to determine the maximum percentage of values that fall below the average in a given sample?  How would someone go about this?  How does this relate to what Markov's inequality and Chebyshev's inequality are saying?</p>
",probability
"<p>Let $P_{XY}$ be the joint probability distribution of discrete random variables $X$, $Y$. Then I would like to prove the following inequality:</p>

<p>$$
\sum_{y}\max_xP_{XY}(x,y)\leq |Y|\max_xP_X(x)
$$</p>

<p>where $P_X$ is the marginal distribution of random variable $X$ and $|Y|$ is the cardinality of random variable $Y$. Hints are also welcome.</p>
",probability
"<blockquote>
  <p>$X_n$ is a sequence of random variables, and $\{\varphi_n(t)\}$ is the corresponding sequence of characteristic functions. Show that $X_n \stackrel{d}{\longrightarrow} 0$ iff $\{\varphi_n(t)\}$ converges to 1 in some neighbourhood of $t=0$.</p>
</blockquote>

<p>The necessity follows immediately from Levy's continuity theorem. I am struggling with showing the sufficiency: it remains to show that $\varphi_n(t) \rightarrow 1$ for all $t \in \mathbb{R}$, but how to do that? Appreciate for any help!</p>
",probability
"<p>Assuming I start with $n$ dice that have been rolled once, is it beneficial to choose the higher dice when I roll less than $n$ dice again (assuming I want a high roll)?</p>

<hr>

<p>In some board games, dice play a big part. And depending on the circumstance, a different amount of dice is used. In this particular case, I'm assuming that the higher the resulting number, the better. Also, I'm assuming not perfectly fair dice, since those rarely happen in everyday play.</p>

<p>Here's my logic: If I roll 7 dice, and 4 are high (5/6) while 3 are low (1/2), should I pick the high dice if I only need to roll 4? (Assuming that this is the first time I see the dice rolled).</p>

<p>This seems as if it might make sense because if the dice aren't fair and the only result we've seen so far is a higher number, it might make it seem as if that number is more likely to occur.</p>

<p>On the other hand, this almost seems like the gambler's fallacy. Except that fallacy assumes perfect dice.</p>

<p>So should I pick the higher dice? Or does it really not matter? If it does matter, by how much?</p>
",probability
"<p>$N(t)$ is a Poisson process with parameter  $\lambda&gt; 0$, and $X_1,X_2,...$ are independent and identically distributed random variables with a common mean and positive variance. Let
$$L(t)=\sum_{i=1}^{N(t)}X_i.$$
Find $E[L(t)|N(t) = n]$.</p>

<p>Any help with this is appreciated.</p>
",probability
"<p>I know that the events $x_1 &gt;0$ and $x_2 &gt;0$ are not independent, but I can't think of a way to find a conditional probability so I can solve this.</p>

<p>Thanks!</p>
",probability
"<p>I try to prove that according to binomial distribution $P(X=k)={n \choose k}p^k(1-p)^{n-k}$ the maximum probability $P(X=k)$ is achieved at maximum likelihood, i.e. $p=\frac{k}{n}$.</p>

<p>Let's apply $\log$ and take the first derivative.</p>

<p>$$\log P(X=k) = \log {n \choose k}+k \log p+ (n-k)\log (1-p)$$</p>

<p>$$\frac{d \log P(X=k)}{dp} = \frac{k}{p}-\frac{n-k}{1-p}=0 \quad \iff \quad  p=\frac{k}{n}$$</p>

<p>The problem is to show that what I found is indeed the global maximum, i.e. I need to show that the second derivative is negative everywhere.</p>

<p>I would appreciate if someone could help me with the second derivative.</p>

<p>The second derivative</p>

<p>$$\frac{d(\frac{k}{p}-\frac{n-k}{1-p}) }{dp} = -\frac{k}{p^2}-\frac{n-k}{(1-p)^2}$$</p>

<p>it's negative because $n&gt;k$</p>
",probability
"<p>I have some difficulties with the following exercise in combinations:</p>

<blockquote>
  <p>There are $8$ beans in the box: $6$ white beans, $2$ green beans. Two players one by one pick $2$ beans; first player one picks $2$ beans, after that player two picks $2$ beans. For every green bean that player picks he gets $5$ points.</p>
  
  <p>What's the expected number of points for player one? What's the probability that player two picks only one green bean?</p>
</blockquote>

<p>Solution:</p>

<p>$$E(\text{points of player one}) = 4 \cdot 5 \cdot \frac{2}{8} \cdot \frac{6}{7} + 10 \cdot 2 \cdot \frac{2}{8} \cdot \frac{1}{7}$$</p>

<p>Unfortunately I didn't find any good way to fir the binomial distribution here. </p>

<p>I don't get any idea how to answer the second question.</p>
",probability
"<p>Probability was never included in my high school classes, so I'm trying to learn it now from the internet. The downside of this is that you don't get anyone grading your work and catching flaws. This is something I'm really uncertain about, so if someone could just point out my mistake or verify that I've understood it, I'd be appreciative.</p>

<p>Just for fun, the topic I chose to practice with was working out the chance that any of the children on <em>19 Kids and Counting</em> (a TV series about a very conservative family raising children with strict traditional roles) would be LGBT. The probability of being gay is roughly $3\%$ ($0.03$) and the probability of being bisexual is roughly $4\%$ ($0.04$).</p>

<p>So combined, this makes $7\%$ ($0.07$). The probability of being heterosexual is $93\%$ ($0.93$). Would I be correct in saying that the probability of at least one being gay or bisexual would be $1-A^{B}$, where $A$ is the probability of being born heterosexual ($0.93$) and $B$ is the number of family members ($25$) -- or $83.7\%$?</p>

<hr>

<p>As a followup question: there's a controversial finding by some studies, <a href=""https://en.wikipedia.org/wiki/Fraternal_birth_order_and_male_sexual_orientation"" rel=""nofollow"">the fraternal birth order effect</a>, that suggests that for each older brother a man has, the probability that he is gay rises by ~$38\%$, hypothesised to be due to hormonal influences during fetal development. There are $10$ boys in the family. How would I include this detail when calculating the probability? </p>
",probability
"<p>So when dealing with the Bayes' Rule and Binomial distributions,  the value $p^k(1-p)^{n-k}$ loses precision and becomes 0 when $n$ and $k$ are large(noting that the binomial coefficient can be safely ignored since it cancels out). For example if $n = 500\,,\,k=250\,\,$for  $p= 0.05$  , then my TI-83 calculator returns 0.</p>

<p>I found out about a ""fix""  for this using the following expression that replaces $p^k(1-p)^{n-k}$.</p>

<p>$e^{k\,ln \,p + (n-k)ln(1-p)-max_i(kln(p_i) + (n-k)ln(1-p_i)}$</p>

<p>I think the $p_i$ in the expression is suppose to represent any one of prior probabilities. Can anyone explain why this works ?</p>
",probability
"<p>""I'm really sorry that I'm asking a basic question, I tried to understand but couldn't understand completely""</p>

<p>These are the 3 parameter results of rolling a single die.
Expectation  E(x)=3.5</p>

<p>Variance Var(x)=2.92</p>

<p>Standard deviation SD=1.709</p>

<p>Expectation is nothing but the average of outcomes of die when we perform infinite trials, that means if we roll a die infinite times and take out the mean of outcome , its value is close to 3.5. that's what I understood.
I searched in Google and read about variance ,standard deviation.
I didn't understand anything about those two, but left with this sentence ""The variance measures how far each number in the set is from the mean""
Can anyone please explain what do those two values indicate regarding to my die problem??
Thanks in advance</p>
",probability
"<p>EDIT:</p>

<p>Let $X,Y$ be random variables over some probability space with  joint distribution  $P$. Then the mutual information between two random variables is defined as</p>

<p>$I(X;Y):=\sum\limits_{(x,y)\in\text{supp}(P)}P(x,y)\log\frac{P(x,y)}{\sum\limits_rP(r,y)\sum\limits_sP(x,s)}$. </p>

<p>It is clear that mutual information $I(X;Y)$ can now be viewed as a function of joint distribution $P$. Hence we denote hereafter the mutual information associated with a joint distribution $P$ between two random variables as $I(P)$.</p>

<p>Now to the problem definition:</p>

<p>Assume $P_1,P_2$ be two joint distributions over $\{1,2,3...,N \}\times \{1,2,3,...N\}$ and hence $P_1,P_2 \in \mathbb{R}^{N \times N}$. Assuming $Q= \frac{P_1+P_2}{2}$, which again defines a new joint distribution over the same set over which $P_1,P_2$ were defined, I am trying to bound the mutual information $I(Q)$ using $I(P_1)$ and/or $I(P_2)$.</p>

<p>I have a bound on $I(Q)\ge\sum \limits_{i,j}\frac{P_1(i,j)}{2}\log{\frac{P_1(i,j)}{\gamma_{ij}}}+\sum \limits_{i,j}\frac{P_2(i,j)}{2}\log{\frac{P_2(i,j)}{\gamma_{ij}}}$ </p>

<p>with</p>

<p>$\gamma_{ij}:= \left( \sum \limits_s \frac{P_1(i,s)+P_2(i,s)}{2} \right )$$\left(  \sum \limits_r \frac{P_1(r,j)+P_2(r,j)}{2} \right)$. With this I am interested in lower bounding $\frac{1}{\gamma_{ij}}$. With some calculations I landed a lower bound of the form, </p>

<p>$\frac{1}{\gamma_{ij}}\ge \frac{1}{\sum \limits_rP_1(i,s)\sum \limits_rP_2(r,j)+\frac{1}{4}(\text{sum of three positive terms all $\le$ 1})}$</p>

<p>However, I am interested in knowing is there anyway I can further get a  lower bound of the RHS of the  above expression such that I have $\frac{1}{\sum \limits_rP_1(i,s)\sum \limits_rP_2(r,j)}$ term left.</p>

<p>The motivation is to get a neat lower bound on $I(Q)$ involving mutual informations of $P_1$ and $P_2$.</p>

<p>Any help/idea will be highly appreciated.</p>

<p>Thanks</p>
",probability
"<p>Give the density $ f_{X}(x)=\frac {x^2} {9} $ with $0 &lt; x &lt; 3$</p>

<p>I should calculate with transformation the density of $Y=X^3$.</p>

<p>Is my calculation correct?</p>

<p>$f_{Y}(y)=f_{X}(g^{-1}(y))\mid\frac{d}{dy}g^{-1}(y)\mid = \frac {(y^{\frac{2}{3}})^2} {9}*\frac{1}{3y^2} =\frac{1}{27}$</p>
",probability
"<p>Does $Z_n=\sum_{k=1}^{n}\sqrt{k}X_k$ satisfy the strong law of large numbers if $ X_n: \begin{matrix}-\frac{1}{n} &amp; \frac{1}{n} \\ \frac{1}{2} &amp; \frac{1}{2} \end{matrix}, n=1,2,...$ are independent random variables. </p>

<p>I have the following theorems, but I cannot prove this, I have tried all which I understand, the theorems I have are:</p>

<p>1.) Strong Law of large numbers states that the sequence $X_1,X_2,...$ must satisfy:</p>

<p>$$\frac{1}{n}\sum_{k=1}^{n}(X_k-EX_k)\to^{a.s.}0, n\to \infty$$</p>

<p>2.) Kolmogorov Law: If $(X_n)$ independent random variables, such that $\sum_{n=1}^{\infty} \frac{\text{Var}(X_n)}{n^2}&lt;\infty$, then the strong law of large numbers is satisfied.</p>

<p>3.)Borels:  If $ S_n:\mathcal B(n,p)$ (binomial distribution), then $$\frac{S_n}{n}\to^{a.s.}p, n \to \infty$$</p>

<p>or the consequence: </p>

<p>Let $X_n$, sequence of independent random variables, equally distributed, such that $EX_k=a$ and $\text{Var}X_k= \omega^2, k=1,2,3... \implies$</p>

<p>$$\frac{1}{n}\sum_{k=1}^{n}X_k\to^{a.s.}a, n\to \infty$$</p>
",probability
"<p>The strong law of large numbers states that the sample average converges almost surely to the expected value $\overline{X}_n\ \xrightarrow{\text{a.s.}}\ \mu \qquad\mathrm{when}\ n \to \infty$ .</p>

<p>That is,$$\Pr\left( \lim_{n\to\infty}\overline{X}_n = \mu \right) = 1.$$</p>

<p>I want to ask whats the domain of the random variable $\overline{X}_n$, given that all $X_n$ have same domain $\Omega$?</p>

<p>For the coin tossing problem $\Omega =\{H,T\} $ and $X_n(H)=1 \quad and \quad X_n(T)=0 \quad\forall n $ so, if the domain of $\overline{X}_n$ was $\Omega$ the $\overline{X}_n(H)=1 \quad \overline{X}_n(T)=0 \quad \forall n$, so $\Pr\left({\omega \in \Omega : \overline{X}_n(\omega)=1/2}\right)=0$ , which is not what strong law says.</p>

<p>I want to know whats the domain of this random variable $\overline{X}_n$?</p>
",probability
"<p>Suppose that you spin a dial that freely moves  marked out in 360 degrees in steps of 5 degrees. Whats the proability that the dial will land somewhere between 5 degrees and 300 degrees. Al so how do you calculate the answer </p>
",probability
"<p>Suppose we have discrete random variable given by
\begin{align*}
P(X=x_i)=\frac{1}{N},  i=1...N
\end{align*}
and Gaussian r.v. $Z \sim \mathcal{N}(0,1)$. Assume $Z$ and $X$ are independent.
Suppose $X$ and $Z$ form an new r.v. $Y$ give by
\begin{align*}
Y=X+Z
\end{align*}</p>

<p>I am interested in computing $E[X|Y]$?</p>

<p>Here are some of the distributions that I have computed:
\begin{align*}
f_Y(y)&amp;=\frac{1}{N} \sum_{i=1}^N \frac{1}{\sqrt{2\pi}} e^{-(y-x_i)^2/2}\\
f_{Y|X}(y|x_i)&amp;=\frac{1}{\sqrt{2\pi}} e^{-(y-x_i)^2/2}=f_Z(z)\\
f_{X|Y}(x_i|y)&amp;=???
\end{align*}</p>

<p>But I am not sure how to proceed next. For example does density $f_{X|Y}(x_i|y)$ even exists?
Thank you for any help or suggestions.</p>
",probability
"<p>I'm really new to statistics and probability so sorry if this is a really basic question. I just wasn't sure how to do it. I tried looking it up but can't find much information. </p>

<p>If I'm given a cdf for a random variable X, how do I find it for a new random variable Y which was in terms of X? Do I just plug in Y? My example is following:</p>

<pre><code>FX(x) = 1 −1/x
for 1 &lt; x &lt; ∞
Find the cdf for the new random variable Y = -X + 2
</code></pre>
",probability
"<p>Let $III$ be a root node of a tree. It may have between $0, \cdots , B_1$ children type $X$, and $1 \cdots B_2$ children type $Y$ with probability $\beta_{i,X}$ and $\beta_{i,Y}$, respectivelly. Let $p_X$ be probabilty a node chidren type $X$ evaluate $1$. And $p_Y$ is probabilty a node chidren type $Y$ evaluate $1$.</p>

<p>Find the probability the root node $III$ evaluates $0$? </p>

<p><a href=""http://i.stack.imgur.com/dQXo9.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/dQXo9.png"" alt=""enter image description here""></a></p>

<p>My solution is</p>

<p>The prob. the root node $III$ evaluates $0$ is</p>

<p>$$P(III=0)=P(X=0)P(Y=0)$$ </p>

<p>We have, $p(.)$ is prob. of a node (.) , $P(.)$ is prob. of a group node</p>

<p>$$p(X=0)=1-p(X=1); P(X=0)=\sum_{j=0}^{B_1} \beta_{j,X} (1- p_X)^j$$
$$p(Y=0)=1-p(X=1); P(Y=0)=\sum_{i=1}^{B_2} \beta_{i,X} (1- p_Y)^i$$</p>

<p>Finaly, we got, </p>

<p>$$P(III=0)=P(X=0)P(Y=0)=\sum_{j=0}^{B_1} \beta_{j,X} (1- p_X)^j \sum_{i=1}^{B_2} \beta_{i,X} (1- p_Y)^i$$</p>

<p>However, I found that someone provides another solution as</p>

<p>$$P_{1}(III=0)=\sum_{i=1}^{B_1+B_2-1} \sum_{j=0}^{i-1} \bigg( \beta_{j,X} \big(1-y_X \big)^j \beta_{i-j,Y} \big(1-y_Y \big)^{(i-j)} \bigg) $$</p>

<p>My question is does $P(III=0)$ same with $P_{1}(III=0)$. If not, which one is correct? Thank all</p>
",probability
"<p>Ill give some background first before asking questions.(the text below is straight out of the book)</p>

<p>Each individual in the population is assumed give birth at an exponential rate of $\lambda$ in addition ,there is a an  exponential rate of increase  $\theta$ due to external source of immigration. Hence the total birth rate where there are $n$ persons in the system is $n\lambda + \theta$ . Deaths are assume to occur at an exponential rate $\mu$  for each member of the population, so $\mu_n = n\mu$.</p>

<p>Let $X(t)$ denote the population size at time $t$. Suppose $X(0)= i$ and let $M(t) = E[X(t)]$ . So they will determine $M(t)$ by deriving and then solving a differential equation that is satisfies.</p>

<p>we start by deriving an equation for $M(t+h)$ by conditioning on $X(t)$ this yields:</p>

<p>$M(t+ h) = E[X(t+h)] = E[E[X(t+h)\vert X(t)]]$ </p>

<p>Now,given the size of the population at time $t$ then, ignoring  events whose probability is $o(h)$, the population at time $t+h$ will either increase in size by 1 if a birth or immigration occurs in $ (t,t+h)$ , or, decrease by 1 if a death occurs in this interval, or remain the same if neither of these two possibilities occurs that is given $X(t)$</p>

<p>$X(t+h)$=
\begin{cases}
 X(t) + 1 , with- probability  &amp; [\theta + X(t)\lambda]h + o(h) \\
 X(t) - 1, with-probability &amp; X(t)\mu h + o(h)\\
 X(t), with-probability &amp; 1-[\theta + X(t)\lambda + X(t)\mu]h +o(h)
\end{cases}</p>

<p>therefore,
$E[X(t+h) \vert X(t)] =  X(t) + [\theta + X(t)\lambda - X(t)\mu]h + o(h)$</p>

<p>.....
.....
.....(text continues)</p>

<p>$\textbf{questions:}$</p>

<p>$\textbf{(1)}$,  i understand the first two cases , but the last case i don' t quiet get: $X(t)$, with-probability  $1-[\theta + X(t)\lambda + X(t)\mu]h +o(h)$. can someone explain this?</p>

<p>$\textbf{(2)}$How do i interpret this statement: $E[X(t+h) \vert X(t)] =  X(t) + [\theta + X(t)\lambda - X(t)\mu]h + o(h)$</p>

<p>these are my two questions.</p>
",probability
"<p>Assume that $H$ is a separable Hilbert space and $\{e_k\}$ is an orthonormal and complete basis of $H$.</p>

<p>$\{\xi_k\}$ is a sequence of normal Gaussian random variables that are independent.</p>

<p>It seems that $\sum_{k=1}^{\infty}\xi_k \langle e_k,h\rangle,\ h\in H$ is square-integrable, but I am not sure how to prove. Who can give me some hints?</p>

<p>Thanks a lot.</p>
",probability
"<p>I'm having a tough time finding the next example's sample space's size:</p>

<p>We have at our disposal the following: the three letters $\;a,b,c\;$ , and the five digits $\;1,2,3,4,5\;$ . We have to form with them all the possible passwords of six ($\;6\;$) characters, under the condition that there <em>must be</em> at least one letter and at least one number in each password. Other than this there are no more restrictions (and, thus, one can repeat at will numbers, letters and etc.)</p>

<p><strong>What I tried:</strong> I fixed one letter and one digit, thus getting $\;3\cdot 5=15\;$ possibilities fir each fixation (?), and for the other $\;4\;$ characters needed in the password I have $\;8\;$ possibilities for each (as repetitions are allowed), rendering $\;8^4\;$ possibilities. </p>

<p>I further thought of multiplying the above by two to indicate that the first two characters I chose can be interchanged, and finally I multiplied by $\;\binom 62=15\;$ possibilities to place them within the six places of the password.</p>

<p>All in all, the above says there are $\;15\cdot8^4\cdot2\cdot\binom65\;(**)$ possibilities</p>

<p>All fine...but there are repetitions! For example, suppose for simplicity I have fixed the characters $\;a,1\;$ , and say I place them in positions $\;2-3\;$ . But then one possible password is $\;1-a-1-1-1-1\;$ , yet if I swap my fixed characters in these positions I get the password $\;1-1-a-1-1-1\;$ , which already appears when the positions $\;2-3\;,\;2-4\;,\;2-5\;,$ etc. are chosen.</p>

<p>Thus, the number (**) abo0ve is way over the actual number I'm seaching, and I'm about to become a friar in Malta out of desperation, so any help will be greatly appreciated.</p>
",probability
"<blockquote>
  <p>Suppose $X\in N(0,1)$. Show that $X$ and $|X|$ are not jointly continuous.</p>
</blockquote>

<p>I am not sure how I can approach this problem. But the following method seems plausible to me:</p>

<blockquote>
  <p>$$P(X\leq x||X|=u)=\lim_{a\to0}\dfrac{P(X\leq x,|X|\in (u-a,u+a))}{P(|X|\in (u-a,u+a))}$$</p>
</blockquote>

<p>Of course we must have $u&gt;0$. Now let $-u&lt;x&lt;u$ then after some stage, I will get $a$ so small that $x$ will not belong to $(u-a,u+a)$ or $(-u-a,-u+a)$. In that case, the intersection of $(-\infty,x)$ and $(-u-a,-u+a)\cup(-u-a,-u+a)$ will be $(-u-a,-u+a)$ due to which the result becomes:</p>

<blockquote>
  <p>$$\lim_{a\to0}\dfrac{P(X\in(-u-a,-u+a))}{P(X\in(-u-a,-u+a))+P(X\in(u-a,u+a))}=\lim_{a\to0}\dfrac{\Phi(-u+a)-\Phi(-u-a)}{\Phi(-u+a)-\Phi(-u-a)+\Phi(u+a)-\Phi(u-a)}=0.5$$</p>
</blockquote>

<p>Now for $x&lt;-u$, the intersection $\{X\leq x\}$ with $\{|X|\in(u-a,u+a)\}$ is null, hence the numerator is $0$, so the probability is $0$. If $x&gt;u$ then the probability is $1$.</p>

<p>Hence $P(X\leq x||X|=u)=0$ if $x&lt;-u$, is $0.5$ if $-u&lt;x&lt;u$ and is $1$ if $x&gt;u$. So it has two jumps and cannot be a continuous distribution function, and hence cannot have a density. But this density is precisely the conditional density of $X$ on $|X|$, which therefore does not exist. This can happen only when $f_{X,|X|}(x,u)$ does not exist, which shows there is no joint density of $X$ and $|X|$.</p>
",probability
"<p>If we define absolutely continuous random variables by Lebesgue integrals &amp; Lebuesgue measures, i.e.</p>

<p>$$F(t) = \int_{-\infty}^{t} f(x) d x$$</p>

<p>for some Lebesgue integrable $f(x)\ge 0$, is it always the case that $F$ is continuous? I know this is true for Riemann integrals due to the fundamental theorem of calculus. Forgive me if this is a stupid question, I'm doing a probability course with very little measure theory in it.</p>
",probability
"<p>What is the likelihood of a fair coin given that it has landed heads up 10 times?</p>

<p>You have a fair coin or a double-headed coin...</p>

<p>$\mathsf P($Fair$\mid 10$ heads$) = \dfrac{(1/2)(1/2^{10})}{(1+2^{10})/(2\cdot 2^{10})}= \dfrac{(1/2)(1/1024)}{1025/2048}$</p>

<p>Is this the correct procedure for setting up this problems?</p>

<p><strong>You have a fair coin or $70\%$ weighted coin favoring heads...</strong></p>

<p><strong>What is the likelihood of a fair coin given that it has landed heads up 10 times?</strong></p>
",probability
"<p>So there are 12 files in total and 3 of them contain viruses. If a file with a virus is selected, it is removed and a new file is then selected. What is the expected number of files that need to be selected to get a virus free computer? </p>

<h3>Progress</h3>

<p>I thought it was an expected value problem. So summation $\sum X(\xi)p(\xi)$ but that doesn't make sense.   </p>

<p>Is this correct?  Let n be the number of viruses, then the result is $n(1/1 + .. +1/n)$ $$3(1/1 + 1/2 +... + 1/12) = 9.3096$$  </p>
",probability
"<p>According to <a href=""http://en.wikipedia.org/wiki/Characteristic_function_%28probability_theory%29"" rel=""nofollow"">Wikipedia</a>, a characteristic function completely determines the properties of a probability distribution. This means it must be unique. However, the definition given is:</p>

<p>$$
\text{Char of }X (t)=E[e^itX]$$</p>

<p>Now $e^{iz}$ repeats for every $2 \pi$ increase in $z$. So how can it be unique?</p>
",probability
"<p>$A, B, C$ are independently sampled from an uniform distribution in $[0, 1]$.</p>

<p>We know $P(A &gt; B) = 0.7, P(B &gt; C) = 0.6$, what is $P(A &gt; C)$?</p>

<p>Is this a well defined problem? Does it have a sensible answer?</p>

<p>EDIT: Suppose we have two careless observers.
An observer observes $A &gt; B$ and there are 70% probability that she is right.
Another observer observes $B &gt; C$ and there are 60% probability that she is right. So what is the probability of $A &gt; C$ in the underlying event?</p>
",probability
"<p>Here $G_{n,p}$ represents the Erdős-Rényi random graph model, where the graph has order $n$ and each edge is added independently with probability $p$. I am faced with proving the following claim:</p>

<blockquote>
  <p>Show that there is a constant $c&gt;0$ such that, for every $p$ we have: </p>
  
  <p>$\mathbb{P}(G_{n,p}$ is disconnected) $\leq c \mathbb{P}(G_{n,p}$ has an isolated vertex).   $\,\,\,(*)$</p>
</blockquote>

<p>From the appearance of the question I think it is meant to be interpreted as asking ''in the limit $n \to \infty$''. It is clear that $\mathbb{P}($a fixed vertex of $G_{n,p}$ is isolated$)=(1-p)^{n-1}$. It is easy to calculate the expected number of isolated vertices using this, but I'm not convinced that helps.</p>

<p>As a last thought, a followup to the question asks ""What value of $c$ would be acceptable""? It is therefore probably not the case that a valid choice of $c$ will actually be obtained in the proof, although it may be reasonably clear how to calculate one; perhaps that clarifies the nature of the solution a little. Many thanks for your help.</p>

<p><strong>Edit:</strong> Update - I have thought a little more about it, and I have the following theorem we can hopefully make use of (if anyone is willing to help me!): suppose $p = \frac{\log{n}+\gamma(n)}{n}$ and $\gamma(n)$ grows at most slowly (say $o(\log \log n)$); then </p>

<blockquote>
  <p>if $\gamma(n) \to +\infty$, $\mathbb{P}(G_{n,p}$ disconnected)$\to 0$, </p>
  
  <p>if $\gamma(n) \to -\infty$, $\mathbb{P}(G_{n,p}$ disconnected)$\to 1$, </p>
  
  <p>if $\gamma(n) \to k$, $\mathbb{P}(G_{n,p}$ disconnected)$\to 1-e^{-e^{-k}}$.</p>
</blockquote>

<p>Now in the first case, being connected implies no isolated vertex, so $(*)$ holds with any constant $c$ since both probabilities are 0. Likewise, in the second case, the graph is almost surely disconnected: while this doesn't immediately imply that an isolated vertex exists, we can hopefully say for $X:=\#$ of isolated vertices,</p>

<p>$\mathbb{E}(X)=n(1-p)^{n-1} = n(1-\frac{\log{n}+\gamma(n)}{n})^{n-1} \sim ne^{-(\log{n}+\gamma(n))} = e^{-\gamma(n)} \to \infty$.</p>

<p>I <strong>think</strong> this last step holds but it may depend on $\gamma$: in general I'm not sure for which functions $(1+\frac{f(n)}{n})^n \to e^{f(n)}$, I know this is true for the log term but maybe not if $\gamma$ grows very fast (though obviously it can't grow any faster than $1-\frac{\log{n}}{n}$ otherwise we would have $p&gt;1$).</p>

<p>We can also calculate the second moment and get $\mathbb{E}(X^2)-\mathbb{E}(X)^2 \sim e^{-\gamma(n)}$ and deduce that with high probability there is an isolated vertex. Thus again, both probabilities are equal and we can take (e.g.) $c=1$. </p>

<p>The <em>hard</em> case is where $\gamma(n) \to k$: in this case we can reapply the same method to get $\mathbb{E}(X) \sim e^{-k}$, a constant. We can calculate again $\mathbb{E}(X^2) -\mathbb{E}(X)^2 \sim e^{-k}$, and use Chebyshev's inequality to calculate $\mathbb{P}(X=0) \leq e^{-k}/e^{-2k} = e^k$. If $k&lt;0$, then this gives us an actual bound on the probability; otherwise we just get $\mathbb{P}(X=0) \leq 1$. </p>

<p>Supposing $k&lt;0$ then; we can rewrite as $s:=\mathbb{P}(X&gt;0)=\mathbb{P}$(isolated vertex)$\geq 1-e^k$, $d:=\mathbb{P}($disconnected) and using the fact $d =1- e^{-e^{-k}}$ and a little rearranging I think we get out the inequality $d \leq 1-\exp\left(\frac{1}{s-1}\right)$. We can then find a $c$ which works by applying the lower bound to $s$ in terms of $k$ then looking at the values of $c$ such that $cx \geq 1-\exp\left(\frac{1}{s-1}\right),\,x \in [1-e^k,1]$. However, this is only for fixed $k$! If we try and do this for <em>every</em> $k&lt;0$ (i.e. every probability of this type) simultaneously, then we find that $c$ must be arbitrarily large. What's worse, this method doesn't work at all for $k \geq 0$ where we don't have a lower bound for $s$: in this case $s$ can be arbitrarily small and we can't pick a $c$ big enough to always work. So close and yet so far. </p>

<p>I am aware this question's length has spiralled out of control, so apologies for that - I know there's a good chance Math.SE is not going to provide me with an answer to this one. Nevertheless, it says add your working and this is what I managed to do! A proof which works for all <em>slowly</em> decreasing $\gamma$ or $\gamma \to k \in (-\infty,-\epsilon],$ any $\epsilon &gt; 0$. </p>

<p>I have a strong suspicion this is not how I was meant to try and tackle the question, but tragically this is the best I could do so far. Thank you in advance to anyone who actually reads through all this!</p>
",probability
"<p>I've found this formula in a blog, it is in the answer to one question. But I don't know how to prove this:</p>

<blockquote>
  <p>Let $x_n$ be a sum of $n$ i.i.d. Bernoulli random variables with parameter $1/2$. Let $q\geq 2$.
  Show that 
  $$
E((2x_n-n)^q)=\sum_{k=0}^n{n \choose k}2^{-n}(2k-n)^q
$$</p>
</blockquote>

<p>Thank you for your help.</p>
",probability
"<p>The formula for the expected value in a binomial distribution is:</p>

<p>$$E(X) = nP(s)$$
where $n$ is the number of trials and $P(s)$ is the probability of success.</p>

<p>The formula for the expected value in a hypergeometric distribution is:</p>

<p>$$E(X) = \frac{ns}{N}$$
where $N$ is the population size, $s$ is the number of successes available in the population and $n$ is the number of trials.</p>

<p>$$E(x) = \left( \frac{s}{N} \right)n $$
$$P(s) = \frac{s}{N}$$
$$\implies E(x) = nP(s)$$</p>

<p>Why do both the distributions have the same expected value? Why doesn't the independence of the events have any effect on expected value?</p>
",probability
"<p>There are $m$ normally distributed, independent random variables $N_1, \ldots, N_m$ with distinct means $\mu_1, \ldots \mu_m$ and standard deviations $\sigma_1, \ldots, \sigma_m$. Then, we get a permutation of the numbers $\{1, \ldots, m\}$. How can we efficiently compute, numerically, the (log) probability of observing the random variables in same ordering as this permutation?</p>

<p>An example:</p>

<ol>
<li>we have four independent random variables $N_1, N_2, N_3, N_4$, all with different means and variances. </li>
<li>We are given the permutation (3, 1, 2, 4).</li>
<li>What's $\Pr(N_3 &gt; N_1 &gt; N_2 &gt; N_4)$?</li>
</ol>

<p>A closed-form solution is not necessary, but computing the solution using an efficient algorithm with good accuracy is. Also, it's probably necessary to compute a log probability due to the fact that when the number of variables becomes large, computing the actual probability will result in a floating-point underflow. </p>

<h3>Some starting points, perhaps...</h3>

<p>The most direct way to compute this value, using the example above, is evaluating one of the following integrals, which I believe are equivalent:</p>

<p>$$ \int_{-\infty}^\infty \int_{n_4}^\infty \int_{n_2}^\infty \int_{n_1}^\infty p(n_1)p(n_2)p(n_3)p(n_4)\ dn_3 dn_1 dn_2 dn_4 $$</p>

<p>$$ \int_{-\infty}^\infty \int_{-\infty}^{n_3} \int_{-\infty}^{n_1} \int_{-\infty}^{n_2} p(n_1)p(n_2)p(n_3)p(n_4)\ dn_4 dn_2 dn_1 dn_3 $$</p>

<p>Where $p(n_i)$ is the density function of the variable $N_i$. However, when I tried to implement this numerically, it is inefficient, prone to inaccuracy, and runs into underflow errors when the number of variables gets large. <strong>If you think you can compute this integral in an acceptable way, please do post your answer!</strong></p>

<p>From one of the answers below, we observe that it's possible to compute $\Pr(N_3 &gt; N_1 &gt; N_2 &gt; N_4)$ directly by evaluating a multivariate normal CDF of dimension $(m-1)$, or 3 in this case. However, this is still nontrivial (though there may be libraries for it), and will underflow for many variables.</p>

<p>Perhaps we can divide the probability up as follows:</p>

<p>$$\Pr(N_3 &gt; N_1 &gt; N_2 &gt; N_4) = $$
$$\Pr(N_3 &gt; N_1 \mid N_1 &gt; N_2, N_2 &gt; N_4 )\Pr(N_1 &gt; N_2 \mid N_2 &gt; N_4 )\Pr(N_2 &gt; N_4)$$</p>

<p>Being able to compute the probabilities of each part directly would make it very easy to compute the log probability simply by adding. We can compute the conditional probabilities separately using the MVN CDF method, which could help if the product might underflow.</p>

<p>Another observation: the $m!$ possible probabilities corresponding to the different permutations must sum to 1. Perhaps there is a way to compute the probabilities iteratively or using dynamic programming: i.e.: $(N_2 &gt;  N_3)$, an ordering over a pair, has some fixed probability, which is further divided into three values by the three possible places to insert $N_1$ into the ordering, further divided into the four values by the possible places to insert $N_3$. This is semantically equivalent to the conditional probabilities above but it might be easier to think of it this way.</p>

<p>Any math wizards have suggestions on how to solve this problem? I would greatly appreciate any ideas!</p>
",probability
"<p>I am not a mathematics guy, and the question which I am gonna ask would be pretty simple for mathematicians. In fact I am doing research and was reading some blogs. I wanted to derive the density function for $n$ number of independent variables. following relation I find on Internet for calculating CDF of $n$ number of independent variables
$$
F(T) = 1 – (1 - F_1(T)) (1 - F_2(T)) \dots (1- F_n(T)) = 1 – \prod_{i=1}^n F_i (T)
$$
 but for PDF they says that take the derivative of it . In fact I learned mathematics decades ago, so I don't know how to do that. Can some one just help me in steps how to take derivate of above equation and finally what would be the Density function?</p>
",probability
"<p>I need to show that if $E_1,E_2,\ldots, E_n$ are independent then $E_1^c ,E_2^c,\ldots, E_n^c$ are independent too. Please provide a hint.</p>
",probability
"<p>First, let's recall the definitions of 4 different types of convergence:almost surely, in $r$th mean, in probability and in distribution:</p>

<ol>
<li>$X_n\xrightarrow{a.s.}X$ if $\{\omega \in \Omega:X_n(\omega)\rightarrow X(\omega),$ as $n\rightarrow\infty\}$ is an event with probability 1.</li>
<li>$X_n\xrightarrow{L^r} X$ if $\forall r\geq1,\mathbb{E}[X_n^r]&lt;\infty$, $\mathbb{E}[|X_n-X|^r]\rightarrow 0$, as $n\rightarrow \infty$</li>
<li>$X_n\xrightarrow{p}X$ if $\forall \epsilon &gt;0,\mathbb{P}(|X_n-X|&gt;\epsilon)\rightarrow 0,$ as $n\rightarrow \infty$</li>
<li>$X_n\xrightarrow{D}X$ if $\mathbb{P}(X_n\leq x)\rightarrow \mathbb{P}(X\leq x)$ as $n\rightarrow \infty$</li>
</ol>

<p>In Wikipedia I got the following implication relations:</p>

<ol>
<li>If $s&gt;r\geq1,(X_n\xrightarrow{L^s} X) \Rightarrow (X_n\xrightarrow{L^r}X)$</li>
<li>Convergence almost surely and convergence in mean both imply convergence in probabilty.</li>
<li>$(X_n\xrightarrow{p}X)\Rightarrow (X_n\xrightarrow{D}X)$ (Convergence in probability implies convergence in distribution)</li>
</ol>

<p>So, what I want to ask here is that if somebody can give me some simple examples to briefly explain why the implication works and some counter examples why it doesn't work conversely(the other direction of the implication arrow), because all those definitions look so similar to me, especially, for example, why convergence in probability doesn't imply convergence almost surely? For the definitions of them are really the same thing.</p>

<p>I'll really appreciate if you can help me out. Thanks!</p>
",probability
"<blockquote>
  <p>An insurance company examines its pool of auto insurance customers and gathers the following information:</p>
  
  <p>(i)  All customers insure at least 1 car</p>
  
  <p>(ii)  64% of all customers insure more than one car</p>
  
  <p>(iii)  20% of the customers insure a sports car</p>
  
  <p>(iv)  Of those customers who insure more than one car, 15% insure a sports car.  </p>
  
  <p>What is the probability that a randomly selected customer insures exactly one car, and that car is not a sports car?</p>
</blockquote>

<p>Let's use the following variable definitions:</p>

<p>O= owns 1 car, O' = owns more than 1 car</p>

<p>S= sports car, S' = Not sports car.  </p>

<p>N() = Cardinal Number of a set</p>

<hr>

<p>From statements (i)-(iii), we get the following:  $N(O') = 64, N(O) = 36, N(S) = 20$</p>

<p>From statement (iv):  $\Pr(S \mid O')=15$</p>

<p>We are asked to find $\Pr(S' \mid O)$</p>

<hr>

<p>By definition:<br>
$Pr(S' \mid O) = \cfrac{\Pr(S' \cap O)}{\Pr(O)}=\cfrac{\Pr(S' \cap O)}{N(O)}\tag{1}$</p>

<p>Pr()=N() since this is a uniform distribution--I interpret this when it says ""randomly selected""</p>

<p>Next, I did: </p>

<p>$N(S)=N(S \cap O') + N(S \cap O)\tag{2}$</p>

<p>$0.2 = .64*.15 + .36 * x$</p>

<p>$x=0.28$, but we want 1-x because we want S' in $\Pr(S' \cap O)$ which equals 0.72.</p>

<p>See diagram below:</p>

<p><img src=""http://i.stack.imgur.com/n5UVW.png"" alt=""Tree diagram""></p>

<p>So plugging back into (1):  </p>

<p>$Pr(S' \mid O) = \cfrac{0.71*.36}{.36}=.71$</p>

<p>but the answer is .26.  </p>

<p><strong>I mainly wanted to know why equation (2) is wrong.  I know that is the crux of the problem.  Why can't I use that equation in this case?</strong></p>

<p>Any help is appreciated.  Thank you.</p>
",probability
"<p>$\newcommand{\E}{\operatorname{\mathbb E}}$
$\newcommand{\Var}{\operatorname{\mathbb Var}}$
If $\E[X] = {^1\!/\!_3}(\E[X\mid Y=1] + \E[X\mid Y=2] + \E[X\mid Y=3]) = 10$</p>

<p>Where $\E[X|Y=1] = 2,\; \E[X|Y=2] = 3+\E[X],\; \E[X|Y=3] = 5+\E[X]$</p>

<p>is $\E[X^2|Y=1] = 4,\; \E[X^2|Y=2] = 9 + 6\E[X] + 6\E[X^2],$ and so on?</p>

<p>This is to find the $\Var(X)$.</p>

<p>where $\Var(X) = \E[X^2] - (\E[X])^2$</p>

<p>Question: How do you find the Variance of this given that $\E[X] = 10$?</p>
",probability
"<p>The characteristic function of a random variable $X$ is given as:</p>

<p>$$E(e^{jvX}) = \int _{-\infty} ^{\infty} e^{jvx} p(x) dx $$</p>

<p>This is interpreted as either mean of function $e^{jvx}$ or fourier transform of pdf $p(x)$. I know that $x$ represents random variable, but what does $v$ represents? What is its physical significance?</p>
",probability
"<p>Let $m$ be a finite measure on $X \subseteq \mathbb{R}^n$, so that $m(\mathbb{R}^n) &lt; \infty$.</p>

<p>Define the hyperplanes on $\mathbb{R}^n$, parametrized by $A \in \mathbb{R}^{n \times n}$ and $b \in \mathbb{R}^n$, as
$$ H(A,b) := \{ x \in \mathbb{R}^n \mid A x = b \}. $$</p>

<p>Take many ""extractions"" $y_1, y_2, ...$ from $m$. </p>

<p>Say under what conditions on $m$ no more than $n$ i.i.d. extractions $y_i$'s belong to the same hyperplane almost surely, i.e.</p>

<p>$$ m^{n+1}\left( \left\{ (y_1, y_2, ..., y_{n+1}) \in X^{n+1} \mid \\
\exists (A,b) \in (\mathbb{R}^{n \times n} \times \mathbb{R}^n) \text{ such that } y_1, y_2, ..., y_{n+1} \in H(A,b)  \right\} \right) = 0,$$</p>

<p>where $m^{n+1} := m \times m \times \cdots \times m$ ($n+1$ times) is the product measure.</p>

<p>I was thinking about merely atomless $m$, but I then thought it may not be enough.</p>
",probability
"<p>I've been struggling for a while to understand the meaning of liminf of a sequence of sets. </p>

<p>I know that the definition is </p>

<p>$\liminf_{n\to\infty}A_n:=\bigcup_{n\in\mathbb{N}}\bigcap_{m\geq n} A_n$.</p>

<p>When I break it up into pieces, I get $(A_1 \cap A_2 \cap A_3 \cap A_4 \cap \ldots) \cup (A_2 \cap A_3 \cap A_4 \ldots) \cup (A_3 \cap A_4 \cap \dots) \cup (A_4 \cap \ldots) \cup \ldots$.</p>

<p>Here, $A_n$ occurs infinitely many times, doesn't it? Because it is in each set of parentheses?</p>

<p>Or do the unions mean <strong>OR</strong>, so that $A_n$ might or might not be in any of the sets? </p>

<p>However, this is wrong! Why? I'm confused.</p>
",probability
"<p>I am studying stochastic processes and have stumbled on a result that is puzzling me. I have searched elsewhere for an answer without luck so hoping some proper mathematicians here can explain the result for me.</p>

<p>Given a two-state Markov process with probability transition matrix
$$
\begin{array}{c|c}
&amp;\begin{matrix}0&amp;1\end{matrix}\\
\hline
\begin{matrix}0\\ 1\end{matrix}
&amp;\pmatrix{a&amp;b\\ c&amp;d}
\end{array}
$$</p>

<p>I have found that the simplest way to calculate its steady-state probability distribution is :</p>

<p>state 0: $c \over {b + c}$</p>

<p>state 1: $b \over {b + c}$</p>

<p>This result holds for all examples I have tried, but I have been unable to explain it from theory, so cannot prove it. My questions are:</p>

<ol>
<li>what is the theoretical explanation for this result?</li>
<li>does it extend to any $n\times n$ transition matrix?</li>
</ol>
",probability
"<p>So the exercise is this:</p>

<p>We have and infinite chessboard and we have a coin. Every grid is of length and width $a$, whereas the coin has diameter $2 \cdot r&lt;a$. We throw a coin into a chessboard and we want to know with what probability the coin will falll into the grid.</p>

<p><img src=""http://i.stack.imgur.com/y9SI1.jpg"" alt=""enter image description here""> </p>

<p>So let $S_{1}$=area of green rectangle, $S_{2}=S_{1}+$ area of the red border.
So the probability in my opinion is 
$ P(a)= \frac{S_{1}}{S_{2}} $.</p>

<p>Is this in any shape or form correct?</p>
",probability
"<p>I'm reading a book with chances and probability.
The book has the following problem:
""The draw for the fifth round of the FA Cup is about to be made.  There are 16 teams, leading to eight matches.  Your task is to pair the teams off, in an attempt to guess as many as possible off the actual matches in the real Cup draw.  You are not asked which teams will be drawn at home, just which pairs will be selected.  I am prepared to pay you $1.50 for each correct guess; how much would you be prepared to offer for the right to make the eight guesses?""
(What is the minimum fair entrance fee?)</p>

<p>I would like pointers to solve this by using ordinary combinatorics, if possible.  (Author uses the idea: sum of the averages is the averages of the sum, which it might be faster, but I would be jumping to an easy way of solving this without first analyzing/understand/adopt it).</p>

<p>I have tried the following:<br>
First Match arrangements (16x15)=240<br>
Second Match arrangements (14x13)=182<br>
Third Match arrangements (12x11)=132<br>
Fourth Match arrangements (10x9)=90<br>
Fifth Match arrangements (8x7)=56<br>
Sixth Match arrangements (6x5)=30<br>
Seventh Match arrangemets (4x3)=12<br>
Eighth Match arrangements (2x1)=2<br>
So I get 744 possible arrangements.  </p>

<p>I'm starting to question my above approach because on the Eighth Match arrangements, I have 2 possible ways, when intuitively I know there is only one way (it is the last matching pair), so I know I'm missing something but cannot point it down.</p>

<p>Thanks in advance!</p>
",probability
"<p>$\newcommand{\Var}{\operatorname{Var}}$
$\newcommand{\Cov}{\operatorname{Cov}}$</p>

<p>I am supposed to show the following:</p>

<p>$$
\Var(Y-E(Y\mid X)) = E(\Var(Y\mid X))
$$</p>

<p>My attempt involved using simple property of conditional expectations and variances, I get a close result, but not quite:</p>

<p>$$
\Var(Y-E(Y\mid X)) = \Var(Y) + \Var(E(Y\mid X)) - 2\Cov(Y,E(Y\mid X))
$$</p>

<p>Since $\Cov(Y,E(Y\mid X)) = \Cov(Y,Y) = \Var(Y)$, then:</p>

<p>$$
\Var(Y) + \Var(E(Y\mid X)) - 2\Cov(Y,E(Y\mid X)) = \Var(E(Y\mid X)) - \Var(Y)
$$</p>

<p>But $\Var(Y) = \Var(E(Y\mid X)) - E(\Var(Y\mid X))$ and then:</p>

<p>$$
\Var(E(Y\mid X)) - \Var(Y) = \Var(E(Y\mid X)) - \Var(E(Y\mid X)) - E(\Var(Y\mid X)) = -E(\Var(Y\mid X))
$$</p>

<p>Thanks!</p>
",probability
"<p>Two n bit binary strings S1 and S2 are chosen randomly with uniform probability.The probability that the Hamming distance in between these strings (the number of bit positions where the two strings differ) is equal to d is</p>

<pre><code>1)nCd/2^n 
2)nCd/2^d
3)d/2^n 
4)1/2^d
</code></pre>

<p>? Choose the right answer.(Sorry for ambiguity).
I tried to solve the problem ,but indeed didn't find any suitable way to tackle this problem.</p>
",probability
"<p>I have the following problem. I'm struggling a little bit with the expression $P(X \in A)$. My problem is that $A$ is a set, whereas $X$ is a function. I can not really related this two items. </p>

<p>Here are some related definitions from the textbook I use. </p>

<ul>
<li>Sample space: $\Omega$ </li>
<li>Outcome: $\omega$</li>
<li>Event: $A, (A \subset \Omega) $</li>
<li>Random variable:  $X: \Omega \rightarrow R $ $\big($X assigns a real number to each outcome ($X(\omega)$ $\big)$.</li>
</ul>

<p>I tried to work out a simple example: Toss a coin two times and let X be the number of heads. Then: $\Omega = \{HH,HT,TH,TT\} $. For example if we have a look on the prob. that we get two heads, $P(X=2)=\frac{|\{HH\}|}{|\Omega|}=\frac{1}{4}$, it makes kind of sense to me, because we compare the cardinality of of two sets. However, I can not imagine a Example of $P(X \in A)$.</p>

<p>Can maybe someone give some intuition for that or give a small example in the case of a coin toss (or dice or ...). </p>

<p>cheers!</p>
",probability
"<blockquote>
  <p>Suppose that $X$ and $Y$ are independent and identically distributed:
  $$P (X = k) = P (Y = k) = ρ (1 − ρ)^k$$
  for $k = 0, 1, \dots$ and let $Z := X + Y$. Find the joint distribution of $(X, Z)$ and find the conditional distribution of $X$, given $Z = n$.</p>
</blockquote>

<p>I need a little help just setting this up.</p>

<p>If I understand the question, I'm looking for $P (X = k, Z = n)$ and $P (X = k \mid Z = n)$. I'm a little confused, though, because I've never done this when I have a variable defined as a linear function of the other random variables. I also don't really understand what $n$ is.</p>

<p>Any hints or help getting started is appreciated.</p>
",probability
"<p>Suppose that $Y$ has the binomial distribution, $Bin(20, 0.25)$ and conditioned on $Y$, a random variable $X$ that has the binomial distribution, $Bin(Y, 0.5)$. </p>

<p>How can I derive the $k$th moment of $X$?</p>

<p>I know the general case:</p>

<p>$E(X)=∑_{x∈Ω_X}x^kP[X=x]$, and I know that just for one binomial random variable, $E[X]$ is $np$, but I'm not sure how to deal with $X$, which is conditioned on a second variable.</p>
",probability
"<p>So the question is: given that you roll $10$ dice, what is the probability of the sum of the total dice rolls adding up to $57$? </p>

<p>I know that there are three ways to do this:</p>

<ol>
<li>Seven die rolls must be $6$ with three $5$s</li>
<li>Eight die rolls must be $6$, one die roll must be $5$ and one must be $4$</li>
<li>Nine die rolls must be $6$, and one roll must be $3$</li>
</ol>

<p>The solution states that the probability of the events are:</p>

<ol>
<li>$ \binom{10}{3} \cdot \frac{1}{6^{10}}$</li>
<li>$ \binom{10}{1} \cdot \binom{9}{1} \cdot \frac{1}{6^{10}} $</li>
<li>$ 10 \cdot 9 \cdot \frac{1}{6^{10}} $</li>
</ol>

<p>I really don't understand why the probabilities work this way. I would really, really appreciate it if someone could perhaps explain this in a more intuitive way for me. </p>

<p>Edit: I am really sorry for the mistake. Edited so that the question reads sum up to 57. </p>

<p>Edit 2: Also, I think my solution sheet is missing the fact that you should sum all of these probabilities and set them over $6^{10}$. I apologize for the mess and I appreciate all the comments that pointed this out.</p>
",probability
"<p>We have that $N$ and $X_1, X_2, \dots$ are all independent. We also have $\operatorname{E} [X_j] = \mu$ and $\operatorname{Var}[X_j] = σ^2$.</p>

<p>Then, we introduce an integer–valued random variable, $N$, which is the random sum such that:
$$Z = \sum_{j=1}^{N+1}X_j.$$
Assuming that $N$ is distributed $\sim\mathrm{Poisson}(\lambda)$, what is the first moment and what is the variance of $Z$?</p>

<p>For a normal Poisson distribution, I know the variance is just $\lambda$, as is the mean. I'm having trouble understanding the implication of having the bounds be poisson distributed. Normally, I would just say ""variance of the sum is the sum of the variance,"" but I don't think that's how it works with random sums. Any hints/guidance appreciated.</p>
",probability
"<p>I know how to calculate expected value for a single roll, and I read several other answers about expected value with rerolls, but how does the calculation change if you can make your reroll before choosing which die to keep?</p>

<p>For instance, what is the expected value of rolling $2$ fair $6$-sided dice and keeping the higher value?  And can you please generalize to $n$ $x$-sided dice?</p>
",probability
"<p>I've been exercising probability and came across the following problem:</p>

<p>A club has $N$ members, where $N$ is a random variable with probability-mass-function: $p_N(n)=p^{n-1}(1-p)$.</p>

<p>Each member has a probability $q$ to show up and all the ""showing-up""s and $N$ are pairwise independent.</p>

<p>If $A$ is a r.v. telling how many members will show up, I need to compute the variance of $A$.</p>

<p><strong>Could you please tell me why the following part of the official solution is correct:</strong></p>

<blockquote>
  <p>$\text{var}(A) = E\ [N]\cdot \text{var}(B) + (E \ [B])^2\cdot\text{var}(N)$</p>
  
  <p>where $B$ is a Bernoulli random variable describing whether a member turns up or not.</p>
</blockquote>

<p>I am familiar with the law of total variance: $\text{var}(X) = E\ [\text{var}(X|Y)]+\text{var}(E\ [X|Y])$</p>

<p>and with the law of iterated expectations: $E\ [X] = E\ [\ E\ [X|Y]\ ]$,</p>

<p>but I can't see any connection between any of them and the statement I want to know the justification of. Thanks!</p>

<p>PS It probably has something to do with expressing $A$ as a sum of $A_1+\ldots+A_n$ where $A_i$ is an indicator function of whether the $i$th member shows up, but still, what do I do with $\text{var}(A) = \text{var}(A_1+\ldots+A_n | N=n)$?</p>
",probability
"<p>The chance that a team wins a game when loosing 3+ turnovers is 13.3% if their opponent is not the Lakers. If
their opponent is the Lakers, the percentage of winning is 24%.</p>

<p>There are 30 teams in total. What is the likelihood of a team winning a game
if their opponent is <strong>not</strong> the Lakers.</p>

<p>I have done the following: <br>
P(Playing not the Lakers) = 28/29 or .9655 <br>P(Playing the Lakers) = 1/29 or .0345<br> P(Win | Playing the Lakers) = .133<br> P(Win | Not the Lakers) = .24<br><br>
However, now that I calculated these values, I am unsure of where to go with them. Any help or elaboration would be much appreciated. Thank you.</p>
",probability
"<p>I have $S=R+\epsilon$ where $R \sim Cauchy(r, 1/\alpha)$ and $\epsilon \sim Cauchy(0, 1/\beta)$. I want to calculate the distribution of $R$ given $S=s$. </p>

<p>I've tried the following:</p>

<p>By the definition of conditional probability, we have $f_{R | s}(x | s) = \frac{f_R(x) f_\epsilon(s-x)}{f_{R+\epsilon}(s)}$. </p>

<p>We know that for $X \sim Cauchy (x_0, \gamma)$ we have the density function
$f(x) = \frac{1}{\pi \gamma} \frac{\gamma^2}{(x-x_0)^2 + \gamma^2}$</p>

<p>Then plugging this in (and simplifying a bit), we get</p>

<p>$$f_{R | s}(x | s) = \frac{1}{\pi (\frac{1}{\alpha + \beta})}
\frac{\frac{1}{(\alpha+\beta)^2}}{\frac{((x-r)^2+\frac{1}{\alpha^2})((s-x)^2+\frac{1}{\beta^2})}{(x-r)^2+(\frac{\alpha+\beta}{\alpha \beta})^2
}
}
$$</p>

<p>I can't simplify the part on the bottom to get what would be desired if it were a Cauchy distribution. Any hints/tips? Thank you!</p>
",probability
"<p>Given a process $X_n \xrightarrow{d} X$ on some probability space $(\Omega,\mathcal{A},P)$. If for every $B \in \mathcal{A}$ it holds, that
$$
\lim_{n\rightarrow \infty} P(X_n\in A,B)=P(X\in A)P(B)
$$
and any set $A$ of continuity of the distribution function of $X$, we say the convergence is renyi-mixing in the classical discrete time sense. 
This is shown to be equivalent to: Fix $m$ and for $B\in \sigma(X_{1},\ldots,X_{m})$ with $P(B)&gt;0$ then
$$
\lim_{n\rightarrow \infty} P(X_n\in A|B)=P(X\in A)
$$</p>

<p>Now lets say we have a continuous time proces $X_t$ with $X_t\xrightarrow{d}X$. If we want the convergence to be renyi-mixing, is it sufficient to show, that for any countable grid $(t_i)_{i\in\mathbb{N}}$ with $t_{i}\rightarrow \infty$ as $i\rightarrow \infty$
$$
\lim_{i\rightarrow \infty}P(X_{t_i}\in A,B)=P(X\in A)P(B)
$$
holds?</p>

<p>Best regards</p>
",probability
"<p>Let $X$ be Brownian motion on a Riemannian manifold $M$ starting at $x\in M$, D a domain and $f$ a bounded continuous function on $D$. Define $\tau_D$ to be the first exit time of $X$ from $D$. $u_f\left(t,x,y\right)=\int_Dp_D\left(t,x,y\right)f\left(y\right)dy$ solves</p>

<p>$
\begin{cases} 
L_Mu_f\left(t,x\right)=0, &amp; t&gt;0,x\in\overline{D}, \\
u_f\left(t,x\right)=0, &amp; t&gt;0,x\in\partial D, \\
\lim_{t\downarrow0}u_f\left(t,x\right)=f\left(x\right), &amp; x\in D.
\end{cases}
$</p>

<p>I have seen the following two formulae written:</p>

<p>$$\mathbb{P}_x\left(X_t\in C, t&lt;\tau_D\right)=\int_Cp_D\left(t,x,y\right)dy$$
and
$$E_x\left(f\left(X_t\right),t&lt;\tau_D\right)=\int_Dp_D\left(t,x,y\right)f\left(y\right)dy.$$</p>

<p>Is $\mathbb{P}_x$ the joint probability of the events $\{X_t\in C\}$ and $\{t&lt;\tau_D\}$? I also do not know what the interpretation for $E_x\left(f\left(X_t\right),t&lt;\tau_D\right)$ is. Any help is appreciated.</p>
",probability
"<p>Let $x$ and $y$ be two random variables with support of $\left[1\hspace{5pt}10\right]$  and $\left[50\hspace{5pt}90\right]$ respectively. The distribution of each of these variables is $p_X(x)$ and $p_Y(y)$ respectively. and their joint distribution is $p_{X,Y}(x,y)$. Now let us define two random variables as follows</p>

<p>\begin{equation}
z_1 = \frac{y}{x} \\
z_2 = x
\end{equation}</p>

<p>The distribution, $p_{Z_1}(z_1)$, of $z_1$ can be found as follows
\begin{equation}
p_{Z_1}(z_1) = \int_{-\infty}^{\infty} z_2p_{X,Y}(z_1z_2,z_2)dz_2
\end{equation}</p>

<p>My question is: </p>

<ol>
<li>Does the distribution $p_{Z_1}(z_1)$ depend upon the values of $x$, $y$ and $\frac{y}{x}$?</li>
<li>Does the distribution $p_{Z_1}(z_1)$ depend only upon $\frac{y}{x}$?</li>
</ol>

<p>The reason for asking this question is as follows:</p>

<p>Assume $y = 70$ and $x = 7$. Then $Z_1 = 10$. Since these values of $x$ and $y$ are within their support, the joint distribution $p_{X,Y}(x,y)$ will be zon-zero and so will be $p_{Z_1}(z_1)$. On the other hand, assume $y = 150$ and $x = 15$. Both these values are outside their support. But $Z_1$ is still $10$. $p_{X,Y}(x,y)$ will be close to zero. What can we say about $p_{Z_1}(z_1)$? In fact, for given $Z_1 = 10$, we can choose several values of $x$ and $y$ within their support and with different $p_{X,Y}(x,y)$. Does the choice of the values of $x$ and $y$ affect $p_{Z_1}(z_1)$?</p>
",probability
"<p>An urn contains 5 red and 6 blue and 8 green balls. 3 balls are randomly selected from the urn, find the probability that they are all of the different colors if the balls are drawn without replacement</p>
",probability
"<p>I'm trying to endow a set of probability measures $\triangle\left(X\right)
 $  with the weak * topology, where $X=\left\{ x_{1},\, x_{2},\,...,\, x_{N}\right\} \subseteq\mathbb{R}$ is a finite set of elements. Of course, this seems very straightforward because the set of probability measures can be identified with the n-dimensional simplex</p>

<p>$\hspace{5cm} S^{N}=\left\{ p\in\mathbb{R}^{N}\,|\, p\geq0,\,\underset{i}{\sum}p_{i}=1\right\}$ </p>

<p>My question is this identification. Is it ""natural"" to identify $\triangle\left(X\right)
 $ with $S^{N}$ (that is, treating each $p \in S^{N}$ as a probability measure defined as, for each $A \subset X$,  $p(A)=\underset{x_{i}\in A}{\sum}p_{i} $ ) and then give $S^{N}$ the topology with subbasis elements of the form </p>

<p>$\hspace{3cm}\left\{ p\in S^{N}\,|\,\left|\underset{i}{\sum}f\left(x_{i}\right)p_{i}-a\right|&lt;\varepsilon\right\},$ $\hspace{1cm} f:X \rightarrow \mathbb{R}$, $a \in \mathbb{R}$, and $\epsilon&gt;0$ </p>

<p>Thanks for your help. I know it's kind of a weird question I just want to make sure I'm staying consistent with definitions. </p>
",probability
"<p>Playing ""Rim World"", I noticed a geometric variable, but whose individual event probability increases with each attempt (or with time).  So I first model it with a simple probability, having a single failure parameter $q$.  The $n$th event has probability $1-q^n$ to succeed.  The probability to suceed at event $n$ is thus</p>

<p>\begin{equation}
P(n) = \left( \prod_{k=1}^{n-1} q^k \right) \cdot (1-q^n)
\end{equation}</p>

<p>My question is, what is the expected value of that random variable ?
Here is what I got so far :</p>

<p>\begin{align}
E[n] &amp;= \sum_{n\ge1} n\cdot \left( \prod_{k=1}^{n-1} q^k \right) \cdot (1-q^n)\\
     &amp;= \sum_{n\ge1} n\cdot \left( q^{\sum_{k=1}^{n-1} k} \right) \cdot (1-q^n)\\
     &amp;= \sum_{n\ge1} n\cdot q^{(n-1)\cdot n} \cdot (1-q^n)\\
     &amp;= \left( \sum_{n\ge1} n\cdot q^{(n-1)\cdot n} \right)
     -  \left( \sum_{n\ge1} n\cdot q^{(n-1)\cdot n^2} \right) \\
\end{align}
Now I'd like to do, $\zeta = q^n$ and $\xi = q^{n^2}$,
\begin{align}
E[n] &amp;= \left( \sum_{n\ge1} n\cdot \zeta^{(n-1)} \right)
     -  \left( \sum_{n\ge1} n\cdot \xi^{(n-1)} \right) \\
     &amp;= \frac{1}{(1-\zeta)^2} - \frac{1}{(1-\xi)^2}\\
\end{align}
But $\zeta$ and $\xi$ depends on $n$, so that's not a valid way of computing that.  How would you do it ?  Thank you for suggestions !</p>
",probability
"<p>I have read some introductory probability theory textbooks and found that for a continuous random variable, $P(x=a) =0\;\forall a$ , that means, whatever what possible outcome I choose, the possibility of it happens is zero. I found it strange, because it stated that no outcome is possible. (But I have no problem in understanding that it does not implies $P(whole sample space) = 0$)</p>

<p>Maybe the above interpretation is flawed, if yes, please correct me, thank you.</p>
",probability
"<p>Let's say I have a signal $y(t) = Acos(2\pi f_c t)$, where $f_c$ is the carrier frequency and $t$ is the independent variable. Since I work with discrete signals i sample this signal with a sampling rate $f_s = 100f_c$, so I obtain $y[n] = \big\{ t \rightarrow \frac{n}{100f_c}\big\} = Acos(\frac{\pi}{50} n)$. Now if we consider $x= \frac{\pi}{50}n$, we have $y = Acos(x)$ where $x \sim unif[-\pi,\pi]$ and $A$ is deterministic. Which is the probability density funciton of variable $y$, i.e. $f_y(y)$ ?</p>

<p>Thanks a lot.</p>
",probability
"<p>This is my second question following this <a href=""http://math.stackexchange.com/questions/771551/a-3-minute-algebra-problem"">post</a>.</p>

<blockquote>
  <p>Three players are playing a game. They all have small amounts of
  money, let say: player 1 has $\$a$, player 2 has $\$b$, and player 3
  has $\$c$, where $a&lt;b&lt;c$. The probability of each player wins each
  turn of the game is $p$ for player 1, $q$ for player 2, $r$ for player
  3, and $s$ for having draw, where $p+q+r+s=1$. The losers will transfer a dollar ($\$1$) to the winner for each turn. The game ends until one
  player has all the money. What is the probability of each player going
  bankrupt? What is the expected number of turns so that only one player
  left as the winner?</p>
</blockquote>

<p>Suppose that they play blackjack, if player 1 gets 20 points, player 2 gets 19 points, and player 3 gets 18 points, then the winner of that turn is player 1, so the other two players must pay a dollar to the player 1. If there are two players get, for example, 19 points and the another player gets 18 points, then that turn is considered draw. If they all get 19 points, this is also considered draw. <strong>If one player loses all the money, then he will stop playing and only two player will continue the game with probability of winning for each player is $x$ and $y$, also the probability of draw is $z$</strong>. Each turn will be repeated until one player has all the money.</p>

<p>To be honest, I can't answer this question and I really don't get it. I left my answer sheet totally empty for this one. (─‿‿─)</p>

<p>Please help me to answer this question and provide a simple explanation about the answer you submit. Every answer would be greatly appreciated.</p>
",probability
"<p>I am interested in probabilistic or explicit ways to construct an $\epsilon$-net of the $l_2$ unit ball in $\mathbb{R}^{d}$.</p>

<p>I know that, for every $\epsilon &gt; 0$, there exists an $\epsilon$-net $\mathcal{N}_{\epsilon}$ for the unit sphere in $d$ dimensions such that
$$
M\triangleq\left|\mathcal{N}_{\epsilon}\right|
\le \left( 1+\frac{2}{\epsilon}\right)^{d}.
$$
(Lemma 5.2 in <a href=""http://www-personal.umich.edu/~romanv/papers/non-asymptotic-rmt-plain.pdf"" rel=""nofollow"">http://www-personal.umich.edu/~romanv/papers/non-asymptotic-rmt-plain.pdf</a>)
To my understanding, the aforementioned bound holds for an $\epsilon$-net of the entire ball, not only the sphere.</p>

<p>In the case of the sphere, we can construct an $\epsilon$-net with high probability, 
by drawing a sufficient number ($O(M\log{M})$) of independent random vectors according to a Gaussian distribution $N(\mathbf{0}, \mathbf{I})$, and normalizing the length to $1$.
I believe that one way to get an $\epsilon$-net for the ball,
would be to repeat the above procedure $O(1/\epsilon)$ times, for all spheres of radii $\epsilon, 2\epsilon,3\epsilon, \dots, 1$.
The union of the $\epsilon$-nets, should be able to cover the ball.
However, it would require $\tilde{O}\left((1+2/{\epsilon})^{d+1}\right)$ points (ignoring the logarithmic factor).</p>

<ul>
<li>Is there a simple way to construct an $\epsilon$-net for the unit ball directly, $\textit{i.e.}$, without constructing nets for multiple spheres?</li>
<li>Is there way to achieve the bound on $\left|\mathcal{N}_{\epsilon}\right|$ (possibly up to logarithmic factors)?</li>
</ul>

<p>I would appreciate any pointers to either probabilistic or explicit methods.</p>
",probability
"<p><strong>First of 2 part query</strong>: I have observed a 100 doctors and recorded the number of times they touch surfaces while in a room:</p>

<p>\begin{array}{l|c|c|c|c}
\text{Dr number}&amp;\text{Bed}&amp;\text{Table}&amp;\text{Chair}&amp;\text{Door}\\
\text{Dr } 1&amp;3&amp;2&amp;2&amp;1\\
\text{Dr } 2&amp;4&amp;1&amp;0&amp;1\\
\vdots&amp;\vdots &amp;\vdots &amp;\vdots &amp;\vdots\\
\text{Dr } 100&amp; 2&amp;3&amp;1&amp;1
\end{array}</p>

<p>I would like to calculate the probability of him touching the Table for example. Would it be:</p>

<p>\begin{array}{l|c|c|c|c|c}
&amp;\text{Bed}&amp;\text{Table}&amp;\text{Chair}&amp;\text{Door}&amp;\text{Total}\\
\text{Average contacts}&amp;3&amp;2&amp;1&amp;1&amp;\text{7}\\
P(\text{surface})&amp;3/7&amp;2/7&amp;1/7&amp;1/7&amp;1
\end{array}</p>

<p>This is confusing me but I think a fresh pair of eyes will spot it instantly.</p>

<p><strong>2nd part</strong>: I gave questionnaires out to some doctors who ticked boxes instead of giving contact numbers, i.e.:</p>

<p>\begin{array}{l|c|c|c|c}
\text{Dr number}&amp;\text{Bed}&amp;\text{Table}&amp;\text{Chair}&amp;\text{Door}\\
\text{Dr}  &amp;\checkmark&amp;\checkmark&amp;\checkmark&amp;\checkmark\\
\text{Dr } \checkmark&amp;\checkmark&amp;\checkmark&amp;\times&amp;\checkmark\\
\vdots&amp;\vdots &amp;\vdots &amp;\vdots &amp;\vdots\\
\text{Dr } 100&amp; \checkmark&amp;\checkmark&amp;\checkmark&amp;\checkmark
\end{array}</p>

<p>What can I deduce from this table of ticks to compare with the table of exact values? Or is it not worth anything? </p>

<p>Please ask for any clarification if needed,
Regards</p>

<p><strong>EDIT: Revised Surface contact Probability</strong>  Should this replace table 2?</p>

<p>\begin{array}{l|c|c|c|c|c}
&amp;\text{Bed}&amp;\text{Table}&amp;\text{Chair}&amp;\text{Door}&amp;\text{Total}\\
\text{Total contacts}&amp;9&amp;6&amp;3&amp;3&amp;\text{21}\\
P(\text{surface})&amp;9/21&amp;6/21&amp;3/21&amp;3/21&amp;1
\end{array}</p>
",probability
