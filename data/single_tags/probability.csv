"<p>Let's say you have a 20 sided dice and every side is considered bad, but each time you roll a bad side it will no longer be bad for future rolls. 
I am looking for the mathmatical term for the scale of increase on the expected amount of times you will be able to roll success as bad sides are removed </p>
",<probability>
"<blockquote>
  <p>Let $X\sim\mathcal N(μ_1,σ_1^2)$ and $Y\sim\mathcal N(μ_2,σ_2^2)$ and $\mathsf{Cov}(X,Y)=c$ How can we compute $\mathsf {Cov}(X^2,Y^2)$?</p>
</blockquote>

<p>I think the answer should be something like $c^2$ and I think the joint PDF is really not necessary here. I think the approach is using some independent standard normal random variables by variable changing. But I can't make it out. </p>

<p>Thanks.</p>
",<probability>
"<p>How can one determine the probability function $f(x)$ given a situation and no equations? I am unsure if there is a special method or if you should just plug in values and look for a pattern.</p>

<p>For example, if you draw 2 numbers from 0 through 9 without replacement, and $X=$ {total of the 2 numbers}, then how could you determine $f(x)$? I came up with the sample space $|S|= {10 \choose 2}$, and found probabilities for X = 1,2,3, ... etc. </p>

<p>I got $\frac{1}{10 \choose 2}$ for $X=1$ and $X=2$ and then the numerator increases by 1 for $X=3,4$, increases again by one for 4 and 5, and then values are repeated in pairs like that if I have done this correctly. My confusion is how to determine a formula now. Can it even be done?</p>
",<probability>
"<p>Problem statement: Suppose we have a random sample $\{X_i:1\le i\le10\}$ from a normal distribution with mean $\mu=20$ and variance $\sigma^2=100$. Find the probability,
$$P\left(\sum_{i=1}^6X_i&gt;X_7+2X_8+2X_9+X_{10}+16\right)$$
My initial thoughts: For any $X_i$, we know the MGF is $M_{X_i}(t)=20t+50t^2$. I defined a new random variable $Y$ denoted by the linear combination in which every term in the inequality is on one side, i.e.
$$Y=X_1+\cdots+X_6-X_7\cdots-X_{10}-16$$
so that now the problem is finding $P(Y&gt;0)$. I find that the MGF of $Y$ is
$$M_Y(t)=e^{-16t}\left(20t+50t^2\right)^6\left(-20t+50t^2\right)^2\left(-40t+200t^2\right)^2$$
Is this making the problem more difficult than it needs to be? I don't think this looks like the MGF of a distribution I might be familiar with.</p>
",<probability>
"<p><img src=""http://i.stack.imgur.com/HqML7.png"" alt=""enter image description here""></p>

<p>im on the last part and my attempt was to:</p>

<p>find $P(|\bar{X_n} - \mu| &lt; 0.01) &gt; 0.99$ but in the solutions showed the equation is $P(|\bar{X_n} - \mu|/\mu &lt; 0.01 ) &gt; 0.99$ why do we have to divide through my $\mu$?</p>
",<probability>
"<p>Motivation: A friend asked me this question.</p>

<p>The Problem: Suppose you start off with a dollar. You flip a fair coin, if it lands on heads you win $50$ cents otherwise you lose $50$ cents. If after $n$ flips you have a nonzero amount of money, you win. What's the probability you win? What about the limiting case as $n$ tends to infinity?</p>

<p>edit: In this game you are not allowed to have negative money. Thanks, Jonathan Fischoff, the linked helped greatly.</p>
",<probability>
"<p>Imagine a process with two variables <em>min</em> and <em>max</em>, and two counters <em>hi</em> and <em>lo</em>.</p>

<p>We initialize <em>min</em> and <em>max</em> by selecting two random numbers (assume a uniform (0,1) distribution for convenience), and sorting them.  We also set the <em>hi</em> and <em>lo</em> counters to 0.</p>

<p>At each step we select a new random number <em>r</em> from our distribution and do the following</p>

<pre><code>if (r &lt; min) {
  lo++;
} else if (r &gt; max) {
  hi++;
} else if (lo &gt; hi) {
  max = r;
  hi++;
} else if (hi &gt; lo) {
  min = r;
  lo++;
} else {
  if (rand(0,1) &gt; 0.5 ){
    max = r;
    hi++;
  } else {
    min = r;
    lo++;
  }
}
</code></pre>

<p>If the random number is outside our range, we increment the appropriate counter, and if it lies inside our range we increment the lower counter and adjust our range appropriately.  The question is, after <em>n</em> iterations, where do we expect min and max to end up.</p>

<p>It can be seen that the difference between min and max (assuming a uniform(0, 1) distribution) is distributed as the minimum of <em>n + 2</em> uniform (0, 1) random variables.  However, it should be possible to say considerably more about the location of <em>min</em> and <em>max</em> over time.</p>

<p><strong>Edit</strong>  This algorithm is only vaguely related to median finding.  The process given here just takes a sequence of unifomly distributed random numbers and attempts to guess the median by remembering only two values.  This, of course is not an effective method, but similar algorithms are used (remembering more than two variables).</p>

<p>The process that I want to analyze has two values and two counters, and takes a sequence of random numbers, if the random number is larger than both, then increase the <em>hi</em> counter, if the number is smaller than both then increase the <em>lo</em> counter, and if the number lies between the two, either replace <em>max</em> with the current number and increase <em>hi</em> or else replace <em>min</em> with the current number and increase <em>lo</em>, whichever makes the <em>hi</em> or <em>lo</em> counters closer (in cases where either choice could be made, flip a coin).  <em>hi</em> and <em>lo</em> are counting the numbers that we have seen that are larger than <em>max</em> or smaller that <em>min</em> respectively.</p>

<p>What I want to know, is how to figure out the distribution of <em>min</em> and <em>max</em> as the number of iterations becomes large, also of interest is the distribution of <em>hi - lo</em>.  I can find the distribution of <em>max - min</em> using elementary order statistics.</p>

<p>If <em>min = max</em>, then <em>hi - lo</em> is an ordinary one dimensional random walk, and is easy to analyze.  When they are different the walk is subtly biased towards 0.  Similarly the values of <em>min</em> and <em>max</em> are biased towards 0.5, I want to know how to find out by how much they are biased.</p>
",<probability>
"<p>Let $X_n $ be uniformly distributed on $[0,1]$. We say $X_k$ is a local maximum if $X_k&gt; X_{k\pm 1}$. Let $A_n$ count the number of local maxima of the sequence unto and including $n$. Find $a_n, b_n$ such that </p>

<p>$$\frac{A_n-a_n}{b_n} \longrightarrow N(0,1)$$</p>

<p>If someone could give a hint on how to approach this problem that would be great. I understand that I will need to use the Lindberg central limit theorem at some point to show the convergence. </p>
",<probability>
"<p>Given two random integers $a$, $b$ calculate probability of $a^2$ + $b^2$ is divisible by $10$.</p>

<p>I've tried to simulate this process and got a result about $0.18$ (maybe incorrect), but have no idea why.</p>
",<probability>
"<p>If the stars are distributed randomly within the universe, what is the probability for a star to be the nearest neighbor of a star that is its nearest neighbor? What if the number of spatial dimensions is higher than 3 or even grows without limit? </p>

<p>PS. I am interested in the asymptotic behavior with the number of stars growing without bound.</p>

<p>PPS. It's a well-known problem (the ""birds on a wire problem"" in higher dimensions) and I know the answers. However, no idea how to solve this analytically.</p>
",<probability>
"<p>Vince buys a box of candy that consists of six chocolate pieces, four fruit pieces and two mint pieces.  He selects three pieces of candy at random without replacement.</p>

<blockquote>
  <ol>
  <li><p>Calculate the probability that the first piece selected will be fruit flavored and the other two will be mint.</p></li>
  <li><p>Calculate the probability that all three pieces selected will be the same type of candy.</p></li>
  </ol>
</blockquote>
",<probability>
"<p>I have a probability density function over $SO\left(3\right)$, which I am trying to sample from. The $pdf$ is given as a generalized fourier series:</p>

<p>$$ f\left(\omega,\theta,\phi\right)=\sum s_{\lambda}^{n}Z_{\lambda}^{n}\left(\omega,\theta,\phi\right)$$</p>

<p>where $s_{\lambda}^{n}$ are the coefficients and $Z_{\lambda}^{n}\left(\omega,\theta,\phi\right)$ are basis functions (symmetrized hyperspherical harmonics), and $SO\left(3\right)$ is parameterized by the variables $\left(\omega,\theta,\phi\right)$, which are the rotation angle, and spherical coordinates of the rotation axis, respectively. I want to sample values of $\left(\omega,\theta,\phi\right)$ (i.e. rotations) from this distribution, but I'm having trouble doing so.</p>

<p>So far I have essentially tried two methods: rejection sampling, a discrete method.</p>

<p>Both methods have given me something that is qualitatively similar to what I would expect, but they seem to have an erroneous uniform distribution superimposed. So I have two questions:</p>

<p><strong>(1) Any ideas why I might be getting this uniform noise?</strong></p>

<p><strong>(2) Any suggestions of how to fix it or a better way to sample from this kind of distribution?</strong></p>

<p><strong>Further Details:</strong>
To check my sampling method I used some software to generate a known distribution and sample rotations. I then computed $s_{\lambda}^{n}$ from these ""correct samples"". Then I tried to generate samples myself from the spectral form of $f\left(\omega,\theta,\phi\right)$ given above. Next I calculated $s_{\lambda}^{n}$ from my samples and compared the two. My samples led to the low order terms being generally too small in magnitude and the higher order terms being too large in magnitude.</p>

<p>The discrete method that I used consisted of generating a ""grid"" of points over $SO\left(3\right)$, and using these as the centers of bins. The bins were sized proportional to the probability density at the bin center. Then uniform samples were generated and the number that fell in each bin was then proportional to the associated probability of the respective bins.</p>

<p>Again, both methods produced a sort of background noise which looks like a uniform distribution on top of the correct distribution.</p>

<p>As, a side note, it seems like I ought to be able to exploit the form of this expression for efficient sampling, but I haven't made use of the spectral decomposition at all in my attempts.</p>
",<probability>
"<p>I am reading a book that defines the Malliavin derivative $D_tF$ as follows:
If  </p>

<ol>
<li><p>$F = \sum_{n=0}^{\infty} I_n(f_n)$ is the Wiener Chaos expansion.</p></li>
<li><p>$F$ is in the brownian filtration and $F \in L^2(P)$.</p></li>
<li><p>$\sum_{n=0}^{\infty} n n! ||f_n||_{L^2([0,T]^n)}^2 &lt; \infty$</p></li>
</ol>

<p>Then
 $D_tF = \sum_{n=1}^{\infty} nI_{n-1}(f_n(.,t))$.</p>

<p>My question is why do we need 3 to be so strong. It seems that in the theory the $n!$ is never used. Is it defined this way in order to have it match the malliavin derivative constructed using other methods?</p>

<p>If it is used in the theory can you please tell me the point where it becomes important.</p>

<p>Thank you</p>
",<probability>
"<p>This is for the GRE:</p>

<p><code>A fair coin is tossed once and a fair die with sides numbered 1, 2, 3, 4, 5, and 6 is rolled once. Let A be the event that the coin toss results in a head. Let B be the event that the roll of the die results in a number less than 5. What is the probability that at least one of the events A and B occurs?</code></p>

<p>How do you solve this to come up with $\frac{5}{6}$ (correct answer)? Probabilities are not easy. Any tip you can give is appreciated. Thanks.</p>
",<probability>
"<p>I have a sequence of iid Bernoulli random variables $X_1, X_2, \dots, X_n$ with $Pr(X_j) = p$, and I'd like to know (a lower bound on) the probability that there exists a consecutive subsequence of length $k$ of them (e.g. $X_i, X_{i+1},...X_{i+k-1}$) such that every random variable in the subsequence takes on the value 1.</p>

<p>Even though the individual variables are independent from each other, the subsequences aren't, and that's where I'm stuck.</p>

<p>Letting $E_{n,k}$ be the event that there is a subsequence of $k$ variables all set to 1: here are the first few terms.</p>

<p>For $k = 2, n=2, Pr(E_{n,k}) = p^2$</p>

<p>For $k = 2, n = 3, Pr(E_{n,k}) = p^3 + 2p^2(1-p)$</p>

<p>For $k = 2, n = 4, Pr(E_{n,k}) = p^4 + 4p^3(1-p) + 3p^2(1-p)^2$</p>

<p>For $k = 2, n = 5, Pr(E_{n,k}) = p^5 + 5p^4(1-p) + 9p^3(1-p)^2 + 4p^2(1-p)^3$</p>

<p>There's simple recurrences for the first, second, and last terms of this sequence, but I can't see how to generate the middle terms, much less sum everything up in a neat way.</p>
",<probability>
"<p>An extra sum of squares $SSR(X_p|X_1,...X_{p-1})$, assuming that no pair of predictor variables are perfectly correlated, measures the marginal reduction in the error sum of squares. Eventually one can view an extra sum of squares as measuring the measuring the marginal increase in the regression sum of squares when one or several predictor variables are added to the regression model.</p>

<p>Assuming the number of observational data $n$ is lager than the number of predictor variables $p$.</p>

<p>Can I have a rigourous proof that $SSTO=\sum_{i=1}^n (Y_i-\bar{Y})^2\geq SSR(X_p|X_1,...X_{p-1})\geq0$ ?</p>

<hr>

<p>Applying LSE</p>

<p>$SSE(X_1,...,X_{p-1})=\sum(Y_i-b_0-b_1X_{1,i}-...-b_{p-1}X_{p-1,i})^2=\sum(Y_i-b_0-b_1X_{1,i}-...-b_{p-1}X_{p-1,i}-0\times X_{p,i})^2\geq\sum(Y_i-b_0'-b_1'X_{1,i}-...-b_{p-1}'X_{p-1,i}-b_p'X_{p,i})^2=SSE(X_1,...,X_{p-1},X_p)$</p>

<p>$SSR(X_p|X_1,...X_{p-1})=SSE(X_1,...,X_{p-1})-SSE(X_1,...,X_{p-1},X_p)\geq 0$</p>

<p>Proved.</p>
",<probability>
"<p>Given an urn with a number of two objects, $A$'s and $B$'s, if I am to find the probability of the $i$-th object drawn without replacement to be an $A$ would I need to compute all the different ways that $i-1$ objects can first be drawn?</p>

<p>For example if $i = 3$ would I need to first compute the probability that the first two objects drawn are $A$ then $A$, $A$ then $B$, $B$ then $A$, and $B$ then $B$. Then find the probability of the 3rd object drawn being $A$ in each of these instances and sum all 4 ways that the 3rd objects is $A$? My particular $i$ is 6 so I want to make sure this is correct before actually doing it.</p>
",<probability>
"<p>Question: An urn contains n red and m blue balls. They are withdrawn one at a time until a total  of r; r · n, red balls have been withdrawn. Find the probability that a total of k balls are  withdrawn.</p>

<p>My attemp:</p>

<pre><code>let A=event that first k-1 draws will get r-1 red balls
let B=event that last (kth) draw will get rth red ball
P(kth draw is the rth red ball)= P(A AND B) = P(A)xP(B)

P(A)=  # of  ways to draw r-1 red balls in k-1 trail
     -----------------------------------------------------
               # of ways to draw k-1 balls
</code></pre>

<p>So I got stuck; I was thinkg that </p>

<pre><code> RBBB *R is one way to achieve P(A AND B)
 BBBR *R is another way. 
</code></pre>

<p>but the solution  for P(A) is:</p>

<pre><code> solution: P(A)= nC(r-1) x mC(n-r) x 1/(n+m)C(k-1)
</code></pre>

<p>This solution is like assuming</p>

<pre><code> R1B1B2B3 * R2       is one way
 R2B4B5B6 * R3       is another way   
</code></pre>

<p>Because they use nC(r-1)x mC(n-r).  Any ideas?</p>
",<probability>
"<p>Set of non negative weights $w_j$, set of non negative i.i.d. random variables $X_j$ and $f(y)$ is a decreasing nonnegative function in $y$. </p>

<p>I want to claim that: </p>

<p>if $\sum w_i&lt;\sum w^{\prime}_i$,then $\mathbb E f(\sum w_iX_i)&gt;\mathbb E f(\sum w^{\prime}_iX_i)$.</p>

<p>This seems intuitive but I would like a formal proof.</p>

<p>My attempt: The next line holds if all r.vs are coupled to a common r.v. $X_i\sim U$. But not sure if we can do that.
$$\sum w_iX_i&lt; \sum w^{\prime}_iX_i,$$
We have  $$f(\sum w_iX_i)&gt; f(\sum w^{\prime}_iX_i),$$ almost surely.</p>

<p>And we take expectation $$\mathbb E f(\sum w_iX_i)&gt;\mathbb E f(\sum w^{\prime}_iX_i). \;\;\;\;\;\;\; (a)$$  Therefore the result holds a.s.</p>

<p>Is this proof correct? If wrong where is the mistake?</p>

<p>The function $f$ I have is $\log(1+\frac{1}{y})$ and $X_i$ are exponential r.vs.</p>
",<probability>
"<p>I know this isn't that hard, but I have been looking and I don't know how to solve it.</p>

<p>The number of students whose grade is higher than 1149 is 44, and the total of students is 135. If the question where only for 1 random student, it would be 32%, but I don't know how it is for more than that.</p>

<p>Please help me.</p>
",<probability>
"<p>Let $X_1,X_2,\dots$ be I.i.d. And $S_n = X_1+X_2+\dots +X_n. $Prove if $S_n/n \to 0$ in probability then $(\max_{1\leq m \leq n}S_m)/n \to 0$ in probability.</p>

<p>I know the idea and there is a detail I don't know how to prove. 
If |Sn-Sk|$\leq$|Sn|+|Sk| and Sn/n limits to 0 in probability, how can I prove that minP(|Sn-Sk|$\leq n\delta$)$\to $ 1 as $ n \to \infty$ ($0\leq k \leq n$)</p>
",<probability>
"<p>The spectrum of a discrete random variable X consists of the points 1, 2, 3,..., n  and its probability mass function (pmf) fi = P(X = i) is proportional to 1/i(i+1). Determine the distribution function of X. Further, compute P(3 &lt; X &lt;= n).</p>
",<probability>
"<p>If four dice are tossed, find the probability that exactly 3 fives will show ( answer to the nearest thousandth in the for 0.xxx)?</p>
",<probability>
"<p>Given $P(A|B)= 0.5, P(B|A)=0.4,$ and $P(A) + P(B) = 0.9$ what is $P(A)=$ ?.</p>
",<probability>
"<p>The number of total outcomes of an experiment are $25$. If $A$ and $B$ are two non-empty independent events of the experiment such that outcomes in favour of event $A$ are $15$, then the minimum number of outcomes in favour of event $B$ can be? </p>
",<probability>
"<p>Assume we have a lottery with payouts $(2,3,5)$. So if you buy a ticket you can win a pot which will payout your ticket price multiplied by one of those numbers.<br>
The organizer expects a margin profit of $4\%$ from all tickets. So if the player plays with $1\$$ the mathematical expectation of outcomes will be $0.96$.</p>

<p>In my <a href=""http://math.stackexchange.com/questions/1470264/lottery-payout-with-organizer-margin"">previous question</a> I asked almost the same question thinking that my approach calculating the probability of each payout was right. I wanted the probability of each payout to be proportional to the payout $P_i \propto \frac1{x_i}$ (where $P_i$ is the probability of winning the $i$ payout and $x_i$ is the value of that payout). So I got an answer with these probabilities $(0.192,0.096,0.0576)$ and this explanation $$
\begin{align}
\sum P_i \cdot x_i &amp;= 0.192 \cdot 2 + 0.096 \cdot 3 + 0.0576 \cdot 5 \\
&amp;= 0.96
\end{align}
$$
Can someone please explain or help me to understand how these probabilities can be counted and the idea behind that. </p>

<p>My previous method which I used and assume was wrong looked like this.<br>
If $P_i$ is the probability of payoff $i$ and there are $N$ total positive payoffs that $P_ii = 0.96/N$. Then you get the formula that $P_i = \frac{0.96}{iN}$, which would look like this in my question <br>
$P_2 = \frac{0.96}{2*3}$ where $3$ is the number of positive payouts. <br>
Thank you</p>
",<probability>
"<p>The first $12$ natural numbers are given. Two distinct numbers are selected. What's the probability that their sum is divisible by $3$? </p>

<p>This looks very easy. I know answer is $1/3$ but in spite of knowing permutations and combinations I had to find favourable cases. The numbers were few. What if we were given  question like probability that two numbers natural less than $100$ are selected and their sum is divisible by $3$? Any smart guy wouldn't go on counting. There has to be some way out which I am missing. Can you guys tell what's the best way? Thanks!</p>
",<probability>
"<p>I have 3 (not independent) events $A, B, C$ and I know everything about how any two of them correlate. For example, I know:</p>

<p>$$ P[A], P[B], P[C], P[A,B], P[A,C], P[B,C], P[A|B], P[A|C], P[B|C], P[B|A], ...$$</p>

<p>Is there any way to use this information to calculate a correlation for the three of them, i.e.</p>

<p>$$    P[A,B,C] \text{ or } P[A,B|C]  \text{ or } P[A|B,C] $$</p>

<p>A numerical algorithm would also be fine if there isn't an exact formula.
If it is not possible, is there a way to get a confidence interval for these values?</p>
",<probability>
"<p>I have a $64$-card deck, with $4$ colours - red, green, blue, yellow, $4$ numbers - $1,2,3,4$ and $4$ letters A,B,C,D. So an example card could be yellow2D.</p>

<p>I was attempting to calculate the probability of $4$ of a kind, i.e. $4$ green cards, $4$ $3$'s, etc... having been dealt $k$ cards.</p>

<p>But I got all stuck!</p>
",<probability>
"<p>Say I roll a $6$ sided dice and I want to roll a $6$. what is the probability that I will have rolled the number I want after $6$ rolls?</p>

<p>I have been using this: $\displaystyle1-\left(1-\frac{1}{x}\right)^y$</p>

<p>where $x$ is the number of sides and $y$ is the amount of rolls, so it would be $\displaystyle1-\left(1-\frac{1}{6}\right)^6$ for rolling a specific number in $6$ rolls, which is $\approx66.5\%$ is this the correct way of calculating the probability of something like this, if not what is the proper way?</p>

<p>i'm not really sure why that formula works(if it does) so some elaboration on that would be nice.</p>

<p>sorry for lack of technical language</p>

<p>thanks in advance</p>
",<probability>
"<p>I have a population C of candidates C1..Cn<br>
An event will occur to Ci with unknown probability Pi (Pi are independent)</p>

<p>The population is divided into disjoint sets S1..Sm
For each sub set Si, P(Si) is known.</p>

<p>(right now, it the probability of an event happening to ANY member of Si, but it can
also be probability of an event happening to all members if it makes analysis easier..)</p>

<p>I am given a set of population subsets R1.. (independent, possibly overlapping subsets of C)</p>

<p>For each Ri, what can i say about P(Ri) ??<br>
Even better, are there any unions of subsets Ri U Rj U Rk for which the computation of P(union) is more accurate ?</p>

<p>Any ideas and pointers are helpful<br>
(I have a Bsc/Msc in CS, Math but i i am really rusty)</p>
",<probability>
"<p>I have a fairly simply question which I am not sure about. A 3 digits number is being chosen by random (100-999). What is the probability of getting a number with two identical digits ? (like 101). Thank you !</p>
",<probability>
"<p>Standard 52 cards deck, calculate the probability of drawing any 4 AND after that any of clubs. </p>

<p>My first intuition is this, there are two possibilities: a) drawing a non clubs 4; or b) drawing a clubs 4, after that you just deduct the card from the deck, so you get:</p>

<p>a) 3/52 * 13/51
b) 1/52 * 12/51</p>

<p>But in the classroom this was resolved as:</p>

<p>a) 4/52 * 13/51
b) 4/52 * 12/51</p>

<p>I don't understand the rationale behind this, is it right/wrong? </p>
",<probability>
"<p>Let $X$ be a random variable. let 
\begin{align*}
Y=\alpha_1+\alpha_2 X
\end{align*}
where $\alpha_1$ and $\alpha_2$ are parameters.</p>

<p>Now let 
\begin{align*}
Z=\hat{\alpha}_1+\hat{\alpha}_2 X
\end{align*}
where $\hat{\alpha}_1$ and $\hat{\alpha}_2$ are estimates of parameters.</p>

<p>As $n \rightarrow \infty$ , $\hat{\alpha}_1 \overset{p}{\to} \alpha_1$ and $\hat{\alpha}_2 \overset{p}{\to} \alpha_2$. </p>

<p>Now can I say $Y\overset{p}{\to}Z$ ($Y$is becoming $Z$ asymptotically, someone critize me by saying that it is strange to say a variable converge in probability to a variable) or $Y\overset{d}{\to} Z$ (in distribution)?</p>
",<probability>
"<p>A random number between $1$ and $100$ is generated every second.
What would be the average waiting time for a specific number ($1$ for instance) to be generated?
Probability distribution is uniform.
Each number is generated independently of the others.</p>
",<probability>
"<p>If $E(X^2)=1$ and $E(|X|)\ge a &gt;0$, then $P(|X|\ge\lambda a)\ge (1-\lambda)^2a^2$ for $0\le \lambda \le 1$.</p>

<p>I can see from the well known inequality $E(|X|) \le E(|X|^2)^{1/2}$ that it must be the case that $a\le 1$. But what to do next I'm not sure.</p>
",<probability>
"<p>If we have 3 players, playing extreme RPS game like image below:</p>

<p><img src=""http://i.stack.imgur.com/OZtXR.jpg"" alt=""enter image description here""></p>

<p>How much tie probabilities?</p>

<p>Thanks</p>
",<probability>
"<p><strong>This is my problem</strong></p>

<p>My problem is modeled by a basic Bayesian Network with only two layers. So I have parent and child nodes but the children has no children. Essentially a bipartite graph. The children depend on one or more of the parents and these edges/relations have a probability. The model is also extended by completing the bipartite graph with low probability edges to account for noisy data. So in the finished model each child $(C_x)$ has a dependency on each parent $(P_x)$.</p>

<p>What I want to be able to do is to infer the most probable solution by maximizing,</p>

<p>$$ max_{P_1,P_2,\dots,P_n}(P(P_1,P_2,\dots,P_n|C_1,C_2,\dots,C_m)) $$ 
where $ C_i \in \{0,1\} $, $ P_j \in \{0,1\} $. For a given observation on the state of the children.</p>

<p>So for a observation $O=\{C_1=0, C_2=1, C_3=1\}$</p>

<p>I want to calculate
$$P(P_1=1,P_2=0,P_3=0|C_1=0, C_2=1, C_3=1)$$
$$P(P_1=0,P_2=1,P_3=0|C_1=0, C_2=1, C_3=1)$$
$$P(P_1=1,P_2=1,P_3=0|C_1=0, C_2=1, C_3=1)$$
and so on.</p>

<p><strong>Here is how I try to solve it</strong></p>

<p>I want to be thorough so I will explain how I try to solve this. I'm not sure that I'm doing it right. Please point out to med if I'm doing this wrong.</p>

<p>What I do first is I complete the conditional distribution tables for the child nodes. From the model I have the CPT as for a child node $C_x$ something like this, the probabilites are chosen to make the example easy.</p>

<p>\begin{array}{ l l l|l l }
P_1 &amp; P_2 &amp; P_3 &amp; P &amp; \lnot P \\
  \hline
	0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
	0 &amp; 0 &amp; 1 &amp; 0.1 &amp; 0.9 \\
	0 &amp; 1 &amp; 0 &amp; 0.4 &amp; 0.6 \\
	1 &amp; 0 &amp; 0 &amp; 0.2 &amp; 0.8 \\
\end{array}</p>

<p>And I complete this table by calculating</p>

<p>\begin{array}{ l l l|l l }
P_1 &amp; P_2 &amp; P_3 &amp; P &amp; \lnot P \\
  \hline
	0 &amp; 1 &amp; 1 &amp; (1- \lnot P) &amp; 0.9 \times 0.6 \\
	1 &amp; 0 &amp; 1 &amp; (1- \lnot P) &amp; 0.9 \times 0.8 \\
	1 &amp; 1 &amp; 0 &amp; (1- \lnot P) &amp; 0.6 \times 0.8 \\
	1 &amp; 1 &amp; 1 &amp; (1- \lnot P) &amp; 0.9 \times 0.6 \times 0.8 \\
\end{array}</p>

<p>And then I calculate the joint conditional probability by doing something like</p>

<p>$$P(P_1=1,P_2=0,P_3=0|C_1=0, C_2=1, C_3=1) = $$
$$P(P_1=1,P_2=0,P_3=0|C_1=0) \times$$ 
$$P(P_1=1,P_2=0,P_3=0|C_2=1) \times$$
$$P(P_1=1,P_2=0,P_3=0|C_3=1)$$</p>

<p>Basically I'm not convinced that the last step is correct. <strong>Any help or comments is greately appreciated!</strong></p>

<p>Yes, this is school related but it is not regular homework. It is a part of a thesis project I'm doing at a company.</p>

<p><strong>Graph update on request</strong></p>

<p><img src=""http://i.stack.imgur.com/eX6iS.png"" alt=""Graph""></p>

<p>Here is a graph example of my model. The regular edges are direct dependencies and the dotted edges are noisy or guess edges added to allow for noisy data. Guess edges has a low probability of $p = 0.0001$ and the regular edges all have the probability $(1-p)$. In my problem I do not care for the probability of individual events like $P(L_1)$ or $P(C_2)$, so they are assumed to be $1$. I make an observation on the state of the variables $C_1...C_n$ and given the graph model above I want to infer to most plausible cause. The possible causes  are $P_1...P_n$ or a combination of them that is most likely. Like I stated earlier on the example observation above.</p>

<p>Here is an example of the basic truth tables for this graph.
\begin{array}{ l|l l }
C_1 &amp; T &amp; F \\
  \hline
	P_1 &amp; 0.9999 &amp; 0.0001 \\
	P_2 &amp; 0.9999 &amp; 0.0001 \\
	P_3 &amp; 0.9999 &amp; 0.0001 \\
\end{array}</p>

<p>\begin{array}{ l|l l }
C_2 &amp; T &amp; F \\
  \hline
	P_1 &amp; 0.0001 &amp; 0.9999 \\
	P_2 &amp; 0.9999 &amp; 0.0001 \\
	P_3 &amp; 0.9999 &amp; 0.0001 \\
\end{array}</p>

<p>\begin{array}{ l|l l }
C_3 &amp; T &amp; F \\
  \hline
	P_1 &amp; 0.0001 &amp; 0.9999 \\
	P_2 &amp; 0.0001 &amp; 0.9999 \\
	P_3 &amp; 0.9999 &amp; 0.0001 \\
\end{array}</p>

<p>Does that make it any clearer?</p>
",<probability>
"<p>We have a fair dice that can produce <code>n</code> different numbers. How many times should we roll the dice to see every number at least once with probability <code>p</code>?</p>

<p>Not a homework, just interesting. Tried to solve myself but with no luck. </p>

<p>I think it could be sort of coupon collector problem, but I can't get exact formula.</p>
",<probability>
"<p>If one word can be at most 63 characters long. It can be combination of :</p>

<ul>
<li>letters from a to z</li>
<li>numbers from 0 to 9</li>
<li>hyphen - but only if not in the first or the last character of the word</li>
</ul>

<p>I'm trying to calculate possible number of combinations for a given domain name. I took stats facts here :</p>

<p><a href=""http://webmasters.stackexchange.com/a/16997"">http://webmasters.stackexchange.com/a/16997</a></p>

<p>I have a very poor, elementary level of math so I've got this address from a friend to ask this. If someone could write me a formula how to calculate this or give me exact number or any useful information that would be great.</p>
",<probability>
"<p>Can someone please give me a reference  to an (simple, realworld, i.e. not constructed) example of a discrete probability space such that there are three events in it that are pairwise independent but all three together are not independent (although I wouldn't mind, if someone would give me the example as an answer).</p>
",<probability>
"<p>Among $t = 60$ lottery tickets there are $w = 20$ prizes. We buy $b = 6$.
What is the probability that $g$ tickets will win, with $g=2$? Generalize this
to arbitrary numbers $t,w, b, g$.</p>
",<probability>
"<p>I want to create a model that tries to predict a user's behavior based on the random walks of similar users. The problem is similar to Netflix's recommendation challenge. One of the popular solutions was to use singular value decomposition to find movies that user would most likely like to see. </p>

<p>My question is more like this: what genre of a movie would a user like to see on a particular day? You move to each state with a probability, and one state could be ""watching no movie"". Does it make sense or even is it even feasible to approach the problem as a Markov process? How has this been done before?</p>

<p>I took only one class on Markov chains in college. 
Thanks.</p>
",<probability>
"<p>Given a poll, where $N$ people were polled, and $n_i$ people voted for party $i$, so that: $$\sum{n_i} = N$$
If there are M parliament seats in total we can expect: 
$$m_i = M\cdot\lim_{N\rightarrow\infty} (n_i/N)$$
To be the number of parliament seats party $i$ will have. </p>

<p>My question regards the error involved in this prediction: </p>

<p><strong>What is it's error distribution and what is it's variance?</strong> </p>

<p>If the number of seats were not finite, I'd say that the distribution would be Poisson and each poll value should be $n_i \pm \sqrt{n_i}$, but since the sum is given, It would seem the errors must be correlated in some way.</p>

<p>Any ideas?</p>
",<probability>
"<p>Five people check identical suitcases before boarding an airplane. At the baggage claim, each person takes one of the five suitcases at random. What is the probability that every person ends up with the wrong suitcase?</p>

<p>I think I need to use the principle of inclusion exclusion to solve this but I'm not quite sure how.</p>
",<probability>
"<p>I am examining Bayes' Theorem, and wondering about the alternative interpretations of ~A, as being:</p>

<ul>
<li>not A, &not; A</li>
<li>everything but A, &forall;-A</li>
</ul>

<p>And how this will affect the use of probabilities.</p>

<p>So, this is not so much a question about Bayes' Theorem, and more to do with how this split interpretation effects the numbers.</p>
",<probability>
"<p>A company that sells annuities must base the annual payout on the distribution of the length of life of the participants in the plan. Suppose the distribution of male participants' lifetimes is normally distributed with a mean of 68 years and a standard deviation of 5 years. Let the random variable X represent the lifetime of a male participant. What is the probability that a male participant would die between 64 and 65 years old?</p>
",<probability>
"<p>X, Y are both random variables of uniform distribution, $0\le\ X \le\ 3$, $0\le\ Y \le\ 4$, then what is the probability of $X \lt Y$? </p>
",<probability>
"<p>I'm working on a problem from Chow and Teicher's book on Probability Theory, page 123, #6(ii):</p>

<p>If $X_n, n\geq 1$ are i.i.d., $\mathcal{L_1}$ r.v.s, then $\sum (X_n / n)$ converges a.c. if $E|X_1|log^+ |X_1| &lt;\infty$ and $EX_1 = 0$.</p>

<p>The most relevant theorem that I've been thinking of using is one that says if $X_n$ are i.i.d. and $\mathcal{L_p}$ for $0&lt;p&lt;2$, then $\sum \left(X_n / n^{1/p} - E\left(\dfrac{X_nI_{\{|X_n|\leq n^{1/p}\}}}{n^{1/p}}\right)\right)$ converges a.c.; since, in this case, $p =1$, it would suffice to show that the series $\sum E\left(\dfrac{X_nI_{\{|X_n|\leq n\}}}{n}\right)$ converges a.c. to complete the exercise. However, I'm having trouble incorporating the $E|X_1|log^+ |X_1| &lt;\infty$ condition. I see how $EX_1 = 0$ implies that the summands of the series satisfy the following: $E\left(\dfrac{X_nI_{\{|X_n|\leq n\}}}{n}\right) = -E\left(\dfrac{X_nI_{\{|X_n|&gt; n\}}}{n}\right)$, but unfortunately I've been thus far unable get anything resembling a logarithmic series by manipulating summands here.</p>

<p>Perhaps I'm missing something obvious? Any help is greatly appreciated. </p>
",<probability>
"<p>I've been trying to understand the following:</p>

<blockquote>
  <p>The distribution of two continuous random variables is given by
  $$f_{X,Y}(x,y)=\frac{3}{7}x\space\space 1\le x\le 2,0\le y\le x$$and $0$ otherwise. What is the
  marginal distribution of $Y$ when $0\le y\le 1$?</p>
</blockquote>

<p>My question is, how do I choose the limits for the integral
$$\int_{-\infty}^{\infty}f_{X,Y}(x,y)dx$$</p>

<p>In the school solution they  did
$$f_Y(y)=\int_{1}^{2}\frac{3}{7}xdx=\frac{9}{14}$$</p>

<p>Why are those the limits? What if I wanted to calculate the marginal distribution of $Y$ when $1\le y\le$ 2? Any thumbs rules?</p>

<p>Thanks!</p>
",<probability>
"<p>So there are 480 squares and 99 mines on the advanced level of minesweeper. It got me thinking, what would be the chances of winning the game randomly clicking each square? So not being influenced by numbers and without it doing any multi openings, so you would need to click 381 boxes (I think) :)</p>
",<probability>
"<p>A bag contains 5 red and 7 black balls. Second bag contains 4 blue and 3 green balls. 1 ball is drawn from each bag. Find the probabilty for
1 red and 1 blue ball.</p>

<p>The answer is 5/21
But don't know the way to get it. 
Plzz help.</p>
",<probability>
"<p>Your (honest) opponent choose a random number from 1 to 13 inclusive. You have to guess the number, and you win if the guess is correct. If not, your opponent either reduces the number chosen by one or increases it by 1, and you guess again.</p>

<p>The question is, what is the minimum # of attempts necessary to guarantee a win for you.</p>

<p>I am not able to get a handle on the problem.</p>

<p>Also, (a new variant just thought of), how many guesses should be allowed for a fair or ""nearest to fair"" game ?</p>
",<probability>
"<p>Suppose I toss a fair coin 10 times. What is the probability that there is a run of at least 4 consecutive heads?</p>

<p>An approach would be to use the Principle of Inclusion-Exclusion on the events $E_i$ where 4 heads occur in positions $i,i+1,i+2,i+3$, where $1\leq i\leq 7$. But this results in a big calculation. </p>

<p>On the other hand, I found the generalization <a href=""http://math.stackexchange.com/questions/59738/probability-for-the-length-of-the-longest-run-in-n-bernoulli-trials"">here</a>, but I think for this problem (with small values $10$ and $4$) maybe there is an easier way to compute the desired value. What would be an easier way?</p>
",<probability>
"<p>I came across the following probability problem:</p>

<p>Start with $1$ black ball and $1$ white ball in a box. At each step, we will put in a new ball. If there are $a$ black balls and $b$ white balls, we put in a black ball with probability $\dfrac{a}{a+b}$ and a white ball with probability $\dfrac{b}{a+b}$. We do this until there are $n$ balls ($n\geq 2$). Prove that the probabilities that there are $1,2,\ldots,n-1$ black balls are all equal.</p>

<p>This problem is trivial by induction on $n$, the total number of balls. I wonder, however, if there is an intuitive way to interpret the result, without the use of induction?</p>
",<probability>
"<p>I would like to ask <strong>how can we derive PGF of any multivariate distribution</strong>?
and can anyone give <strong>an example</strong> of deriving the PGF of a multivariate distribution?
That will be great.
Thanks advance.</p>
",<probability>
"<p>I have stumbled upon many questions, and one of the weaknesses is the ability to test if the concept is distinguishable or not. For example this: </p>

<blockquote>
  <p>Nine delegates, three each from three different countries, randomly select chairs at a round table that seats nine people. Let the probability that each delegate sits next to at least one delegate from another country be $\frac{m}{n}$, where $m$ and $n$ are relatively prime positive integers. Find $m+n$.</p>
</blockquote>

<p>Take the race: $AAA$ Then are the people distinguishable or not? Is it: $A_1, A_2, A_3$ or not? I ask this because of cyclic shifts. I asked this question <a href=""http://math.stackexchange.com/questions/1399651/the-probability-that-each-delegate-sits-next-to-at-least-one-delegate-from-anoth"">Here.</a>. But drhab said they are not, but he uses the concept of $AaA$, or $AAa$ or $aAA$? Is there something with the chair being distinguishable or what is the whole issue exactly?</p>
",<probability>
"<p>Sorry for the topic being weird, but as a person not too good at math I would like to know whether the following argument is mathematically valid:</p>

<blockquote>
  <p>If $50$% of pregnancies are aborted, is it valid to say that a fetus has $50$% chance to be aborted? Considering that criteria for abortion is random. </p>
  
  <p>Is the following sentence that I heard, mathematically valid?
  ""$50$% of pregnancies are aborted, therefore if you are a fetus you have $50$% chance of not coming out alive""</p>
</blockquote>

<p>Thanks in advance.</p>
",<probability>
"<p>Let $N_t$ be a Poisson process and $S_{N_t}=X_1+...+X_{N_t}$. </p>

<p>Let $A_t=t-S_{N_t}$ and $B_t=S_{N_t}-t$</p>

<p>1) Show $P(B_t \geq x \ \text{and}\ A_t \geq y)=\frac{1}{E(X_1)} \int_{x+y}^{\infty} P(X_1 \geq u)du\:\:$ with $x,y,t \geq 0$</p>

<p>2) Deduce $A_t$ is independent of $B_t$</p>

<p>For the question 2) I don't know but for the question 1) I tried:</p>

<p>$P(B_t \geq x \ \text{and}\ A_t \geq y)=P(X_{N_t}-A_t \geq x | A_t \geq y)P(A_t \geq y)=P(X_{N_t} \geq x+y)P(A_t \geq y)=P(X_1 \geq x+y)P(A_t \geq y)$</p>

<p>However after I don't know:
$P(X_1 \geq x+y)=\int_{x+y}^{\infty}F'(u)du$ and $P(A_t \leq y)=P(S_{N_t-1} \leq t-y)$</p>

<p>Thank you</p>
",<probability>
"<p>Let's say I have $3$ events with probabilities $P(A) = 0.5, P(B) = 0.5$ and $P(C)= 0.5,$ and I need to find if </p>

<p>$$P(A \cap B \mid C) = P(A \mid C)P(B \mid C)$$</p>

<p>I am tying to prove this by expanding the formula above to:</p>

<p>$$P(A \cap B \mid C) = \frac{P(A \cap C)}{P(C)}\frac{P(B \cap C)}{P(C)}$$</p>

<p>Is this a correct assumption?</p>
",<probability>
"<p>Is the following statement true or not?</p>

<blockquote>
  <p>Let $X$, $Y$, $Z$ be $3$ events in the same sample space such that $p(X)$, $P(Y)$, $p(Z) &gt; 0$ and every pair of these events is independent. Then $p(X \cap Y \cap Z) &gt; 0$.</p>
</blockquote>
",<probability>
"<p>Abe and Bernard are dealt five cards each from the same $52$ card deck. Let $A$ be the event that Abe gets a flush (five cards of the same suit) and $B$ be the event that Bernard’s five cards are of pairwise different kinds (i.e. pairwise independent). Are $A$ and $B$ independent?</p>

<p><strong>Thoughts.</strong> Is $P(A) = P(A|B)$? In other words, is the probability of $A$ the same as the probability of $A$ given that $B$ occurred?</p>
",<probability>
"<p><strong>Three people have been exposed to a certain illness. Once exposed, a person has a 50-50 chance of actually becoming ill.</strong></p>

<p>a) What is the probability that exactly one of the people becomes ill?</p>

<p>I am a bit unsure, how to solve this question.</p>
",<probability>
"<p>I am looking at the proof of convergence in probability implying convergence in distribution. The proof begins by stating that if $X_n \leq x$ then either $ X \leq x + \epsilon $ or $ |X_n - X| &gt; \epsilon $. I can't quite see this implication;</p>

<p>$ X_n \leq x \Rightarrow X \leq x + \epsilon$ or $ X &gt; x + \epsilon$</p>

<p>$\Rightarrow X \leq x + \epsilon$ or $ X - X_n \geq X - x &gt; \epsilon $</p>

<p>but how do I obtain $X_n - X &gt; \epsilon$ ? </p>
",<probability>
"<p>Do you have an idea how I could model the following process somehow as a sum of independent indicator random variables?</p>

<p>I have given a grid of size $n \times n$ for $n \rightarrow \infty$. </p>

<p>Now I color each point of this grid uniformly at random with one out of $k$ colors, where $k=\mathcal{O}(1)$. </p>

<p>I am interested in the probability that none of the $3 \times 3$-subgrids in this grid are monochromatic (monochromatic=all 9 points have the same color) and should show this probability is at most $e^{- \Omega(n^2)}$.  </p>

<p>My task is explicitly to model this such that I can use Chernoff bounds. 
Chernoff bounds, in the context we had it, can be applied if we have a sum $X:=\sum_{i=1}^m X_i$ of independent indicator random variables $X_i \sim Be(p_i)$.</p>

<p>My problem is that clearly the different $3 \times 3$ grids are <em>not</em> independent, so the easy approach to state $X=\sum_{s \in S} X_s$ where $S$ is the set of all $3\times 3$ subgrids and $X_s$ is $1$ if $s$ is a monochromatic grid, and calculate $P[X=0]$ does not work. </p>

<p>Would be very happy about any hint. 
Thank you very much!</p>
",<probability>
"<blockquote>
  <p>Let $k\leqslant n$ denote two positive integers, $A$ an $n \times k$ matrix with $A'A = I_k$, and $X$ and $Y$ two independent random variables on $\mathbb R^n$, each rotationally invariant (that is, their distributions do not change under the orthogonal transformations). 
  Write $X' = (U',W')$ and $Y' = (V',Z')$ with $U$ and $V$ on $\mathbb R^k$ and $W$ and $Z$ on $\mathbb R^{n-k}$.</p>
  
  <p>Prove that $(A'X, A'Y)$ has the same distribution as $(U,V)$. </p>
</blockquote>

<p>I know that by the Cramer-Wold theorem, for rotationally invariant random variables if we have a linear functional $t$ then $t'X$ has the same distribution as $|t|U$. Also $U$ and $W$ are rotationally invariant each in its own right in this case. I think these two assumptions should be used somewhere in the proof I just don't know how to start, because to me this is basically saying that the joint distribution of $(X, Y)$ is completely determined by the distribution of their first coordinate which is similar to Cramer-Wold except that the factor $|t|$ here is one so somehow ""length"" of $A'$ should be $1$ or it should appear as $A'A$ which is the identity. 
Any help would be appreciated. </p>
",<probability>
"<p>A factory has produced n robots, each of which is faulty with probability $\phi$. To each robot a test is applied which detects the faulty (if present) with probability $\delta$. Let X be the number of faulty robots, and Y the number detected as faulty.</p>

<p>Assuming the usual indenpendence, determine the value of $\mathbb E(X|Y)$.</p>

<p>Please explain me the result in detail or give me a good hint pls, since I am very new to this concept (of conditional expectation).</p>

<p>Thanks!</p>
",<probability>
"<p>I'm trying to solve a question from Pathria's statistical mechanics textbook (10.21) but it is more math oriented.</p>

<p>Show that, for a general Gaussian distribution of variables $u_j$ , the average of the exponential of a linear combination of the variables obeys the relation:</p>

<p>$\left\langle \exp\left(\sum_j a_j u_j\right) \right\rangle=\exp\left(\dfrac{1}{2}\left\langle\left(\sum_j a_j u_j\right)^2 \right\rangle \right)$</p>

<p>I'm not entirely sure how to write this; I was doing Taylor series expansions of exponentials and I could solve it easily if it were a standard normal (mean=0).  I believe the linear combination of normal variables is normal, so this seems to have something to do with the log-normal distribution?  </p>

<p>I don't need a full solution; just a hint to go forward.</p>
",<probability>
"<p>A decision making problem will be resolved by tossing $2n + 1$ coins. If Head comes in majority one option will be taken, for majority of tails it’ll be the other one. Initially all the coins were fair. A witty mathematician replaced $n$ pairs of fair coins with $n$ pairs of biased coins, but in each pair the probability of obtaining head in one is the same the probability of obtaining tail in the other. Will this cause any favor for any of the options available? Justify with logic</p>
",<probability>
"<p>Tv company receives 90 job application. Information about applicants:</p>

<pre><code>--------------------------------------------
     | have bachelor | dont have bachelor |
     |     (B)       |     (B) negation   |
---------------------------------------------
exp  |     18        |          9         |
(D)  |               |                    |
---------------------------------------------
no exp |      36     |         27         |
(D)     |            |                    |
negation|------------|--------------------|
</code></pre>

<p>Calculate probability for: <code>P(D/B) and P(B neg/ D neg )</code></p>

<p>answers:  <code>P(D/B) =&gt; 1/3</code>,  <code>P(B neg/ D neg ) =&gt; 3/7</code></p>

<p>I tried to do this-></p>

<p>D/B = D - DnB = 18+9 - 18 = 9</p>

<p>P(D/B) = 9/90 = 1/10 (wrong)</p>

<p>and</p>

<p>D/B = B - BnD = 54 - 18 = 36</p>

<p>P(D/B) = 36/90 = 4/10 (wrong)</p>

<p>I have no idea where I am wrong. How to figure out the answer?</p>
",<probability>
"<p>A fair die is rolled nine times. What is the probability that 1 appears three times, 2 and 3 each appear twice, 4 and 5 once and 6 not at all?</p>

<hr>

<p>My approach is fairly simple. The dice is  fair, so we have a total of $6^9$ possible strings. Consider the set $\{1,1,1,2,2,3,3,4,5\}$. From this set is a total possible number of combinations of</p>

<p>$$\frac{9!}{3!2!2!}=30240$$</p>

<p>Thus, the probability of the above occuring is $30240/6^9$</p>

<p>My question is whether or not I have properly accounted for the probability of $4$ and $5$, and whether or not I should account for their probabilty of being rolled by considering the probability of <strong>never</strong> rolling a $6$. </p>

<p>Could someone explain why I should or should not have these concerns?</p>
",<probability>
"<p>I think I have some problem understanding markov chains, because we defined them as abstract objects but our professor does proofs with them as if they where just elementary conditional probabilities.</p>

<p>This is our <strong>definition</strong> of a <strong>markov chain</strong>: Given prob. space $(\Omega, \mathcal{A}, \mathbb{P})$, standard borel space $(S, \mathcal{S})$ and a sequence of random variables $X_n: \Omega \to \mathcal{S}, n \in \mathbb{N}$. $(X_n)_{n\in \mathbb{N}}$ is called markov chain if 
$$\forall B \in \mathcal{S}: \mathbb{E}[\mathbb{1}_B(X_n)|\sigma(X_0, ..., X_{n-1})] = \mathbb{E}[\mathbb{1}_B(X_n) |\sigma(X_{n-1})]$$</p>

<hr>

<p>So far, so good. But now we've got the following <strong>preposition</strong>: </p>

<p>Given $(\xi_i)_{i\in \mathbb{N}}$ iid rv on $\mathbb{R}^d$ and random variable $X_0$ independent of $(\xi_i)_{i \in \mathbb{N}}$ (also on $\mathbb{R}^d$) we define $X_n := X_0 + \sum_{i=1}^n \xi_i$. Then $(X_n)_{n \in \mathbb{N}_0}$ is a markov chain.</p>

<p><strong>Proof</strong>: $$P(X_n \in B | X_0 = x_0, ..., X_{n-1} = x_{n-1}) = $$</p>

<p>$$= P(\xi_n + x_{n-1} \in B | X_0 = x_0, X_0 + \xi_1 = x_1, ..., X_0 + \sum_{i=1}^{n-1}\xi_i = x_{n-1}) = $$</p>

<p>$$=_{independce} P(\xi_n + x_{n-1} \in B) = ... = P(X_n \in B | X_{n-1} = x_{n-1})$$
Why do we start treating these conditional expectations just like elementary conditional probability for events?</p>

<p>Sorry for the awful formatting of the proof </p>
",<probability>
"<p>Let $[n+1]$ be the set defined by $[n+1]=\{1,2,\ldots,n+1\}$.</p>

<p>Call a subset of $[n+1]$ with $r+1$ distinct elements an $(r+1)$-subset. How many $(r+1)$-subsets of $[n+1]$ have $(k+1)$ as their largest element?</p>

<hr>

<p>This seem fairly facile, so I am concerned that I am doing it wrong. By definition, $[n+1]$ is a bounded set. If $(r+1)$ is a subset of $[n+1]$, then $(r+1)$ is bounded as well. Denote that bound as $k+1$ s.t. $k \geq r_0 \forall r_0 \in (r+1)$.</p>

<p>Is anything wrong here?</p>

<p>Additionally, I am supposed to deduce that </p>

<p>$$\sum^n_{k=r}{k\choose r}={n+1\choose r+1}.$$</p>

<p>I have no idea where to start for this one. </p>

<p><strong>EDIT:</strong> Using the hints given by Hagen von Eitzen, I claim that the total number of subsets of $[n+1]$ that have $(k+1)$ as their largest element is $k$. Note that an $(r+1)$-element subset of $[n+1]$ is an $(r+1)$-element subset of $[n+1]$ that has $k+1$ as maximal elelment for exactly one k∈{r,…,n}.</p>

<p>I am fairly sure that I can prove this by induction. Can someone suggest anything for the second half and whether I did the first half correctly?</p>
",<probability>
"<p>I have been playing a game and came up with this question:</p>

<p>There are $n$ different object, and each time you randomly choose one of them. </p>

<p>One success is defined as one of the objects being selected $m$ times. What is the expected time to get one success (accumulating $m$ of any one object)?</p>

<p>In addition, what is the expected rate of success? </p>

<p>Please help...</p>
",<probability>
"<p>I came to the following problem: 
Let $A_1, A_2, ...$ be events in a probability space $(\Omega, F, \mathbb{P})$ and $\mathbb{P}[A_j]=1$ for all $j&gt;1$. I need to show that the probability of the intersection of all those events $A_j$, where j goes from 1 to infinity, is also $1$. </p>

<p>From what I understand, the events we have are not dependent so we can use the formula for a joint probability, so it will be the product of the probabilities of the events. However, I am not sure whether that formula holds in the general case. </p>

<p>Any suggestions?</p>
",<probability>
"<p>I want to calculate $P(X=Y)$, where $X,Y$ are independent and geometrically distributed, which means: $P(X=k) = P(Y=k) = p(1-p)^k$, $k \in \mathbb N_0$ and $p \in (0,1)$.</p>

<p>Can anybody tell me how to do this? I'm afraid I don't have an idea..</p>

<p>Thanks in advance!</p>
",<probability>
"<p>If we have two coins of radius of $R_1=8$ and $R_2=12$. Assume that 99% of people will be able to tell the size within $\pm5\%$ by touch it only, and assume it is a normal distribution.</p>

<p>Question A: How many people will mistakenly think a given coin is the other one.</p>

<p>Question B: If insert a third coin in between in a average radius, how many people make the mistakes for each coin?</p>

<p>Question C: If insert n coins in between with same step of change, what will be the worst case? (It must be a function of n, right?)</p>

<p>If the question does not make sense, please let me know.</p>
",<probability>
"<p>Suppose we have an urn with $N$ white balls and $M$ black balls. Suppose we draw $n$ balls and each time a ball is drawn, then we put it back. Let $X =$ number of white ball we get. Let $U = \{1,2,...,N+M\}$. For our probability space, we take $\Omega = U^n $. We want to find </p>

<p>$$ P(X = x) \; \; \; \text{where} \; 0 \leq x \leq n  $$</p>

<p>I am stuck trying to solve this problem. I know the cardinality of $\Omega$ is $(N+M)^n$.</p>
",<probability>
"<p>Let $Y_1,\,Y_2\ldots$ be a sequence of real random variables and $Y(\omega)=\liminf_{n\to\infty}Y_n(\omega)\in R$. I define using ricursion the sequenze $\tau_k(\omega)=\inf \{n&gt;\tau_{k-1} : |Y_n(\omega)-Y(\omega)|\leq 1/k\}$ and I want to prove that $\tau_k$ is measurable. Can anyone give me any idea? Thank you in advance.</p>
",<probability>
"<p>Let $\left\{ X_t \right\} $ be a stochastic process $MA(2)$ such that $X_t = Z_t + 0.8Z_{t-2}$. Where $\left\{ Z_t \right\} $ is White Noise $WN(0,1)$.</p>

<p>Compute variance of $$\frac{X_1+X_2+X_3+X_4}{4}$$</p>

<p>I don't have any idea how can I compute it. Could you give me a tip?</p>
",<probability>
"<p>Consider two real random variables $X,Y$ and the conditional expectation $\mathbb E[Y|X]$, also a random variable. What is the conditional expectation $\mathbb E[\mathbb E[Y|X]|Y]$? Is it $=Y$? Is it $=\mathbb E[Y|X]$? Is it even well-defined?</p>
",<probability>
"<p>Consider two Normally distributed random variables, $X_1 \sim N(0,T_1)$ and $X_2 \sim N(0,T_2)$, such that $X_2-X_1 \sim N(0,T_2-T_1)$. How to calculate $E[X_2^2\mid X_1]$?</p>
",<probability>
"<p>In the group of $100$ microprocessors $10$ microprocessors are faulty. $5$ microprocessors are selected randomly. Find the probability that</p>

<p>a) All selected microprocessors are correctly</p>

<p>b) Exactly one microprocessor is faulty</p>

<p>c) At least one microprocessor is faulty</p>

<p>d) Maximum $3$ microprocessors are correctly </p>

<p>I tried</p>

<p>a) $\frac{\binom{90}{5}} {\binom{100}{5}}$ =0.5837</p>

<p>b) $\frac{\binom{10}{1}*\binom{90}{4}} {\binom{100}{5}}$ = 0.3393</p>

<p>c) ${\binom{90}{5}}+{\binom{90}{3}}*{\binom{10}{1}}+{\binom{90}{3}}*{\binom{10}{2}}+{\binom{90}{2}}*{\binom{10}{3}}+{\binom{90}{1}}*{\binom{10}{4}} {\binom{100}{5}}$</p>

<p>and all that divided with ${\binom{100}{5}}$</p>

<p>d) ${\binom{90}{1}})*{\binom{10}{4}}+ {\binom{90}{2}}*{\binom{10}{3}}+{\binom{90}{3}}*{\binom{100}{2}}$</p>

<p>and all that divided with ${\binom{100}{5}}$</p>

<p>Is this good way or I made mistake in reasoning? </p>
",<probability>
"<p><strong>Given:</strong> $X = Y^2 + Z^2$ (hence $E[X] = E[Y^2] + E[Z^2]$)</p>

<p>$p(X = 1) = .52$, $p(X = 4) = .24$, $p(X = 16) = .24$<br>
$p(Y = -1) = .5$, $p(Y = 3) = .5$</p>

<p><strong>Question:</strong> Despite not being handed any information about $Z$, prove that this could never hold in classical probability theory.</p>
",<probability>
"<p>We've got a random sample of iid $X_1,\dots,X_n$. We're testing the mean of $X \sim \mathcal{N}(\mu,\sigma^2)$, where $\sigma^2$ is known. The size of the test $\alpha=0.05$.</p>

<p>$H_0: \mu=0$</p>

<p>$H_1: \mu=v$</p>

<p>By the Neyman-Pearson lemma the Most Powerful test is $\phi(X) = \mathbf{1}_A$ where the set $A =\{ x: \prod_{i=1}^n \frac{f(\mu_1,\sigma^2)}{f(\mu_0,\sigma^2)} &gt; k \} $</p>

<p>simplyfying we can reduce the test to:
\begin{equation}
\frac{1}{n}\sum_{i=1}^n X_i &gt; \frac{2\sigma^2(\log k+\mu_1^2 n)}{n \mu_1}
\end{equation}</p>

<p>where $\mu_1 = v$.
Calculating the critical value $k$ we evaluate:
$$
\begin{align}
\alpha=\mathbb{E}[\phi(X) |H_0] &amp;= \frac{1}{\sqrt{2 \pi \sigma^2}} \int_{-\infty}^{\infty}\phi(x) e^{-\frac{x^2}{2\sigma^2}} dx\\
&amp;=\frac{1}{\sqrt{2 \pi \sigma^2}} \int_{-\infty}^{\infty}\mathbf{1}_A e^{-\frac{x^2}{2\sigma^2}} dx\\
&amp;= \frac{1}{\sqrt{2 \pi \sigma^2}} \int_{k}^{\infty}e^{-\frac{(x-\mu_1)^2}{2\sigma^2}} dx\\
&amp;= \frac{1}{\sqrt{2 \pi }} \int_{\frac{k-\mu_1}{\sigma}}^{\frac{\infty-\mu_1}{\sigma}}e^{-\frac{x^2}{2}} dx\\
&amp;=1-\Phi\Bigg(\frac{k-\mu_1}{\sigma} \Bigg)
\end{align}
$$</p>

<p>therefore we can derive $k=\mu_1 + \sigma \Phi^{-1}(1-\alpha)$</p>

<p>Is my approach correct, or did I mess up the calculation of the critical value?</p>
",<probability>
"<p>Given an infinitely differentiable function $ g: \mathbb{R} \rightarrow \mathbb{R}$, can we always find a distribution function $f_X$ of some random variable $X$ so that 
$g(t) = \int_{-\infty}^\infty e^{tx}f_X(x) dx$?</p>

<p>If my question is too vague or ill-posed, can anyone recommend any literature on the characterization of moment-generating functions?</p>
",<probability>
"<p>I'm attemtping to solve this problem:</p>

<blockquote>
  <p>Suppose a shot is fired at a circular target.  The vertical and the
  horizontal coordinates  of the point of impact (taking the center of
  the target as origin) are independent random variables, each
  distributed according to the standardized normal distribution. </p>
  
  <p>a. Write down the PDFs of the two coordinates.<br>
  b. Write down the joint
  PDF of the coordinates of the point of impact.<br>
  c. What is the PDF of
  the radius of the point of impact $r = \sqrt{x^2 + y^2}$ ?  Show all  steps you used to
  derive this expression.<br>
  <em>Hint: you can use the CDF method for finding the PDF of a transformed RV.</em><br>
  d. What is the probability that the
  point of impact will land in the ring of radii 2-3?</p>
</blockquote>

<p>MY attempt at a solution:</p>

<p>a)
P.D.F. of x is: $$\frac{1}{2\sqrt{\pi}}e^{-\frac{x^2}{2}}$$
P.D.F. of y is: $$\frac{1}{2\sqrt{\pi}}e^{-\frac{y^2}{2}}$$</p>

<p>b)
joint PDF is:
PDF(x) * PDF(y) = $$\frac{1}{2\sqrt{\pi}}e^{-\frac{y^2}{2}} * \frac{1}{2\sqrt{\pi}}e^{-\frac{x^2}{2}} = 2\pi^{-1}e^{\frac{-(x^2 + y^2)}{2}} $$</p>

<p>c) this is where I'm getting hung up on...</p>

<p>So the C.D.F. of a std. normal R.V. $x$ is:</p>

<p>$$\phi (x) = \frac{1}{\sqrt{2 \pi}}\int e^{\frac{-t^{2}}{2}}dt$$ </p>

<p>correct?</p>

<p>since $r = \sqrt{x^2 + y^2}$  is given, then is the CDF of $r$ just
$$\phi (r) = \frac{1}{\sqrt{2 \pi}}\int e^{\frac{-r^{2}}{2}}dr$$
And then would the PDF of the radius just be the first derivative of this?</p>
",<probability>
"<p>I am trying to solve this:</p>

<blockquote>
  <p>Consider a stick of length 1.  You break the stick in two
  random places, X and Y.<br>
  a. Define the individual
  probability distribution functions of the breaking points X and Y.<br>
  b. Write the joint PDF of the breaking points, if X and Y are
  independent.  Sketch its  support (domain) and indicate the density
  values of this domain.<br>
  c. Assume that Y is such that $Y &gt; X$. What is the joint PDF of $(X,Y)$ if it needs to be  uniform on this domain. Again, sketch its support and indicate the density value.<br>
  d. The two breaking points divide the stick in three segments. 
  What is the probability of the left-most segment is the shortest
  segment, when $Y &gt; X$?  Sketch the area in the $X-Y$  plane that
  corresponds to this event.  (Hint: to be the shortest segment the
  leftmost segment  needs to satisfy two constraints simultaneously.)</p>
</blockquote>

<p>Solutions:</p>

<p>a/b)</p>

<p>$$PDF(X,Y) = 1 | (x,y) \in [0,1]\times [0,1]$$$$0|otherwise$$</p>

<p>c) we know that $X$~U$(0,1)$. The clause that $Y\gt X$ means that $Y$~U$(X, 1)$.  </p>

<p>Now, Y has become dependent on X, correct? Therefore, the joint PDF isn't as simple as multiplying the PDF's together. How do I get the joint PDF in this case? </p>

<p>The answer I was given is that $$PDF(X,Y) = 2|(X,Y)\in [0,1]\times [0,1] \cap (Y &gt; X)$$ but I'm having trouble understanding why this is... </p>

<p>I think I understand the concept that, because $Y&gt;X$, the area in which Y can live is halved, because, when X is chosen (since it is chosen uniformly), Y's value depends on the value of X, and the uniform distribution means that the area Y can occupy is halved. but, why does the P.D.F. = 2 in this case? Wouldn't it still be equal to 1, as in: $$PDF(X,Y) = 1|(X,Y)\in [0,1]\times [0,1] \cap (Y &gt; X)$$ I thought the only change would be in the are for which the PDF was valid (hence the distribution needing to intersect the area where $Y&gt;X$</p>

<p>d) For this one, I came up with 3 constraints: $\frac{1}{2} &lt;Y&lt;\frac{3}{4}$ and $X&lt;\frac{1}{4}$</p>

<p>thus, $X$~U$(0,\frac{1}{4} )$ and $Y$~U$(\frac{1}{2} , \frac{3}{4})$</p>

<p>making $$PDF(X) = \frac{1}{\frac{1}{4}} = 4$$and $$PDF(Y)= \frac{1}{\frac{3}{4} -\frac{1}{2}} = 4$$</p>

<p>so joint $PDF(X,Y) = 16|\frac{1}{2} &lt;Y&lt;\frac{3}{4}$ and $X&lt;\frac{1}{4}$</p>

<p>However, this is incorrect, and I can't rightly figure out why.</p>

<p>Any advice as to where I'm going wrong? Thank you very much!</p>
",<probability>
"<p>I was wondering if someone could critique my argument here. The problem is to find the probability where exactly 2 people in a room full of 23 people share the same birthday.</p>

<p>My argument is that there are 23 choose 2 ways times $\displaystyle \frac{1}{365^{2}}$ for 2 people to share the same birthday. But, we also have to consider the case involving 21 people who don't share the same birthday. This is just 365 permute 21 times $\displaystyle \frac{1}{365^{21}}$. To summarize:</p>

<p>$$\binom{23}{2} \frac{1}{365^2} \frac{1}{365^{21}} P\binom{365}{21}$$ </p>
",<probability>
"<p>I deal a standard deck of 52 cards to you face up, one card at a time. Before
any deal of any card you can shout out ""NOW"". If you shout out ""NOW"" and the
next card I deal is a queen, then the game finishes and I give you $100. If the next
card isn't a queen, then the game finishes and I give you nothing. What is a fair
price for you to pay me in order to play this game with me?</p>

<p>What I think of is to use the optional sampling theorem and show it is a martingale. But I am a bit lost on the setup.</p>
",<probability>
"<p>Given some real number $a$ can anyone prove that if
$$
P(X &gt; a) &gt; P(Y &gt; a)
$$
is true then
$$
P(X &gt; Y) &gt; \frac12
$$
is also true.</p>
",<probability>
"<p>Suppose there are thirteen slips in a bag, labelled 1-13. If I draw a 10, 11, 12, or 13 then I stop adding to the sum and return the sum. If not, I add the number I draw to the current sum and place the slip back in the bag. </p>

<p>What is the expected value of the sum?</p>

<p><strong>My Attempt:</strong></p>

<p>S: total sum</p>

<p>Xi: the ith drawn slip</p>

<p>Probability of drawing a slip from 1-9: 9/13</p>

<p>Have a 9/13 chance of getting # from 1-9 and expect to add average of 5 and trying again...</p>

<p>Ending with a 10, 11, 12, or 13 each has 1/4 chance
$$
E[S] = \frac{1}{4}(\frac{9}{13}(5+E[S]) +10) + \frac{1}{4}(\frac{9}{13}(5+E[S]) + 11) +... +\frac{1}{4}(\frac{9}{13}(5+E[S])+13)
$$</p>

<p>which gives E[S] = 48.625</p>

<p>I wasn't sure how to factor in the four different ways that we could end the drawing (i.e. ending with a 10, 11, 12, 13). The answer doesn't seem right to me. </p>

<p>Additionally, let Y be the number of times a number of a particular number is drawn. What is E[Y]? I have no idea how to start with this with this part.  </p>
",<probability>
"<p>A non-closed path is chosen at random on the complete graph K9. All
paths are equally likely. What is the probability that the path contains
the edges {23} and {34} given that it is length 6? Given that it has
the edge {89}?</p>
",<probability>
"<p>I have a conditional probability problem I'm unsure can be answered given the information I have - as such I'm unsure if Bayesian Theorem is the way to answer it, or if the answer is staring at me in the face and I can't spot it.</p>

<p>It's easiest to think of this problem in terms of a game of baseball, with two teams - A and B.  I want to work out:</p>

<p><strong>Pr(A scores first and A wins)</strong> (A1) - and similarly<br>
<strong>Pr(B scores first and B wins)</strong> (A2)</p>

<p>Obviously these two scenarios alone won't sum to 100% as there are the possibilities that a team could score first and go on to lose.  Also worth keeping in mind that in a baseball setting Team A will bat first and have first chance to score.</p>

<p>I have the following known information:</p>

<p>Pr(A Wins) = 0.58  (B1)<br>
Pr(B Wins) = 0.42  (B2)</p>

<p>Pr(A Scores First) = 0.51 (C1)<br>
Pr(B Scores First) = 0.49 (C2)</p>

<p>Pr(The team who scores first wins) = 0.75  (D1)<br>
Pr(The team who scores first loses) = 0.25  (D2)</p>

<p>Is it as simple as saying that A1 = C1 * D1 (ie, the prob of team A scoring first by the prob that the team who scores first wins is the prob that team A will score first and win).  </p>

<p>In the back of my mind it seems to me this isn't valid as there is some dependency here, hence I'm unsure whether I need to use Bayes Theorem - or is it the case there isn't enough information here?</p>

<p>Thanks in advance.</p>
",<probability>
"<p><img src=""http://i.stack.imgur.com/5VGgn.jpg"" alt=""enter image description here""></p>

<p>Find $E[X]$ and $Var[X]$</p>

<p>So for the expectation so far I got that:</p>

<p>$$E[X] = E[X|N=n]P(N=n) = \large\frac{n+1}{\lambda} \frac{\lambda^{n}}{n!}e^{-\lambda}$$
but for conditioning on both a discrete and continuous random variable I am not sure whether to use the summation or integration. For integration it comes out to be just $\frac{n+1}{\lambda}$ which does not seem right since that would indicate that the expectation is independent of each other.</p>
",<probability>
"<p>A box contains $3$ yellow socks, $4$ blue socks, $1$ orange sock, and $2$ green socks. What is the probability of picking $2$ blue socks at the same time? What is the probability of picking $1$ green and $1$ blue sock at the same time?</p>

<p>I was thinking it is:<br>
$\large\frac{4}{10} \cdot \frac39$ for the $1^{st}$ question,  </p>

<p>$\large\frac{2}{10} \cdot \frac49$ for the $2^{nd}$ question.</p>
",<probability>
"<p>Question: </p>

<p>A store opens at $t =0$ and potential customers arrive in a Poisson manner at an average arrival rate of $λ$ <em>potential</em> customers per hour. As long as the store is open, and independently of all other events, each particular potential customer becomes an <em>actual</em> customer with probability $p$. The store closes as soon as ten actual customers have arrived.</p>

<p>Considering only customers arriving between $t =0$ and the closing of the store, what is the probability that no two <em>actual</em> customers arrive within $τ$ time units of each other?</p>

<p>Thanks! Could you give me idea or answer? 
Why downvote? The given answer is a little werid that I could not understand...</p>
",<probability>
"<p>I have a question.</p>

<p>I'm looking to calculate the probability of getting $4$ different suits cards in a $5$ card poker game using a standard $52$ card deck.</p>

<p>I think this is: $$\frac{\dbinom{4}{1}\dbinom{13}{2}\dbinom{13}{1}^{3}}{\dbinom{52}{5}}$$</p>

<p>What do you think?
Thanks.</p>
",<probability>
"<p>Consider a homogenenous Markov chain $\{X_n\,:\, n\in \mathbb N\}$ ($0\in\mathbb N$). The state space is $S$ with $|S|\le |\mathbb N|$ and $i\in S$. Consider moreover the function $1_{\{i\}}:S\longrightarrow\{0,1\}$ such that $1_{\{i\}}(i)=1$ and $1_{\{i\}}(s)=0$ if $s\neq i$ and then define the following random variable:</p>

<p>$$N_i:=\sum_{n=1}^\infty1_{\{i\}}(X_n)$$</p>

<p>Clearly $N_i$ counts (starting from $X_1$) ""the passages"" of the Markov chain from the state $i$.</p>

<p>I don't understand the following equality that can be found in the book  ""A course in stochastic - D. Bosq, H.T.Nguyen"" (page 57 on my edition):</p>

<p>$$E(N_i|X_0=i)=\sum_{n=1}^\infty P(X_n=i|X_0=i)$$</p>

<p>where $E(\cdot|\cdot)$ is the conditioned expected value. Please give me an explaination.</p>

<p>Thanks in advance.</p>
",<probability>
"<p>I'm trying to find the probability that $X$ is greater than, given a mean of $50$ and a std deviation of $5$.</p>

<p>I enter <code>normalcdf(66, 1E99, 50, 5)</code> in my calculator and receive and error.</p>

<p>Please help.</p>
",<probability>
"<p>A am a bit confused, when we are using choosing the critical value for a wilcoxon rank sum test (2-samples unpaired) when do we use the upper bound and when do we use the lower bound. So far i have only used the lower bound with the lowest of the two W values but keep seeing questions (A-level exam questions) where they specifically take the upper bound. For what reasons and when do we use the upper critical value and when the lower??</p>
",<probability>
"<p>Let E and F be independent with E = AUB and F=AB. Prove that either P(AB)=0 or else P(not A and not B)=0.
I dont know how to solve it. Please help.
Thank you very much.</p>
",<probability>
"<p>This is another question like <a href=""http://math.stackexchange.com/questions/520844"">this one</a>. And by the same reason, the book only has the final answer, I'd like to check if my reasoning is right.</p>

<p>A couple has 2 children. What is the probability that both are girls if the eldest is a girl?</p>
",<probability>
"<p>A population consists of F females and M males;the population includes f female smokers and m male smokers. If A is the event that the individual is female and B is the event he or she is a smoker , find  the  condition on f, m, F and M so that A and B are independent events?
The answer is f/F=m/M
I dont know how to get that answer. Please help.
Thank you.</p>
",<probability>
"<p>I'm trying to find if my approach to this kind of problems is correct. </p>

<p>For example: You have 3 boxes, and you have a 33% chance of finding an item in a box. What is the probability of finding items in: 0, 1, 2, 3 (all) boxes?</p>

<p>My answer:</p>

<p>$P=0.33$ $(!P =1 - 0.33=0.67)$</p>

<p>for 0 boxes: $(!P * !P * !P) * 3 = (0.67 ^ 3) * 3= 0.9$</p>

<p>for 1 box: $P * !P * !P + !P * P * !P + !P * !P * P  = (0.33 * 0.67 ^ 2) * 3 = 0.44$</p>

<p>for 2 boxes: $P * P * !P + P * !P * P + !P * P * P = (0.33 ^ 2 * 0. 67) * 3 = 0.21$</p>

<p>for 3 boxes: $(P * P * P) * 3 = (0.33 ^ 3) * 3 = 0.10$</p>

<p>The reasoning (for example for the 1 box case) is that we need to take the probability that the first chest contains an item AND $(*)$ the other don't, OR $(+)$ the second chest contains an item and the other don't, OR the third contains an item and the other don't.</p>

<p>Is this the correct way to calculate the probability for this type of problem?</p>
",<probability>
"<p>Let $X$ be a non-negative random variable. Prove that $$\Pr(X\geq a) \leq \frac{E[e^X]}{e^a}$$ </p>

<p>where e is Napier's base.</p>

<p>Can I know what the question means and how to prove it.</p>
",<probability>
"<p>If Government increases payment then they increase it by 9% . now if whether government will increase payment follows binomial distribution with parameters n=2 and p=(2/3) , then what percentage of payment increase is expected ? </p>

<p>my logic is let 
X denotes  government will increase payment.
then  x follows Bin(2, 2/3)</p>

<p>then E(X)=4/3.
so expected payment increase is 9*(4/3)=12%</p>
",<probability>
"<blockquote>
  <p>Let $X$ denote the number of tosses required to get the 5th head and $Y$ the number between the 6th and 7th heads. Are $X$ and $Y$ independent?</p>
</blockquote>

<p>Y will always depend on X . NO ?
i know geometric distribution has lack of memory property . but in this the underlying distribution is i think negative binomial. </p>

<p>i think 'no, they are not independent ' . help please. </p>
",<probability>
"<p>Let $\{X_n\}$ be a sequence of independent random variables on some probability space. </p>

<p>Then, by definition(according to the book that I am reading), I know that $\{\sigma(X_1),\sigma(X_2),\dots, \}$ is independent. </p>

<p>Then, I am wondering whether $\sigma(X_{n+1})$ is independent of $\sigma(\sigma(X_1),\sigma(X_2),\dots,\sigma(X_n))$. </p>

<p>Or in general, is $\sigma(\sigma(X_{n_1}),\sigma(X_{n_2}),\dots,\sigma(X_{n_k}))$ is independent of 
$\sigma(\sigma(X_{j_1}),\sigma(X_{j_2}),\dots,\sigma(X_{j_l}))$, where $\{n_1,n_2,\dots,n_k\} \cap \{j_1,j_2,\dots,j_l\} = \emptyset$?</p>
",<probability>
"<p>I know that there exists a particular measure, called <a href=""https://en.wikipedia.org/wiki/Haar_measure"" rel=""nofollow"">Haar measure</a>, defined on random matrices, i.e. $n \times n$ orthogonal complex matrices. 
My question is the following: can we define a probability measure on the space of $n \times n$ symmetric matrices with non negative integer coefficients? If yes, can you suggest me some case?</p>
",<probability>
"<p>Firstly apologies for lack of maths skill, I am a biologist and sadly fit the stereotype of being terrible at maths. </p>

<p>I am designing a set of unique identifiers for sample identification, which are generated from the genetic data associated with the sample. </p>

<p>I am trying to calculate the probability that within a given population of samples, two or more samples will be assigned the same identifier, which clearly is not desirable.</p>

<p>The identifiers are an ordered concatenation of $22$ pieces of data, each with three states i.e. RR, RA &amp; AA. These three states each have a different frequency in the population, as well as being different between the 22 pieces of data. I think that for these 22 pieces of data the number of possible identifiers will be $3^{22}$ =~ $3.14x10^{10}$. Presumably the average probability for each identifier would be $\large \frac{1}{3.14x10^{10}}$, but it would be the upper outliers that would be the limiting factor on the use of the method.</p>

<p>I have calculated the probability of the most probable identifier occurring in a single sample, which is ~$2x10^{-7}$. As such, I think that:</p>

<p>$p$ = $(2x10^-7)^{2}$ $\cdot n$</p>

<p>where p is the probability of the most likely identifier being assigned twice and n is the number of samples in the population.</p>

<p>This is as far as my maths can take me, though this clearly fails say where the identifier can be assigned more than twice, and as there are $3.14x10^{10}$ identifiers which could potentially also be repeatedly assigned. </p>

<p>I am struggling to see a way to deal with the multiple identifiers issue other than presuming that all identifiers have the same probability as this most likely identifier, though this would surely result in an enormously conservative estimate. </p>

<p>Once I have a way to do this I will then try to calculate the maximum size of a population sampled while maintaining a probability of replication of less than say $0.05$.</p>

<p>Any help with this would be greatly appreciated, sorry for the rather cumbersome explanation. I and others in my group have some skill in programming, so computational approaches that are more accurate are viable, and indeed preferable to conservative estimations.</p>

<p>Many thanks</p>
",<probability>
"<p>Say we have a compact space $X$ and a probability measure $P$ on $X$.</p>

<p>Assume that we know that for some event $A$ the sequence $f_n(x)\rightarrow f_\infty(x)$ converges a.s. in $Q$ which is the regular conditional probability space generated by conditioning $P$ on the event  $A$.</p>

<p>Under which conditions we can conclude that $f_n(x)\rightarrow f_\infty(x)$ converges a.s. in $P$ also?</p>
",<probability>
"<p>Given the probability density function $(x+y)$ if $0 \leq x \leq y \leq c$, $0$ otherwise.</p>

<p>I want to calculate $c$. I clearly do not know at all where to start. I tried to take some integrals but I just do not know how to find the ""limit"" of the function.
 However, my math skills are not too advanced that is why I am not quite sure if there actually is some calculation involved.</p>

<p>I would appreciate some help, thanks. </p>
",<probability>
"<p>I'll just give you the four rules that matter in this problem and explain my thought process and the other opinion.</p>

<p>Rule #1: 15 players are playing a game.</p>

<p>Rule #2: One player (J) can secretly select a player (not themselves).</p>

<p>Rule #3: A different player (K) can then secretly select a player (not themselves) and kill them.</p>

<p>Rule #4: If J selects K, then K will be given no choice and will kill J.</p>

<p>Clarification: J and K can select the same person.</p>

<p>It is then revealed that K killed J. What is the probability that J had selected K?</p>

<p>Let Q be the required probability.</p>

<p>I will attempt to calculate the probability that J did NOT select K given that K killed J.</p>

<p>Let's call A the event {J does NOT select K} and B the event {K kills J}. </p>

<p>We're trying to calculate P(A/B), which is equal to P(AB)/P(B). Clarification: AB means A∩B.</p>

<p>P(Β) first. B can happen if J selects K (1/14), or K selects J (1/14), minus the intersection (1/196). Thus, P(B)=2/14-1/196=27/196.</p>

<p>AB now. The probability that K selects J (1/14), minus P{K selects J AND J selects K} (1/196). So, P(AB)=13/196.</p>

<p>Thus, P(A/B)=0.481481... or about 48%. And Q=0.52. Almost.</p>

<p>Some people, however, argued that since we know J died to K, the sample space only includes the events {K killed J}, of which there are 14, and only 1 of those also includes J selecting K, thus Q=1/14. Part of the argument is that P(B)=1, since we know that K killed J.</p>

<p>I am not sure wether we are looking for dependent probability or intersection. The problem, however, is perfectly defined. If it is revealed that K killed J, what are the odds of J having selected K?</p>

<p>EDIT: Another clarification: While, yes, both J and K do not have to select another player, we assume that both did (although K will kill J if he is selected, even if he doesn't want to kill anyone).</p>

<p>I was also a bit vague about what J does when he selects another player because it is irrelevant. If you must know, during the day he selects the player he wants to interrogate that night, and in all nights except the first one (which this problem examines), kill them if he so wants. There are exceptions, but this is the general rule.</p>
",<probability>
"<p>We choose a random number from 1 to 10. We ask someone to find what number it is by asking a yes or no question. Calculate the expected value if the person ask if it is $x$ number till you got it right?</p>

<p>I know the answer is around 5 but i can't find how to get there.</p>

<p>I tried $\frac{1}{10}(1)+\frac{1}{9}(2)+\frac{1}{8}(3)+\frac{1}{7}(4)+\frac{1}{6}(5)+\frac{1}{5}(6)+\frac{1}{4}(7)+\frac{1}{3}(8)+\frac{1}{2}(9)$</p>

<p>but it doesn't work. Any help to point me in the right direction would be greatly appreciated.</p>

<p>Thank you</p>
",<probability>
"<p>You are dealt $20$ cards. What is the probability you have all kings given that you hold at least one king?</p>

<p>So I set it up like 
$$
P(4\textrm{ Kings | at least one king}) =\frac{{4 \choose 4}{48 \choose 9}}{{52 \choose 20}-{48 \choose 20}}
$$
Does this setup look correct? </p>
",<probability>
"<p>Suppose that I have a finite population of A's and B's, with properties:</p>

<ul>
<li><p>Population size: $n$</p></li>
<li><p>There are $n_1$ A's and $n - n_1$ B's  (so that $p = \frac{n_1}{n}$, $q = \frac{n - n_1}{n}$)</p></li>
</ul>

<p>I'm taking a sample of size r without replacement. What I need to demonstrate (<strong>if it can be demonstrated</strong>, I'm not sure) is that: if p > 0,5 then the probability that sample proportion $\bar{p}$ > p is greater than the probability that $\bar{p}$ &lt; p.</p>

<p>Put another way: <strong>If p > 0,5, then Prob($\bar{p} \ge p$) > Prob($\bar{p} \le p$)</strong></p>

<p>Plainly, that if deviations from the expected value occur, then they are more likely to occur in the direction of the more frequent type of member.</p>

<p>As an additional premise I have that $pr \in \mathbb{Z}$.</p>

<p>So, instead of using a cumulative hypergeometric distribution, I thought it would be simpler (avoiding the sums) to reformulate the problem in this manner:</p>

<p>$$\frac{\binom{n_1}{pr} \binom{n - pr}{r - pr}}{n \choose r} &gt; \frac{\binom{n - n_1}{qr} \binom{n - qr}{r - qr}}{n \choose r}$$</p>

<p>Is this ok? What it says -on the left for example- is basically ""from the population, take a subset of pr A's (so you know now that the sample will contain at least the same proportion of A's than the population), and then take the rest of the sample from the remainder of the population as you please"".</p>

<p>If this is ok, then how do I go on from there?
I managed to reduce what I need to prove to:</p>

<p>$$\frac{(pn)!}{(pn -pr)!} (n - pr)! &gt; \frac{(n - pn)!}{(n - r - (pn -pr))!} (n - (r - pr))!$$</p>

<p>(since the denominators cancel and, after applying the binomial coeeficient formula, (r - pr)! = (qr)! and (r - qr)! = pr! can also be cancelled).</p>

<p>Is what i've got so far all right? where to go from here? Thank you</p>

<p>EDIT: I've been trying the conjecture for various values here: <a href=""http://stattrek.com/online-calculator/hypergeometric.aspx"" rel=""nofollow"">http://stattrek.com/online-calculator/hypergeometric.aspx</a>  and the result seems to hold. Furthermore, there seem to be some interesting properties, such as, the greater p is, the greater the difference between $Prob(\hat{p} \ge p)$ and $Prob(\hat{p} \le p)$.</p>

<p>It seems to hold for sampling with replacement as well, which can be tried here: <a href=""http://onlinestatbook.com/simulations/CLT/clt.html"" rel=""nofollow"">http://onlinestatbook.com/simulations/CLT/clt.html</a></p>
",<probability>
"<p>Here's a nice probability puzzle I have thought about for a class I'm TAing, I'm curious to see different solutions :) It goes like this:</p>

<p>We have a classroom with $n$ seats available and $m \leq n$ incoming students. Each student has an (ordered) list of $k \leq n$ preferences for the seat he is going to take, where $k$ is some fixed positive integer. If at the moment of his arrival, a person's $k$ favorite seats are already taken, then he randomly chooses a seat from the remaining $n-k$. What is the probability that everyone occupies one of his favorite $k$ seats?</p>
",<probability>
"<p>Given two points $X,Y$ on two sides of square $[0,1]\times [0,1]$ ($X:(0,1/2),Y:(1,1/2)$ (PS: My original question is $X,Y$ on opposite of a square, but I think that's not the real case) )and $n$ points distributed uniformly(i.i.d) in the square (where $n$ is large, and $A$ denotes the set of $n$ points), can I caluculate the asymptotic behavior of the value $M(n)$, where $M$ is defined as
$$M(n)=E\left[\min_{B\subset A} \sum_{k=1}^{|B|+1} d(B_k,B_{k-1})^2\right]$$
where $B_k$ is the $k$th element of $B$,$B_0=X,B_{m+1}=Y$(We let $m=|B|$), and the expected value is taken over all the possible $A$ . That is to say, I would like to compute the expected value of the minimal weight defined as sum of the square of distance.</p>

<p>I know that when $n\to\infty,M(n)\to 0$. And in the $1$-dim case, this is easy, since it is only a Poisson process, and the distance between two consecutive points are surely exponential distribution.(Calculation suggests it's about $(n+3)/((n+1)(n+2))$,where $n$ is number of points added) But in the two dimensional case, I got stuck and don't know how to tackle it. This is a problem arouse from the calculation of the cost of a network. Any hint or reference are welcomed, Thanks!</p>

<p>(Some computer experiment suggests that the weight is about $\approx 1.1/\sqrt{n}=O(1/\sqrt{n})$. I also wonder if there are some similar results?)</p>
",<probability>
"<p>N uniform spheres are to be segregated into 4 boxes labelled A,B,C,D. What is the probability of not finding a sphere in box A if :</p>

<ol>
<li>N=4</li>
<li>N=10</li>
</ol>

<p>?</p>

<p>According to me , if they are the spheres and boxes are represented by X and * respectively and  listed as a string eg.XX*X*X* (Actually the * represents the separation between regions that represent a box ie. two spheres in each box would be shown as- XX*XX*XX*XX), the no. of ways in which they could be segregated is $\binom{10 +4-1}{10}$ where 10 is the no. of spheres and in this case the 10 spaces in the resultant 13 character string.</p>

<p>Subsequently, if one box is ignored as per the requirement of the question , the required probability should be :  $\frac{\binom{10+3-1}{10}}{\binom{10+4-1}{10}}$</p>

<p>Please provide an answer to the probability question and any mistakes that I may have made in my approach.</p>
",<probability>
"<p>Then you toss a fair coin as many times as the number of pips. For each heads, you win \$20; for each tails, you lose \$1. Let X = total amount you win (or lose if $X&lt;0$). </p>

<p>What is $E(X)$?</p>

<p><strong>My thoughts:</strong></p>

<p>If you roll $n$ you lose $n$ and then gain ($20 \cdot$ expected head) $-$ ($1 \cdot$ expected tails) </p>

<p>Expected heads = expected tails = $\frac{n}{2}$. </p>

<p>Probability of rolling $n$ is $\frac{1}{6}$. Therefore:</p>

<p>$E(X) = \sum_{n=1}^6 \frac{-n + 20\frac{n}{2} - 1\frac{n}{2}}{6}$ </p>

<p>$= \sum_{n=1}^6 \frac{-n + 10n - \frac{n}{2}}{6}$ </p>

<p>$= \sum_{n=1}^6 \frac{8.5n}{6}$ </p>

<p>$= \frac{8.5}{6}\cdot \frac{6\cdot7}{2}= \frac{(8.5)\cdot7}{2} = 29.75$</p>

<p>Does this work seem correct? I feel like I did something wrong. Thanks!</p>
",<probability>
"<p>I have a rectangular section of constant height and length and I choose a random starting point anywhere along its length. From the randomly chose starting point, I first add <code>x</code> units of red material immediately to its right and then fill the remaining section to the right of the red material with blue material.</p>

<p>Here's a graphic I drew up as an example:</p>

<p><img src=""http://i.stack.imgur.com/V1gQt.jpg"" alt=""enter image description here""></p>

<p>My questions is, how do I go about finding the probability that the variable blue material section will be greater than the static red material section?</p>

<p>And also is there a way to determine an average size of the blue section?</p>

<p>My idea was that that the average starting point would be in the middle of the rectangle, therefore the average blue material section would be:</p>

<p>$$
\frac{length\_rectangle}{2} - x
$$</p>

<p>Is that correct?</p>

<p>For the probability component, I figure that for the red material section to be greater than the blue section, the starting point would have to start at such a point that:
$$
(length\_rectagle - start\_point) &lt; 2x 
$$
Therefore, the probability that the starting point satisfies the inequality, would be just less than:
$$
\frac{2x}{length\_rectangle}
$$</p>
",<probability>
"<p>This is an interview question.</p>

<p>Given n red balls and m blue balls and some containers, how would you distribute those balls among the containers such that the probability of picking a red ball is maximized, assuming that the user randomly chooses a container and then randomly picks a ball from that. </p>

<p>My solution: </p>

<p>suppose we have c containers, distribute n/c read balls to each c. 
     If c == 1, put all of them together, it is
                n/(m+n)    </p>

<pre><code> If c == 2,  put 1 red in c1 and all left red and all blue ones in c2 in this way , we have:
              1/2 + 1/2 *(n-1) /(m+n-1) &gt; 1/2

 If c == 3,   put a red in c1, put a red in c2, put left red and all blue in c3, we have:
    1/3 + 1/3 + 1/3 * (n-2)/(m+n-2) &gt; 2/3

 If c == n,  put a red in each of p -1, and all left red and blue in pth container, we have:
            ( Sum of (1/n) from 1 to n-1 ) +  ( 1/n * 1/(m+1) )
            (n-1)/n + 1/n * 1/(m+1) == 1 (almost)
</code></pre>

<p>As n is large, the (n-1)/n is very close to 1 so that we maximize the probability to get a red balls.  </p>

<p>Any better ideas ? </p>
",<probability>
"<p>Suppose you ﬂip a fair coin repeatedly until you see a Heads followed by a
Tails. What is the expected number of coin ﬂips you have to ﬂip?</p>

<p>By manipulating an equation based on the result of the first flip, shown at this link:</p>

<p><a href=""http://www.codechef.com/wiki/tutorial-expectation"">http://www.codechef.com/wiki/tutorial-expectation</a></p>

<p>the answer is 6. This also makes sense intuitively since the expected value of the number flips until HH or TT is 3. But is there a way to tackle this problem by summing a series of probabilities multiplied by the values?</p>

<p>Thank you!</p>
",<probability>
"<p>If there is an 82% chance that within your average lifetime, lets assume 70 years (25567 days), that ""E"" event will happen: what is the percent chance that it will happen on any given day?
<br><br>I'm assuming that it'll be something like .02347% or something small. My problem is I've only taken up through Advanced Algebra and that was six years ago. I would have searched for this on google to solve it myself, but I'm not even sure what to call this beyond ""math I don't know"". 
<br><br>So if you could help me identify the solution, how to solve it, and what this is (i.e. I imagine terms like 'graphing polonomials' 'deductive statistics' or some such name that would give me an idea of what exactly it is that I should be learning to handle similar questions on my own). Thanks for the help in advance.</p>
",<probability>
"<p>I am trying to show that the stationary distribution for a Markov Chain on a continuous state space can be obtained by building a transition density kernel, which obeys the detailed balance rule where $P_{t+1|t}(X_{t+1}=i|X_{t}=j)P_{t}(X_{t}=j) = P_{t+1|t}(X_{t+1}=j|X_{t}=i)P_{t}(X_{t}=i)$. The Markov Chain is time-homogeneous so $P_{t+1|t}(X_{t+1}=i|X_{t}=j)=T(X_{t+1}=i|X_{t}=j)$ is independent of time step $t$ and $T$ is the continuous transition kernel (density kernel). I suppose that the distribution at the time $t$ is the stationary distribution $\pi$, which is $P_{t}(X_{t}=i) = \pi(i)$ and I aim to show that $P_{t+1}(X_{t+1}=i) = \pi(i)$ given the detailed balance.</p>

<p>I am currently proving this already but I am not sure whether my way of proof is mathematically valid.</p>

<p>Here is what I am doing:</p>

<p>1) I calculate $P_{t+1}(X_{t+1}=i)$ as $P_{t+1}(X_{t+1}=i) = \int_{-\infty}^{\infty} P_{t+1|t}(X_{t+1}=i|X_{t})P_{t}(X_{t})dX_{t} = \int_{-\infty}^{\infty} P_{t+1,t}(X_{t+1}=i,X_{t})dX_{t}$</p>

<p>2) According to the detailed balance, for each $i,j \in \mathbb{R}$, it is $P_{t+1|t}(X_{t+1}=i|X_{t}=j)P_{t}(X_{t}=j) = P_{t+1|t}(X_{t+1}=j|X_{t}=i)P_{t}(X_{t}=i)$. This means that the joint distribution function is symmetrical: $P_{t+1,t}(X_{t+1}=i,X_{t}=j) = P_{t+1,t}(X_{t+1}=j,X_{t}=i)$. Here, I think about the joint distribution as an uncountable sized, symmetric matrix. Therefore the integration over the row ""belonging"" to $X_{t+1}=i$ is equal to the integration over the column ""belonging"" to $X_{t}=i$. According to this logic it must be $P_{t+1}(X_{t+1}=i) = \int_{-\infty}^{\infty} P_{t+1,t}(X_{t+1}=i,X_{t})dX_{t} = \int_{-\infty}^{\infty} P_{t+1,t}(X_{t+1},X_{t}=i)dX_{t+1} = P_{t}(X_{t}=i)$.</p>

<p>3)Since $P_{t}(X_{t}=i) = \pi(i)$ we have that $P_{t+1}(X_{t+1}=i) = \pi(i)$ and this ends the proof.</p>

<p>The part 2 is where I am feeling uneasy about my way of proof. I know that the symmetry induced on the joint distribution of consecutive random variables must yield the change of integration variables in the step 2 as valid. This is indeed the case, if we had a finite state space Markov Chain. The joint distribution would be a finite sized matrix and the symmetry would immediately tell that the $i$th row and $i$th column are equal. But I am not comfortable with this way of thinking on a continuous state space, mainly because of my shallow mathematical background.</p>

<p>What would be a more mathematically rigorous way to show that the step 2 is correct? How should we show that integrals in the step 2 are equal to each other?</p>

<p>Thanks in advance.</p>
",<probability>
"<p>How to evaluate $$\frac{\Gamma\left(\frac{n}{2}\right)}{\Gamma\left(\frac{n-1}{2}\right)}$$, where n is integer > 0?</p>

<p>I know the gamma function formula will give</p>

<p>$$ \frac{(\frac{n-2}{2})!}{(\frac{n-3}{2})!}$$ How to simplify it?</p>
",<probability>
"<p>We say that a graph $G$ is distributed with $\mathcal{G}_{n,p}$ if it is a graph on $n$ vertices, and for which each of the ${n\choose 2}$ possible edges is chosen independently of the other edges and with probability $p$.</p>

<p>A <em>monotone property</em> $P$ of a graph is a set of graphs (on $n$ vertices) that is closed from above (that is, if $G\in P$ and $G\subseteq H$ then $H\in P$.</p>

<p>A function $f(n)$ is said to be a <em>threshold</em> for a property $P$ if for any $p(n)=\omega(f(n))$, $G\sim\mathcal{G}_{n,p}$ has $P$ asymptotically almost surely (a.a.s.), and for any $p(n)=o(f(n))$, $G\sim\mathcal{G}_{n,p}$ does not have $P$ a.a.s.</p>

<p>For example, if $P$ is ""has a triangle as a subgraph"", then $P$ is clearly monotone, and $f(n)=n^{-1}$ is a threshold for $P$. $f(n)=\frac{\ln{n}+\ln\ln{n}}{n}$ is a threshold for the Hamiltonicity property (in a stronger sense).</p>

<p><strong>My question is this:</strong> what are the thresholds for the properties of having ""quite short"" paths or cycles? By ""quite short"" I mean of length $\Theta(n^\varepsilon)$ for some $0&lt;\varepsilon&lt;1$, or of length $\Theta(\ln{n})$.</p>
",<probability>
"<p>We have $11$ bins with $10$ objects each. Every object is either black or white, and the $i$th bin ($1 \le i \le 11$) has precisely $(i -1)$ black objects in it. Someone selects, uniformly at random, one of those bins and then selects, also uniformly at random, two objects from it. What is the probability that these two objects are of the same color?</p>
",<probability>
"<p>The chances of being born with a certain disease are estimated as $1$ in $1200$. What is a good estimate of the chance that an island with $10000$ inhabitants has precisely $8$ people born with that particular disease? We assume that all $10000$ events of being born with that particular disease are mutually independent.</p>
",<probability>
"<p>Is it true that for continuous distribution $$E(X^a) =  \int_{-\infty}^{+\infty} x^a\cdot g(x)dx $$ where $g(x)$ is probability density function?</p>
",<probability>
"<p>If I have two events that occur on a specific interval (one every 8 seconds, the other every 200 milliseconds) but were not started synchronously, how can I calculate the frequency with which these two events will occur at the same time?</p>

<p>Looking at the numbers, it seems that unless they start synchronously, they will <em>never</em> coincide. If they started synchronously, in a perfect world, it would be every 8 seconds.</p>

<p>Obviously there is some variation/imperfection because they <em>do</em> coincide occasionally despite not starting at the same time.</p>

<p>I suppose I am looking for a harmonic, or additive function. Forgive me, my math knowledge is lacking.</p>
",<probability>
"<p>Is it</p>

<ul>
<li>The number of failures BEFORE the first success OR</li>
<li>The number of trials required to get a first success?</li>
</ul>

<p>Also, if I was to work out the expected value of a geometric random variable, say $p = 0.25$ (Expected value = $3$), does that mean that I will have $3$ failures AND THEN a success, or $2$ failures and then a success??</p>

<p>I would immensely appreciate some help here.
Thank you so much x</p>
",<probability>
"<p>The urn consists 4 balls (black and white) with at least 1 white. Two randomly drawed balls were both white. What it the probability of getting white ball again?</p>

<p>My solution:</p>

<pre><code>balls(w/b)    || 4:0  | 3:1  | 2:2  | 1:3  | 0:4
P(prior)      || 1/15 | 4/15 | 6/15 | 4/15 | 0/15
P(2w|prior)   || 1    | 1/2  | 1/6  | 0    | 0
P(posterior)  || 1/4  | 1/2  | 1/4  | 0    | 0
P(w|posterior)|| 1    | 1/2  | 0    | 0    | 0

P(w) = ∫P(w|u) P(u) du = 1 * 1/4 + 1/2 * 1/2 + 0 * 1/4 = 1/2
</code></pre>

<p>But the answer is $7/12$. Where have I made a mistake?</p>

<p>The prior was assumed:</p>

<pre><code>balls(w/b)    || 4:0 | 3:1 | 2:2 | 1:3 | 0:4
P(prior)      || 1/8 | 3/8 | 3/8 | 1/8 | 0/8
</code></pre>

<p>Meaning the first ball was white and all others were decided by coin toss. However, I think the original formulation does not correspond to this problem and should be replaced with something like: </p>

<pre><code>In an urn with a white ball one puts another 3 balls ...
</code></pre>
",<probability>
"<p>Let there be $2$ urns containing $a$ white, $b$ black balls and $c$ white, $d$ black balls respectively.Everytime a ball is drawn at random from the first urn  and is transferred to the second and similarly a ball from the second urn is transferred to the first urn , both events taking place  simultaneously at a particular moment.After n such operations, a ball is randomly selected from the first urn .Find the probability that it is white.</p>

<p>{Inspired by a problem of J.V. Uspensky}</p>
",<probability>
"<p>Let N denote the number of automobile accidents on a given stretch of interstate
highway over a specific period. It is known that N has the geometric distribution with pmf </p>

<p>$f_N(n)=x(1-x)^{n-1}$, $n=1,2,3,...$ </p>

<p>where x is bounded between 0 and 1, $0&lt; x&lt; 1$ </p>

<p>for the ith accident $Y_i=1$ if accident contains a fatality, </p>

<p>$Y_i=0$ if no fatality,</p>

<p>for each i, $P(Y_i=1)=p$, each $Y_i$ is independent</p>

<p>Let T be the total number of accidents with at least one fatality. </p>

<p>Then, $T=Y_1 + Y_2 +...+Y_N$</p>

<p>Find $E(T)$ and $Var(T)$,
I was thinking that since each $Y_i$ is bernoulli that is dependent on N then sum of each $E(Y_i)$ is $Nxp$ and the variance would be summing $p(1-p)$ which is $Npx(1-px)$</p>

<p>Maybe this is $E(T)=E(E(T|N))=\frac{p}{x}$ then $Var(T)=...$</p>

<p>Find $Corr(N,T)$=
$\frac{E(NT)-E(N)E(T)}{sd(T)sd(N)}$</p>

<p>Find $P(T=0)$</p>

<p>I seem to be missing something in my analysis that would lead me to get the rest of the problem</p>
",<probability>
"<p>Every night, different meteorologist gives the probability of rain for the next day. To judge their predictions, we use the following scoring system: if a meteorologist predicts rain with the probability $\color{blue}{p^*}$ and is right, that meteorologist receives a score of $1-(1-p)^2$; if wrong, they receive a score of $(1-p)^2$. After a while we will be able to know which meteorologist is the best. Assumming one meteorologist knows the scoring system, what is the best way for them to maximise their expected value?</p>

<p>I know they probably should predict with a 50% accuracy everytime because that is where both fucntion intersect but what is the formula i should use to get to the right answer?</p>
",<probability>
"<p>I've been trying to answer this question for the past few days, and I'm absolutely stuck. Without further ado, here's the mystery:</p>

<p>We are given a pair of boxes. There are n red balls in box number 1, and n blue balls in box number 2. Every turn, a ball is randomly taken out of the first box, and not returned. After the ball is taken out, a blue ball from the second box is inserted into the first one. This continues until there are no more blue balls to be transferred from box 2 to box 1. That means that there are n+1 turns in which a ball is randomly taken out of box 1. </p>

<p>I am asked to find the probability that the last ball taken out of box 1 (which means in the (n+1)-th turn) is red. Here's what I've got so far:</p>

<p>Event A - the ball taken out of box 1 in the last turn is red.</p>

<p>Event B(i) - i red balls were left in box 1 after n turns.</p>

<p>I'm trying to find P(A). Bayes wasn't helpful, and the law of total probability was not useful as well, since I can't seem to know what P(B(i)) is for any given i (other than, of course, i=0 and i=n-1). I did find a two-dimensional recursive function for P(B(i)), but that doesn't seem to be the right solution. </p>

<p>Any thoughts about how to properly approach (and hopefully solve) this question would be highly appreciated. </p>
",<probability>
"<p>Suppose we flip 10 times an unfair coin that fall a probability of $p$ on 'heads'. Knowing that we obtained 'heads' 6 times out of the 10 flips, find the conditionnal probability of the first three flips being heads, tails, tails.</p>

<p>My effort: Since we don't know the exact probability of getting heads i would think it would be somthing like:</p>

<p>A: Probability of getting 6 'head' out of 10
B: Probability for the first 3 flip to be 'heads''tails''tails'</p>

<p>$A:\binom{10}{6}(p)^6(1-p)^4$</p>

<p>$B:p(1-p)^2$</p>

<p>$(B|A):???$</p>

<p>Any help to point me in the right direction would be greatly appreciated.</p>

<p>Thank you.</p>
",<probability>
"<p>Suppose we have a set of $b^n$ different numbers. Every time we randomly choose a number from this set and put it in a list of length  $b^\frac  n2$.
So we want to fill this list with unique numbers. However every time we choose a number we place it back to the set, giving it another chance to be selected. of course we would like numbers on our list be unique so I guess the probability to have a list of unique numbers is:</p>

<p>$\prod_{i=0}^{b^\frac n2 -1} \left(\frac{b^n-i}{b^n}\right)$</p>

<p>With sufficiently large $n$ and regardless of base $b$, computer analysis shows that it converges into 0.606 but I cannot fathom the reason. I wonder if someone can show me how this happens.</p>
",<probability>
"<p>I have a circle iwth radius $r$. I want to test the hypothesis that $r \leq 2$ vs. $r &gt;2$ based on the posterior of $r$. $r$ follows the prior distribution: $f(r) = \frac{2}{r^{2}}$, $ r &gt;0.5$. I observed the following points $(x,y): (1,3), (2,1), (0.5,1.4)$. My question is What should be the likelihood?</p>

<p>Edited:
The center of the circle is (0,0)</p>
",<probability>
"<p>I have a large set $S$ of items, but the set is not exactly known. All I know are the cardinal numbers of <em>categories</em> i.e. a number of disjoint subsets, </p>

<p>$ \vert{S_1}\vert \dots \vert S_n\vert$ with $\bigcup S_i = S$. </p>

<p>Thus I also know the cardinal number $\vert S\vert = \sum\vert S_i\vert$.</p>

<p>I then want to apply a predicate $p$ and estimate the cardinal number of the subset of $T \subset S$ which satisfies $p$, i.e. </p>

<p>$\vert T\vert = \vert \lbrace x\in S \mid p(x)\rbrace\vert$. </p>

<p>The predicate $p$ is precisely known and so are the predicates $p_i$ which need to be satisfied to fall into one of the categories $S_i$ (the ""meanings"" of $S_i$ are known).</p>

<p>In other words, I want to describe a large set with a few numbers $ \vert{S_1}\vert \dots \vert S_n\vert$, which still contain enough information, so I can estimate the cardinal number of the result of the filtering with $p$. I am willing to do a costly transformation on $p$ as long as the final computation of $\vert T\vert$ is fast.</p>

<p>I have the feeling that this is a textbook problem, but I don't know where to look for ideas. </p>

<ul>
<li>I don't know how to do this at all, and </li>
<li>I don't know what is the best way to define $p_i$. </li>
<li>What happens when my $S_i$ are not disjoint? Can I still say <em>something</em> about $\vert S\vert$ and $\vert T\vert$?</li>
<li>I suppose the more $p_i$s I have, the better the estimate will be, but I'd like to be be able to say something quantitatively about the accuracy.</li>
</ul>
",<probability>
"<p>Let $n$ be a positive integer. Suppose $a$ and $b$ are randomly (and independently) chosen two $n$-digit positive integers which consist of digits 1, 2, 3, ..., 9. (So in particular neither $a$ nor $b$ contains digit 0; I am adding this condition so that division by $b$ will be possible, and that we don't get numbers of the form $0002$ and so on). Here ""randomly"" means each digit of $a$ and $b$ is equally likely to be one of the 9 digits from $\{1,2,3,..., 9\}$. </p>

<p>My question concerns the divisibility of these integers:</p>

<blockquote>
  <p>1) What is the probability that $b$ divides $a$ ?</p>
</blockquote>

<p>The answer, of course, will depend on $n$. Denote this probability by $p(n)$. I would be happy with rough estimates for $p(n)$ as well :)</p>

<blockquote>
  <p>2) Is it true that $p(n)\to 0$ as $n\to\infty$?</p>
</blockquote>

<p>I think answer to question 2) is yes (just by intuition). </p>
",<probability>
"<p>Let $X_1, \ldots, X_n$ be a collection of random variables. Consider the directed graph with vertex set $\{ 1, 2, \ldots, n \}$ where there is a directed edge $i \to j$ if $\mathbb{P}(X_i &gt; X_j) &gt; \frac{1}{2}$. </p>

<p><strong>Question 1:</strong> What directed graphs can arise in this way? Certainly they must be simple and have no loops. Is that the only restriction? Alternatively, $\mathbb{P}(X_i &gt; X_j) &gt; \frac{1}{2}$ defines an irreflexive antisymmetric relation on $\{ 1, 2, ... n \}$. Which such relations arise in this way? </p>

<p><strong>Question 2:</strong> Does the answer change if we require the $X_i$ to all be defined on a finite sample space? </p>

<p><strong>Question 3:</strong> What if we require the $X_i$ to be independent? </p>

<p>It is known (see <a href=""http://en.wikipedia.org/wiki/Nontransitive_dice"">nontransitive dice</a>) that this graph can have directed cycles even if the $X_i$ are independent; in particular, the corresponding relation need not be transitive. </p>
",<probability>
"<p>Assume that we have a biased coin with probability $p_1$ of getting H and $1−p_1$ of getting T on the first trial, $p_2$ of getting H and $1−p_2$ of getting T on the second trial and so on such that
$2/3&lt;p_1&lt;p_2&lt;p_3...&lt;p_n&lt;1$. The probability $p_i$ of getting H increases as long as we get head in a row. If a tail appears, then we reset to probability $p_1$ of getting H in the next trail and so on.  </p>

<p>What is the expected number of trials to get $n$ H in a row?</p>
",<probability>
"<p>If a particle performs a random walk on the vertices of a cube, what is the mean number of steps before it returns to the starting vertex S? What is the mean number of visits to the opposite vertex T to S before its first return to S and what is the mean number of steps before its first visit to T?</p>

<p>Nobody ever explained random walks to me, so I find it all very odd right now. Maybe someone can explain how to handle these problems or you can link me to a site where these kinds of problems are explained well? Thanks a lot!</p>
",<probability>
"<p>If U has a $\chi^2$ distribution with v df, find E(U) and V(U).</p>

<p>By definition, $E(U)
=\int^{\infty}_{0} u\frac{1}{\gamma(\frac{v}{2})2^\frac{v}{2}}u^{\frac{v}{2}-1} e^\frac{-u}{2}\,du 
=\int^{\infty}_{0} \frac{1}{\gamma(\frac{v}{2})2^\frac{v}{2}}u^\frac{v}{2} e^\frac{-u}{2}\,du$.</p>

<p>How do I integrate this?</p>

<p>Note: This isn't a homework problem.</p>
",<probability>
"<p>Recently I took a Master's-level class on probability. I was very interested in the material, but the class itself was average. It used a textbook which I didn't care for (by Grimmett and Stirzaker). I've been looking for another text on probability to deepen my knowledge. I am familiar with measure theory, so I am fine with a book that employs it.</p>

<p>I am looking at Feller's book <em><a href=""http://rads.stackoverflow.com/amzn/click/0471257087"" rel=""nofollow"">An Introduction to Probability</a></em>, which seems to be well-regarded. I really like the examples and the way the material is covered. One thing I'm concerned about is that the book does not seem to involve measure theory. </p>

<p>How much of the soul of probability will I be missing if I read a book which covers it from non-measure-theoretic perspective? Will I have to consult another resource if I want to really understand the heart of what's going on?</p>

<p>Perhaps I should use Feller to become acquainted with the basics of probability theory, and supplement it by referring to a more theoretical text for the ""real"" proofs of certain theorems?</p>
",<probability>
"<p>Suppose a random walk on an infinite line $[...-3,-2,-1,0,1,2,3,...]$, starting from 0. Probability to go right or left are equal. 
Does such a process stationary?
I think that it is NOT, since the support of each step is different. I.e., $x_1\in{\{-1,1\}},  x_2\in{-2,0,2}, ...$. 
Thanks.</p>
",<probability>
"<p>Let a stochastic process defines as:
$$X(t+1)=A X(t)+B U(t)$$
with: $X(t) \in R^n$, $U(t) \sim N(0,Q_t)$, $Q_t$ semi-positive-definite of size $n \times n$, $X(0) \sim N(0,W_0)$, $A$ of size $n \times n$, $B$ of size $n \times n$.</p>

<p>Is there any condition on $A$ and $B$ to state the existence and the form of the conditional pdf $p_{X_t|X_{t-1}}(x_t|x_{t-1})$?</p>

<p>Thanks in advance.</p>
",<probability>
"<p>Let $X\geqslant 0$ be a random variable. Then, we have</p>

<p>$$\mathcal{E}(X)=\int_0^\infty P(X&gt;t)dt$$</p>

<p>(provided $\mathcal{E}(X)$ exists).</p>

<p>Suppose we have a finite data set $\{(d_1, a_1), \ldots, (d_n, a_n)\}$ consisting of pairs or real numbers where $d_i$ stands for a level (height) of some vessel and $a_i$ is the area of the surface of the vesel at level $d_i$.</p>

<p>How can I apply the above mentioned formula to calculate the (expected) capacity of the vessel?</p>
",<probability>
"<p>Let $X,Y$ random variables with $Y$ real valued. I was wondering if any inequality of the type: 
\begin{equation}
\mathbb{E}[f(X,Y)] \leq g \left[\sup_{\displaystyle s \in \mathbb{R}} \mathbb{E}[f(X,s)] \right]
\end{equation}</p>

<p>exists, where $g$ is some function. It seems very wrong at first sight, but I was wondering if you knew something of this type.</p>
",<probability>
"<p>Assume ""standard"" bingo (75 numbers) with the columns ranging the following inclusive ""semi-random"" values B: 1 to 15, I: 16 to 30, N: 31 to 45, G: 46 to 60, O: 61 to 75. By semi-random I mean restricted to a small range (15 at a time).  There is a free space in the middle of the 5x5 playing board.  Numbers (from 1 to 75 inclusive) are randomly drawn one a time without replacement (without any repeats in each game) and with equal probability of being drawn.  A win (Bingo) is defined as a completed line segment of 5 adjacent squares made only from the drawn numbers but which may include the free space (and must include it if it is beneficial).  A bingo card has 25 of these board squares arranged in a 5x5 matrix.</p>

<p>So my question is if there are 20 players, each with a unique playing card (randomly generated by computer out of I think 552 septillion possible playing cards), what are the chances/probability that 2 or more players will get Bingo on the same drawn number?.  For example, someone could win bingo with as few as 4 drawn numbers but likely it would take much more.  So I am asking if balls are drawn until at least one person wins, what are the chances that at least 2 people will win at the same time?  The game is considered finished / decided when there is at least 1 winner for that game.  You can assume that all players are good enough not to make any mistakes (not true in real bingo but assume here).</p>

<p>I am not sure how to set this up mathematically and because there are so many possible bingo cards, computer simulation of all of them is not a good idea.  Perhaps what can be done with simulation is to first simulate 20 legitimate bingo cards (out of 552 septillion), and then have the computer draw one random number at a time until we have at least 1 winner.  Do this for maybe 1 million trials and count how many have simultaneous multiwinners.  For example, after 11 balls drawn there are no winners yet for that game but on the 12 drawn ball, there are 2 or more winners.  I would like to know how often the multiwinner situation occurs.</p>

<p>I could probably do the simulation with a fair amount of work but wanted to know if this problem can be done mathematically or if is too difficult to set up.</p>

<p>One concern I see is that if one card has for its first column (the B column), from top to bottom, 1, 4, 7, 10, and 15 and some other card has for column B (also from top to bottom), 15, 10, 7, 4, and 1 in that order.  Problem there is even though the cards have different order for the B column numbers, if those 5 numbers are drawn, both players may win at the same time.  So my point is it makes a difference if we say (or not) that multiple bingo cards cannot have the same exact 5 numbers in a row, column, or diagonal but just in a different order.  That might be an interesting problem in itself to figure out how many fewer ""legit"" bingo cards there are with that constraint so someone could comment about it but the actual question is about the multiwinner probability.  I think the answer to the no permutation bingo card restriction is about 111 quadrillion legit bingo cards.</p>
",<probability>
"<p>I am trying to prove that if F is a cdf with finite right extreme ($\tau &lt; \infty $), then $G=F(\tau - 1/x) , x&gt;0$ is a cdf on $(0,\infty)$. For one of the steps:
$$
\lim_{x \to 0} F( \tau - 1/x)
$$
and this should be equal to zero. Intuitively $-1/x$ goes off to $-\infty$ so the limit should be $F(-\infty) =0$ but should I be making another step first? or does the jump make sense?</p>
",<probability>
"<p>John and Mary arrive under the clock tower independently. Let X be John's arrival time and let Y be Mary's arrival time. If John arrives first and Mary is not there then he will leave. If Mary arrives first then she will wait up to one hour before leaving. John's arrival time, X, is exponentially distributed with mean of 1. Mary's arrival time has density $f(y) = {2y\over 9}$, $0≤y≤3$. Calculate the probability they will meet. </p>

<p><strong>What I've tried.</strong> </p>

<p>I figured this problem should be the summation of two probabilities. The probability that Mary arrives before John + The probability that John arrives within an hour of Mary. </p>

<p>the joint distribution is $f(x,y) = {2y\over 9}e^{-x}$, therefore the first probability could be written as $P[X&gt;Y]$ of the joint distribution. </p>

<p>$$\int_0^3 \int_0^y f(x,y) dxdy$$</p>

<p>this gives the answer of .822, which is well above the answer given in the book of .1125, without the second probability even being found. </p>

<p>I'm not even sure how to set up the limits for the second probability.  </p>

<p>Any help would be appreciated. </p>
",<probability>
"<p>If I have that $\limsup_{n}E|X_n|^{r} \leq E|X|^{r}$, is that enough to show that $\{|X_n|^{r}:n\geq 1\}$ is uniformly integrable? I am not sure here if the limsup condition here is as strong as if I had a uniformly bound. Does anyone have any hints as to how I can work with such a definition? Thanks.</p>
",<probability>
"<p>Even before attempting the problem, I immediately defaulted to an answer: $\frac{1}{2}$.</p>

<p>I thought that this was a possible answer since the probability of flipping a head on one flip is definitely $\frac{1}{2}$.</p>

<p>I then worked through the problem:</p>

<p>Let E be the event in the problem statement.</p>

<p>The total number of possible outcomes of $10$ coin flips: $N = 2^{10}$</p>

<p>The total number of ways in which E can result:for $n=10,r=5, nCr= 252$</p>

<p>$P(E) =\frac{n}{N} = .246$</p>

<p>How do I correct my intuition?</p>
",<probability>
"<p>I met an interesting but challenging problem in my homework:</p>

<p>Suppose $n-1$ independent points $x_1$, $x_2$, ..., $x_{n-1}$ are uniformly distributed on unit interval [0,1]. These $n-1$ points seperate the unit interval into $n$ pieces. Suppose the lengths of these $n$ intrvals are $v_1$, $v_2$, ..., $v_n$. What is the probablity that $v_i &lt; a$ for $i = 1,2,...,n$ ?
Here $1/n &lt; a &lt; 1$ is a constant.</p>

<p>The joint distribution of $v_1$, $v_2$, ..., $v_{n-1}$ is a uniform distribution on a $n-2$ dimention simplx with $f(v_1, v_2,...,v_{n-1}) = (n-1)!$. The simplex is
$$v_i \geq 0, \; i=1,2,...,n-1$$
$$v_1 + v_2 + ... + v_{n-1} \leq 1$$
The proof of this density distribution is not easy.</p>

<p>I followed this idea but I found it's still hard. Maybe there are some other starting points to consider this problem.</p>
",<probability>
"<blockquote>
  <blockquote>
    <p>Consider the situation of decoding a 6-digit password that consists of the symbols A to Z and 0 to 9, where all possible combinations are tried randomly and uniformly. </p>
  </blockquote>
</blockquote>

<p>Consider the following decoding method: At first a combination is chosen randomly and uniformly. At the next trial a digit from this combination is chosen uniformly at random and its entry is substituted by a uniformly randomly chosen element from $\left\{A,...,Z,0,...,9\right\}$. This procedure is repeated until the password is found. </p>

<p>(a) What is the probability that the correct password will never be entered?</p>

<p>(b) What is the probability that eventually the same combination will be entered two consecutive times?</p>

<hr>

<p>I already asked how to get the anwers to (a) and (b) without using the here mentioned special decoding method and I got great help, see <a href=""http://math.stackexchange.com/questions/1012075/probability-concerning-a-6-digit-password"">Probability concerning a 6-digit password</a>.</p>

<p>Now I have to answer (a) and (b) using the decoding method and again I have enormous problems! Combinatorical thoughts are not my favourite business. Nevertheless I tried to find the probabilities in an analog way as it was shown to me in the linked thread. </p>

<p>Additionally, <em>I wonder if this task now maybe has something to do with Markov chains</em> because the lecture this task is from is about Markov chains.</p>

<hr>

<p>I think there are (at least) the two following ways to understand the described decoding strategy, which sense is meant?</p>

<p><strong>Sense 1</strong> <em>We choose (randomly and uniformly) one of the $36^6$ possible combinations. If it is the right, we stop. Otherwise we then choose (randomly and uniformly) one of the 6 digits and substitute it (randomly and uniformly) by a symbol out of the alphabet. Then we choose (randomly and uniformly) one of the remaining 5 digits and subtitute it and so on until we substituted all the 6 digits. If this was the right password, we stop. If not, we again start substituting the 6 digits (the digits of the combination that we chosed at the beginning, that is, we stick to this combination).</em></p>

<p><strong>Sense 2</strong> <em>Same as above with the difference that after we substituted all 6 digits and saw that it is the wrong password, we choose (randomly and uniformly) another combination out of the $36^6$ possibilities (it can be the same as before) and then substitute the digits of this new combination.</em></p>

<p><strong>I think that sense 1 is meant and thus I considered the task in this sense.</strong></p>

<p><strong>(a)</strong> Anyway, my result here is $0$, because as far as I see the probability not to have reached the right password after n passages is
$$
\left(1-\frac{1}{36^6}\right)\cdot\left(1-\prod_{k=1}^6\frac{1}{k\cdot 36}\right)^n
$$
and this tends to $0$ as $n\to\infty$.</p>

<p><em>Remark</em>: If we decode without this special method (see the linked thread) then the probability of (a) is 0, too.</p>

<p><strong>(b)</strong> The probability that we have eventually one pair of consecutive equal guesses is - to my results - 
$$
\sum_{n=0}^{\infty}\left(1-\frac{1}{36^6}\right)\cdot\left(\prod_{k=1}^6\frac{35}{k\cdot 36}\right)\cdot\left(\prod_{k=1}^6\frac{34}{k\cdot 36}\right)^n\left(\prod_{k=1}^6\frac{1}{k\cdot 36}\right)
$$</p>

<p><strong>Edit</strong></p>

<p>I think my last result for <strong>(b)</strong> was <em>not</em> correct, I think instead it has to be
$$
\sum_{n=0}^{\infty}\left(1-\frac{1}{36^6}\right)\cdot\left(1-\prod_{k=1}^k\frac{1}{k\cdot 36}\right)\cdot\left(1-\prod_{k=1}^{6}\frac{2}{k\cdot 36}\right)^n\cdot\left(\prod_{k=1}^{6}\frac{1}{k\cdot 36}\right).
$$</p>

<p>If I know compute the geometrical series and use that $1-\prod_{k=1}^{6}\frac{1}{k\cdot 36}\approx 1$, then I get that (with $p:=\frac{1}{36^6}$) the probability of (b) is
$$
\approx \left(\frac{1}{2}\right)^6\cdot (1-p)
$$</p>

<p><em>Remark</em>: When decoding without this method (see the linked thread) then the probability of (b) is $\frac{1}{2}\cdot (1-p)$. That is, using the method, if my result is correct, we have a much smaller probability for (b). So this decoding method is more efficient.</p>

<hr>

<p>Would be great to get a feedback from you to know if I am right. And, as mentioned, I am interested to know if the task has something to do with the context of Markov chains.</p>

<p>Ciao &amp; greetings</p>

<p>Salamo</p>
",<probability>
"<p>I am working through Hamming's <em>The Art of Probability</em> and am having trouble with a problem in the Bernouilli Trials section. The wording is the following</p>

<blockquote>
  <p>Expand the binomials in the probabilities of 0, 1, 2, and 3 occurrences, and show that the expansions cancel out to the next term provided $np \lt 1$. Hence if $np \ll 1$, the first term neglected in the expansion is close to the exact result for 4 or more events.</p>
</blockquote>

<p>I am assuming that the solution should give something like $\sum_{k = 0}^{3}B(k; n, p) = np + \mathcal{O}\left [(np)^4 \right ]$ but I can't actually get anything that cancels to the first order.</p>

<p>Using the recursion relation of Bernouilli trials, $B(k+1; n, p) = \frac{n - k}{k+1}\frac{p}{q}B(k; n,p)$, I get</p>

<p>$$(1 - p)^n \left (1 + \frac{np}{q} + \frac{n(n-1)}{2}\frac{p^2}{q^2} + \frac{n(n-1)(n-2)}{6}\frac{p^3}{q^3} \right)$$</p>

<p>Expanding this and keeping the terms 0th and first order in $np$ yields</p>

<p>$$(1-p)^n \left (1 - \frac{1}{6}\frac{6 p^3 -29 p^2 + 33 p - 12}{(1-p)^3} + \mathcal{O}\left [(np)^2 \right ]\right )$$</p>

<p>Am I misunderstanding the question? I expected the second term to cancel.</p>

<p><strong>Edit:</strong> I guess one could use the expansion for $\exp (-np) \approx \left ((1-p)^{\frac{1}{p}} \right )^{-np}$ and then expand it in a Taylor series, $\exp (-np) = 1 - np + \frac{(np)^2}{2} - \frac{(np)^3}{6} + \mathcal{O}\left [(np)^4\right ]$. This matches the terms of the form $(np)^k$ and they do have the opposite signs, but I don't quite understand why you can get away with ignoring the $q$ in the denominator. That is,</p>

<p>$$\begin{eqnarray}
&amp; \exp (-np) + \frac{np}{q} + \frac{n(n-1)}{2}\frac{p^2}{q^2} + \frac{n(n-1)(n-2)}{6}\frac{p^3}{q^3} \\ 
\approx &amp; 1 - np + \frac{(np)^2}{2} - \frac{(np)^3}{6} + \frac{np}{q} + \frac{n^2p^2}{2q^2} + \frac{n^3p^3}{6q^3} + \mathcal{O}\left [(np)^4\right ]\\
\approx &amp;1 + \mathcal{O}\left [(np)^4\right ] ?
\end{eqnarray}$$</p>
",<probability>
"<p>The hydrocarbon emissions are known to have decreased dramatically during the 1980s.</p>

<p>A study was conducted to compare the hydrocarbon emissions at idling speed, in parts per million (ppm), for automobiles of 1980 and 1990. Ten cars of each year model were randomly selected and their hydrocarbon emission levels were recorded. The data are as follows:</p>

<p>1980 models: 295 545 236 388 290 152 391 291 132 206</p>

<p>1990 models: 281 279 212 157 241 121 275 134 139 217</p>

<p>Assume that the hydrocarbon emission levels are normally distributed.</p>

<p>(a) Conduct a hypothesis test (by specifying the critical region) about the variability in hydrocarbon emission of cars of 1980 versus 1990. Use a 0.10 signiﬁcance level.</p>

<p>(b) Conduct a two-sided hypothesis test (by specifying the critical region) to compare the means of the hydrocarbon emission level of cars of 1980 and 1990 models. Use a 0.10 signiﬁcance level.</p>

<p>(c) Compute (or give bounds to) the p-value for the test in (b).</p>
",<probability>
"<p>A roulette from a casino contain 18 red cases, 18 black cases and 1 green cases. A player shows up with $10$dollars. He decides to bet $1$dollar on red 10 consecutives times. If it's red, he wins a dollar and if not he loses his dollar. Let $S$ be the the amount of money the player has after 10 bets. Find the value $S$ can have, then calculate $P(S&lt;3|S\leq18)$.</p>

<p>So the value S can take is every natural numbers $0\leq S\leq20$</p>

<p>but after that I'm confused on how to proceed. I guess we could do it using a density function but i don't know how.</p>

<p>Any help to point me in the right direction would be greatly appreciated.</p>

<p>Thank you.</p>
",<probability>
"<p>In the book, ""A Practical Guide to Quantitative Finance Interviews"", the following question is posed on page 75:</p>

<blockquote>
  <p>Jason throws two darts at a dartboard, aiming for the center.  The second dart lands farther from the center than the first.  If Jason throws a third dart aiming for the center, what is the probability that the third throw is further from the center than the first?  Assume Jason's skillfulness is constant.</p>
</blockquote>

<p>At first glance, it seems the second throw is irrelevant - since his skillfulness is constant, the second throw in no way influences his third throw.  Furthermore, it seems like this question can only be answered in terms of the distance from the center of the first toss.  Indeed, denote this distance by $D_1$.  Then assuming the area of the dart board is $1$, the probability that the third throw is further than the first is just the area of the annulus, which is given by $1 - \pi D_1^2$.</p>

<p>However, the solution given in this text is $\frac{2}{3}$, which is arrived at by enumerating the possible outcomes.  Let $D_i$ be the distance of the $i$th throw.  Then the possible outcomes assuming the second throw is further than the first are:
$$
D_3 &lt; D_1 &lt; D_2 \\
\boxed{D_1 &lt; D_3 &lt; D_2} \\
\boxed{D_1 &lt; D_2 &lt; D_3}
$$</p>

<p>The two boxed outcomes satisfy our event in question, so the probability must be $\frac{2}{3}$.  But, this seems to be answering a different question, namely,</p>

<blockquote>
  <p>What's the probability the third throw is not the best out of three, given the second throw is worse than the first?</p>
</blockquote>

<p>Are the two block-quoted questions really asking the same thing, and I've misunderstood the first one?</p>
",<probability>
"<p>If $A \sim N (\mu, \frac{1}{a})$ and $B \sim N(0, \frac{1}{b})$, and $S = A + B$, then what is
the distribution of $A$ given $S=s$? Assume $A$ and $B$ are independent.</p>
",<probability>
"<p>Let $X(t)$ be a stationary Gaussian process with mean $\mu$, variance $\sigma^2$ and stationary correlation function $\rho(t_1-t_2)$. If $X(t)$ is a white noise process the correlation function is given by the Dirac delta function $\rho(t_1-t_2) = \delta(t_1-t_2)$.</p>

<p>The integral of this process is given by:</p>

<p>$$I = \int_0^L X(t) \, dt$$</p>

<p>According to this <a href=""http://stats.stackexchange.com/questions/229877/max-and-min-variance-of-the-integral-of-a-stationary-stochastic-process/229896?noredirect=1#comment435077_229896"">CrossValidated post</a> the variance of $I$ is given by:</p>

<p>$$\text{Var}[I] = L\sigma^2$$</p>

<p>However this does not agree with the results I obtained through simulation. The approach is to discretise the white noise Gaussian process into $N$ independent normal variables. The integral can then be approximated through:</p>

<p>$$ I = \int_0^L X(t) \approx \frac{L}{N}\sum_{i=1}^NX_i$$</p>

<p>Where $X_i$ are indepedent random variables $X_i \sim \mathcal{N}(\mu,\sigma^2)$. In simulation I find that as $N$ grows large then $\text{Var}[I] \rightarrow 0$. Why does it not approach $L\sigma^2$? What is the problem with my approximation?</p>
",<probability>
"<p>Let $X, Y$ be conditionally independent given $Z$. Based on this, I am trying to get an intuition of what happens with the associated sigma-algebras and the conditional expectation. In particular, I want to calculate </p>

<p>$$ \mathbb{E}[B \vert X, Y,Z] = \mathbb{E}[B\vert \mathcal{F}]$$</p>

<p>where $B$ is an event and $\mathcal{F}$ is the sigma-algebra generated by $X,Y,Z$. Given the conditional independence stated above, I know that $\sigma(X)$ and $\sigma(Y)$ are conditionally independent given $\sigma(Z)$, but what does that mean for $\mathcal{F}$? Could I somehow partition this sigma-algebra into two independent components depending on $X,Z$ and $Y,Z$? In general, any intuition about the structure of $\mathcal{F}$ given conditional independence would be great.</p>
",<probability>
"<p>Given $$X_1\sim f_{X_1}(x_1)$$ and $$X_2\sim f_{X_2}(x_2)$$ are independent Random Variables, does this mean that $$Z=X_1+X_2$$ has distribution $$f_Z(z)\sim f_{X_1}f_{X_2} $$  or does it mean that the distribution is given by convolution of the two pdfs.</p>
",<probability>
"<p>In a Poker match, asumming 52 cards (13 of each type). This is the state:</p>

<ul>
<li><p>On my hand I have cards [3] and [4] of any type.</p></li>
<li><p>In table, there are these cards: [1] [2] [3] [?] [?], this is, two unknown cards and 1 [3].</p></li>
<li><p>There are other two players, each one with two unknown cards. So in the deck there are remaining 52 - 6 = 46 cards.</p></li>
</ul>

<p>The question is: <strong>what is the probability of other players to get Three of a kind composed of [3]. (Only three of a kind, no four) in ""river""?</strong></p>

<p>I can try to solve this problem partioning probabilities first for table, then for each case probability for next player, then for each case for the last player. But I'll need to solve the same problem for a table for 5 players, so this will be very laborious.</p>
",<probability>
"<p>Here is the problem that I'm solving:<img src=""//i.stack.imgur.com/6NGRt.jpg"" alt=""enter image description here""></p>

<p>So a) was quite easy (if I didn't miss anything :) )
Now for b): my CDF does converge to Exp(1) when x is from 0 to n</p>

<p>But if x more then n my function is constant 1 and Exp(1) is not. </p>

<p>Would it be a good explanation if I say that when n goes to infinity, x less than n with probability 1?
Would appreciate any constructive critique of my solution and advice on explaining part b)</p>
",<probability>
"<p>How do I solve the following?</p>

<p>$$
\lim_{x \rightarrow \infty} \int_0^{x} \left[ 1 + \text{erf} \left( \frac{\epsilon - a}{b} \right) \right] \left[ 1 + \text{erf} \left( \frac{\epsilon - c}{d} \right) \right] d\epsilon
$$</p>

<p>Related (but the problem is slightly different):
<a href=""http://math.stackexchange.com/questions/63026/integral-of-product-of-two-error-functions-erf"">Integral of product of two error functions (erf)</a></p>

<p>Or help me solve this (simpler version of the above)...</p>

<p>$$
\lim_{x \rightarrow \infty} \int_0^{x} \text{erf} \left( \frac{\epsilon - a}{b} \right) \text{erf} \left( \frac{\epsilon - c}{d} \right) d \epsilon
= \lim_{x \rightarrow \infty} \frac{4}{\pi} \int_0^{x} \int_0^{ \frac{\epsilon - a}{b} } \int_0^{ \frac{\epsilon - c}{d} } e^{-t^2 - s^2} ~ ds ~ dt ~ d\epsilon 
$$</p>

<p>Mathematica can provide a closed form solution in terms of erf if we change the order of integration from $ds ~ dt ~ d\epsilon$ to $d\epsilon ~ ds ~ dt$.</p>

<p>We can let,
$$
f(\epsilon, t) = \int_0^{ \frac{\epsilon - c}{d} } e^{-t^2 - s^2} ~ ds
$$</p>

<p>So we can focus on changing the order from $ds ~ dt ~ d\epsilon$ to $ds ~ d\epsilon ~ dt$.
$$
\int_0^{x} \int_0^{ \frac{\epsilon - a}{b} } f(\epsilon, t) ~ dt ~ d\epsilon
$$</p>

<p>To obtain,
$$
\int_0^{\frac{x-a}{b}} \int_{tb+a}^x f(\epsilon, t) ~ d\epsilon ~ dt - \int_{-\frac{a}{b}}^0 \int_0^{tb+a} f(\epsilon, t) ~ d\epsilon ~ dt \\
\int_0^{\frac{x-a}{b}} \int_{tb+a}^x \int_0^{ \frac{\epsilon - c}{d} } e^{-t^2 - s^2} ~ ds ~ d\epsilon ~ dt - \int_{-\frac{a}{b}}^0 \int_0^{tb+a} \int_0^{ \frac{\epsilon - c}{d} } e^{-t^2 - s^2} ~ ds ~ d\epsilon ~ dt
$$</p>

<p>Next, to switch the integral order from $ds ~ d\epsilon ~ dt$ to $d\epsilon ~ ds ~ dt$. Someone please continue the rest...</p>
",<probability>
"<p>I'm trying to prove urns version of Laplace's law of succession my professor suggested. Laplace's law states that the chance that the next trial is a success given $j$ successes out of the first $n$ is $\frac{(j+1)}{(n+2)}$. Here is how the problem states: </p>

<p>""If we have $n+k+1$ urns and urn $i$ has $i$ balls labeled $1$ and $n+k-i$ labeled zero. We pick an urn at random and draw $n$ balls from it without replacement say $j$ of them are ones. Show that the conclusion of Laplace's law holds for this setup. In other word, the chance that the next ball is a one is $\frac{(j+1)}{(n+2)}$.""</p>

<p>I've proved one version of the law, which close to this version <a href=""http://math.stackexchange.com/questions/102417/an-elementary-version-of-laplaces-method-of-succession"">An elementary version of Laplace&#39;s Method of Succession</a>. I tried to use similar approach but somehow my answer always in form of $k$ and I can't get rid of it. What is the intuition behind this $k$? Is it just to increase the complexity of the problem, or it has some meaning behind it?     </p>
",<probability>
"<blockquote>
  <p>The probability that a randomly chosen male has a circulation problem is 0.25.  Males who have a circulation problem are twice as likely to be smokers as those who do not have a circulation problem.  What is the conditional probability that a  male has a circulation problem, given that he is a smoker?</p>
</blockquote>

<p>Let:</p>

<p>C = Circulation Problem</p>

<p>S = smoker.</p>

<p>The problem is asking you to solve for $\Pr(C \mid S)$.  I thought I could solve problem by using a table and I completed it below.  I interpreted the statements as such:</p>

<p>1:  ""a randomly chosen male has a circulation problem is 0.25"":  $\Pr(C)=0.25$</p>

<p>2:  ""Males who have a circulation problem are twice as likely to be smokers as those who do not have a circulation problem."":  $\Pr(C \cap S) = 2x$ and $\Pr(C' \cap S) = x$</p>

<p>\begin{array}
{|c|c|c|c} \hline &amp; C &amp; C' &amp;  \\ \hline S&amp; 2x&amp; x&amp;\\ \hline S'&amp; &amp; &amp;\\ \hline &amp; 0.25 &amp; &amp;1\\ 
\hline . \end{array}</p>

<p>Which becomes:</p>

<p>\begin{array}
{|c|c|c|c} \hline &amp; C &amp; C' &amp;  \\ \hline S&amp; 2x&amp; x &amp; 3x\\ \hline S'&amp; &amp; &amp;\\ \hline &amp; 0.25 &amp; 0.75 &amp;1\\ 
\hline . \end{array}</p>

<p>So I did $\Pr(C\mid S) = \cfrac{\Pr(C \cap S)}{\Pr(S)}=\cfrac{2x}{3x}=2/3$ which is wrong.  The answer is 2/5!  </p>

<p><strong>Am I incorrectly interpreting statement 2 above as an intersection when instead it is a conditional probability?  In other words, should I be writing $\Pr(S\mid C)=2x$ and $\Pr(S\mid C')=x$?</strong></p>

<p>Thank you in advance.</p>
",<probability>
"<p>I've got a general question regarding a certain sticking point I often encounter. When tackling questions where for example an UMVUE (uniformly minimum-variance unbiased estimator) has to found I get stuck at the part where an expectation has to be determined. Maybe I'm overlooking certain theorems. </p>

<p>Example 1.  Consider a random sample of size $n$ with $X_i\tilde{}Poi(\mu)$. </p>

<p>I am able to find the UMVUE of $\mu$ and the MLE (Maximum Likelihood Estimator) of $\theta=e^{-\mu}$. But then for example follows the question: is this MLE unbiased for $\theta$?</p>

<p>If I want to determine the expectation, should I just write out the sum as follows from the definition of the expected value of a discrete distributed variable? This seems to lead to quite an ugly expression...</p>

<p>(<em>For this particular problem I found that Jensen's Inequality could come in handy to show biasedness (or actually non-unbiasedness))</em> </p>

<p><strong>But if I could summarize the problem I've got: how to rewrite expected values of functions of stochast in general?</strong>
Which theorems or properties should I use... for example I do use $E(aX)=aE(X)$ for $a$ a constant and $var(X)=E(X^2)-E(X)^2$ to rewrite certain expectations to a combination of simpler/known ones.</p>

<p>Example 2. Take a random sample $n$ of a distribution with pdf $f(x;\theta)=\theta x^{\theta -1}$ if $0&lt;x&lt;1$ and else $0$ and with $\theta &gt; 0$.</p>

<p>Find the UMVUE of $\theta$</p>

<p>Here I get stuck again at the expectation. I've got a sufficient and complete statistic in 
$\sum ln(X_i)$.</p>

<p>The expected value, i'd figure, is equal to $nE(ln(X_i))=-n/ \theta$  $\,\,\,\,$(where $[-ln(X)]=\frac{1}{\theta}$ was given as a hint).</p>

<p>But what if I want to determine the expected value of $\frac{1}{\sum_{i}ln(X_i)}$ ?</p>

<hr>

<p>In general: how to determine the expectations of functions of stochasts?
For example $E[ln(X)]$or $E[e^{\bar{X}}]$...?</p>
",<probability>
"<p>Let $X$~Binom($n,1/2$) and $Y$~Binom($m,1/2$) be independent. Calculate $P(X=Y)$.</p>

<p>My attempt:</p>

<p>Assume $m\le n$
$$P(X=Y)=\sum_{k=0,\ldots,m} P(X=k)P(Y=k)=(\frac{1}{2})^{n+m} \sum_{k=0,\ldots,m}{n \choose k}{m \choose k}$$</p>

<p>I have no idea how can I move further. Any ideas?</p>
",<probability>
"<p>I have a question regarding conditional probabilities. </p>

<p>Experiment: we toss a coin $10$ times. We count the amount of head and we toss that amount again. Let $X$ be the amount of heads in the first $10$ trials and $Y$ the total amount of heads. </p>

<p>Clearly, $X$~$bin(10, 1/2)$. I suppose $Y$~$bin(10+X, 1/2)$, but not sure about that though.</p>

<p>Question: what is $P[Y=5|X=7]$. But that seems pretty silly to me, because this basically says: 'What is the chance of having $5$ heads in total given that we have $7$ heads in the first $10$ trials'. Isn't that just $0$ since $Y \geq X$? </p>
",<probability>
"<p>Let $A,B,C$ be events. The event ""$A$ and $B$ occur but $C$ does not"" may be expressed as $A \cap B \cap C^c$. </p>

<p>(a)  Find an expression for the event ""at least one of B and C occur, but A does not""</p>

<p>(b)  Show that the probability of event in (a) is equal to</p>

<p>$\mathbb{P}(B)+\mathbb{P}(C)-\mathbb{P}(B\cap C)-\mathbb{P}(A\cap C)+\mathbb{P}(A\cap B \cap C)$</p>

<hr>

<p>I claim that the answer to (a) is $(B \cup C)\cap A^c$. Can someone confirm or deny?</p>

<p>I have no idea how to proceed from here. From previous work, I have proven the following results:</p>

<p>$\mathbb{P}(A\setminus B)=\mathbb{P}(A)-\mathbb{P}(A \cap B)$</p>

<p>$\mathbb{P}(A\cup B)=\mathbb{P}(A)+\mathbb{P}(B)-\mathbb{P}(A\cap B)$</p>

<p>My main concern about (a) is what exactly they mean by ""at least one"" and the use of the operator ""and"".</p>
",<probability>
"<p>Studying for a final:</p>

<blockquote>
  <p>1) Suppose we have four indistinguishable red balls, 6 indistinguishable blue balls, and 2 indistinguishable green balls. How many different color patterns can be obtained by arranging these balls in a straight line?</p>
</blockquote>

<p>I did ${12\choose4} {12\choose6} {12\choose2} = 30,187,080$ but that's definitely not correct.</p>

<blockquote>
  <p>2) A fair, ordinary six-sided die is colored red on one face, blue on two faces, and green on the remaining three faces. Find an explicit expression (but do not simplify it) for the probability that, in the 12 rolls fo this die, red will come up 4 times, blue will come up 6 times, and green will come up 2 times? <em>Hint: What is the probability of observing the sequence RBBRGBBRGBRB?</em></p>
</blockquote>

<p>I'm not really sure what to do and the hint only made me even more confused.</p>
",<probability>
"<blockquote>
  <p>If $X$ is a normally distributed random variable with standard deviation $\sigma=10$, and $P(X&gt;16.34) = .1212$, what is the mean (expected value) of $X$?</p>
</blockquote>

<p><strong>Attempt at solution:</strong>
This problem doesn't make sense... standard deviation is given, by the probability $X&gt;16.34$ has no upper bound, so how can this be computed? The expected value is just the summation of all the values which $=.1212$ here, so I'm not exactly sure what is being asked. please help! </p>
",<probability>
"<p>Let $X_n\xrightarrow[d]{}N(0,\sigma^2_x)$ and $Y_n\xrightarrow[d]{}N(0,\sigma^2_y)$.</p>

<p>$X_n, Y_n$ are not independent.</p>

<p>Can I say that $\left( \begin{array} {}
X_n \\
Y_n \end{array} \right)\xrightarrow[d]{}N(\mathbf{0},\mathbf{C})$, with $\mathbf{C}$ a variance-covariance matrix?</p>

<p>Would $\mathbf{C}=\left( \begin{array}{ccc}
\sigma^2_x &amp; \lim Cov(X_n,Y_n)  \\
\lim Cov(Y_n,X_n) &amp; \sigma^2_y \end{array} \right)$ ?</p>
",<probability>
"<p>I have a system of linear equations as follows.</p>

<blockquote>
  <p>$$M(p) = 1+\frac{n-p-1}{n}M(n-1) + \frac{2}{n} N(p-1) + \frac{p-1}{n}M(p-1)$$
   $$N(p) = 1+\frac{n-p-1}{n}M(n-1) + \frac{p}{n}N(p-1)$$
   $$M(1) = 1+\frac{n-2}{n}M(n-1) + \frac{2}{n}N(0)$$
   $$N(0) = 1+\frac{n-1}{n}M(n-1)$$</p>
</blockquote>

<p>$M(p)$ is defined for $1 \leq p \leq n-1$.  $N(p)$ is defined for $0 \leq p \leq n-2$.  What is $M(n-1)$?</p>
",<probability>
"<p>I have a stochastic process $X_t$, and I have a function $a(x | t)$ that reflects my beliefs about the value of $X_t$ ($a$ is a density function in its first parameter).  I am studying the properties of the stochastic process $Y_t = \int_0^t X_s ds$.  I am thinking of using the following method to find a density function $b(y | t)$ for $Y_t$:</p>

<p>Let $M_n$ be a function that returns the $n^{th}$ moment of a random variable.  By Fubini's Theorem, $\int_0^t M_n(X_s) ds = M_n(\int_0^t X_s ds) = M_n(Y_t)$.  Since this gives me a function that spits out all moments of $Y_t$, and since a random variable is uniquely determined by its moments, this is enough information to find $Y_t$.</p>

<p>My questions:
(1) Have I applied Fubini's Theorem correctly?  I'm having trouble formalizing the proof of that first equality, but I intuitively feel that it's true.
(2) Are there any other obvious flaws with this method?</p>

<p>Thank you.</p>
",<probability>
"<p>We are preparing this for an exam.</p>

<p>Given the division of a plane into a number of regions of different sizes. We would like to find, or guess, which is the biggest region, by doing the following.</p>

<p>We will shoot a number of random points at the plane, and then conclude that the region containing the most points, is also the biggest.</p>

<p>The question is: how do use Chernoff bounds to say how many random points we need to shoot, to know that we have found the biggest region with, say, 75% probability? </p>
",<probability>
"<p>All the workers at a certain company drive to work and park in the company’s lot. The company is interested in estimating the average number of workers in a car. Which of the following methods will enable the company to estimate this quantity? </p>

<ol>
<li>Randomly choose $n$ workers, find out how many were in the cars in
which they were driven, and take the average of the $n$ values.</li>
<li>Randomly choose $n$ cars in the lot, find out how many were driven
in those cars, and take the average of the $n$ values.</li>
</ol>

<p>My intuition goes for number 2, but I'm not able to justify it formally.</p>
",<probability>
"<p>There is a notation used in many sources (e.g. Wikipedia: <a href=""http://en.wikipedia.org/wiki/Exponential_family"" rel=""nofollow"">http://en.wikipedia.org/wiki/Exponential_family</a>) for the natural parameters of exponential family distributions which I do not understand, and I cannot find a description of.</p>

<p>With vector parameters and variables, the exponential family form has the dot product between the vector natural parameter, ${\boldsymbol\eta}({\boldsymbol\theta})$ and the vector sufficient statistic, ${\mathbf{T}}({\mathbf{x}})$, in the exponent. i.e. $e^{{\boldsymbol\eta}({\boldsymbol\theta})^{\top}{\mathbf{T}}({\mathbf{x}})}$. </p>

<p>However, many examples of these parameters for different distributions are vectors composed of matrices &amp; vectors. E.g. the multivariate Normal distribution has parameter $[\Sigma^{-1}\mu\space\space-\frac{1}{2}\Sigma^{-1}]$ and sufficient statistic $[\mathbf{x}\space\space\mathbf{xx^{\top}}]$.</p>

<p>So what are these ""vectors"" and moreover, how is the dot product between them defined? Does this notation have a name?</p>
",<probability>
"<p>Should I use a certain table for this question or should I use a special formula. A random value has a normal distribution with the mean 102.9 and the standard deviation 4.7. What are the probabilities that this random variable will also take on a value</p>

<p>a. Less than 110.1;</p>

<p>b. Greater than 95.6;</p>

<p>c. Between 104.5 and 105.9;</p>

<p>d. Between 98.7 and 150?</p>

<p>I have worked so far by finding the z value and im going on to find it through the table. </p>
",<probability>
"<p>Attempting to understand Exercise 20 (pdf page 44) in the paper: (Warning: large paper; small exercise)</p>

<p><a href=""http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/090310.pdf"" rel=""nofollow"">Bayesian Reasoning and Machine Learning</a> </p>

<blockquote>
  <p>The party animal problem corresponds to the network in g(3.14). The boss is angry and the worker has a headache - what is the probability  the worker has been to a party?</p>
  
  <p>When set to 1 the statements are true: P = Been to Party, H = Got a Headache, D = Demotivated at work, U = Underperform at work, A =Boss Angry. Shaded variables (A, H) are observed in the true state.</p>
  
  <p>$\begin{matrix} &amp; &amp; D \\ &amp; &amp; \downarrow \\ P &amp; \rightarrow &amp; U \\ \downarrow &amp; &amp; \downarrow \\ (H) &amp; &amp; (A)\end{matrix} $</p>
</blockquote>

<p>I would like to solve the following:</p>

<ul>
<li>Prove that p(P|H,A ) = a*p(P,H,A) where a is a constant.</li>
<li>Expand p(P, H, A) by marginalizing over the variables U and D.</li>
<li>how to compute 'a'</li>
</ul>

<p>Any help is greatly appreciated.</p>

<p>Thank You.</p>
",<probability>
"<p>would the answer to this question be right by any chance? Thanks.</p>

<p>A stain remover is tried out on various stain patches. It is found that 40% of stain is removed on the first application, but the remaining stains become resistant so that the proportion removed in any subsequent application is only one half that of the preceding application. Find the probability that a stain patch will survive 3 applications:</p>

<p>Answer: 40/( 100)  ×  20/( 100)  ×  10/( 100) =  8000/1000000 = 0.008</p>
",<probability>
"<p>Given  $x_1, x_2,..x_n ; x_i \in R$ that drawn from an unknown distribution $P(x)$ and a constant $ C$  $ 0 \leq C \leq 1$.
Find $x^{*}$ such that
$$P(x^{*}) =C$$.</p>

<p>We want to use the kernel density estimation to estimate $P(x)$ here. So:</p>

<p>$$P(x^{*}) \approx \frac{1}{N} \bigg( \sum_{i=1}^N K_h(x^{*};x_i) \bigg)$$ </p>
",<probability>
"<p>Let $p \in (0,1)$ and $n \in \mathbb{N}$. We consider a sample of $n$ i.i.d. Bernoulli variables $X_1,\dots,X_n$ with parameter p.</p>

<p>Computer $E[e^{\lambda\bar{X_n}}]$ such that $\bar{X_n}= \frac{1}{n} \sum_{i=1}^n X_i$</p>

<p>$E[e^{\lambda\bar{X_n}}]=E[e^{\frac{\lambda}{n} \sum_{i=1}^n X_i}]=e^{\frac{1}{n}}E[e^{\lambda\sum_{i=1}^n X_i}]= e^{\frac{1}{n}}E[e^{\lambda X_1}]\dots E[e^{\lambda X_n}]=e^{\frac{1}{n}}(1-p+pe^{\lambda})^n$</p>

<p>Is it correct ?</p>
",<probability>
"<p>I took mathematical probability last semester and now I am taking financial mathematics, but only probability was a pre requisite for financial math (no finance classes were required). These types of questions re confusing me because I don't quite understand financial terminology and I guess my professor thinks that we had taken finance classes in the past. Can someone explain what a portfolio is and what $V(O)$, $V(T)$, and $K_v$ is referring to in this question?</p>

<blockquote>
  <p>Let $A(0)=90$, $A(T)=100$, $S(0)=25$ dollars and let<br>
    $$S(T) =
\begin{cases}
30,  &amp; \text{with probability } p \\
20, &amp; \text{with probability } 1-p
\end{cases}$$</p>
  
  <p>where $0 &lt; p &lt; 1$. For a portfolio with $x=10$ shares and $y=15$ bonds, calculate $V(0)$, $V(T)$, and $K_V$.</p>
</blockquote>

<p>I know what a random variable is and how to solve for expectation because I learned that in probability, but I just don't know what these finance terms are refering to?</p>
",<probability>
"<p>$\DeclareMathOperator{\var}{var}\DeclareMathOperator{\cov}{cov}$</p>

<blockquote>
  <p>The signal-to-noise ratio (SNR) of a random variable quantifies the accuracy of a measurement of a physical quantity. It is defined as $E^2[X]/\var(X)$ and is seen to increase as the mean, which represents the power of the measurement error, that is, $X - E[X]$, decreases. For example, if $X\sim\mathcal{N}(\mu, \sigma^2)$, then $\text{SNR} = \mu^2/\sigma^2$. Determine the SNR if the measurement is $X = A + U$, where $A$ is the true value and $U$ is the measurement error with $U\sim\mathcal{U}(-1/2, 1/2)$. For an SNR of $1000$, what should be $A$?</p>
</blockquote>

<hr>

<p>The mean and variance of a uniform random variable is $E[U] = 0$ and $\var(U) = \frac{1}{12}$. Since the SNR is $1000$, we have that
  $$
  1000 = \frac{\mu^2}{\sigma^2}\Rightarrow 10\sqrt{10} = \frac{\mu}{\sigma}
  $$
where $\mu = E[X] = E[A + U] = E[A] + E[U] = E[A]$ and $\sigma^2 = \var(X) = \var(A + U) = \var(A) + \var(U) + 2\cov(A, U) = \var(A) + \frac{1}{12} + \cov(A, U)$.</p>

<ol>
<li>Without knowing anything about $A$ how do I find $E[A]$ and $\var(A)$?</li>
<li>What is meant by what should $A$ be? Is it asking what type of distribution?</li>
</ol>
",<probability>
"<p>Define a sequence of r.v.'s {$X_n$}$_{n\ge 1}$ iteratively, such that $X_1\sim\text{Unif}(0,1]$ and $X_{n+1}\sim\text{Unif}(0,X_n]$. </p>

<p>Could someone please explain why this is equivalent to:</p>

<p>Let a sequence of r.v.'s {$U_n$}$ \stackrel{iid}{\sim}\text{Unif}(0,1]$. For a sequence of r.v's {$X_n$}$_{n\ge 1}$, set $X_1=U_1$. Then set $X_{n+1}=U_{n+1}X_{n}$.</p>

<p>In general, what about the construction of $X_n$ in the first formulation tells us that we can construct a sequence of products in the second formulation?</p>

<p>Thank you.</p>
",<probability>
"<p>We say that $X$ is smaller than $Y$ in distribution (which we denote by $X \stackrel{D}{&lt;} Y$) if $\mathbb{E}[h(X)] \leq \mathbb{E}[h(Y)]$ for all positive, increasing and bounded functions $h$.</p>

<p>We say that $X$ and $Y$ are equal in distribution (which we denote by $X \stackrel{D}{\sim} Y$) if $X \stackrel{D}{&lt;} Y$ and $Y \stackrel{D}{&lt;} X$</p>

<p>I've already answered the following question :</p>

<blockquote>
  <ol>
  <li>Prove that $X \stackrel{D}{&lt;} Y$ if and only if the cumulative
  distribution functions $F$ and $G$ of $X$ and $Y$ respectively
  satisfy $F \geq G$</li>
  </ol>
</blockquote>

<p>Indeed, it suffices to take $h(x) = 1\!\!1_{x \geq c}$ for different values of $c$.</p>

<p>But I don't know how to answer the following two questions :</p>

<blockquote>
  <ol start=""2"">
  <li>Prove that $X \stackrel{D}{&lt;} Y$  if and only if we can find two random variables $X'$ and $Y'$ such that $X \stackrel{D}{\sim} X'$, $Y \stackrel{D}{\sim} Y'$ and $X' \leq Y'$ a.s.</li>
  <li>Suppose that $X \leq Y$ a.s. and $X \stackrel{D}{\sim} Y$. Prove that $X = Y$ a.s.</li>
  </ol>
</blockquote>

<p>Can I have some help on these two questions ?</p>
",<probability>
"<p>Two processes $(X_t)_{t \in T}$, $(Y_t)_{t \in T}$ are known to be equal in distribution if and only if they agree on all finite-dimensional distributions, i.e.,
for all $t_1$, $t_2$, $\ldots$, $t_n$, $n \in \mathbb{B}$,
$$
(X_{t_1}, \ldots X_{t_n}) \overset{d}{=}   (Y_{t_1}, Y_{t_2}, \ldots Y_{t_n})
$$</p>

<p>How to give sense of this by using the $\pi-\lambda$ theorem, when the process takes value on a countable state space?</p>
",<probability>
"<p><strong>Q.1)</strong> A family has $n$ children, $n\geq2$. We ask from the father, ""Do you have at least one daughter named Lilia?"" He replies, ""Yes!"". What is the probability that all of their children are girls? </p>

<p>In other words, we want to find the probability that all $n$ children are girls, given that the family has at least one daughter named Lilia. </p>

<p>Here we can assume that if a child is a girl, her name will be Lilia with probability $\alpha\ll1$ independently from other children's names. If the child is a boy, his name will not be Lilia.</p>

<p><strong>Q.2)</strong> In a family of $n$ children. We pick one among them and found that she is a girl. What is the probability that all children are girls?</p>

<hr>

<p>My solution to Q.1)</p>

<p>$$
\begin{equation}
\begin{split}
P(\text{all are girls | at-least one named Lila}) &amp;= \frac{P(\text{at-least one name Lila | all are girls})\ \times\ P(\text{all are girls})}{P(\text{at-leat one named Lila})}\\
&amp;= \frac{{n\choose1}\ \alpha\ (1-\alpha)^{n-1}\ \times\ \frac{1}{2^n}}{{n\choose1}\ \alpha \ \frac{1}{2^{n-1}}}
\end{split}
\end{equation}$$</p>

<p>My solution to Q.2)</p>

<p>$$\begin{equation}
\begin{split}
P(\text{all are girls | at-least one girl}) &amp;= \frac{P(\text{at-least one girl | all are girls})\ \times\ P(\text{all are girls})}{P(\text{at-least one girl})}\\
&amp;= \frac{1\ \times\ \frac{1}{2^n}}{{n\choose1}\ \frac{1}{2} \ \frac{1}{2^{n-1}}}
\end{split}
\end{equation}$$</p>
",<probability>
"<p>I am reading a paper and there is a theorem which says:</p>

<p>Let $(S, A, \mu)$ be a probability space, and let $\theta$ be a $\mu$-measure
preserving transformation on it. Then
there exists a subset $S_0 \subset S$ of full $\mu$-measure such that ....</p>

<p>What does ""there exists a subset $S_0 \subset S$ of full $\mu$-measure"" mean?</p>
",<probability>
"<p>I'm having a bit of trouble with this problem.</p>

<p>Three cards are drawn from a pack of regular playing cards. What's the probability of getting different suits, as well as different denominations (number, face, etc.)?</p>

<p>Bonus question. In the above case, it isn't specified whether the cards are drawn simultaneously, or one by one. Would it make a difference?</p>
",<probability>
"<p>16 players, $S1,S2...S16$ are divided into eight pairs. What's the probability of only one of $S1$ or $S2$ coming out as one of the eight quarterfinalists?</p>

<p>To clarify, only one of them qualify. And all players are of equal strength. And, the pairings are completely random.</p>
",<probability>
"<p>when a biased coin is tossed 5 times the probability of having 2 heads is same as that of having 3 (and not 0) What is the probability of having heads exactly 3 out of 5?</p>
",<probability>
"<p>This problem seems to me a brain teaser, in the form of a probability puzzle. I would be really grateful if someone could help me to solve this simple conditional probability problem.
We have a $n \times n$ $(0,1)$-matrix $M$. Let $R$ be the set of rows and let $C$ be the set of columns. Finally, we indicate the $i$-th row and column with $R_i$ and $C_i$ respectively, and the set $\{1, 2, ..., n\}$ with $[n]$.</p>

<p>We have the following information:</p>

<p>(1) Given any $i \in [n]$ and $y \in \{0,1\}$, we know the number $f_{y}(R_i)$ of indices $k \in [n]$ such that $M_{i, k}=y$. Analogously, we also know the number $f_{y}(C_i)$ of indices $k \in [n]$ such that $M_{k, i}=y$.</p>

<p>(2) Given any pair of integers $(i,j) \in [n] \times [n]$ and any value $y \in \{0,1\}$, we know the number $f_{y, 1}(R_i, R_j)$ of vector component indices $k$ such that $M_{j,k}=1$ when $M_{i,k}=y$.  </p>

<hr>

<p>We select at the same time three integers $i$, $j$ and $k$ uniformly at random in $[n]$. We then read the value of $M_{i, k}$ and observe it is equal to a certain value $y$ (where therefore $y \in \{0,1\}$). </p>

<p>QUESTION: How can we calculate the probability that $M_{j,k}=1$?</p>

<p>Using the second part of information (1) solely, I guess one would answer $f_{1}(C_k)/n$. On the other hand, using all information except the second part of (1), I guess one would answer $f_{y, 1}(R_i, R_j)/f_{y}(R_i)$ (please observe $f_{y}(R_i)$ cannot be null). I do not know how to combine all the information.</p>

<p>Thank you very much for your help!
Cheers,
T.</p>
",<probability>
"<p>I have set of sample which are grouped in different size. If I want to find probability of an event in each group, how can I normalize the probability over all the groups. For example, Let say I have 3 set of samples each sized 3, 8 and 30 respectively. If the probability of an event to occur in set $1$ is $\frac{1}{3}$, in set $2$ it is $\frac{3}{8}$ and in set $3$ it is $\frac{4}{30}$. How can I normalize the probability so that highest probability is assigned for set $3$ then set $2$ and then set $1$.</p>
",<probability>
"<p>Let $X_{n,k}$ be a double sequence of random variables. </p>

<p>Assume for each fixed $k$, $X_{n,k}\xrightarrow[n\rightarrow\infty]{p}\alpha_k$, where $\alpha_k$ is a non-random scalar. Assume further that $\alpha_k\xrightarrow[k\rightarrow\infty]{p.w} \alpha$, where $\alpha$ is again non-random. Is it possible to show the following?</p>

<p>$$X_{n,k}\xrightarrow[n,k\rightarrow\infty]{p} \alpha$$</p>

<p>My attempt: Let $f$ be any arbitrary Lipschitz Cont. function bounded by $M&lt;\infty$ and satisfying the contraction $\vert f(x_1) - f(x_2)\vert \leq K\vert x_1 - x_2\vert$ for some $K$ (by definition). Then consider
\begin{align}
\mathbb{E}\big\vert f(X_{n,k}) - f(\alpha)\big\vert&amp;\leq\mathbb{E}\big[\big\vert f(X_{n,k}) - f(\alpha_k)\big\vert\big] + \big\vert f(\alpha_k) - f(\alpha)\big\vert\\
&amp;=\mathbb{E}\big\vert f(X_{n,k}) - f(\alpha_k)\big\vert\mathbb{1}_{(\vert X_{n,k} - \alpha_k\vert\leq \epsilon)} + \mathbb{E}\big\vert f(X_{n,k}) - f(\alpha_k)\big\vert\mathbb{1}_{(\vert X_{n,k} - \alpha_k\vert&gt; \epsilon)} + \big\vert f(\alpha_k) - f(\alpha)\big\vert\\
&amp;\leq K\epsilon + M\mathbb{P}[\vert X_{n,k} - \alpha_k\vert&gt; \epsilon] + K\vert \alpha_k - \alpha\vert
\end{align}</p>

<p>Now, we know that there exists a $K^*$ large enough such $K\vert \alpha_k - \alpha\vert\leq K\delta$ for all $\delta&gt;0$</p>

<p>Similarly, $\mathbb{P}[\vert X_{n,k} - \alpha_k\vert&gt; \epsilon]&lt;\delta$ for large enough $N^{*}$.</p>

<p>Is it enough to choose $N = \max(N^{*},K^{*})$ to show that $\mathbb{E}\big\vert f(X_{n,k}) - f(\alpha)\big\vert\leq \delta$ for all $n,k\geq N$? Then I could use the Portmanteau lemma to show the rest.</p>
",<probability>
"<p>How do I calculate the pdf for the following case?  In general, if we have 2 r.v. $x,y$ which are normal, then the pdf of the difference of 2 r.v. which are Gaussian will also be Gaussian, I think with mean $\mu_Z = \mu_x - \mu_y$ and variance $\sigma^2_Z = \sigma^2_x + \sigma^2_y$.</p>

<p>Based on this premise, how to find the pdf from a Gaussian Mixture model (GMM). The time series $Z$ has the pdf $f_Z$ which is GMM distribution. The time series contains 2 r.v $x,y$.  So, both the r.v. together constitute a GMM. Considering that there are only 2 mixtures.
I have observations of multivariate time series $Z_i = {[x_i,y_i]}_{i=1}^n$ where $x,y$ are the random variables. The pdf of $Z$ is Gaussian mixture model (GMM). The parameters of the GMM model are learnt through Expectation Maximization.   How to get the functional form for the pdf $f(d_i) = f(x_i-y_i)$ where $d_ i = x_i-y_i$. Thank you for help.</p>
",<probability>
"<p>I am probably missing something obvious but here goes: Lets say we have ten people, and over a period of five days, five of them die. One does each day
The probability of any person dying on Day 1 is 1/10, Day 2 is 1/9, and so on.
I started off with the (obvious) premise that the probability of dying was 1/2. I then calculated that there were 10P5 possible permutations of YES DYING and of NOT DYING. There are 9P4 permutations that just include NOT DYING. 9P5/10P5 = 1/2.</p>

<p>PROBLEM: Some of those 10P5 possibilities include YES DYING more than once, which is not really an valid possibility. So now I am left with the absurd situation where the probability of dying is less than 1/2!
Where is my error?
Thanks</p>
",<probability>
"<p>Fifty marbles numbered 1 to 50 are placed in a barrel and twenty drawn one at a time without replacement. What is the probability that at least one will be drawn in sequence? i.e. 1 is drawn first, two is drawn second etc.</p>
",<probability>
"<p>I <em>understand</em> the concept of standard deviation as the <strong>square root</strong> of the <strong>square</strong> of the <strong>mean</strong> of <strong>each sample value - the <em>mean</em> of the sample values</strong>.<br>
Here is the mathematical representation (I've solved out the proof independently) :</p>

<p>1.) $\sigma = \sqrt{\{x^2\} - \{x\}^2}$<br>
where $\{\,\}$ is the average and $x$ is a sample value.  </p>

<p>2.) There is an alternate mathematical representation using summation sigma (for discrete random variable also) that more people are probably acquainted with. <strong>Or does this one have a slightly different meaning, I'm not sure?</strong> </p>

<p>My question is, can someone explicitly show me the derivation for the standard deviation of a binomial distribution.<br>
Here is  the information I know:</p>

<p>1.) Final formula:  $\sigma = \sqrt{pqN}$</p>

<p>2.) $p =$ probability of event A occurring AKA $p = n(A)/N$</p>

<p>where $A$ is an event OR <strong>the first binomially distributed random variable</strong>, $n(A)$ is the amount of times event $A$ happens, and $N$ is the total number of events</p>

<p>3.) $q =$ probability of event $B$ occurring AKA $p = n(B)/N$ where $B$ is an event OR <strong>the second binomially distributed random variable</strong>, $n(B)$ is the amount of times event $B$ happens, and $N$ is the total number of events. Also, $q = 1-p$ because there are only two events, $A$ and $B$.</p>
",<probability>
"<p>I am currently working on conditional probability and I am somewhat confused about how exactly to complete this problem. I know that to find conditional probability that you utilize:</p>

<p>$$P(A|B) = \frac{P(A\cap B)}{P(B)}$$</p>

<p>I also know that there is a $6/36$ chance to roll a sum of 7, and that if you roll a sum of 7 that there is a $4/6$ chance to get a sum without using the number 2. I do not know what else is necessary however in order to finish this problem and to find $P(A|B)$.</p>
",<probability>
"<p>Let $B=(B_t)_{t\ge 0}$ be a Brownian motion on a probability space $(\Omega,\mathcal{A},\operatorname{P})$. By definition of $B$, for $\operatorname{P}$-almost every $\omega\in\Omega$ $$[0,\infty)\to\mathbb{R}\;,\;\;\;t\mapsto X_t(\omega)\tag{1}$$ is continuous. Generally, a stochastic process $X=(X_t)_{t\in I}$ on $(\Omega,\mathcal{A})$ with $I\subseteq\mathbb{R}$ can be viewed as a mapping $$X:\Omega\mapsto\mathbb{R}^I\;,\;\;\;\omega\mapsto \left(t\mapsto X_t(\omega)\right)\tag{2}$$ I've frequently read that $B$ is considered to be a mapping $\Omega\to C\left([0,\infty)\right)$, where $C(I)$ is the space of continuous functions $I\to\mathbb{R}$.</p>

<hr>

<p>Why can we do that? Clearly, there exists a $\operatorname{P}$-null set $N\subseteq\mathcal{A}$ such that $(1)$ is continuous for all $\omega\in\Omega\setminus N$. Moreover, I know that we can alter measurable functions on null sets without changing their measure related properties. However, is it guaranteed that we can alter $B$ on all null sets on which $(1)$ is not continuous such that $(1)$ is continuous for all $\omega\in\Omega$?</p>

<hr>

<p>Remark: Maybe we can use the <em>Kolmogorov-Chentsov theorem</em> to prove that $(1)$ can indeed be assumed as continuous for all $\omega\in\Omega$. The theorem can be formulated as follows:</p>

<p>Let $X=(X_t,t\ge 0)$ be a real-valued stochastic process such that for all $T&gt;0$, there exists $\alpha,\beta,C&gt;0$ with $$\operatorname{E}\left[\left|X_t-X_s\right|^\alpha\right]\le C|t-s|^{1+\beta}\;\;\;\text{for all }s,t\in [0,T]]$$ Then, there exists a <em>modification</em> of $X$ which is locally Hölder-continuous of order $\gamma\in \left(0,\frac \beta\alpha\right)$.</p>

<p>Stochastic processes $X,Y$ are called <em>modifications</em> of each other, if $X_t=Y_t$ almost surely.</p>
",<probability>
"<p>Here is one I'm stumped on. </p>

<blockquote>
  <p>A ball can be in any one of $n$ boxes. It is the $i^{th}$ box with probability $p_i$. If the ball is in the $i^{th}$ box a search of that box will uncover it with probability $\alpha_i$. Given that a search of box $i$ did not uncover the ball, what is the conditional probability the ball is actually in box $j$ where $i,j=1,\ldots,n$? </p>
</blockquote>

<p>I tried fooling around with the multinomial distribution but kept getting tripped up. Any thoughts?</p>
",<probability>
"<p>Is there any way to simplify the following expression?</p>

<p>$$
\sum_{d = 1}^k \left(\sum_{i=1}^d \frac{1}{i}\right) \frac{{n-t \choose d}{t \choose k-d}}{{n \choose k}}
$$</p>

<p>This formula comes from the expected number of record lows over the first $k$ elements in a permutation of $[1,n]$, given some minimum threshold $t$ below which the elements don't count as a record low. </p>

<p>Let $L$ be the number of record lows, and let $d$ be the number of elements above the threshold.
$$
E[L] = E[E[L|d]] = \sum_{d=1}^k E[L|d]\cdot P(d)
$$</p>

<p>where $P(d)$ is a <a href=""http://en.wikipedia.org/wiki/Hypergeometric_distribution"" rel=""nofollow"">hypergeometric</a> distribution, with n-t success states, population size $n$, and $k$ draws.</p>

<p>This comes up for example in this question: <a href=""http://math.stackexchange.com/q/139523/23846"">Expected number of cards in the stack?</a></p>
",<probability>
"<p>Consider the density $f(x,y)=\large\frac{1}{2\pi}\frac{1}{\sqrt{1-x^2-y^2}}$ on the unit disk centered at the origin. There is a particular characterization of this distribution: it is the unique circularly symmetric distribution whose projections onto any line through the origin are uniformly distributed. </p>

<p>Showing the projections of $f(x,y)$ are uniform is simple calculus. However I can't seem to think of an elegant proof for uniform projections implying $f$ must have the above density. If we let $R$ denote any rotation of coordinates $x,y\rightarrow x',y'$, then by assumption, $f(x,y)=R\circ f(x,y):=f(x',y')$. It would then suffice to show that $f(x,0)=\large\frac{1}{2\pi}\frac{1}{\sqrt{1-x^2}}$. Writing out the projected density as $u(x)$:</p>

<p>$$u(x):=\int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}}f(x,y)dy$$</p>

<p>and we must have that $u(x)=1/2$ (being uniform on $[-1,1]$). Differentiating in $x$ with Leibnitz's rule seems to get nowhere. I've also tried considering the characteristic function of $f$ but got nowhere. </p>

<p>If it helps, $f(x,y)$ arises from projecting the uniform distribution on the sphere to the $x,y$ plane. So in essence this is Archimedes rule for the sphere inscribed in a cylinder: the surface areas are equal. My gut feeling is that this is not entirely dissimilar from showing that the multivariate Gaussian distribution is the only rotationally invariant distribution with independent components.</p>
",<probability>
"<p>is there a simple way to prove that $X_n \rightarrow_{L^p} X$ implies that $\mathrm{E}(X^p_n) \rightarrow \mathrm{E}(X^p)$? the proof for $p=1$ is easy. but what about the case $p&gt;1$? I would appreciate any comments. many thanks!</p>
",<probability>
"<p>I have encountered two definitions of weak convergence in $L^1$:</p>

<p>1) $X_n\rightarrow X$ weakly in $L_1$ iff $\mathrm{E}(X_n\mathrm{1}_A)\rightarrow \mathrm{E}(X\mathrm{1}_A)$ for every measurable set $A$.</p>

<p>2) $X_n\rightarrow X$ weakly in $L_1$ iff $\mathrm{E}(X_n f)\rightarrow \mathrm{E}(X\mathrm{1}f)$ for every (essentially) bounded measurable function $f$.</p>

<p>my question: are 1) and 2) equivalent?</p>

<p>I see that 2) implies 1) (indicators are bounded), but I have difficulties establishing that 1) implies 2). I tried approximating $f$ by simple functions $f_m$, say, assuming $X_n,X$ are nonnegative for simplicity; the problem: I cannot justify the interchange in the order of taking the limits (first with $n$, and then with $m$). any ideas? I would appreciate any sort of help. many thanks!</p>
",<probability>
"<p>This question is from DeGroot's ""Probability and Statistics"" :</p>

<blockquote>
  <p><strong>Unbounded p.d.f.’s.</strong> Since a value of a p.d.f.(probability density function) is a probability density, rather than a
  probability, such a value can be larger than $1$. In fact, the values of the following
  p.d.f. are unbounded in the neighborhood of $x = 0$:$$f(x) =
\begin{cases}
\frac{2}{3}x^{-\frac{1}{3}}  &amp; \text{for 0&lt;$x$&lt;1,} \\
0 &amp; \text{otherwise.}  \\
\end{cases}$$</p>
</blockquote>

<p>Now, I don't know how the p.d.f. can take value larger than $1$.Please let me know the difference between the probability and probability density.</p>
",<probability>
"<p>I asked <a href=""http://math.stackexchange.com/questions/1402463/2011-aime-problem-12-probability-round-table"">Here</a> This question and I am still confused. I got that, for at least one group together there are:</p>

<p>$$3 \cdot 9 \cdot \binom{6}{3, 3}$$</p>

<p>But why do we subtract: $3 \cdot 9 \cdot 4$. </p>

<p>Lets begin with $AAA$ suppose circularly. (We multiply by $3$ in the end for $BBB, CCC$ so not to worry about that). There are $9$ possible places for $AAA$. I saw that: $BCBCBC, CBCBCB$ are two already. Then :$BBCBCC, BCBBCC$, etcc... that is more than $4$.</p>

<p>What am I missing here? </p>
",<probability>
"<p>Three players A, B and C take turns to roll a fair die; they do this in the order ABCABC... 
(a) Find the probability that, of the three players, A is the ﬁrst to throw a 6, B is the second, and C is the third. 
(b) Find the probability that the ﬁrst 6 to appear is thrown by A, the second 6 to appear is thrown by B, and the third 6 to appear is thrown by C.</p>

<p>I am confused as to the difference between the two questions. 
Also, can anyone give me shorter ways to solve the first part?</p>
",<probability>
"<p><strong>Question</strong>: 
Consider n independent tosses of a $k$-sided fair dice. Let $X_i$ be the number of tosses that result in $i$.</p>

<p>What is the covariance $\mathrm{cov}(X_1,X_2)$ of $X_1$ and $X_2$.</p>

<hr>

<p>\begin{align}
\mathrm{cov}(X_1,X_2) = \mathbf{E}[X_1X_2] - \mathbf{E}[X_1]\mathbf{E}[X_2]
\end{align}</p>

<p>I get a different $\mathbf{E}[X_1X_2]$ than the given solution.</p>

<p><strong>The solution given is</strong></p>

<p>Let $A_t$ (respectively, $B_t$) be a Bernoulli random variabe that is equal to 1 if and only if the $t$th toss resulted in 1 (respectively, 2). We have <strong>E</strong>$[A_tB_t] = 0$ (since $A_t \neq 0$ implies $B_t \neq 0$)</p>

<p>$$ \mathbf{E}[A_tB_s] = \mathbf{E}[A_t]\mathbf{E}[B_t] = \frac{1}{k} \cdot \frac{1}{k}   \mathrm{for}\  s \neq t.$$</p>

<p>Thus,</p>

<p>\begin{align}
\mathbf{E}[X_1X_2] &amp;= \mathbf{E}[(A_1+\cdots + A_n)(B_1+\cdots B_n)]\\
 &amp;=n\mathbf{E}[A_1(B_1+\cdots+B_n)] = n(n-1)\cdot   \frac{1}{k} \cdot \frac{1}{k} \\
&amp;= \frac{n(n-1)}{k^2}
\end{align}</p>

<p>and</p>

<hr>

<p><strong>My solution that gives slightly off answer</strong></p>

<p>My approach uses iterated expectations.
\begin{align}
\mathbf{E}[X_1X_2] = \mathbf{E}[\mathbf{E}[X_1X_2|X2]]
\end{align}
If I had $k$ instead of $k-1$ in the following equation, I would get an answer identical to given solution but if I already know $X_2=x_2$ then dice tosses should be identically distributed among k-1 remaining options, right?
\begin{align}
\mathbf{E}[X_1|X_2=x_2] = \frac{n-x_2}{k-1} 
\end{align}</p>

<p>Then 
\begin{align}
\mathbf{E}[X_1X_2|X_2] = \frac{n-X_2}{k-1} \cdot X_2
\end{align}
\begin{align}
\mathbf{E}[\mathbf{E}[X_1X_2|X_2]] = \mathbf{E}[\frac{nX_2-{X_2}^2}{k-1}]
\end{align}</p>

<p>given $\mathbf{E}[{X_2}^2] = \mathbf{E}[{X_2}] = \frac{n}{k}$</p>

<p>\begin{align}
\mathbf{E}[X_1X_2] = \frac{n(n-1)}{k(k-1)}
\end{align}</p>

<p>So my answer differs to the solution on the matter of $\mathbf{E}[X_1X_2]$</p>

<p>\begin{align}
\mathbf{E}[X_1X_2] = \frac{n(n-1)}{k^2} \neq \frac{n(n-1)}{k(k-1)}
\end{align}
Whats wrong with my logic? Or maybe MIT is wrong.</p>
",<probability>
"<p>Let $X$, $Y,$ and $Z$ be random variables. (There are no restrictions on these variables, but you may assume that these are continuous random variables if you want.) Suppose that $X$ and $Z$ are independent, and also suppose that $Y$ and $Z$ are independent. Does it follow that $\mathrm{cov}(XY,Z)=0$? (I understand that $XY$ and $Z$ may not be independent, but this does not rule out the zero covariance.)</p>

<p>Under the assumption that $X$ and $Z$ are independent and that $Y$ and $Z$ are independent, I am able to show that $$\mathrm{cov}(X,YZ) = \mathrm{cov}(Y,XZ) = \mathrm{cov}(XY,Z) + \mathrm{E}[Z]\cdot \mathrm{cov}(X,Y).$$ Showing this is fairly straightforward: $\mathrm{cov}(XY,Z)=\mathrm{E}[XYZ]-\mathrm{E}[XY]\cdot\mathrm{E}[Z]$; in addition, $\mathrm{cov}(X,YZ)=\mathrm{E}[XYZ]-\mathrm{E}[X]\cdot\mathrm{E}[YZ]=\mathrm{E}[XYZ]-\mathrm{E}[X]\cdot\mathrm{E}[Y]\cdot\mathrm{E}[Z]$, implying that $\mathrm{cov}(X,YZ)=\mathrm{cov}(XY,Z)+\mathrm{E}[XY]\cdot\mathrm{E}[Z]-\mathrm{E}[X]\cdot\mathrm{E}[Y]\cdot\mathrm{E}[Z]$, which is obviously equal to $\mathrm{cov}(XY,Z) + \mathrm{E}[Z]\cdot\mathrm{cov}(X,Y).$ And, of course, $\mathrm{cov}(X,YZ) = \mathrm{E}[XYZ]-\mathrm{E}[X]\cdot\mathrm{E}[Y]\cdot\mathrm{E}[Z]= \mathrm{cov}(Y,XZ)$, proving the above result.</p>

<p>However, to proceed further, my intuition tells me that $\mathrm{cov}(XY,Z) = 0$ and thus that $\mathrm{cov}(X,YZ) = \mathrm{cov}(Y,XZ) = \mathrm{E}[Z]\cdot\mathrm{cov}(X,Y)$. Am I wrong in thinking that $\mathrm{cov}(XY,Z) = 0$? But if it is true that $\mathrm{cov}(XY,Z) = 0$, is there a simple proof that does not possibly involve measure theory? Thanks.</p>
",<probability>
"<p>Let $\mathbf{u} =\begin{bmatrix}u_1 &amp; u_2 &amp; \dots &amp; u_N \end{bmatrix}^T$ and $\mathbf{v} = \begin{bmatrix} v_1 &amp; v_2 &amp; \dots &amp; v_N\end{bmatrix}^T$. All the elements of $\mathbf{u}$ and $\mathbf{v}$ are complex Gaussian random variables with zero mean and variance $\frac{1}{N}$ and $N$ is large. Also let $x_1, x_2 \in \{-1,1\}$ where $x_1$ a can be $-1$ or $1$ with equal probability $(p=0.5)$ and similaraly $x_2$. </p>

<p>Define $d^2$ as the square of the euclidean distance between $\mathbf{u}x_1 \text{and } \mathbf{v}x_2$: $$d^2=\mathbf{|u}x_1-\mathbf{v}x_2|^2 = |u_1x_1-v_1x_2|^2 + \dots +|u_Nx_1-v_Nx_2|^2 \\ \text{let} ~~d_\min = \min(d^2)~~ \text{what is} ~~ E(d_\min) \text{?}$$.</p>

<p>There are $4$ combinations for $(x_1, x_2)$: $(1,1),(1,-1),(-1,1),(-1,-1)$ and therefore $4$ combinations for $d^2$ $$d_1^2=|u_1-v_1|^2 + \dots +|u_N-v_N|^2 \\ d_2^2=|u_1+v_1|^2 + \dots +|u_N+v_N|^2 \\ d_3^2 = |-u_1-v_1|^2 + \dots + |-u_N-v_N|^2 \\ d_4^2 = |-u_1+v_1|^2 + \dots +|-u_N+v_N|^2$$
Since $u_i$ and $v_i$ are complex Gaussian, $|u_i-v_i|$ is Rayleigh and $|u_i-v_i|^2$ is going to be exponential. $N$ is large here and since all terms $|u_i-v_i|^2$ are independent I can use the central limit theorem and say that $d_1^2,d_2^2,d_3^2,d_4^2$ are all Gaussian. I can use the CDF method to calculate the distribution of $d_\min$ and then calculate the average minimum distance but $d_1^2,d_2^2,d_3^2,d_4^2$ are not independent and I don't know how to proceed. Any help/guidance is greatly appreciated.</p>
",<probability>
"<p>I was trying to solve the following question:</p>

<blockquote>
  <p>Out of 2 Boys and 2 Girls, two students are chosen to advance to the next level. What is the probability that two girls advance to the next level</p>
</blockquote>

<p>However, because the question was ambiguous I calculated the probabilities considering all four cases of whether they were distinguishable or indistinguishable, and whether order mattered or didn't matter and got different probabilities for each case.</p>

<p>However, I want to know why this happens. All you are doing is simply picking two students and seeing if they are both girls. You keep doing this and after infinite trials, divide the number of times they were both girls by the number of total trials. How does this outcome depend upon whether you view them as distinguishable, indistinguishable, ordered, or non-ordered? </p>

<p>Cases:</p>

<ol>
<li><p>Indistinguishable, order matters: $\frac{1}{2\cdot 2}=\frac{1}{4}$ (Cases are BB, BG, GB, GG)</p></li>
<li><p>Indistinguishable, order does not matter: $\frac{1}{3}$ (Cases are BB, B+G, GG)</p></li>
<li><p>Distinguishable, order matters: $\frac{2}{\text{Permutation}(4,2)} = \frac{1}{6}$</p></li>
<li><p>Distinguishable, order does not matter: $\frac{1}{\binom{4}{2}}=\frac{1}{6}$</p></li>
</ol>
",<probability>
"<blockquote>
  <p>Six teams play a tournament in which every team plays every other team exactly once. No ties occur, and each team has a $\dfrac{1}{2}$ probability of winning any game it plays. Find the probability that no two teams win the same number of games.</p>
</blockquote>

<p>This is what I have so far:</p>

<p>There are $\binom{6}{2} = 15$ pairs of teams, and $2^{15}$ possible outcomes. The min and max possible # of games won are from $0$ to $5$. If $h$ represents the # of games on by a certain team, than $0 \leq k \leq 5$. Because of this, there are $5!$ outcomes in which no two teams win the same number of games. Therefore, the probability is: $\dfrac{5!}{2^{15}}$. When simplified, we get $\dfrac{15}{4096}$. However, when I imputed this answer into the question, it was wrong. Where was my error, and how can I fix it? </p>

<p>NOTICE: The probability of a team winning in each game is 1/2 , NOT 1/12. </p>
",<probability>
"<p>$8$ students take an exam.</p>

<p>All of them are prepared average, so probability that they will pass or fail is the same.</p>

<p>After checking half of the tests, it's discovered that $3$ of them passed and $1$ failed.</p>

<p>What is probability that in the next $3$ tests, $1$ will pass and $2$ will fail</p>

<p>My reasoning:</p>

<p>If $A$ is event in which $1$ out of checked $4$ has passed and $2$ have failed and $B$ is event in which $3$ out of checked $4$ have passed and $1$ has failed then that two events are independent??</p>
",<probability>
"<p>I have a 60-40 weighted distribution, of uniform(0,7.5) and uniform(7.5,10) respectively, i.e. 
$$f_X(x)=(0.6/7.5)1_{x∈[0,7.5)}+(0.4/2.5)1_{x∈[7.5,1]}$$</p>

<p>I have worked out that 
$$E(X) = 0.6(7.5/2) + 0.4((10+7.5)/2) = 5.75$$ 
$$Var(X) = 9.0208$$</p>

<p>Right now this distribution is continuous, and I would like to make it discrete via the method of moment matching, with number of moments p = 2 and span h = 1.25.</p>

<p>How do I go about this?</p>

<p>I sort of understand how the equations work for p=1 (matching $m_0^k$ and $m_1^k$), but I'm not sure how to work it out for p=2.</p>

<p>*Notes: </p>

<p>Method of moment matching for arithmetizing a continuous distribution</p>

<p>We construct an arithmetic distribution that matches p moments of the arithmetic and the true severity distributions. Consider an arbitrary interval of length $ph$, denoted by $[x_k ; x_{k+ph})$. We locate point masses $m^k_0$, $m^k_1$, $m^k_2$, ... , $m^k_p$ at points $x_k$, $x_k + h$, ... , $x_k + ph$ so that the first p moments are preserved.</p>

<p>The system of p + 1 equations reflecting these conditions is
$$\sum_{j=0}^p (x_k + jh)^rm^k_j = \int_{x_k􀀀􀀀 - 0}^{x_k􀀀􀀀 + ph - 0} x^r dF_X(x) - (*)$$</p>

<p>where r = 0,1,2,...,p and the notation “􀀀- 0” at the limits of the integral indicates that discrete probability at $x_k$ is to be included but discrete probability at $x_k + ph$ is to be excluded.</p>

<p>Arrange the intervals so that $x_k+1 = x_k + ph$ and so the endpoints coincide. Then the point masses at the endpoints are added together.</p>

<p>With $x_0 = 0$, the resulting discrete distribution has successive probabilities:</p>

<p>$f_0 = m_0^0$, $f_1 = m_1^0$, $f_2 = m_2^0$, ...</p>

<p>$f_p = m_p^0 + m_0^1$, $f_{p+1} = m_1^1$, $f_{p+2} = m_2^1$, ...</p>

<p>We need to solve the system of equations defined by $(*)$.</p>

<p>The solution of $(*)$ is $$m_j^k = \int_{x_k􀀀􀀀 - 0}^{x_k􀀀􀀀 + ph - 0} \prod_{i \neq j}\frac{x - x_k - ih}{(j-i)h}dF_X(x)$$
where j = 0,1,...,p</p>
",<probability>
"<p>When you pick three cards, without replacement, from a standard 52 card deck, what are the probabilities of:</p>

<ul>
<li>only one suit in your three cards</li>
<li>two different suits in your three cards</li>
<li>three different suits in your three cards</li>
</ul>

<p>For the first I have the probability of $4 \cdot \frac{13}{52} \cdot \frac{12}{51} \cdot \frac{11}{50} = \frac{22}{425} $</p>

<p>But I cannot think of a way to determine the possibilities you have two or three different suits in the three chosen cards. Any help is appreciated.</p>
",<probability>
"<p>Let $(X_{n,m})_{n\geq 1,m\geq1}$ be a double sequence of random variables such that $X_{n,m}\Rightarrow X_m$ (weak convergence) as $n\rightarrow\infty$, $X_{n,m}\rightarrow X_n$ (almost sure convergence) as $m\rightarrow\infty$, and $X_m\rightarrow X$ (almost sure convergence) as $m\rightarrow\infty$. I am trying to determine whether these conditions are sufficient to establish that $X_n \Rightarrow X$ as $n\rightarrow\infty$, or if not, what additional assumptions would have to be made in order to ensure the result. This is what I have done so far. Let $f$ be continuous and bounded. Using continuity of $f$ and then its boundedness (to apply dominated convergence theorem) we have:
$$\mathbb{E}(f(X))=\lim_{m\rightarrow\infty}\mathbb{E}(f(X_m))=\lim_{m\rightarrow\infty}\lim_{n\rightarrow\infty}\mathbb{E}(f(X_{n,m})).$$
If I could interchange the two above limits, I would be able to conclude, since:
$$\mathbb{E}(f(X))=\lim_{n\rightarrow\infty}\lim_{m\rightarrow\infty}\mathbb{E}(f(X_{n,m}))=\lim_{n\rightarrow\infty}\mathbb{E}(f(X_{n})),$$
also by continuity of $f$ and dominated convergence. However, I am having difficulties proving that we can effectively interchange these two limits (to do so, one of the two limits needs to be uniform), and wondering if the assumptions I currently have are sufficient? Any comments or ideas would be greatly appreciated.</p>

<p>update: I think it's probably better to consider $f$ to be continuous with compact support instead, as we can therefore use the uniform continuity of $f$.</p>
",<probability>
"<p>A box contains two coins: a regular coin and one fake two-headed coin (P(H)=1). One coin is choose at random and tossed $n$ times. </p>

<p>If the first n coin tosses result in heads, What is the probability that the $(n+1)^{th}$ coin toss will also result in heads?</p>

<hr>

<p>My solution:</p>

<p>$$\text{Required Probability} = \frac{1}{2}\times \left(\frac{1}{2}\right)^n \times \frac{1}{2}+\frac{1}{2} \times 1^n \times 1$$</p>
",<probability>
"<p>Suppose that you are playing blackjack against the dealer. In a freshly shuffled deck (standard $52$ cards), what is the probability that neither of you are dealt a blackjack. Blackjack being $2$ cards adding to $21$ i.e. $Ace + 10,J,Q,or K$ (or vice versa as order does not matter).</p>

<p>The farthest I've really come is that the odds of the first player getting dealt a blackjack is $128\over 2652$. </p>

<p>First case: Odds of getting an Ace are $4\over52$, odds of the next being 10,J,Q,or K are $16\over51$.</p>

<p>Other case: Odds of getting 10,J,Q,or K are $16\over52$ and Ace $4\over 51$ so ${((4*16)*2)\over (52*51)} == {128\over 2652}$</p>

<p>Not sure where to go from here...</p>
",<probability>
"<p>Having two binary numbers of length 6, what is the probability that they match exactly? What is the probability that they have hamming distance of exactly 1?  or of 2?  </p>

<p>For the first part, the number of possible variants of the binary number is 2^6 I believe. What is the probability of the second binary number matching the first?  It seems to me that this probability would be 1/2 ^ 6?  </p>

<p>If this probability is found is it a simple matter to then find the probability of when they mismatch by exactly one number?  </p>
",<probability>
"<p>We note that given a probability distribution function $P$ over a space $U$ the expected value of a function of the elements in U:</p>

<p>$$ E(f(x)) = \int_{U} f(x)P(x) $$ </p>

<p>We thus consider the mean as the expected value of the numbers that is:</p>

<p>$$ E(x) = \int_{U} x P(x) $$</p>

<p>Now we consider ""standard deviation"" to be the expected difference between a variable from the mean that is</p>

<p>$$ Std(x) = E(|x - E(x)|)  = E\left(\sqrt{(x - E(x))^2}\right) $$</p>

<p>Yet Standard deviation is always measured as:</p>

<p>$$ \sqrt{E((x - E(x)^2)} $$</p>

<p>The latter formula doesn't make sense to me. Can someone explain why mine is wrong and hte latter is corret?</p>
",<probability>
"<p>Consider the following game of chance. A fair coin is tossed until the first tails appears.
You place an initial bet of k. If the 1st tails appears on the nth toss, you receive a total of $2^n$ (2 to the power of n) in return for your initial bet. How large should k be in order for your expected winnings to be zero (note, expected winnings of zero is sometimes called a “fair” game)?</p>

<p>I did the question and the answer comes to infinite. Is that correct? If not, what did I do wrong?</p>

<p>In other words, we can rephrase the question as: what is the expectation value of $2^n$ given $p(n)=1/2^{(n+1)}$?</p>
",<probability>
"<p>The material I'm reading derives Jeffrey's prior (or rather, the Fisher information for the Jeffrey's) for single-parameter binomial distribution in a manner quite similar to <a href=""https://en.wikipedia.org/wiki/Fisher_information#Single-parameter_Bernoulli_experiment"" rel=""nofollow"">this Wikipedia article</a>.</p>

<p>I could work out the steps until (following Wikipedia's notation, $A$ is number of successes, $B$ failures, $A+B$ total number of trials)</p>

<p>$$E [\frac{A}{\theta^2} + \frac{B}{(1-\theta)^2}] \\
= \frac{E[A]}{\theta^2} + \frac{E[B]}{(1-\theta)^2}
$$</p>

<p>Maybe my background in probability calculus is just lacking, but I'm not exactly sure about the justification for this step. $E[\frac{A}{\theta^2}] + E[\frac{B}{(1-\theta)^2}]$ follows from the linearity properties of expected value, but the next step? Are we treating $\frac{1}{\theta^2}, \frac{1}{(1-\theta)^2}$ as constants?</p>
",<probability>
"<p>I have this scenario:</p>

<blockquote>
  <p>1 animal with 30% probability of be moved to Japan. <br> 1 animal with
  30% probability of be moved to Japan. <br> 1 animal with 30%
  probability of be moved to Japan. <br> 1 animal with 30% probability
  of be moved to Japan. <br> 1 animal with 30% probability of be moved
  to Japan. <br> 1 animal with 30% probability of be moved to Japan.
  <br> 1 animal with 30% probability of be moved to China. <br> 1 animal
  with 30% probability of be moved to Japan. <br> 1 animal with 80%
  probability of be moved to Brazil. <br> 1 animal with 30% probability
  of be moved to Japan. <br> 1 animal with 20% probability of be moved
  to Brazil. <br> 1 animal with 30% probability of be moved to Japan.
  <br> 1 animal with 50% probability of be moved to Mexico. <br> 1
  animal with 30% probability of be moved to Japan. <br> (...)</p>
</blockquote>

<p>Resuming, 10 animals with 30% of probability of being moved to Japan.</p>

<p>Is that ""right"" to expect that 3 animals gonna be moved to Japan?</p>

<p>The formula is:
30/100 * 10 = 3</p>

<p>Can I use <strong>Binomial Distribution</strong> for this scenario?
If yes, how to elaborate the formula?</p>

<p>Thanks a lot!</p>
",<probability>
"<p>I understand the question but I am not sure how to solve it. For example, if we flip HHHTTTTT then the next three must be heads because of the question. This however seems counterintuitive. I believe that there are $2^{10}$ possible strings, but I am unsure of how to count all possible strings that begin with HHH.</p>
",<probability>
"<p>Given that time interval $T^*$ in seconds between certain events has a negative exponential distribution. </p>

<p>The instrument cannot detect intervals which are less than $\delta$ seconds.</p>

<p>Let $T_1, ..., T_n$ be a sample of independent intervals measyred by the instrument. The distribution of one of those observation $T_i$ is the conditional distribution of $T^*$ given that $T^*&gt;\delta$</p>

<p>In this question, if I want to find the probability density function of $T_i$, should I consider the <strong>shifted exponential distribution</strong> such that:
$$f_T(t) = \begin{cases} \lambda e^{-\lambda (t- \delta)} &amp; t&gt;\delta, \\ 0 &amp; otherwise \end{cases}$$</p>

<p>with $E(T)=\delta + \frac{1}{\lambda}$ and $Var(T) = \frac{1}{\lambda ^2}$ </p>

<p>Thank you</p>
",<probability>
"<p>Let $X,Y$ be two i.i.d. r.v.'s with zero mean and unit variance. If $X+Y$ and $X-Y$ are independent, then $X$ and $Y$ are both standard normal distributed.</p>

<p>Is there any short proof for this problem?</p>
",<probability>
"<p>There are two independent variables X and Y. Y is an input for non deterministic algorithm f, and the output of f(Y) is Z. How to prove that X and Z are independent?</p>
",<probability>
"<p>I'm trying to calculate the probabilities of different lengths of repetitions of X length number however I know I'm doing it incorrectly since when I add all the probabilities together they don't total to 1</p>

<p>e.g. 
Here is my reasoning to calculate the probabilities of the different lengths repetitions for length 4</p>

<p>Probability that there are 0 repeating sequences: 
e.g. WXYZ
10/10 * (9/10)^3 = 729</p>

<p>Probability that there is 1 repeating sequence of length 2: 
e.g XXYZ or YXXZ or YZXX
10/10 * (9/10)^2 * 1/10 * 3 = 243</p>

<p>Probability that there is 2 repeating sequence of length 2: 
e.g XXYY or YYXX
10/10 * 9/10 * (1/10)^2 * 2 = 18</p>

<p>Probability that there is a repeating sequence of length 3: 
e.g XXXY or YXXX
10/10 * 9/10 * (1/10)^2 * 2 = 18</p>

<p>Probability that there is a repeating sequence of length 4:
e.g XXXX
10/10 * (1/10)^2 * 3 = 1</p>

<p>When I add the number of outcomes I get 1009, when I should be getting a 1000.
Anyone know what I'm doing wrong?</p>

<p>Thanks in advance!</p>
",<probability>
"<p>I have recently seen a probability question which says<br>
""i am asking randomly the persons I met if they are having two chidren and one of them is a boy who was born on tuesday. At last I met one whose answer is yes. What is the probability that the other child is also a boy. Assume equal probability to either gender and equal probability to be born on each day of the week""<br></p>

<p>I could actually solve it to 2/21. Did I do it right or can some one help me solve it?</p>
",<probability>
"<p>I'm a little confused in some simple question in probability theory,</p>

<p>Say that the probability for rain in London in some random day is $P_{rain}$; and the probabilities of rain in one day and another are independent.</p>

<p>We know that the probability for rain in exactly 3 days of 7 is $C(7,3) \cdot P_{rain}^3 \cdot(1-P_{rain})^4$.</p>

<p><em>Question:</em> Say that I arrived to London in a rainy day, what's the probability of rain in 3 days of the current week?</p>

<p>Does it equal $C(6,2) \cdot P_{rain}^2 \cdot(1-P_{rain})^4$ ? (I think so because of the fact that the probabilities are independent...)</p>
",<probability>
"<p>Assuming I can play forever, what are my chances of coming out ahead in a coin flipping series?</p>

<p>Let's say I want ""heads""...then if I flip once, and get heads, then I win, because I've reached a point where I have more heads than tails (1-0).  If it was tails, I can flip again.  If I'm lucky, and I get two heads in a row after this, this is another way for me to win (2-1).</p>

<p>Obviously, if I can play forever, my chances are probably pretty decent.  They are at least greater than 50%, since I can get that from the first flip.  After that, though, it starts getting sticky.</p>

<p>I've drawn a tree graph to try to get to the point where I could start see the formula hopefully dropping out, but so far it's eluding me.</p>

<p>Your chances of coming out ahead after 1 flip are 50%.  Fine.  Assuming you don't win, you have to flip at least twice more.  This step gives you 1 chance out of 4.  The next level would be after 5 flips, where you have an addtional 2 chances out of 12, followed by 7 flips, giving you 4 out of 40.</p>

<p>I suspect I may be able to work through this given some time, but I'd like to see what other people think...is there an easy way to approach this?  Is this a known problem?</p>
",<probability>
"<blockquote>
  <p>Let $X$, $Y$ be independent random variables with the common pdf
   \begin{eqnarray*} f(u) &amp;=&amp; \left\{\begin{array}{ll} u\over2 &amp;
 \mbox{for } 0 &lt; u &lt; 2\\ 0 &amp;\mbox{elsewhere} \end{array}\right.\\
\end{eqnarray*}
  Set up an explicit double integral for $P(X Y &gt; 1)$</p>
  
  <p>Let $Z$ be the maximum of $X,Y$ (That is, $Z = X$ if $X \geqslant Y$, and $Z= Y$ 
   if $Y &gt; X$). Find $P(Z\leqslant 1)$</p>
  
  <p>Find the pdf $g(z)$ of $Z$, being sure to define $g(z)$ for all
   numbers $z$.</p>
</blockquote>

<p>This is a problem on a practice exam I'm studying, but I really have no idea how to approach the problem.</p>
",<probability>
"<p>Let $\pi$ be a random permutation of $n$ objects and let $ T := \text{the number of transpositions in } \pi $. Use Chebychev's Inequality to find an upper bound for $T\geqslant k$.</p>

<p>Okay the problem I'm having here is with $\mathbb{Var}(T)$, I'm not sure how to find it. I know the expectation is $\frac{1}{2}$, so my formula so far is $$\mathbb{P}\left(T-\frac{1}{2}\geqslant k\right) \leqslant \frac{\mathbb{Var}(T)}{k^2}$$ </p>
",<probability>
"<p>Let $F$ be the number of fixed points of a random permutation on $n$ items. Show that as $n$ approaches infinity, the distribution of $F$ approaches a Poisson distribution with a mean $(\lambda)=1$.</p>
",<probability>
"<p>In his book <a href=""http://rads.stackoverflow.com/amzn/click/159420411X"">The Signal and the Noise</a>, Nate Silver presents this example application of Bayes's Theorem on pp. 247-248:</p>

<blockquote>
  <p>Consider a somber example: the September 11 attacks. Most of us would
  have assigned almost no probability to terrorists crashing planes into
  buildings in Manhattan when we woke up that morning. But we recognized
  that a terror attack was an obvious possibility once the first plane hit
  the World Trade Center. And we had no doubt we were being attacked
  once the second tower was hit. Bayes's theorem can replicate this result.</p>
</blockquote>

<p>You can view the complete example in Amazon.com's previw, and I've made the two pages available <a href=""http://imgur.com/YI2rv,nIakZ,rwbYH,MB8U6,07VIA#0"">here</a>.</p>

<p>Silver assumes the prior probability of a terrorist plane attack to be 1 in 20,000. After the first plane crash, using Bayes's Theorem he updates that to 38%. And after the second plane crash, he comes up with a 99.99% probability. However, I think he may be mistaken. I'll provide the details below.</p>

<p>To be precise, let us define the following three events:</p>

<ul>
<li>$PC$ = Plane Crash: At least one plane crashes into a Manhattan skyscraper on a given day. </li>
<li>$TPA$ = Terrorist Plane Attack: At least one plane is intentionally crashed into a Manhattan skyscraper on a given day.</li>
<li>$APC$ = Accidental Plane Crash: At least one plane is accidentally crashed into a Manhattan skyscraper on a given day.</li>
</ul>

<p>We assume all plane crashes into buildings are either terrorist plane attacks or accidental (i.e. $PC = TPA \cup APC$). Using historical data, Silver estimates the prior probability of an accidental plane crash to be 1 in 12,500. In summary: $$P(TPA) = \frac{1}{20000},$$$$P(APC) = \frac{1}{12500}.$$</p>

<p>Furthermore, Silver assumes $P(APC) = P(PC|\overline{TPA})$ (which is true if $APC$ and $TPA$ are independent events).</p>

<p>Applying Bayes's Theorem, he comes up with 
$$\begin{align}P(TPA|PC) &amp;= \frac{P(PC|TPA) \times P(TPA)}{P(PC|TPA) \times P(TPA) + P(PC|\overline{TPA})(1-P(TPA))} \\
&amp;= \frac{1 \times \frac{1}{20000}}{1 \times \frac{1}{20000} + 
\frac{1}{12500} \times (1 - \frac{1}{20000})} = 0.385\end{align}$$</p>

<p>Silver continues:</p>

<blockquote>
  <p>The idea behind Bayes's theorem, however, is not that we update our 
  probability estimates just once. Instead, we do so continuously as new
  evidence presents itself to us. Thus our posterior probability of a
  terror attack after the first plane hit, 38 percent, becomes our
  <em>prior</em> probability before the second one did. And if you go through the calculation again, to  reflect the second plane hitting the World
  Trade Center, the probability that we were under attack becomes a
  near-certainty -- 99.99 percent.</p>
</blockquote>

<p>That is (this is Silver's calculation): $$P(TPA|PC) = \frac{1 \times 0.385}{1 \times 0.385 + 
\frac{1}{12500}(1-0.385)} = 99.99 \%$$</p>

<p>""Cool!"" I thought, until I thought a bit more. The problem is that you can apply the same logic to calculate the conditional probability of an <em>accidental</em> crash, too. I'll spare you the math, but I come up with $P(APC|PC) = 0.615$ after the first crash, and $P(APC|PC) = 99.997\%$ after the second.</p>

<p>So we can be almost certain the second plane crash is a terrorist attack, and we can be even more certain that it's accidental?  </p>

<p>I think the problem is that when Silver applies Bayes's Theorem after the second crash, he uses the updated probability of a terrorist plane attack as his prior, but fails to update the prior probability of an accidental plane crash (which should become 0.615). After the second crash, then, the correct formula is
$$P(TPA|PC) = \frac{1 \times 0.385}{1 \times 0.385 + 
0.615(1-0.385)} = 0.504$$</p>

<p>Similarly, the probability that we're observing an accidental crash given that there have been two crashes is 
$$P(APC|PC) = \frac{1 \times 0.615}{1 \times 0.615 + 
0.385(1-0.615)} = 0.806$$</p>

<p><strong>Question 1</strong>: Am I correct that Nate Silver is doing it wrong?</p>

<p><strong>Question 2</strong>: Am I doing it right?</p>
",<probability>
"<p>In my book:
$\mathbf{X}=(X_1,\ldots,X_n)$
$f(\mathbf{x})$ is the joint density, where $f$ is either $f_0 \text{ or } f_1$.</p>

<p>Suppose we want to test $H_0: f=f_0$ or $H_1: f=f_1$. The test, whose test function is</p>

<p>$$\phi(\mathbf{X})=1\text{ if }\frac{f_1}{f_0}\geq k;$$</p>

<p>$$\phi(\mathbf{X})=0 \text{ otherwise,}$$</p>

<p>(for some $0&lt;k&lt;\infty$) is a most powerful test of $H_0$ versus $H_1$ at level $E_0(\phi(\mathbf{X}))$.</p>

<p>My question is how is $k$ defined? Can I interpret the lemma as if $\forall k \in (0,\infty)$ there will be a test function $\phi(\mathbf{X})$ such that it will determine the size for which the test with test function $\phi(\mathbf{X})$ is most powerful?</p>

<p>I'm just trying to understand which kind of relationship $k$ and the size of the test have between each other.</p>

<p>EDIT: </p>

<p>Here is a citation from the book I'm using: «the Neyman-Pearson lemma as stated here does not guarantee the existence of an MP $\alpha$ level test but merely states that the test that rejects $H_0$ for $T(X)\geq k$ will be an MP for some level $\alpha$» This makes me want to interpret as $\forall k \exists \alpha$. May I? </p>
",<probability>
"<p>Suppose I have $n$ random number generators.  Once an hour, on the hour, each one generates a random real number $x_k$ such that $0 \le x_k \lt \infty$. Each generator produces its values according to its own independent probability distribution function $f_k()$, which is a known function.  For example, one generator might follow an exponential distribution, another might follow a normal distribution, etc.</p>

<p>Let $X = \sum\limits_{k=1}^n x_k$ for all of the number generators in any one hour.</p>

<p>Given $y$ such that $0 \le y \lt 1$ (a probability), I need to find a value $z$ such that $P(X \le z) = y$.</p>

<p>Basically, I need to be able to do something like find the value that $X$ will be less than or equal to 50% of the time.</p>

<p>I apologize if I've gotten any of the notation wrong, I'm actually a software engineer so I know some things about math but not others.  I know enough about probability to express the problem above, but I don't even know where to begin in terms of solving it. Any help, or even suggested readings would be much appreciated.</p>
",<probability>
"<p>Under an insurance policy, a maximum of five claims may be filed per year by a policy holder. Let $p_n$ be the probability that a policy holder files $n$ claims during a given year, where $n = 0, 1, 2, 3, 4, 5.$</p>

<p>An actuary makes the following observations:</p>

<blockquote>
  <p>(i) $p_n\geq p_{n+1}$ for $0\leq n \leq 4$</p>
  
  <p>(ii) The difference between $p_n$ and $p_{n+1}$ is the same for $0 \leq n \leq 4$</p>
  
  <p>(iii) Exactly $40\%$ of policyholders file fewer than two claims during a given year.</p>
</blockquote>

<p>Calculate the probability that a random policyholder will file more than three
claims during a given year.</p>

<p><strong>Source:</strong> Marcel B. Finan's <em>A Probability Course for the Actuaries</em></p>

<p><strong>My thoughts:</strong> The goal is to find $P(n &gt; 3)$. We are given that $P(n&lt;2)=.4$, which means that $P(n\geq2)=.6$. $P(n&gt;3) = p_4 + p_5$. From this, we know that $p_0 + p_1 = .4$, and $p_2 + p_3 + p_4 + p_5 = .6$; so, $p_2 + p_3 + P(n &gt; 3) = .6$. But I don't know how to solve for $p_2$ or $p_3$ to find $P(n &gt; 3)$. Any help would be greatly appreciated.</p>
",<probability>
"<p>We'll start off with an example of a question of finding expected value.</p>

<p>What is the expected number of tries to get ’6′ when rolling dice?
E(x)=1/6*1 + 5/6 (1+E(x))
E(x)=6</p>

<p>I understand the intuition, there is a 1/6 probability of getting 6 in one roll and 5/6 of not getting 6, so we roll again and add 1 to the counter since we have done one roll. I wonder what is the formal proof of such method?</p>
",<probability>
"<p>Given a square $S$ with size $1 \times 1$. Two randomly selected points $A$ and $B$ are inside the square. Let $U$ be a square with diagonal $AB$. How to find out the probability $P$($U$ is inside $S$).
<img src=""http://i.stack.imgur.com/KO82j.png"" alt=""example""></p>
",<probability>
"<p>My task is: assess the probability that for some number $n_0$, $A_n$ will happen for every $n&gt;n_0$, where $A_n = \{|\frac{S_n}{n} -p| \le \epsilon\}$ ($S_n $ is the number of successes in Bernoulli scheme with probability of the success equal to $p$).
I don't really understand what exactly should I do. My first attempt was that I found $P(|\frac{S_n}{n} -p| \ge \epsilon) = e^{\frac{-n\epsilon^2}{4}}$ (which was quite easy to do), but I don't know how to use it here? May somebody show me? I would be grateful.</p>
",<probability>
"<p>Given $A$, $B$ and $C$ where $A$ and $B$ are mutually exclusive. </p>

<p>If $P(A\cap C)=0.2$, $P(B\cap C)= 0.1$, $P(C)=0.6$, $P(A\cup B)= 0.6$, $P(A\cup C)= 0.8$, and the relation $P(A) = 2P(B)$, find the probabilities of $A$ and $B$.</p>
",<probability>
"<p>Let us have a walk on $\mathbb Z$ of size $2^n$. To compute the final height of the walk, the trivial way is to sum $1$ for an ascending step and $-1$ for a descending step all along the walk. I would like to have some method to infer the final height in a more efficient way.</p>

<p>More formally, let us denote $\bar h = \frac{h}{2^n}$, where $h$ is the final height. Given an error $\epsilon$ and a probability $p$, I'd like to compute $g$ such that $\mathbb P(\lvert g- \bar h \rvert &gt; \epsilon) &lt; 1-p$, in some ""efficient"" way (i.e in polynomial time in $n$, and the smaller $\epsilon$ and $p$ are, the more I'll give myself time).</p>

<p>What I have is that if I take $i\in \{1,\cdots,2^n\}$, and set $X_i$ to be $1$ if the $i$-th step is ascending and $-1$ if the step is descending, then the expectation of $X_i$ is exactly $\bar h$. I repeat this $k$ times and set $g = \frac{1}{k}\sum_{i=1}^k X_i$. What should be $k$ for $g$ to be close to $\bar h$ with good probability? I guess this should have the flavour of a Chernoff bound, but all I found on this talks about boolean random variables, and I don't know if I can finish we this. How should I conclude?</p>
",<probability>
"<p>I would like to calculate conditional expectation $E[X|A]$, where $A$ is a set, only from the characteristic function $\phi(\omega)$ of a random variable $X$. How can I do this?</p>

<p>Since the characteristic function describes the density function completely, I should be able to do everything at the frequency domain but I dont know how it can be done. If there is no conditioning then, the result is simply the derivative of the characteristic function.</p>

<p>I also wonder how to calculate 
$$\int_{-\infty}^A f(t)\mathrm{d}t$$
from the chracteristic function $\phi(\omega)$ without going back to the density domain.</p>

<p>Thanks alot...</p>

<p>NOTES:</p>

<p>I found a solution to the second part of my question from</p>

<p>$$F_X(x)=\frac{1}{2}+\frac{1}{2\pi}\int_0^\infty \frac{e^{iwx}\phi_X(-w)-e^{-iwx}\phi_X(w)}{iw} \mathrm{d}w$$
with $F_X(A)$</p>
",<probability>
"<p>how would I be able to answer this question?</p>

<p>The first box contains 3 white and 7 black balls, and the second box contains 6 white and 3 black balls, A ball is chosen at random from the first box, and, without looking at its colour, put into the second box. Then a ball is chosen at random from the second box, and it is white. Is it more likely that the ball moved from the first box to the second was black?</p>
",<probability>
"<p>I am currently reading a book ""measure, integral and probability"" by Capinski and Kopp. The correlation between random variables $X$ and $Y$ is defined as the cosine of the angle between $X_c$ and $Y_c$, that is:
$$
\operatorname{corr(X,Y)} = \frac{(X_c,Y_c)}{(\|X\|\cdot\|Y\|)},
$$
where $X_c$, $Y_c$ are centered random variables defined by $X_c=X-\mathbb{E}(X)$, $Y_c=Y-\mathbb{E}(Y)$.
The question that immediately arises is:
Why do we divide by $\|X\|\cdot\|Y\|$, and not $\|X_c\|\cdot\|Y_c\|$? </p>

<p>I want to understand the concept of correlation, independence and other concepts of probability from the point of view of functional analysis. I would be very happy if you could recommend some literature that has a treatment of this topic, and desirably, detailed discussion of the following questions: Are uncorrelated variables just orthogonal? or only if $\mathbb{E}(X)=0=\mathbb{E}(Y)$? How is the ""centred"" vector different from original, ""geometrically""? I know in infinite dimenstions it is hard to visualise geometry, but still... Thank you very much.</p>
",<probability>
"<p><strong>There are $n$ seats in a room. If $n$ people come to the room, what is the probability that $j$ specified people occupy $j$ specified seats? ($j$ names were tagged on the $j$ seats)</strong></p>

<p>$n$ people can occupy $n$ seats in $n!$ ways.
I can't get my head around how to go forward from here.
Any help would be appreciated.</p>
",<probability>
"<p>Suppose I have three random variables, $X,Y,Z$ with $X$ independent of $Z$, $Y$ independent of $Z$.</p>

<p>Which transformation can I apply to $X,Y$ to that the result is again a random variable independent of $Z$? Or better, for which $f(x,y)$ is $f(X,Y)$ independent of $Z$?</p>

<p>For example $f(x,y) = xy$ does not work because in general $XY$ is not independent of $Z$. </p>

<p>Is there a general result?</p>
",<probability>
"<blockquote>
  <p>Suppose we have a box containing $n$ balls numbered $1, 2,\dotsc,n$. A random sample of size $k$ is drawn without replacement and the numbers on the balls noted. These balls are than returned to the box and a second random sample of size $r$ is then drawn without replacement. $(r + k &lt; n)$ Find the probability that two samples contain all different balls.</p>
</blockquote>

<hr>

<p>This was my approach.<br>
Take the $k$ balls first.<br>
Then the probability that of not getting the same $k$ balls again is $$1-\frac{1}{(n)(n-1)(n-2)\dotsm(n-k)}$$
I hope that makes sense.<br>
In this I ignored the second sample size, I don't think that matters. 
Is it right?</p>
",<probability>
"<p>Suppose a fair coin is tossed $900$ times. Find the probability of getting more than $475$ heads. Use the continuity correction.</p>

<p>My answer:</p>

<p>$n=900, p=1/2, q=1/2$</p>

<p>$\mu=900(1/2)=450, npq=\sigma^{2}=225,\sigma=15$</p>

<p>$Z=(X-\mu)/\sigma$</p>

<p>$P_B(X\geq475)=P_B(475 \leq x \leq 900)$</p>

<p>$=P_N(474.5 \leq 900.5)$</p>

<p>$Z=(X-\mu)/\sigma$</p>

<p>$=(474.5-450)/15=1.63$</p>

<p>$Z=(X-\mu)/\sigma$</p>

<p>$(900.5-450)/15=30.03$</p>

<p>$=P_N(0&lt;z&lt;1.63)+P_N(0,z,30.03)$</p>

<p>$.4484+.5000$</p>

<p>$.9484$</p>

<p>Then we get:</p>

<p>$1-.9484$</p>

<p>$.0516$</p>

<p>I was just trying this problem to see what it would be like after reading about the topic. I wanted to know what I did wrong. The answer says $.0446$. Can someone help me with this?</p>
",<probability>
"<p>I want to show</p>

<p>Px$(B(s)\ge0 $ for all 0 $\le s \le t$ and B(t) $\in$ M) = Px(B(t) \in M)$-$P-x$(B(t) \in M)$</p>

<p>where,x>0,M is measurable set in [0,$\infty$).</p>

<p>The difficulty for me is how to handle the left side of the equation.I know the distribution of hitting time.But here it is not only about hitting time.</p>
",<probability>
"<p>Question: </p>

<p>I have $5$ yellow bulbs and $4$ red bulbs. These bulbs will be placed in a straight line such that $2$ on the left side are the same colour as each other, and $2$ on the right side are also the same colour (but not the same as the left side). How many ways are there of planting the bulbs?</p>

<p>I'm really not sure about how to answer this question, I assumed you would go about it by doing $5C2 + 5C3$. But I'm really not too sure. </p>

<p>Thanks!</p>
",<probability>
"<p>So the question is really hard I think. I tried using a simple way by calculating the probability of each combination that makes a sum divisible by six, but it would take forever. Does anyone have any ideas?</p>

<p>Suppose that we roll a six-sided die ten times. What is the probability
that the total of all ten rolls is divisible by six?</p>
",<probability>
"<p>I was wondering how the ordinary expectation value $E(X)$ is related to $E(X|\mathcal{F})$ where $\mathcal{F} \subset \mathcal{E}$ where the latter is supposed to be the sigma algebra on our probability space.</p>

<p>My first thought was that $E(X|\mathcal{E}) = E(X),$ but this is clearly wrong, as $X$ is $\mathcal{E}$ measurable and thus $E(X|\mathcal{E})= X.$</p>

<p>Then I noticed that by the total law of expectation $E(E(X|\mathcal{F}))=E(X)$ we have something like a tower property for the standard expectation value, but in the sense that $E(.)$ wins over any $E(.|\mathcal{F}).$ Spoken in terms of tower properties, this would mean that if $E(X)$ can be represented as a conditional expectation, it must be a maximally small sigma algebra. So my guess is $E(X|\{\emptyset, \Omega\})=E(X),$ is this true?</p>

<p>At first glance, it seems to fulfill all the properties of the conditional expectation, so my guess is yes, but I would like to have your confirmation.</p>
",<probability>
"<p>Determine the probability that in a group of $7$ randomly drawn cards from well
mixed deck of $52$ cards will be exactly $2$ cards with a picture and exactly $4$ red cards (hearts or diamonds)</p>

<p>I don't know how to start I have trouble with reasoning in this case</p>
",<probability>
"<p>Convergence in Probability talks about two RVs, $X_n$ and $X$ , associated with an experiment  - </p>

<p>$\lim_{n \rightarrow \infty} P\big(|X_n-X| \geq \epsilon \big)=0, \qquad \textrm{ for all }\epsilon&gt;0.$</p>

<p>I'm quite not able to understand what $P( \vert X_n - X \vert &gt; \epsilon)$ means in terms of elementary outcomes of the experiment.</p>

<p>I can understand that $P(X_n &gt; a)$ means the sum of probabilities of all outcomes, $o_i$,  such that $X_n(o_i)$ = $x_i$ and $x_i &gt; a$</p>

<p>Similarly, an expression like $P(X &gt; b)$.</p>

<p>But an expression like $P( \vert X_n - X \vert &gt; \epsilon)$ involves 2 random variables. How do we explain this expression in terms of elementary outcomes of the experiment ?</p>
",<probability>
"<p>You have $n = n_A + n_B$ $k$-sided dice. The $n_A$ dice are thrown and a <em>set</em> of the resulting values, call it $S_A$, is built; likewise for the $n_B$ dice, calling the resulting set $S_B$.</p>

<p>What is the probability of $S_A \cap S_B = \varnothing$?</p>
",<probability>
"<p>Past Exam Paper Question -</p>

<p>Prof. Smith is crossing the Pacific Ocean on a plane, on her way to a conference.
The Captain has just announced that an unusual engine fault has been
signalled by the plane’s computer; this indicates a fault that only occurs once in
10,000 flights. If the fault report is true, then there’s a 70% chance the plane
will have to crash-land in the Ocean, which means certain death for the passengers.
However, the sensors are not completely reliable: there’s a 2% chance of
a false positive; and there’s a 1% chance of the same fault occurring without the
computer flagging the error report.</p>

<p><strong>Question</strong> </p>

<p>Formulate this problem in terms of conditional probabilities of outcomes, existence of
a fault and whether or not it is reported and use Bayes’ rule to compute Prof. Smith’s chances of survival. </p>

<p><strong>My Attempt</strong></p>

<p>P(Fault) - 0.0001</p>

<p>P(Crash | Fault) - 0.7</p>

<p>P(FalsePositive | Fault) - 0.02</p>

<p>P(NoReport | Fault) - 0.01</p>

<p>I have no idea what to do next, every example I look at seems  a lot easier than this. Could someone help me out? </p>
",<probability>
"<p>Consider the random variables $W_i,W_j, X_i, X_j$ with $X_i\sim X_j$, $X_i\perp X_j$ and $W_i\sim W_j, W_i\perp W_j$, where $\sim$ denotes equal probability distribution and $\perp$ denotes independence. </p>

<p>Suppose $W_i, W_j$ are continuously distributed with support $\mathcal{W}$ with everywhere strictly positive density. Suppose $X_i, X_j$ have support $\mathcal{X}$. </p>

<p>Consider the function $p(X_i,X_j): \mathcal{X}\times \mathcal{W}\rightarrow [0,1]$ continuous in $W_i$ $(W_j)$ for any realisation of $X_i$ $(X_j)$. </p>

<p>Consider the function $\lambda(p): [0,1]\rightarrow \mathbb{R}$ continuous in p.  </p>

<p>Suppose that the support of $(X,W)$ is $\mathcal{X}\times \mathcal{W}$. </p>

<p>I think that under these conditions
$$
\mathbb{P}(\lambda(p(X_i,W_i))-\lambda(p(X_j,W_j))&lt;\epsilon| X_i=x, X_j=\tilde{x})&gt;0 \hspace{2cm}(\star)
$$
$\forall x, \tilde{x}\in \mathcal{X}^2, x\neq\tilde{x} $, $\forall \epsilon&gt;0$. </p>

<p>Could you help me to formalise a proof? Do I need $\mathcal{W}$ compact?</p>

<hr>

<p><strong>Attempt:</strong> </p>

<p>(1) Since $\lambda$ is the composition of continuous functions, it is continuous in $W_i$ $W_i$ $(W_j)$ for any realisation of $X_i$ $(X_j)$. </p>

<p>(2) Given $X_i=X_j=x$ (and if $\mathcal{W}$ is compact?) $\exists$ $w,\tilde{w}\in \mathcal{W}^2, w\neq \tilde{w}$ such that $\lambda(p(x,w))-\lambda(p(x,\tilde{w}))&lt;\epsilon$ $\forall \epsilon&gt;0$</p>

<p>(3) Does (2) imply $\lambda(p(x,w))-\lambda(p(\tilde{x},\tilde{w}))&lt;\epsilon$ $\forall \epsilon&gt;0$ $\forall x, \tilde{x}\in \mathcal{X}^2, x\neq\tilde{x} $?</p>

<p>(4) As the support of $(X,W)$ is $\mathcal{X}\times \mathcal{W}$ and $W$ has everywhere positive density on $\mathcal{W}$, $(\star)$
follows. </p>

<p>(5) Where do I use the fact that $X_i\sim X_j$, $X_i\perp X_j$ and $W_i\sim W_j, W_i\perp W_j$?</p>
",<probability>
"<p>In a book about machine learning, it reads,</p>

<blockquote>
  <p>Generally, the probability that $x$ generated independently by a continuous probability distribution $p(x)$ have the same value is zero. Otherwise, $\int p(x)dx = \infty$. </p>
</blockquote>

<p>Why is it impossible that the same value is sampled more than once?</p>
",<probability>
"<p>Assume we toss a coin 10 times, independent of each other. 
Each time we can get Heads (H) or Tails (T) , regardless of whether it is fair or not.</p>

<p>So for example this is one possible outcome: HHHHHHHHHH ie 10 heads. Let's call this a 10-toss sequence. </p>

<p>The total number of possible 10-toss sequences is 2^10 because each toss has 2 possible outcomes: Heads or Tails.</p>

<p>--The first question is What is the meaning of 10!/(3!7!) ? The answer is that It is the total number of ways, by which we can place the three heads inside the 10-toss sequence. The order by which we place the three heads does not matter. </p>

<p>--The second question is : What is the total number of possible 3-head sequences?
Is it 10!/(3!7!)? Some say YES. Others, say NO.<br>
A 10-toss sequence with three heads, can be this one: HHH THTHTHT. So three positions are fixed to 'heads'. The remaining seven positions can be H or T. So we have 2^7 possible 7-toss sequences. And the three heads can be anywhere in this 10-toss sequence. </p>

<p>So an answer can be that the total number of 10-toss sequences with 3 heads is 10!/(3!7!) multiplied by (2^7) . That is in the 10-toss sequence the number of ways by which we can place 3 heads is 10!/(3!7!). Then, we have to say something about the remaining 7-toss sequence. Each position can take Heads or Tails . So 2^7 is the possible number of this 7-toss sequence. </p>

<p>However, I know that the correct answer is 10!/(3!7!) and that we don't need to multiply by 2^7. But I cannot understand why.  </p>
",<probability>
"<p>In an example, where a test has a maximum score of $200$, and a minimum score of $0$, can one eliminate the infinite boundaries?</p>

<p>Let's say my $\mu$ is $100$, and my $\sigma$ is $50$. Integrating the normal function for $200 \leq X$, I get:</p>

<p>$$\int^\infty_{200} \frac{e^{-\frac{(x-100)^2}{2\times50^2}}}{50\sqrt{2\pi}}dx \approx 0.022$$</p>

<p>There is a 2.2% chance that one will score over the limit of 200. Is there any way to make scoring over 200 impossible, and changing the maximum bound from $\infty$ to 200, and $-\infty$ to 0 in a way, that the integral below is true:</p>

<p>$$\int^{200}_{0} \frac{e^{-\frac{(x-100)^2}{2\times50^2}}}{50\sqrt{2\pi}}dx = 1$$</p>
",<probability>
"<p>If $Y_1,\ldots,Y_n$ independent each having pdf:
$$ f(y\mid \beta,\theta, x)=\theta e^{-\theta(y-\beta x)},~~ y&gt;\beta x$$
where $x_1,\ldots,x_n$ are given, the parameters $\beta$ and $\theta$ are unknown. I know the joint sufficent statistics for $\beta$ and $\theta$ are $\overline{Y}$ and $\min\{Y_i\}$. But can I say that the sufficient statistic for $\beta$ is $\min\{Y_i/X_i\}$?</p>

<p>I don't know why, but I feel strange calculating sufficient statistics for only part of the parameters.</p>
",<probability>
"<p>I have been working on this problem from a previous exam in Probability theory but I can't understand the next step I am supposed to take. Here is the problem:</p>

<p>Suppose that $Z_1$ and $Z_2$ are independent exponential random variables with
parameter 1 and let $X=\frac{Z_1}{Z_1 + Z_2}$.
Find the cumulative distribution function of X and identify the corresponding distribution.</p>

<p>I tried this:
$$
\begin{align}
P(X \le x) &amp;= P(\frac{Z_1}{Z_1+Z_2} \le x)\\
&amp;= P(Z_1 \le xZ_1+xZ_2)\\
&amp;= P(Z_1 \le Z_2(\frac{x}{1-x}))\\
&amp;= P(Z_1 \le g(Z_2))\\
\end{align}
$$</p>

<p>At this point I would like to use CDF for $Z_1$ like this $1-e^{-x*g(Z_2)}$ but the key uses
$\int_{0}^{\infty}e^{-x}P(Z_1 \le\frac{x}{1-x}z)dz$.  How do I make this jump because it doesn't seem to follow from the work I have done.</p>
",<probability>
"<p>I am using Ross' A First Course In Probability (4th). On page 113, Example 1d states the following:</p>

<blockquote>
  <p>Independent tirals consisting of the flipping of a coin having
  probability $p$ of coming up heads are continually performed until
  either a head occurs or a total of $n$ flips is made. If we let $X$
  denote the number of times the coin is flipped, then $X$ is a random
  variable taking on one of the values 1, 2, 3, ..., n with respective
  probabilities</p>
  
  <p>$P\{X=1\} = P\{H\} = p$</p>
  
  <p>$P\{X=2\} = P\{(T,H)\} = (1-p)p$</p>
  
  <p>$P\{X=3\}=P\{(T,T,H)\} = (1-p)^2p$</p>
  
  <p>.</p>
  
  <p>.</p>
  
  <p>.</p>
  
  <p>$P\{X=n-1\}=P\{(T,T,...,T,H)\}=(1-p)^{n-2}p$</p>
  
  <p>$P\{X=n\}=\{(T,T,...,T,T),(T,T,...,T,H)\}=(1-p)^{n-1}$</p>
</blockquote>

<p>There are a couple of things that are confusing to me here. To my understanding, they are defining $X$ to be ""the number of times the coin is flipped until a head occurs or a total of $n$ flips is made."" Then, We would have $P\{X\}$ to be</p>

<p>$P\{X = n\} = \sum\limits_{i=1}^n (1-p)^{i-1}p^i + (1-p)^i$    , isn't it?</p>

<p>Also, wouldn't $P\{X=n\} =(1-p)^{n-1}p$? How does it turn out to be $(1-p)^{n-1}$?</p>

<p>Any help would be appreciated.</p>
",<probability>
"<p>I am new in this forum and I am happy to find it, because it seems a very precious place for asking questions.
My question is  about some probability inequality. I formulate this as following.
Let $(X_k)_{1\leq k \leq K}$, with $K$ a nonzero integer, be a discrete-random variables live in   $\{2, ..., n\}$ where $n \geq 2$ . Then, if  $(n_k)_{0\leq k \leq K}$, with $n_0 =1$, is a sequence of integers in  $\{1, ..., n\}$, one can prove that
$$ \mathbb{P}\big( \exists k\in \{1, ...., K\};\, X_k \leq n_{k-1}\big) \leq \sum_{k=1}^K 2^{k-1}\mathbb{P}\big(\max\{ 1\leq \ell \leq K; X_\ell \leq n_{\ell-1}\} = k\big).
$$ </p>

<p>Thank you very much for your sugggestions, </p>

<p>Emera</p>
",<probability>
"<p>This is what I got. $\dfrac{1}{6} \cdot \dfrac{1}{6} = 2.78\% \cdot 24 = 66.72\%$</p>

<p>I believe that since it is a six sided dice, since you roll both of them simultaneously it would be $\dfrac{1}{6} \cdot \dfrac{1}{6}$. </p>

<p>So since they are rolling them $24$ times, I would just multiply it by $24$, so $2.78\% * 24$ would be $66.72\%$, which would mean I have a  $67.7\%$ chance of rolling a double six.</p>

<blockquote>
  <p>Do you think this is correct? Am i doing this correctly? </p>
</blockquote>
",<probability>
"<p>I'm facing the following problem.</p>

<p>Let's say I have N dices in a hand. I need to calculate how much time I should roll my dices to make all of them equal selected (pre-defined) number. Each time when I roll dice with selected number I'm removing this dice(s) from my hand and roll the rest.</p>

<p>Example:
I have 2 dices and I want to all six. I'm rolling two dices until I will get 6 (or possible two) six. When I will get one I will remove this dice and will roll 1 dice instead of two. How much times I need roll dices in my hand to get all six (to make my hand empty)?</p>

<p>I suppose that correct answer is (for two dices): 1/6 + 1/6 + 1/6*1/6 but it seems to be wrong because I tried to implement algorythm to calculate probability running 1M continuous rolls to calculate average amount of required rolls.</p>

<p>Any help appreciated</p>
",<probability>
"<p>I've had a crack at this question however I don't seem to be getting the correct answer and I can't figure out why. I've been given a table of the 'Normal Distribution Function' where the left tail is tabulated for $0\leq x\leq 4$.</p>

<blockquote>
  <p>Given that $Z\sim N(0,1)$, what is the value of $P(-1.1 &lt; Z &lt; 0.35)$
  to 4 decimal places?</p>
</blockquote>

<p>My working is as follows:
Rearranging the equation first then looking up the values in the given tables.
$$P(Z &lt; 0.35) - P(X &gt; -1.1)$$
$$P(Z &lt; 0.35) - P(X &lt; 1.1)$$
$$0.6368 - 0.8643 = -0.2275$$</p>

<p>The given answer for this question is $0.5011$.</p>

<p>Could someone please explain where I'm falling short and how to correctly solve this question?</p>
",<probability>
"<p>A family is considering buying a dog. The probability that they will buy a small dog is $0.1$, that they will buy a medium-size dog is $0.3$, that they will buy a large dog is $0.2$, and that they will buy a very large dog is $0.1$. What is the probability that the family will buy a dog? </p>
",<probability>
"<blockquote>
  <p>Let $\phi_X(t)$ be the characteristic function of $X$. Let $N$ be a Poisson random varivale with mean $1$ and $(X_i)_{\in\mathbb{N}}$ be i.i.d. copies of $X$. Then how to derive the charactersitics function of $S=\sum_{i=1}^NX_i$.</p>
</blockquote>

<p>My attempts: $\phi_S(t)=E(e^{it\sum_{i=1}^NX_i}).$ How to continue?</p>
",<probability>
"<p>A restaurant has 3 fish dishes, 6 meat dishes and 5 vegetarian dishes on the menu. Suppose that customers select their dish at random. Five customers enter the restaurant.
Note that more than one customer can have the same dish.</p>

<p>a) What is the probability that the first customer chooses a vegetarian and two fish dishes are chosen?</p>

<p>b)What is the probability that two customers choose a fish dish given that only one customer chooses a vegetarian dish?</p>

<p>c)What is the probability that the first customer orders a fish and the second, a vegetarian?</p>

<p>Very interested in how probability distribution can be used in solving these, my current approach was the conventional use of combinations and permutations but not getting the correct answers.</p>
",<probability>
"<p><strong>Problem.</strong> Suppose we have $n + 1$ random variable $\xi_0, \xi_1, \dots, \xi_n$ and they are independent and all standard normal distributed. Find probability that $\xi_0$ greater than $\max\{\xi_1, \dots, \xi_n\}$ at least in $\alpha &gt; 1$ times.</p>

<p><strong>Solution.</strong></p>

<ol>
<li><p>Let's find distribution of $\max\{\xi_1, \dots, \xi_n\}$. For me it's pretty obvious and intuitive that if $\xi_0$ has a distribution $F(x)$ and density $f(x)$ then $\max\{\xi_1, \dots, \xi_n\}$ distributed like $(F(x))^n$ and its density will be $f(x)n(F(x))^{n-1}$.</p></li>
<li><p>Let's integrate it over suitable domain.
$$
\int_{-\infty}^{+\infty} \int_{\alpha y}^{+\infty} f(x) n(F(y))^{n-1}f(y) dx dy = \int_{-\infty}^{+\infty} (1 - F(\alpha y)) n(F(y))^{n-1}f(y) dy
$$</p></li>
</ol>

<p>and I don't know how to deal with this integral because $F(x)$ has no good explicit form.</p>
",<probability>
"<p>I got this problem:</p>

<p>Given a $7\times 7$ grid, if we distribute $29$ disks on the grid such that each square cannot hold more than $1$ disk, what is the probability that there will be at least one row full of disks on the grid?</p>

<p>My first try:<br/>
$P(\{\text{there is at least one row full of disks}\}= \frac{7\times{42\choose 22}}{49\choose 29}$</p>

<p>Since we have $7$ ways to choose the row that we will fill by disks, and then we have remaining $22$ disks which we will distribute over the remaining $42$ squares. But this is obviously wrong since we count some combinations multiple times.</p>

<p>My second try:<br/>
$P(\{ \text{there is at least one row full of disks}\}= P(\{\text{there is exactly 1 row full of disks}\}\cup\{\text{there is exactly 2 rows full of disks}\}\cup\{\text{there is exactly 3 rows full of disks}\}\cup\{\text{there is exactly 4 rows full of disks}\})=P(\{\text{there is exactly 1 row full of disks}\}+P(\{\text{there is exactly 2 rows full of disks}\}+P(\{\text{there is exactly 3 rows full of disks}\}+P(\{\text{there is exactly 4 rows full of disks}\}$</p>

<p>But this probably makes things harder and does not simplifies things.</p>

<p>My third try:<br/>
$P(\{\text{there is at least one row full of disks}\}= 1-P(\{\text{there are no rows full of disks}\})$</p>

<p>But I got stuck, I tried to count the number of combinations in which each row got an empty square but here too I counted some combinations multiple times.</p>

<p>Any hint/help will be appreciated.</p>
",<probability>
"<p>How do we use the Chernoff bound to prove that </p>

<p>$$ Q(x)\leq e^{-\frac{x^{2}}{2}} $$</p>

<p>where Q(x) is the probability that a standard normal random variable X takes a value greater than x</p>
",<probability>
"<p>I am having a very hard time understanding Strict Sense Stationary Random Processes(SSSRP). One of the examples I am given has $X[n]$ being a SSSRP. We then have $Y[n] = X[n]^2$. Does this make $Y[n]$ SSS? </p>

<p>I originally thought yes, because $Y[n+t] = X[n+t]^2$ which would make it SSS, correct? </p>

<p>(Homework)</p>
",<probability>
"<p>I just came back from a class on Probability in Game Theory, and was musing over something in my head.</p>

<p>Assuming, for the sake of the question:</p>

<ul>
<li>Playing cards in their current state have been around for approximately eight centuries</li>
<li>A deck of playing cards is shuffled to a random configuration one billion times per day</li>
<li>Every shuffle ever is completely (theoretically) random and unaffected by biases caused by human shuffling and the games the cards are used for</li>
<li>By ""deck of cards"", I refer to a stack of unordered $52$ unique cards, with a composition that is identical from deck to deck.</li>
</ul>

<p>This would, approximately, be on the order of $3 \cdot 10^{14}$ random shuffles in the history of playing cards.</p>

<p>If I were to shuffle a new deck today, completely randomly, what are the probabilistic odds (out of $1$) that you create a new unique permutation of the playing cards that has never before been achieved in the history of $3 \cdot 10^{14}$ similarly random shuffles?</p>

<p>My first thought was to think that it was a simple matter of $\frac{1}{52!} \cdot 3 \cdot 10^{14}$, but then I ran into things like <a href=""http://en.wikipedia.org/wiki/Birthday_Paradox"">Birthday Paradox</a>.  While it is not analogous (I would have to be asking about the odds that any two shuffled decks in the history of shuffled decks ever matched), it has caused me to question my intuitive notions of Probability.</p>

<p>What is wrong in my initial approach, if it is wrong?</p>

<p>What is the true probability?</p>

<p>And, if the probability is less than $0.5$, if we how many more years (centuries?) must we wait, assuming the current rate of one billion shuffles per day, until we reach a state where the probability is $0.5$+?   $0.9$+?</p>

<p>(Out of curiosity, it would be neat to know the analogous birthday paradox answer, as well)</p>
",<probability>
"<p>Randomly break a stick (or a piece of dry spaghetti, etc.) in two places, forming three pieces.  The probability that these three pieces can form a triangle is $\frac14$ (coordinatize the stick form $0$ to $1$, call the breaking points $x$ and $y$, consider the unit square of the coordinate plane, shade the areas that satisfy the triangle inequality <em>edit</em>: see comments on the question, below, for a better explanation of this).</p>

<p>The other day in class<sup>*</sup>, my professor was demonstrating how to do a Monte Carlo simulation of this problem on a calculator and wrote a program that, for each trial did the following:</p>

<ol>
<li>Pick a random number $x$ between $0$ and $1$.  This is the first side length.</li>
<li>Pick a random number $y$ between $0$ and $1 - x$ (the remaning part of the stick).  This is the second side length.</li>
<li>The third side length is $1 - x - y$.</li>
<li>Test if the three side lengths satisfy the triangle inequality (in all three permutations).</li>
</ol>

<p>He ran around $1000$ trials and was getting $0.19$, which he said was probably just random-chance error off $0.25$, but every time the program was run, no matter who's calculator we used, the result was around $0.19$.</p>

<p>What's wrong with the simulation method?  What is the theoretical answer to the problem actually being simulated?</p>

<p>(<sup>*</sup> the other day was more than $10$ years ago)</p>
",<probability>
"<p>Two mathematicians each come into a coffee shop at a random time between 8:00 a.m. and 9:00 a.m. each day. Each orders a cup of coffee then sits at a table, reading a newspaper for 20 minutes before leaving to go to work.</p>

<p>On any day, what is the probability that both mathematicians are at the coffee shop at the same time (that is, their arrival times are within 20 minutes of each other)?</p>
",<probability>
"<p>Recently I discussed an experiment with a friend. Assume we start a random experiment. At first there is an array with size $100,000$, all set to $0$. We calculate at each round a random number modulo $2$ and select one random position in that array. If the number in the array is $1$, nothing is changed and otherwise the pre-computed value is set. The question is: how many distinct hash values would we have added in $1$%, $5$%, $50$%, $95$%, $99$% of all cases?</p>

<p>Example: $4$ rounds with array of size $10$:</p>

<pre><code>Array                     Position   random number
[0,...,0]                    5              0
[0,...,0]                    7              1
[0,...0,1,0,0,0]             6              1
[0,..0,.1,1,0,0,0]           6              0
[0,..0,.1,1,0,0,0]           2              0
</code></pre>

<p>First we considered this a somehow simple problem, but after thinking for some hours, searching the web, and asking some math students, we couldn't find a solution. Do you know a probability distribution for this problem? </p>

<p>Remark: Was also posted on <a href=""http://mathoverflow.net/questions/33335/looking-for-a-probability-distribution"">Math Overflow</a> and got its answer there.</p>
",<probability>
"<p>Say there are three jars, $j_1, j_2, j_3$ filled with different binary sequences of length two.  </p>

<p>The distribution of the binary sequences in each of the jars is given by the $p_i^k(1-p_i)^{n-k}$, where 
$p_i = \frac{i}{m + 1}$ where $m$ is the number of jars, $i$ is the jar index, $k $is number of 1$$'s and $n$ is the length of the string.  </p>

<p>So for three jars we have $p_1 = 0.25, p_2 = 0.5$, and $p_3 = 0.75$ for $j_1, j_2, j_3$ respectively.  </p>

<p>Here are the sequences and their probabilities for $j_1$ with $p_1 = 0.25$:</p>

<p>\begin{align*}
P(00) = 9 / 16 \\
P(10) = 3 / 16 \\  
P(01) = 3 / 16 \\  
P(11) = 1 / 16.
\end{align*}</p>

<p>If I tell you that I have selected a binary sequence and the first element is $1$ what is the E($p_i$)?</p>

<p>Well, this can be calculated by looking at each of the jars and adding up the probability of candidate sequences times the value of $p_i$.</p>

<p><strong>Edit:</strong> I wasn't normalizing this conditionally space properly. I'm skipping a step which I'll explain, someone wants.</p>

<p>\begin{equation*}
E(p_i) = (4/24 * 1/4) + (8/24 * 1/2) + (12/24 * 3/4) = 14 / 24 = 0.58.
\end{equation*}</p>

<p>So the question is ... what is $E(p_i)$ when the numbers of jars goes to infinity (or alternatively, when $p$ can take on values between $0$ and $1$)? Also what happens when the size of the binary strings goes to infinity? Does it have an effect on the outcome? If it does, does the order we take the limits change the answer?</p>

<p>And most importantly what is the general case for when I have $s$ 1's and $r$ $0$'s?, with a continuous $p$ from $0$ to $1$ and infinite sequences?</p>
",<probability>
"<p>A rather fundamental concept which I somewhat failed to grasp and now is jeopardising my further understanding/solving of probability problems..</p>

<p>In the case of this question, where we are to find the probability, that the minimum of two throws of a fair die equals $k$, $k \leq 6, k \in \mathbb{N}$, do we have to account for the ordering of the dice? </p>

<p>I.e., assuming $k = 3$, is the probability $P(\{3\}) = \frac{1}{6}\times\frac{4}{6}\times 2$ in order to account for the fact that the first throw could be $3$ and the second throw anything from $3$ onwards OR vice versa (the first throw anything from $3$ onwards and the second throw $= 3$)? Or should it just be $P(\{3\}) = \frac{1}{6}\times\frac{4}{6}$ since the dice are similar and there is no mention that the two dice are unique (e.g. different in colour, size etc.).</p>

<p>The general question, hence, is, for cases where coins/dice are involved and are not uniquely labelled, should the order be regarded, if there is no additional mention of a first/second throw? </p>

<p>Hope you all get my drift..</p>
",<probability>
"<blockquote>
  <p>Let $A$ and $B$ be events, $P(A) = \frac{1}{4} $, $P(A\cup B) = \frac{1}{3} $ and $ P (B) = p $. </p>
  
  <ol>
  <li>Find $p$, if $A$ and $B$ are mutually exclusive.</li>
  <li>Find $p$, if $A$ and $B$ are independent.</li>
  <li>Find $p$, if $A$ is a subset $B$.</li>
  </ol>
</blockquote>

<p>Can someone help me to solve it?</p>
",<probability>
"<p>$n$ balls, each with a weight $p_i$, are thrown into $m$ bins. Each bin is chosen with uniform probability.</p>

<p>Prove or disprove that the expected value of the maximum load among the loads of bins is $\frac1m\sum_{j=1}^n p_j$, where with ""load"" means the sum of the weights of the balls in that bin.</p>

<p>Now, I was able to model the problem on the expected value of each bin and this is:
$E[X_i]=\frac1m\sum_{j=1}^n p_j$, where $X_i$ is the load of the bin $i$.</p>

<p>Should I calculate something like this:
$$E[\max_{1 \leq i \leq n} {X_i}]$$</p>

<p>Do you have any idea? Or is the equation to disprove? But, I have no idea how to have to find a counterexample to disprove with expected values.</p>
",<probability>
"<p>Suppose we pick a random real number between 0 and 1 and call it $x$. There are $2^{\aleph_0}$ possible values, so the chance of picking any specific number (such as $x$) in that range is 0. But in the end, we did manage to pick $x$, despite its probability of 0.</p>

<p>Does this mean that a 0% chance is actually possible, or is there some flaw in this logic?</p>
",<probability>
"<p>Given the probability density function of the random variable $X$ is $f_X(x)$ and the probability of set $A=\{x:a&lt;X&lt;b\}.$ How can we find the conditional probability density function $f_{X\mid A}(x)$?</p>

<p>My attempt:</p>

<p>When $x\notin A$, $f_{X\mid A}(x)=0.$</p>

<p><strong>Correction according to comment</strong>
When $x\in A$, $f_{X\mid A}(x)=\cfrac{f_X(y)}{P(A)}$ where $P(A)$ is the probability of even $A$.</p>

<p>This seems to give a valid probability distribution that sums to 1. But I am not sure if it is correct. Also is it a definition that I just wrote? Or can we derive it from some fundamentals?</p>

<p>Thanks a lot in advance. </p>
",<probability>
"<p>Suppose I have $20$ red balls in one box and $20$ blue balls in another box. There $12$ red balls and $7$ blue balls have stars on them. </p>

<p>I randomly take out one red ball and one blue ball at each time, don't put them back, and repeat this $10$ times. </p>

<p>What is the probability that I get one red ball with stars and one blue ball with stars for at least $5$ times?   </p>
",<probability>
"<p>I have four random variables <strong>A,B,C</strong> and <strong>S</strong>. A,B and C are conditionally independent given S. So, I need to obtain <strong>P(A,B,C,S)</strong></p>

<p>By the chain rule:
$$P(A,B,C,S)=P(S)P(A|S)P(B|A,S)P(C|A,B,S)$$
By the conditional independence
$$P(B|A,S)=P(B|S)$$
Is this correct? $$P(C|A,B,S)=P(C|S)$$
So $$P(A,B,C,S)=P(S)P(A|S)P(B|S)P(C|S)$$</p>

<p>Also I have doubts in the calculation of the joint probability between A,B and C.
$$P(A,B,C)=P(A)P(B|A)P(C|A,B)$$
I am not sure how to compute $P(C|A,B)$ I know the diverse marginal probabilities and conditional between two variables.
Thanks.</p>
",<probability>
"<p>Suppose $\sum_{n=1}^\infty X_n = \infty$ almost surely for nonnegative $X_n$. Let $\mathcal F_n = \sigma(\{X_0, X_1, \ldots, X_n \})$. </p>

<p>Can we show that $\sum_{n=1}^\infty \mathbf{E} (X_n | \mathcal F_{n-1}) = \infty$? </p>
",<probability>
"<p>Suppose $X_1, X_2, \ldots, X_n$ are a Bernoulli($\theta$) with pmf:</p>

<p>$$P(X|\theta)=\theta^X(1-\theta)^{1-X}, \; X \in \{0,1\}$$</p>

<p>Prove or disprove that $\bar{X}(1-\bar{X})$ is an unbiased estimator of $\theta(1-\theta)$</p>

<p>My attempt:</p>

<p>After taking the expectation of $\bar{X}(1-\bar{X})$, I'm getting $E(\bar{X})-E(\bar{X}^2)$. I know that $E(\bar{X}^2)=Var(\bar{X}^2)+[E(\bar{X})]^2$.</p>

<p>If I'm on the right course, how do I calculate $Var(\bar{X}^2)$?
Or Is there an alternative method for this?</p>
",<probability>
"<p>First of all, I'm asking this because I'm writing a game, so this is probably not a typical question in probability. However I'm new to game design so I don't even know what this would be called.</p>

<p>Suppose I have a certain event that should occur and the probability of that event happening (over a certain amount of time). For example, let's suppose the probability is 15% per day.</p>

<p>Is there a <em>single calculation</em> I can perform that will, along with an evenly distributed random number, predict <em>when</em> that event will occur?</p>

<p>Predict is probably not the best word to use here, since I'm not going for accuracy in a single prediction, only a realistic distribution, were it to be predicted over and over again with different random numbers.</p>

<p>Ideally it should not be limited to a certain temporal resolution. I.e. it should not be an even number of days, but should be a continuous function giving me a result right down to the second.</p>
",<probability>
"<p>Suppose you roll a fair 6-sided dice three times. There are $6^3$ possible outcomes and each is equally likely.</p>

<p>Let $A_1$, $A_2$, $A_3$, $A_4$, $A_5$, and $A_6$ be the events that the last value is a $1$,$2$,$3$,$4$,$5$, and $6$ respectively. 
Let $B$ be the event that the first value is less or equal to the second value and the second value is less or equal to the
third value.</p>

<p>What is $P(B)$?</p>

<p>The total probability law states that </p>

<p>$$P(B) = P(A_i)P(B|A_i)+....+P(A_n)P(B|A_n)$$</p>

<p>Let's assume that $x_i$ are values of $A_i\cap B$, then 
$$P(B|A_n) = \frac{x_i}{P(A_i)}$$</p>

<p>What I am getting confused at is that, if I substitute $P(B|A_n)$ in I'd get $$P(A_i)\frac{x_i}{P(A_i)} = x_i+...+x_n$$ which is just the addition of $x_i$'s.</p>

<p>I don't feel this is the correct way to simplify the total probability law. I am looking for some clarification. </p>
",<probability>
"<p>How to find a Probability Density/Mass Function for a random variable without assuming it follows a predetermined distribution, say, Normal or Poisson etc,. Lets say i have two hours of data of vehicle arrives at a specific point and i want to know what kind of distribution it has? Please help me understand this. Thank You, Guys.</p>
",<probability>
"<p>Good morning,</p>

<p>I want to calculate the probability density function of a random variate $Z=cos(Y)$, where $Y=Φ_1−Φ_2$ and $Φ_{1,2}∼U(0,2π)$, that is both variables are uniformly distributed in $(0,2π)$ and also independent. This last hypothesis makes $Y$ a triangular distribution in $(−2π,2π)$, so with this pdf:
\begin{equation}
f_Y(y)=\frac{1}{2π}\biggl( 1−\frac{|y|}{2π} \biggr )
\end{equation}</p>

<p>I calculate Z using the funtamental theorem. When $−2π&lt;y&lt;2π$ we have 4 solution to the equation $z=cos(y)$:
\begin{align}
f_Z(z) &amp; =∑f_Y(\cos^{−1}(z)) \biggl |\frac{1}{−\sin(\cos^{−1}(z))} \biggr |  =4⋅\frac{\frac{1}{2π}(1−\frac{|\cos^{−1}(z)|}{2π})}{\sqrt{1-z^2}} \\
&amp;=\frac{2\biggl (1−\frac{\cos^{−1}(z)}{2π}\biggr)}{π \sqrt{1 - z^2}},  \ \ \ \ \ \ −2π&lt;\cos^{−1}(z)&lt;2π
\end{align}</p>

<p>I have now two problems:</p>

<ol>
<li><p>it's not verified the property of normalisation of $f_Z(z)$;</p></li>
<li><p>if I calculate the cumulative distribution function by integrating the pdf from $-1$ to $\infty$
$$
    F_Z(z)=\frac{\cos^{−1}(z)(\cos^{−1}(z)−4π)}{2π^2}+3/2
$$
and compare this CDF with the ECDF estimated with Matlab, the <a href=""http://i.stack.imgur.com/CQIWD.jpg"" rel=""nofollow"">comparison</a> is not good, it's like something's missing.</p></li>
</ol>

<p>Somebody can tell me where's the mistake?</p>

<p>Thanks for your help, </p>

<p>Stephen</p>
",<probability>
"<p>Recall that a forward contract on $S_T$ contracted at time $t$, with time of delivery $T$, and with forward price $f(t; T, S_T)$ can be seen as a contingent T-claim $X$ with payoff:
$$
X = S_T - f(t; T, S_T)
$$
The forward price is determined at time t in such a way that the price of X is zero at time t, i.e. $\pi(t;X) = 0$.</p>

<p>How can I compute the forward price $f(t; T, S_T )$ in the Black-Scholes model?</p>
",<probability>
"<p>Assume that $X,X_1,X_2,...$ are iid with characteristic function $\phi(t)=\mathbb E[e^{itx}]$, and let $S_n = X_1 + X_2 + X_3 + ...$.</p>

<p>(a) For a random variable $X$, $X$ and $-X$ have the same distribution iff $\phi$ is real.</p>

<p>Comment: I can show this by the inversion formula. I just plug in the formula; however, is there a simple way to see this rather than writing all the steps out?</p>

<p>(b) Express the characteristic function of the sample average, $\phi_{\frac{S_n}{n}}(t)$, in terms of $\phi$.</p>

<p>Comment: This one is easy. $\phi_{\frac{S_n}{n}}(t) = [\phi(\frac{t}{n})]^n$.</p>

<p>(c) Assume $\phi'(0)=0$. Show that $\frac{S_n}{n}$ converges to zero in probability.</p>

<p>I have no idea about this one.</p>

<p>For (d) and (e), we assume $X$ has density: $f(x)=c\frac{1}{x^2 ln|x|} \chi_{\{|x|&gt;4\}}$, where $c$ is the appropriate normalizing constant.</p>

<p>(d) Show $\mathbb E{|X|}=\infty$</p>

<p>Commnet: Just plug in the definition formula of the expectation.</p>

<p>(e) Show that the ch.f for $X$ has $\phi'(0)=0$.</p>

<p>Like (c), I don't know how to show this one either.</p>

<p>Thanks.</p>
",<probability>
"<p>If I have a $6,7$ spades in my hand, and the flop shows $4$ clubs, $5$ spades and $Q$ spades. What is the probability I will hit my straight or flush with $2$ cards still to come?  I see $15$ cards that help me with $32$ that don't help me. So about $32\%$ with one card. But with $2$ yet to come?</p>
",<probability>
"<p>I'm given a circle with point $A$ defined by $(x,y)$. Then $T=1-d[O,A]$, so $T=1-\sqrt{(x^2+y^2)}$.</p>

<p>Asked to find:</p>

<ol>
<li>$P[T&lt;=u]$</li>
<li>$E[T]$</li>
<li>$Var(T)$</li>
</ol>

<hr>

<p>Alright, so $d[O,A]$ has the CDF $u^2$. So, for the first piece, $P[T&lt;=u]=1-u^2$.</p>

<p>However, our professor has given us also the hint that $u^2$ is beta-distributed. For $Y$ that follows a beta distribution,</p>

<p>$$E[Y]=\frac{a}{a+b}$$
  $$Var(Y)=\frac{ab}{(a+b)^2(a+b+1)}$$</p>

<p>So I kind of know what the answers are supposed to be, aside from the fact that I don't see how $u^2$ follows a beta distribution, so I don't know what the values $a$ and $b$ would be. </p>

<p>Ultimately, I think the generalized answers are:</p>

<ol start=""2"">
<li>$$E[T]=E[1-Y]=E[1]-E[Y]=1-\frac{a}{a+b}$$</li>
<li><p>$$Var(T)=Var(1-Y)=Var(T)=\frac{ab}{(a+b)^2(a+b+a)}$$</p>

<p>Help uncovering the beta distribution parameters would be greatly appreciated. Thank you!</p></li>
</ol>
",<probability>
"<p>I am developing an app that will create a chart and show trends based on a couple factors, but cannot find the <em>correct</em> way of calculating deviations over a period of time where multiple different scenarios are taken into account and averaged. <strong>Here is an example scenario to help:</strong></p>

<p>Lets say we have two people playing games in a casino. Bob and Tom.</p>

<p>Bob plays <code>3000 hands</code> of Mississippi Stud at an average bet of <code>$25/hand</code>.
Mississippi stud has a <code>variance of 121</code>. House edge of <code>5% (-0.05 EV)</code>.
Here is what Bob's end of session results would look like:</p>

<pre><code>Expected Return (ER): -$3,750 (EV * Avg Bet * Hands)
Most Expected (2 Devs): +$26,374.74 (ER + (sqrt(Hands)*((Avg Bet * sqrt(Variance))*2)
Least Expected (2 Devs): -$33,874.70 (ER - (sqrt(Hands)*((Avg Bet * sqrt(Variance))*2)
</code></pre>

<p>Tom plays <code>5 hands</code> of Blackjack at an average bet of <code>$200/hand</code>. Blackjack has a variance of <code>1.44</code>. House edge of <code>0.5% (-0.005 EV)</code>. Here is what Tom's end of session results would look like:</p>

<pre><code>Expected Return (ER): -$26
Most Expected: +$506
Least Expected: -$454
</code></pre>

<p>Calculating these things is very easy. The problem comes when I try to get the average. If I were to combine both into one line chart, and try to find the Most/Least Expected after BOTH players had finished, I get a very unrealistic number. Since Tom only played 5 hands, his play should barely affect Bob's play and possible variance. After both I get:</p>

<pre><code>ER: -$3,776
Most Expected: $13,440.37
Least Expected: -$17,164.40
</code></pre>

<p>This is definitely incorrect because you cannot simply average them and must take into account the weight of duration. Any help would be greatly appreciated.</p>
",<probability>
"<p>Total number of trials = N. The trials are independent. Probability of success = p. Probability of failure = 1-p. What would be probability of getting m or more consecutive successes?</p>

<p>Is there some online/downloadable efficient software where I can input N, m, p and it gives me the answer? Can scientific calculators can do this job?</p>
",<probability>
"<p>I have the following problem where I have difficulties grasping the intuition: </p>

<blockquote>
  <p>Lets say we have three boxes, with two of them empty and one
  containing a gold price. Lets say we randomly select one of the boxes.
  After our selection, we are given which one of the remaining two boxes <strong>does not</strong> contain the price. Now the question is: Should I
  stick with my original selection or select another box from the two
  possible alternatives left. What are the probabilities?</p>
</blockquote>

<p>I empirically tried this problem by making a computer program to repeat this experiment 1,000,000 times with first staying with the original choice and then always changing the selection. I got the probabilities to be: </p>

<p>$$P(golden\; price\;with\;original\;selection)\approx33\%$$
$$P(golden\; price\;with\;changing\;selection)\approx 66\%$$</p>

<p>Intuitively the probabilities seem at first to be 50% for both of these choices, but it seems it's not the case. I can't grasp on why?...</p>

<p>P.S. please let me know if my question is unclear</p>
",<probability>
"<p>We have: $X_n \rightarrow X$ in $L^p$ and $Y_n \rightarrow Y$ in $L^q$. Moreover $p,q&gt;1$ are such that $\frac{1}{p} + \frac{1}{q} =1$. Prove that $X_nY_n \rightarrow XY$ in $L^1$. Please, can you help?</p>
",<probability>
"<blockquote>
  <p>A fair die and two unbiased coins are tossed. What are possible outcomes of each object and the probability of each outcome?</p>
</blockquote>

<p><strong>My solution:</strong></p>

<ul>
<li>Probability for a fair Die $D$: $\frac{1}{6}$</li>
<li>Probability for unbiased Coin $C_1$:  $\frac{1}{2}$</li>
<li>Probability for unbiased Coin $C_2$: $\frac{1}{2}$</li>
</ul>

<p>So we can calculate it this way:</p>

<p>$$\Pr(D) * \Pr(C_1) * \Pr(C_2) = \frac{1}{6} * \frac{1}{2} * \frac{1}{2} = \frac{1}{6 * 2 * 2} = \frac{1}{24}$$</p>

<p><em>or</em></p>

<p>$$\frac{1}{\binom{6}{1} \binom{2}{1} \binom{2}{1}} = \frac{1}{6 * 2 * 2} = \frac{1}{24}$$</p>

<p><strong>Is this correct?</strong></p>
",<probability>
"<p>I know that the pdf $X$ conditional on $Y=y$ is
$$f_{X|Y}(x|y)=\frac{f_{(X,Y)}(x,y)}{f_Y(y)},$$
and this can be used to calculate conditional probabilities such as $P(X&gt;\alpha | Y&gt;\beta)$ (for example). My question is know do we find conditional probabilities such as $P(X^2&gt;a|Y=b)$ or things of this nature, wherein there is a transformation of the random variable $X$. </p>
",<probability>
"<p>What is the probability that in a randomly chosen group of r people at least three people have the same birthday?</p>

<p>I have tried doing this question as fallows- 1-(probability of all people having different birthday+ any 2 people have same birthday+2 people in each of 2 sets have same birthdays but distinct for particular set+probability of 2 people in each of 3 sets have same birthdays but distinct for particular set+.......) </p>

<p>but i can't generalize it....</p>
",<probability>
"<blockquote>
  <p>Let $50$ balls numerated on a box. Let the event be ""to draw five balls such that the order doesn't matter and there's no replacement"".
  Let $\alpha \in\{1,2,...,50\}$. The probability of $\alpha$ being drawn is given by 
  $\frac{^{49}C_{4}}{^{50}C_{5}}$.</p>
</blockquote>

<p>But if the event is repeated $n$ times, how can I compute the probability of the $\alpha$ number to be drawn again, $p$ times $\left( p \leq n \right)$?</p>

<p>I thought about the binomial distribution where the probability of success is $\frac{^{49}C_{4}}{^{50}C_{5}} \approx 0,1$.</p>
",<probability>
"<p>Let $X_t,t\geq 0$ be a Poisson process with rate parameter $\lambda$. Compute the Karhunen-Loève expansion of $X$ in interval $[0, T]$. How about the KL expansion of the centered process $X_t−\lambda t$?</p>

<p>The auto-correlation function of Poisson process is $R(s,t)=\lambda^2st+\lambda \min(s,t)$. By definition, KL expansion should satisfy $\int^T_0 R(s,t)\phi_n(t)dt=\lambda_n \phi_n(s)$.</p>

<p>I've problems figuring out how to solve the integrated equation.</p>

<p>For Wiener process, <a href=""http://mathoverflow.net/questions/59337/karhunenloeve-approximation-of-brownian-motion-and-diffusions"" rel=""nofollow"">this link</a> and Wikipedia article on KL expansion was useful.</p>

<p>This is a mirror question of <a href=""http://mathoverflow.net/questions/95941/karhunen-loeve-expansion-of-poisson-process"" rel=""nofollow"">this MO question</a>.</p>
",<probability>
"<p>A fair die is thrown until a score of less than 5 is obtained. How to find the probability of less than 3 in the last throw?</p>

<p>I am not too sure how to approach this one, any ideas?</p>
",<probability>
"<p>On <a href=""http://en.wikipedia.org/wiki/Benford%27s_law"" rel=""nofollow"">wikipedia</a> i have find this statement:</p>

<blockquote>
  <p>...it is scale invariant, and the only continuous distribution that fits this (scale invariance) is one whose logarithm is uniformly distributed.</p>
</blockquote>

<p>how can be proven?</p>
",<probability>
"<p>I am trying to show the following: </p>

<p>\begin{equation*}
E[e^{-\gamma W}]=e^{-\gamma(E[W]-\frac{\gamma}{2}Var [W])}
\end{equation*}</p>

<p>but I really can't remember what I am supposed to do to get from the LHS to the RHS. I have tried using integration this way</p>

<p>\begin{equation*}
\int We^{-\gamma W}dW
\end{equation*}</p>

<p>and then use integration by parts, but even though what I get resembles it, it can't be correct (because $e^{-\gamma W}$ is not the distribution of W).</p>

<p>I have also tried using Taylor series expansion, but I think I am way off, and I don't think an approximation here is what I need, because the equality above is exact.</p>

<p>FYI, this is not homework, I am working through a <a href=""http://www.princeton.edu/~markus/research/papers/liquidity.pdf"" rel=""nofollow"">paper</a> (page 10) and I would really like to know how every step was derived.</p>

<p>Can anyone at least point me to the right direction?</p>

<p><strong>EDIT</strong>: This expectation on the RHS is very similar to the moment generating function formula (with a negative exponent). If you check <a href=""http://en.wikipedia.org/wiki/Moment-generating_function#Examples"" rel=""nofollow"">here</a>, you will see that the moment generating function for the normal distribution is like the LHS (but with a positive sign). So in a way I have my answer, but I still would like to know how to derive it, if there is a way. I know little if anything at all about moment generating functions, so maybe I shouldn't try and derive it but rather just use the result? Does it even make sense to try and derive it?</p>
",<probability>
"<p>When I have watched Deal or No Deal (I try not to make a habit of it) I always do little sums in my head to work out if the banker is offering a good deal. Where odds drop below ""evens"" it's easy to see it's a bad deal, but what would be the correct mathematical way to decide if you're getting a good deal?</p>
",<probability>
"<p>Let $P$ be a probability function. It satisfied <a href=""http://en.wikipedia.org/wiki/Probability_axioms"" rel=""nofollow"">probability axioms</a>. Can we deduce from it that if $P(A)=0$ then $A=\emptyset $ ?</p>
",<probability>
"<p>I'm failing to understand how to come to the answer to this question.</p>

<p>If you roll a fair die six times, what is the probability that the numbers recorded are $1$, $2$, $3$, $4$, $5$, and $6$ in any order?</p>

<p>The answer given is $6!(1/6)^6 = 3/324$</p>

<p>Can anyone explain to me how to get to that answer? I would really appreciate the help! :)</p>
",<probability>
"<p>There is a classic problem:</p>

<blockquote>
  <p>Suppose that $X_1,\ldots,X_n$ form an i.i.d. sample from a distribution with the following pdf:</p>
  
  <p>$$f(x\mid\theta) = 
\begin{cases}
e^{\theta-x}\quad&amp;\text{for }\, x&gt; \theta \\
0 &amp;\text{otherwise}.
\end{cases}$$</p>
</blockquote>

<p>I would like to show that the MLE of $\theta$ does not exist. </p>

<p>The argument I have is that the likelihood function will be a maximum when $\theta$ is made as large as possible subject to the strict inequality $\theta &lt; \min\{X_1, \ldots, X_n\}$. Therefore, the value $\theta = \min\{X_1,\ldots , X_n\}$ cannot be used and there is no MLE.</p>

<p>However, I do not understand WHY we want $\theta$ to the equal to the maximum of the values. </p>

<p>Also, is there a way to show mathematically why this MLE doesn't exist?</p>

<p>I get that the log-likelihood function is:</p>

<p>$$L(\theta) = n\theta - (X_1+\ldots+X_n)$$</p>

<p>but when you differentiate via $\theta$ and set to $0$, we get:</p>

<p>$n=0$. How does the fact $n=0$ fit into the fact the MLE doesn't exist for $\theta$? Thanks!</p>
",<probability>
"<p>Let $X$ be random variable such that $\begin{align} F_X(x) = 1- e^{-x} \end{align}$ if $x \ge 0$ and $F_X(x)=0$ in other case. Find distribution function $Y= \min(1,X)$, $Z=\max(1,X)$. </p>

<p>If I have to find $\max(X,Y)$ or $\min(X,Y)$ ($X,Y$ - random variable) I don't have any problem. But in this case I have number - what should I do?</p>
",<probability>
"<p>A wheel of fortune is divided into 40 sectors, numbered from 1 to 40. Tickets are sold representing each sector. Tickets are \$1 each. All 40 tickets must be sold before the wheel can be spun. Only the winning ticket receives a \$10 prize.  Calculate the probability of winning the \$10 prize in one game and again in the next game.</p>
",<probability>
"<p>Given $\bar{X} \sim N(\bar{\mu}, \sigma)$ is a vector of independent continuous random variables (with identical variance) and $Y_j = ( \bar w_{j} \cdot \bar X + b_j &gt; 0)$ is a set of dependent discrete random variables is there a nice expression for the joint probability $P(Y_0 = 1, Y_1 = 1)$?</p>

<p>Also, I think the marginal distributions are given by: </p>

<p>$P(Y_j=1) = \int^{\infty}_{0} N(\bar w_j \cdot \bar \mu + b_j, \sigma) dx = 0.5 - 0.5 erf \left ( -{\bar w_j \cdot \bar \mu + b_j \over \sigma \sqrt {2}} \right )$</p>

<p>Is this correct?</p>
",<probability>
"<p>I have a midterm I am studying for and I don't have the solutions to this homework problem. Can anyone please explain how to do it? I would really appreciate it.
Here is the problem:</p>

<p><a href=""http://i.stack.imgur.com/oTIYm.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/oTIYm.png"" alt=""two tables of MATHEMATICS letters""></a></p>

<p>I googled the answer for this question, but I did not understand the solution. Can anyone please explain or give their own interpretation of the answer? Thanks!!</p>

<p><a href=""http://users.wpi.edu/~hservat/cs2022d12finalsolutions.pdf"" rel=""nofollow"">http://users.wpi.edu/~hservat/cs2022d12finalsolutions.pdf</a> </p>

<p>Page 2 has the solution I am confused about.</p>
",<probability>
"<p>Suppose you pick a number between $1$ and $30$ uniformly at random. Let $A$ be the event that
the number is even. Let $B$ be the event that the number is divisible by $3$. Let $C$ be the event that the number
is divisible by $5$. Using the above formula, what is the probability that the number is divisible be at least one
of the values $2, 3,$ or $5$?</p>

<p>$$|A|=15$$
 $$ |B| = 10$$
 $$ |C| = 6$$</p>

<p>From what I have worked out</p>

<p>$$P(A) = \frac{1}{2}$$
$$P(B) = \frac{1}{3}$$
$$P(C) = \frac{1}{5}$$
$$P(A \cap B) = \frac{1}{6}$$
$$P(A \cap C) = \frac{1}{10}$$
$$P(B \cap C) = \frac{1}{15}$$</p>

<p>I am using the formula of inclusion=exclusion</p>

<p>$$ P(A ∪ B ∪ C) = P(A) + P(B) + P(C) − P(A ∩ B) − P(A ∩ C) − P(B ∩ C) + P(A ∩ B ∩ C)$$</p>

<p>When I add it all up I end up with $P(A ∪ B ∪ C) = 1.03$ </p>

<p>How is that possible? Logically, there are 8 numbers that would not divide by $2,3,5$ Thus, if you take the opposite, there should be $\frac{22}{30}$ probability that you would get a number divisible by $2,3,5$. So what am I doing wrong?!</p>
",<probability>
"<p>Let $X\to Y\to Z$ be three random variables.</p>

<p>The data processing inequality states $I(X;Y)\geq I(X;Z)$.</p>

<p>Further assume $Y=f(X)$ where $f:\mathcal{X}\to\mathcal{Y}$ is an arbitrary function.</p>

<p>What more can we say about how $I(Y;Z)=I(f(X);Z)$ relates to $I(X;Y)=I(X;f(X))$ and $I(X;Z)$?</p>

<p>I.e. can one somehow add the mutual informations along the path or obtain an inequality relating the three pairwise mutual informations? Somehow the choice of $f$ establishes an upper bound on what information can potentially be shared between $X$ and $Z$, but how does it affect the mutual information $I(Y;Z)=I(f(X);Z)$?</p>
",<probability>
"<p>There are four Envelopes with letters. Two are chosen Randomly and opened and found that they are wrongly addressed. Find the Probability that there are exactly two wrongly addressed envelopes.</p>

<p>My Try: Let the Envelopes be $E_1$,$E_2$,$E_3$ and $E_4$ and Corresponding Letters be $L_1$,$L_2$,$L_3$ and $L_4$ Since two opened are found wrongly addressed,implies there are minimum of two wrongly addressed envelopes.So Favorable cases are :</p>

<p>$1$.There are Exactly two wrongly addressed Envelopes i.e.,Remaining two are correctly addressed and this can happen in $\binom{4}{2}=6$ ways</p>

<p>$2$.There are exactly three wrongly addressed envelopes i.e., remaining one has correctly addressed and this an happen in $\binom{4}{3}\left(3!-1\right)=20 $ways</p>

<p>$3.$There are exactly four wrongly addressed envelopes and this an happen in $\left(4!-1\right)=23 $ways, so Required Probability is</p>

<p>$\frac{6}{6+20+23}=\frac{6}{49}$. I am not sure whether i have done in a right way, please help me if i am wrong.</p>
",<probability>
"<p>Boxes 1 and 2 contain 4 white, 3 red and 3 blue balls; and 5 white, 4 red and 3 blue balls respectively. If one ball is drawn at random from each box, what is the probability that both the balls are of the same colour?</p>
",<probability>
"<p>Say we have custom-marked 6-sided die: 1-2-3 is marked as a toad, 4-5 - as a bird, 6 - as a monkey.</p>

<p>So, what is probability of rolling both toad and monkey rolling 4 dice?</p>

<p>I'm totally confused with this example.</p>
",<probability>
"<p>I'm studying Markov's chain and a very important condition is the detailed balance condition.I'm a bit curious and my question is:</p>

<p>Why is detailed balance condition called like that?</p>

<p>Anyone explains this name in any book.</p>
",<probability>
"<p>Assume we have a server, the time between two packets received by our server is defined as exponential distributed with intensity   $\lambda=2 \text{ packets}/10 \text{ mins}$</p>

<p>Now calculate the probability that the time from $X$(random time) until the next packet-received, is $5$ minutes or longer?</p>

<p>We that we can model waiting time as exponential function, therefore we get </p>

<p>$f(t)= (1/10)*e^{-t/10}$</p>

<p>Now we need to find out the probability that the time from $X$(random time) until the next packet-received, is 5 minutes or longer?</p>

<p>We integrate $f(t)$ and get $[e^{-t/10}]$ but i am not sure how to choose my limits ?</p>

<p>Am I thinking right here?</p>
",<probability>
"<blockquote>
  <p>Two envelopes are given. Envelope 1 contains $x$ dollars and envelope 2 contains $2x$ dollars. We opened one of them and found in it $100$$. Now we have the option  to change envelopes or not.</p>
  
  <ol>
  <li><p>Formulate the problem as a Baisian estimation problem.</p></li>
  <li><p>Is it worthwhile to exchange the envelopes? </p></li>
  </ol>
</blockquote>

<p>This is the original question. In order to simplify it, I added the condition that the envelopes can contain only $5{$},10{$},20{$}$ and $100{$}$ bills. </p>

<p>As I understood, a Baisian estimation problem formulation contains the following terms:</p>

<p>$\Omega$-the set of possible states, $X$-the set of observations,$P$-a probablistic model, $A$-possible actions, $\Gamma$-cost for any action.</p>

<p>I also understood that there is a risk function: $R(\alpha_k|x_j)=\Sigma_{\omega_i\in \Omega}\lambda(\alpha_k|\omega_i)P(\omega_i|x_j)$, a probability to be in a state $\omega_i$: $P(\omega_i|x_j)=\frac{P(x_j|\omega_i)}{P(x_j)}P_0(\omega_i)$, and a total risk function: $R[\alpha(x)]=\Sigma_jR(\alpha(x_j)|x_j)P(x_j)$.</p>

<p>But, I am not sure how to build this risk function for the above exercise.
It seems like the set of optional actions is $a_0$-not exchanging envelopes,$a_1$-exchanging envelopes.
What are the possible states set $\Omega$ for example? What is a possible state in this example? If I choose to exchange envelopes and there are $5+5+10$ bills in envelope 1 and $5+5+10+20$ in envelope 2, is this considred one possible state? Also, what is the cost of being wrong?</p>

<p>Any ideas?
Thanks!</p>
",<probability>
"<p>My question is based on the beginning of Chapter 8.3.2 in the book ""Modelling Extremal Events"" by Embrechts,Klüppelberg and Mikosch.
We consider a Cramer-Lundberg-Model and assume that the conditions of the Cramer-Lundberg-Theorem are satiesfied.</p>

<p>More specifically:
Let $X$ be a positive random variable with distribution function $F$ and mean $E[X] = \mu$, $Y$ a random variable, which follows an $Exp(\lambda)$-distribution independent of $X$, $c &gt; 0$ a constant.
We set $Z:=X-cY$.</p>

<p>We assume that the Lundberg-Exponent exists, i.e. a  $\nu &gt; 0$, that satisfies 
$
\int_{0}^{\infty} xe^{\nu x}(1-F(x))dx = \frac{c}{\lambda}
$
Further assume that $X$ has a moment generating function, which is finite in some neighbourhood of $0$.</p>

<p>Now consider $\kappa(s):= E\left[e^{sZ}\right]$. My goal is to show that $\kappa(\nu) = 1$, which is stated in the book without further explaination.</p>

<p>I get that:
$
\kappa(\nu) = E\left[e^{\nu Z}\right] = E\left[e^{\nu X}e^{-\nu cY}\right] = E\left[e^{\nu X}\right] E\left[e^{-\nu cY}\right] = E\left[e^{\nu X}\right] \frac{\lambda}{\lambda + \nu c}
$
but I am stuck at this point and don't see how to use the equation above to show that this is equal to $1$.</p>

<p>Any help is appreciated :)</p>
",<probability>
"<p>I am trying to prove theorem 7.3.23 in Casella and Burger. </p>

<p>Theorem: 
Let T be a complete sufficient statistic for a parameter $\theta$, and let $\phi(T)$ be any estimator based only on T. Then $\phi(T)$ is the best unbiased estimator of its expected value. </p>

<p>Here is my attempt to prove this:</p>

<p>To show that $\phi(T)$ is best unbiased estimator for E[$\phi(T)$], I must show that $\phi(T)$ is uncorrelated with any unbiased estimator of $0$. So I must show that $Cov({\phi(T)}, W)=0$ for any W such that W is an unbiased estimator of $0$. For any W such that E[W]=0, $E[E[W|T]]=0$=>$E[W|T]=0$ by completeness of T. So $E[W|T]=0=E[W]$. So W is independent of T. So W and $\phi(T)$ are uncorrelated? So $\phi(T)$ is best unbiased for  its expected value. Is this correct?</p>
",<probability>
"<p>I have a Markov chain as follows:</p>

<ul>
<li>$G+1$ finite states, it begins from $s=G$ and completes at $s=0$</li>
<li>A transition ($s\to s-1$) occurs in case if event $A$ happens. No other form of transition is possible. Denote the transition probabilities by $P_{ij}^{A}$</li>
</ul>

<p>We want to improve this system to complete faster. So I devised a set of operations denoted by $B$. If $B$ is successful with probability $\beta$, it is just like $A$ is repeated $k$ times, where $k$ is a random variable with known probability. Otherwise, another [real] $A$ should happen to change the state (with probability 1-$\alpha$). Any advise on how to model the Markov chain of the improved system using on $P_{ij}^A$ is appreciated.</p>
",<probability>
"<p>I tried to look for a similar question but didn't find the exact thing (the closest I found was <a href=""http://math.stackexchange.com/questions/102673/what-is-the-expected-number-of-trials-until-x-successes"">this</a> but AFAIK it is not the same)</p>

<p>I have $r$ coins that land heads w.p. $p$. I want at least $m$ heads. On the first step I toss all of $r$ coins and from the second step and on I toss only the coins that didn't land heads already.</p>

<p>What is the expected number of steps until I have at least $m$ heads?</p>

<p>Thank you in advance!</p>
",<probability>
"<p>A and B play a game of chess. They play 20 games of which A wins 12 and B wins 4.The remaining 4 games are drawn.If 3 games are played between them, find the probability that 
i)B wins at least 1 game?ii) the probability that 2 games are drawn?</p>
",<probability>
"<p>I have a problem about intuition:
substracting the mean of iid RVs seems to increase the mutual information.</p>

<p>Say $X,Y$ are real iid RVs, then $\frac{X-Y}{2}$ and $\frac{Y-X}{2}$ are not independent because one is just the negative of the other?</p>

<p>If this is right, it seems contraintuitive to me, as subtracting the mean is such a usual preprocessing step for iid samples.
What am I missing or where did I go completely wrong? It's probably rather stupid but my intuition fails or tricks me here. Guess I am mixing up things. Sorry.</p>
",<probability>
"<p>A box contains $3$ coins . Among these three , each of  two coins have the probability of giving head $\dfrac 23$ and the remaining one have the probability of turning head $\dfrac 12$ . One coin is chosen randomly from the box and tossed three times and each time it turns out to be head . What is the probability that the coin chosen from the box was the unbiased one i.e. the one with head probability $\dfrac 12$ ?   </p>
",<probability>
"<blockquote>
  <p>Let $p,q \in (0,1)$. Let $Y$ be the R.V denotes the number of days of the storm in the ocean. $Y\sim \text{Bin}(n,p)$. Let $X$ be the number of ships drowned during the storm and we know that the number of ships drowned in the $k$-day is $\text{Bin}(k,q)$. Find $E(x)$.</p>
</blockquote>

<p>Now, I look at the solution which starts like this:</p>

<p>$$E(X) = E(E(X|Y)) = E(q+2q+\ldots + Yq) = \ldots $$</p>

<p>Why is it true?  </p>

<p>I thought about splitting $X$ to $\sum_{k=1}^Y X_k$ where $X_k$ is the number of ships drowned in the $k$ day. Hence,</p>

<p>$$E(X|Y) = E(\sum_{n=1}^Y X_k| Y) = \sum_{n=1}^Y E(X_k |Y) = \sum_{n=1}^Y E(X_k) = Y\cdot kq$$</p>

<p>But it's not the right answer, apparently.</p>
",<probability>
"<p>I looking for confirmation, or not, that I am on the correct track with the following proof.</p>

<p>Show that if $P(A\mid B) = P(A\mid B^c), 0 &lt; P(B) &lt; 1$, then $A$ and $B$ are independent? </p>

<p><strong>Attempt</strong></p>

<p>By way of contradiction assume that $A$ and $B$ are not independent. Then,
\begin{align*}
P(A\mid B)=P(A\mid B^c)&amp;\Rightarrow\dfrac{P(B\cap A)}{P(A)}=\frac{P(B^c\cap A)}{P(A)}\quad\text{by definition}\\
&amp;\Rightarrow P(B\cap A)= P(B^{c}\cap A)
\end{align*}
But this contradicts $0 &lt; P(B) &lt; 1$. Thus, $A$ and $B$ must be independent.</p>

<p>Thank you in advance for any helpful feedback. Cheers.</p>
",<probability>
"<p>A container contains 4 Red marbles and 2 Green Marbles. I pull out each marble one at a time, without putting an marbles back in. X is a random variable that is the number of red marbles before pulling out a Green. Y is a random variable that is the number of green marbles that I draw out in the first three tries.</p>

<p>What is the Range of X and Y?</p>

<p>Calculate the probability mass function of P(x) for X? (Make a table of the  probability distribution for X)</p>

<p>Is {X ≤ 1} or {Y ≤ 1} likely?</p>

<hr>

<p>I figured the range of X is {0, 1, 2, 3, 4} since you cant have more than 4 marbles coming before Green and for Y is {0, 1, 2} since you're only limited to two green marbles. </p>

<p>For the second question would P(X = 0) = Pr(GGRRRR) since no Reds come before Green and P(X = 1) = Pr(RGGRRRR), P(X = 2) = Pr(RRGGRRR) and so on. I'm not sure how to find these values, since these events aren't independent I would have to make a tree diagram with 6 sets of ""generations"" until I have an outcome space of 6 marbles. </p>
",<probability>
"<p>Is there a difference between:</p>

<p>$$p(y|x,z) = \frac{p(y,x|z)}{p(x|z)}$$
and
$$p(y|x,z) = \frac{p(y,x,z)}{p(x,z)}$$</p>

<p>I was working on a problem that asks one to prove $p(x, y|z) = p(x|z)p(y|x, z)$ and the second one just came to my mind.</p>
",<probability>
"<p>You flip a coin with the goal of maximizing the ratio of heads to total flips; you can decide to stop whenever. What is the expected value of this ratio?</p>

<p>My thoughts: The ratio is at least $3/4$. With $1/2$ probability we flip heads first and stop.</p>

<p>Otherwise, we flip until the ratio is $1/2$ (random walks return to the origin with probability $1$) giving an expected ratio of $3/4$. Can we do better?</p>
",<probability>
"<p>Suppose you want to show $sup_{x\in D}|f_n(x)|\to_p 0$, for $n\to \infty$, where $D\subset \mathbb R$ is a compact interval, $f$ is continuous depending on one or more random variables, and $\to_p$ means convergence in probability. For example, $f_n(x)=\sum_{i=1}^n(X_i-x)$ (this, however, is not the problem).</p>

<p>Because showing statements as the one above directly is rather difficult I was wondering if it is sufficient to show $sup_{x\in D}| Ef_n(x)|\to 0$ and $sup_{x\in D}| Var(f_n(x))|\to 0$. Where $E$ and $Var$ are the expectation and variance operator, respectively. If some of you know a good read on this I appreciate your suggestions. Thanks in advance. Cheers.</p>
",<probability>
"<p>I am wondering if there is a closed form for finding the expected value or variance for a conditional exponential distribution.</p>

<p>For example:
$$ E(X|x &gt; a) $$ where X is exponential with mean $\lambda$.</p>

<p>Same question for variance.</p>

<p>What about for a joint distribution of independent exponentials?</p>

<p>$$ E(X|y &gt; a) $$ where X is exponential with mean $\lambda$, Y is exponential with mean $\theta$ and X &amp; Y are independent.</p>

<p>A sample problem for the actuarial P/1 exam (#124 for those also studying) asks:</p>

<blockquote>
  <p>The joint probability for $f(x,y) = 2e^{-x-2y}, ~ x &gt; 0, ~ y &gt; 0$. Calculate the variance of Y given $x &gt; 3, ~ y &gt; 3$.</p>
</blockquote>

<p>The solution goes like this: (Math on the right, reasoning on the left)</p>

<blockquote>
  <ol>
  <li>$Var (Y|x&gt;3, y&gt;3) =$</li>
  <li>$Var (Y|x&gt;3) = ~~~~~$Independence</li>
  <li>$Var (Y + 3) = ~~~~~$Memoryless</li>
  <li>$Var (Y) + Var (3) =~~~~~$Independence of Y and 3.</li>
  <li>$Var (Y) = ~~~~~ $ Since $Var (3) = 0$.</li>
  <li>$0.25 ~~~~~ $Exponential Variance, $\lambda = 2$.</li>
  </ol>
</blockquote>

<p><strong>So this says to me that  $Var (Y|x&gt;3) = Var (Y)$.</strong>  Is that true?  If so, is it always true?  If not, then how does this solution work?</p>

<p>Could one also replace E(Y) for Steps 1 - 4, Use $E(a) = a$ and get $E(Y| y&gt;a) = E(y) + a$?</p>

<p>Shortcuts like this are immensely valuable for a timed test.  (Not just faster, but less error prone).</p>
",<probability>
"<blockquote>
  <p>A fair coin is tossed:</p>
  
  <ul>
  <li>If <em>heads</em>: an unbiased die is thrown <strong>three</strong> times. The sum of the outcomes of the three rolls is recorded.</li>
  <li>If <em>tails</em>: an unbiased dice is thrown <strong>once</strong>. The result is recorded.</li>
  </ul>
  
  <p>What are the possible outcomes of each action and the probability of
  each outcome?</p>
</blockquote>

<p><strong>My solution:</strong></p>

<ul>
<li><p>if <em>heads</em>:</p>

<ul>
<li>Dice 1: $\Pr(\frac{1}{6})$</li>
<li>Dice 2: $\Pr(\frac{1}{6})$  </li>
<li>Dice 3: $\Pr(\frac{1}{6})$</li>
</ul>

<p>This outcome will yield  $\Pr(\frac{1}{6}) * \Pr(\frac{1}{6}) * \Pr(\frac{1}{6}) = \frac{1}{36}$</p></li>
<li><p>if <em>tails</em>:</p>

<ul>
<li>Dice: $\Pr(\frac{1}{6})$</li>
</ul>

<p>This outcome will yield  $\Pr(\frac{1}{6}) = \frac{1}{6}$</p></li>
</ul>

<p><em>Am I on the right track?</em></p>
",<probability>
"<p>If 20 persons were invited for a party, in how many ways will two particular persons be seated on either side of the host in a circular arrangement?</p>

<p>According to me the answer should be $17!.2!$. But the given answer is $18!.2!$.</p>

<p>If we consider the guest and the host as one unit and let them take the first three chairs the other 17 can be occupied by 17! ways and the two particular persons can then rearrange them by 2! ways.</p>

<p>What am i doing wrong?</p>
",<probability>
"<blockquote>
  <p>A fair die is thrown three times:  </p>
  
  <ul>
  <li>What is the probability of getting: three sixes?  </li>
  <li>What is the probability of getting: six, one, six?</li>
  </ul>
</blockquote>

<p><strong>My solution:</strong></p>

<p>Probability of getting three sixes:</p>

<p>$$\Pr(\text{1st dice six}) + \Pr(\text{2nd six}) + \Pr(\text{3rd six})$$
$$ = \frac{1}{6} \frac{5}{6} \frac{5}{6} + \frac{5}{6} \frac{1}{6} \frac{5}{6} + \frac{5}{6} \frac{5}{6} \frac{1}{6} = 3 \cdot \frac{25}{216} = \frac{75}{216} = \frac{25}{72}$$</p>

<p>Probability of getting six, one, six:</p>

<p>$$\Pr(\text{1st dice six}) + \Pr(\text{2nd one}) + \Pr(\text{3rd six})$$
$$ = \frac{1}{6} \frac{5}{6} \frac{5}{6} + \frac{5}{6} \frac{1}{6} \frac{5}{6} + \frac{5}{6} \frac{5}{6} \frac{1}{6} = 3 \cdot \frac{25}{216} = \frac{75}{216} = \frac{25}{72}$$</p>

<p><em>Am I on the right track?</em></p>

<hr>

<h2><em>Update:</em></h2>

<p>The problem am trying to solve does not specify order. Can we assume that order matters?</p>

<p>How about the following question, would the result be different from the initial question?</p>

<blockquote>
  <p>A fair die is thrown three times:  </p>
  
  <ul>
  <li>What is the probability of getting: three sixes, where the first throw MUST be six?</li>
  <li>What is the probability of getting: six, one, six, where the first throw MUST also be six?</li>
  </ul>
</blockquote>
",<probability>
"<p>I know this question is asked over and over, but I still can't understand anything.</p>

<p>Say I'm introduced to a random father of two and I want to know what's the probability that both his children are boys. Currently:</p>

<ul>
<li><strong>BB</strong> BG GB GG ⇢ 1/4</li>
</ul>

<p>Where the first letter represents the younger sibling and the second letter represents the older sibling. So far so good.</p>

<p>(1) Now the father tells me that his youngest child is boy:</p>

<ul>
<li><strong>BB</strong> BG <strike><em>GB GG</em></strike> ⇢ 1/2</li>
</ul>

<p>(2) If, instead, he told me that at least one of his children is a boy:</p>

<ul>
<li><strong>BB</strong> BG GB <strike><em>GG</em></strike> ⇢ 1/3</li>
</ul>

<p>Makes sense, kind of.</p>

<p>(3) But if the father brought one of his children with him without telling whether he's the younger child or the older child and that child happened to be a boy, I think I could have still honestly arrived to the 50/50 probability:</p>

<ul>
<li><strong>BB</strong> BG <strike><em>GB GG</em></strike> ⇢ 1/2</li>
</ul>

<p>Where the first letter represents the boy I've just seen and the second letter represents his sibling.</p>

<p>Now, say, the father first told me that he has at least 1 boy. That's the case (2).</p>

<p>Then the father called (one of) the boy(s) here, and somehow the situation turned into the case (3)!</p>

<p>What exactly has changed? What kind of new information did I just get? OK, I've seen (one of) the boy(s), but the only thing it tells me is that one of the children is a boy, which I already knew from the father's own words.</p>

<p>It seems to me that anything he could bring that has some kind of relationship to (one of) the boy(s) so as to allow me to uniquely identify him would work: a photo, a footprint on a beach, etc. Even if he simply told me that he has just thought about one of his children who is a boy, I think I could still have done this:</p>

<ul>
<li><strong>BB</strong> BG <strike><em>GB GG</em></strike> ⇢ 1/2</li>
</ul>

<p>Where the first letter represents the boy the father has thought about at XX/XX/XXXX XX:XX:XX UTC, and the second letter represents his other child.</p>

<p>Is this magic? Or am I just stupid?</p>

<p>Can't I simply construct such a way of identification myself? For example, let the first letter represent the youngest boy (the only boy if there's just one), and let the other letter represent the other child. Since the father is not an abstract entity, this would uniquely identify some child.</p>

<hr>

<p>I don't see how changing the representation changes things.</p>

<p>Say I saw one of the father's on a photo behind a thick blurry glass that doesn't let me see whether it's a girl or a boy. Therefore:</p>

<ul>
<li><strong>BB</strong> BG GB GG ⇢ 1/4</li>
</ul>

<p>Where the first letter represents the child on the photo and the second letter represents the other child.</p>

<p>Now the glass is removed and I can see the photo clearly and it's indeed a boy:</p>

<ul>
<li><strong>BB</strong> BG <strike><em>GB GG</em></strike> ⇢ 1/2</li>
</ul>
",<probability>
"<p>(There are 4 districts in the land of Oz. At home, the inhabitants of
each region wear ties of a special colour, Munchkins (M) wear blue, Scarecrows
(S) wear purple, Tin Men (T) wear red and Wizards (W) wear yellow. When visiting the Emerald city however, some inhabitants wear green ties, 25% of Munchkins, 35% of Scarecrows, 45% of Tin Men and 55% of Wizards. As a visitor approaches, the gatekeeper of the Emerald city who knows the tourism rate for the last few years assigns the probabilities as follows:</p>

<p>P(M)=1/3, P(S)=1/4; P(T)=1/6; P(W)=1/4</p>

<p>(i) What is the probability that the visitor will wear a green tie?</p>

<p>(ii) Given that a visitor is wearing a green tie, calculate the
probability that the visitor is a Munchkin.</p>
",<probability>
"<p>Given a box which contains $3$ red balls and $7$ blue balls. A ball is drawn from the box and a ball of the other color is then put into the box. A second ball is drawn from the box, What is the probability that the second ball is blue? </p>

<p>could anyone provide me any hint? </p>

<p>Please, don't offer a complete sketch of the solution, a hint is enough for me as this is a homework problem. </p>
",<probability>
"<p>From medical investigations it is known that the symptoms $S_1$ and $S_2$ can appear with three different diseases $K_1, K_2, K_3$. The conditional probabilities $a_{i,j}=P(S_j|K_i), i \in \{1,2,3\}, j \in \{1,2\}$ are given by the following matrix.</p>

<p>$$ A= (a_{i,j}) = \left(
\begin{array}{cc}
 0.8 &amp; 0.3 \\
 0.2 &amp; 0.9 \\
 0.4 &amp; 0.6 \\
\end{array}
\right)$$</p>

<p>In the first part of the question I already calculated $P(S_j)$ and $P(K_i|S_j)$. For the second part of the question, I'm given the conditional probabilities $P(S_1 \cap S_2 |K_i)$ by the following vector $(0.2, 0.1, 0.3)$. Assuming that a patient shows symptoms $S_1$, but not $S_2$, what is the probability that he suffers from $K_1, K_2$ and $K_3$?</p>

<p>So I'm looking for $P(K_i|S_1 \cap S_2^C)$. I can get $P(S_1 \cap S_2^C)$ using $P(S_1 \cap S_2^C) = P(S_1) - P(S_1 \cap S_2)$, but I have problems getting the joint distribution $P(S_1 \cap S_2, K_i)$.</p>

<p>First I was trying to show that $S_1$ and $S_2$ are independent and use that to derive the joint probability, but they are not. Alternatively, is it true that the formula $P(S_1 \cap S_2^C) = P(S_1) - P(S_1 \cap S_2)$ remains true when conditioning on K, so that I have $P(S_1 \cap S_2^C | K_i) = P(S_1 | K_i) - P(S_1 \cap S_2 | K_i)$? Or can anybody help me by providing an alternative way to solve this?</p>
",<probability>
"<blockquote>
  <p>Let $(\mu_n)_{n\in\mathbb{N}}$ be a sequence of probability measures on $\mathbb{N}$, such that the Laplace transform $\phi_n(\lambda)=\int e^{-\lambda x}\mu_n(dx)$ converges pointwise to a limit $\phi(\lambda)=\int e^{-\lambda x}\mu(dx)$ for some probability measure $\mu$ and $\lambda$ in some non-empty interval $(a,b)$. Prove that $\mu_n$ converges weakly to $\mu$.</p>
</blockquote>

<p>Hint: Fix $\lambda_0\in(a,b)$ and rewrite $\phi_n$ as Laplace transform of the new probability measure $\eta_n(dx)=e^{-\lambda_0x}\frac{\mu_n(dx)}{\phi_n(\lambda_0)}$, with $\eta$ defined similarly. Show that $\eta_n$ is tight and converges weakly to $\eta$ and then deduce that $\mu_n$ converges weakly to $\mu$.</p>

<p>This is the continuity theorem with respect to Laplace transform. I have found it in ""An introduction to Probability"" by Feller. But it doesn't provide proofs clearly. Does anyone see the proof of the the continuity theorem with respect to Laplace transform? Can you recommend me the source about this?</p>
",<probability>
"<p>Okay so <a href=""http://math.stackexchange.com/questions/835/optimal-strategy-for-deal-or-no-deal"">this question</a> reminded me of one my brother asked me a while back about the hit day-time novelty-worn-off-now snoozathon <a href=""http://en.wikipedia.org/wiki/Deal_or_no_deal"">Deal or no deal</a>.</p>

<h3>For the uninitiated:</h3>

<p>In playing deal or no deal, the player is presented with one of 22 boxes (randomly selected) each containing different sums of money, he then asks in turn for each of the 21 remaining boxes to be opened, occasionally receiving an offer (from a wholly unconvincing 'banker' figure) for the mystery amount in his box.</p>

<p>If he rejects all of the offers along the way, the player is allowed to work his way through several (for some unfathomable reason, emotionally charged) box openings until there remain only two unopened boxes: one of which is his own, the other not. He is then given a choice to stick or switch (take the contents of his own box or the other), something he then agonises pointlessly over for the next 10 minutes.</p>

<h3>Monty hall</h3>

<p>[If you have not seen the monty hall 'paradox' check out this <a href=""http://en.wikipedia.org/wiki/Monty_Hall_problem"">wikipedia link</a> and prepare to be baffled, then enlightened, then disappointed that the whole thing is so trivial. After which feel free to read on.]</p>

<p>There is a certain similarity, you will agree, between the situation a deal or no deal player finds himself in having rejected all offers and the dilemma of Monty's contestant in the classic problem: several 'bad choices' have been eliminated and he is left with a choice between a better and worse choice with no way of knowing between them.</p>

<h3>So???</h3>

<blockquote>
  <p><strong>Question:</strong> The solution to the monty hall problem is that it is, in fact, better to switch- does the same apply here? Does this depend upon the money in the boxes? Should every player opt for 'switch', cutting the 10 minutes of agonising away???</p>
</blockquote>
",<probability>
"<p>Say a gossip magazine editor is paying 2 sources to gather information about a particular celebrity. From his past experience the editor knows source# 1 is right 80% of time, and source# 2 is right 65% of the time. </p>

<p>Now, for a particular case, the editor wants to be sure at least 95%. Say the source #1, gives the editor some information piece x. What is the end probability in the following cases:</p>

<p>a. source# 2 also gives same information
b. source# 2 gives a different information about same thing than what source#1 gave. </p>

<p>In both above cases, what is the probability of the info from source #1 being correct?</p>
",<probability>
"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://math.stackexchange.com/questions/140836/a-probability-problem"">A probability problem</a>  </p>
</blockquote>



<blockquote>
  <p>Let $A$ and $B$ be events, $P(A) = \frac{1}{4} $, $P(A\cup B) = \frac{1}{3} $ and $ P (B) = p $. </p>
  
  <ol>
  <li>Find $p$, if $A$ and $B$ are mutually exclusive.</li>
  <li>Find $p$, if $A$ and $B$ are independent.</li>
  <li>Find $p$, if $A$ is a subset $B$.</li>
  </ol>
</blockquote>

<p>I know for 1) mutually exclusive: $P(A) + P(B) = P(A \cup B)$, but  how I can find p ? 
I don't know how to solve it. Please help me.</p>

<p>Obs: Sorry for duplicate post.</p>
",<probability>
"<p>I am trying to prove Boole’s inequality</p>

<p>$$P\left(\ \bigcup_{i=1}^\infty A_i\right) \leq \sum_{i=1}^\infty P(A_i).$$</p>

<p>I can show it of any finite $n$ using induction. What to do for $\infty$ ?</p>
",<probability>
"<p>Show that if $P(A_{i}) = 1$ for all $i \geq 1$ then $P(\ \bigcap_{i=1}^{\infty}A_i)=1$</p>
",<probability>
"<p>When playing many board games, the first step is to have everyone roll a die to see who goes first, with a roll off in the case of a tie.  While doing that over the Christmas break, my husband suggested that we roll two dice instead of one, with the assertion that this would make ties less likely.  My brother disagreed, claiming it wouldn't make any difference.  I'm interested in investigating this question.</p>

<p>I've been able to calculate the probability of ties for the case of rolling one die for any number of players, and the case for rolling two dice with two players.  However, I haven't actually found a general solution in either case (I mostly used a brute force approach in the one die case).  Is anyone here aware of any sources that have investigated this issue?</p>

<p>(For the record, I'm pretty sure both my husband and brother have forgotten the conversation, so you don't need to worry about hurting anyone's feelings.  :) )</p>
",<probability>
"<p>I have what seems like a simple question, but it's been a while since I've done any P/S. So i come to SE for help!</p>

<blockquote>
  <p>Two player pool/billiards: P1 has probability p of sinking a ball on any shot and has N balls remaining, while P2 has prob q and M balls remaining.</p>
  
  <p>Question: What is the probability of the first player winning?</p>
</blockquote>

<p>I can type out my reasoning (and will in an edit - will post before i reason it out though), but my answer has come down to:</p>

<p>$$\sum_{j=0}^{M-1} [p^N q^j \sum_{i=0}^\infty [(1-p)^i (1-q)^i]]$$</p>

<p>Is this correct or close?</p>

<p>Reasoning:</p>

<p>not really theoretical reasoning, but extrapolating the simple cases outwards:</p>

<p>(hit = h, miss = m, with probability p = w/p)</p>

<p>1 ball each: possible victory paths - </p>

<p>P1 wins w/p, </p>

<p>P1 m w/ (1-p), P2 m w/ (1-q), P1 wins w/ p</p>

<p>... etc - $p \sum_{i=0}^\infty (1-p)^i (1-q)^i$</p>

<p>2 and above balls each:</p>

<p>At some point, all the P1 hits must occur - $p^N$</p>

<p>All possible amounts of P2 hits must be accounted for - $\sum_{j=0}^{M-1} q^j$</p>

<p>Every miss variation is accounted for - <em>*</em> &lt;-- This is where i think I am wrong. Is it actually a double sum in and of itself? IE $\sum_{i=0}^\infty \sum_{k=0}^\infty (1-p)^i (1-q)^k$ ?</p>

<p>EDIT: Some wolfram alpha shows me that $\sum_{i=0}^\infty (1-p)^i = \frac 1 p$, so I guess my final final equation can be simplified to</p>

<p>$$\sum_{j=0}^{M-1} \frac{p^N q^j}{pq} $$ ??</p>

<p>etc.</p>
",<probability>
"<p>what is the probability of a person with a last name “Doe” replacing a house vacated by another “Doe”. Assuming 1% of the population has last name “Doe”? I have a excel sheet where I have 50 most popular name in the US. Let's say ""Doe"" is the most popular name and 1% of the toal population have last name ""Doe""? Let's assume ""John"" is the second most popular name and .8% of the population have last name ""John"". I want to know what is the probability of ""Doe"" replacing a house vacated by another ""Doe""? Or ""John"" replacing a house vacated by another ""John""? Thanks</p>
",<probability>
"<p>Let there be a family consisting of 2 children such that :</p>

<p>B : Event in which both children in a family are girls.</p>

<p>L : Event in which at least one child is a girl<br>
\begin{align}
P(B\mid L)&amp;=?\\
\text{I found it by enumeration as:}&amp;
\{(g,g),(g,b),(b,g),(b,b)\}\\
P(B|L)=1/3
\end{align}
Is there a way of arriving at this answer <em>without</em> enumerating?
\begin{align}
P(B|L)&amp;=P(BL)/P(L)\\
P(L)&amp;=1-P(\text{No Girls})\\&amp;=1-1/4=3/4\\P(BL)&amp;=?
\end{align}
Obviously, the answer has to be $1/4$ and I can see that from the enumeration but I can't deduce why.</p>
",<probability>
"<p>I want to calculate a conditional expectation and I do not see where my mistake is. I'm solving the following exercise (namely, 1a):</p>

<blockquote>
  <p><img src=""http://i.stack.imgur.com/IotJc.png"" alt=""enter image description here""></p>
</blockquote>

<p>(<a href=""http://www.math.ethz.ch/education/bachelor/lectures/hs2012/math/mff/MFF_2012_ex05beta.pdf"" rel=""nofollow"">source</a>)</p>

<p>Here $S^1,S^2$ are stochastic processes, which model for example a stock price. At time (day) $0$, $S^1_0=100$, which means that the price of stock one is $100$ unit of money. Then the stock price can go up, with probability $p_u=\frac{2}{3}$ and go down with prob. $p_d=\frac{1}{3}$. Hence at day $1$ it can take the prices $S^1_1=104$ or $S^1_1=98$ and so on.</p>

<p>The exercise want to construct an equivalent martingale measure for $S^1$.
To have an equivalent martingale for $S^1$ I need to find transition probabilities $q_u,q_d=1-q_u$ (u=up, d=down) and $q_{u,u},q_{u,d}=1-q_{u,u},q_{d,u},q_{d,d}=1-q_{d,u}$ such that $S^1=(S^1_k), k=0,1,2$ is a $Q^1$-martingale. The equivalence of the measure follows immediately if $q_j,q_{j,i}&gt;0$, $i,j\in\{u,d\}$. The filtration is generated by $S^1$, i.e. $\mathcal{F}_0=\sigma(S^1_0)$ which is trivial and $\mathcal{F}_1=\sigma(S^1_1)$. To be a martingale under the measure $Q^1$ (which is characterized by transition probabilities $q_j,q_{j,i}$ $i,j\in\{u,d\}$ we have to solve the equations:</p>

<p>$$E_{Q^1}[S^1_1]=100$$
$$E_{Q^1}[S^1_2|\mathcal{F}_1]=S^1_1$$</p>

<p>the first one is easy to solve and gives $q_u=\frac{1}{3}$ and $q_d=\frac{2}{3}$. Now for the second equation I want to use that $\mathcal{F}_1$ is generated by $\sigma(A_1,A_2)$, where $A_1=\{S^1_1=104\},A_2=\{S^1_1=98\}$. Then I know that </p>

<p>$$E_{Q^1}[S^1_2|\mathcal{F}_1]=\sum_{j=1}^2\frac{E[S^1_2\mathbf1_{A_j}]}{Q^1[A_j]}\mathbf1_{A_j}$$</p>

<p>hence for writting this out gives two equations:</p>

<p>$$\frac{1}{Q^1[A_1]}(116.48\cdot q_{u,u}+(1-q_{u,u})\cdot 99.84)=104$$
$$\frac{1}{Q^1[A_2]}(101.92\cdot q_{d,u}+(1-q_{d,u})\cdot 96.04)=98$$</p>

<p>where clearly $\frac{1}{Q^1[A_1]}=\frac{1}{q_u}$ and $\frac{1}{Q^1[A_2]}=\frac{1}{q_d}$. I would get the right result without the $\frac{1}{Q^1[A_j]}$ in the front of the equations. But I do not see why they do not have to be there. Right result: $q_{u,u}=\frac{1}{4}$, $q_{d,u}=\frac{1}{3}$. It would be very helpful, if someone could point out, where I my mistake is exactly.</p>

<p>As mentioned in the comment, I used the following theorem for calculating the conditional expectation:</p>

<blockquote>
  <p>Let $(\Omega,\mathcal{F},P)$ be a prob. space, $A_i\in \mathcal{F}$, for $1\le i\le N\le\infty$ pairwise disjoint measurable sets with $P(A_i)&gt;0$ and $\bigcup_{i=1}^N A_i=\Omega$. Let $\mathcal{A}=\sigma(A_i;1\le i\le N)$. Let $X\in L^1(\Omega,\mathcal{F},P)$, then
  $$E[X|\mathcal{A}]=\sum_{i=1}^N\frac{E[X\mathbf1_{A_i}]}{P(A_i)}\mathbf1_{A_i}$$</p>
</blockquote>
",<probability>
"<p>I'm reading <a href=""http://machinelearning.wustl.edu/mlpapers/paper_files/BleiNJ03.pdf"" rel=""nofollow"">http://machinelearning.wustl.edu/mlpapers/paper_files/BleiNJ03.pdf</a> and trying to understand the notation and concepts behind LDA, in order to implement it myself. I've followed some tutorials about the Poisson and Dirichlet distribution but I'm not super comfortable with them as topics yet.</p>

<p>Can someone explain what is meant on page 4 of the PDF:</p>

<blockquote>
  <p>LDA assumes the following generative process for each document w in a
  corpus D:</p>
  
  <ol>
  <li>Choose N ~ Poisson(ξ).</li>
  <li>Choose θ ~ Dir(α).</li>
  </ol>
</blockquote>

<p>What are these symbols referring to? Extracting words from the Poisson Distribution? How is that even possible? And extracting parameters from a Dirichlet distribution is equally confusing.</p>
",<probability>
"<p>I understand that when you apply a transformation $\sigma Y+\mu$ to $Y$~$N(0,1)$ ,we get a new random variable that is distributed $N(\mu,\sigma^2)$. However, I dont know through which mechanism this was obtained. Is it by multiplying the pdf by $\sigma^2$ and adding $\mu$? In general, I usually think about it as the following for normal distribution manipulations:</p>

<p>If you multiply, leave the mean alone but square the variance</p>

<p>If you add, leave the variance alone but add to the mean. </p>

<p>Is there another way of thinking about normal manipulations? Thanks!</p>
",<probability>
"<p>Let $\{X_i\}_{i\in\mathbb{N}}$ 
be a sequence of random variables taking values in 
$\{\pm e_1,\pm e_2\}$, 
where $\{e_1,e_2\}$ is the standard basis of $\mathbb{R}^2$.
If $\{X_i\}$ are i.i.d. uniformly distributed over $\{\pm e_1,\pm e_2\}$, 
then the simple random walk $S_N$ on $\mathbb{Z}^2$ have the mean square displacement given by $\mathbb{E}[\|S_N\|^2] =N$. We also know that the random 
walk $S_n$ is recurrent, i.e., 
$$
\sum_{n=1}^{\infty}\mathbb{P}(S_{2n}=0)=+\infty.
$$
<b>Question</b> Suppose now that the random variables $X_i$ $(i=1,2,\ldots)$ have some kind of dependence between its coordinates (but the steps $X_{i}'s$ are independent) so that the mean 
square displacement now obeys the following inequality for any $N\in\mathbb{N}$
$$
C_1N^2 \leq \mathbb{E}[\|S_N\|^2] \leq C_2N^2,
$$ 
where $0&lt;C_1&lt;1/2$ and $1/2&lt;C_2&lt;1$ are positive constants.
Is this inequality enough to assures that this random walk is transient ?</p>
",<probability>
"<p>I had a doubt on one ""diagonlization argument"" used to show Prohorov's Theorem. I am simplifying the discussion, so lets say that we consider the space $\mathbb{R}^{\infty}$
, and a set Π of probability measures on $\mathbb{R}^{\infty}$. Let us assume that $\Pi$ is tight. Now we want to show that it is relatively compact, i.e. every sequence $P_n \in \Pi$ has a subsequence $P_{n^{\prime}}$ which has a weak limit.</p>

<p>This statement below is easily proved:</p>

<p>Statement: Assume that we know that if the replace in the above statement $\mathbb{R}^{\infty}$ by $\mathbb{R}^{k}$
, then it is true, i.e. for a tight set in the set of measures on $\mathbb{R}^{k}$
, every sub-sequence has a weak limit.
Now we note that the projections $π_k$ of elements of $\mathbb{R}^{\infty}$ to $\mathbb{R}^{k}$
 are continuous, which implies that the sets ${Pπ^{−1}_k:P∈\Pi}$ are tight. Hence for every sequence $P_n$, by passing onto subsequence, $π^{−1}_k P_{n^{\prime}}$ has a weak limit. Now there is a ""diagonalization"" argument, which I had a problem absorbing. It essentially says that ""prune"" the above $P_{n^{\prime}}$ inductively to obtain a sequence $P_{\tilde{n}}$ which is such that the projection sequence of measures $π^{−1}_l P_{\tilde{n}}$ have a weak limit for all $l=1,2,\ldots$.</p>

<p>My problem is that if the ""pruning"" of the sequence $P_{n^{\prime}}$ was to be done only finitely many times, I know that after ""pruning"" the left over sequence is non-empty. But the problem here is that I have to prune the sequence infinitely many times, so how come in the end I get a non-empty set? I have seen this diagonalization argument used at many places but no one talks of the non-empty limit set.</p>

<p>I posted this question at some other site and was told this is connected to Tychonoff's Theorem. I get it that if at each step of pruning if I take the closure of the the subsequence, then they are compact, and hence their intersection is compact. But then who guarantees me that the intersection is non-empty??</p>
",<probability>
"<p>In a problem in the book, there is a batter never swings, and the pitcher has a .5 probability to strike and a .5 to throw a ball.</p>

<p>In this situation, we found:
P(batter strikes out) = 21/32
P(batter walks) = 11/32</p>

<p>(Keep in mind that it takes 3 strikes to strike out and 4 balls to walk)</p>

<p>We found this by adding the probability of the batter striking out on the 3rd, 4th, 5th, and 6th pitch. </p>

<p>To do this:</p>

<pre><code>P(Strike out on 3rd pitch) = (.5)^3 = 4/32  (3 strikes)

P(Strike out on 4th pitch) = C(3, 2)(.5)^2(.5)(.5) = 6/32
</code></pre>

<p>(2 strikes, 1 ball, then another strike)</p>

<pre><code>P(Strike out on 5th pitch) = C(4, 2)(.5)^2(.5)^2(.5) = 6/32
</code></pre>

<p>(2 strikes, 2 balls, then another strike)</p>

<pre><code>P(Strike out on 6th pitch) = C(5, 2)(.5)^2(.5)^3(.5) = 5/32
</code></pre>

<p>(2 strikes, 3 balls, then another strike)</p>

<p>So, add those up to get <code>P(Strike out) = 21/32</code></p>

<p>Find the probability for P(pitcher throws a strike) for which P(batter walks) = P(batter strikes out) = 1/2</p>

<p>My thinking was to turn this into an equation. Let x represent P(pitcher throws a strike). So then we have P(strike out) is</p>

<p>= <code>x^3 + C(3,2)x^3(1-x) + C(4,2)x^3(1-x)^2 + C(5,2)x^3(1-x)^3</code></p>

<p>= <code>x^3( 1 + C(3,2)(1-x) + C(4,2)(1-x)^2 + C(5,2)(1-x)^3</code></p>

<p>This makes it a little easy to try out... but to solve I was thinking that if we need 21/32 to be 1/2 then.... (21/32)x = .5 => x = 16/21. But I am not sure what to do with this</p>
",<probability>
"<p>From <em>A First Course in Probability (9th Edition)</em>:</p>

<blockquote>
  <p>3.5 An urn contains 6 white and 9 black balls. If 4 balls are to be
  randomly selected without replacement, what is the probability that
  the first 2 selected are white and the last 2 black?</p>
</blockquote>

<p>This method is straightforward and results in the correct answer (according to the book):
$$\frac{6}{15} \cdot \frac{5}{14} \cdot \frac{9}{13} \cdot \frac{8}{12} = \frac{6}{91} $$</p>

<p><em>(This is just the multiplication principle and probability of drawing the color of that ball at that time)</em> </p>

<p>However, I want to understand this in terms of conditional probability. I don't understand why <em>this</em> doesn't work:</p>

<p>$$P(E \mid F) = \frac{P(E \cap F)}{P(F)} ={\frac{{6 \choose{2}}{9 \choose 2}}{{15 \choose{2}}{13 \choose 2}}}÷{\frac{{6 \choose{2}}}{{15 \choose{2}}}} = {\frac{{9 \choose 2}}{{13 \choose 2}}} = \frac{6}{13} \ne \frac{6}{91}$$</p>

<p>$\frac{6}{13}$ is exactly 7 times more than the previous answer. Why does this method fail to work? What mistake have I made? I tried to use the exact same method used in question 3.3, where this resulted in the correct answer. </p>

<hr>

<p>Optional – About 3.3</p>

<pre><code>3.3 Use Equation (2.1) to compute in a hand of bridge the conditional 
probability that East has 3 spades given taht North and South have a 
combined total of 8 spades.
</code></pre>

<p>Here, we see that:
$$P(E \mid F) = \frac{P(E \cap F)}{P(F)} ={\frac{{13 \choose{8}}{39 \choose 18}{5 \choose 3}{21 \choose 10}}    {{52 \choose{26}}{26 \choose 13}}}÷{\frac{{13 \choose{8}}{39 \choose 18}}{{52 \choose{26}}}} = {\frac{{5 \choose 3}{21 \choose 10}}{{26 \choose 13}}} = \frac{29}{115} \approx 0.339$$</p>

<p>Which is the answer in the back of the book.</p>
",<probability>
"<p>I have N balls and M boxes. The balls are thrown at random onto the boxes. What is the probability that some box contains at least 3 balls? </p>

<p>Based on the Birthday problem, I know how to find the solution to the problem if we are finding the probability that some box contains at least 2 balls.</p>

<p>I am struggling to find the solution to this problem. Any help is much appreciated.</p>

<p>Here is what I have tried:
If we have M boxes and N balls, then the probability that some box contains at least two balls is approximately equal to $$ 1-e ^{ (-n^2 / 2m)} $$</p>

<p>Let us suppose that we have 4 balls and 6 boxes, then the probability that some box has at least 2 balls is approximately equal to $$ 1 - e ^ {(-16/12)} .$$ This is approximately equal to 0.7364.</p>

<p>Now I would like to find the probability that some box will contain at least 3 balls, when 4 balls are thrown at random onto 6 boxes.</p>

<p>Thanks
Sekhar </p>
",<probability>
"<p>(Quant job Interviews - Questions and Answers - Joshi et al, Question 3.5)</p>

<blockquote>
Suppose you have a fair coin. You start with 1 dollar, and if you toss a H your position doubles, if you toss a T your position halves. What is the expected value of the money you have if you toss the coin to infinity ?
</blockquote>

<p>Now the answer is stated as follows:</p>

<blockquote>
We work out what happens with one toss, then $n$ tosses and then let $n$ tend to infinity.

Let X denote a toss then:
$$\mathbb E (X) = \frac{1}{2} * 2 + \frac{1}{2} * 0.5= {5\over4} $$

Provided the tosses are independent, the product of expectations is the expectation of the product. Let $X_j$ be the effect of toss $j$. This means that
$$ \mathbb E (\prod_{j=1}^{n} X_j) = \prod_{j=1}^{n} \mathbb E (X_j) = ({5\over4})^n$$
this clearly tends to infinity as n tends to infinity
</blockquote>

<p>Now, I don't understand this answer :(</p>

<p>First, the way the answer is written out, surely the ${5\over4}$ is the expectation of the outcome of the first toss $X_1$ , not that of a toss $X_j , j \ge 1$ ?</p>

<p>Secondly, whilst I do understand that the tosses are independent, it would seem that the $X_{j+1}$ is actually quite heavily dependent on the $X_{j}$ before it ?</p>

<p>So then why is it so obvious that $\mathbb E ( X_{j+1} ) = \mathbb E ( X_{j})$ ?</p>
",<probability>
"<p>My aim is to become sharp in the necessary knowledge of basic probability and counting to follow my studies of Statistics for Computer Science.</p>

<p>Right now I found the following book:</p>

<p><a href=""http://aops-cdn.artofproblemsolving.com/products/intro-counting/toc.pdf"" rel=""nofollow"">http://aops-cdn.artofproblemsolving.com/products/intro-counting/toc.pdf</a></p>

<p>But the price is too high.</p>

<p>Are there any other cheaper alternatives that cover the same ground?</p>
",<probability>
"<p>Suppose a sample of <strong>120</strong> items is drawn from a population of manufactured products and the number of defective items is recorded. Prior experience has shown that the proportion of defectives is <strong>0.05</strong>.</p>

<p>a) Describe the sampling distribution of <strong>p̂</strong>, the proportion of defectives.</p>

<p>b) What is the probability that the sample proportion is less than <strong>0.10</strong>?</p>

<p>My Work:</p>

<p>a) $$np ≥ 5$$</p>

<p>because</p>

<p>$$ 120*0.05 =6$$</p>

<p>and</p>

<p>$$nq = 120*0.95 = 114 ≥ 5$$</p>

<p>therefore the sampling distribution is approximately normal distributed. </p>

<p>b) $$P(p̂&lt;0.10) = P(z &lt; (0.10-0.05)/[\sqrt{(0.05x0.95)/120)})$$</p>

<p>$$= P(z&lt;0.05/0.0199) = P(z&lt;2.5126)$$</p>

<p>$$ =0.9940$$</p>

<p>resulting in <strong>99.4%</strong>.</p>

<p>I'm not sure if I'm solving this problem properly, any help is greatly appreciated!</p>
",<probability>
"<p>Let $X_{1}, X_{2},\ldots, X_{n},\ldots$ be independent and identically distributed random variables with distribution</p>

<p>$P(X_{n}=0)=P(X_{n}=1)=P(X_{n}=2)=P(X_{n}=3)=\frac{1}{4}$</p>

<p>Assume that the sequence $\{Y_n\}$ is defined as: $Y_{0}=0$ and for all $n\in\mathbb{N}$ we have</p>

<p>$Y_n=\begin{cases} 3 &amp;\text{if } X_n=3,\\\min{\{Y_{n-1},X_n\}} &amp;\text{if } X_n&lt;3. \end{cases}
$</p>

<p>Compute $\displaystyle \lim_{n\to +\infty}E[Y_{n}Y_{n-1}]$?</p>

<p>I don't know how to start.</p>
",<probability>
"<p>If I get to draw $3$ cards from a standard deck. </p>

<p>With replacement - a) What is the probability of drawing a $10,J,Q$ in that order?</p>

<p>Without replacement - b) What is the probability of drawing a $10,J,Q$ in that order?</p>

<p>With replacement - c) Drawing at least one ace (I got $= \left(\frac{4}{52}\right)^3$).</p>

<p>Without replacement - d) Drawing at least one ace (I got $= \left(\frac{4}{52}\right)\left(\frac{3}{51}\right)\left(\frac{2}{50}\right)$)</p>

<p>Having trouble with a) and b) I know that order matters so I would have to use combinations.</p>

<p>Any thoughts? Thanks.</p>
",<probability>
"<p>We flip a fair coin. Then, if the result is tails, we stop.  If it is heads, 
we flip a second time and then stop. Let $X$ be the number of heads from the flip(s). If $X = 0$, let $Y = 0$. If $X = 1$ or $X = 2$, choose $Y$ uniformly at random from the interval $[0,X]$.</p>

<p>How can I find the c.d.f. of $Y$? I know that $P(X = 0) = 1/2$, $P(X = 1) = 1/4$, and $P(X = 2) = 1/4$. But, how can I extend this information to get the c.d.f. of $Y$?</p>
",<probability>
"<p>You have $n$ urns, each containing $p_i$ white balls and $q_i$ black ones. One of the urns is selected uniformly at random, and balls are extracted with replacement from it until a black ball is found.</p>

<p>What is the distribution of the number of draws needed?</p>

<p>This is simply a random selection out of $n$ independent geometric distributions, but I'm unable to find this particular ensemble anywhere. Does this distribution have a proper name? Is it a geometric distribution itself?</p>
",<probability>
"<p>In this <a href=""http://math.stackexchange.com/questions/331280/probability-distribution-of-tossing-a-coin-until-obtaining-k-heads"">Question</a> the correct answer is the negative binomial distribution. My problem is: What is the distribution if I want the k heads in a row?</p>

<p>Any help is apreciated.</p>
",<probability>
"<blockquote>
  <p>The finite population correction in sample survey is :</p>
  
  <p>(A) $n/N$</p>
  
  <p>(B) $N/n$</p>
  
  <p>(C) $1-\frac{n}{N}$</p>
  
  <p>(D) $1-\frac{N}{n}$</p>
</blockquote>

<p>I know that , finite population correction factor is 
$$fpc=\sqrt{\frac{N-n}{N-1}}$$where , $n=$sample size and $N=$population size.</p>

<p>How I can deduce from it to get one option ? Please help..</p>
",<probability>
"<p>In a dancing party, there are 3 pairs of married couple. Each husband will pick his female dancing partner randomly. So, the probability of every wives will dance with her non-husband is...?</p>
",<probability>
"<p>I am trying to set up a probability table for the events of drawing two cards from a $52$ card deck. What counts is either an exact match or a match in flush with two already drawn cards from another deck. I am not sure the table is correct, so I would be grateful for a judgement. </p>

<ol>
<li><p>Two exact matches:                        $\frac{1}{1326}$</p></li>
<li><p>One exact match + one flush match: $\frac{13 \times 2-1}{1326}$</p></li>
<li><p>One exact match only:                  $\frac{26 \times2}{1326}$</p></li>
<li><p>Two flush matches:               $\frac{13 \times13\times2-39}{1326}$</p></li>
<li><p>One flush match only:            $\frac{26 \times 26-52}{1326}$</p></li>
<li><p>No match at all:                        $\frac{325}{1326}$</p></li>
</ol>
",<probability>
"<p>May I please borrow your expertise or could anyone check if I'm on the right track please?</p>

<p>Consider customers arriving at a bank. The bank has $2$ types of customers - business and personal. On average, $10$ business customers arrive per hour, and $20$ personal customers. The times between arrivals of the business customers are independent of each other, and exponentially distributed, and is the same for personal customers. The two streams are independent of each other. Suppose no new customers have entered the bank in the last $5$ minutes.</p>

<p>1) What is the probability that no business customers arrive in the next $3$ minutes?</p>

<p>I'm assuming the arrival time for business customers is 60/10 = 6 customers
Thus, by using the exponential equation and also that this is a memoryless property,</p>

<p>$1 - e^{-3/6}$ (am I on the right track here anyone)?</p>

<p>2) What is the probability that no personal customers arrive in the next $3$ minutes?</p>

<p>Assuming the arrival time for personal customers to be 60/20 = 3 customers
Using the equation from question 1)</p>

<p>$1 - e^{3/3}$ (is this right)?</p>

<p>3) What is the probability that no customers at all arrive in the next $3$ minutes?</p>

<p>Assuming that this is something like $1 - ((1-e^{-3/6}) + (1-e^{-3/3}))$
by adding the no personal customer and business customer together and minus it by 1</p>

<p>4) What is the distribution of the time until the arrival of the next customer?</p>

<p>(Any hints on how I might be able to use to get the answer for this question?)</p>

<p>Your helps are much appreciated. Thanks,</p>
",<probability>
"<p>For a discrete RV $X$, is it true that the conditional distribution $P_{X \mid Y} (B \mid y)$ is discrete as well for all $y$?</p>

<p>I only managed to prove that this is true almost surely. Let $\Pr(X\in C) = 1$ for countable $C$, then by definition $\Pr (X \in C, Y \in \mathbb{R}) =\mathbf{E} [P_{X \mid Y} (C \mid Y) ; Y \in \mathbb{R}] = 1$.</p>
",<probability>
"<p>Say I have an image, with pixels that can be either $0$ or $1$. For simplicity, assume it's a $2D$ image (though I'd be interested in a $3D$ solution as well). </p>

<p>A pixel has $8$ neighbors (if that's too complicated, we can drop to $4$-connectedness). Two neighboring pixels with value $1$ are considered to be connected. </p>

<p>If I know the probability $p$ that an individual pixel is $1$, and if I can assume that all pixels are independent, how many groups of at least $k$ connected pixels should I expect to find in an image of size $n\times n$?</p>

<p>What I really need is a good way of calculating the probability of $k$ pixels being connected given the individual pixel probabilities. I have started to write down a tree to cover all the possibilities up to $k=3$, but even then, it becomes really ugly really fast. Is there a more clever way to go about this?</p>
",<probability>
"<p>I want to solve the following exercise:</p>

<p>Suppose that two sets $X$ and $Y$ are chosen independently and uniformly at random from all the $2^n$ subsets of $\{1, \dotsc, n\}$. </p>

<p>Determine $P[X \subseteq Y]$ and $P[X \cup Y = \{1, \dotsc, n\}]$.</p>

<p><strong>MY IDEA:</strong> </p>

<p>My idea is that a random subset is the same as deciding for each element independently with probability $\frac{1}{2}$ whether it is in the subset or not. </p>

<p>Then $$P[X \subseteq Y] = P[ \forall x \in X \colon x \in Y]$$</p>

<p>Now I have the first problem, because I am not sure how to express the for all $x$ that are in $X$. I mean, is this the same as computing $$\sum_{x=1}^n P[x \in X] P[x \in Y | x \in X] = \sum_{x=1}^n P[x \in X] P[x \in Y] = \frac{n}{4},$$
since this computation does not feel right. Can someone intuitively tell me what the above calculation calculates and how to solve the actual problem? My problem is here that we have somehow to condition on the event that this $x$ is already in $X$, otherwise we need not do anything. </p>

<p>The second one sounds a bit easier to me. There we have
$$P[X \cup Y = \{1, \dotsc, n\}] = P[\forall x \in \{1, \dotsc, n\} \colon x \in X \vee x \in Y] =\prod_{x=1}^n P[x \in X \vee x \in Y] = \prod_{x=1}^n (P[x \in X] + P[x \in Y] - P[x \in X \wedge x \in Y] ) =\prod_{x=1}^n (P[x \in X] + P[x \in Y] - P[x \in X] P[ x \in Y] =  \prod_{x=1}^n (\frac{1}{2}+\frac{1}{2}-\frac{1}{4})= \left(\frac{3}{4}\right)^n.$$
Is this correct? Is there an easier way?</p>
",<probability>
"<p>I have a somewhat open-ended question. Let's say I have a sequence of random variables $(X_n: n \geq 1)$ which are <strong>neither independent, ergodic, nor identically distributed</strong>. Normally I would say that I am completely dead in the water, <strong>but let's say that $X_n \overset{d}{\to} X$</strong>. Are there any additional assumptions under which I can say that:</p>

<p>$$ \frac{1}{n} \sum_{i=1}^n X_n \;\overset{P}{\to}\; \mathbb{E}X $$</p>

<p>Even if I assume that expectation of the left-hand side converges to $\mathbb{E}X$, I'm stuck thinking about this more generally. Any tips?</p>

<p>EDIT: Thinking about this some more, I feel like making a martingale out of the LHS and then checking under what conditions we have the desired martingale convergence would be a reasonable route to follow. Any thoughts on this?</p>

<p>EDIT 2: per Nate Eldredge's comment below, I need to assume that the expectation of the LHS of the partial-sum object converges to $EX$... it doesn't follow from $X_n \overset{d}{\to} X$. </p>
",<probability>
"<p>Two piece of gold are contained in two same-looking black boxes respectively. It is known that one piece weights twice as the other, but do not know which is which.  </p>

<p>Two persons, say A and B, randomly choose a box. One person, say A, opened his box, but he does not known whether it is lighter or weightier. </p>

<p>Question: Is A willing to exchange his box with B?</p>

<p>This might be a well-known problem, but I do not know the proper name to search it online. </p>

<p>Intuitive, it make no difference to exchange the boxes.</p>

<p>On the other hand, if we compute the expectation for A, it seems that A should change the box (the expectation is 1.25 of the current holding).</p>

<p>I would like to hear your answer to the question and preferably fuller story about this paradox.</p>
",<probability>
"<p>Here is lottery machine, if the current no. on the screen is ""1"" then probability of getting ""2"" is ""a"" and probability of getting ""3"" is ""b"" and probability of getting ""1"" is ""c"", after each step.<br>
where ""a""+""b""+""c""=1.<br>
similarly, <br>
if the current no. on the screen is ""2"" then probability of getting ""1"" is ""d"" and probability of getting ""3"" is ""e"" and probability of getting ""2"" is ""f"".<br>
where ""d""+""e""+""f""=1.<br>
and,<br>
if the current no. on the screen is ""3"" then probability of getting ""1"" is ""g"" and probability of getting ""2"" is ""h"" and probability of getting ""3"" is ""i"".<br>
where ""g""+""h""+""i""=1.<br>
<br>
then what is probability of getting ""1"" after exactly k steps, if current no. on screen is:<br>
a)""1"",<br>
b)""2"",<br>
c)""3"".<br></p>
",<probability>
"<p>Trying to work out the probability of a fault occuring over a 12.5 year time period. The probability of a fault occuring per year is 1/15. </p>

<p>Does this mean the probability of no fault occuring over the period is (14/15)^12.5 = 0.422</p>

<p>And of one fault occuring 1 - 0.422 = 0.578?</p>

<p>How could I go about calculating the probabilty of two faults occuring?</p>
",<probability>
"<p>My book states that $E[X^2]$ is the average power. It then says for $\mathcal{N}(0, 1)$, the average power is $\frac{1}{2}$ and for $\mathcal{N}(0, \sigma^2)$ is $\frac{\sigma^2}{2}$.</p>

<p>How can this be?</p>

<p>The second moment of the Gaussian is $\mu^2 + \sigma^2$ so the average power for $\mathcal{N}(0, 1)$ should be one and $\sigma^2$ for $\mathcal{N}(0, \sigma^2)$.</p>

<p>It makes since to multiple by $1/2$ since we average by $1/N$ but the book just states the average power is $E[X^2]$ not $\frac{1}{2}E[X^2]$.</p>

<p>Can someone shed some light on this?</p>
",<probability>
"<p>In Bayesian probability, does the prior distribution $\pi(\theta)$ only depend on $\theta$? For example, suppose the prior distribution of the unknown parameter $\theta$ is binomial. Then does $$ \pi(\theta) = \binom{n}{\theta} p^{\theta} (1-p)^{n-\theta}$$ </p>

<p>Whereas if $f(\theta|x_1)$ is binomial then  $$f(\theta|x_1) = \binom{n}{x_1} p^{x_1}(1-p)^{n-x_1}$$</p>

<p>Is this correct?</p>
",<probability>
"<p>Is there any way to calculate the restricted Laplace transform of the random variable $X$, i.e., $$ 
\int_{0}^{u}e^{-sx}dF(x)\ 
$$
$(u&lt;\infty)$, based on its Laplace transform?</p>
",<probability>
"<p>Given the definition of conditional expectation as E$[X|B] = \frac{E[1(B) \cdot X]}{P(B)}$, and understanding $1(B)$ as an indicator function that returns $1 (0)$ when $B$ is true (false), it would seem $E[1(B)\cdot X]$ takes the expected value of members of $X$ where $B$ is true. Why the further division by $P(B)$? Intuitive as well as formal explanation requested.</p>

<p>E.g., suppose we have:</p>

<blockquote>
  <p>$(S,P)$:
  $(1,3)$
  $(1,4)$
  $(0,3)$
  $(0,2)$
  $(0,1)$
  $(0,0)$
  $(1,1)$
  $(1,2)$
  $(1,3)$
  $(0,2)$</p>
</blockquote>

<p>$P(S = 1) = 0.5$, $E[1(S=1) \cdot P] = \frac{13}{5} \approx 2.6 $ (where $1[x]$ is an indicator function that flips to $1$ if $S = 1$ and $0$ if $S != 1$). </p>

<p>Thus $E[P|S = 1] = \frac{E[1(S=1) \cdot P]}{P(S = 1)} \approx 5.2$? What am I doing wrong here?</p>
",<probability>
"<p>A book has 10 short and 10 long chapters. Short chapters span 10 pages, and long chapters span 20 pages.</p>

<p>Why does the probability that you will pick a long or a short chapter differ between these  strategies?</p>

<p>Strategy #1: Flip to a random page, back up to the start of that chapter, and start reading.<br />
Strategy #2: Flip to a random page, go forward to the start of the next chapter, and start reading (and pick the first chapter if the page you pick lies within the last chapter).</p>
",<probability>
"<p>Math and probability wasn't ever my strong side, so I need to ask for a help in calculating simple (as I assume) value. Here is situation description.</p>

<blockquote>
  <p>Player <strong>A</strong> throws seven times with ten-side dice (numbers in range 1-10). Writes down results and shows them to player <strong>B</strong>. Player <strong>B</strong> throws three times with the same dice.</p>
  
  <p><em>What is the probabillity that among all ten numbers (both players) there will be no repeats - i.e. all three player <strong>B</strong>'s numbers will be exactly different than all player <strong>A</strong>'s numbers?</em></p>
</blockquote>

<p>This comes from a simple game, that I've been playing. Developer of this game suggests that above mentioned situation can appear fairly often (sometimes 2-3 times per particular game) completely random. While I'm pretty sure, that probability of such situation is so extremely low, that it can't happen that often, without any changes to game random generator, to make game itself much harder to complete. In other words -- I claim that game's random generator is not that random.</p>

<p>Thank you in advance for any help.</p>
",<probability>
"<p>How would I calculate the probability of randomly selecting a house and getting the current owner’s last naming same as previous owner’s last name? For example, let’s say 1% of the population has the last name “Doe” and picking a house randomly getting the current owner’s name is Doe and the previous owner’s name was Doe too. Thanks </p>
",<probability>
"<p>Jar $A$ contains $3$ red and $3$ black marbles, and Jar $B$ contains $4$ red and $6$ black marbles. If a marble is randomly selected from each Jar, what is the probability that the marbles will be the same color?</p>

<p>I'm having difficulty approaching this problem.  It seems like I should use Baye's Theorem to solve this problem, that is, let $A = \{\text{select a marble randomly from Jar A and Jar B}\}$ and $B = \{\text{the color of the marbles is the same}\}$.  I think I'm suppose to find $P(A|B)$ by Baye's Theorem.  However, I get stuck here as I need $P(A)$ and $P(B|A)$.  Perhaps my approach is incorrect.   </p>
",<probability>
"<p>I've heard somewhere from someone about a theorem that roughly says ""the probability of an event decreases as time increases""</p>

<p>I couldn't find the exact theorem (assign it exists at all.)</p>

<p>So figure I should ask all of you great mathematicans here if anyone has ever heard of this.</p>
",<probability>
"<p>Forgive me if this is really basic:</p>

<blockquote>
  <p>Tammy is a general contractor and has submitted two bids for two projects (A and B). The probability of getting project A is 0.65. The probability of getting project B is 0.77. The probability of getting at least one of the projects is 0.90. What is the probability that she will get both projects?</p>
</blockquote>

<p>Is this a simple question using the addition law or am I missing something? I calculated that her probability of getting both would be 0.52.</p>

<p>(0.65 + 0.77 - 0.90) = .52</p>
",<probability>
"<blockquote>
  <p>Given the random vector $(X,Y)$ with joint probability $P(0,1)=\frac{1}{18}$, $P(1,2)=\frac{3}{18}$, $P(1,4)=\frac{5}{18}$, $P(2,0)=\frac{2}{18}$, $P(2,1)=\frac{4}{18}$, $P(2,3)=\frac{3}{18}$ and $0$ otherwise, I need to find:</p>
</blockquote>

<ol>
<li>Domain, probability and distribution for $(Y|X=2)$</li>
<li>Domain and probability for $Z=X+Y$</li>
</ol>

<p>1) I need to find the marginal $p_X$ for $X$ as:</p>

<p>$p_X(2)=\sum_yp(2,y)=\frac{2}{18}+\frac{4}{18}+\frac{3}{18}=\frac{9}{18}$</p>

<p>Now I can calcolate che conditional $(Y|X=2)$</p>

<p>$p_{Y|X}(2,0)=\frac{p(2,0)}{p_X(2)}=\frac{2}{9}$</p>

<p>$p_{Y|X}(2,1)=\frac{p(2,1)}{p_X(2)}=\frac{4}{9}$</p>

<p>$p_{Y|X}(2,3)=\frac{p(2,3)}{p_X(2)}=\frac{3}{9}$</p>

<p>2) I read that $p_Z(z)=\sum_{x}p(x,z-x)$, but I don't know how to proceed. And suggestion?</p>
",<probability>
"<p>I need help with solving one of the questions the teacher gave us to prepare for an upcoming exam. I tried solving it but with no luck. Here is the question:</p>

<blockquote>
  <p>On one shelf there are 5 hardcover books and 6 paperbacks and on the other shelf there are 7 hardcover and 4 paperback. From the first shelf we pick two books randomly and put them on a table and from the second shelf we pick one book randomly and also put it on the table. And at last we randomly pick one book from the table. What is the possibility for that book to be a hardcover?</p>
</blockquote>

<p><strong>EDIT:</strong> I gave it a shot with something like this: I calculated $P1$ like so with fractions $P(5 hard, 6 paper) = 5/11 + 4/10$ - so I can see the probability of taking 2 hardcover books from the first shelf then I gave $P2 7/11$ from the second shelf and the final P(A) I tried adding then together. This was of no use as you can see.. </p>
",<probability>
"<p>Let $X^1$ and $X^{-1}$ be two simple random walk in $\mathbb{Z}$ starting respectively from $1$ and $-1$. Let $\tau$ be the first time one of them reaches the origin,</p>

<p>$$\tau = \inf \{ j \geq 0 \, : \, X^{-1}(j) = 0 \, \, \mbox{or}\, \,  X^{1}(j) = 0 \}.$$</p>

<p>How much is $E[\tau]$, the expectation of $\tau$?</p>

<p><strong>Comment:</strong> If there was only a random walk, then the expectation of $\tau$ would be infinite, as $P(\tau &gt;k ) \sim 1/k$. However, for two random walks I think it should not be infinite, as $P(\tau &gt;k ) \sim 1/k^2$. How to make it rigorous and compute the exact number? </p>
",<probability>
"<p>Say we role $n$ identical, fair dice, each with $d$ sides (every side comes up with the same probability $\frac{1}{d}$). On each die, the sides are numbered from $1$ to $d$ with no repeating number, as you would expect. So an ordinary $d$ sided die pool. </p>

<p>Every dice in the outcome that shows a number equal or higher than the threshold number $t$ is said to show a hit. Every die that shows the maximum result of $d$ is rolled again, which we call ""exploding"". If the re-rolled dice show hits, the number of hits is added to the hit count. Dice that show the maximum after re-rolling are rolled again and their hits counted until none show a maximum result. <strong>Given the values of</strong></p>

<p>$$ d\ ...\ \text{Number of sides on each die}\ \ d&gt;0 $$
$$ n\ ...\ \text{Number of dies rolled}\ \ n\ge 0$$
$$ h\ ...\ \text{Number of hits, we want the probability for}$$
$$ t\ ...\ \text{Threshold value for a die to roll a hit}\ \ 0 &lt; t \le d$$</p>

<p><strong>what is the probability to get exactly exactly $h$ hits?</strong> Lets call it: $$p^\text{exploding}(d,n,t,h) = p_{d,n,t,h}$$ 
Can you derive a formula for this probability?</p>

<p><strong>Example roll:</strong></p>

<p><em>We roll 7 six-sided dice and count those as hits that show a <code>5</code> or a <code>6</code>. In this example, $d=6$, $n=7$, $t=5$. The outcome of such a roll may be <code>6</code>,<code>5</code>,<code>1</code>,<code>2</code>,<code>3</code>,<code>6</code>,<code>1</code>. That's three hits so far, but we have to roll the two sixes again (they explode). This time it's <code>6</code>, <code>2</code>. One more hit, and one more die to roll. We are at four hits at this point. The last die to be re-rolled shows <code>6</code> again, we re-roll it yet another time. On the last re-roll it shows a <code>4</code> - no more hits. That gives five hits in total and the roll is complete. So, for this roll $h=5$.</em></p>

<p><strong>Simple case for just one die $n=1$</strong>:</p>

<p>If we roll only one die with the same threshold as above, so ($d=6$, $n=1$,  $t=5$), the probabilities can be easily calculated:</p>

<p>$$ p_{6,1,5,0} = \frac{4}{6} \quad \text{(Probability for exactly 0 hits - roll 1-4 on the first roll, no explosion here)} $$
$$ p_{6,1,5,1} = \frac{1}{6} + \frac{1}{6} \cdot \frac{4}{6} \quad \text{(Probability for exactly 1 hit - roll either a 5 or a result of 1-4 after a 6)} $$
$$ p_{6,1,5,2} = \frac{1}{6} \cdot \frac{1}{6} + \frac{1}{6} \cdot \frac{1}{6} \cdot \frac{4}{6} \quad \text{(Probability for exactly 2 hits - either a 6 and 5 or two sixes and 1-4)} $$
$$ p_{d,1,t,h\ge 1} = \left(\frac{1}{d}\right)^{h-1}\frac{d-t}{d}  + \left( \frac{1}{d} \right)^h \cdot \frac{t-1}{d} \quad \text{(Probability for exactly $h\ge 1$ hits - either $h-1$ maximum rolls and non-maximal success or $h$ maximum rolls and a non-success )} $$</p>

<p><strong>Without Explosion:</strong></p>

<p>For none-exploding dice the probability would just be <a href=""https://en.wikipedia.org/wiki/Binomial_distribution"" rel=""nofollow"">binomially distributed</a>:</p>

<p>$$ p^\text{non-exploding}_{d,n,t,h} = \binom{n}{h} \left( \frac{d-t+1}{d} \right)^h \left( 1 - \frac{d-t+1}{d} \right)^{n-h} $$</p>

<p>$$ E^\text{non-exploding}_{d,n,t} = n \frac{d-t+1}{d}; \qquad V^\text{non-exploding}_{d,n,t} = n \frac{(d-1)(d-t+1))}{d^2} $$</p>

<p>Where $E_{d,n,t}$ is the expected number of hits, and $V_{d,n,t}$ its variance.</p>

<hr>

<p><strong>Edit1:</strong> In the mean time I found <a href=""http://math.stackexchange.com/q/391792/11949"">Probability of rolling $n$ successes on an open-ended/exploding dice roll</a>. However I'm afraid, I don't fully get the answer there. E.g. the author says $s = n^k + r$, which does not hold for his examples. Also I'm not sure how to get $s$, $k$ and $r$ from my input values stated above (which are $d$, $n$, $h$ and $s$).</p>

<p><strong>Edit2:</strong> If one had the probability for $b$ successes via explosions, given that the initial role had $l$ successes prior to the explosions, one could just subtract all those probabilities for all values of $b$ from the value for the pure binomial distributions with $l$ successes and add the respective value to the pure binomial probability of $b+l$ successes. Just an idea. I suppose this should be something like a combination of geometric and binomial distribution.</p>

<p><strong>Edit3:</strong> I accepted <a href=""http://math.stackexchange.com/users/224454/brian-tung"">Brian Thug</a>'s excellent answer, giving the formula:
$$ p^\text{exploding}_{d,n,t,h} = \frac{(t-1)^n}{d^{n+h}}
             \sum_{k=0}^{\max\{h, n\}} \binom{n}{k} \binom{n+h-k-1}{h-k}
             \left[ \frac{d(d-t)}{t-1} \right]^k $$</p>

<p>$$ E^\text{exploding}_{d,n,t} = n\frac{d+1-t}{d-1}; \qquad V^\text{exploding}_{d,n,t} = E_{d,n,t} - n\frac{(d-t)^2-1}{(d-1)^2} $$</p>

<p>Here is a graph from a <a href=""https://github.com/con-f-use/Exploding-Diepool"" rel=""nofollow"">simulation</a> (<a href=""http://con-f-use.github.io/Exploding-Diepool/"" rel=""nofollow"">html</a>) that illustrates the whole thing:</p>

<p><img src=""https://github.com/con-f-use/Exploding-Diepool/raw/master/img/hist_d6_n15_t5.png"" alt=""Comparison between exploding and non-exploding dice pools""></p>
",<probability>
"<p>My text book uses the linearity of the expected value to compute it. It defines a random variable $X_i$ that indicates whether the urn $i$ contains $k$ balls or not. So the asked value is $E[X_1 + X_2 + ... + X_n]$.</p>

<p>What is not entirely clear for me is the following. It states that $P\{X_i=1\}={r \choose k}({{1}\over{n}})^k({1-{{1}\over{n}}})^{r-k}$. However, if the balls are indistinguishable, I thought we should compute that probability with the ""stars and bars"" approach?</p>
",<probability>
"<p>Is there an explicit formula for the probability that a simple symmetric random walk on $\mathbb{Z}$ starting from $1$ will not hit $0$ before time $t$?</p>
",<probability>
"<p>For $X_i \sim$ i.i.d with cdf $F_x$, and $\forall c \in \mathbb R$, then, letting $M_n$ denote the maximum observation</p>

<p>$$
M_n \le c+  \sum_i^n (X_i - c) \mathbb I(X_i &gt; c)
$$
I proved this by taking $n=1$ and $X_i = c$ and showing that this was a contradiction. Now, I am trying to show that, for $\bar{F}(x)= 1- F(x)$ :</p>

<p>$$
E(M_n) \le c + n \int_c^\infty \bar{F}(x)dx
$$
My attempt so far, using the initial result, then then the same inequality must hold for the expectations of both sides, that is:
\begin{align*}
E(M_n) &amp;\le c+  \sum_i^n E[(X_i - c) \mathbb I(X_i &gt; c)] \\
&amp;\overset{\text{iid}}{=}c+ n E[(X - c) \mathbb I(X &gt; c)] \\
&amp;= c+ n \int_{-\infty}^ \infty (x-c)\mathbb I(X &gt; c) f_X(x) dx \\
&amp;= c+ n \int_{c}^ \infty (x-c)  f_X(x) dx \\
&amp;= c+ n \int_{c}^ \infty x  f_X(x) dx - nc \int_c^\infty f_X(x)dx \\
&amp;=c+ n \int_{c}^ \infty x  f_X(x) dx -nc \bar{F}(c)\\
\end{align*}</p>

<p>I think i take a wrong turn somewhere, maybe I shouldn't expand the term in the integral, I still don't quite get where the second integral would come from, to define the CDF in the required inequality... any hints?</p>
",<probability>
"<p>The probability that it will rain on Saturday is 25% and the probability that it will rain on Sunday is also 25%. Is it true that the probability that it will rain on the weekends is 50%. Explain why or why not.</p>

<p>What i tried</p>

<p>I know that it is not true.
Let $P(A)$ represent the probability that it will rain on Saturday, while $P(B)$ represent the probability that it will rain on Sunday. Hence $P(A \cap B)$ will represent the probability that it would rain on both days (weekends) and since $$P(A \cap B)=P(A)+P(B)-P(A\cup B)$$</p>

<p>From the formula above we can see that the sum of  $P(A)$ and  $P(B)$ alone would not add up to $P(A \cap B)$ which means that we simply could not just add the two probabilities together to get $50$%. Since i find this rather counterintutive could anyone provide a simpler and more clearer explanation to this problem.Thanks</p>
",<probability>
"<p>If I have the probability distribution $f(x) = \begin{cases}x &amp; 0 &lt; x &lt; 1 \\ 2-x &amp; 1 &lt; x &lt; 2 \\ 0 &amp; \text{otherwise} \end{cases}$,</p>

<p>how do I calculate $E(X)$, and $E(X^2)$, and therefore $VAR(X)$?</p>

<p>I understand that $E(X)=\int_{-\infty}^\infty xf(x)~dx$, and $E(X^2)=\int_{-\infty}^\infty x^2f(x)~dx$, but don't know how to apply this given that the function takes different forms over $(0,1)$ and $(1,2)$.</p>
",<probability>
"<blockquote>
  <p>In a coorporation there are 3% absence due to sickness each day. 60% of those are men. 30% of the cooporations employees are women. So, </p>
  
  <p>M = the employee are  male<br>
  F = the employee are female<br>
  S = employee is home due to sickness.  </p>
  
  <p>My task is to find P(M) and P(S|M).</p>
</blockquote>

<p>I've tried to look around for some examples to apply to this problem but I can't manage to find one.</p>

<p>I need a hint or something to get started. I'm very rusty in probability-calculation.</p>
",<probability>
"<blockquote>
  <p>Suppose there are three students wanting to meet a Professor in his office. The time $i$-th student takes with the Professor is $Exponential(\lambda_i)$ distributed, and they are independent. Assume all students start talking to the Professor simultaneously. Find the distribution of the time until only one student is left.</p>
</blockquote>

<p>If I denote $T$ to be the desired time and $T_i$ to be the discussion time for $i$-th student, how exactly can I write $\{T\leq x\}$ in terms of $T_i$?</p>

<p>It seems that $\{T\leq x\}=\{T_1\leq x,T_2\leq x\}\cup\{T_2\leq x,T_3\leq x\}\cup\{T_1\leq x,T_3\leq x\}$.</p>

<p>Am I right?</p>
",<probability>
"<p>A player with unlimited money decides to play roulette. He bets $1$ on red, if he loses, he bets $2$, if he loses again he bets $4$ and so on till he wins. Prove that he is guaranteed to make a profit.</p>

<p>I know this is the theory of martingale and I looked for proof online but everything I found was way more complex than what's needed here. Isn't there a formula to prove that after unlimited tries the probability of never winning is $0$?</p>

<p>I understand why it works but I'm having a hard time explaining it using mathematics. Any help would be greatly appreciated.</p>

<p>Thank you</p>
",<probability>
"<blockquote>
  <p>Given $x_1, \ldots, x_N$, independent and all distributed as a
  Gaussian with mean $\mu$ and variance $\sigma^2$. Then, the average
  $$\bar{x} = \frac{1}{N}\sum_{i=1}^Nx_i$$ is distributed as a Gaussian
  with mean $\mu$ and variance $\frac{\sigma^2}{N}.$</p>
</blockquote>

<p>This is a very well-known result. Anyway, I'm looking around to find a proof for this and I'm not having luck.</p>
",<probability>
"<p>I have a problem proving an inequality regarding probabilities.
You may prefer to skip to the definitions and the inequality right away 
without reading the paragraph below.</p>

<p>Suppose there are $n$ light bulbs. Independently, each light bulb is ON with probability $x$ and OFF with probability $(1-x)$. After the random variables realized, i.e., after it is observed which bulbs are on or off, one is smashed and this one is selected randomly among those that are OFF.</p>

<p>Let 
$$\alpha = x^{n-2}$$
be the probability that, given two lights $i$ and $j$ are OFF, all other lights are ON.</p>

<p>Let 
$$\beta_i = \sum\limits_{i=0}^{n-2} {n-2 \choose i}\frac{1}{i+1} x^{n-2-i}(1-x)^i = \frac{1-x^{n-1}}{(n-1)(1-x)}$$
be the probability that, given light $i$ is off and light $j$ is on, light bulb $i$ is smashed.
Similarly, define $\beta_j = \beta_i$.</p>

<p>Let 
$$\beta_{i,j} = \sum\limits_{i=0}^{n-2} {n-2 \choose i}\frac{2}{i+2} x^{n-2-i}(1-x)^i$$
be the probability that either $i$ or $j$ are smashed, given both of them are OFF.</p>

<p>It should hold that
$$ (1-\alpha) (1-\beta_{i,j}) \geq (1-\beta_i) (1- \beta_j) \quad  \forall n &gt; 2, x\in [0,1]  $$
Unfortunately, I am not able to show that this generally holds. It would be great to point me to the basic math that I am missing.</p>
",<probability>
"<p>Let $\{X_t\}_{t\ge 0}$ be a Poisson Process with parameter $\lambda$. Suppose that each event is type 1 with probability $\alpha$ and type 2 with probability $1-\alpha$. Let $\{X^{(1)}_t\}_{t\ge 0}$ the number of type 1 events up until time $t$ and $\{X^{(2)}_t\}_{t\ge 0}$ the number of type 2 events up until time $t$ </p>

<p>Prove that $\{X^{(1)}_t\}_{t\ge 0}$ and $\{X^{(2)}_t\}_{t\ge 0}$ are Poisson Processes with parameter $\lambda \alpha$ and $\lambda(1-\alpha)$ respectively </p>

<p>Furrthermore prove that for each $t\ge 0$ the random variables $\{X^{(1)}_t\}_{t\ge 0}$ and $\{X^{(2)}_t\}_{t\ge 0}$ are independent</p>

<p>My attempt: In order to prove that they are poisson process I will use the next definition:</p>

<p>An stochastic process $\{Y_t\}_{t\ge 0}$ is a poisson process iff:</p>

<p>a) $Y_0=0$</p>

<p>b) It has independent increments</p>

<p>c) $Y_{t+s}-Y_{s}$~$Poisson(\lambda t)$ for any values $s\ge 0$ and $t&gt;0$</p>

<p>a) For any $t\ge 0$ we have: $X_t=X^{(1)}_t+X^{(2)}_t$; we know that $\{X_t\}_{t\ge 0}$ is a poisson process hence $X_0=0$ $\Rightarrow X^{(1)}_0+X^{(2)}_0=0 \Rightarrow X^{(1)}_0=0$ and $X^{(2)}_0=0$</p>

<p>b)Let $n\in \mathbb N$ In this part I need to prove that for any $n$ arbitrary times $0&lt;t_1\le t_2\le...\le t_n$ and states $x_1,...,x_n$
 $$P[X^{(1)}_{t_1}=x_1,X^{(1)}_{t_2}-X^{(1)}_{t_1}=x_2,...,X^{(1)}_{t_n}-X^{(1)}_{t_{n-1}}=x_n]=P[X^{(1)}_{t_1}=x_1]P[X^{(1)}_{t_2}-X^{(1)}_{t_1}=x_2]...P[X^{(1)}_{t_n}-X^{(1)}_{t_{n-1}}=x_n]$$</p>

<p>I don´t know how to Formally prove this part, and I don´t think this is trivial. Any help would be highly appreciated </p>

<p>c) $$P[X^{(1)}_t=k]=\sum_{i=k}^\infty P[X^{(1)}_t=k|X_t=i]P[X_t=i]=\sum_{i=k}^\infty \binom{i}{k}\alpha^i(1-\alpha)^{i-k}{e^{-\lambda t}(\lambda t)^i \over i!}={e^{-\lambda \alpha t}(\lambda \alpha t)^k\over k!}$$</p>

<p>Know I need to compute $P[X^{(1)}_{t+s}-X^{(1)}_t=n]=\sum_{j=0}^\infty P[X^{(1)}_{t+s}-X^{(1)}_t=n|X^{(1)}_s=j]P[X^{(1)}_s=j]$</p>

<p>This part is also giving me trouble because I dont´know what to do from here </p>

<p>I would really apreciate if you can help me with this problem. Also I hope that this won´t be marked as a duplicate because I haven´t seen a formal proof about the splitting poisson process.</p>
",<probability>
"<p>Let $\{ X(t), t \ge 0\}$ be standard Brownian motion.</p>

<p>How do I find Cov$[X(3) - 2X(2), X(4)]$? </p>

<p>The answer is $-1$, but I can't seem to get there no matter what I hit it with. I know that $X(3) \sim N(0,3)$, $2X(2) \sim N(0, 4)$, and $X(4) \sim N(0,4)$. Furthermore, I know that $\text{Cov}[X(s),X(t)] = \min (s,t)$; but this is only for Brownian motion, which isn't preserved (I assume) by the new normal random variable created by $X(3) - 2X(2)$. I imagine that I need to somehow transform $X(3) - 2X(2)$ in a way that preserves Brownian motion so that I can use the above property, but I'm at a loss here.</p>
",<probability>
"<p>A fair die having two faces coloured blue, two red and two green, is thrown repeatedly. Find
the probability that not all colours occur in the first $k$ throws.</p>

<p>My attempt:
Denote by $G_k$ the number of results=green in $k-$tosses, and similarly $R_k$ and $B_k$. Then we have $\mathbb{P}(G_k=0)=(2/3)^k=\mathbb{P}(R_k=0)=\mathbb{P}(B_k=0)$. In this way the answer is $\mathbb{P}(G_kR_kB_k=0)=(2/3)^{3k}$.</p>
",<probability>
"<p>A crabs' life expectancy can be modeled exponentially, and a crab lives 3 months on average.</p>

<p>I am absolutely not sure about this, because there is nothing concerning this in our book, so I guess it was meant to be solved in some obvious/easy fashion, here's what I tried:</p>

<blockquote>
  <p>If it were only one crab, I could simply plug 9 into $\lambda e^{-\lambda x}$, where $\lambda=1/3$. </p>
  
  <p>$60$ is $10\%$ of $600$, so maybe I need to look after what time 90% died, intuitively I would resort to</p>
  
  <p>$$1-e^{-x/3}=0.9$$
  $$0.1=e^{-x/3}$$
  and so on, which would give me $\approx 6.9$ months, and then do <em>something</em> about the remaining $2.1$ months.</p>
</blockquote>

<p>The last thing I was thinking of is to calculate the probability for 540 crabs dying at some point before the 9 month mark, and then taking the converse probability, but that I'd only know how to do with the help of a computer. </p>
",<probability>
"<p>Assume the expected number of transitions (events) it takes until a Markov chain with $G+1$ states ranging from $s=0$ to $s=G$ is completed is $M$. Suppose we have $K$ independent instances of this Markov chain synchronized such that a single event can lead to a transition to all of them. We are interested in the average number of transitions required to complete all of them.</p>

<p>One approach is to model this using a new Markov chain with a state space of size $(G+1)^K$ that corresponds to vectors (0,...0) to (G,...,G), calculate the transition probabilities and then derive the expected number of required transitions. We are already aware of how to do it. However, it is very interesting and insightful to approximate this using $M$ and $K$. Any suggestions is appreciated.</p>
",<probability>
"<p>I have a very basic propability question:</p>

<p>There are 200 socks in my basket. 25 are white, the rest are black. If I pick 10 socks, what's the probability of picking 3 white ones?</p>

<p>I tried to calculate as follows:</p>

<p>P_3 = [25/200 * 24/199 * 23/198] * [175/197 * 174/196 * 173/195 * 172/194 * 171/193 * 170/192 * 169/191]</p>

<p>However, when I create all P_{0-10} and sum them up I don't get a overall probability of 1. So I must be doing something wrong?</p>
",<probability>
"<p>Let $C(\mathbb{R})$ be the set of continuous and bounded functions $\mathbb{R}\to\mathbb{R}$.</p>

<p>Is there a probability measure $p$ on $C(\mathbb{R})$ such $\forall g\in C(\mathbb{R}),\ \forall \varepsilon&gt;0,\ p(\{f\in C(\mathbb{R}), |f-g|&lt;\varepsilon\})&gt;0$ ?</p>
",<probability>
"<p>I want to know if the following distribution has a name or a PDF in the literature. I have:
$$ Z = \left(\sum_{i=1}^{N}{X_i^2}\right)^{\alpha}$$
where $\{X_i\}_{i=1}^{N}$ are independent Gaussian random variables with mean $\mu_i$ and variance $\sigma_i^2$ and $\alpha \in \mathbb{R}$.</p>

<p>Thanks.</p>
",<probability>
"<p>I am looking to solve the following integration. Given $Z_1,Z_2,\ldots,$ are all independent and standard gaussian variable, $Z_i = N(0,1)$.</p>

<p>For the first case, I am interested in the probability $P(Z_1+Z_2&lt; \sqrt{2}\alpha , Z_2+Z_3&lt;\sqrt{2}\alpha)$, or simply 
$$\frac{Z_1+Z_2}{\sqrt{2}} &lt; \alpha$$
$$\frac{Z_2+Z_3}{\sqrt{2}} &lt; \alpha$$</p>

<p>where $\alpha$ is a constant. I can solve this numerically. First question is there analytical solution to this?</p>

<p>Secondly, for higher dimensional case, what is the probability that
$$\frac{Z_1+Z_2+Z_3}{\sqrt{3}} &lt; \alpha$$
$$\frac{Z_2+Z_3+Z_4}{\sqrt{3}} &lt; \alpha$$
$$\frac{Z_3+Z_4+Z_5}{\sqrt{3}} &lt; \alpha$$</p>

<p>Thank you for your help.</p>
",<probability>
"<p>In fair gambler's ruin problem, we already knew that the expected time of winning is $E(\tau_n|\tau_n&lt;\tau_0)=\frac{n^2-k^2}{3}$, where $k$ is how much money we have in the beginning and $\tau_i$ is the first hitting time at $i$. I know how to solve it by using first step analysis in markov chain, but my teacher wants me to use martingale instead, he said it is much easier. I think I have to use optional stopping time theorem, but I don't know how to use it in this problem. Any idea? Thank you so much</p>
",<probability>
"<p>I'm trying to solve a certain problem but I'm stuck at a point.</p>

<p>The problem is:
I have a uniform r.v. $U$ on [$-\pi,+\pi$] and I have a sequence of r.vs $X_1,X_2...$ where $X_k=cos(kU)$.
Then I have $S_n=X_1+X_2+...+X_n$.</p>

<p>The problem is to find what is $lim_{n\rightarrow \infty} P{(|\frac{S_n}n|&lt;\epsilon)}$</p>

<p>My attempt:</p>

<p>I know that $E[\frac{S_n}n]=0$ and its variance is $2\pi^2/n$.</p>

<p>I know that $P{(|\frac{S_n}n|&lt;\epsilon)} =P_{\frac{S_n}n}([-\epsilon,+\epsilon])= \begin{matrix} \int_{-\epsilon}^{\epsilon} f_{\frac{S_n}n}(x) dx \end{matrix}$</p>

<p>Where $f_{\frac{S_n}n}(x)$ is the probability density of $\frac{S_n}n$.</p>

<p>I don't know how to find this probability density: I tried with the characteristic function of the sum but the result is not very ""writable"".</p>

<p>Maybe there is another way to find that probability with $n\rightarrow \infty$?</p>

<p>Thank you</p>
",<probability>
"<p>I asked similar question in <a href=""http://math.stackexchange.com/questions/395666/a-special-random-subset-of-uniformly-distributed-numbers-is-still-uniformly-dist"">A special random subset of uniformly distributed numbers is still uniformly distributed?</a></p>

<p>Here, I slightly change my random number generation method, and want to see whether the sampled numbers are still uniformly distributed.</p>

<p>Assume that I have a value range [1,1000].</p>

<p>Goal: I want to have 10 numbers randomly sampled from [1,1000].</p>

<p>case1:</p>

<pre><code>I sample 20 numbers, a1, ..., a20 from [1,1000].

Then I sample b1, ..., b10 from [a1, a2, ..., a20].

b1, ..., b10 are what I want.
</code></pre>

<p>case2:</p>

<pre><code>I sample 20 numbers, a1, ..., a20 from [1,1000].

Then I sort a1, ..., a20.

For notation simplicity, I assume that after sorting, a1&lt; ...&lt; a20.

Then, for each consecutive pair of numbers, 

I uniformly at random select one number.

Eventually, I can get 10 numbers as well.
</code></pre>

<p>I know the numbers in case1 are uniformly distributed.</p>

<p>Does anyone have idea whether the numbers in case2 are uniformly distributed?</p>
",<probability>
"<p>The probability generating function of $X$ is $G_x(s)=\frac{1}{2}(s^9(1+s^2))$. Find $EX$ and probability distribution function.</p>

<p>$EX=G_x^{'}(s)=\frac{1}{2}(9s^8+11s^{10})$</p>

<p>How about pdf? Do I need to expand $G_x(s)$ function with Taylor series?</p>
",<probability>
"<p>Two of my facebook friends had their birthdays on the same day</p>

<p>The first guy's name was ""Wael Toujeni""</p>

<p>The second guy's name was ""Wael Jeni""</p>

<p>How do I calculate the probability of this event happening?</p>

<p>The event: two of your facebook friends have the same birthday, and have similar names except an n characters difference in their last names.</p>
",<probability>
"<p>I have a two week holiday after finishing this semester and I was hoping to study something. Ideally, I would like to study something that I can benefit from in any upcoming courses I take. I'm thinking of either fourier series or probablity theory. Currently I'm leaning towards Fourier because it's very relevant to electrical engineering, however, Probablity theory seems intriguing to me (also opens up interesting areas such machine learning).</p>

<p>So how relevant is probablity theory to undergraduate electrical engineering ?!</p>
",<probability>
"<p>If we know that the two random sequences $\{X_n\}$ and $\{Y_n\}$
$$
X_n \stackrel{d}{\longrightarrow} N(0,\sigma_1^2)\\
Y_n \stackrel{d}{\longrightarrow} N(0,\sigma_2^2)
$$
and $\mathrm{cov}(X_n,Y_n) \to 0$, can we conclude that the joint random vectors
$$
\pmatrix{X_n \\ Y_n} \stackrel{d}{\longrightarrow} N(0,\mathrm{diag}\{\sigma_1^2, \sigma_2^2\})
$$</p>

<p>Is there any counterexample or proof? I have considered using the characteristic function with expansion but did not work it out....</p>

<p>Many thanks to any help!</p>
",<probability>
"<p>Consider the normal distribution. We know that $$p(x| \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}} $$</p>

<p>The kernel is $$ p(x| \mu, \sigma^{2}) \propto e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}} $$ omitting the part that isn't a function of $x$. Why write $p(x|\mu, \sigma^{2})$ like this? </p>
",<probability>
"<p>A cube is painted on all its faces. It is then cut into 64 smaller identical cubes, which are then thoroughly. What is the probability that 2 randomly chosen smaller cubes have exactly 2 coloured faces each?</p>

<p>I have a doubt , there will be 24 <strong>identical</strong> cubes whose 2 faces will be painted, 8 <strong>identical</strong> cubes with 3 faces painted,  24 <strong>identical</strong> cubes with one face painted and 8 <strong>identical</strong> cubes with no face painted. 
Now total cases to pick 2 smaller cubes should be 4C2 not 64C2 .
correct me if I am wrong</p>
",<probability>
"<p>Is there a way to determine the maximum percentage of values that fall below the average in a given sample?  How would someone go about this?  How does this relate to what Markov's inequality and Chebyshev's inequality are saying?</p>
",<probability>
"<p>Let $P_{XY}$ be the joint probability distribution of discrete random variables $X$, $Y$. Then I would like to prove the following inequality:</p>

<p>$$
\sum_{y}\max_xP_{XY}(x,y)\leq |Y|\max_xP_X(x)
$$</p>

<p>where $P_X$ is the marginal distribution of random variable $X$ and $|Y|$ is the cardinality of random variable $Y$. Hints are also welcome.</p>
",<probability>
"<blockquote>
  <p>$X_n$ is a sequence of random variables, and $\{\varphi_n(t)\}$ is the corresponding sequence of characteristic functions. Show that $X_n \stackrel{d}{\longrightarrow} 0$ iff $\{\varphi_n(t)\}$ converges to 1 in some neighbourhood of $t=0$.</p>
</blockquote>

<p>The necessity follows immediately from Levy's continuity theorem. I am struggling with showing the sufficiency: it remains to show that $\varphi_n(t) \rightarrow 1$ for all $t \in \mathbb{R}$, but how to do that? Appreciate for any help!</p>
",<probability>
"<p>Assuming I start with $n$ dice that have been rolled once, is it beneficial to choose the higher dice when I roll less than $n$ dice again (assuming I want a high roll)?</p>

<hr>

<p>In some board games, dice play a big part. And depending on the circumstance, a different amount of dice is used. In this particular case, I'm assuming that the higher the resulting number, the better. Also, I'm assuming not perfectly fair dice, since those rarely happen in everyday play.</p>

<p>Here's my logic: If I roll 7 dice, and 4 are high (5/6) while 3 are low (1/2), should I pick the high dice if I only need to roll 4? (Assuming that this is the first time I see the dice rolled).</p>

<p>This seems as if it might make sense because if the dice aren't fair and the only result we've seen so far is a higher number, it might make it seem as if that number is more likely to occur.</p>

<p>On the other hand, this almost seems like the gambler's fallacy. Except that fallacy assumes perfect dice.</p>

<p>So should I pick the higher dice? Or does it really not matter? If it does matter, by how much?</p>
",<probability>
"<p>$N(t)$ is a Poisson process with parameter  $\lambda&gt; 0$, and $X_1,X_2,...$ are independent and identically distributed random variables with a common mean and positive variance. Let
$$L(t)=\sum_{i=1}^{N(t)}X_i.$$
Find $E[L(t)|N(t) = n]$.</p>

<p>Any help with this is appreciated.</p>
",<probability>
"<p>I know that the events $x_1 &gt;0$ and $x_2 &gt;0$ are not independent, but I can't think of a way to find a conditional probability so I can solve this.</p>

<p>Thanks!</p>
",<probability>
"<p>I try to prove that according to binomial distribution $P(X=k)={n \choose k}p^k(1-p)^{n-k}$ the maximum probability $P(X=k)$ is achieved at maximum likelihood, i.e. $p=\frac{k}{n}$.</p>

<p>Let's apply $\log$ and take the first derivative.</p>

<p>$$\log P(X=k) = \log {n \choose k}+k \log p+ (n-k)\log (1-p)$$</p>

<p>$$\frac{d \log P(X=k)}{dp} = \frac{k}{p}-\frac{n-k}{1-p}=0 \quad \iff \quad  p=\frac{k}{n}$$</p>

<p>The problem is to show that what I found is indeed the global maximum, i.e. I need to show that the second derivative is negative everywhere.</p>

<p>I would appreciate if someone could help me with the second derivative.</p>

<p>The second derivative</p>

<p>$$\frac{d(\frac{k}{p}-\frac{n-k}{1-p}) }{dp} = -\frac{k}{p^2}-\frac{n-k}{(1-p)^2}$$</p>

<p>it's negative because $n&gt;k$</p>
",<probability>
"<p>I have some difficulties with the following exercise in combinations:</p>

<blockquote>
  <p>There are $8$ beans in the box: $6$ white beans, $2$ green beans. Two players one by one pick $2$ beans; first player one picks $2$ beans, after that player two picks $2$ beans. For every green bean that player picks he gets $5$ points.</p>
  
  <p>What's the expected number of points for player one? What's the probability that player two picks only one green bean?</p>
</blockquote>

<p>Solution:</p>

<p>$$E(\text{points of player one}) = 4 \cdot 5 \cdot \frac{2}{8} \cdot \frac{6}{7} + 10 \cdot 2 \cdot \frac{2}{8} \cdot \frac{1}{7}$$</p>

<p>Unfortunately I didn't find any good way to fir the binomial distribution here. </p>

<p>I don't get any idea how to answer the second question.</p>
",<probability>
"<p>Probability was never included in my high school classes, so I'm trying to learn it now from the internet. The downside of this is that you don't get anyone grading your work and catching flaws. This is something I'm really uncertain about, so if someone could just point out my mistake or verify that I've understood it, I'd be appreciative.</p>

<p>Just for fun, the topic I chose to practice with was working out the chance that any of the children on <em>19 Kids and Counting</em> (a TV series about a very conservative family raising children with strict traditional roles) would be LGBT. The probability of being gay is roughly $3\%$ ($0.03$) and the probability of being bisexual is roughly $4\%$ ($0.04$).</p>

<p>So combined, this makes $7\%$ ($0.07$). The probability of being heterosexual is $93\%$ ($0.93$). Would I be correct in saying that the probability of at least one being gay or bisexual would be $1-A^{B}$, where $A$ is the probability of being born heterosexual ($0.93$) and $B$ is the number of family members ($25$) -- or $83.7\%$?</p>

<hr>

<p>As a followup question: there's a controversial finding by some studies, <a href=""https://en.wikipedia.org/wiki/Fraternal_birth_order_and_male_sexual_orientation"" rel=""nofollow"">the fraternal birth order effect</a>, that suggests that for each older brother a man has, the probability that he is gay rises by ~$38\%$, hypothesised to be due to hormonal influences during fetal development. There are $10$ boys in the family. How would I include this detail when calculating the probability? </p>
",<probability>
"<p>So when dealing with the Bayes' Rule and Binomial distributions,  the value $p^k(1-p)^{n-k}$ loses precision and becomes 0 when $n$ and $k$ are large(noting that the binomial coefficient can be safely ignored since it cancels out). For example if $n = 500\,,\,k=250\,\,$for  $p= 0.05$  , then my TI-83 calculator returns 0.</p>

<p>I found out about a ""fix""  for this using the following expression that replaces $p^k(1-p)^{n-k}$.</p>

<p>$e^{k\,ln \,p + (n-k)ln(1-p)-max_i(kln(p_i) + (n-k)ln(1-p_i)}$</p>

<p>I think the $p_i$ in the expression is suppose to represent any one of prior probabilities. Can anyone explain why this works ?</p>
",<probability>
"<p>""I'm really sorry that I'm asking a basic question, I tried to understand but couldn't understand completely""</p>

<p>These are the 3 parameter results of rolling a single die.
Expectation  E(x)=3.5</p>

<p>Variance Var(x)=2.92</p>

<p>Standard deviation SD=1.709</p>

<p>Expectation is nothing but the average of outcomes of die when we perform infinite trials, that means if we roll a die infinite times and take out the mean of outcome , its value is close to 3.5. that's what I understood.
I searched in Google and read about variance ,standard deviation.
I didn't understand anything about those two, but left with this sentence ""The variance measures how far each number in the set is from the mean""
Can anyone please explain what do those two values indicate regarding to my die problem??
Thanks in advance</p>
",<probability>
"<p>EDIT:</p>

<p>Let $X,Y$ be random variables over some probability space with  joint distribution  $P$. Then the mutual information between two random variables is defined as</p>

<p>$I(X;Y):=\sum\limits_{(x,y)\in\text{supp}(P)}P(x,y)\log\frac{P(x,y)}{\sum\limits_rP(r,y)\sum\limits_sP(x,s)}$. </p>

<p>It is clear that mutual information $I(X;Y)$ can now be viewed as a function of joint distribution $P$. Hence we denote hereafter the mutual information associated with a joint distribution $P$ between two random variables as $I(P)$.</p>

<p>Now to the problem definition:</p>

<p>Assume $P_1,P_2$ be two joint distributions over $\{1,2,3...,N \}\times \{1,2,3,...N\}$ and hence $P_1,P_2 \in \mathbb{R}^{N \times N}$. Assuming $Q= \frac{P_1+P_2}{2}$, which again defines a new joint distribution over the same set over which $P_1,P_2$ were defined, I am trying to bound the mutual information $I(Q)$ using $I(P_1)$ and/or $I(P_2)$.</p>

<p>I have a bound on $I(Q)\ge\sum \limits_{i,j}\frac{P_1(i,j)}{2}\log{\frac{P_1(i,j)}{\gamma_{ij}}}+\sum \limits_{i,j}\frac{P_2(i,j)}{2}\log{\frac{P_2(i,j)}{\gamma_{ij}}}$ </p>

<p>with</p>

<p>$\gamma_{ij}:= \left( \sum \limits_s \frac{P_1(i,s)+P_2(i,s)}{2} \right )$$\left(  \sum \limits_r \frac{P_1(r,j)+P_2(r,j)}{2} \right)$. With this I am interested in lower bounding $\frac{1}{\gamma_{ij}}$. With some calculations I landed a lower bound of the form, </p>

<p>$\frac{1}{\gamma_{ij}}\ge \frac{1}{\sum \limits_rP_1(i,s)\sum \limits_rP_2(r,j)+\frac{1}{4}(\text{sum of three positive terms all $\le$ 1})}$</p>

<p>However, I am interested in knowing is there anyway I can further get a  lower bound of the RHS of the  above expression such that I have $\frac{1}{\sum \limits_rP_1(i,s)\sum \limits_rP_2(r,j)}$ term left.</p>

<p>The motivation is to get a neat lower bound on $I(Q)$ involving mutual informations of $P_1$ and $P_2$.</p>

<p>Any help/idea will be highly appreciated.</p>

<p>Thanks</p>
",<probability>
"<p>Give the density $ f_{X}(x)=\frac {x^2} {9} $ with $0 &lt; x &lt; 3$</p>

<p>I should calculate with transformation the density of $Y=X^3$.</p>

<p>Is my calculation correct?</p>

<p>$f_{Y}(y)=f_{X}(g^{-1}(y))\mid\frac{d}{dy}g^{-1}(y)\mid = \frac {(y^{\frac{2}{3}})^2} {9}*\frac{1}{3y^2} =\frac{1}{27}$</p>
",<probability>
"<p>Does $Z_n=\sum_{k=1}^{n}\sqrt{k}X_k$ satisfy the strong law of large numbers if $ X_n: \begin{matrix}-\frac{1}{n} &amp; \frac{1}{n} \\ \frac{1}{2} &amp; \frac{1}{2} \end{matrix}, n=1,2,...$ are independent random variables. </p>

<p>I have the following theorems, but I cannot prove this, I have tried all which I understand, the theorems I have are:</p>

<p>1.) Strong Law of large numbers states that the sequence $X_1,X_2,...$ must satisfy:</p>

<p>$$\frac{1}{n}\sum_{k=1}^{n}(X_k-EX_k)\to^{a.s.}0, n\to \infty$$</p>

<p>2.) Kolmogorov Law: If $(X_n)$ independent random variables, such that $\sum_{n=1}^{\infty} \frac{\text{Var}(X_n)}{n^2}&lt;\infty$, then the strong law of large numbers is satisfied.</p>

<p>3.)Borels:  If $ S_n:\mathcal B(n,p)$ (binomial distribution), then $$\frac{S_n}{n}\to^{a.s.}p, n \to \infty$$</p>

<p>or the consequence: </p>

<p>Let $X_n$, sequence of independent random variables, equally distributed, such that $EX_k=a$ and $\text{Var}X_k= \omega^2, k=1,2,3... \implies$</p>

<p>$$\frac{1}{n}\sum_{k=1}^{n}X_k\to^{a.s.}a, n\to \infty$$</p>
",<probability>
"<p>The strong law of large numbers states that the sample average converges almost surely to the expected value $\overline{X}_n\ \xrightarrow{\text{a.s.}}\ \mu \qquad\mathrm{when}\ n \to \infty$ .</p>

<p>That is,$$\Pr\left( \lim_{n\to\infty}\overline{X}_n = \mu \right) = 1.$$</p>

<p>I want to ask whats the domain of the random variable $\overline{X}_n$, given that all $X_n$ have same domain $\Omega$?</p>

<p>For the coin tossing problem $\Omega =\{H,T\} $ and $X_n(H)=1 \quad and \quad X_n(T)=0 \quad\forall n $ so, if the domain of $\overline{X}_n$ was $\Omega$ the $\overline{X}_n(H)=1 \quad \overline{X}_n(T)=0 \quad \forall n$, so $\Pr\left({\omega \in \Omega : \overline{X}_n(\omega)=1/2}\right)=0$ , which is not what strong law says.</p>

<p>I want to know whats the domain of this random variable $\overline{X}_n$?</p>
",<probability>
"<p>Suppose that you spin a dial that freely moves  marked out in 360 degrees in steps of 5 degrees. Whats the proability that the dial will land somewhere between 5 degrees and 300 degrees. Al so how do you calculate the answer </p>
",<probability>
"<p>Suppose we have discrete random variable given by
\begin{align*}
P(X=x_i)=\frac{1}{N},  i=1...N
\end{align*}
and Gaussian r.v. $Z \sim \mathcal{N}(0,1)$. Assume $Z$ and $X$ are independent.
Suppose $X$ and $Z$ form an new r.v. $Y$ give by
\begin{align*}
Y=X+Z
\end{align*}</p>

<p>I am interested in computing $E[X|Y]$?</p>

<p>Here are some of the distributions that I have computed:
\begin{align*}
f_Y(y)&amp;=\frac{1}{N} \sum_{i=1}^N \frac{1}{\sqrt{2\pi}} e^{-(y-x_i)^2/2}\\
f_{Y|X}(y|x_i)&amp;=\frac{1}{\sqrt{2\pi}} e^{-(y-x_i)^2/2}=f_Z(z)\\
f_{X|Y}(x_i|y)&amp;=???
\end{align*}</p>

<p>But I am not sure how to proceed next. For example does density $f_{X|Y}(x_i|y)$ even exists?
Thank you for any help or suggestions.</p>
",<probability>
"<p>I'm really new to statistics and probability so sorry if this is a really basic question. I just wasn't sure how to do it. I tried looking it up but can't find much information. </p>

<p>If I'm given a cdf for a random variable X, how do I find it for a new random variable Y which was in terms of X? Do I just plug in Y? My example is following:</p>

<pre><code>FX(x) = 1 −1/x
for 1 &lt; x &lt; ∞
Find the cdf for the new random variable Y = -X + 2
</code></pre>
",<probability>
"<p>Let $III$ be a root node of a tree. It may have between $0, \cdots , B_1$ children type $X$, and $1 \cdots B_2$ children type $Y$ with probability $\beta_{i,X}$ and $\beta_{i,Y}$, respectivelly. Let $p_X$ be probabilty a node chidren type $X$ evaluate $1$. And $p_Y$ is probabilty a node chidren type $Y$ evaluate $1$.</p>

<p>Find the probability the root node $III$ evaluates $0$? </p>

<p><a href=""http://i.stack.imgur.com/dQXo9.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/dQXo9.png"" alt=""enter image description here""></a></p>

<p>My solution is</p>

<p>The prob. the root node $III$ evaluates $0$ is</p>

<p>$$P(III=0)=P(X=0)P(Y=0)$$ </p>

<p>We have, $p(.)$ is prob. of a node (.) , $P(.)$ is prob. of a group node</p>

<p>$$p(X=0)=1-p(X=1); P(X=0)=\sum_{j=0}^{B_1} \beta_{j,X} (1- p_X)^j$$
$$p(Y=0)=1-p(X=1); P(Y=0)=\sum_{i=1}^{B_2} \beta_{i,X} (1- p_Y)^i$$</p>

<p>Finaly, we got, </p>

<p>$$P(III=0)=P(X=0)P(Y=0)=\sum_{j=0}^{B_1} \beta_{j,X} (1- p_X)^j \sum_{i=1}^{B_2} \beta_{i,X} (1- p_Y)^i$$</p>

<p>However, I found that someone provides another solution as</p>

<p>$$P_{1}(III=0)=\sum_{i=1}^{B_1+B_2-1} \sum_{j=0}^{i-1} \bigg( \beta_{j,X} \big(1-y_X \big)^j \beta_{i-j,Y} \big(1-y_Y \big)^{(i-j)} \bigg) $$</p>

<p>My question is does $P(III=0)$ same with $P_{1}(III=0)$. If not, which one is correct? Thank all</p>
",<probability>
"<p>Ill give some background first before asking questions.(the text below is straight out of the book)</p>

<p>Each individual in the population is assumed give birth at an exponential rate of $\lambda$ in addition ,there is a an  exponential rate of increase  $\theta$ due to external source of immigration. Hence the total birth rate where there are $n$ persons in the system is $n\lambda + \theta$ . Deaths are assume to occur at an exponential rate $\mu$  for each member of the population, so $\mu_n = n\mu$.</p>

<p>Let $X(t)$ denote the population size at time $t$. Suppose $X(0)= i$ and let $M(t) = E[X(t)]$ . So they will determine $M(t)$ by deriving and then solving a differential equation that is satisfies.</p>

<p>we start by deriving an equation for $M(t+h)$ by conditioning on $X(t)$ this yields:</p>

<p>$M(t+ h) = E[X(t+h)] = E[E[X(t+h)\vert X(t)]]$ </p>

<p>Now,given the size of the population at time $t$ then, ignoring  events whose probability is $o(h)$, the population at time $t+h$ will either increase in size by 1 if a birth or immigration occurs in $ (t,t+h)$ , or, decrease by 1 if a death occurs in this interval, or remain the same if neither of these two possibilities occurs that is given $X(t)$</p>

<p>$X(t+h)$=
\begin{cases}
 X(t) + 1 , with- probability  &amp; [\theta + X(t)\lambda]h + o(h) \\
 X(t) - 1, with-probability &amp; X(t)\mu h + o(h)\\
 X(t), with-probability &amp; 1-[\theta + X(t)\lambda + X(t)\mu]h +o(h)
\end{cases}</p>

<p>therefore,
$E[X(t+h) \vert X(t)] =  X(t) + [\theta + X(t)\lambda - X(t)\mu]h + o(h)$</p>

<p>.....
.....
.....(text continues)</p>

<p>$\textbf{questions:}$</p>

<p>$\textbf{(1)}$,  i understand the first two cases , but the last case i don' t quiet get: $X(t)$, with-probability  $1-[\theta + X(t)\lambda + X(t)\mu]h +o(h)$. can someone explain this?</p>

<p>$\textbf{(2)}$How do i interpret this statement: $E[X(t+h) \vert X(t)] =  X(t) + [\theta + X(t)\lambda - X(t)\mu]h + o(h)$</p>

<p>these are my two questions.</p>
",<probability>
"<p>Assume that $H$ is a separable Hilbert space and $\{e_k\}$ is an orthonormal and complete basis of $H$.</p>

<p>$\{\xi_k\}$ is a sequence of normal Gaussian random variables that are independent.</p>

<p>It seems that $\sum_{k=1}^{\infty}\xi_k \langle e_k,h\rangle,\ h\in H$ is square-integrable, but I am not sure how to prove. Who can give me some hints?</p>

<p>Thanks a lot.</p>
",<probability>
"<p>I'm having a tough time finding the next example's sample space's size:</p>

<p>We have at our disposal the following: the three letters $\;a,b,c\;$ , and the five digits $\;1,2,3,4,5\;$ . We have to form with them all the possible passwords of six ($\;6\;$) characters, under the condition that there <em>must be</em> at least one letter and at least one number in each password. Other than this there are no more restrictions (and, thus, one can repeat at will numbers, letters and etc.)</p>

<p><strong>What I tried:</strong> I fixed one letter and one digit, thus getting $\;3\cdot 5=15\;$ possibilities fir each fixation (?), and for the other $\;4\;$ characters needed in the password I have $\;8\;$ possibilities for each (as repetitions are allowed), rendering $\;8^4\;$ possibilities. </p>

<p>I further thought of multiplying the above by two to indicate that the first two characters I chose can be interchanged, and finally I multiplied by $\;\binom 62=15\;$ possibilities to place them within the six places of the password.</p>

<p>All in all, the above says there are $\;15\cdot8^4\cdot2\cdot\binom65\;(**)$ possibilities</p>

<p>All fine...but there are repetitions! For example, suppose for simplicity I have fixed the characters $\;a,1\;$ , and say I place them in positions $\;2-3\;$ . But then one possible password is $\;1-a-1-1-1-1\;$ , yet if I swap my fixed characters in these positions I get the password $\;1-1-a-1-1-1\;$ , which already appears when the positions $\;2-3\;,\;2-4\;,\;2-5\;,$ etc. are chosen.</p>

<p>Thus, the number (**) abo0ve is way over the actual number I'm seaching, and I'm about to become a friar in Malta out of desperation, so any help will be greatly appreciated.</p>
",<probability>
"<blockquote>
  <p>Suppose $X\in N(0,1)$. Show that $X$ and $|X|$ are not jointly continuous.</p>
</blockquote>

<p>I am not sure how I can approach this problem. But the following method seems plausible to me:</p>

<blockquote>
  <p>$$P(X\leq x||X|=u)=\lim_{a\to0}\dfrac{P(X\leq x,|X|\in (u-a,u+a))}{P(|X|\in (u-a,u+a))}$$</p>
</blockquote>

<p>Of course we must have $u&gt;0$. Now let $-u&lt;x&lt;u$ then after some stage, I will get $a$ so small that $x$ will not belong to $(u-a,u+a)$ or $(-u-a,-u+a)$. In that case, the intersection of $(-\infty,x)$ and $(-u-a,-u+a)\cup(-u-a,-u+a)$ will be $(-u-a,-u+a)$ due to which the result becomes:</p>

<blockquote>
  <p>$$\lim_{a\to0}\dfrac{P(X\in(-u-a,-u+a))}{P(X\in(-u-a,-u+a))+P(X\in(u-a,u+a))}=\lim_{a\to0}\dfrac{\Phi(-u+a)-\Phi(-u-a)}{\Phi(-u+a)-\Phi(-u-a)+\Phi(u+a)-\Phi(u-a)}=0.5$$</p>
</blockquote>

<p>Now for $x&lt;-u$, the intersection $\{X\leq x\}$ with $\{|X|\in(u-a,u+a)\}$ is null, hence the numerator is $0$, so the probability is $0$. If $x&gt;u$ then the probability is $1$.</p>

<p>Hence $P(X\leq x||X|=u)=0$ if $x&lt;-u$, is $0.5$ if $-u&lt;x&lt;u$ and is $1$ if $x&gt;u$. So it has two jumps and cannot be a continuous distribution function, and hence cannot have a density. But this density is precisely the conditional density of $X$ on $|X|$, which therefore does not exist. This can happen only when $f_{X,|X|}(x,u)$ does not exist, which shows there is no joint density of $X$ and $|X|$.</p>
",<probability>
"<p>If we define absolutely continuous random variables by Lebesgue integrals &amp; Lebuesgue measures, i.e.</p>

<p>$$F(t) = \int_{-\infty}^{t} f(x) d x$$</p>

<p>for some Lebesgue integrable $f(x)\ge 0$, is it always the case that $F$ is continuous? I know this is true for Riemann integrals due to the fundamental theorem of calculus. Forgive me if this is a stupid question, I'm doing a probability course with very little measure theory in it.</p>
",<probability>
"<p>What is the likelihood of a fair coin given that it has landed heads up 10 times?</p>

<p>You have a fair coin or a double-headed coin...</p>

<p>$\mathsf P($Fair$\mid 10$ heads$) = \dfrac{(1/2)(1/2^{10})}{(1+2^{10})/(2\cdot 2^{10})}= \dfrac{(1/2)(1/1024)}{1025/2048}$</p>

<p>Is this the correct procedure for setting up this problems?</p>

<p><strong>You have a fair coin or $70\%$ weighted coin favoring heads...</strong></p>

<p><strong>What is the likelihood of a fair coin given that it has landed heads up 10 times?</strong></p>
",<probability>
"<p>So there are 12 files in total and 3 of them contain viruses. If a file with a virus is selected, it is removed and a new file is then selected. What is the expected number of files that need to be selected to get a virus free computer? </p>

<h3>Progress</h3>

<p>I thought it was an expected value problem. So summation $\sum X(\xi)p(\xi)$ but that doesn't make sense.   </p>

<p>Is this correct?  Let n be the number of viruses, then the result is $n(1/1 + .. +1/n)$ $$3(1/1 + 1/2 +... + 1/12) = 9.3096$$  </p>
",<probability>
"<p>According to <a href=""http://en.wikipedia.org/wiki/Characteristic_function_%28probability_theory%29"" rel=""nofollow"">Wikipedia</a>, a characteristic function completely determines the properties of a probability distribution. This means it must be unique. However, the definition given is:</p>

<p>$$
\text{Char of }X (t)=E[e^itX]$$</p>

<p>Now $e^{iz}$ repeats for every $2 \pi$ increase in $z$. So how can it be unique?</p>
",<probability>
"<p>$A, B, C$ are independently sampled from an uniform distribution in $[0, 1]$.</p>

<p>We know $P(A &gt; B) = 0.7, P(B &gt; C) = 0.6$, what is $P(A &gt; C)$?</p>

<p>Is this a well defined problem? Does it have a sensible answer?</p>

<p>EDIT: Suppose we have two careless observers.
An observer observes $A &gt; B$ and there are 70% probability that she is right.
Another observer observes $B &gt; C$ and there are 60% probability that she is right. So what is the probability of $A &gt; C$ in the underlying event?</p>
",<probability>
"<p>Here $G_{n,p}$ represents the Erdős-Rényi random graph model, where the graph has order $n$ and each edge is added independently with probability $p$. I am faced with proving the following claim:</p>

<blockquote>
  <p>Show that there is a constant $c&gt;0$ such that, for every $p$ we have: </p>
  
  <p>$\mathbb{P}(G_{n,p}$ is disconnected) $\leq c \mathbb{P}(G_{n,p}$ has an isolated vertex).   $\,\,\,(*)$</p>
</blockquote>

<p>From the appearance of the question I think it is meant to be interpreted as asking ''in the limit $n \to \infty$''. It is clear that $\mathbb{P}($a fixed vertex of $G_{n,p}$ is isolated$)=(1-p)^{n-1}$. It is easy to calculate the expected number of isolated vertices using this, but I'm not convinced that helps.</p>

<p>As a last thought, a followup to the question asks ""What value of $c$ would be acceptable""? It is therefore probably not the case that a valid choice of $c$ will actually be obtained in the proof, although it may be reasonably clear how to calculate one; perhaps that clarifies the nature of the solution a little. Many thanks for your help.</p>

<p><strong>Edit:</strong> Update - I have thought a little more about it, and I have the following theorem we can hopefully make use of (if anyone is willing to help me!): suppose $p = \frac{\log{n}+\gamma(n)}{n}$ and $\gamma(n)$ grows at most slowly (say $o(\log \log n)$); then </p>

<blockquote>
  <p>if $\gamma(n) \to +\infty$, $\mathbb{P}(G_{n,p}$ disconnected)$\to 0$, </p>
  
  <p>if $\gamma(n) \to -\infty$, $\mathbb{P}(G_{n,p}$ disconnected)$\to 1$, </p>
  
  <p>if $\gamma(n) \to k$, $\mathbb{P}(G_{n,p}$ disconnected)$\to 1-e^{-e^{-k}}$.</p>
</blockquote>

<p>Now in the first case, being connected implies no isolated vertex, so $(*)$ holds with any constant $c$ since both probabilities are 0. Likewise, in the second case, the graph is almost surely disconnected: while this doesn't immediately imply that an isolated vertex exists, we can hopefully say for $X:=\#$ of isolated vertices,</p>

<p>$\mathbb{E}(X)=n(1-p)^{n-1} = n(1-\frac{\log{n}+\gamma(n)}{n})^{n-1} \sim ne^{-(\log{n}+\gamma(n))} = e^{-\gamma(n)} \to \infty$.</p>

<p>I <strong>think</strong> this last step holds but it may depend on $\gamma$: in general I'm not sure for which functions $(1+\frac{f(n)}{n})^n \to e^{f(n)}$, I know this is true for the log term but maybe not if $\gamma$ grows very fast (though obviously it can't grow any faster than $1-\frac{\log{n}}{n}$ otherwise we would have $p&gt;1$).</p>

<p>We can also calculate the second moment and get $\mathbb{E}(X^2)-\mathbb{E}(X)^2 \sim e^{-\gamma(n)}$ and deduce that with high probability there is an isolated vertex. Thus again, both probabilities are equal and we can take (e.g.) $c=1$. </p>

<p>The <em>hard</em> case is where $\gamma(n) \to k$: in this case we can reapply the same method to get $\mathbb{E}(X) \sim e^{-k}$, a constant. We can calculate again $\mathbb{E}(X^2) -\mathbb{E}(X)^2 \sim e^{-k}$, and use Chebyshev's inequality to calculate $\mathbb{P}(X=0) \leq e^{-k}/e^{-2k} = e^k$. If $k&lt;0$, then this gives us an actual bound on the probability; otherwise we just get $\mathbb{P}(X=0) \leq 1$. </p>

<p>Supposing $k&lt;0$ then; we can rewrite as $s:=\mathbb{P}(X&gt;0)=\mathbb{P}$(isolated vertex)$\geq 1-e^k$, $d:=\mathbb{P}($disconnected) and using the fact $d =1- e^{-e^{-k}}$ and a little rearranging I think we get out the inequality $d \leq 1-\exp\left(\frac{1}{s-1}\right)$. We can then find a $c$ which works by applying the lower bound to $s$ in terms of $k$ then looking at the values of $c$ such that $cx \geq 1-\exp\left(\frac{1}{s-1}\right),\,x \in [1-e^k,1]$. However, this is only for fixed $k$! If we try and do this for <em>every</em> $k&lt;0$ (i.e. every probability of this type) simultaneously, then we find that $c$ must be arbitrarily large. What's worse, this method doesn't work at all for $k \geq 0$ where we don't have a lower bound for $s$: in this case $s$ can be arbitrarily small and we can't pick a $c$ big enough to always work. So close and yet so far. </p>

<p>I am aware this question's length has spiralled out of control, so apologies for that - I know there's a good chance Math.SE is not going to provide me with an answer to this one. Nevertheless, it says add your working and this is what I managed to do! A proof which works for all <em>slowly</em> decreasing $\gamma$ or $\gamma \to k \in (-\infty,-\epsilon],$ any $\epsilon &gt; 0$. </p>

<p>I have a strong suspicion this is not how I was meant to try and tackle the question, but tragically this is the best I could do so far. Thank you in advance to anyone who actually reads through all this!</p>
",<probability>
"<p>I've found this formula in a blog, it is in the answer to one question. But I don't know how to prove this:</p>

<blockquote>
  <p>Let $x_n$ be a sum of $n$ i.i.d. Bernoulli random variables with parameter $1/2$. Let $q\geq 2$.
  Show that 
  $$
E((2x_n-n)^q)=\sum_{k=0}^n{n \choose k}2^{-n}(2k-n)^q
$$</p>
</blockquote>

<p>Thank you for your help.</p>
",<probability>
"<p>The formula for the expected value in a binomial distribution is:</p>

<p>$$E(X) = nP(s)$$
where $n$ is the number of trials and $P(s)$ is the probability of success.</p>

<p>The formula for the expected value in a hypergeometric distribution is:</p>

<p>$$E(X) = \frac{ns}{N}$$
where $N$ is the population size, $s$ is the number of successes available in the population and $n$ is the number of trials.</p>

<p>$$E(x) = \left( \frac{s}{N} \right)n $$
$$P(s) = \frac{s}{N}$$
$$\implies E(x) = nP(s)$$</p>

<p>Why do both the distributions have the same expected value? Why doesn't the independence of the events have any effect on expected value?</p>
",<probability>
"<p>There are $m$ normally distributed, independent random variables $N_1, \ldots, N_m$ with distinct means $\mu_1, \ldots \mu_m$ and standard deviations $\sigma_1, \ldots, \sigma_m$. Then, we get a permutation of the numbers $\{1, \ldots, m\}$. How can we efficiently compute, numerically, the (log) probability of observing the random variables in same ordering as this permutation?</p>

<p>An example:</p>

<ol>
<li>we have four independent random variables $N_1, N_2, N_3, N_4$, all with different means and variances. </li>
<li>We are given the permutation (3, 1, 2, 4).</li>
<li>What's $\Pr(N_3 &gt; N_1 &gt; N_2 &gt; N_4)$?</li>
</ol>

<p>A closed-form solution is not necessary, but computing the solution using an efficient algorithm with good accuracy is. Also, it's probably necessary to compute a log probability due to the fact that when the number of variables becomes large, computing the actual probability will result in a floating-point underflow. </p>

<h3>Some starting points, perhaps...</h3>

<p>The most direct way to compute this value, using the example above, is evaluating one of the following integrals, which I believe are equivalent:</p>

<p>$$ \int_{-\infty}^\infty \int_{n_4}^\infty \int_{n_2}^\infty \int_{n_1}^\infty p(n_1)p(n_2)p(n_3)p(n_4)\ dn_3 dn_1 dn_2 dn_4 $$</p>

<p>$$ \int_{-\infty}^\infty \int_{-\infty}^{n_3} \int_{-\infty}^{n_1} \int_{-\infty}^{n_2} p(n_1)p(n_2)p(n_3)p(n_4)\ dn_4 dn_2 dn_1 dn_3 $$</p>

<p>Where $p(n_i)$ is the density function of the variable $N_i$. However, when I tried to implement this numerically, it is inefficient, prone to inaccuracy, and runs into underflow errors when the number of variables gets large. <strong>If you think you can compute this integral in an acceptable way, please do post your answer!</strong></p>

<p>From one of the answers below, we observe that it's possible to compute $\Pr(N_3 &gt; N_1 &gt; N_2 &gt; N_4)$ directly by evaluating a multivariate normal CDF of dimension $(m-1)$, or 3 in this case. However, this is still nontrivial (though there may be libraries for it), and will underflow for many variables.</p>

<p>Perhaps we can divide the probability up as follows:</p>

<p>$$\Pr(N_3 &gt; N_1 &gt; N_2 &gt; N_4) = $$
$$\Pr(N_3 &gt; N_1 \mid N_1 &gt; N_2, N_2 &gt; N_4 )\Pr(N_1 &gt; N_2 \mid N_2 &gt; N_4 )\Pr(N_2 &gt; N_4)$$</p>

<p>Being able to compute the probabilities of each part directly would make it very easy to compute the log probability simply by adding. We can compute the conditional probabilities separately using the MVN CDF method, which could help if the product might underflow.</p>

<p>Another observation: the $m!$ possible probabilities corresponding to the different permutations must sum to 1. Perhaps there is a way to compute the probabilities iteratively or using dynamic programming: i.e.: $(N_2 &gt;  N_3)$, an ordering over a pair, has some fixed probability, which is further divided into three values by the three possible places to insert $N_1$ into the ordering, further divided into the four values by the possible places to insert $N_3$. This is semantically equivalent to the conditional probabilities above but it might be easier to think of it this way.</p>

<p>Any math wizards have suggestions on how to solve this problem? I would greatly appreciate any ideas!</p>
",<probability>
"<p>I am not a mathematics guy, and the question which I am gonna ask would be pretty simple for mathematicians. In fact I am doing research and was reading some blogs. I wanted to derive the density function for $n$ number of independent variables. following relation I find on Internet for calculating CDF of $n$ number of independent variables
$$
F(T) = 1 – (1 - F_1(T)) (1 - F_2(T)) \dots (1- F_n(T)) = 1 – \prod_{i=1}^n F_i (T)
$$
 but for PDF they says that take the derivative of it . In fact I learned mathematics decades ago, so I don't know how to do that. Can some one just help me in steps how to take derivate of above equation and finally what would be the Density function?</p>
",<probability>
"<p>I need to show that if $E_1,E_2,\ldots, E_n$ are independent then $E_1^c ,E_2^c,\ldots, E_n^c$ are independent too. Please provide a hint.</p>
",<probability>
"<p>First, let's recall the definitions of 4 different types of convergence:almost surely, in $r$th mean, in probability and in distribution:</p>

<ol>
<li>$X_n\xrightarrow{a.s.}X$ if $\{\omega \in \Omega:X_n(\omega)\rightarrow X(\omega),$ as $n\rightarrow\infty\}$ is an event with probability 1.</li>
<li>$X_n\xrightarrow{L^r} X$ if $\forall r\geq1,\mathbb{E}[X_n^r]&lt;\infty$, $\mathbb{E}[|X_n-X|^r]\rightarrow 0$, as $n\rightarrow \infty$</li>
<li>$X_n\xrightarrow{p}X$ if $\forall \epsilon &gt;0,\mathbb{P}(|X_n-X|&gt;\epsilon)\rightarrow 0,$ as $n\rightarrow \infty$</li>
<li>$X_n\xrightarrow{D}X$ if $\mathbb{P}(X_n\leq x)\rightarrow \mathbb{P}(X\leq x)$ as $n\rightarrow \infty$</li>
</ol>

<p>In Wikipedia I got the following implication relations:</p>

<ol>
<li>If $s&gt;r\geq1,(X_n\xrightarrow{L^s} X) \Rightarrow (X_n\xrightarrow{L^r}X)$</li>
<li>Convergence almost surely and convergence in mean both imply convergence in probabilty.</li>
<li>$(X_n\xrightarrow{p}X)\Rightarrow (X_n\xrightarrow{D}X)$ (Convergence in probability implies convergence in distribution)</li>
</ol>

<p>So, what I want to ask here is that if somebody can give me some simple examples to briefly explain why the implication works and some counter examples why it doesn't work conversely(the other direction of the implication arrow), because all those definitions look so similar to me, especially, for example, why convergence in probability doesn't imply convergence almost surely? For the definitions of them are really the same thing.</p>

<p>I'll really appreciate if you can help me out. Thanks!</p>
",<probability>
"<blockquote>
  <p>An insurance company examines its pool of auto insurance customers and gathers the following information:</p>
  
  <p>(i)  All customers insure at least 1 car</p>
  
  <p>(ii)  64% of all customers insure more than one car</p>
  
  <p>(iii)  20% of the customers insure a sports car</p>
  
  <p>(iv)  Of those customers who insure more than one car, 15% insure a sports car.  </p>
  
  <p>What is the probability that a randomly selected customer insures exactly one car, and that car is not a sports car?</p>
</blockquote>

<p>Let's use the following variable definitions:</p>

<p>O= owns 1 car, O' = owns more than 1 car</p>

<p>S= sports car, S' = Not sports car.  </p>

<p>N() = Cardinal Number of a set</p>

<hr>

<p>From statements (i)-(iii), we get the following:  $N(O') = 64, N(O) = 36, N(S) = 20$</p>

<p>From statement (iv):  $\Pr(S \mid O')=15$</p>

<p>We are asked to find $\Pr(S' \mid O)$</p>

<hr>

<p>By definition:<br>
$Pr(S' \mid O) = \cfrac{\Pr(S' \cap O)}{\Pr(O)}=\cfrac{\Pr(S' \cap O)}{N(O)}\tag{1}$</p>

<p>Pr()=N() since this is a uniform distribution--I interpret this when it says ""randomly selected""</p>

<p>Next, I did: </p>

<p>$N(S)=N(S \cap O') + N(S \cap O)\tag{2}$</p>

<p>$0.2 = .64*.15 + .36 * x$</p>

<p>$x=0.28$, but we want 1-x because we want S' in $\Pr(S' \cap O)$ which equals 0.72.</p>

<p>See diagram below:</p>

<p><img src=""http://i.stack.imgur.com/n5UVW.png"" alt=""Tree diagram""></p>

<p>So plugging back into (1):  </p>

<p>$Pr(S' \mid O) = \cfrac{0.71*.36}{.36}=.71$</p>

<p>but the answer is .26.  </p>

<p><strong>I mainly wanted to know why equation (2) is wrong.  I know that is the crux of the problem.  Why can't I use that equation in this case?</strong></p>

<p>Any help is appreciated.  Thank you.</p>
",<probability>
"<p>$\newcommand{\E}{\operatorname{\mathbb E}}$
$\newcommand{\Var}{\operatorname{\mathbb Var}}$
If $\E[X] = {^1\!/\!_3}(\E[X\mid Y=1] + \E[X\mid Y=2] + \E[X\mid Y=3]) = 10$</p>

<p>Where $\E[X|Y=1] = 2,\; \E[X|Y=2] = 3+\E[X],\; \E[X|Y=3] = 5+\E[X]$</p>

<p>is $\E[X^2|Y=1] = 4,\; \E[X^2|Y=2] = 9 + 6\E[X] + 6\E[X^2],$ and so on?</p>

<p>This is to find the $\Var(X)$.</p>

<p>where $\Var(X) = \E[X^2] - (\E[X])^2$</p>

<p>Question: How do you find the Variance of this given that $\E[X] = 10$?</p>
",<probability>
"<p>The characteristic function of a random variable $X$ is given as:</p>

<p>$$E(e^{jvX}) = \int _{-\infty} ^{\infty} e^{jvx} p(x) dx $$</p>

<p>This is interpreted as either mean of function $e^{jvx}$ or fourier transform of pdf $p(x)$. I know that $x$ represents random variable, but what does $v$ represents? What is its physical significance?</p>
",<probability>
"<p>Let $m$ be a finite measure on $X \subseteq \mathbb{R}^n$, so that $m(\mathbb{R}^n) &lt; \infty$.</p>

<p>Define the hyperplanes on $\mathbb{R}^n$, parametrized by $A \in \mathbb{R}^{n \times n}$ and $b \in \mathbb{R}^n$, as
$$ H(A,b) := \{ x \in \mathbb{R}^n \mid A x = b \}. $$</p>

<p>Take many ""extractions"" $y_1, y_2, ...$ from $m$. </p>

<p>Say under what conditions on $m$ no more than $n$ i.i.d. extractions $y_i$'s belong to the same hyperplane almost surely, i.e.</p>

<p>$$ m^{n+1}\left( \left\{ (y_1, y_2, ..., y_{n+1}) \in X^{n+1} \mid \\
\exists (A,b) \in (\mathbb{R}^{n \times n} \times \mathbb{R}^n) \text{ such that } y_1, y_2, ..., y_{n+1} \in H(A,b)  \right\} \right) = 0,$$</p>

<p>where $m^{n+1} := m \times m \times \cdots \times m$ ($n+1$ times) is the product measure.</p>

<p>I was thinking about merely atomless $m$, but I then thought it may not be enough.</p>
",<probability>
"<p>I've been struggling for a while to understand the meaning of liminf of a sequence of sets. </p>

<p>I know that the definition is </p>

<p>$\liminf_{n\to\infty}A_n:=\bigcup_{n\in\mathbb{N}}\bigcap_{m\geq n} A_n$.</p>

<p>When I break it up into pieces, I get $(A_1 \cap A_2 \cap A_3 \cap A_4 \cap \ldots) \cup (A_2 \cap A_3 \cap A_4 \ldots) \cup (A_3 \cap A_4 \cap \dots) \cup (A_4 \cap \ldots) \cup \ldots$.</p>

<p>Here, $A_n$ occurs infinitely many times, doesn't it? Because it is in each set of parentheses?</p>

<p>Or do the unions mean <strong>OR</strong>, so that $A_n$ might or might not be in any of the sets? </p>

<p>However, this is wrong! Why? I'm confused.</p>
",<probability>
"<p>I am studying stochastic processes and have stumbled on a result that is puzzling me. I have searched elsewhere for an answer without luck so hoping some proper mathematicians here can explain the result for me.</p>

<p>Given a two-state Markov process with probability transition matrix
$$
\begin{array}{c|c}
&amp;\begin{matrix}0&amp;1\end{matrix}\\
\hline
\begin{matrix}0\\ 1\end{matrix}
&amp;\pmatrix{a&amp;b\\ c&amp;d}
\end{array}
$$</p>

<p>I have found that the simplest way to calculate its steady-state probability distribution is :</p>

<p>state 0: $c \over {b + c}$</p>

<p>state 1: $b \over {b + c}$</p>

<p>This result holds for all examples I have tried, but I have been unable to explain it from theory, so cannot prove it. My questions are:</p>

<ol>
<li>what is the theoretical explanation for this result?</li>
<li>does it extend to any $n\times n$ transition matrix?</li>
</ol>
",<probability>
"<p>So the exercise is this:</p>

<p>We have and infinite chessboard and we have a coin. Every grid is of length and width $a$, whereas the coin has diameter $2 \cdot r&lt;a$. We throw a coin into a chessboard and we want to know with what probability the coin will falll into the grid.</p>

<p><img src=""http://i.stack.imgur.com/y9SI1.jpg"" alt=""enter image description here""> </p>

<p>So let $S_{1}$=area of green rectangle, $S_{2}=S_{1}+$ area of the red border.
So the probability in my opinion is 
$ P(a)= \frac{S_{1}}{S_{2}} $.</p>

<p>Is this in any shape or form correct?</p>
",<probability>
"<p>I'm reading a book with chances and probability.
The book has the following problem:
""The draw for the fifth round of the FA Cup is about to be made.  There are 16 teams, leading to eight matches.  Your task is to pair the teams off, in an attempt to guess as many as possible off the actual matches in the real Cup draw.  You are not asked which teams will be drawn at home, just which pairs will be selected.  I am prepared to pay you $1.50 for each correct guess; how much would you be prepared to offer for the right to make the eight guesses?""
(What is the minimum fair entrance fee?)</p>

<p>I would like pointers to solve this by using ordinary combinatorics, if possible.  (Author uses the idea: sum of the averages is the averages of the sum, which it might be faster, but I would be jumping to an easy way of solving this without first analyzing/understand/adopt it).</p>

<p>I have tried the following:<br>
First Match arrangements (16x15)=240<br>
Second Match arrangements (14x13)=182<br>
Third Match arrangements (12x11)=132<br>
Fourth Match arrangements (10x9)=90<br>
Fifth Match arrangements (8x7)=56<br>
Sixth Match arrangements (6x5)=30<br>
Seventh Match arrangemets (4x3)=12<br>
Eighth Match arrangements (2x1)=2<br>
So I get 744 possible arrangements.  </p>

<p>I'm starting to question my above approach because on the Eighth Match arrangements, I have 2 possible ways, when intuitively I know there is only one way (it is the last matching pair), so I know I'm missing something but cannot point it down.</p>

<p>Thanks in advance!</p>
",<probability>
"<p>$\newcommand{\Var}{\operatorname{Var}}$
$\newcommand{\Cov}{\operatorname{Cov}}$</p>

<p>I am supposed to show the following:</p>

<p>$$
\Var(Y-E(Y\mid X)) = E(\Var(Y\mid X))
$$</p>

<p>My attempt involved using simple property of conditional expectations and variances, I get a close result, but not quite:</p>

<p>$$
\Var(Y-E(Y\mid X)) = \Var(Y) + \Var(E(Y\mid X)) - 2\Cov(Y,E(Y\mid X))
$$</p>

<p>Since $\Cov(Y,E(Y\mid X)) = \Cov(Y,Y) = \Var(Y)$, then:</p>

<p>$$
\Var(Y) + \Var(E(Y\mid X)) - 2\Cov(Y,E(Y\mid X)) = \Var(E(Y\mid X)) - \Var(Y)
$$</p>

<p>But $\Var(Y) = \Var(E(Y\mid X)) - E(\Var(Y\mid X))$ and then:</p>

<p>$$
\Var(E(Y\mid X)) - \Var(Y) = \Var(E(Y\mid X)) - \Var(E(Y\mid X)) - E(\Var(Y\mid X)) = -E(\Var(Y\mid X))
$$</p>

<p>Thanks!</p>
",<probability>
"<p>Two n bit binary strings S1 and S2 are chosen randomly with uniform probability.The probability that the Hamming distance in between these strings (the number of bit positions where the two strings differ) is equal to d is</p>

<pre><code>1)nCd/2^n 
2)nCd/2^d
3)d/2^n 
4)1/2^d
</code></pre>

<p>? Choose the right answer.(Sorry for ambiguity).
I tried to solve the problem ,but indeed didn't find any suitable way to tackle this problem.</p>
",<probability>
"<p>I have the following problem. I'm struggling a little bit with the expression $P(X \in A)$. My problem is that $A$ is a set, whereas $X$ is a function. I can not really related this two items. </p>

<p>Here are some related definitions from the textbook I use. </p>

<ul>
<li>Sample space: $\Omega$ </li>
<li>Outcome: $\omega$</li>
<li>Event: $A, (A \subset \Omega) $</li>
<li>Random variable:  $X: \Omega \rightarrow R $ $\big($X assigns a real number to each outcome ($X(\omega)$ $\big)$.</li>
</ul>

<p>I tried to work out a simple example: Toss a coin two times and let X be the number of heads. Then: $\Omega = \{HH,HT,TH,TT\} $. For example if we have a look on the prob. that we get two heads, $P(X=2)=\frac{|\{HH\}|}{|\Omega|}=\frac{1}{4}$, it makes kind of sense to me, because we compare the cardinality of of two sets. However, I can not imagine a Example of $P(X \in A)$.</p>

<p>Can maybe someone give some intuition for that or give a small example in the case of a coin toss (or dice or ...). </p>

<p>cheers!</p>
",<probability>
"<blockquote>
  <p>Suppose that $X$ and $Y$ are independent and identically distributed:
  $$P (X = k) = P (Y = k) = ρ (1 − ρ)^k$$
  for $k = 0, 1, \dots$ and let $Z := X + Y$. Find the joint distribution of $(X, Z)$ and find the conditional distribution of $X$, given $Z = n$.</p>
</blockquote>

<p>I need a little help just setting this up.</p>

<p>If I understand the question, I'm looking for $P (X = k, Z = n)$ and $P (X = k \mid Z = n)$. I'm a little confused, though, because I've never done this when I have a variable defined as a linear function of the other random variables. I also don't really understand what $n$ is.</p>

<p>Any hints or help getting started is appreciated.</p>
",<probability>
"<p>Suppose that $Y$ has the binomial distribution, $Bin(20, 0.25)$ and conditioned on $Y$, a random variable $X$ that has the binomial distribution, $Bin(Y, 0.5)$. </p>

<p>How can I derive the $k$th moment of $X$?</p>

<p>I know the general case:</p>

<p>$E(X)=∑_{x∈Ω_X}x^kP[X=x]$, and I know that just for one binomial random variable, $E[X]$ is $np$, but I'm not sure how to deal with $X$, which is conditioned on a second variable.</p>
",<probability>
"<p>So the question is: given that you roll $10$ dice, what is the probability of the sum of the total dice rolls adding up to $57$? </p>

<p>I know that there are three ways to do this:</p>

<ol>
<li>Seven die rolls must be $6$ with three $5$s</li>
<li>Eight die rolls must be $6$, one die roll must be $5$ and one must be $4$</li>
<li>Nine die rolls must be $6$, and one roll must be $3$</li>
</ol>

<p>The solution states that the probability of the events are:</p>

<ol>
<li>$ \binom{10}{3} \cdot \frac{1}{6^{10}}$</li>
<li>$ \binom{10}{1} \cdot \binom{9}{1} \cdot \frac{1}{6^{10}} $</li>
<li>$ 10 \cdot 9 \cdot \frac{1}{6^{10}} $</li>
</ol>

<p>I really don't understand why the probabilities work this way. I would really, really appreciate it if someone could perhaps explain this in a more intuitive way for me. </p>

<p>Edit: I am really sorry for the mistake. Edited so that the question reads sum up to 57. </p>

<p>Edit 2: Also, I think my solution sheet is missing the fact that you should sum all of these probabilities and set them over $6^{10}$. I apologize for the mess and I appreciate all the comments that pointed this out.</p>
",<probability>
"<p>We have that $N$ and $X_1, X_2, \dots$ are all independent. We also have $\operatorname{E} [X_j] = \mu$ and $\operatorname{Var}[X_j] = σ^2$.</p>

<p>Then, we introduce an integer–valued random variable, $N$, which is the random sum such that:
$$Z = \sum_{j=1}^{N+1}X_j.$$
Assuming that $N$ is distributed $\sim\mathrm{Poisson}(\lambda)$, what is the first moment and what is the variance of $Z$?</p>

<p>For a normal Poisson distribution, I know the variance is just $\lambda$, as is the mean. I'm having trouble understanding the implication of having the bounds be poisson distributed. Normally, I would just say ""variance of the sum is the sum of the variance,"" but I don't think that's how it works with random sums. Any hints/guidance appreciated.</p>
",<probability>
"<p>I know how to calculate expected value for a single roll, and I read several other answers about expected value with rerolls, but how does the calculation change if you can make your reroll before choosing which die to keep?</p>

<p>For instance, what is the expected value of rolling $2$ fair $6$-sided dice and keeping the higher value?  And can you please generalize to $n$ $x$-sided dice?</p>
",<probability>
"<p>I've been exercising probability and came across the following problem:</p>

<p>A club has $N$ members, where $N$ is a random variable with probability-mass-function: $p_N(n)=p^{n-1}(1-p)$.</p>

<p>Each member has a probability $q$ to show up and all the ""showing-up""s and $N$ are pairwise independent.</p>

<p>If $A$ is a r.v. telling how many members will show up, I need to compute the variance of $A$.</p>

<p><strong>Could you please tell me why the following part of the official solution is correct:</strong></p>

<blockquote>
  <p>$\text{var}(A) = E\ [N]\cdot \text{var}(B) + (E \ [B])^2\cdot\text{var}(N)$</p>
  
  <p>where $B$ is a Bernoulli random variable describing whether a member turns up or not.</p>
</blockquote>

<p>I am familiar with the law of total variance: $\text{var}(X) = E\ [\text{var}(X|Y)]+\text{var}(E\ [X|Y])$</p>

<p>and with the law of iterated expectations: $E\ [X] = E\ [\ E\ [X|Y]\ ]$,</p>

<p>but I can't see any connection between any of them and the statement I want to know the justification of. Thanks!</p>

<p>PS It probably has something to do with expressing $A$ as a sum of $A_1+\ldots+A_n$ where $A_i$ is an indicator function of whether the $i$th member shows up, but still, what do I do with $\text{var}(A) = \text{var}(A_1+\ldots+A_n | N=n)$?</p>
",<probability>
"<p>The chance that a team wins a game when loosing 3+ turnovers is 13.3% if their opponent is not the Lakers. If
their opponent is the Lakers, the percentage of winning is 24%.</p>

<p>There are 30 teams in total. What is the likelihood of a team winning a game
if their opponent is <strong>not</strong> the Lakers.</p>

<p>I have done the following: <br>
P(Playing not the Lakers) = 28/29 or .9655 <br>P(Playing the Lakers) = 1/29 or .0345<br> P(Win | Playing the Lakers) = .133<br> P(Win | Not the Lakers) = .24<br><br>
However, now that I calculated these values, I am unsure of where to go with them. Any help or elaboration would be much appreciated. Thank you.</p>
",<probability>
"<p>I have $S=R+\epsilon$ where $R \sim Cauchy(r, 1/\alpha)$ and $\epsilon \sim Cauchy(0, 1/\beta)$. I want to calculate the distribution of $R$ given $S=s$. </p>

<p>I've tried the following:</p>

<p>By the definition of conditional probability, we have $f_{R | s}(x | s) = \frac{f_R(x) f_\epsilon(s-x)}{f_{R+\epsilon}(s)}$. </p>

<p>We know that for $X \sim Cauchy (x_0, \gamma)$ we have the density function
$f(x) = \frac{1}{\pi \gamma} \frac{\gamma^2}{(x-x_0)^2 + \gamma^2}$</p>

<p>Then plugging this in (and simplifying a bit), we get</p>

<p>$$f_{R | s}(x | s) = \frac{1}{\pi (\frac{1}{\alpha + \beta})}
\frac{\frac{1}{(\alpha+\beta)^2}}{\frac{((x-r)^2+\frac{1}{\alpha^2})((s-x)^2+\frac{1}{\beta^2})}{(x-r)^2+(\frac{\alpha+\beta}{\alpha \beta})^2
}
}
$$</p>

<p>I can't simplify the part on the bottom to get what would be desired if it were a Cauchy distribution. Any hints/tips? Thank you!</p>
",<probability>
"<p>Given a process $X_n \xrightarrow{d} X$ on some probability space $(\Omega,\mathcal{A},P)$. If for every $B \in \mathcal{A}$ it holds, that
$$
\lim_{n\rightarrow \infty} P(X_n\in A,B)=P(X\in A)P(B)
$$
and any set $A$ of continuity of the distribution function of $X$, we say the convergence is renyi-mixing in the classical discrete time sense. 
This is shown to be equivalent to: Fix $m$ and for $B\in \sigma(X_{1},\ldots,X_{m})$ with $P(B)&gt;0$ then
$$
\lim_{n\rightarrow \infty} P(X_n\in A|B)=P(X\in A)
$$</p>

<p>Now lets say we have a continuous time proces $X_t$ with $X_t\xrightarrow{d}X$. If we want the convergence to be renyi-mixing, is it sufficient to show, that for any countable grid $(t_i)_{i\in\mathbb{N}}$ with $t_{i}\rightarrow \infty$ as $i\rightarrow \infty$
$$
\lim_{i\rightarrow \infty}P(X_{t_i}\in A,B)=P(X\in A)P(B)
$$
holds?</p>

<p>Best regards</p>
",<probability>
"<p>Let $X$ be Brownian motion on a Riemannian manifold $M$ starting at $x\in M$, D a domain and $f$ a bounded continuous function on $D$. Define $\tau_D$ to be the first exit time of $X$ from $D$. $u_f\left(t,x,y\right)=\int_Dp_D\left(t,x,y\right)f\left(y\right)dy$ solves</p>

<p>$
\begin{cases} 
L_Mu_f\left(t,x\right)=0, &amp; t&gt;0,x\in\overline{D}, \\
u_f\left(t,x\right)=0, &amp; t&gt;0,x\in\partial D, \\
\lim_{t\downarrow0}u_f\left(t,x\right)=f\left(x\right), &amp; x\in D.
\end{cases}
$</p>

<p>I have seen the following two formulae written:</p>

<p>$$\mathbb{P}_x\left(X_t\in C, t&lt;\tau_D\right)=\int_Cp_D\left(t,x,y\right)dy$$
and
$$E_x\left(f\left(X_t\right),t&lt;\tau_D\right)=\int_Dp_D\left(t,x,y\right)f\left(y\right)dy.$$</p>

<p>Is $\mathbb{P}_x$ the joint probability of the events $\{X_t\in C\}$ and $\{t&lt;\tau_D\}$? I also do not know what the interpretation for $E_x\left(f\left(X_t\right),t&lt;\tau_D\right)$ is. Any help is appreciated.</p>
",<probability>
"<p>Let $x$ and $y$ be two random variables with support of $\left[1\hspace{5pt}10\right]$  and $\left[50\hspace{5pt}90\right]$ respectively. The distribution of each of these variables is $p_X(x)$ and $p_Y(y)$ respectively. and their joint distribution is $p_{X,Y}(x,y)$. Now let us define two random variables as follows</p>

<p>\begin{equation}
z_1 = \frac{y}{x} \\
z_2 = x
\end{equation}</p>

<p>The distribution, $p_{Z_1}(z_1)$, of $z_1$ can be found as follows
\begin{equation}
p_{Z_1}(z_1) = \int_{-\infty}^{\infty} z_2p_{X,Y}(z_1z_2,z_2)dz_2
\end{equation}</p>

<p>My question is: </p>

<ol>
<li>Does the distribution $p_{Z_1}(z_1)$ depend upon the values of $x$, $y$ and $\frac{y}{x}$?</li>
<li>Does the distribution $p_{Z_1}(z_1)$ depend only upon $\frac{y}{x}$?</li>
</ol>

<p>The reason for asking this question is as follows:</p>

<p>Assume $y = 70$ and $x = 7$. Then $Z_1 = 10$. Since these values of $x$ and $y$ are within their support, the joint distribution $p_{X,Y}(x,y)$ will be zon-zero and so will be $p_{Z_1}(z_1)$. On the other hand, assume $y = 150$ and $x = 15$. Both these values are outside their support. But $Z_1$ is still $10$. $p_{X,Y}(x,y)$ will be close to zero. What can we say about $p_{Z_1}(z_1)$? In fact, for given $Z_1 = 10$, we can choose several values of $x$ and $y$ within their support and with different $p_{X,Y}(x,y)$. Does the choice of the values of $x$ and $y$ affect $p_{Z_1}(z_1)$?</p>
",<probability>
"<p>An urn contains 5 red and 6 blue and 8 green balls. 3 balls are randomly selected from the urn, find the probability that they are all of the different colors if the balls are drawn without replacement</p>
",<probability>
"<p>I'm trying to endow a set of probability measures $\triangle\left(X\right)
 $  with the weak * topology, where $X=\left\{ x_{1},\, x_{2},\,...,\, x_{N}\right\} \subseteq\mathbb{R}$ is a finite set of elements. Of course, this seems very straightforward because the set of probability measures can be identified with the n-dimensional simplex</p>

<p>$\hspace{5cm} S^{N}=\left\{ p\in\mathbb{R}^{N}\,|\, p\geq0,\,\underset{i}{\sum}p_{i}=1\right\}$ </p>

<p>My question is this identification. Is it ""natural"" to identify $\triangle\left(X\right)
 $ with $S^{N}$ (that is, treating each $p \in S^{N}$ as a probability measure defined as, for each $A \subset X$,  $p(A)=\underset{x_{i}\in A}{\sum}p_{i} $ ) and then give $S^{N}$ the topology with subbasis elements of the form </p>

<p>$\hspace{3cm}\left\{ p\in S^{N}\,|\,\left|\underset{i}{\sum}f\left(x_{i}\right)p_{i}-a\right|&lt;\varepsilon\right\},$ $\hspace{1cm} f:X \rightarrow \mathbb{R}$, $a \in \mathbb{R}$, and $\epsilon&gt;0$ </p>

<p>Thanks for your help. I know it's kind of a weird question I just want to make sure I'm staying consistent with definitions. </p>
",<probability>
"<p>Playing ""Rim World"", I noticed a geometric variable, but whose individual event probability increases with each attempt (or with time).  So I first model it with a simple probability, having a single failure parameter $q$.  The $n$th event has probability $1-q^n$ to succeed.  The probability to suceed at event $n$ is thus</p>

<p>\begin{equation}
P(n) = \left( \prod_{k=1}^{n-1} q^k \right) \cdot (1-q^n)
\end{equation}</p>

<p>My question is, what is the expected value of that random variable ?
Here is what I got so far :</p>

<p>\begin{align}
E[n] &amp;= \sum_{n\ge1} n\cdot \left( \prod_{k=1}^{n-1} q^k \right) \cdot (1-q^n)\\
     &amp;= \sum_{n\ge1} n\cdot \left( q^{\sum_{k=1}^{n-1} k} \right) \cdot (1-q^n)\\
     &amp;= \sum_{n\ge1} n\cdot q^{(n-1)\cdot n} \cdot (1-q^n)\\
     &amp;= \left( \sum_{n\ge1} n\cdot q^{(n-1)\cdot n} \right)
     -  \left( \sum_{n\ge1} n\cdot q^{(n-1)\cdot n^2} \right) \\
\end{align}
Now I'd like to do, $\zeta = q^n$ and $\xi = q^{n^2}$,
\begin{align}
E[n] &amp;= \left( \sum_{n\ge1} n\cdot \zeta^{(n-1)} \right)
     -  \left( \sum_{n\ge1} n\cdot \xi^{(n-1)} \right) \\
     &amp;= \frac{1}{(1-\zeta)^2} - \frac{1}{(1-\xi)^2}\\
\end{align}
But $\zeta$ and $\xi$ depends on $n$, so that's not a valid way of computing that.  How would you do it ?  Thank you for suggestions !</p>
",<probability>
"<p>I have read some introductory probability theory textbooks and found that for a continuous random variable, $P(x=a) =0\;\forall a$ , that means, whatever what possible outcome I choose, the possibility of it happens is zero. I found it strange, because it stated that no outcome is possible. (But I have no problem in understanding that it does not implies $P(whole sample space) = 0$)</p>

<p>Maybe the above interpretation is flawed, if yes, please correct me, thank you.</p>
",<probability>
"<p>Let's say I have a signal $y(t) = Acos(2\pi f_c t)$, where $f_c$ is the carrier frequency and $t$ is the independent variable. Since I work with discrete signals i sample this signal with a sampling rate $f_s = 100f_c$, so I obtain $y[n] = \big\{ t \rightarrow \frac{n}{100f_c}\big\} = Acos(\frac{\pi}{50} n)$. Now if we consider $x= \frac{\pi}{50}n$, we have $y = Acos(x)$ where $x \sim unif[-\pi,\pi]$ and $A$ is deterministic. Which is the probability density funciton of variable $y$, i.e. $f_y(y)$ ?</p>

<p>Thanks a lot.</p>
",<probability>
"<p>This is my second question following this <a href=""http://math.stackexchange.com/questions/771551/a-3-minute-algebra-problem"">post</a>.</p>

<blockquote>
  <p>Three players are playing a game. They all have small amounts of
  money, let say: player 1 has $\$a$, player 2 has $\$b$, and player 3
  has $\$c$, where $a&lt;b&lt;c$. The probability of each player wins each
  turn of the game is $p$ for player 1, $q$ for player 2, $r$ for player
  3, and $s$ for having draw, where $p+q+r+s=1$. The losers will transfer a dollar ($\$1$) to the winner for each turn. The game ends until one
  player has all the money. What is the probability of each player going
  bankrupt? What is the expected number of turns so that only one player
  left as the winner?</p>
</blockquote>

<p>Suppose that they play blackjack, if player 1 gets 20 points, player 2 gets 19 points, and player 3 gets 18 points, then the winner of that turn is player 1, so the other two players must pay a dollar to the player 1. If there are two players get, for example, 19 points and the another player gets 18 points, then that turn is considered draw. If they all get 19 points, this is also considered draw. <strong>If one player loses all the money, then he will stop playing and only two player will continue the game with probability of winning for each player is $x$ and $y$, also the probability of draw is $z$</strong>. Each turn will be repeated until one player has all the money.</p>

<p>To be honest, I can't answer this question and I really don't get it. I left my answer sheet totally empty for this one. (─‿‿─)</p>

<p>Please help me to answer this question and provide a simple explanation about the answer you submit. Every answer would be greatly appreciated.</p>
",<probability>
"<p>I am interested in probabilistic or explicit ways to construct an $\epsilon$-net of the $l_2$ unit ball in $\mathbb{R}^{d}$.</p>

<p>I know that, for every $\epsilon &gt; 0$, there exists an $\epsilon$-net $\mathcal{N}_{\epsilon}$ for the unit sphere in $d$ dimensions such that
$$
M\triangleq\left|\mathcal{N}_{\epsilon}\right|
\le \left( 1+\frac{2}{\epsilon}\right)^{d}.
$$
(Lemma 5.2 in <a href=""http://www-personal.umich.edu/~romanv/papers/non-asymptotic-rmt-plain.pdf"" rel=""nofollow"">http://www-personal.umich.edu/~romanv/papers/non-asymptotic-rmt-plain.pdf</a>)
To my understanding, the aforementioned bound holds for an $\epsilon$-net of the entire ball, not only the sphere.</p>

<p>In the case of the sphere, we can construct an $\epsilon$-net with high probability, 
by drawing a sufficient number ($O(M\log{M})$) of independent random vectors according to a Gaussian distribution $N(\mathbf{0}, \mathbf{I})$, and normalizing the length to $1$.
I believe that one way to get an $\epsilon$-net for the ball,
would be to repeat the above procedure $O(1/\epsilon)$ times, for all spheres of radii $\epsilon, 2\epsilon,3\epsilon, \dots, 1$.
The union of the $\epsilon$-nets, should be able to cover the ball.
However, it would require $\tilde{O}\left((1+2/{\epsilon})^{d+1}\right)$ points (ignoring the logarithmic factor).</p>

<ul>
<li>Is there a simple way to construct an $\epsilon$-net for the unit ball directly, $\textit{i.e.}$, without constructing nets for multiple spheres?</li>
<li>Is there way to achieve the bound on $\left|\mathcal{N}_{\epsilon}\right|$ (possibly up to logarithmic factors)?</li>
</ul>

<p>I would appreciate any pointers to either probabilistic or explicit methods.</p>
",<probability>
"<p><strong>First of 2 part query</strong>: I have observed a 100 doctors and recorded the number of times they touch surfaces while in a room:</p>

<p>\begin{array}{l|c|c|c|c}
\text{Dr number}&amp;\text{Bed}&amp;\text{Table}&amp;\text{Chair}&amp;\text{Door}\\
\text{Dr } 1&amp;3&amp;2&amp;2&amp;1\\
\text{Dr } 2&amp;4&amp;1&amp;0&amp;1\\
\vdots&amp;\vdots &amp;\vdots &amp;\vdots &amp;\vdots\\
\text{Dr } 100&amp; 2&amp;3&amp;1&amp;1
\end{array}</p>

<p>I would like to calculate the probability of him touching the Table for example. Would it be:</p>

<p>\begin{array}{l|c|c|c|c|c}
&amp;\text{Bed}&amp;\text{Table}&amp;\text{Chair}&amp;\text{Door}&amp;\text{Total}\\
\text{Average contacts}&amp;3&amp;2&amp;1&amp;1&amp;\text{7}\\
P(\text{surface})&amp;3/7&amp;2/7&amp;1/7&amp;1/7&amp;1
\end{array}</p>

<p>This is confusing me but I think a fresh pair of eyes will spot it instantly.</p>

<p><strong>2nd part</strong>: I gave questionnaires out to some doctors who ticked boxes instead of giving contact numbers, i.e.:</p>

<p>\begin{array}{l|c|c|c|c}
\text{Dr number}&amp;\text{Bed}&amp;\text{Table}&amp;\text{Chair}&amp;\text{Door}\\
\text{Dr}  &amp;\checkmark&amp;\checkmark&amp;\checkmark&amp;\checkmark\\
\text{Dr } \checkmark&amp;\checkmark&amp;\checkmark&amp;\times&amp;\checkmark\\
\vdots&amp;\vdots &amp;\vdots &amp;\vdots &amp;\vdots\\
\text{Dr } 100&amp; \checkmark&amp;\checkmark&amp;\checkmark&amp;\checkmark
\end{array}</p>

<p>What can I deduce from this table of ticks to compare with the table of exact values? Or is it not worth anything? </p>

<p>Please ask for any clarification if needed,
Regards</p>

<p><strong>EDIT: Revised Surface contact Probability</strong>  Should this replace table 2?</p>

<p>\begin{array}{l|c|c|c|c|c}
&amp;\text{Bed}&amp;\text{Table}&amp;\text{Chair}&amp;\text{Door}&amp;\text{Total}\\
\text{Total contacts}&amp;9&amp;6&amp;3&amp;3&amp;\text{21}\\
P(\text{surface})&amp;9/21&amp;6/21&amp;3/21&amp;3/21&amp;1
\end{array}</p>
",<probability>
